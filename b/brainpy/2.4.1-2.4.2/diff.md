# Comparing `tmp/brainpy-2.4.1-py3-none-any.whl.zip` & `tmp/brainpy-2.4.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,291 +1,310 @@
-Zip file size: 574756 bytes, number of entries: 289
--rw-r--r--  2.0 unx    10037 b- defN 23-May-24 10:04 brainpy/__init__.py
--rw-r--r--  2.0 unx      661 b- defN 23-May-24 10:04 brainpy/analysis.py
--rw-r--r--  2.0 unx     1308 b- defN 23-May-24 10:04 brainpy/channels.py
--rw-r--r--  2.0 unx    18712 b- defN 23-May-24 10:04 brainpy/check.py
--rw-r--r--  2.0 unx      245 b- defN 23-May-24 10:04 brainpy/checkpoints.py
--rw-r--r--  2.0 unx     1243 b- defN 23-May-24 10:04 brainpy/connect.py
--rw-r--r--  2.0 unx      324 b- defN 23-May-24 10:04 brainpy/encoding.py
--rw-r--r--  2.0 unx     8551 b- defN 23-May-24 10:04 brainpy/errors.py
--rw-r--r--  2.0 unx      350 b- defN 23-May-24 10:04 brainpy/experimental.py
--rw-r--r--  2.0 unx     1123 b- defN 23-May-24 10:04 brainpy/initialize.py
--rw-r--r--  2.0 unx      335 b- defN 23-May-24 10:04 brainpy/inputs.py
--rw-r--r--  2.0 unx     1944 b- defN 23-May-24 10:04 brainpy/layers.py
--rw-r--r--  2.0 unx      963 b- defN 23-May-24 10:04 brainpy/losses.py
--rw-r--r--  2.0 unx      487 b- defN 23-May-24 10:04 brainpy/measure.py
--rw-r--r--  2.0 unx     1033 b- defN 23-May-24 10:04 brainpy/neurons.py
--rw-r--r--  2.0 unx     1013 b- defN 23-May-24 10:04 brainpy/optim.py
--rw-r--r--  2.0 unx      303 b- defN 23-May-24 10:04 brainpy/rates.py
--rw-r--r--  2.0 unx      466 b- defN 23-May-24 10:04 brainpy/running.py
--rw-r--r--  2.0 unx       51 b- defN 23-May-24 10:04 brainpy/testing.py
--rw-r--r--  2.0 unx      951 b- defN 23-May-24 10:04 brainpy/tools.py
--rw-r--r--  2.0 unx      241 b- defN 23-May-24 10:04 brainpy/types.py
--rw-r--r--  2.0 unx       24 b- defN 23-May-24 10:04 brainpy/_src/__init__.py
--rw-r--r--  2.0 unx      924 b- defN 23-May-24 10:04 brainpy/_src/checking.py
--rw-r--r--  2.0 unx     2622 b- defN 23-May-24 10:04 brainpy/_src/context.py
--rw-r--r--  2.0 unx     9982 b- defN 23-May-24 10:04 brainpy/_src/delay.py
--rw-r--r--  2.0 unx    48588 b- defN 23-May-24 10:04 brainpy/_src/dynsys.py
--rw-r--r--  2.0 unx      119 b- defN 23-May-24 10:04 brainpy/_src/modes.py
--rw-r--r--  2.0 unx     1359 b- defN 23-May-24 10:04 brainpy/_src/test_check.py
--rw-r--r--  2.0 unx      976 b- defN 23-May-24 10:04 brainpy/_src/types.py
--rw-r--r--  2.0 unx      846 b- defN 23-May-24 10:04 brainpy/_src/analysis/__init__.py
--rw-r--r--  2.0 unx      156 b- defN 23-May-24 10:04 brainpy/_src/analysis/base.py
--rw-r--r--  2.0 unx     1721 b- defN 23-May-24 10:04 brainpy/_src/analysis/constants.py
--rw-r--r--  2.0 unx     3924 b- defN 23-May-24 10:04 brainpy/_src/analysis/plotstyle.py
--rw-r--r--  2.0 unx     5651 b- defN 23-May-24 10:04 brainpy/_src/analysis/stability.py
--rw-r--r--  2.0 unx       52 b- defN 23-May-24 10:04 brainpy/_src/analysis/highdim/__init__.py
--rw-r--r--  2.0 unx    30951 b- defN 23-May-24 10:04 brainpy/_src/analysis/highdim/slow_points.py
--rw-r--r--  2.0 unx       93 b- defN 23-May-24 10:04 brainpy/_src/analysis/lowdim/__init__.py
--rw-r--r--  2.0 unx    44743 b- defN 23-May-24 10:04 brainpy/_src/analysis/lowdim/lowdim_analyzer.py
--rw-r--r--  2.0 unx    25000 b- defN 23-May-24 10:04 brainpy/_src/analysis/lowdim/lowdim_bifurcation.py
--rw-r--r--  2.0 unx    20273 b- defN 23-May-24 10:04 brainpy/_src/analysis/lowdim/lowdim_phase_plane.py
--rw-r--r--  2.0 unx      199 b- defN 23-May-24 10:04 brainpy/_src/analysis/utils/__init__.py
--rw-r--r--  2.0 unx     2840 b- defN 23-May-24 10:04 brainpy/_src/analysis/utils/function.py
--rw-r--r--  2.0 unx     3054 b- defN 23-May-24 10:04 brainpy/_src/analysis/utils/measurement.py
--rw-r--r--  2.0 unx     5302 b- defN 23-May-24 10:04 brainpy/_src/analysis/utils/model.py
--rw-r--r--  2.0 unx    19554 b- defN 23-May-24 10:04 brainpy/_src/analysis/utils/optimization.py
--rw-r--r--  2.0 unx     5822 b- defN 23-May-24 10:04 brainpy/_src/analysis/utils/others.py
--rw-r--r--  2.0 unx      158 b- defN 23-May-24 10:04 brainpy/_src/analysis/utils/outputs.py
--rw-r--r--  2.0 unx      967 b- defN 23-May-24 10:04 brainpy/_src/analysis/utils/visualization.py
--rw-r--r--  2.0 unx      175 b- defN 23-May-24 10:04 brainpy/_src/base/__init__.py
--rw-r--r--  2.0 unx       24 b- defN 23-May-24 10:04 brainpy/_src/base/base.py
--rw-r--r--  2.0 unx       24 b- defN 23-May-24 10:04 brainpy/_src/base/collector.py
--rw-r--r--  2.0 unx       25 b- defN 23-May-24 10:04 brainpy/_src/base/function.py
--rw-r--r--  2.0 unx      502 b- defN 23-May-24 10:04 brainpy/_src/base/io.py
--rw-r--r--  2.0 unx      305 b- defN 23-May-24 10:04 brainpy/_src/base/naming.py
--rw-r--r--  2.0 unx       24 b- defN 23-May-24 10:04 brainpy/_src/checkpoints/__init__.py
--rw-r--r--  2.0 unx    12240 b- defN 23-May-24 10:04 brainpy/_src/checkpoints/io.py
--rw-r--r--  2.0 unx    57388 b- defN 23-May-24 10:04 brainpy/_src/checkpoints/serialization.py
--rw-r--r--  2.0 unx      268 b- defN 23-May-24 10:04 brainpy/_src/connect/__init__.py
--rw-r--r--  2.0 unx    24303 b- defN 23-May-24 10:04 brainpy/_src/connect/base.py
--rw-r--r--  2.0 unx     4210 b- defN 23-May-24 10:04 brainpy/_src/connect/custom_conn.py
--rw-r--r--  2.0 unx    39143 b- defN 23-May-24 10:04 brainpy/_src/connect/random_conn.py
--rw-r--r--  2.0 unx     9173 b- defN 23-May-24 10:04 brainpy/_src/connect/regular_conn.py
--rw-r--r--  2.0 unx      338 b- defN 23-May-24 10:04 brainpy/_src/dyn/__init__.py
--rw-r--r--  2.0 unx      636 b- defN 23-May-24 10:04 brainpy/_src/dyn/_utils.py
--rw-r--r--  2.0 unx    24972 b- defN 23-May-24 10:04 brainpy/_src/dyn/runners.py
--rw-r--r--  2.0 unx    10267 b- defN 23-May-24 10:04 brainpy/_src/dyn/transform.py
--rw-r--r--  2.0 unx    40139 b- defN 23-May-24 10:04 brainpy/_src/dyn/channels/Ca.py
--rw-r--r--  2.0 unx     9130 b- defN 23-May-24 10:04 brainpy/_src/dyn/channels/IH.py
--rw-r--r--  2.0 unx    35637 b- defN 23-May-24 10:04 brainpy/_src/dyn/channels/K.py
--rw-r--r--  2.0 unx     4491 b- defN 23-May-24 10:04 brainpy/_src/dyn/channels/KCa.py
--rw-r--r--  2.0 unx    11936 b- defN 23-May-24 10:04 brainpy/_src/dyn/channels/Na.py
--rw-r--r--  2.0 unx      423 b- defN 23-May-24 10:04 brainpy/_src/dyn/channels/__init__.py
--rw-r--r--  2.0 unx     4039 b- defN 23-May-24 10:04 brainpy/_src/dyn/channels/base.py
--rw-r--r--  2.0 unx     2102 b- defN 23-May-24 10:04 brainpy/_src/dyn/channels/leaky.py
--rw-r--r--  2.0 unx       24 b- defN 23-May-24 10:04 brainpy/_src/dyn/networks/__init__.py
--rw-r--r--  2.0 unx      250 b- defN 23-May-24 10:04 brainpy/_src/dyn/networks/cann.py
--rw-r--r--  2.0 unx      177 b- defN 23-May-24 10:04 brainpy/_src/dyn/neurons/__init__.py
--rw-r--r--  2.0 unx    48741 b- defN 23-May-24 10:04 brainpy/_src/dyn/neurons/biological_models.py
--rw-r--r--  2.0 unx      595 b- defN 23-May-24 10:04 brainpy/_src/dyn/neurons/compat.py
--rw-r--r--  2.0 unx    13124 b- defN 23-May-24 10:04 brainpy/_src/dyn/neurons/fractional_models.py
--rw-r--r--  2.0 unx     5632 b- defN 23-May-24 10:04 brainpy/_src/dyn/neurons/input_groups.py
--rw-r--r--  2.0 unx     2311 b- defN 23-May-24 10:04 brainpy/_src/dyn/neurons/noise_groups.py
--rw-r--r--  2.0 unx    89191 b- defN 23-May-24 10:04 brainpy/_src/dyn/neurons/reduced_models.py
--rw-r--r--  2.0 unx       52 b- defN 23-May-24 10:04 brainpy/_src/dyn/rates/__init__.py
--rw-r--r--  2.0 unx    41039 b- defN 23-May-24 10:04 brainpy/_src/dyn/rates/populations.py
--rw-r--r--  2.0 unx      223 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses/__init__.py
--rw-r--r--  2.0 unx    36074 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses/abstract_models.py
--rw-r--r--  2.0 unx    21863 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses/biological_models.py
--rw-r--r--  2.0 unx    10250 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses/compat.py
--rw-r--r--  2.0 unx    11137 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses/delay_couplings.py
--rw-r--r--  2.0 unx     2023 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses/gap_junction.py
--rw-r--r--  2.0 unx     9212 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses/learning_rules.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses_v2/__init__.py
--rw-r--r--  2.0 unx    13658 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses_v2/abstract_synapses.py
--rw-r--r--  2.0 unx     4649 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses_v2/base.py
--rw-r--r--  2.0 unx     2621 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses_v2/others.py
--rw-r--r--  2.0 unx     2652 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses_v2/syn_outs.py
--rw-r--r--  2.0 unx     4726 b- defN 23-May-24 10:04 brainpy/_src/dyn/synapses_v2/syn_plasticity.py
--rw-r--r--  2.0 unx       73 b- defN 23-May-24 10:04 brainpy/_src/dyn/synouts/__init__.py
--rw-r--r--  2.0 unx     2634 b- defN 23-May-24 10:04 brainpy/_src/dyn/synouts/conductances.py
--rw-r--r--  2.0 unx     3279 b- defN 23-May-24 10:04 brainpy/_src/dyn/synouts/ions.py
--rw-r--r--  2.0 unx       62 b- defN 23-May-24 10:04 brainpy/_src/dyn/synplast/__init__.py
--rw-r--r--  2.0 unx       24 b- defN 23-May-24 10:04 brainpy/_src/dyn/synplast/long_term_plasticity.py
--rw-r--r--  2.0 unx     5168 b- defN 23-May-24 10:04 brainpy/_src/dyn/synplast/short_term_plasticity.py
--rw-r--r--  2.0 unx      114 b- defN 23-May-24 10:04 brainpy/_src/encoding/__init__.py
--rw-r--r--  2.0 unx      364 b- defN 23-May-24 10:04 brainpy/_src/encoding/base.py
--rw-r--r--  2.0 unx     4769 b- defN 23-May-24 10:04 brainpy/_src/encoding/stateful_encoding.py
--rw-r--r--  2.0 unx     2249 b- defN 23-May-24 10:04 brainpy/_src/encoding/stateless_encoding.py
--rw-r--r--  2.0 unx      154 b- defN 23-May-24 10:04 brainpy/_src/initialize/__init__.py
--rw-r--r--  2.0 unx      614 b- defN 23-May-24 10:04 brainpy/_src/initialize/base.py
--rw-r--r--  2.0 unx    11571 b- defN 23-May-24 10:04 brainpy/_src/initialize/decay_inits.py
--rw-r--r--  2.0 unx     9310 b- defN 23-May-24 10:04 brainpy/_src/initialize/generic.py
--rw-r--r--  2.0 unx      554 b- defN 23-May-24 10:04 brainpy/_src/initialize/others.py
--rw-r--r--  2.0 unx    13534 b- defN 23-May-24 10:04 brainpy/_src/initialize/random_inits.py
--rw-r--r--  2.0 unx     2266 b- defN 23-May-24 10:04 brainpy/_src/initialize/regular_inits.py
--rw-r--r--  2.0 unx      173 b- defN 23-May-24 10:04 brainpy/_src/inputs/__init__.py
--rw-r--r--  2.0 unx    11406 b- defN 23-May-24 10:04 brainpy/_src/inputs/currents.py
--rw-r--r--  2.0 unx     1189 b- defN 23-May-24 10:04 brainpy/_src/integrators/__init__.py
--rw-r--r--  2.0 unx     4154 b- defN 23-May-24 10:04 brainpy/_src/integrators/base.py
--rw-r--r--  2.0 unx     2946 b- defN 23-May-24 10:04 brainpy/_src/integrators/constants.py
--rw-r--r--  2.0 unx     8158 b- defN 23-May-24 10:04 brainpy/_src/integrators/joint_eq.py
--rw-r--r--  2.0 unx    11802 b- defN 23-May-24 10:04 brainpy/_src/integrators/runner.py
--rw-r--r--  2.0 unx     4455 b- defN 23-May-24 10:04 brainpy/_src/integrators/utils.py
--rw-r--r--  2.0 unx    15058 b- defN 23-May-24 10:04 brainpy/_src/integrators/fde/Caputo.py
--rw-r--r--  2.0 unx     7233 b- defN 23-May-24 10:04 brainpy/_src/integrators/fde/GL.py
--rw-r--r--  2.0 unx      110 b- defN 23-May-24 10:04 brainpy/_src/integrators/fde/__init__.py
--rw-r--r--  2.0 unx     2771 b- defN 23-May-24 10:04 brainpy/_src/integrators/fde/base.py
--rw-r--r--  2.0 unx     2706 b- defN 23-May-24 10:04 brainpy/_src/integrators/fde/generic.py
--rw-r--r--  2.0 unx      220 b- defN 23-May-24 10:04 brainpy/_src/integrators/ode/__init__.py
--rw-r--r--  2.0 unx    17892 b- defN 23-May-24 10:04 brainpy/_src/integrators/ode/adaptive_rk.py
--rw-r--r--  2.0 unx     4845 b- defN 23-May-24 10:04 brainpy/_src/integrators/ode/base.py
--rw-r--r--  2.0 unx     1493 b- defN 23-May-24 10:04 brainpy/_src/integrators/ode/common.py
--rw-r--r--  2.0 unx    25974 b- defN 23-May-24 10:04 brainpy/_src/integrators/ode/explicit_rk.py
--rw-r--r--  2.0 unx    13764 b- defN 23-May-24 10:04 brainpy/_src/integrators/ode/exponential.py
--rw-r--r--  2.0 unx     4139 b- defN 23-May-24 10:04 brainpy/_src/integrators/ode/generic.py
--rw-r--r--  2.0 unx       24 b- defN 23-May-24 10:04 brainpy/_src/integrators/pde/__init__.py
--rw-r--r--  2.0 unx       98 b- defN 23-May-24 10:04 brainpy/_src/integrators/pde/base.py
--rw-r--r--  2.0 unx      184 b- defN 23-May-24 10:04 brainpy/_src/integrators/sde/__init__.py
--rw-r--r--  2.0 unx     3310 b- defN 23-May-24 10:04 brainpy/_src/integrators/sde/base.py
--rw-r--r--  2.0 unx     3877 b- defN 23-May-24 10:04 brainpy/_src/integrators/sde/generic.py
--rw-r--r--  2.0 unx    24171 b- defN 23-May-24 10:04 brainpy/_src/integrators/sde/normal.py
--rw-r--r--  2.0 unx    17060 b- defN 23-May-24 10:04 brainpy/_src/integrators/sde/srk_scalar.py
--rw-r--r--  2.0 unx    17016 b- defN 23-May-24 10:04 brainpy/_src/integrators/sde/srk_strong.py
--rw-r--r--  2.0 unx      268 b- defN 23-May-24 10:04 brainpy/_src/layers/__init__.py
--rw-r--r--  2.0 unx      197 b- defN 23-May-24 10:04 brainpy/_src/layers/base.py
--rw-r--r--  2.0 unx    29797 b- defN 23-May-24 10:04 brainpy/_src/layers/conv.py
--rw-r--r--  2.0 unx     1468 b- defN 23-May-24 10:04 brainpy/_src/layers/dropout.py
--rw-r--r--  2.0 unx     1803 b- defN 23-May-24 10:04 brainpy/_src/layers/function.py
--rw-r--r--  2.0 unx     4106 b- defN 23-May-24 10:04 brainpy/_src/layers/interoperation_flax.py
--rw-r--r--  2.0 unx     7105 b- defN 23-May-24 10:04 brainpy/_src/layers/linear.py
--rw-r--r--  2.0 unx    25687 b- defN 23-May-24 10:04 brainpy/_src/layers/normalization.py
--rw-r--r--  2.0 unx     6687 b- defN 23-May-24 10:04 brainpy/_src/layers/nvar.py
--rw-r--r--  2.0 unx    34199 b- defN 23-May-24 10:04 brainpy/_src/layers/pooling.py
--rw-r--r--  2.0 unx     8906 b- defN 23-May-24 10:04 brainpy/_src/layers/reservoir.py
--rw-r--r--  2.0 unx    27026 b- defN 23-May-24 10:04 brainpy/_src/layers/rnncells.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-24 10:04 brainpy/_src/layers/tests/__init__.py
--rw-r--r--  2.0 unx     4756 b- defN 23-May-24 10:04 brainpy/_src/layers/tests/test_conv.py
--rw-r--r--  2.0 unx     5073 b- defN 23-May-24 10:04 brainpy/_src/layers/tests/test_pooling.py
--rw-r--r--  2.0 unx      276 b- defN 23-May-24 10:04 brainpy/_src/losses/__init__.py
--rw-r--r--  2.0 unx    22010 b- defN 23-May-24 10:04 brainpy/_src/losses/comparison.py
--rw-r--r--  2.0 unx     2370 b- defN 23-May-24 10:04 brainpy/_src/losses/regularization.py
--rw-r--r--  2.0 unx      792 b- defN 23-May-24 10:04 brainpy/_src/losses/utils.py
--rw-r--r--  2.0 unx       63 b- defN 23-May-24 10:04 brainpy/_src/lsbnn/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-24 10:04 brainpy/_src/lsbnn/neurons_abstract.py
--rw-r--r--  2.0 unx     1488 b- defN 23-May-24 10:04 brainpy/_src/math/__init__.py
--rw-r--r--  2.0 unx     1792 b- defN 23-May-24 10:04 brainpy/_src/math/_utils.py
--rw-r--r--  2.0 unx    13411 b- defN 23-May-24 10:04 brainpy/_src/math/activations.py
--rw-r--r--  2.0 unx    29884 b- defN 23-May-24 10:04 brainpy/_src/math/compat_numpy.py
--rw-r--r--  2.0 unx     6488 b- defN 23-May-24 10:04 brainpy/_src/math/compat_pytorch.py
--rw-r--r--  2.0 unx    17887 b- defN 23-May-24 10:04 brainpy/_src/math/compat_tensorflow.py
--rw-r--r--  2.0 unx      911 b- defN 23-May-24 10:04 brainpy/_src/math/datatypes.py
--rw-r--r--  2.0 unx    15918 b- defN 23-May-24 10:04 brainpy/_src/math/delayvars.py
--rw-r--r--  2.0 unx    16825 b- defN 23-May-24 10:04 brainpy/_src/math/environment.py
--rw-r--r--  2.0 unx     1498 b- defN 23-May-24 10:04 brainpy/_src/math/fft.py
--rw-r--r--  2.0 unx     8866 b- defN 23-May-24 10:04 brainpy/_src/math/index_tricks.py
--rw-r--r--  2.0 unx     2523 b- defN 23-May-24 10:04 brainpy/_src/math/interoperability.py
--rw-r--r--  2.0 unx     1792 b- defN 23-May-24 10:04 brainpy/_src/math/linalg.py
--rw-r--r--  2.0 unx     2319 b- defN 23-May-24 10:04 brainpy/_src/math/modes.py
--rw-r--r--  2.0 unx    45121 b- defN 23-May-24 10:04 brainpy/_src/math/ndarray.py
--rw-r--r--  2.0 unx     2255 b- defN 23-May-24 10:04 brainpy/_src/math/others.py
--rw-r--r--  2.0 unx    15894 b- defN 23-May-24 10:04 brainpy/_src/math/pre_syn_post.py
--rw-r--r--  2.0 unx    78615 b- defN 23-May-24 10:04 brainpy/_src/math/random.py
--rw-r--r--  2.0 unx     2119 b- defN 23-May-24 10:04 brainpy/_src/math/remove_vmap.py
--rw-r--r--  2.0 unx       61 b- defN 23-May-24 10:04 brainpy/_src/math/event/__init__.py
--rw-r--r--  2.0 unx    17787 b- defN 23-May-24 10:04 brainpy/_src/math/event/_csr_matvec.py
--rw-r--r--  2.0 unx     5062 b- defN 23-May-24 10:04 brainpy/_src/math/event/_info_collection.py
--rw-r--r--  2.0 unx       53 b- defN 23-May-24 10:04 brainpy/_src/math/jitconn/__init__.py
--rw-r--r--  2.0 unx    24908 b- defN 23-May-24 10:04 brainpy/_src/math/jitconn/_event_matvec.py
--rw-r--r--  2.0 unx    27403 b- defN 23-May-24 10:04 brainpy/_src/math/jitconn/_matvec.py
--rw-r--r--  2.0 unx      914 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/__init__.py
--rw-r--r--  2.0 unx     2869 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/_tools.py
--rw-r--r--  2.0 unx      758 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/_utils.py
--rw-r--r--  2.0 unx    38682 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/autograd.py
--rw-r--r--  2.0 unx    22499 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/base.py
--rw-r--r--  2.0 unx     5931 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/collectors.py
--rw-r--r--  2.0 unx    27560 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/controls.py
--rw-r--r--  2.0 unx     2999 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/function.py
--rw-r--r--  2.0 unx    15077 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/jit.py
--rw-r--r--  2.0 unx     1637 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/naming.py
--rw-r--r--  2.0 unx    17774 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/parallels.py
--rw-r--r--  2.0 unx    11821 b- defN 23-May-24 10:04 brainpy/_src/math/object_transform/variables.py
--rw-r--r--  2.0 unx      204 b- defN 23-May-24 10:04 brainpy/_src/math/op_registers/__init__.py
--rw-r--r--  2.0 unx     1051 b- defN 23-May-24 10:04 brainpy/_src/math/op_registers/utils.py
--rw-r--r--  2.0 unx     7130 b- defN 23-May-24 10:04 brainpy/_src/math/op_registers/numba_approach/__init__.py
--rw-r--r--  2.0 unx     5129 b- defN 23-May-24 10:04 brainpy/_src/math/op_registers/numba_approach/cpu_translation.py
--rw-r--r--  2.0 unx     2587 b- defN 23-May-24 10:04 brainpy/_src/math/op_registers/numba_approach/test_ei_net.py
--rw-r--r--  2.0 unx      116 b- defN 23-May-24 10:04 brainpy/_src/math/sparse/__init__.py
--rw-r--r--  2.0 unx    14286 b- defN 23-May-24 10:04 brainpy/_src/math/sparse/_bsr_mm.py
--rw-r--r--  2.0 unx     8134 b- defN 23-May-24 10:04 brainpy/_src/math/sparse/_bsr_mv.py
--rw-r--r--  2.0 unx     7127 b- defN 23-May-24 10:04 brainpy/_src/math/sparse/_coo_mv.py
--rw-r--r--  2.0 unx    16697 b- defN 23-May-24 10:04 brainpy/_src/math/sparse/_csr_mv.py
--rw-r--r--  2.0 unx     5021 b- defN 23-May-24 10:04 brainpy/_src/math/sparse/_utils.py
--rw-r--r--  2.0 unx       79 b- defN 23-May-24 10:04 brainpy/_src/math/surrogate/__init__.py
--rw-r--r--  2.0 unx     7216 b- defN 23-May-24 10:04 brainpy/_src/math/surrogate/_compt.py
--rw-r--r--  2.0 unx    40736 b- defN 23-May-24 10:04 brainpy/_src/math/surrogate/_one_input.py
--rw-r--r--  2.0 unx     1492 b- defN 23-May-24 10:04 brainpy/_src/math/surrogate/_two_inputs.py
--rw-r--r--  2.0 unx     3665 b- defN 23-May-24 10:04 brainpy/_src/math/surrogate/_utils.py
--rw-r--r--  2.0 unx      287 b- defN 23-May-24 10:04 brainpy/_src/measure/__init__.py
--rw-r--r--  2.0 unx    10102 b- defN 23-May-24 10:04 brainpy/_src/measure/correlation.py
--rw-r--r--  2.0 unx     1770 b- defN 23-May-24 10:04 brainpy/_src/measure/firings.py
--rw-r--r--  2.0 unx     3896 b- defN 23-May-24 10:04 brainpy/_src/measure/lfp.py
--rw-r--r--  2.0 unx       75 b- defN 23-May-24 10:04 brainpy/_src/optimizers/__init__.py
--rw-r--r--  2.0 unx    41331 b- defN 23-May-24 10:04 brainpy/_src/optimizers/optimizer.py
--rw-r--r--  2.0 unx    13240 b- defN 23-May-24 10:04 brainpy/_src/optimizers/scheduler.py
--rw-r--r--  2.0 unx      525 b- defN 23-May-24 10:04 brainpy/_src/running/__init__.py
--rw-r--r--  2.0 unx      269 b- defN 23-May-24 10:04 brainpy/_src/running/constants.py
--rw-r--r--  2.0 unx     4913 b- defN 23-May-24 10:04 brainpy/_src/running/jax_multiprocessing.py
--rw-r--r--  2.0 unx     2976 b- defN 23-May-24 10:04 brainpy/_src/running/native_multiprocessing.py
--rw-r--r--  2.0 unx     6995 b- defN 23-May-24 10:04 brainpy/_src/running/pathos_multiprocessing.py
--rw-r--r--  2.0 unx     9779 b- defN 23-May-24 10:04 brainpy/_src/running/runner.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-24 10:04 brainpy/_src/testing/__init__.py
--rw-r--r--  2.0 unx      422 b- defN 23-May-24 10:04 brainpy/_src/testing/base.py
--rw-r--r--  2.0 unx      159 b- defN 23-May-24 10:04 brainpy/_src/tools/__init__.py
--rw-r--r--  2.0 unx     7326 b- defN 23-May-24 10:04 brainpy/_src/tools/codes.py
--rw-r--r--  2.0 unx     5882 b- defN 23-May-24 10:04 brainpy/_src/tools/dicts.py
--rw-r--r--  2.0 unx      223 b- defN 23-May-24 10:04 brainpy/_src/tools/math_util.py
--rw-r--r--  2.0 unx     4424 b- defN 23-May-24 10:04 brainpy/_src/tools/others.py
--rw-r--r--  2.0 unx     1407 b- defN 23-May-24 10:04 brainpy/_src/tools/package.py
--rw-r--r--  2.0 unx      659 b- defN 23-May-24 10:04 brainpy/_src/train/__init__.py
--rw-r--r--  2.0 unx     1970 b- defN 23-May-24 10:04 brainpy/_src/train/_utils.py
--rw-r--r--  2.0 unx    24067 b- defN 23-May-24 10:04 brainpy/_src/train/back_propagation.py
--rw-r--r--  2.0 unx     2978 b- defN 23-May-24 10:04 brainpy/_src/train/base.py
--rw-r--r--  2.0 unx    10034 b- defN 23-May-24 10:04 brainpy/_src/train/offline.py
--rw-r--r--  2.0 unx    10356 b- defN 23-May-24 10:04 brainpy/_src/train/online.py
--rw-r--r--  2.0 unx       77 b- defN 23-May-24 10:04 brainpy/_src/visualization/__init__.py
--rw-r--r--  2.0 unx     3544 b- defN 23-May-24 10:04 brainpy/_src/visualization/base.py
--rw-r--r--  2.0 unx      841 b- defN 23-May-24 10:04 brainpy/_src/visualization/figures.py
--rw-r--r--  2.0 unx    14603 b- defN 23-May-24 10:04 brainpy/_src/visualization/plots.py
--rw-r--r--  2.0 unx     1026 b- defN 23-May-24 10:04 brainpy/_src/visualization/styles.py
--rw-r--r--  2.0 unx       90 b- defN 23-May-24 10:04 brainpy/algorithms/__init__.py
--rw-r--r--  2.0 unx    17344 b- defN 23-May-24 10:04 brainpy/algorithms/offline.py
--rw-r--r--  2.0 unx     6284 b- defN 23-May-24 10:04 brainpy/algorithms/online.py
--rw-r--r--  2.0 unx     2656 b- defN 23-May-24 10:04 brainpy/algorithms/utils.py
--rw-r--r--  2.0 unx      128 b- defN 23-May-24 10:04 brainpy/integrators/__init__.py
--rw-r--r--  2.0 unx      576 b- defN 23-May-24 10:04 brainpy/integrators/fde.py
--rw-r--r--  2.0 unx     1061 b- defN 23-May-24 10:04 brainpy/integrators/ode.py
--rw-r--r--  2.0 unx      679 b- defN 23-May-24 10:04 brainpy/integrators/sde.py
--rw-r--r--  2.0 unx     1518 b- defN 23-May-24 10:04 brainpy/math/__init__.py
--rw-r--r--  2.0 unx      612 b- defN 23-May-24 10:04 brainpy/math/activations.py
--rw-r--r--  2.0 unx     8074 b- defN 23-May-24 10:04 brainpy/math/compat_numpy.py
--rw-r--r--  2.0 unx      469 b- defN 23-May-24 10:04 brainpy/math/compat_pytorch.py
--rw-r--r--  2.0 unx      932 b- defN 23-May-24 10:04 brainpy/math/compat_tensorflow.py
--rw-r--r--  2.0 unx      498 b- defN 23-May-24 10:04 brainpy/math/datatypes.py
--rw-r--r--  2.0 unx      255 b- defN 23-May-24 10:04 brainpy/math/delayvars.py
--rw-r--r--  2.0 unx      943 b- defN 23-May-24 10:04 brainpy/math/environment.py
--rw-r--r--  2.0 unx       75 b- defN 23-May-24 10:04 brainpy/math/event.py
--rw-r--r--  2.0 unx      402 b- defN 23-May-24 10:04 brainpy/math/fft.py
--rw-r--r--  2.0 unx      217 b- defN 23-May-24 10:04 brainpy/math/interoperability.py
--rw-r--r--  2.0 unx      292 b- defN 23-May-24 10:04 brainpy/math/jitconn.py
--rw-r--r--  2.0 unx      470 b- defN 23-May-24 10:04 brainpy/math/linalg.py
--rw-r--r--  2.0 unx      292 b- defN 23-May-24 10:04 brainpy/math/modes.py
--rw-r--r--  2.0 unx      150 b- defN 23-May-24 10:04 brainpy/math/ndarray.py
--rw-r--r--  2.0 unx      909 b- defN 23-May-24 10:04 brainpy/math/object_base.py
--rw-r--r--  2.0 unx      651 b- defN 23-May-24 10:04 brainpy/math/object_transform.py
--rw-r--r--  2.0 unx      127 b- defN 23-May-24 10:04 brainpy/math/op_register.py
--rw-r--r--  2.0 unx      257 b- defN 23-May-24 10:04 brainpy/math/others.py
--rw-r--r--  2.0 unx      331 b- defN 23-May-24 10:04 brainpy/math/pre_syn_post.py
--rw-r--r--  2.0 unx     1770 b- defN 23-May-24 10:04 brainpy/math/random.py
--rw-r--r--  2.0 unx      167 b- defN 23-May-24 10:04 brainpy/math/sparse.py
--rw-r--r--  2.0 unx     1186 b- defN 23-May-24 10:04 brainpy/math/surrogate.py
--rw-r--r--  2.0 unx       73 b- defN 23-May-24 10:04 brainpy/synapses/__init__.py
--rw-r--r--  2.0 unx      612 b- defN 23-May-24 10:04 brainpy/synapses/dynamics.py
--rw-r--r--  2.0 unx      180 b- defN 23-May-24 10:04 brainpy/synapses/synouts.py
--rw-r--r--  2.0 unx      117 b- defN 23-May-24 10:04 brainpy/synapses/synplast.py
--rw-r--r--  2.0 unx    35100 b- defN 23-May-24 10:04 brainpy-2.4.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     4489 b- defN 23-May-24 10:04 brainpy-2.4.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-24 10:04 brainpy-2.4.1.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-May-24 10:04 brainpy-2.4.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    25958 b- defN 23-May-24 10:04 brainpy-2.4.1.dist-info/RECORD
-289 files, 2256206 bytes uncompressed, 533544 bytes compressed:  76.4%
+Zip file size: 630975 bytes, number of entries: 308
+-rw-r--r--  2.0 unx    10155 b- defN 23-Jun-27 09:01 brainpy/__init__.py
+-rw-r--r--  2.0 unx      661 b- defN 23-Jun-27 09:01 brainpy/analysis.py
+-rw-r--r--  2.0 unx     1308 b- defN 23-Jun-27 09:01 brainpy/channels.py
+-rw-r--r--  2.0 unx    19357 b- defN 23-Jun-27 09:01 brainpy/check.py
+-rw-r--r--  2.0 unx      407 b- defN 23-Jun-27 09:01 brainpy/checkpoints.py
+-rw-r--r--  2.0 unx     1275 b- defN 23-Jun-27 09:01 brainpy/connect.py
+-rw-r--r--  2.0 unx     2690 b- defN 23-Jun-27 09:01 brainpy/dnn.py
+-rw-r--r--  2.0 unx      324 b- defN 23-Jun-27 09:01 brainpy/encoding.py
+-rw-r--r--  2.0 unx     7520 b- defN 23-Jun-27 09:01 brainpy/errors.py
+-rw-r--r--  2.0 unx      334 b- defN 23-Jun-27 09:01 brainpy/experimental.py
+-rw-r--r--  2.0 unx     1123 b- defN 23-Jun-27 09:01 brainpy/initialize.py
+-rw-r--r--  2.0 unx      335 b- defN 23-Jun-27 09:01 brainpy/inputs.py
+-rw-r--r--  2.0 unx       20 b- defN 23-Jun-27 09:01 brainpy/layers.py
+-rw-r--r--  2.0 unx     1086 b- defN 23-Jun-27 09:01 brainpy/losses.py
+-rw-r--r--  2.0 unx      487 b- defN 23-Jun-27 09:01 brainpy/measure.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-27 09:01 brainpy/mixin.py
+-rw-r--r--  2.0 unx     1013 b- defN 23-Jun-27 09:01 brainpy/neurons.py
+-rw-r--r--  2.0 unx     1013 b- defN 23-Jun-27 09:01 brainpy/optim.py
+-rw-r--r--  2.0 unx      299 b- defN 23-Jun-27 09:01 brainpy/rates.py
+-rw-r--r--  2.0 unx      466 b- defN 23-Jun-27 09:01 brainpy/running.py
+-rw-r--r--  2.0 unx       51 b- defN 23-Jun-27 09:01 brainpy/testing.py
+-rw-r--r--  2.0 unx     1046 b- defN 23-Jun-27 09:01 brainpy/tools.py
+-rw-r--r--  2.0 unx      265 b- defN 23-Jun-27 09:01 brainpy/types.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-27 09:01 brainpy/_src/__init__.py
+-rw-r--r--  2.0 unx     9945 b- defN 23-Jun-27 09:01 brainpy/_src/_delay.py
+-rw-r--r--  2.0 unx     2457 b- defN 23-Jun-27 09:01 brainpy/_src/checking.py
+-rw-r--r--  2.0 unx     2631 b- defN 23-Jun-27 09:01 brainpy/_src/context.py
+-rw-r--r--  2.0 unx    22860 b- defN 23-Jun-27 09:01 brainpy/_src/delay.py
+-rw-r--r--  2.0 unx     1500 b- defN 23-Jun-27 09:01 brainpy/_src/deprecations.py
+-rw-r--r--  2.0 unx    49179 b- defN 23-Jun-27 09:01 brainpy/_src/dynsys.py
+-rw-r--r--  2.0 unx     2328 b- defN 23-Jun-27 09:01 brainpy/_src/mixin.py
+-rw-r--r--  2.0 unx     1101 b- defN 23-Jun-27 09:01 brainpy/_src/modes.py
+-rw-r--r--  2.0 unx    24973 b- defN 23-Jun-27 09:01 brainpy/_src/runners.py
+-rw-r--r--  2.0 unx    10267 b- defN 23-Jun-27 09:01 brainpy/_src/transform.py
+-rw-r--r--  2.0 unx     1065 b- defN 23-Jun-27 09:01 brainpy/_src/types.py
+-rw-r--r--  2.0 unx      846 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/__init__.py
+-rw-r--r--  2.0 unx      156 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/base.py
+-rw-r--r--  2.0 unx     1721 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/constants.py
+-rw-r--r--  2.0 unx     3924 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/plotstyle.py
+-rw-r--r--  2.0 unx     5651 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/stability.py
+-rw-r--r--  2.0 unx       52 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/highdim/__init__.py
+-rw-r--r--  2.0 unx    30947 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/highdim/slow_points.py
+-rw-r--r--  2.0 unx       93 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/lowdim/__init__.py
+-rw-r--r--  2.0 unx    44743 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/lowdim/lowdim_analyzer.py
+-rw-r--r--  2.0 unx    25000 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/lowdim/lowdim_bifurcation.py
+-rw-r--r--  2.0 unx    20273 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/lowdim/lowdim_phase_plane.py
+-rw-r--r--  2.0 unx      199 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/utils/__init__.py
+-rw-r--r--  2.0 unx     2840 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/utils/function.py
+-rw-r--r--  2.0 unx     3054 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/utils/measurement.py
+-rw-r--r--  2.0 unx     5298 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/utils/model.py
+-rw-r--r--  2.0 unx    19554 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/utils/optimization.py
+-rw-r--r--  2.0 unx     5822 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/utils/others.py
+-rw-r--r--  2.0 unx      158 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/utils/outputs.py
+-rw-r--r--  2.0 unx      967 b- defN 23-Jun-27 09:01 brainpy/_src/analysis/utils/visualization.py
+-rw-r--r--  2.0 unx      169 b- defN 23-Jun-27 09:01 brainpy/_src/base/__init__.py
+-rw-r--r--  2.0 unx       24 b- defN 23-Jun-27 09:01 brainpy/_src/base/collector.py
+-rw-r--r--  2.0 unx       25 b- defN 23-Jun-27 09:01 brainpy/_src/base/function.py
+-rw-r--r--  2.0 unx     1029 b- defN 23-Jun-27 09:01 brainpy/_src/base/io.py
+-rw-r--r--  2.0 unx      305 b- defN 23-Jun-27 09:01 brainpy/_src/base/naming.py
+-rw-r--r--  2.0 unx       24 b- defN 23-Jun-27 09:01 brainpy/_src/checkpoints/__init__.py
+-rw-r--r--  2.0 unx    12240 b- defN 23-Jun-27 09:01 brainpy/_src/checkpoints/io.py
+-rw-r--r--  2.0 unx    57361 b- defN 23-Jun-27 09:01 brainpy/_src/checkpoints/serialization.py
+-rw-r--r--  2.0 unx      268 b- defN 23-Jun-27 09:01 brainpy/_src/connect/__init__.py
+-rw-r--r--  2.0 unx    24714 b- defN 23-Jun-27 09:01 brainpy/_src/connect/base.py
+-rw-r--r--  2.0 unx     4210 b- defN 23-Jun-27 09:01 brainpy/_src/connect/custom_conn.py
+-rw-r--r--  2.0 unx    40725 b- defN 23-Jun-27 09:01 brainpy/_src/connect/random_conn.py
+-rw-r--r--  2.0 unx     9173 b- defN 23-Jun-27 09:01 brainpy/_src/connect/regular_conn.py
+-rw-r--r--  2.0 unx      295 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/__init__.py
+-rw-r--r--  2.0 unx    32514 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/activations.py
+-rw-r--r--  2.0 unx      197 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/base.py
+-rw-r--r--  2.0 unx    29730 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/conv.py
+-rw-r--r--  2.0 unx     1302 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/dropout.py
+-rw-r--r--  2.0 unx     1803 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/function.py
+-rw-r--r--  2.0 unx     4106 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/interoperation_flax.py
+-rw-r--r--  2.0 unx    35318 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/linear.py
+-rw-r--r--  2.0 unx    25687 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/normalization.py
+-rw-r--r--  2.0 unx     6732 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/nvar.py
+-rw-r--r--  2.0 unx    34199 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/pooling.py
+-rw-r--r--  2.0 unx     8875 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/reservoir.py
+-rw-r--r--  2.0 unx    27026 b- defN 23-Jun-27 09:01 brainpy/_src/dnn/rnncells.py
+-rw-r--r--  2.0 unx        1 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/__init__.py
+-rw-r--r--  2.0 unx     1382 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/_docs.py
+-rw-r--r--  2.0 unx     4882 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/base.py
+-rw-r--r--  2.0 unx     5485 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/projections.py
+-rw-r--r--  2.0 unx    40139 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/channels/Ca.py
+-rw-r--r--  2.0 unx     9190 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/channels/IH.py
+-rw-r--r--  2.0 unx    35645 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/channels/K.py
+-rw-r--r--  2.0 unx     4491 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/channels/KCa.py
+-rw-r--r--  2.0 unx    11936 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/channels/Na.py
+-rw-r--r--  2.0 unx      423 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/channels/__init__.py
+-rw-r--r--  2.0 unx     4039 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/channels/base.py
+-rw-r--r--  2.0 unx     2102 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/channels/leaky.py
+-rw-r--r--  2.0 unx       21 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/neurons/__init__.py
+-rw-r--r--  2.0 unx    44733 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/neurons/hh.py
+-rw-r--r--  2.0 unx     5860 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/neurons/input.py
+-rw-r--r--  2.0 unx    84993 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/neurons/lif.py
+-rw-r--r--  2.0 unx       28 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/others/__init__.py
+-rw-r--r--  2.0 unx     4141 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/others/common.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/synapses/__init__.py
+-rw-r--r--  2.0 unx    28351 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/synapses/dynamics.py
+-rw-r--r--  2.0 unx     3147 b- defN 23-Jun-27 09:01 brainpy/_src/dyn/synapses/outputs.py
+-rw-r--r--  2.0 unx      114 b- defN 23-Jun-27 09:01 brainpy/_src/encoding/__init__.py
+-rw-r--r--  2.0 unx      364 b- defN 23-Jun-27 09:01 brainpy/_src/encoding/base.py
+-rw-r--r--  2.0 unx     4769 b- defN 23-Jun-27 09:01 brainpy/_src/encoding/stateful_encoding.py
+-rw-r--r--  2.0 unx     2156 b- defN 23-Jun-27 09:01 brainpy/_src/encoding/stateless_encoding.py
+-rw-r--r--  2.0 unx      154 b- defN 23-Jun-27 09:01 brainpy/_src/initialize/__init__.py
+-rw-r--r--  2.0 unx      614 b- defN 23-Jun-27 09:01 brainpy/_src/initialize/base.py
+-rw-r--r--  2.0 unx    13428 b- defN 23-Jun-27 09:01 brainpy/_src/initialize/decay_inits.py
+-rw-r--r--  2.0 unx    10608 b- defN 23-Jun-27 09:01 brainpy/_src/initialize/generic.py
+-rw-r--r--  2.0 unx      554 b- defN 23-Jun-27 09:01 brainpy/_src/initialize/others.py
+-rw-r--r--  2.0 unx    13534 b- defN 23-Jun-27 09:01 brainpy/_src/initialize/random_inits.py
+-rw-r--r--  2.0 unx     2266 b- defN 23-Jun-27 09:01 brainpy/_src/initialize/regular_inits.py
+-rw-r--r--  2.0 unx      173 b- defN 23-Jun-27 09:01 brainpy/_src/inputs/__init__.py
+-rw-r--r--  2.0 unx    11432 b- defN 23-Jun-27 09:01 brainpy/_src/inputs/currents.py
+-rw-r--r--  2.0 unx     1189 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/__init__.py
+-rw-r--r--  2.0 unx     4154 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/base.py
+-rw-r--r--  2.0 unx     2946 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/constants.py
+-rw-r--r--  2.0 unx     8158 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/joint_eq.py
+-rw-r--r--  2.0 unx    11802 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/runner.py
+-rw-r--r--  2.0 unx     4455 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/utils.py
+-rw-r--r--  2.0 unx    15040 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/fde/Caputo.py
+-rw-r--r--  2.0 unx     7233 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/fde/GL.py
+-rw-r--r--  2.0 unx      110 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/fde/__init__.py
+-rw-r--r--  2.0 unx     2771 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/fde/base.py
+-rw-r--r--  2.0 unx     2706 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/fde/generic.py
+-rw-r--r--  2.0 unx      220 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/ode/__init__.py
+-rw-r--r--  2.0 unx    17892 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/ode/adaptive_rk.py
+-rw-r--r--  2.0 unx     4845 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/ode/base.py
+-rw-r--r--  2.0 unx     1493 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/ode/common.py
+-rw-r--r--  2.0 unx    25974 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/ode/explicit_rk.py
+-rw-r--r--  2.0 unx    13756 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/ode/exponential.py
+-rw-r--r--  2.0 unx     4139 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/ode/generic.py
+-rw-r--r--  2.0 unx       24 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/pde/__init__.py
+-rw-r--r--  2.0 unx       98 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/pde/base.py
+-rw-r--r--  2.0 unx      184 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/sde/__init__.py
+-rw-r--r--  2.0 unx     3321 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/sde/base.py
+-rw-r--r--  2.0 unx     3877 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/sde/generic.py
+-rw-r--r--  2.0 unx    24171 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/sde/normal.py
+-rw-r--r--  2.0 unx    17060 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/sde/srk_scalar.py
+-rw-r--r--  2.0 unx    17016 b- defN 23-Jun-27 09:01 brainpy/_src/integrators/sde/srk_strong.py
+-rw-r--r--  2.0 unx      274 b- defN 23-Jun-27 09:01 brainpy/_src/losses/__init__.py
+-rw-r--r--  2.0 unx      445 b- defN 23-Jun-27 09:01 brainpy/_src/losses/base.py
+-rw-r--r--  2.0 unx    40982 b- defN 23-Jun-27 09:01 brainpy/_src/losses/comparison.py
+-rw-r--r--  2.0 unx     2368 b- defN 23-Jun-27 09:01 brainpy/_src/losses/regularization.py
+-rw-r--r--  2.0 unx      792 b- defN 23-Jun-27 09:01 brainpy/_src/losses/utils.py
+-rw-r--r--  2.0 unx     1488 b- defN 23-Jun-27 09:01 brainpy/_src/math/__init__.py
+-rw-r--r--  2.0 unx     1792 b- defN 23-Jun-27 09:01 brainpy/_src/math/_utils.py
+-rw-r--r--  2.0 unx    18933 b- defN 23-Jun-27 09:01 brainpy/_src/math/activations.py
+-rw-r--r--  2.0 unx    29884 b- defN 23-Jun-27 09:01 brainpy/_src/math/compat_numpy.py
+-rw-r--r--  2.0 unx     6488 b- defN 23-Jun-27 09:01 brainpy/_src/math/compat_pytorch.py
+-rw-r--r--  2.0 unx    17887 b- defN 23-Jun-27 09:01 brainpy/_src/math/compat_tensorflow.py
+-rw-r--r--  2.0 unx      911 b- defN 23-Jun-27 09:01 brainpy/_src/math/datatypes.py
+-rw-r--r--  2.0 unx    15861 b- defN 23-Jun-27 09:01 brainpy/_src/math/delayvars.py
+-rw-r--r--  2.0 unx    16825 b- defN 23-Jun-27 09:01 brainpy/_src/math/environment.py
+-rw-r--r--  2.0 unx     1498 b- defN 23-Jun-27 09:01 brainpy/_src/math/fft.py
+-rw-r--r--  2.0 unx     8866 b- defN 23-Jun-27 09:01 brainpy/_src/math/index_tricks.py
+-rw-r--r--  2.0 unx     2523 b- defN 23-Jun-27 09:01 brainpy/_src/math/interoperability.py
+-rw-r--r--  2.0 unx     1792 b- defN 23-Jun-27 09:01 brainpy/_src/math/linalg.py
+-rw-r--r--  2.0 unx     2319 b- defN 23-Jun-27 09:01 brainpy/_src/math/modes.py
+-rw-r--r--  2.0 unx    47277 b- defN 23-Jun-27 09:01 brainpy/_src/math/ndarray.py
+-rw-r--r--  2.0 unx     2255 b- defN 23-Jun-27 09:01 brainpy/_src/math/others.py
+-rw-r--r--  2.0 unx    15894 b- defN 23-Jun-27 09:01 brainpy/_src/math/pre_syn_post.py
+-rw-r--r--  2.0 unx    78579 b- defN 23-Jun-27 09:01 brainpy/_src/math/random.py
+-rw-r--r--  2.0 unx     2088 b- defN 23-Jun-27 09:01 brainpy/_src/math/remove_vmap.py
+-rw-r--r--  2.0 unx     3578 b- defN 23-Jun-27 09:01 brainpy/_src/math/sharding.py
+-rw-r--r--  2.0 unx       61 b- defN 23-Jun-27 09:01 brainpy/_src/math/event/__init__.py
+-rw-r--r--  2.0 unx    17787 b- defN 23-Jun-27 09:01 brainpy/_src/math/event/_csr_matvec.py
+-rw-r--r--  2.0 unx     5062 b- defN 23-Jun-27 09:01 brainpy/_src/math/event/_info_collection.py
+-rw-r--r--  2.0 unx       53 b- defN 23-Jun-27 09:01 brainpy/_src/math/jitconn/__init__.py
+-rw-r--r--  2.0 unx    26368 b- defN 23-Jun-27 09:01 brainpy/_src/math/jitconn/_event_matvec.py
+-rw-r--r--  2.0 unx    28793 b- defN 23-Jun-27 09:01 brainpy/_src/math/jitconn/_matvec.py
+-rw-r--r--  2.0 unx      914 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/__init__.py
+-rw-r--r--  2.0 unx     3615 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/_tools.py
+-rw-r--r--  2.0 unx      758 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/_utils.py
+-rw-r--r--  2.0 unx    40562 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/autograd.py
+-rw-r--r--  2.0 unx    22773 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/base.py
+-rw-r--r--  2.0 unx     5931 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/collectors.py
+-rw-r--r--  2.0 unx    32211 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/controls.py
+-rw-r--r--  2.0 unx     2999 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/function.py
+-rw-r--r--  2.0 unx    16336 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/jit.py
+-rw-r--r--  2.0 unx     1637 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/naming.py
+-rw-r--r--  2.0 unx    17774 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/parallels.py
+-rw-r--r--  2.0 unx    14573 b- defN 23-Jun-27 09:01 brainpy/_src/math/object_transform/variables.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-27 09:01 brainpy/_src/math/op_registers/__init__.py
+-rw-r--r--  2.0 unx     1051 b- defN 23-Jun-27 09:01 brainpy/_src/math/op_registers/utils.py
+-rw-r--r--  2.0 unx     7129 b- defN 23-Jun-27 09:01 brainpy/_src/math/op_registers/numba_approach/__init__.py
+-rw-r--r--  2.0 unx     5129 b- defN 23-Jun-27 09:01 brainpy/_src/math/op_registers/numba_approach/cpu_translation.py
+-rw-r--r--  2.0 unx      142 b- defN 23-Jun-27 09:01 brainpy/_src/math/sparse/__init__.py
+-rw-r--r--  2.0 unx    14576 b- defN 23-Jun-27 09:01 brainpy/_src/math/sparse/_bsr_mm.py
+-rw-r--r--  2.0 unx     8134 b- defN 23-Jun-27 09:01 brainpy/_src/math/sparse/_bsr_mv.py
+-rw-r--r--  2.0 unx     7127 b- defN 23-Jun-27 09:01 brainpy/_src/math/sparse/_coo_mv.py
+-rw-r--r--  2.0 unx    16697 b- defN 23-Jun-27 09:01 brainpy/_src/math/sparse/_csr_mv.py
+-rw-r--r--  2.0 unx     4439 b- defN 23-Jun-27 09:01 brainpy/_src/math/sparse/_jax_prim.py
+-rw-r--r--  2.0 unx     5021 b- defN 23-Jun-27 09:01 brainpy/_src/math/sparse/_utils.py
+-rw-r--r--  2.0 unx       99 b- defN 23-Jun-27 09:01 brainpy/_src/math/surrogate/__init__.py
+-rw-r--r--  2.0 unx     7216 b- defN 23-Jun-27 09:01 brainpy/_src/math/surrogate/_compt.py
+-rw-r--r--  2.0 unx    42623 b- defN 23-Jun-27 09:01 brainpy/_src/math/surrogate/_one_input.py
+-rw-r--r--  2.0 unx     1492 b- defN 23-Jun-27 09:01 brainpy/_src/math/surrogate/_two_inputs.py
+-rw-r--r--  2.0 unx     3665 b- defN 23-Jun-27 09:01 brainpy/_src/math/surrogate/_utils.py
+-rw-r--r--  2.0 unx      243 b- defN 23-Jun-27 09:01 brainpy/_src/math/surrogate/base.py
+-rw-r--r--  2.0 unx      287 b- defN 23-Jun-27 09:01 brainpy/_src/measure/__init__.py
+-rw-r--r--  2.0 unx    10102 b- defN 23-Jun-27 09:01 brainpy/_src/measure/correlation.py
+-rw-r--r--  2.0 unx     1770 b- defN 23-Jun-27 09:01 brainpy/_src/measure/firings.py
+-rw-r--r--  2.0 unx     3896 b- defN 23-Jun-27 09:01 brainpy/_src/measure/lfp.py
+-rw-r--r--  2.0 unx      177 b- defN 23-Jun-27 09:01 brainpy/_src/neurons/__init__.py
+-rw-r--r--  2.0 unx    48772 b- defN 23-Jun-27 09:01 brainpy/_src/neurons/biological_models.py
+-rw-r--r--  2.0 unx      595 b- defN 23-Jun-27 09:01 brainpy/_src/neurons/compat.py
+-rw-r--r--  2.0 unx    13124 b- defN 23-Jun-27 09:01 brainpy/_src/neurons/fractional_models.py
+-rw-r--r--  2.0 unx     5477 b- defN 23-Jun-27 09:01 brainpy/_src/neurons/input_groups.py
+-rw-r--r--  2.0 unx     2301 b- defN 23-Jun-27 09:01 brainpy/_src/neurons/noise_groups.py
+-rw-r--r--  2.0 unx    92062 b- defN 23-Jun-27 09:01 brainpy/_src/neurons/reduced_models.py
+-rw-r--r--  2.0 unx       75 b- defN 23-Jun-27 09:01 brainpy/_src/optimizers/__init__.py
+-rw-r--r--  2.0 unx    41331 b- defN 23-Jun-27 09:01 brainpy/_src/optimizers/optimizer.py
+-rw-r--r--  2.0 unx    13240 b- defN 23-Jun-27 09:01 brainpy/_src/optimizers/scheduler.py
+-rw-r--r--  2.0 unx       52 b- defN 23-Jun-27 09:01 brainpy/_src/rates/__init__.py
+-rw-r--r--  2.0 unx    41216 b- defN 23-Jun-27 09:01 brainpy/_src/rates/populations.py
+-rw-r--r--  2.0 unx      525 b- defN 23-Jun-27 09:01 brainpy/_src/running/__init__.py
+-rw-r--r--  2.0 unx      269 b- defN 23-Jun-27 09:01 brainpy/_src/running/constants.py
+-rw-r--r--  2.0 unx     4913 b- defN 23-Jun-27 09:01 brainpy/_src/running/jax_multiprocessing.py
+-rw-r--r--  2.0 unx     2976 b- defN 23-Jun-27 09:01 brainpy/_src/running/native_multiprocessing.py
+-rw-r--r--  2.0 unx     6995 b- defN 23-Jun-27 09:01 brainpy/_src/running/pathos_multiprocessing.py
+-rw-r--r--  2.0 unx     9779 b- defN 23-Jun-27 09:01 brainpy/_src/running/runner.py
+-rw-r--r--  2.0 unx      223 b- defN 23-Jun-27 09:01 brainpy/_src/synapses/__init__.py
+-rw-r--r--  2.0 unx    35980 b- defN 23-Jun-27 09:01 brainpy/_src/synapses/abstract_models.py
+-rw-r--r--  2.0 unx    21845 b- defN 23-Jun-27 09:01 brainpy/_src/synapses/biological_models.py
+-rw-r--r--  2.0 unx    10246 b- defN 23-Jun-27 09:01 brainpy/_src/synapses/compat.py
+-rw-r--r--  2.0 unx    11133 b- defN 23-Jun-27 09:01 brainpy/_src/synapses/delay_couplings.py
+-rw-r--r--  2.0 unx     2023 b- defN 23-Jun-27 09:01 brainpy/_src/synapses/gap_junction.py
+-rw-r--r--  2.0 unx     9212 b- defN 23-Jun-27 09:01 brainpy/_src/synapses/learning_rules.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-27 09:01 brainpy/_src/synapses_v2/__init__.py
+-rw-r--r--  2.0 unx    13557 b- defN 23-Jun-27 09:01 brainpy/_src/synapses_v2/abstract_synapses.py
+-rw-r--r--  2.0 unx     4649 b- defN 23-Jun-27 09:01 brainpy/_src/synapses_v2/base.py
+-rw-r--r--  2.0 unx     2553 b- defN 23-Jun-27 09:01 brainpy/_src/synapses_v2/others.py
+-rw-r--r--  2.0 unx     2648 b- defN 23-Jun-27 09:01 brainpy/_src/synapses_v2/syn_outs.py
+-rw-r--r--  2.0 unx     4722 b- defN 23-Jun-27 09:01 brainpy/_src/synapses_v2/syn_plasticity.py
+-rw-r--r--  2.0 unx       73 b- defN 23-Jun-27 09:01 brainpy/_src/synouts/__init__.py
+-rw-r--r--  2.0 unx     2634 b- defN 23-Jun-27 09:01 brainpy/_src/synouts/conductances.py
+-rw-r--r--  2.0 unx     3279 b- defN 23-Jun-27 09:01 brainpy/_src/synouts/ions.py
+-rw-r--r--  2.0 unx       62 b- defN 23-Jun-27 09:01 brainpy/_src/synplast/__init__.py
+-rw-r--r--  2.0 unx       24 b- defN 23-Jun-27 09:01 brainpy/_src/synplast/long_term_plasticity.py
+-rw-r--r--  2.0 unx     5168 b- defN 23-Jun-27 09:01 brainpy/_src/synplast/short_term_plasticity.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-27 09:01 brainpy/_src/testing/__init__.py
+-rw-r--r--  2.0 unx      422 b- defN 23-Jun-27 09:01 brainpy/_src/testing/base.py
+-rw-r--r--  2.0 unx      182 b- defN 23-Jun-27 09:01 brainpy/_src/tools/__init__.py
+-rw-r--r--  2.0 unx     7448 b- defN 23-Jun-27 09:01 brainpy/_src/tools/codes.py
+-rw-r--r--  2.0 unx     5882 b- defN 23-Jun-27 09:01 brainpy/_src/tools/dicts.py
+-rw-r--r--  2.0 unx     1015 b- defN 23-Jun-27 09:01 brainpy/_src/tools/install.py
+-rw-r--r--  2.0 unx      223 b- defN 23-Jun-27 09:01 brainpy/_src/tools/math_util.py
+-rw-r--r--  2.0 unx     4425 b- defN 23-Jun-27 09:01 brainpy/_src/tools/others.py
+-rw-r--r--  2.0 unx     1407 b- defN 23-Jun-27 09:01 brainpy/_src/tools/package.py
+-rw-r--r--  2.0 unx      562 b- defN 23-Jun-27 09:01 brainpy/_src/train/__init__.py
+-rw-r--r--  2.0 unx     1970 b- defN 23-Jun-27 09:01 brainpy/_src/train/_utils.py
+-rw-r--r--  2.0 unx    24067 b- defN 23-Jun-27 09:01 brainpy/_src/train/back_propagation.py
+-rw-r--r--  2.0 unx     2974 b- defN 23-Jun-27 09:01 brainpy/_src/train/base.py
+-rw-r--r--  2.0 unx    10034 b- defN 23-Jun-27 09:01 brainpy/_src/train/offline.py
+-rw-r--r--  2.0 unx    10356 b- defN 23-Jun-27 09:01 brainpy/_src/train/online.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-27 09:01 brainpy/_src/visualization/__init__.py
+-rw-r--r--  2.0 unx     3544 b- defN 23-Jun-27 09:01 brainpy/_src/visualization/base.py
+-rw-r--r--  2.0 unx      841 b- defN 23-Jun-27 09:01 brainpy/_src/visualization/figures.py
+-rw-r--r--  2.0 unx    14603 b- defN 23-Jun-27 09:01 brainpy/_src/visualization/plots.py
+-rw-r--r--  2.0 unx     1026 b- defN 23-Jun-27 09:01 brainpy/_src/visualization/styles.py
+-rw-r--r--  2.0 unx       90 b- defN 23-Jun-27 09:01 brainpy/algorithms/__init__.py
+-rw-r--r--  2.0 unx    17344 b- defN 23-Jun-27 09:01 brainpy/algorithms/offline.py
+-rw-r--r--  2.0 unx     6284 b- defN 23-Jun-27 09:01 brainpy/algorithms/online.py
+-rw-r--r--  2.0 unx     2656 b- defN 23-Jun-27 09:01 brainpy/algorithms/utils.py
+-rw-r--r--  2.0 unx      121 b- defN 23-Jun-27 09:01 brainpy/dyn/__init__.py
+-rw-r--r--  2.0 unx      820 b- defN 23-Jun-27 09:01 brainpy/dyn/channels.py
+-rw-r--r--  2.0 unx      737 b- defN 23-Jun-27 09:01 brainpy/dyn/neurons.py
+-rw-r--r--  2.0 unx       69 b- defN 23-Jun-27 09:01 brainpy/dyn/others.py
+-rw-r--r--  2.0 unx       81 b- defN 23-Jun-27 09:01 brainpy/dyn/projections.py
+-rw-r--r--  2.0 unx      271 b- defN 23-Jun-27 09:01 brainpy/dyn/synapses.py
+-rw-r--r--  2.0 unx      128 b- defN 23-Jun-27 09:01 brainpy/integrators/__init__.py
+-rw-r--r--  2.0 unx      576 b- defN 23-Jun-27 09:01 brainpy/integrators/fde.py
+-rw-r--r--  2.0 unx     1061 b- defN 23-Jun-27 09:01 brainpy/integrators/ode.py
+-rw-r--r--  2.0 unx      679 b- defN 23-Jun-27 09:01 brainpy/integrators/sde.py
+-rw-r--r--  2.0 unx     4768 b- defN 23-Jun-27 09:01 brainpy/math/__init__.py
+-rw-r--r--  2.0 unx      780 b- defN 23-Jun-27 09:01 brainpy/math/activations.py
+-rw-r--r--  2.0 unx     8074 b- defN 23-Jun-27 09:01 brainpy/math/compat_numpy.py
+-rw-r--r--  2.0 unx      469 b- defN 23-Jun-27 09:01 brainpy/math/compat_pytorch.py
+-rw-r--r--  2.0 unx      932 b- defN 23-Jun-27 09:01 brainpy/math/compat_tensorflow.py
+-rw-r--r--  2.0 unx      498 b- defN 23-Jun-27 09:01 brainpy/math/datatypes.py
+-rw-r--r--  2.0 unx      255 b- defN 23-Jun-27 09:01 brainpy/math/delayvars.py
+-rw-r--r--  2.0 unx      943 b- defN 23-Jun-27 09:01 brainpy/math/environment.py
+-rw-r--r--  2.0 unx       75 b- defN 23-Jun-27 09:01 brainpy/math/event.py
+-rw-r--r--  2.0 unx      402 b- defN 23-Jun-27 09:01 brainpy/math/fft.py
+-rw-r--r--  2.0 unx      217 b- defN 23-Jun-27 09:01 brainpy/math/interoperability.py
+-rw-r--r--  2.0 unx      292 b- defN 23-Jun-27 09:01 brainpy/math/jitconn.py
+-rw-r--r--  2.0 unx      470 b- defN 23-Jun-27 09:01 brainpy/math/linalg.py
+-rw-r--r--  2.0 unx      292 b- defN 23-Jun-27 09:01 brainpy/math/modes.py
+-rw-r--r--  2.0 unx      150 b- defN 23-Jun-27 09:01 brainpy/math/ndarray.py
+-rw-r--r--  2.0 unx     1225 b- defN 23-Jun-27 09:01 brainpy/math/object_base.py
+-rw-r--r--  2.0 unx      651 b- defN 23-Jun-27 09:01 brainpy/math/object_transform.py
+-rw-r--r--  2.0 unx      127 b- defN 23-Jun-27 09:01 brainpy/math/op_register.py
+-rw-r--r--  2.0 unx      257 b- defN 23-Jun-27 09:01 brainpy/math/others.py
+-rw-r--r--  2.0 unx      331 b- defN 23-Jun-27 09:01 brainpy/math/pre_syn_post.py
+-rw-r--r--  2.0 unx     1770 b- defN 23-Jun-27 09:01 brainpy/math/random.py
+-rw-r--r--  2.0 unx      213 b- defN 23-Jun-27 09:01 brainpy/math/sharding.py
+-rw-r--r--  2.0 unx      164 b- defN 23-Jun-27 09:01 brainpy/math/sparse.py
+-rw-r--r--  2.0 unx     1249 b- defN 23-Jun-27 09:01 brainpy/math/surrogate.py
+-rw-r--r--  2.0 unx       73 b- defN 23-Jun-27 09:01 brainpy/synapses/__init__.py
+-rw-r--r--  2.0 unx      596 b- defN 23-Jun-27 09:01 brainpy/synapses/dynamics.py
+-rw-r--r--  2.0 unx      172 b- defN 23-Jun-27 09:01 brainpy/synapses/synouts.py
+-rw-r--r--  2.0 unx      113 b- defN 23-Jun-27 09:01 brainpy/synapses/synplast.py
+-rw-r--r--  2.0 unx    35100 b- defN 23-Jun-27 09:01 brainpy-2.4.2.dist-info/LICENSE
+-rw-r--r--  2.0 unx     4131 b- defN 23-Jun-27 09:01 brainpy-2.4.2.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-27 09:01 brainpy-2.4.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Jun-27 09:01 brainpy-2.4.2.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    27335 b- defN 23-Jun-27 09:01 brainpy-2.4.2.dist-info/RECORD
+308 files, 2583636 bytes uncompressed, 587735 bytes compressed:  77.3%
```

## zipnote {}

```diff
@@ -12,14 +12,17 @@
 
 Filename: brainpy/checkpoints.py
 Comment: 
 
 Filename: brainpy/connect.py
 Comment: 
 
+Filename: brainpy/dnn.py
+Comment: 
+
 Filename: brainpy/encoding.py
 Comment: 
 
 Filename: brainpy/errors.py
 Comment: 
 
 Filename: brainpy/experimental.py
@@ -36,14 +39,17 @@
 
 Filename: brainpy/losses.py
 Comment: 
 
 Filename: brainpy/measure.py
 Comment: 
 
+Filename: brainpy/mixin.py
+Comment: 
+
 Filename: brainpy/neurons.py
 Comment: 
 
 Filename: brainpy/optim.py
 Comment: 
 
 Filename: brainpy/rates.py
@@ -60,30 +66,42 @@
 
 Filename: brainpy/types.py
 Comment: 
 
 Filename: brainpy/_src/__init__.py
 Comment: 
 
+Filename: brainpy/_src/_delay.py
+Comment: 
+
 Filename: brainpy/_src/checking.py
 Comment: 
 
 Filename: brainpy/_src/context.py
 Comment: 
 
 Filename: brainpy/_src/delay.py
 Comment: 
 
+Filename: brainpy/_src/deprecations.py
+Comment: 
+
 Filename: brainpy/_src/dynsys.py
 Comment: 
 
+Filename: brainpy/_src/mixin.py
+Comment: 
+
 Filename: brainpy/_src/modes.py
 Comment: 
 
-Filename: brainpy/_src/test_check.py
+Filename: brainpy/_src/runners.py
+Comment: 
+
+Filename: brainpy/_src/transform.py
 Comment: 
 
 Filename: brainpy/_src/types.py
 Comment: 
 
 Filename: brainpy/_src/analysis/__init__.py
 Comment: 
@@ -141,17 +159,14 @@
 
 Filename: brainpy/_src/analysis/utils/visualization.py
 Comment: 
 
 Filename: brainpy/_src/base/__init__.py
 Comment: 
 
-Filename: brainpy/_src/base/base.py
-Comment: 
-
 Filename: brainpy/_src/base/collector.py
 Comment: 
 
 Filename: brainpy/_src/base/function.py
 Comment: 
 
 Filename: brainpy/_src/base/io.py
@@ -180,138 +195,114 @@
 
 Filename: brainpy/_src/connect/random_conn.py
 Comment: 
 
 Filename: brainpy/_src/connect/regular_conn.py
 Comment: 
 
-Filename: brainpy/_src/dyn/__init__.py
-Comment: 
-
-Filename: brainpy/_src/dyn/_utils.py
-Comment: 
-
-Filename: brainpy/_src/dyn/runners.py
-Comment: 
-
-Filename: brainpy/_src/dyn/transform.py
+Filename: brainpy/_src/dnn/__init__.py
 Comment: 
 
-Filename: brainpy/_src/dyn/channels/Ca.py
+Filename: brainpy/_src/dnn/activations.py
 Comment: 
 
-Filename: brainpy/_src/dyn/channels/IH.py
+Filename: brainpy/_src/dnn/base.py
 Comment: 
 
-Filename: brainpy/_src/dyn/channels/K.py
+Filename: brainpy/_src/dnn/conv.py
 Comment: 
 
-Filename: brainpy/_src/dyn/channels/KCa.py
+Filename: brainpy/_src/dnn/dropout.py
 Comment: 
 
-Filename: brainpy/_src/dyn/channels/Na.py
+Filename: brainpy/_src/dnn/function.py
 Comment: 
 
-Filename: brainpy/_src/dyn/channels/__init__.py
+Filename: brainpy/_src/dnn/interoperation_flax.py
 Comment: 
 
-Filename: brainpy/_src/dyn/channels/base.py
+Filename: brainpy/_src/dnn/linear.py
 Comment: 
 
-Filename: brainpy/_src/dyn/channels/leaky.py
+Filename: brainpy/_src/dnn/normalization.py
 Comment: 
 
-Filename: brainpy/_src/dyn/networks/__init__.py
+Filename: brainpy/_src/dnn/nvar.py
 Comment: 
 
-Filename: brainpy/_src/dyn/networks/cann.py
-Comment: 
-
-Filename: brainpy/_src/dyn/neurons/__init__.py
+Filename: brainpy/_src/dnn/pooling.py
 Comment: 
 
-Filename: brainpy/_src/dyn/neurons/biological_models.py
+Filename: brainpy/_src/dnn/reservoir.py
 Comment: 
 
-Filename: brainpy/_src/dyn/neurons/compat.py
+Filename: brainpy/_src/dnn/rnncells.py
 Comment: 
 
-Filename: brainpy/_src/dyn/neurons/fractional_models.py
-Comment: 
-
-Filename: brainpy/_src/dyn/neurons/input_groups.py
-Comment: 
-
-Filename: brainpy/_src/dyn/neurons/noise_groups.py
-Comment: 
-
-Filename: brainpy/_src/dyn/neurons/reduced_models.py
-Comment: 
-
-Filename: brainpy/_src/dyn/rates/__init__.py
+Filename: brainpy/_src/dyn/__init__.py
 Comment: 
 
-Filename: brainpy/_src/dyn/rates/populations.py
+Filename: brainpy/_src/dyn/_docs.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses/__init__.py
+Filename: brainpy/_src/dyn/base.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses/abstract_models.py
+Filename: brainpy/_src/dyn/projections.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses/biological_models.py
+Filename: brainpy/_src/dyn/channels/Ca.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses/compat.py
+Filename: brainpy/_src/dyn/channels/IH.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses/delay_couplings.py
+Filename: brainpy/_src/dyn/channels/K.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses/gap_junction.py
+Filename: brainpy/_src/dyn/channels/KCa.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses/learning_rules.py
+Filename: brainpy/_src/dyn/channels/Na.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses_v2/__init__.py
+Filename: brainpy/_src/dyn/channels/__init__.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses_v2/abstract_synapses.py
+Filename: brainpy/_src/dyn/channels/base.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses_v2/base.py
+Filename: brainpy/_src/dyn/channels/leaky.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses_v2/others.py
+Filename: brainpy/_src/dyn/neurons/__init__.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses_v2/syn_outs.py
+Filename: brainpy/_src/dyn/neurons/hh.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synapses_v2/syn_plasticity.py
+Filename: brainpy/_src/dyn/neurons/input.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synouts/__init__.py
+Filename: brainpy/_src/dyn/neurons/lif.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synouts/conductances.py
+Filename: brainpy/_src/dyn/others/__init__.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synouts/ions.py
+Filename: brainpy/_src/dyn/others/common.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synplast/__init__.py
+Filename: brainpy/_src/dyn/synapses/__init__.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synplast/long_term_plasticity.py
+Filename: brainpy/_src/dyn/synapses/dynamics.py
 Comment: 
 
-Filename: brainpy/_src/dyn/synplast/short_term_plasticity.py
+Filename: brainpy/_src/dyn/synapses/outputs.py
 Comment: 
 
 Filename: brainpy/_src/encoding/__init__.py
 Comment: 
 
 Filename: brainpy/_src/encoding/base.py
 Comment: 
@@ -423,77 +414,29 @@
 
 Filename: brainpy/_src/integrators/sde/srk_scalar.py
 Comment: 
 
 Filename: brainpy/_src/integrators/sde/srk_strong.py
 Comment: 
 
-Filename: brainpy/_src/layers/__init__.py
-Comment: 
-
-Filename: brainpy/_src/layers/base.py
-Comment: 
-
-Filename: brainpy/_src/layers/conv.py
-Comment: 
-
-Filename: brainpy/_src/layers/dropout.py
-Comment: 
-
-Filename: brainpy/_src/layers/function.py
-Comment: 
-
-Filename: brainpy/_src/layers/interoperation_flax.py
-Comment: 
-
-Filename: brainpy/_src/layers/linear.py
-Comment: 
-
-Filename: brainpy/_src/layers/normalization.py
-Comment: 
-
-Filename: brainpy/_src/layers/nvar.py
-Comment: 
-
-Filename: brainpy/_src/layers/pooling.py
-Comment: 
-
-Filename: brainpy/_src/layers/reservoir.py
-Comment: 
-
-Filename: brainpy/_src/layers/rnncells.py
-Comment: 
-
-Filename: brainpy/_src/layers/tests/__init__.py
-Comment: 
-
-Filename: brainpy/_src/layers/tests/test_conv.py
+Filename: brainpy/_src/losses/__init__.py
 Comment: 
 
-Filename: brainpy/_src/layers/tests/test_pooling.py
-Comment: 
-
-Filename: brainpy/_src/losses/__init__.py
+Filename: brainpy/_src/losses/base.py
 Comment: 
 
 Filename: brainpy/_src/losses/comparison.py
 Comment: 
 
 Filename: brainpy/_src/losses/regularization.py
 Comment: 
 
 Filename: brainpy/_src/losses/utils.py
 Comment: 
 
-Filename: brainpy/_src/lsbnn/__init__.py
-Comment: 
-
-Filename: brainpy/_src/lsbnn/neurons_abstract.py
-Comment: 
-
 Filename: brainpy/_src/math/__init__.py
 Comment: 
 
 Filename: brainpy/_src/math/_utils.py
 Comment: 
 
 Filename: brainpy/_src/math/activations.py
@@ -543,14 +486,17 @@
 
 Filename: brainpy/_src/math/random.py
 Comment: 
 
 Filename: brainpy/_src/math/remove_vmap.py
 Comment: 
 
+Filename: brainpy/_src/math/sharding.py
+Comment: 
+
 Filename: brainpy/_src/math/event/__init__.py
 Comment: 
 
 Filename: brainpy/_src/math/event/_csr_matvec.py
 Comment: 
 
 Filename: brainpy/_src/math/event/_info_collection.py
@@ -609,17 +555,14 @@
 
 Filename: brainpy/_src/math/op_registers/numba_approach/__init__.py
 Comment: 
 
 Filename: brainpy/_src/math/op_registers/numba_approach/cpu_translation.py
 Comment: 
 
-Filename: brainpy/_src/math/op_registers/numba_approach/test_ei_net.py
-Comment: 
-
 Filename: brainpy/_src/math/sparse/__init__.py
 Comment: 
 
 Filename: brainpy/_src/math/sparse/_bsr_mm.py
 Comment: 
 
 Filename: brainpy/_src/math/sparse/_bsr_mv.py
@@ -627,14 +570,17 @@
 
 Filename: brainpy/_src/math/sparse/_coo_mv.py
 Comment: 
 
 Filename: brainpy/_src/math/sparse/_csr_mv.py
 Comment: 
 
+Filename: brainpy/_src/math/sparse/_jax_prim.py
+Comment: 
+
 Filename: brainpy/_src/math/sparse/_utils.py
 Comment: 
 
 Filename: brainpy/_src/math/surrogate/__init__.py
 Comment: 
 
 Filename: brainpy/_src/math/surrogate/_compt.py
@@ -645,35 +591,65 @@
 
 Filename: brainpy/_src/math/surrogate/_two_inputs.py
 Comment: 
 
 Filename: brainpy/_src/math/surrogate/_utils.py
 Comment: 
 
+Filename: brainpy/_src/math/surrogate/base.py
+Comment: 
+
 Filename: brainpy/_src/measure/__init__.py
 Comment: 
 
 Filename: brainpy/_src/measure/correlation.py
 Comment: 
 
 Filename: brainpy/_src/measure/firings.py
 Comment: 
 
 Filename: brainpy/_src/measure/lfp.py
 Comment: 
 
+Filename: brainpy/_src/neurons/__init__.py
+Comment: 
+
+Filename: brainpy/_src/neurons/biological_models.py
+Comment: 
+
+Filename: brainpy/_src/neurons/compat.py
+Comment: 
+
+Filename: brainpy/_src/neurons/fractional_models.py
+Comment: 
+
+Filename: brainpy/_src/neurons/input_groups.py
+Comment: 
+
+Filename: brainpy/_src/neurons/noise_groups.py
+Comment: 
+
+Filename: brainpy/_src/neurons/reduced_models.py
+Comment: 
+
 Filename: brainpy/_src/optimizers/__init__.py
 Comment: 
 
 Filename: brainpy/_src/optimizers/optimizer.py
 Comment: 
 
 Filename: brainpy/_src/optimizers/scheduler.py
 Comment: 
 
+Filename: brainpy/_src/rates/__init__.py
+Comment: 
+
+Filename: brainpy/_src/rates/populations.py
+Comment: 
+
 Filename: brainpy/_src/running/__init__.py
 Comment: 
 
 Filename: brainpy/_src/running/constants.py
 Comment: 
 
 Filename: brainpy/_src/running/jax_multiprocessing.py
@@ -684,14 +660,71 @@
 
 Filename: brainpy/_src/running/pathos_multiprocessing.py
 Comment: 
 
 Filename: brainpy/_src/running/runner.py
 Comment: 
 
+Filename: brainpy/_src/synapses/__init__.py
+Comment: 
+
+Filename: brainpy/_src/synapses/abstract_models.py
+Comment: 
+
+Filename: brainpy/_src/synapses/biological_models.py
+Comment: 
+
+Filename: brainpy/_src/synapses/compat.py
+Comment: 
+
+Filename: brainpy/_src/synapses/delay_couplings.py
+Comment: 
+
+Filename: brainpy/_src/synapses/gap_junction.py
+Comment: 
+
+Filename: brainpy/_src/synapses/learning_rules.py
+Comment: 
+
+Filename: brainpy/_src/synapses_v2/__init__.py
+Comment: 
+
+Filename: brainpy/_src/synapses_v2/abstract_synapses.py
+Comment: 
+
+Filename: brainpy/_src/synapses_v2/base.py
+Comment: 
+
+Filename: brainpy/_src/synapses_v2/others.py
+Comment: 
+
+Filename: brainpy/_src/synapses_v2/syn_outs.py
+Comment: 
+
+Filename: brainpy/_src/synapses_v2/syn_plasticity.py
+Comment: 
+
+Filename: brainpy/_src/synouts/__init__.py
+Comment: 
+
+Filename: brainpy/_src/synouts/conductances.py
+Comment: 
+
+Filename: brainpy/_src/synouts/ions.py
+Comment: 
+
+Filename: brainpy/_src/synplast/__init__.py
+Comment: 
+
+Filename: brainpy/_src/synplast/long_term_plasticity.py
+Comment: 
+
+Filename: brainpy/_src/synplast/short_term_plasticity.py
+Comment: 
+
 Filename: brainpy/_src/testing/__init__.py
 Comment: 
 
 Filename: brainpy/_src/testing/base.py
 Comment: 
 
 Filename: brainpy/_src/tools/__init__.py
@@ -699,14 +732,17 @@
 
 Filename: brainpy/_src/tools/codes.py
 Comment: 
 
 Filename: brainpy/_src/tools/dicts.py
 Comment: 
 
+Filename: brainpy/_src/tools/install.py
+Comment: 
+
 Filename: brainpy/_src/tools/math_util.py
 Comment: 
 
 Filename: brainpy/_src/tools/others.py
 Comment: 
 
 Filename: brainpy/_src/tools/package.py
@@ -753,14 +789,32 @@
 
 Filename: brainpy/algorithms/online.py
 Comment: 
 
 Filename: brainpy/algorithms/utils.py
 Comment: 
 
+Filename: brainpy/dyn/__init__.py
+Comment: 
+
+Filename: brainpy/dyn/channels.py
+Comment: 
+
+Filename: brainpy/dyn/neurons.py
+Comment: 
+
+Filename: brainpy/dyn/others.py
+Comment: 
+
+Filename: brainpy/dyn/projections.py
+Comment: 
+
+Filename: brainpy/dyn/synapses.py
+Comment: 
+
 Filename: brainpy/integrators/__init__.py
 Comment: 
 
 Filename: brainpy/integrators/fde.py
 Comment: 
 
 Filename: brainpy/integrators/ode.py
@@ -828,14 +882,17 @@
 
 Filename: brainpy/math/pre_syn_post.py
 Comment: 
 
 Filename: brainpy/math/random.py
 Comment: 
 
+Filename: brainpy/math/sharding.py
+Comment: 
+
 Filename: brainpy/math/sparse.py
 Comment: 
 
 Filename: brainpy/math/surrogate.py
 Comment: 
 
 Filename: brainpy/synapses/__init__.py
@@ -846,23 +903,23 @@
 
 Filename: brainpy/synapses/synouts.py
 Comment: 
 
 Filename: brainpy/synapses/synplast.py
 Comment: 
 
-Filename: brainpy-2.4.1.dist-info/LICENSE
+Filename: brainpy-2.4.2.dist-info/LICENSE
 Comment: 
 
-Filename: brainpy-2.4.1.dist-info/METADATA
+Filename: brainpy-2.4.2.dist-info/METADATA
 Comment: 
 
-Filename: brainpy-2.4.1.dist-info/WHEEL
+Filename: brainpy-2.4.2.dist-info/WHEEL
 Comment: 
 
-Filename: brainpy-2.4.1.dist-info/top_level.txt
+Filename: brainpy-2.4.2.dist-info/top_level.txt
 Comment: 
 
-Filename: brainpy-2.4.1.dist-info/RECORD
+Filename: brainpy-2.4.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## brainpy/__init__.py

```diff
@@ -1,24 +1,28 @@
 # -*- coding: utf-8 -*-
 
-__version__ = "2.4.1"
-
+__version__ = "2.4.2"
 
 # fundamental supporting modules
 from brainpy import errors, check, tools
 
+try:
+  import jaxlib
+
+  del jaxlib
+except ModuleNotFoundError:
+  raise ModuleNotFoundError(tools.jaxlib_install_info) from None
 
 #  Part 1: Math Foundation  #
 # ------------------------- #
 
 # math foundation
 from brainpy import math
 from .math import BrainPyObject
 
-
 #  Part 2: Toolbox  #
 # ----------------- #
 
 # modules of toolbox
 from brainpy import (
   connect,  # synaptic connection
   initialize,  # weight initialization
@@ -31,230 +35,203 @@
   check,  # error checking
 )
 from . import algorithms  # online or offline training algorithms
 
 # convenient alias
 conn = connect
 init = initialize
-globals()['optimizers'] = optim
 
 # numerical integrators
 from brainpy import integrators
 from brainpy.integrators import ode, sde, fde
 from brainpy._src.integrators.base import (Integrator as Integrator)
 from brainpy._src.integrators.joint_eq import (JointEq as JointEq)
 from brainpy._src.integrators.runner import (IntegratorRunner as IntegratorRunner)
 from brainpy._src.integrators.ode.generic import (odeint as odeint)
 from brainpy._src.integrators.sde.generic import (sdeint as sdeint)
 from brainpy._src.integrators.fde.generic import (fdeint as fdeint)
 
-
 #  Part 3: Models  #
 # ---------------- #
 
-from brainpy import (channels,  # channel models
-                     layers,  # ANN layers
-                     neurons,  # neuron groups
-                     synapses,  # synapses
-                     rates,  # rate models
-                     experimental,
-                     )
-from brainpy.synapses import (synouts,  # synaptic output
-                              synplast, )  # synaptic plasticity
-
-from brainpy._src.dynsys import (DynamicalSystem as DynamicalSystem,
-                                 Container as Container,
-                                 Sequential as Sequential,
-                                 Network as Network,
-                                 NeuGroup as NeuGroup,
-                                 SynConn as SynConn,
-                                 SynOut as SynOut,
-                                 SynSTP as SynSTP,
-                                 SynLTP as SynLTP,
-                                 TwoEndConn as TwoEndConn,
-                                 CondNeuGroup as CondNeuGroup,
-                                 Channel as Channel)
-from brainpy._src.delay import Delay
+from brainpy import (
+  channels,  # channel models
+  neurons,  # neuron groups
+  synapses,  # synapses
+  rates,  # rate models
+  experimental,
+
+  dnn, layers,  # deep neural network module
+  dyn,  # dynamics module
+  # delay,  # delay module
+)
+
+from brainpy.synapses import (
+  synouts,  # synaptic output
+  synplast,  # synaptic plasticity
+)
+
+from brainpy._src.dynsys import (
+  DynamicalSystem as DynamicalSystem,
+  Container as Container,
+  Sequential as Sequential,
+  Network as Network,
+  NeuGroup as NeuGroup,
+  SynConn as SynConn,
+  SynOut as SynOut,
+  SynSTP as SynSTP,
+  SynLTP as SynLTP,
+  TwoEndConn as TwoEndConn,
+  CondNeuGroup as CondNeuGroup,
+  Channel as Channel
+)
+
 # shared parameters
 from brainpy._src.context import share
 from brainpy._src.dynsys import not_pass_shared
+
 # running
-from brainpy._src.dyn.runners import (DSRunner as DSRunner)
-from brainpy._src.dyn.transform import (LoopOverTime as LoopOverTime,)
-# DynamicalSystem base classes
-from brainpy._src.dynsys import (DynamicalSystemNS as DynamicalSystemNS,
-                                 NeuGroupNS as NeuGroupNS,
-                                 TwoEndConnNS as TwoEndConnNS,
-                                 )
-from brainpy._src.dyn.synapses_v2.base import (SynOutNS as SynOutNS,
-                                               SynSTPNS as SynSTPNS,
-                                               SynConnNS as SynConnNS, )
+from brainpy._src.runners import (DSRunner as DSRunner)
+from brainpy._src.transform import (LoopOverTime as LoopOverTime, )
 
+# DynamicalSystem base classes
+from brainpy._src.dynsys import (
+  DynamicalSystemNS as DynamicalSystemNS,
+  NeuGroupNS as NeuGroupNS,
+  TwoEndConnNS as TwoEndConnNS,
+)
+from brainpy._src.synapses_v2.base import (SynOutNS as SynOutNS,
+                                           SynSTPNS as SynSTPNS,
+                                           SynConnNS as SynConnNS, )
 
 #  Part 4: Training  #
 # ------------------ #
 
-from ._src.train.base import (DSTrainer as DSTrainer)
-from ._src.train.back_propagation import (BPTT as BPTT,
-                                          BPFF as BPFF,)
-from ._src.train.online import (OnlineTrainer as OnlineTrainer,
-                                ForceTrainer as ForceTrainer,)
-from ._src.train.offline import (OfflineTrainer as OfflineTrainer,
-                                 RidgeTrainer as RidgeTrainer,)
-
+from brainpy._src.train.base import (DSTrainer as DSTrainer, )
+from brainpy._src.train.back_propagation import (BPTT as BPTT,
+                                                 BPFF as BPFF, )
+from brainpy._src.train.online import (OnlineTrainer as OnlineTrainer,
+                                       ForceTrainer as ForceTrainer, )
+from brainpy._src.train.offline import (OfflineTrainer as OfflineTrainer,
+                                        RidgeTrainer as RidgeTrainer, )
 
 #  Part 6: Others    #
 # ------------------ #
 
-from . import running, testing, analysis
-from ._src.visualization import (visualize as visualize)
-from ._src import base, modes, train, dyn
-
+from brainpy import running, testing, analysis
+from brainpy._src.visualization import (visualize as visualize)
+from brainpy._src import base, train
 
 #  Part 7: Deprecations  #
 # ---------------------- #
 
-
-math.__dict__['event_matvec_prob_conn_homo_weight'] = math.jitconn.event_mv_prob_homo
-math.__dict__['event_matvec_prob_conn_uniform_weight'] = math.jitconn.event_mv_prob_uniform
-math.__dict__['event_matvec_prob_conn_normal_weight'] = math.jitconn.event_mv_prob_normal
-
-math.__dict__['matvec_prob_conn_homo_weight'] = math.jitconn.mv_prob_homo
-math.__dict__['matvec_prob_conn_uniform_weight'] = math.jitconn.mv_prob_uniform
-math.__dict__['matvec_prob_conn_normal_weight'] = math.jitconn.mv_prob_normal
-
-math.__dict__['csr_matvec'] = math.sparse.csrmv
-math.__dict__['cusparse_csr_matvec'] = math.sparse.csrmv
-math.__dict__['cusparse_coo_matvec'] = math.sparse.coomv
-math.__dict__['coo_to_csr'] = math.sparse.coo_to_csr
-math.__dict__['csr_to_coo'] = math.sparse.csr_to_coo
-math.__dict__['csr_to_dense'] = math.sparse.csr_to_dense
-
-math.__dict__['event_csr_matvec'] = math.event.csrmv
-math.__dict__['event_info'] = math.event.info
-
-integrators.__dict__['Integrator'] = Integrator
-integrators.__dict__['odeint'] = odeint
-integrators.__dict__['sdeint'] = sdeint
-integrators.__dict__['fdeint'] = fdeint
-integrators.__dict__['IntegratorRunner'] = IntegratorRunner
-integrators.__dict__['JointEq'] = JointEq
-ode.__dict__['odeint'] = odeint
-sde.__dict__['sdeint'] = sdeint
-fde.__dict__['fdeint'] = fdeint
-
-
-# deprecated
+from brainpy._src import modes
 from brainpy._src.math.object_transform.base import (Base as Base,
                                                      ArrayCollector,
                                                      Collector as Collector, )
-globals()['TensorCollector'] = ArrayCollector
 
-train.__dict__['DSTrainer'] = DSTrainer
-train.__dict__['BPTT'] = BPTT
-train.__dict__['BPFF'] = BPFF
-train.__dict__['OnlineTrainer'] = OnlineTrainer
-train.__dict__['ForceTrainer'] = ForceTrainer
-train.__dict__['OfflineTrainer'] = OfflineTrainer
-train.__dict__['RidgeTrainer'] = RidgeTrainer
-
-
-base.base.__dict__['BrainPyObject'] = BrainPyObject
-base.base.__dict__['Base'] = Base
-base.collector.__dict__['Collector'] = Collector
-base.collector.__dict__['ArrayCollector'] = ArrayCollector
-base.collector.__dict__['TensorCollector'] = ArrayCollector
-base.function.__dict__['FunAsObject'] = math.FunAsObject
-base.function.__dict__['Function'] = math.FunAsObject
-base.io.__dict__['save_as_h5'] = checkpoints.io.save_as_h5
-base.io.__dict__['save_as_npz'] = checkpoints.io.save_as_npz
-base.io.__dict__['save_as_pkl'] = checkpoints.io.save_as_pkl
-base.io.__dict__['save_as_mat'] = checkpoints.io.save_as_mat
-base.io.__dict__['load_by_h5'] = checkpoints.io.load_by_h5
-base.io.__dict__['load_by_npz'] = checkpoints.io.load_by_npz
-base.io.__dict__['load_by_pkl'] = checkpoints.io.load_by_pkl
-base.io.__dict__['load_by_mat'] = checkpoints.io.load_by_mat
-base.naming.__dict__['clear_name_cache'] = math.clear_name_cache
-base.__dict__['BrainPyObject'] = BrainPyObject
-base.__dict__['Base'] = Base
-base.__dict__['Collector'] = Collector
-base.__dict__['ArrayCollector'] = ArrayCollector
-base.__dict__['TensorCollector'] = ArrayCollector
-base.__dict__['FunAsObject'] = math.FunAsObject
-base.__dict__['Function'] = math.FunAsObject
-base.__dict__['save_as_h5'] = checkpoints.io.save_as_h5
-base.__dict__['save_as_npz'] = checkpoints.io.save_as_npz
-base.__dict__['save_as_pkl'] = checkpoints.io.save_as_pkl
-base.__dict__['save_as_mat'] = checkpoints.io.save_as_mat
-base.__dict__['load_by_h5'] = checkpoints.io.load_by_h5
-base.__dict__['load_by_npz'] = checkpoints.io.load_by_npz
-base.__dict__['load_by_pkl'] = checkpoints.io.load_by_pkl
-base.__dict__['load_by_mat'] = checkpoints.io.load_by_mat
-base.__dict__['clear_name_cache'] = math.clear_name_cache
-
-modes.__dict__['Mode'] = math.Mode
-modes.__dict__['NormalMode'] = math.NonBatchingMode
-modes.__dict__['BatchingMode'] = math.BatchingMode
-modes.__dict__['TrainingMode'] = math.TrainingMode
-modes.__dict__['normal'] = math.nonbatching_mode
-modes.__dict__['batching'] = math.batching_mode
-modes.__dict__['training'] = math.training_mode
-modes.__dict__['check_mode'] = check.is_subclass
-
-
-dyn.__dict__['channels'] = channels
-dyn.__dict__['neurons'] = neurons
-dyn.__dict__['rates'] = rates
-dyn.__dict__['synapses'] = synapses
-dyn.__dict__['synouts'] = synouts
-dyn.__dict__['synplast'] = synplast
-dyn.__dict__['DynamicalSystem'] = DynamicalSystem
-dyn.__dict__['Container'] = Container
-dyn.__dict__['Sequential'] = Sequential
-dyn.__dict__['Network'] = Network
-dyn.__dict__['NeuGroup'] = NeuGroup
-dyn.__dict__['SynConn'] = SynConn
-dyn.__dict__['SynOut'] = SynOut
-dyn.__dict__['SynSTP'] = SynSTP
-dyn.__dict__['SynLTP'] = SynLTP
-dyn.__dict__['TwoEndConn'] = TwoEndConn
-dyn.__dict__['CondNeuGroup'] = CondNeuGroup
-dyn.__dict__['Channel'] = Channel
-dyn.__dict__['LoopOverTime'] = LoopOverTime
-dyn.__dict__['DSRunner'] = DSRunner
-
-# neurons
-dyn.__dict__['HH'] = neurons.HH
-dyn.__dict__['MorrisLecar'] = neurons.MorrisLecar
-dyn.__dict__['PinskyRinzelModel'] = neurons.PinskyRinzelModel
-dyn.__dict__['FractionalFHR'] = neurons.FractionalFHR
-dyn.__dict__['FractionalIzhikevich'] = neurons.FractionalIzhikevich
-dyn.__dict__['LIF'] = neurons.LIF
-dyn.__dict__['ExpIF'] = neurons.ExpIF
-dyn.__dict__['AdExIF'] = neurons.AdExIF
-dyn.__dict__['QuaIF'] = neurons.QuaIF
-dyn.__dict__['AdQuaIF'] = neurons.AdQuaIF
-dyn.__dict__['GIF'] = neurons.GIF
-dyn.__dict__['Izhikevich'] = neurons.Izhikevich
-dyn.__dict__['HindmarshRose'] = neurons.HindmarshRose
-dyn.__dict__['FHN'] = neurons.FHN
-dyn.__dict__['SpikeTimeGroup'] = neurons.SpikeTimeGroup
-dyn.__dict__['PoissonGroup'] = neurons.PoissonGroup
-dyn.__dict__['OUProcess'] = neurons.OUProcess
-
-# synapses
-from brainpy._src.dyn.synapses import compat
-dyn.__dict__['DeltaSynapse'] = compat.DeltaSynapse
-dyn.__dict__['ExpCUBA'] = compat.ExpCUBA
-dyn.__dict__['ExpCOBA'] = compat.ExpCOBA
-dyn.__dict__['DualExpCUBA'] = compat.DualExpCUBA
-dyn.__dict__['DualExpCOBA'] = compat.DualExpCOBA
-dyn.__dict__['AlphaCUBA'] = compat.AlphaCUBA
-dyn.__dict__['AlphaCOBA'] = compat.AlphaCOBA
-dyn.__dict__['NMDA'] = compat.NMDA
-del compat
+# deprecated
+from brainpy._src import checking
+from brainpy._src.synapses import compat
+from brainpy._src.deprecations import deprecation_getattr2
 
+__deprecations = {
+  'optimizers': ('brainpy.optimizers', 'brainpy.optim', optim),
+  'TensorCollector': ('brainpy.TensorCollector', 'brainpy.ArrayCollector', ArrayCollector),
+}
+__getattr__ = deprecation_getattr2('brainpy', __deprecations)
+
+tools.__deprecations = {
+  'clear_name_cache': ('brainpy.tools.clear_name_cache', 'brainpy.math.clear_name_cache', math.clear_name_cache),
+  'checking': ('brainpy.tools.checking', 'brainpy.checking', checking),
+}
+tools.__getattr__ = deprecation_getattr2('brainpy.tools', tools.__deprecations)
+
+integrators.__deprecations = {
+  'Integrator': ('brainpy.integrators.Integrator', 'brainpy.Integrator', Integrator),
+  'odeint': ('brainpy.integrators.odeint', 'brainpy.odeint', odeint),
+  'sdeint': ('brainpy.integrators.sdeint', 'brainpy.sdeint', sdeint),
+  'fdeint': ('brainpy.integrators.fdeint', 'brainpy.fdeint', fdeint),
+  'IntegratorRunner': ('brainpy.integrators.IntegratorRunner', 'brainpy.IntegratorRunner', IntegratorRunner),
+  'JointEq': ('brainpy.integrators.JointEq', 'brainpy.JointEq', JointEq),
+}
+integrators.__getattr__ = deprecation_getattr2('brainpy.integrators', integrators.__deprecations)
+
+train.__deprecations = {
+  'DSTrainer': ('brainpy.train.DSTrainer', 'brainpy.DSTrainer', DSTrainer),
+  'BPTT': ('brainpy.train.BPTT', 'brainpy.BPTT', BPTT),
+  'BPFF': ('brainpy.train.BPFF', 'brainpy.BPFF', BPFF),
+  'OnlineTrainer': ('brainpy.train.OnlineTrainer', 'brainpy.OnlineTrainer', OnlineTrainer),
+  'ForceTrainer': ('brainpy.train.ForceTrainer', 'brainpy.ForceTrainer', ForceTrainer),
+  'OfflineTrainer': ('brainpy.train.OfflineTrainer', 'brainpy.OfflineTrainer', OfflineTrainer),
+  'RidgeTrainer': ('brainpy.train.RidgeTrainer', 'brainpy.RidgeTrainer', RidgeTrainer),
+}
+train.__getattr__ = deprecation_getattr2('brainpy.train', train.__deprecations)
+
+ode.__deprecations = {'odeint': ('brainpy.ode.odeint', 'brainpy.odeint', odeint)}
+ode.__getattr__ = deprecation_getattr2('brainpy.ode', ode.__deprecations)
+
+sde.__deprecations = {'sdeint': ('brainpy.sde.sdeint', 'brainpy.sdeint', sdeint)}
+sde.__getattr__ = deprecation_getattr2('brainpy.sde', sde.__deprecations)
+
+fde.__deprecations = {'fdeint': ('brainpy.fde.fdeint', 'brainpy.fdeint', fdeint)}
+fde.__getattr__ = deprecation_getattr2('brainpy.fde', sde.__deprecations)
+
+dyn.__deprecations = {
+  # module
+  # 'channels': ('brainpy.dyn.channels', 'brainpy.channels', channels),
+  # 'neurons': ('brainpy.dyn.neurons', 'brainpy.neurons', neurons),
+  'rates': ('brainpy.dyn.rates', 'brainpy.rates', rates),
+  # 'synapses': ('brainpy.dyn.synapses', 'brainpy.synapses', synapses),
+  'synouts': ('brainpy.dyn.synouts', 'brainpy.synapses', synouts),
+  'synplast': ('brainpy.dyn.synplast', 'brainpy.synapses', synplast),
+
+  # models
+  'DynamicalSystem': ('brainpy.dyn.DynamicalSystem', 'brainpy.DynamicalSystem', DynamicalSystem),
+  'Container': ('brainpy.dyn.Container', 'brainpy.Container', Container),
+  'Sequential': ('brainpy.dyn.Sequential', 'brainpy.Sequential', Sequential),
+  'Network': ('brainpy.dyn.Network', 'brainpy.Network', Network),
+  'NeuGroup': ('brainpy.dyn.NeuGroup', 'brainpy.NeuGroup', NeuGroup),
+  'SynConn': ('brainpy.dyn.SynConn', 'brainpy.SynConn', SynConn),
+  # 'SynOut': ('brainpy.dyn.SynOut', 'brainpy.SynOut', SynOut),
+  'SynLTP': ('brainpy.dyn.SynLTP', 'brainpy.SynLTP', SynLTP),
+  'SynSTP': ('brainpy.dyn.SynSTP', 'brainpy.SynSTP', SynSTP),
+  'TwoEndConn': ('brainpy.dyn.TwoEndConn', 'brainpy.TwoEndConn', TwoEndConn),
+  'CondNeuGroup': ('brainpy.dyn.CondNeuGroup', 'brainpy.CondNeuGroup', CondNeuGroup),
+  'Channel': ('brainpy.dyn.Channel', 'brainpy.Channel', Channel),
+  'LoopOverTime': ('brainpy.dyn.LoopOverTime', 'brainpy.LoopOverTime', LoopOverTime),
+  'DSRunner': ('brainpy.dyn.DSRunner', 'brainpy.DSRunner', DSRunner),
+
+  # neurons
+  'HH': ('brainpy.dyn.HH', 'brainpy.neurons.HH', neurons.HH),
+  'MorrisLecar': ('brainpy.dyn.MorrisLecar', 'brainpy.neurons.MorrisLecar', neurons.MorrisLecar),
+  'PinskyRinzelModel': ('brainpy.dyn.PinskyRinzelModel', 'brainpy.neurons.PinskyRinzelModel',
+                        neurons.PinskyRinzelModel),
+  'FractionalFHR': ('brainpy.dyn.FractionalFHR', 'brainpy.neurons.FractionalFHR', neurons.FractionalFHR),
+  'FractionalIzhikevich': ('brainpy.dyn.FractionalIzhikevich', 'brainpy.neurons.FractionalIzhikevich',
+                           neurons.FractionalIzhikevich),
+  'LIF': ('brainpy.dyn.LIF', 'brainpy.neurons.LIF', neurons.LIF),
+  'ExpIF': ('brainpy.dyn.ExpIF', 'brainpy.neurons.ExpIF', neurons.ExpIF),
+  'AdExIF': ('brainpy.dyn.AdExIF', 'brainpy.neurons.AdExIF', neurons.AdExIF),
+  'QuaIF': ('brainpy.dyn.QuaIF', 'brainpy.neurons.QuaIF', neurons.QuaIF),
+  'AdQuaIF': ('brainpy.dyn.AdQuaIF', 'brainpy.neurons.AdQuaIF', neurons.AdQuaIF),
+  'GIF': ('brainpy.dyn.GIF', 'brainpy.neurons.GIF', neurons.GIF),
+  'Izhikevich': ('brainpy.dyn.Izhikevich', 'brainpy.neurons.Izhikevich', neurons.Izhikevich),
+  'HindmarshRose': ('brainpy.dyn.HindmarshRose', 'brainpy.neurons.HindmarshRose', neurons.HindmarshRose),
+  'FHN': ('brainpy.dyn.FHN', 'brainpy.neurons.FHN', neurons.FHN),
+  'SpikeTimeGroup': ('brainpy.dyn.SpikeTimeGroup', 'brainpy.neurons.SpikeTimeGroup', neurons.SpikeTimeGroup),
+  'PoissonGroup': ('brainpy.dyn.PoissonGroup', 'brainpy.neurons.PoissonGroup', neurons.PoissonGroup),
+  'OUProcess': ('brainpy.dyn.OUProcess', 'brainpy.neurons.OUProcess', neurons.OUProcess),
+
+  # synapses
+  'DeltaSynapse': ('brainpy.dyn.DeltaSynapse', 'brainpy.synapses.Delta', compat.DeltaSynapse),
+  'ExpCUBA': ('brainpy.dyn.ExpCUBA', 'brainpy.synapses.Exponential', compat.ExpCUBA),
+  'ExpCOBA': ('brainpy.dyn.ExpCOBA', 'brainpy.synapses.Exponential', compat.ExpCOBA),
+  'DualExpCUBA': ('brainpy.dyn.DualExpCUBA', 'brainpy.synapses.DualExponential', compat.DualExpCUBA),
+  'DualExpCOBA': ('brainpy.dyn.DualExpCOBA', 'brainpy.synapses.DualExponential', compat.DualExpCOBA),
+  'AlphaCUBA': ('brainpy.dyn.AlphaCUBA', 'brainpy.synapses.Alpha', compat.AlphaCUBA),
+  'AlphaCOBA': ('brainpy.dyn.AlphaCOBA', 'brainpy.synapses.Alpha', compat.AlphaCOBA),
+  # 'NMDA': ('brainpy.dyn.NMDA', 'brainpy.synapses.NMDA', compat.NMDA),
+}
+dyn.__getattr__ = deprecation_getattr2('brainpy.dyn', dyn.__deprecations)
 
-from brainpy._src import checking
-tools.__dict__['checking'] = checking
-tools.__dict__['clear_name_cache'] = math.clear_name_cache
-del checking
+del deprecation_getattr2, checking, compat
```

## brainpy/check.py

```diff
@@ -1,12 +1,13 @@
 # -*- coding: utf-8 -*-
 
 from functools import wraps, partial
 from typing import Union, Sequence, Dict, Callable, Tuple, Type, Optional, Any
 
+import jax
 import numpy as np
 import numpy as onp
 from jax import numpy as jnp
 from jax.experimental.host_callback import id_tap
 from jax.lax import cond
 
 conn = None
@@ -34,15 +35,17 @@
   'is_string',
   'is_sequence',
   'is_subclass',
   'is_instance',
   'is_elem_or_seq_or_dict',
   'is_all_vars',
   'is_all_objs',
+  'jit_error',
   'jit_error_checking',
+  'jit_error2',
 
   'serialize_kwargs',
 ]
 
 _check = True
 _name_check = True
 
@@ -245,15 +248,15 @@
   if initializer is None:
     if allow_none:
       return
     else:
       raise ValueError(f'{name} must be an initializer, but we got None.')
   if isinstance(initializer, init.Initializer):
     return initializer
-  elif isinstance(initializer, (Array, jnp.ndarray)):
+  elif isinstance(initializer, (Array, jax.Array)):
     return initializer
   elif callable(initializer):
     return initializer
   else:
     raise ValueError(f'{name} should be an instance of brainpy.init.Initializer, '
                      f'tensor or callable function. While we got {type(initializer)}')
 
@@ -275,15 +278,15 @@
   if connector is None:
     if allow_none:
       return None
     else:
       raise ValueError(f'{name} must be an initializer, but we got None.')
   if isinstance(connector, conn.Connector):
     return connector
-  elif isinstance(connector, (Array, jnp.ndarray)):
+  elif isinstance(connector, (Array, jax.Array)):
     return connector
   elif callable(connector):
     return connector
   else:
     raise ValueError(f'{name} should be an instance of brainpy.conn.Connector, '
                      f'tensor or callable function. While we got {type(connector)}')
 
@@ -342,21 +345,22 @@
   if allow_int:
     if not isinstance(value, (float, int, np.integer, np.floating)):
       raise ValueError(f'{name} must be a float, but got {type(value)}')
   else:
     if not isinstance(value, (float, np.floating)):
       raise ValueError(f'{name} must be a float, but got {type(value)}')
   if min_bound is not None:
-    if value < min_bound:
-      raise ValueError(f"{name} must be a float bigger than {min_bound}, "
-                       f"while we got {value}")
+    jit_error2(value < min_bound,
+               ValueError(f"{name} must be a float bigger than {min_bound}, "
+                          f"while we got {value}"))
+
   if max_bound is not None:
-    if value > max_bound:
-      raise ValueError(f"{name} must be a float smaller than {max_bound}, "
-                       f"while we got {value}")
+    jit_error2(value > max_bound,
+               ValueError(f"{name} must be a float smaller than {max_bound}, "
+                          f"while we got {value}"))
   return value
 
 
 def is_integer(value: int, name=None, min_bound=None, max_bound=None, allow_none=False):
   """Check integer type.
 
   Parameters
@@ -379,21 +383,21 @@
   if not isinstance(value, (int, np.integer)):
     if hasattr(value, '__array__'):
       if not (np.issubdtype(value.dtype, np.integer) and value.ndim == 0 and value.size == 1):
         raise ValueError(f'{name} must be an int, but got {value}')
     else:
       raise ValueError(f'{name} must be an int, but got {value}')
   if min_bound is not None:
-    if jnp.any(value < min_bound):
-      raise ValueError(f"{name} must be an int bigger than {min_bound}, "
-                       f"while we got {value}")
+    jit_error2(jnp.any(value < min_bound),
+               ValueError(f"{name} must be an int bigger than {min_bound}, "
+                          f"while we got {value}"))
   if max_bound is not None:
-    if jnp.any(value > max_bound):
-      raise ValueError(f"{name} must be an int smaller than {max_bound}, "
-                       f"while we got {value}")
+    jit_error2(jnp.any(value > max_bound),
+               ValueError(f"{name} must be an int smaller than {max_bound}, "
+                          f"while we got {value}"))
   return value
 
 
 def is_string(value: str, name: str = None, candidates: Sequence[str] = None, allow_none=False):
   """Check string type.
   """
   if name is None: name = ''
@@ -587,22 +591,48 @@
 
   cond(remove_vmap(pred),
        partial(_err_jit_true_branch, true_err_fun),
        _err_jit_false_branch,
        err_arg)
 
 
-def jit_error_checking(pred, err_fun, err_arg=None):
+def jit_error(pred, err_fun, err_arg=None):
   """Check errors in a jit function.
 
   Parameters
   ----------
   pred: bool
     The boolean prediction.
   err_fun: callable
     The error function, which raise errors.
   err_arg: any
     The arguments which passed into `err_f`.
   """
+  from brainpy._src.math.interoperability import as_jax
+  partial(_cond, err_fun)(as_jax(pred), err_arg)
+
+
+jit_error_checking = jit_error
+
+
+def jit_error2(pred: bool, err: Exception):
+  """Check errors in a jit function.
+
+  Parameters
+  ----------
+  pred: bool
+    The boolean prediction.
+  err: Exception
+    The error.
+  """
+  from brainpy._src.math.remove_vmap import remove_vmap
+  from brainpy._src.math.interoperability import as_jax
+
+  assert isinstance(err, Exception), 'Must be instance of Exception.'
+
+  def true_err_fun(arg, transforms):
+    raise err
+
+  cond(remove_vmap(as_jax(pred)),
+       lambda: id_tap(true_err_fun, None),
+       lambda: None)
 
-  # jax.jit(partial(_cond, err_fun), inline=True)(pred, err_arg)
-  partial(_cond, err_fun)(pred, err_arg)
```

## brainpy/checkpoints.py

```diff
@@ -1,11 +1,21 @@
 # -*- coding: utf-8 -*-
 
 
 from brainpy._src.checkpoints import io
+from brainpy._src.checkpoints.io import (
+  save_as_h5,
+  save_as_npz,
+  save_as_pkl,
+  save_as_mat,
+  load_by_h5,
+  load_by_npz,
+  load_by_pkl,
+  load_by_mat,
+)
 from brainpy._src.checkpoints.serialization import (
   save as save,
   load as load,
   save_pytree as save_pytree,
   load_pytree as load_pytree,
   AsyncManager as AsyncManager
 )
```

## brainpy/connect.py

```diff
@@ -9,14 +9,15 @@
   mat2csr as mat2csr,
   csr2csc as csr2csc,
   csr2mat as csr2mat,
   csr2coo as csr2coo,
   coo2csr as coo2csr,
   coo2csc as coo2csc,
   coo2mat as coo2mat,
+  visualizeMat as visualizeMat,
 
   CONN_MAT,
   PRE_IDS, POST_IDS,
   PRE2POST, POST2PRE,
   PRE2SYN, POST2SYN,
   PRE_SLICE, POST_SLICE,
   COO, CSR, CSC
```

## brainpy/errors.py

```diff
@@ -219,48 +219,14 @@
       'https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError\n'
       '3. The static variables which set in the "static_argnames" are provided '
       'as arguments, not keyword arguments, like "jit_f(v1, v2)" [<- wrong]. '
       'Please write it as "jit_f(static_k1=v1, static_k2=v2)" [<- right].'
     )
 
 
-
-try:
-  import jaxlib
-
-  del jaxlib
-except ModuleNotFoundError:
-  raise ModuleNotFoundError(
-    '''
-
-BrainPy needs jaxlib, please install it. 
-
-1. If you are using Windows system, install jaxlib through
-
-   >>> pip install jaxlib -f https://whls.blob.core.windows.net/unstable/index.html
-
-2. If you are using macOS platform, install jaxlib through
-
-   >>> pip install jaxlib -f https://storage.googleapis.com/jax-releases/jax_releases.html
-
-3. If you are using Linux platform, install jaxlib through
-
-   >>> pip install jaxlib -f https://storage.googleapis.com/jax-releases/jax_releases.html
-
-4. If you are using Linux + CUDA platform, install jaxlib through
-
-   >>> pip install jaxlib -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
-
-Note that the versions of "jax" and "jaxlib" should be consistent, like "jax=0.3.14" and "jaxlib=0.3.14".  
-
-For more detail installation instructions, please see https://brainpy.readthedocs.io/en/latest/quickstart/installation.html#dependency-2-jax 
-
-    ''') from None
-
-
 class GPUOperatorNotFound(Exception):
   def __init__(self, name):
     super(GPUOperatorNotFound, self).__init__(f'''
 GPU operator for "{name}" does not found. 
 
 Please install brainpylib GPU operators with linux + CUDA environment.
     ''')
```

## brainpy/experimental.py

```diff
@@ -1,18 +1,18 @@
 
-from brainpy._src.dyn.synapses_v2.syn_plasticity import (
+from brainpy._src.synapses_v2.syn_plasticity import (
   STD as STD,
   STP as STP,
 )
-from brainpy._src.dyn.synapses_v2.syn_outs import (
+from brainpy._src.synapses_v2.syn_outs import (
   CUBA as CUBA,
   COBA as COBA,
 )
-from brainpy._src.dyn.synapses_v2.abstract_synapses import (
+from brainpy._src.synapses_v2.abstract_synapses import (
   Exponential,
   DualExponential,
   Alpha,
 )
-from brainpy._src.dyn.synapses_v2.others import (
+from brainpy._src.synapses_v2.others import (
   PoissonInput,
 )
```

## brainpy/layers.py

```diff
@@ -1,91 +1,2 @@
-# -*- coding: utf-8 -*-
-
-
-from brainpy._src.layers.base import (
-  Layer as Layer,
-)
-
-from brainpy._src.layers.conv import (
-  Conv1d as Conv1d,
-  Conv2d as Conv2d,
-  Conv3d as Conv3d,
-  Conv1D as Conv1D,
-  Conv2D as Conv2D,
-  Conv3D as Conv3D,
-  ConvTranspose1d as ConvTranspose1d,
-  ConvTranspose2d as ConvTranspose2d,
-  ConvTranspose3d as ConvTranspose3d,
-)
-
-
-from brainpy._src.layers.dropout import (
-  Dropout as Dropout,
-)
-
-from brainpy._src.layers.function import (
-  Activation as Activation,
-  Flatten as Flatten,
-  FunAsLayer as FunAsLayer,
-)
-
-from brainpy._src.layers.linear import (
-  Dense as Dense,
-  Linear as Linear,
-  Identity as Identity,
-)
-
-from brainpy._src.layers.normalization import (
-  BatchNorm1d as BatchNorm1d,
-  BatchNorm2d as BatchNorm2d,
-  BatchNorm3d as BatchNorm3d,
-  BatchNorm1D as BatchNorm1D,
-  BatchNorm2D as BatchNorm2D,
-  BatchNorm3D as BatchNorm3D,
-  LayerNorm as LayerNorm,
-  GroupNorm as GroupNorm,
-  InstanceNorm as InstanceNorm,
-)
-
-from brainpy._src.layers.nvar import (
-  NVAR as NVAR,
-)
-
-from brainpy._src.layers.pooling import (
-  MaxPool as MaxPool,
-  MaxPool1d as MaxPool1d,
-  MaxPool2d as MaxPool2d,
-  MaxPool3d as MaxPool3d,
-
-  MinPool as MinPool,
-
-  AvgPool as AvgPool,
-  AvgPool1d as AvgPool1d,
-  AvgPool2d as AvgPool2d,
-  AvgPool3d as AvgPool3d,
-
-  AdaptiveAvgPool1d as AdaptiveAvgPool1d,
-  AdaptiveAvgPool2d as AdaptiveAvgPool2d,
-  AdaptiveAvgPool3d as AdaptiveAvgPool3d,
-  AdaptiveMaxPool1d as AdaptiveMaxPool1d,
-  AdaptiveMaxPool2d as AdaptiveMaxPool2d,
-  AdaptiveMaxPool3d as AdaptiveMaxPool3d,
-)
-
-from brainpy._src.layers.reservoir import (
-  Reservoir as Reservoir,
-)
-
-from brainpy._src.layers.rnncells import (
-  RNNCell as RNNCell,
-  GRUCell as GRUCell,
-  LSTMCell as LSTMCell,
-  Conv1dLSTMCell as Conv1dLSTMCell,
-  Conv2dLSTMCell as Conv2dLSTMCell,
-  Conv3dLSTMCell as Conv3dLSTMCell,
-)
-
-from brainpy._src.layers.interoperation_flax import (
-  FromFlax,
-  ToFlaxRNNCell, ToFlax,
-)
 
+from .dnn import *
```

## brainpy/losses.py

```diff
@@ -1,28 +1,37 @@
 # -*- coding: utf-8 -*-
 
 from brainpy._src.losses.comparison import (
   cross_entropy_loss as cross_entropy_loss,
   cross_entropy_sparse as cross_entropy_sparse,
   cross_entropy_sigmoid as cross_entropy_sigmoid,
-  l1_loos as l1_loos,
+  nll_loss,
+  l1_loss as l1_loss,
   l2_loss as l2_loss,
   huber_loss as huber_loss,
   mean_absolute_error as mean_absolute_error,
   mean_squared_error as mean_squared_error,
   mean_squared_log_error as mean_squared_log_error,
   binary_logistic_loss as binary_logistic_loss,
   multiclass_logistic_loss as multiclass_logistic_loss,
   sigmoid_binary_cross_entropy as sigmoid_binary_cross_entropy,
   softmax_cross_entropy as softmax_cross_entropy,
   log_cosh_loss as log_cosh_loss,
   ctc_loss_with_forward_probs as ctc_loss_with_forward_probs,
   ctc_loss as ctc_loss,
 )
 
+from brainpy._src.losses.comparison import (
+  CrossEntropyLoss,
+  NLLLoss,
+  L1Loss,
+  MAELoss,
+  MSELoss,
+)
+
 from brainpy._src.losses.regularization import (
   l2_norm as l2_norm,
   mean_absolute as mean_absolute,
   mean_square as mean_square,
   log_cosh as log_cosh,
   smooth_labels as smooth_labels,
 )
```

## brainpy/neurons.py

```diff
@@ -1,34 +1,34 @@
 # -*- coding: utf-8 -*-
 
-from brainpy._src.dyn.neurons.biological_models import (
+from brainpy._src.neurons.biological_models import (
   HH as HH,
   MorrisLecar as MorrisLecar,
   PinskyRinzelModel as PinskyRinzelModel,
   WangBuzsakiModel as WangBuzsakiModel,
 )
 
-from brainpy._src.dyn.neurons.fractional_models import (
+from brainpy._src.neurons.fractional_models import (
   FractionalNeuron as FractionalNeuron,
   FractionalFHR as FractionalFHR,
   FractionalIzhikevich as FractionalIzhikevich,
 )
 
-from brainpy._src.dyn.neurons.input_groups import (
+from brainpy._src.neurons.input_groups import (
   InputGroup as InputGroup,
   OutputGroup as OutputGroup,
   SpikeTimeGroup as SpikeTimeGroup,
   PoissonGroup as PoissonGroup,
 )
 
-from brainpy._src.dyn.neurons.noise_groups import (
+from brainpy._src.neurons.noise_groups import (
   OUProcess as OUProcess,
 )
 
-from brainpy._src.dyn.neurons.reduced_models import (
+from brainpy._src.neurons.reduced_models import (
   Leaky as Leaky,
   Integrator as Integrator,
   LeakyIntegrator as LeakyIntegrator,
   LIF as LIF,
   ExpIF as ExpIF,
   AdExIF as AdExIF,
   QuaIF as QuaIF,
```

## brainpy/rates.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 
 
-from brainpy._src.dyn.rates.populations import (
+from brainpy._src.rates.populations import (
   RateModel as RateModel,
   FHN as FHN,
   FeedbackFHN as FeedbackFHN,
   QIF as QIF,
   StuartLandauOscillator as StuartLandauOscillator,
   WilsonCowanModel as WilsonCowanModel,
   ThresholdLinearModel as ThresholdLinearModel,
```

## brainpy/tools.py

```diff
@@ -1,12 +1,13 @@
 # -*- coding: utf-8 -*-
 
 
 from brainpy._src.tools.codes import (
   repr_object as repr_object,
+  repr_dict as repr_dict,
   repr_context as repr_context,
   copy_doc as copy_doc,
   code_lines_to_func as code_lines_to_func,
   get_identifiers as get_identifiers,
   indent as indent,
   deindent as deindent,
   word_replace as word_replace,
@@ -35,7 +36,13 @@
   not_customized as not_customized,
   to_size as to_size,
   size2num as size2num,
   timeout as timeout,
   init_progress_bar as init_progress_bar,
 )
 
+from brainpy._src.tools.install import (
+  jaxlib_install_info,
+)
+
+
+
```

## brainpy/types.py

```diff
@@ -5,9 +5,10 @@
   Array as Array,
   Parameter as Parameter,
   PyTree as PyTree,
   Shape as Shape,
   Initializer as Initializer,
   Output as Output,
   Monitor as Monitor,
+  Sharding as Sharding,
 )
```

## brainpy/_src/__init__.py

```diff
@@ -1,2 +0,0 @@
-00000000: 2320 2d2a 2d20 636f 6469 6e67 3a20 7574  # -*- coding: ut
-00000010: 662d 3820 2d2a 2d0a                      f-8 -*-.
```

## brainpy/_src/checking.py

```diff
@@ -1,37 +1,52 @@
 # -*- coding: utf-8 -*-
 
 from brainpy import check
 
+from brainpy._src.deprecations import deprecation_getattr2
 
-__all__ = [
-  'check_shape_consistency',
-  'check_shape_broadcastable',
-  'check_shape_except_batch',
-  'check_shape',
-  'check_dict_data',
-  'check_callable',
-  'check_initializer',
-  'check_connector',
-  'check_float',
-  'check_integer',
-  'check_string',
-  'check_sequence',
-  'check_mode',
-
-  'serialize_kwargs',
-]
-
-check_shape_consistency = check.is_shape_consistency
-check_shape_broadcastable = check.is_shape_broadcastable
-check_shape_except_batch = check.check_shape_except_batch
-check_shape = check.check_shape
-check_dict_data = check.is_dict_data
-check_callable = check.is_callable
-check_initializer = check.is_initializer
-check_connector = check.is_connector
-check_float = check.is_float
-check_integer = check.is_integer
-check_string = check.is_string
-check_sequence = check.is_sequence
-check_mode = check.is_subclass
-serialize_kwargs = check.serialize_kwargs
+__deprecations = {
+  'check_shape_consistency': ('brainpy.checking.check_shape_consistency',
+                              'brainpy.check.is_shape_consistency',
+                              check.is_shape_consistency),
+  'check_shape_broadcastable': ('brainpy.checking.check_shape_broadcastable',
+                                'brainpy.check.is_shape_broadcastable',
+                                check.is_shape_broadcastable),
+  'check_shape_except_batch': ('brainpy.checking.check_shape_except_batch',
+                               'brainpy.check.check_shape_except_batch',
+                               check.check_shape_except_batch),
+  'check_shape': ('brainpy.checking.check_shape',
+                  'brainpy.check.check_shape',
+                  check.check_shape),
+  'check_dict_data': ('brainpy.checking.check_dict_data',
+                      'brainpy.check.is_dict_data',
+                      check.is_dict_data),
+  'check_callable': ('brainpy.checking.check_callable',
+                     'brainpy.check.is_callable',
+                     check.is_callable),
+  'check_initializer': ('brainpy.checking.check_initializer',
+                        'brainpy.check.is_initializer',
+                        check.is_initializer),
+  'check_connector': ('brainpy.checking.check_connector',
+                      'brainpy.check.is_connector',
+                      check.is_connector),
+  'check_float': ('brainpy.checking.check_float',
+                  'brainpy.check.is_float',
+                  check.is_float),
+  'check_integer': ('brainpy.checking.check_integer',
+                    'brainpy.check.is_integer',
+                    check.is_integer),
+  'check_string': ('brainpy.checking.check_string',
+                   'brainpy.check.is_string',
+                   check.is_string),
+  'check_sequence': ('brainpy.checking.check_sequence',
+                     'brainpy.check.is_sequence',
+                     check.is_sequence),
+  'check_mode': ('brainpy.checking.check_mode',
+                 'brainpy.check.is_subclass',
+                 check.is_subclass),
+  'serialize_kwargs': ('brainpy.checking.serialize_kwargs',
+                       'brainpy.check.serialize_kwargs',
+                       check.serialize_kwargs),
+}
+__getattr__ = deprecation_getattr2('brainpy.checking', __deprecations)
+del deprecation_getattr2
```

## brainpy/_src/context.py

```diff
@@ -48,15 +48,15 @@
     """
     if key == 'dt':
       return self.dt
     if key in self._arguments:
       return self._arguments[key]
     if value is None:
       raise KeyError(f'Cannot found shared data of {key}. '
-                     f'Please define it with "brainpy.share.save()". ')
+                     f'Please define it with "brainpy.share.save({key}=<?>)". ')
     else:
       return value
 
   def save(self, *args, **kwargs) -> None:
     """Save shared arguments in the global context."""
     assert len(args) % 2 == 0
     for i in range(0, len(args), 2):
```

## brainpy/_src/delay.py

```diff
@@ -1,141 +1,263 @@
 """
 Delay variable.
 """
-
-from typing import Union, Callable, Optional, Dict
+import math
+import numbers
+from typing import Union, Callable, Optional, Dict, Sequence
 
 import jax
+from functools import partial
 import jax.numpy as jnp
 import numpy as np
 from jax.lax import stop_gradient
 
 from brainpy import check
-from brainpy import math as bm
+from brainpy import math as bm, tools
+from brainpy._src.context import share
+from brainpy._src.initialize import parameter, variable_
 from brainpy._src.dynsys import DynamicalSystemNS
 from brainpy._src.math.delayvars import ROTATE_UPDATE, CONCAT_UPDATE
-from brainpy.check import is_integer, jit_error_checking
-from brainpy._src.context import share
+from brainpy._src.mixin import ParamDesc
+from brainpy.check import jit_error
 
 __all__ = [
   'Delay',
+  'VariableDelay',
+  'DataDelay',
 ]
 
 
-class Delay(DynamicalSystemNS):
-  """Delay variable which has a fixed delay length.
+class Delay(DynamicalSystemNS, ParamDesc):
+  """Base class for delay variables.
 
-    The data in this delay variable is arranged as::
+  Args:
+    time: The delay time.
+    init: The initial delay data.
+    method: The delay method. Can be ``rotation`` and ``concat``.
+    name: The delay name.
+    mode: The computing mode.
+  """
 
-         delay = 0             [ data
-         delay = 1               data
-         delay = 2               data
-         ...                     ....
-         ...                     ....
-         delay = length-1        data
-         delay = length          data ]
+  max_time: float
+  max_length: int
+  data: Optional[bm.Variable]
+
+  def __init__(
+      self,
+      # delay time
+      time: Optional[Union[int, float]] = None,
+
+      # delay init
+      init: Optional[Union[numbers.Number, bm.Array, jax.Array, Callable]] = None,
+
+      # delay method
+      method: Optional[str] = None,
+
+      # others
+      name: Optional[str] = None,
+      mode: Optional[bm.Mode] = None,
+  ):
+    super().__init__(name=name, mode=mode)
+
+    # delay method
+    if method is None:
+      if self.mode.is_parent_of(bm.NonBatchingMode):
+        method = ROTATE_UPDATE
+      elif self.mode.is_parent_of(bm.TrainingMode):
+        method = CONCAT_UPDATE
+      else:
+        method = ROTATE_UPDATE
+    assert method in [ROTATE_UPDATE, CONCAT_UPDATE]
+    self.method = method
+
+    # delay length
+    if time is None:
+      length = 0
+      time = 0.
+    elif isinstance(time, (int, float)):
+      length = int(time / bm.get_dt())
+    else:
+      raise TypeError('time must be a int or float or None.')
+    assert isinstance(length, int)
+    self.max_length = length
+    self.max_time = time
+
+    # delay data
+    if init is not None:
+      assert isinstance(init, (numbers.Number, bm.Array, jax.Array, Callable))
+    self._init = init
+
+    # other info
+    self._registered_entries = dict()
+
+  def register_entry(
+      self,
+      entry: str,
+      delay_time: Optional[Union[float, bm.Array, Callable]],
+  ) -> 'Delay':
+    """Register an entry to access the data.
+
+    Args:
+      entry: str. The entry to access the delay data.
+      delay_time: The delay time of the entry (can be a float).
+
+    Returns:
+      Return the self.
+    """
+    raise NotImplementedError
+
+  def at(self, entry: str, *indices) -> bm.Array:
+    """Get the data at the given entry.
+
+    Args:
+      entry: str. The entry to access the data.
+      *indices: The slicing indices.
+
+    Returns:
+      The data.
+    """
+    raise NotImplementedError
+
+  def retrieve(self, delay_step, *indices):
+    """Retrieve the delay data according to the delay length.
 
     Parameters
     ----------
-    latest: Variable
-      The initial delay data.
-    length: int
-      The delay data length.
-    before_t0: Any
-      The delay data. It can be a Python number, like float, int, boolean values.
+    delay_step: int, ArrayType
+      The delay length used to retrieve the data.
+    """
+    raise NotImplementedError()
+
+
+class _TargetDelay1(Delay):
+  """Delay variable which has a fixed delay length.
+
+  The data in this delay variable is arranged as::
+
+       delay = 0             [ data
+       delay = 1               data
+       delay = 2               data
+       ...                     ....
+       ...                     ....
+       delay = length-1        data
+       delay = length          data ]
+
+  Args:
+    target: Variable. The delay target.
+    sharding: sequence of str. The name for each axis.
+    time: int, float. The delay time.
+    init: Any. The delay data. It can be a Python number, like float, int, boolean values.
       It can also be arrays. Or a callable function or instance of ``Connector``.
       Note that ``initial_delay_data`` should be arranged as the following way::
 
          delay = 1             [ data
          delay = 2               data
          ...                     ....
          ...                     ....
          delay = length-1        data
          delay = length          data ]
-    method: str
-      The method used for updating delay.
+    entries: optional, dict. The delay access entries.
+    name: str. The delay name.
+    method: str. The method used for updating delay. Default None.
+    mode: Mode. The computing mode. Default None.
 
-    """
+  """
 
-  latest: bm.Variable
-  data: Optional[bm.Variable]
-  length: int
+  not_desc_params = ('time', 'entries')
 
   def __init__(
       self,
-      latest: bm.Variable,
-      length: int = 0,
-      before_t0: Union[float, int, bool, bm.Array, jax.Array, Callable] = None,
+
+      # delay target
+      target: bm.Variable,
+      sharding: Optional[Sequence[str]] = None,
+
+      # delay time
+      time: Optional[Union[int, float]] = None,
+
+      # delay init
+      init: Optional[Union[numbers.Number, bm.Array, jax.Array, Callable]] = None,
+
+      # delay access entry
       entries: Optional[Dict] = None,
-      name: str = None,
-      method: str = ROTATE_UPDATE,
+
+      # delay method
+      method: Optional[str] = None,
+
+      # others
+      name: Optional[str] = None,
+      mode: Optional[bm.Mode] = None,
   ):
-    super().__init__(name=name)
-    if method is None:
-      if self.mode.is_a(bm.NonBatchingMode):
-        method = ROTATE_UPDATE
-      elif self.mode.is_parent_of(bm.TrainingMode):
-        method = CONCAT_UPDATE
+    super().__init__(time=time, init=init, method=method, name=name, mode=mode)
+
+    # check
+    if not isinstance(target, bm.Variable):
+      raise ValueError(f'Must be an instance of brainpy.math.Variable. But we got {type(target)}')
+
+    if self.mode.is_child_of(bm.BatchingMode):
+      assert target.batch_axis is not None
+
+    # sharding
+    if sharding is not None:
+      if len(sharding) == target.ndim:
+        sharding = list(sharding)
+      elif len(sharding) + 1 == target.ndim and target.batch_axis is not None:
+        sharding = list(sharding)
+        sharding.insert(target.batch_axis, bm.sharding.BATCH_AXIS)
       else:
-        method = ROTATE_UPDATE
-    assert method in [ROTATE_UPDATE, CONCAT_UPDATE]
-    self.method = method
+        raise ValueError('sharding axis names do not match the target dimension. ')
+    self._target_axis_names = tuple(sharding)
+    if sharding is not None:
+      sharding = list(sharding)
+      sharding.insert(0, bm.sharding.TIME_AXIS)
+    self._data_sharding = tuple(sharding)
 
     # target
-    if not isinstance(latest, bm.Variable):
-      raise ValueError(f'Must be an instance of brainpy.math.Variable. But we got {type(latest)}')
-    self.latest = latest
-
-    # delay length
-    assert isinstance(length, int)
-    self.length = length
+    self.target = bm.sharding.partition(target, self._target_axis_names)
 
     # delay data
-    if before_t0 is not None:
-      assert isinstance(before_t0, (int, float, bool, bm.Array, jax.Array, Callable))
-    self._before_t0 = before_t0
-    if length > 0:
-      self._init_data(length)
+    self._init = init
+    if self.max_length > 0:
+      self._init_data(self.max_length)
     else:
       self.data = None
 
     # other info
-    self._access_to_step = dict()
-    for entry, value in entries.items():
-      self.register_entry(entry, value)
+    if entries is not None:
+      for entry, value in entries.items():
+        self.register_entry(entry, value)
 
   def register_entry(
       self,
       entry: str,
-      delay_time: Optional[Union[float, bm.Array, Callable]] = None,
-      delay_step: Optional[Union[int, bm.Array, Callable]] = None,
+      delay_time: Optional[Union[float, bm.Array, Callable]],
   ) -> 'Delay':
     """Register an entry to access the data.
 
     Args:
-      entry (str): The entry to access the delay data.
-      delay_step: The delay step of the entry (must be an integer, denoting the delay step).
+      entry: str. The entry to access the delay data.
       delay_time: The delay time of the entry (can be a float).
 
     Returns:
       Return the self.
     """
-    if entry in self._access_to_step:
+    if entry in self._registered_entries:
       raise KeyError(f'Entry {entry} has been registered.')
 
-    if delay_time is not None:
-      if delay_step is not None:
-        raise ValueError('Provide either "delay_time" or "delay_step". Both you have given both.')
-      if callable(delay_time):
-        delay_time = bm.as_jax(delay_time(self.delay_target_shape))
-        delay_step = jnp.asarray(delay_time / bm.get_dt(), dtype=bm.get_int())
-      elif isinstance(delay_time, float):
-        delay_step = int(delay_time / bm.get_dt())
-      else:
-        delay_step = jnp.asarray(bm.as_jax(delay_time) / bm.get_dt(), dtype=bm.get_int())
+    if delay_time is None:
+      delay_step = None
+      delay_time = 0.
+    elif callable(delay_time):
+      delay_time = bm.as_jax(delay_time(self.delay_target_shape))
+      delay_step = jnp.asarray(delay_time / bm.get_dt(), dtype=bm.get_int())
+    elif isinstance(delay_time, float):
+      delay_step = int(delay_time / bm.get_dt())
+    else:
+      delay_step = jnp.asarray(bm.as_jax(delay_time) / bm.get_dt(), dtype=bm.get_int())
 
     # delay steps
     if delay_step is None:
       delay_type = 'none'
     elif isinstance(delay_step, int):
       delay_type = 'homo'
     elif isinstance(delay_step, (bm.Array, jax.Array, np.ndarray)):
@@ -162,80 +284,79 @@
     elif delay_type == 'homo':
       max_delay_step = delay_step
     else:
       max_delay_step = None
 
     # delay variable
     if max_delay_step is not None:
-      if self.length < max_delay_step:
+      if self.max_length < max_delay_step:
         self._init_data(max_delay_step)
-        self.length = max_delay_step
-    self._access_to_step[entry] = delay_step
+        self.max_length = max_delay_step
+        self.max_time = delay_time
+    self._registered_entries[entry] = delay_step
     return self
 
   def at(self, entry: str, *indices) -> bm.Array:
     """Get the data at the given entry.
 
     Args:
-      entry (str): The entry to access the data.
-      *indices:
+      entry: str. The entry to access the data.
+      *indices: The slicing indices.
 
     Returns:
       The data.
     """
-    assert isinstance(entry, str)
-    if entry not in self._access_to_step:
+    assert isinstance(entry, str), 'entry should be a string for describing the '
+    if entry not in self._registered_entries:
       raise KeyError(f'Does not find delay entry "{entry}".')
-    delay_step = self._access_to_step[entry]
+    delay_step = self._registered_entries[entry]
     if delay_step is None:
-      return self.latest.value
+      return self.target.value
     else:
       if self.data is None:
-        return self.latest.value
+        return self.target.value
       else:
         if isinstance(delay_step, slice):
           return self.retrieve(delay_step, *indices)
         elif np.ndim(delay_step) == 0:
           return self.retrieve(delay_step, *indices)
         else:
-          if len(indices) == 0 and len(delay_step) == self.latest.shape[0]:
+          if len(indices) == 0 and len(delay_step) == self.target.shape[0]:
             indices = (jnp.arange(delay_step.size),)
           return self.retrieve(delay_step, *indices)
 
   @property
   def delay_target_shape(self):
     """The data shape of the delay target."""
-    return self.latest.shape
+    return self.target.shape
 
   def __repr__(self):
     name = self.__class__.__name__
-    return (f'{name}(num_delay_step={self.length}, '
-            f'delay_target_shape={self.delay_target_shape}, '
-            f'update_method={self.method})')
+    return f'{name}(step={self.max_length}, shape={self.delay_target_shape}, method={self.method})'
 
   def _check_delay(self, delay_len):
     raise ValueError(f'The request delay length should be less than the '
-                     f'maximum delay {self.length}. '
+                     f'maximum delay {self.max_length}. '
                      f'But we got {delay_len}')
 
   def retrieve(self, delay_step, *indices):
     """Retrieve the delay data according to the delay length.
 
     Parameters
     ----------
     delay_step: int, ArrayType
       The delay length used to retrieve the data.
     """
     assert delay_step is not None
     if check.is_checking():
-      jit_error_checking(jnp.any(delay_step > self.length), self._check_delay, delay_step)
+      jit_error(bm.any(delay_step > self.max_length), self._check_delay, delay_step)
 
     if self.method == ROTATE_UPDATE:
       i = share.load('i')
-      delay_idx = (i + delay_step) % (self.length + 1)
+      delay_idx = (i + delay_step) % (self.max_length + 1)
       delay_idx = stop_gradient(delay_idx)
 
     elif self.method == CONCAT_UPDATE:
       delay_idx = delay_step
 
     else:
       raise ValueError(f'Unknown updating method "{self.method}"')
@@ -244,56 +365,380 @@
     if hasattr(delay_idx, 'dtype') and not jnp.issubdtype(delay_idx.dtype, jnp.integer):
       raise ValueError(f'"delay_len" must be integer, but we got {delay_idx}')
     indices = (delay_idx,) + tuple(indices)
 
     # the delay data
     return self.data[indices]
 
-  def update(self, latest_value: Optional[Union[bm.Array, jax.Array]] = None) -> None:
+  def update(
+      self,
+      latest_value: Optional[Union[bm.Array, jax.Array]] = None
+  ) -> None:
     """Update delay variable with the new data.
     """
     if self.data is not None:
       # get the latest target value
       if latest_value is None:
-        latest_value = self.latest.value
+        latest_value = self.target.value
 
       # update the delay data at the rotation index
       if self.method == ROTATE_UPDATE:
         i = share.load('i')
-        idx = bm.as_jax((i - 1) % (self.length + 1))
+        idx = bm.as_jax((i - 1) % (self.max_length + 1))
         self.data[idx] = latest_value
 
       # update the delay data at the first position
       elif self.method == CONCAT_UPDATE:
-        if self.length >= 2:
+        if self.max_length >= 2:
           self.data.value = bm.vstack([latest_value, self.data[1:]])
         else:
           self.data[0] = latest_value
 
   def reset_state(self, batch_size: int = None):
     """Reset the delay data.
     """
     # initialize delay data
     if self.data is not None:
-      self._init_data(self.length, batch_size)
+      self._init_data(self.max_length, batch_size)
 
-  def _init_data(self, length, batch_size: int = None):
+  def _init_data(self, length: int, batch_size: int = None):
     if batch_size is not None:
-      if self.latest.batch_size != batch_size:
+      if self.target.batch_size != batch_size:
         raise ValueError(f'The batch sizes of delay variable and target variable differ '
-                         f'({self.latest.batch_size} != {batch_size}). '
+                         f'({self.target.batch_size} != {batch_size}). '
                          'Please reset the target variable first, because delay data '
                          'depends on the target variable. ')
 
-    if self.latest.batch_axis is None:
+    if self.target.batch_axis is None:
       batch_axis = None
     else:
-      batch_axis = self.latest.batch_axis + 1
-    self.data = bm.Variable(jnp.zeros((length + 1,) + self.latest.shape, dtype=self.latest.dtype),
-                            batch_axis=batch_axis)
+      batch_axis = self.target.batch_axis + 1
+
+    f = jax.jit(jnp.zeros,
+                static_argnums=0,
+                static_argnames='dtype',
+                out_shardings=bm.sharding.get_sharding(self._data_sharding))
+    data = f((length + 1,) + self.target.shape, dtype=self.target.dtype)
+    self.data = bm.Variable(data, batch_axis=batch_axis)
     # update delay data
-    self.data[0] = self.latest.value
-    if isinstance(self._before_t0, (bm.Array, jax.Array, float, int, bool)):
-      self.data[1:] = self._before_t0
-    elif callable(self._before_t0):
-      self.data[1:] = self._before_t0((length,) + self.latest.shape, dtype=self.latest.dtype)
+    self.data[0] = self.target.value
+    if isinstance(self._init, (bm.Array, jax.Array, numbers.Number)):
+      self.data[1:] = self._init
+    elif callable(self._init):
+      self.data[1:] = self._init((length,) + self.target.shape,
+                                 dtype=self.target.dtype)
+
+
+def _check_target_sharding(sharding, ndim, mode: bm.Mode):
+  if sharding is not None:
+    if len(sharding) == ndim:
+      sharding = list(sharding)
+    elif len(sharding) + 1 == ndim and mode.is_child_of(bm.BatchingMode):
+      sharding = list(sharding)
+      sharding.insert(0, bm.sharding.BATCH_AXIS)
+    else:
+      raise ValueError('sharding axis names do not match the target dimension. ')
+  return sharding
+
+
+class VariableDelay(Delay):
+  """Delay variable which has a fixed delay length.
 
+  The data in this delay variable is arranged as::
+
+       delay = 0             [ data
+       delay = 1               data
+       delay = 2               data
+       ...                     ....
+       ...                     ....
+       delay = length-1        data
+       delay = length          data ]
+
+  Args:
+    target: Variable. The delay target.
+    time: int, float. The delay time.
+    init: Any. The delay data. It can be a Python number, like float, int, boolean values.
+      It can also be arrays. Or a callable function or instance of ``Connector``.
+      Note that ``initial_delay_data`` should be arranged as the following way::
+
+         delay = 1             [ data
+         delay = 2               data
+         ...                     ....
+         ...                     ....
+         delay = length-1        data
+         delay = length          data ]
+    entries: optional, dict. The delay access entries.
+    name: str. The delay name.
+    method: str. The method used for updating delay. Default None.
+    mode: Mode. The computing mode. Default None.
+
+  """
+
+  not_desc_params = ('time', 'entries')
+
+  def __init__(
+      self,
+
+      # delay target
+      target: bm.Variable,
+
+      # delay time
+      time: Optional[Union[int, float]] = None,
+
+      # delay init
+      init: Optional[Union[numbers.Number, bm.Array, jax.Array, Callable]] = None,
+
+      # delay access entry
+      entries: Optional[Dict] = None,
+
+      # delay method
+      method: Optional[str] = None,
+
+      # others
+      name: Optional[str] = None,
+      mode: Optional[bm.Mode] = None,
+  ):
+    super().__init__(time=time, init=init, method=method, name=name, mode=mode)
+
+    # check
+    if not isinstance(target, bm.Variable):
+      raise ValueError(f'Must be an instance of brainpy.math.Variable. But we got {type(target)}')
+
+    if self.mode.is_child_of(bm.BatchingMode):
+      assert target.batch_axis is not None
+
+    # sharding
+    sharding = None
+    if target.axis_names is not None:
+      sharding = list(target.axis_names)
+      sharding.insert(0, bm.sharding.TIME_AXIS)
+      sharding = tuple(sharding)
+    self.axis_names = sharding
+
+    # target
+    self.target = target
+
+    # delay data
+    self._init = init
+    if self.max_length > 0:
+      self._init_data(self.max_length)
+    else:
+      self.data = None
+
+    # other info
+    if entries is not None:
+      for entry, value in entries.items():
+        self.register_entry(entry, value)
+
+  def register_entry(
+      self,
+      entry: str,
+      delay_time: Optional[Union[int, float]],
+  ) -> 'Delay':
+    """Register an entry to access the data.
+
+    Args:
+      entry: str. The entry to access the delay data.
+      delay_time: The delay time of the entry (can be a float).
+
+    Returns:
+      Return the self.
+    """
+    if entry in self._registered_entries:
+      raise KeyError(f'Entry {entry} has been registered.')
+
+    if isinstance(delay_time, (np.ndarray, jax.Array)):
+      assert delay_time.size == 1 and delay_time.ndim == 0
+      delay_time = delay_time.item()
+
+    if delay_time is None:
+      delay_step = None
+      delay_time = 0.
+    else:
+      assert isinstance(delay_time, (int, float))
+      delay_step = math.ceil(delay_time / bm.get_dt())
+
+    # delay variable
+    if delay_step is not None:
+      if self.max_length < delay_step:
+        self._init_data(delay_step)
+        self.max_length = delay_step
+        self.max_time = delay_time
+    self._registered_entries[entry] = delay_step
+    return self
+
+  def at(self, entry: str, *indices) -> bm.Array:
+    """Get the data at the given entry.
+
+    Args:
+      entry: str. The entry to access the data.
+      *indices: The slicing indices.
+
+    Returns:
+      The data.
+    """
+    assert isinstance(entry, str), 'entry should be a string for describing the '
+    if entry not in self._registered_entries:
+      raise KeyError(f'Does not find delay entry "{entry}".')
+    delay_step = self._registered_entries[entry]
+    if delay_step is None or delay_step == 0.:
+      return self.target.value
+    else:
+      assert self.data is not None
+      if delay_step == 0:
+        return self.target.value
+      else:
+        return self.retrieve(delay_step, *indices)
+
+  @property
+  def delay_target_shape(self):
+    """The data shape of the delay target."""
+    return self.target.shape
+
+  def __repr__(self):
+    name = self.__class__.__name__
+    return f'{name}(step={self.max_length}, shape={self.delay_target_shape}, method={self.method})'
+
+  def _check_delay(self, delay_len):
+    raise ValueError(f'The request delay length should be less than the '
+                     f'maximum delay {self.max_length}. '
+                     f'But we got {delay_len}')
+
+  def retrieve(self, delay_step, *indices):
+    """Retrieve the delay data according to the delay length.
+
+    Parameters
+    ----------
+    delay_step: int, ArrayType
+      The delay length used to retrieve the data.
+    """
+    assert delay_step is not None
+    if check.is_checking():
+      jit_error(delay_step > self.max_length, self._check_delay, delay_step)
+
+    if self.method == ROTATE_UPDATE:
+      i = share.load('i')
+      delay_idx = (i + delay_step - 1) % self.max_length
+      delay_idx = stop_gradient(delay_idx)
+
+    elif self.method == CONCAT_UPDATE:
+      delay_idx = delay_step
+
+    else:
+      raise ValueError(f'Unknown updating method "{self.method}"')
+
+    # the delay index
+    if hasattr(delay_idx, 'dtype') and not jnp.issubdtype(delay_idx.dtype, jnp.integer):
+      raise ValueError(f'"delay_len" must be integer, but we got {delay_idx}')
+    indices = (delay_idx,) + tuple(indices)
+
+    # the delay data
+    return self.data[indices]
+
+  def update(
+      self,
+      latest_value: Optional[Union[bm.Array, jax.Array]] = None
+  ) -> None:
+    """Update delay variable with the new data.
+    """
+    if self.data is not None:
+      # get the latest target value
+      if latest_value is None:
+        latest_value = self.target.value
+
+      # update the delay data at the rotation index
+      if self.method == ROTATE_UPDATE:
+        i = share.load('i')
+        idx = bm.as_jax((i - 1) % self.max_length)
+        self.data[idx] = latest_value
+
+      # update the delay data at the first position
+      elif self.method == CONCAT_UPDATE:
+        if self.max_length > 1:
+          self.data.value = bm.vstack([latest_value, self.data[1:]])
+        else:
+          self.data[0] = latest_value
+
+  def reset_state(self, batch_size: int = None):
+    """Reset the delay data.
+    """
+    # initialize delay data
+    if self.data is not None:
+      self._init_data(self.max_length, batch_size)
+
+  def _init_data(self, length: int, batch_size: int = None):
+    if batch_size is not None:
+      if self.target.batch_size != batch_size:
+        raise ValueError(f'The batch sizes of delay variable and target variable differ '
+                         f'({self.target.batch_size} != {batch_size}). '
+                         'Please reset the target variable first, because delay data '
+                         'depends on the target variable. ')
+
+    if self.target.batch_axis is None:
+      batch_axis = None
+    else:
+      batch_axis = self.target.batch_axis + 1
+
+    f = jax.jit(jnp.zeros,
+                static_argnums=0,
+                static_argnames='dtype',
+                out_shardings=bm.sharding.get_sharding(self.axis_names))
+    data = f((length,) + self.target.shape, dtype=self.target.dtype)
+    self.data = bm.Variable(data, batch_axis=batch_axis)
+    # update delay data
+    if isinstance(self._init, (bm.Array, jax.Array, numbers.Number)):
+      self.data[:] = self._init
+    elif callable(self._init):
+      self.data[:] = self._init((length,) + self.target.shape, dtype=self.target.dtype)
+
+
+class DataDelay(VariableDelay):
+  
+  not_desc_params = ('time', 'entries')
+
+  def __init__(
+      self,
+
+      # delay target
+      target: bm.Variable,
+      target_init: Callable,
+
+      # delay time
+      time: Optional[Union[int, float]] = None,
+
+      # delay init
+      init: Optional[Union[numbers.Number, bm.Array, jax.Array, Callable]] = None,
+
+      # delay access entry
+      entries: Optional[Dict] = None,
+
+      # delay method
+      method: Optional[str] = None,
+
+      # others
+      name: Optional[str] = None,
+      mode: Optional[bm.Mode] = None,
+  ):
+    self.target_init = target_init
+    super().__init__(target=target,
+                     time=time,
+                     init=init,
+                     entries=entries,
+                     method=method,
+                     name=name,
+                     mode=mode)
+
+  def reset_state(self, batch_size: int = None):
+    """Reset the delay data.
+    """
+    self.target.value = variable_(self.target_init, self.target.size_without_batch, batch_size)
+    if self.data is not None:
+      self._init_data(self.max_length, batch_size)
+
+  def update(
+      self,
+      latest_value: Union[bm.Array, jax.Array]
+  ) -> None:
+    """Update delay variable with the new data.
+    """
+    self.target.value = latest_value
+    super().update(latest_value)
```

## brainpy/_src/dynsys.py

```diff
@@ -28,15 +28,15 @@
   # containers
   'Container', 'Network', 'Sequential', 'System',
 
   # channel models
   'Channel',
 
   # neuron models
-  'NeuGroup', 'CondNeuGroup',
+  'NeuGroup', 'CondNeuGroup', 'NeuGroupNS',
 
   # synapse models
   'SynConn',
   'TwoEndConn',
   'SynOut', 'NullSynOut',
   'SynSTP',
   'SynLTP',
@@ -109,14 +109,17 @@
   ----------
   name : optional, str
     The name of the dynamical system.
   mode: optional, Mode
     The model computation mode. It should be instance of :py:class:`~.Mode`.
   """
 
+  supported_modes: Optional[Sequence[bm.Mode]] = None
+  '''Supported computing modes.'''
+
   _pass_shared_args: bool = True
 
   global_delay_data: Dict[str, Tuple[Union[bm.LengthDelay, None], Variable]] = dict()
   '''Global delay data, which stores the delay variables and corresponding delay targets. 
   This variable is useful when the same target variable is used in multiple mappings, 
   as it can reduce the duplicate delay variable registration.'''
 
@@ -128,14 +131,20 @@
     # mode setting
     mode = bm.get_mode() if mode is None else mode
     if not isinstance(mode, bm.Mode):
       raise ValueError(f'Should be instance of {bm.Mode.__name__}, '
                        f'but we got {type(mode)}: {mode}')
     self._mode = mode
 
+    if self.supported_modes is not None:
+      if not self.mode.is_parent_of(*self.supported_modes):
+        raise UnsupportedError(f'The mode only supports computing modes '
+                               f'which are parents of {self.supported_modes}, '
+                               f'but we got {self.mode}.')
+
     # local delay variables
     self.local_delay_vars: Dict[str, bm.LengthDelay] = Collector()
 
     # super initialization
     BrainPyObject.__init__(self, name=name)
 
   @property
@@ -155,36 +164,39 @@
 
   def __call__(self, *args, **kwargs):
     """The shortcut to call ``update`` methods."""
     global share
     if share is None:
       from brainpy._src.context import share
 
-    if self._pass_shared_args:
-      if hasattr(self.update, '_new_style') and getattr(self.update, '_new_style'):
-        if len(args) and isinstance(args[0], dict):
+    try:
+      if self._pass_shared_args:
+        if hasattr(self.update, '_new_style') and getattr(self.update, '_new_style'):
+          if len(args) and isinstance(args[0], dict):
+            share.save(**args[0])
+            return self.update(*args[1:], **kwargs)
+          else:
+            return self.update(*args, **kwargs)
+        else:
+          if len(args) and isinstance(args[0], dict):
+            return self.update(*args, **kwargs)
+          else:
+            # If first argument is not shared argument,
+            # we should get the shared arguments from the global context.
+            # However, users should set and update shared arguments
+            # in the global context when using this mode.
+            return self.update(share.get_shargs(), *args, **kwargs)
+      else:
+        if len(args) and isinstance(args[0], dict):  # it may be shared arguments
           share.save(**args[0])
           return self.update(*args[1:], **kwargs)
         else:
           return self.update(*args, **kwargs)
-      else:
-        if len(args) and isinstance(args[0], dict):
-          return self.update(*args, **kwargs)
-        else:
-          # If first argument is not shared argument,
-          # we should get the shared arguments from the global context.
-          # However, users should set and update shared arguments
-          # in the global context when using this mode.
-          return self.update(share.get_shargs(), *args, **kwargs)
-    else:
-      if len(args) and isinstance(args[0], dict):  # it may be shared arguments
-        share.save(**args[0])
-        return self.update(*args[1:], **kwargs)
-      else:
-        return self.update(*args, **kwargs)
+    except Exception as e:
+      raise RuntimeError(f'Error occurs when running {self.name}: {self}') from e
 
   def register_delay(
       self,
       identifier: str,
       delay_step: Optional[Union[int, ArrayType, Callable, Initializer]],
       delay_target: Variable,
       initial_delay_data: Union[Initializer, Callable, ArrayType, float, int, bool] = None,
@@ -643,14 +655,15 @@
     elif isinstance(size, (int, np.integer)):
       size = (size,)
     else:
       raise ValueError('size must be int, or a tuple/list of int.'
                        f'But we got {type(size)}')
     self.size = size
     self.keep_size = keep_size
+
     # number of neurons
     self.num = tools.size2num(size)
 
     # initialize
     super(NeuGroup, self).__init__(name=name, mode=mode)
 
   @property
@@ -663,30 +676,29 @@
 
   def get_batch_shape(self, batch_size=None):
     if batch_size is None:
       return self.varshape
     else:
       return (batch_size,) + self.varshape
 
-  def update(self, *args):
+  def update(self, *args, **kwargs):
     """The function to specify the updating rule.
     """
     raise NotImplementedError(f'Subclass of {self.__class__.__name__} must '
                               f'implement "update" function.')
 
   def clear_input(self):
     """Function to clear inputs in the neuron group.
     It will be useful when monitoring inputs of the object received."""
     pass
 
   def __getitem__(self, item):
     return NeuGroupView(target=self, index=item)
 
 
-
 class SynConn(DynamicalSystem):
   """Base class to model two-end synaptic connections.
 
   Parameters
   ----------
   pre : NeuGroup
     Pre-synaptic neuron group.
```

## brainpy/_src/modes.py

```diff
@@ -1,6 +1,27 @@
 # -*- coding: utf-8 -*-
 
 """
 This module is deprecated since version 2.3.1.
 Please use ``brainpy.math.*`` instead.
 """
+
+from brainpy._src.math import modes
+from brainpy import check
+from brainpy._src.deprecations import deprecation_getattr2
+
+__deprecations = {
+  'Mode': ('brainpy.modes.Mode', 'brainpy.math.Mode', modes.Mode),
+  'NormalMode': ('brainpy.modes.NormalMode', 'brainpy.math.NonBatchingMode', modes.NonBatchingMode),
+  'BatchingMode': ('brainpy.modes.BatchingMode', 'brainpy.math.BatchingMode', modes.BatchingMode),
+  'TrainingMode': ('brainpy.modes.TrainingMode', 'brainpy.math.TrainingMode', modes.TrainingMode),
+  'normal': ('brainpy.modes.normal', 'brainpy.math.nonbatching_mode', modes.nonbatching_mode),
+  'batching': ('brainpy.modes.batching', 'brainpy.math.batching_mode', modes.batching_mode),
+  'training': ('brainpy.modes.training', 'brainpy.math.training_mode', modes.training_mode),
+  'check_mode': ('brainpy.modes.check_mode', 'brainpy.check.is_subclass', check.is_subclass),
+}
+__getattr__ = deprecation_getattr2('brainpy.modes', __deprecations)
+del deprecation_getattr2
+
+
+
+
```

## brainpy/_src/types.py

```diff
@@ -1,34 +1,37 @@
 # -*- coding: utf-8 -*-
 
-from typing import TypeVar, Tuple, Union, Callable
+import numbers
+from typing import TypeVar, Tuple, Union, Callable, Sequence
 
-import jax.numpy as jnp
+import jax
 import numpy as np
 
-from brainpy._src.math.ndarray import Array
-from brainpy._src.math.object_transform import Variable, TrainVar
 from brainpy._src import connect as conn
 from brainpy._src import initialize as init
+from brainpy._src.math.ndarray import Array
+from brainpy._src.math.object_transform import Variable, TrainVar
 
 __all__ = [
   'ArrayType', 'Parameter', 'PyTree',
   'Shape', 'Initializer',
-  'Output', 'Monitor'
+  'Output', 'Monitor', 'Sharding',
 ]
 
 
 # data
-Parameter = TypeVar('Parameter', float, int, jnp.ndarray, 'Array', 'Variable') # noqa
-ArrayType = TypeVar('ArrayType', Array, Variable, TrainVar, jnp.ndarray, np.ndarray) # noqa
+Parameter = TypeVar('Parameter', numbers.Number, jax.Array, 'Array', 'Variable') # noqa
+ArrayType = TypeVar('ArrayType', Array, Variable, TrainVar, jax.Array, np.ndarray) # noqa
 Array = ArrayType # noqa
 PyTree = TypeVar('PyTree') # noqa
 
 # shape
 Shape = TypeVar('Shape', int, Tuple[int, ...]) # noqa
 
 # component
 Output = TypeVar('Output') # noqa
 Monitor = TypeVar('Monitor') # noqa
-Connector = Union[conn.Connector, Array, Variable, jnp.ndarray, np.ndarray]
-Initializer = Union[init.Initializer, Callable, Array, Variable, jnp.ndarray, np.ndarray]
+Connector = Union[conn.Connector, Array, Variable, jax.Array, np.ndarray]
+Initializer = Union[init.Initializer, Callable, Array, Variable, jax.Array, np.ndarray]
+
+Sharding = Union[Sequence[str], jax.sharding.Sharding, jax.Device]
```

## brainpy/_src/analysis/highdim/slow_points.py

```diff
@@ -10,15 +10,15 @@
 from jax.scipy.optimize import minimize
 from jax.tree_util import tree_flatten, tree_map
 
 import brainpy._src.math as bm
 from brainpy import optim, losses
 from brainpy._src.analysis import utils, base, constants
 from brainpy._src.dynsys import DynamicalSystem
-from brainpy._src.dyn.runners import check_and_format_inputs, _f_ops
+from brainpy._src.runners import check_and_format_inputs, _f_ops
 from brainpy._src.tools.dicts import DotDict
 from brainpy.errors import AnalyzerError, UnsupportedError
 from brainpy.types import ArrayType
 
 __all__ = [
   'SlowPointFinder',
 ]
```

## brainpy/_src/analysis/utils/model.py

```diff
@@ -1,15 +1,15 @@
 # -*- coding: utf-8 -*-
 
 
 from brainpy._src.math.object_transform import Variable
 from brainpy._src.math.environment import get_float
 from brainpy._src.math.interoperability import as_jax
 from brainpy._src.dynsys import DynamicalSystem
-from brainpy._src.dyn.runners import DSRunner
+from brainpy._src.runners import DSRunner
 from brainpy._src.integrators.base import Integrator
 from brainpy._src.integrators.joint_eq import JointEq
 from brainpy._src.integrators.ode.base import ODEIntegrator
 from brainpy._src.integrators.ode.generic import odeint
 from brainpy.errors import AnalyzerError, UnsupportedError
 
 __all__ = [
```

## brainpy/_src/base/__init__.py

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
 
 """
 This module is deprecated since version 2.3.1.
 Please use ``brainpy.math.*`` instead.
 """
 
-from . import (base, collector, function, io, naming)
+from . import (collector, function, io, naming)
```

## brainpy/_src/base/io.py

```diff
@@ -1,24 +1,20 @@
 # -*- coding: utf-8 -*-
 
 from brainpy._src.checkpoints import io
 
-__all__ = [
-  'SUPPORTED_FORMATS',
-  'save_as_h5', 'load_by_h5',
-  'save_as_npz', 'load_by_npz',
-  'save_as_pkl', 'load_by_pkl',
-  'save_as_mat', 'load_by_mat',
-]
+__deprecations = {
+  'save_as_h5': ('brainpy.base.io.save_as_h5', 'brainpy.checkpoints.save_as_h5', io.save_as_h5),
+  'load_by_h5': ('brainpy.base.io.load_by_h5', 'brainpy.checkpoints.load_by_h5', io.load_by_h5),
+  'save_as_npz': ('brainpy.base.io.save_as_npz', 'brainpy.checkpoints.save_as_npz', io.save_as_npz),
+  'load_by_npz': ('brainpy.base.io.load_by_npz', 'brainpy.checkpoints.load_by_npz', io.load_by_npz),
+  'save_as_pkl': ('brainpy.base.io.save_as_pkl', 'brainpy.checkpoints.save_as_pkl', io.save_as_pkl),
+  'load_by_pkl': ('brainpy.base.io.load_by_pkl', 'brainpy.checkpoints.load_by_pkl', io.load_by_pkl),
+  'save_as_mat': ('brainpy.base.io.save_as_mat', 'brainpy.checkpoints.save_as_mat', io.save_as_mat),
+  'load_by_mat': ('brainpy.base.io.load_by_mat', 'brainpy.checkpoints.load_by_mat', io.load_by_mat),
+}
+from brainpy._src.deprecations import deprecation_getattr2
+__getattr__ = deprecation_getattr2('', __deprecations)
+del deprecation_getattr2
 
 
-SUPPORTED_FORMATS = io.SUPPORTED_FORMATS
-save_as_h5 = io.save_as_h5
-load_by_h5 = io.load_by_h5
-save_as_npz = io.save_as_npz
-load_by_npz = io.load_by_npz
-save_as_pkl = io.save_as_pkl
-load_by_pkl = io.load_by_pkl
-save_as_mat = io.save_as_mat
-load_by_mat = io.load_by_mat
-
```

## brainpy/_src/checkpoints/serialization.py

```diff
@@ -24,19 +24,20 @@
 from jax import process_index
 from jax.experimental.multihost_utils import sync_global_devices
 
 try:
   from jax import monitoring
 except (ModuleNotFoundError, ImportError):
   monitoring = None
+
 try:
-  from jax.experimental.gda_serialization.serialization import get_tensorstore_spec
-  from jax.experimental.gda_serialization.serialization import GlobalAsyncCheckpointManager
+  from jax.experimental.array_serialization import get_tensorstore_spec, GlobalAsyncCheckpointManager  # noqa
 except (ModuleNotFoundError, ImportError):
   get_tensorstore_spec = None
+  GlobalAsyncCheckpointManager = None
 
 from brainpy._src.math.ndarray import Array
 from brainpy.errors import (AlreadyExistsError,
                             MPACheckpointingRequiredError,
                             MPARestoreTargetRequiredError,
                             MPARestoreDataCorruptedError,
                             InvalidCheckpointPath,
```

## brainpy/_src/connect/base.py

```diff
@@ -5,14 +5,16 @@
 
 import jax.numpy as jnp
 import numpy as onp
 
 from brainpy import tools, math as bm
 from brainpy.errors import ConnectorError
 
+import textwrap
+
 __all__ = [
   # the connection types
   'CONN_MAT',
   'PRE_IDS', 'POST_IDS',
   'PRE2POST', 'POST2PRE',
   'PRE2SYN', 'POST2SYN',
   'SUPPORTED_SYN_STRUCTURE',
@@ -23,14 +25,17 @@
   # brainpy_object class
   'Connector', 'TwoEndConnector', 'OneEndConnector',
 
   # methods
   'mat2coo', 'mat2csc', 'mat2csr',
   'csr2csc', 'csr2mat', 'csr2coo',
   'coo2csr', 'coo2csc', 'coo2mat',
+
+  # visualize
+  'visualizeMat',
 ]
 
 CONN_MAT = 'conn_mat'
 PRE_IDS = 'pre_ids'
 POST_IDS = 'post_ids'
 PRE2POST = 'pre2post'
 POST2PRE = 'post2pre'
@@ -715,7 +720,20 @@
     indptr_new = jnp.asarray(indptr_new, dtype=IDX_DTYPE)
 
   if data is None:
     return pre_ids_new, indptr_new
   else:
     data_new = data[sort_ids]
     return pre_ids_new, indptr_new, data_new
+
+
+def visualizeMat(mat, description):
+  try:
+    import seaborn as sns
+    import matplotlib.pyplot as plt
+  except (ModuleNotFoundError, ImportError):
+    print('Please install seaborn and matplotlib for this function')
+    return
+  sns.heatmap(mat, cmap='viridis')
+  warpped_title = textwrap.fill(description, width=60)
+  plt.title(warpped_title)
+  plt.show()
```

## brainpy/_src/connect/random_conn.py

```diff
@@ -1,12 +1,12 @@
 # -*- coding: utf-8 -*-
-
+from functools import partial
 from typing import Optional
 
-import jax.numpy as jnp
+from jax import vmap, jit, numpy as jnp
 import numpy as np
 
 import brainpy.math as bm
 from brainpy.errors import ConnectorError
 from brainpy.tools import numba_seed, numba_jit, numba_range, format_seed
 from brainpy._src.tools.package import SUPPORT_NUMBA
 from .base import *
@@ -323,14 +323,29 @@
       pre_nums -= jnp.sum(true_ids, axis=1)
       selected_post_ids = selected_post_ids.flatten()[jnp.logical_not(true_ids).flatten()]
     else:
       selected_post_ids = selected_post_ids.flatten()
     selected_pre_inptr = jnp.cumsum(jnp.concatenate([jnp.zeros(1), pre_nums]))
     return selected_post_ids.astype(IDX_DTYPE), selected_pre_inptr.astype(IDX_DTYPE)
 
+@jit
+@partial(vmap, in_axes=(0, None, None))
+def gaussian_prob_dist_cal1(i_value, post_values, sigma):
+  dists = jnp.abs(i_value - post_values)
+  exp_dists = jnp.exp(-(jnp.sqrt(jnp.sum(dists ** 2, axis=0)) / sigma) ** 2 / 2)
+  return bm.asarray(exp_dists)
+
+@jit
+@partial(vmap, in_axes=(0, None, None, None))
+def gaussian_prob_dist_cal2(i_value, post_values, value_sizes, sigma):
+  dists = jnp.abs(i_value - post_values)
+  dists = jnp.where(dists > (value_sizes / 2), value_sizes - dists, dists)
+  exp_dists = jnp.exp(-(jnp.sqrt(jnp.sum(dists ** 2, axis=0)) / sigma) ** 2 / 2)
+  return bm.asarray(exp_dists)
+
 
 class GaussianProb(OneEndConnector):
   r"""Builds a Gaussian connectivity pattern within a population of neurons,
   where the connection probability decay according to the gaussian function.
 
   Specifically, for any pair of neurons :math:`(i, j)`,
 
@@ -388,15 +403,16 @@
   def __repr__(self):
     return (f'{self.__class__.__name__}(sigma={self.sigma}, '
             f'normalize={self.normalize}, '
             f'periodic_boundary={self.periodic_boundary}, '
             f'include_self={self.include_self}, '
             f'seed={self.seed})')
 
-  def build_mat(self, pre_size=None, post_size=None):
+  def build_mat(self, isOptimized=True):
+    self.rng = np.random.RandomState(self.seed)
     # value range to encode
     if self.encoding_values is None:
       value_ranges = tuple([(0, s) for s in self.pre_size])
     elif isinstance(self.encoding_values, (tuple, list)):
       if len(self.encoding_values) == 0:
         raise ConnectorError(f'encoding_values has a length of 0.')
       elif isinstance(self.encoding_values[0], (int, float)):
@@ -422,32 +438,53 @@
     # post_values = np.stack([v.flatten() for v in np.meshgrid(*values, indexing='ij')])
     post_values = np.stack([v.flatten() for v in np.meshgrid(*values)])
     value_sizes = np.array([v[1] - v[0] for v in value_ranges])
     if value_sizes.ndim < post_values.ndim:
       value_sizes = np.expand_dims(value_sizes, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
 
     # probability of connections
-    prob_mat = []
-    for i in range(self.pre_num):
-      # values for node i
-      i_coordinate = tuple()
-      for s in self.pre_size[:-1]:
-        i, pos = divmod(i, s)
-        i_coordinate += (pos,)
-      i_coordinate += (i,)
-      i_value = np.array([values[i][c] for i, c in enumerate(i_coordinate)])
-      if i_value.ndim < post_values.ndim:
-        i_value = np.expand_dims(i_value, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
-      # distances
-      dists = np.abs(i_value - post_values)
+    if isOptimized:
+      i_value_list = np.zeros(shape=(self.pre_num, len(self.pre_size), 1))
+      for i in range(self.pre_num):
+        list_index = i
+        # values for node i
+        i_coordinate = tuple()
+        for s in self.pre_size[:-1]:
+          i, pos = divmod(i, s)
+          i_coordinate += (pos,)
+        i_coordinate += (i,)
+        i_value = np.array([values[i][c] for i, c in enumerate(i_coordinate)])
+        if i_value.ndim < post_values.ndim:
+          i_value = np.expand_dims(i_value, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
+        i_value_list[list_index] = i_value
+
       if self.periodic_boundary:
-        dists = np.where(dists > value_sizes / 2, value_sizes - dists, dists)
-      exp_dists = np.exp(-(np.linalg.norm(dists, axis=0) / self.sigma) ** 2 / 2)
-      prob_mat.append(exp_dists)
-    prob_mat = np.stack(prob_mat)
+        prob_mat = gaussian_prob_dist_cal2(i_value_list, post_values, value_sizes, self.sigma)
+      else:
+        prob_mat = gaussian_prob_dist_cal1(i_value_list, post_values, self.sigma)
+    else:
+      prob_mat = []
+      for i in range(self.pre_num):
+        # values for node i
+        i_coordinate = tuple()
+        for s in self.pre_size[:-1]:
+          i, pos = divmod(i, s)
+          i_coordinate += (pos,)
+        i_coordinate += (i,)
+        i_value = np.array([values[i][c] for i, c in enumerate(i_coordinate)])
+        if i_value.ndim < post_values.ndim:
+          i_value = np.expand_dims(i_value, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
+        # distances
+        dists = np.abs(i_value - post_values)
+        if self.periodic_boundary:
+          dists = np.where(dists > value_sizes / 2, value_sizes - dists, dists)
+        exp_dists = np.exp(-(np.linalg.norm(dists, axis=0) / self.sigma) ** 2 / 2)
+        prob_mat.append(exp_dists)
+      prob_mat = np.stack(prob_mat)
+
     if self.normalize:
       prob_mat /= prob_mat.max()
 
     # connectivity
     conn_mat = np.asarray(prob_mat) >= self.rng.random(prob_mat.shape)
     if not self.include_self:
       np.fill_diagonal(conn_mat, False)
@@ -822,15 +859,15 @@
   References
   ----------
   .. [1] P. Holme and B. J. Kim,
          "Growing scale-free networks with tunable clustering",
          Phys. Rev. E, 65, 026107, 2002.
   """
 
-  def __init__(self, m, p, directed=False, seed=None, **kwargs):
+  def __init__(self, m: int, p: float, directed=False, seed=None, **kwargs):
     super(PowerLaw, self).__init__(**kwargs)
     self.m = m
     self.p = p
     if self.p > 1 or self.p < 0:
       raise ConnectorError(f"p must be in [0,1], while p={self.p}")
     self.directed = directed
     self.seed = format_seed(seed)
```

## brainpy/_src/dyn/__init__.py

```diff
@@ -1,22 +1 @@
-00000000: 2320 2d2a 2d20 636f 6469 6e67 3a20 7574  # -*- coding: ut
-00000010: 662d 3820 2d2a 2d0a 0a22 2222 0a4d 6f64  f-8 -*-..""".Mod
-00000020: 756c 6520 666f 7220 6272 6169 6e20 6479  ule for brain dy
-00000030: 6e61 6d69 6373 206d 6f64 656c 2062 7569  namics model bui
-00000040: 6c64 696e 672e 0a22 2222 0a0a 6672 6f6d  lding.."""..from
-00000050: 202e 2069 6d70 6f72 7420 280a 2020 6368   . import (.  ch
-00000060: 616e 6e65 6c73 2c20 6e65 7572 6f6e 732c  annels, neurons,
-00000070: 2072 6174 6573 2c20 2023 206e 6575 726f   rates,  # neuro
-00000080: 6e20 7265 6c61 7465 640a 2020 7379 6e61  n related.  syna
-00000090: 7073 6573 2c20 7379 6e6f 7574 732c 2073  pses, synouts, s
-000000a0: 796e 706c 6173 742c 2020 2320 7379 6e61  ynplast,  # syna
-000000b0: 7073 6520 7265 6c61 7465 640a 2020 6e65  pse related.  ne
-000000c0: 7477 6f72 6b73 2c0a 2020 7275 6e6e 6572  tworks,.  runner
-000000d0: 732c 0a20 2074 7261 6e73 666f 726d 2c0a  s,.  transform,.
-000000e0: 290a 6672 6f6d 202e 6e65 7572 6f6e 732e  ).from .neurons.
-000000f0: 636f 6d70 6174 2069 6d70 6f72 7420 2a0a  compat import *.
-00000100: 6672 6f6d 202e 7275 6e6e 6572 7320 696d  from .runners im
-00000110: 706f 7274 202a 0a66 726f 6d20 2e73 796e  port *.from .syn
-00000120: 6170 7365 732e 636f 6d70 6174 2069 6d70  apses.compat imp
-00000130: 6f72 7420 2a0a 6672 6f6d 202e 7472 616e  ort *.from .tran
-00000140: 7366 6f72 6d20 696d 706f 7274 202a 0a0a  sform import *..
-00000150: 0a0a                                     ..
+00000000: 0a                                       .
```

## brainpy/_src/dyn/channels/IH.py

```diff
@@ -216,16 +216,16 @@
   def dOL(self, OL, t, O, P1):
     return self.k3 * P1 * O - self.k4 * OL
 
   def dP1(self, P1, t, C_Ca):
     return self.k1 * C_Ca ** 4 * (1 - P1) - self.k2 * P1
 
   def update(self, tdi, V, C_Ca, E_Ca):
-    self.O.value = self.integral(self.O.value, self.OL.value, self.P1.value,
-                                 tdi['t'], V=V, C_Ca=C_Ca, dt=tdi['dt'])
+    self.O.value, self.OL.value, self.P1.value = self.integral(self.O.value, self.OL.value, self.P1.value,
+                                                               tdi['t'], V=V, C_Ca=C_Ca, dt=tdi['dt'])
 
   def current(self, V, C_Ca, E_Ca):
     return self.g_max * (self.O + self.g_inc * self.OL) * (self.E - V)
 
   def reset_state(self, V, C_Ca, E_Ca, batch_size=None):
     varshape = self.varshape if (batch_size is None) else ((batch_size,) + self.varshape)
     self.P1.value = bm.broadcast_to(self.k1 * C_Ca ** 4 / (self.k1 * C_Ca ** 4 + self.k2), varshape)
```

## brainpy/_src/dyn/channels/K.py

```diff
@@ -808,25 +808,25 @@
                                        E=E,
                                        mode=mode)
 
     # parameters
     self.V_sh = parameter(V_sh, self.varshape, allow_none=False)
 
   def f_p_inf(self, V):
-    raise 1. / (1. + bm.exp(-(V - self.V_sh + 43.) / 17.))
+    return 1. / (1. + bm.exp(-(V - self.V_sh + 43.) / 17.))
 
   def f_p_tau(self, V):
     return 1. / (bm.exp((V - self.V_sh - 81.) / 25.6) +
                  bm.exp(-(V - self.V_sh + 132) / 18.)) + 9.9
 
   def f_q_inf(self, V):
-    raise 1. / (1. + bm.exp((V - self.V_sh + 58.) / 10.6))
+    return 1. / (1. + bm.exp((V - self.V_sh + 58.) / 10.6))
 
   def f_q_tau(self, V):
-    raise 1. / (bm.exp((V - self.V_sh - 1329.) / 200.) +
+    return 1. / (bm.exp((V - self.V_sh - 1329.) / 200.) +
                 bm.exp(-(V - self.V_sh + 130.) / 7.1))
 
 
 class IKK2B_HM1992(_IKK2_pq_ss):
   r"""The slowly inactivating Potassium channel (IK2b) model proposed by (Huguenard & McCormick, 1992) [2]_.
 
   The dynamics of the model is given as [2]_ [3]_.
@@ -899,25 +899,25 @@
                                        E=E,
                                        mode=mode)
 
     # parameters
     self.V_sh = parameter(V_sh, self.varshape, allow_none=False)
 
   def f_p_inf(self, V):
-    raise 1. / (1. + bm.exp(-(V - self.V_sh + 43.) / 17.))
+    return 1. / (1. + bm.exp(-(V - self.V_sh + 43.) / 17.))
 
   def f_p_tau(self, V):
     return 1. / (bm.exp((V - self.V_sh - 81.) / 25.6) +
                  bm.exp(-(V - self.V_sh + 132) / 18.)) + 9.9
 
   def f_q_inf(self, V):
-    raise 1. / (1. + bm.exp((V - self.V_sh + 58.) / 10.6))
+    return 1. / (1. + bm.exp((V - self.V_sh + 58.) / 10.6))
 
   def f_q_tau(self, V):
-    raise bm.where(V < -70 + self.V_sh,
+    return bm.where(V < -70 + self.V_sh,
                    1. / (bm.exp((V - self.V_sh - 1329.) / 200.) +
                          bm.exp(-(V - self.V_sh + 130.) / 7.1)),
                    8.9)
 
 
 class IKNI_Ya1989(PotassiumChannel):
   r"""A slow non-inactivating K+ current described by Yamada et al. (1989) [1]_.
@@ -1006,12 +1006,12 @@
 
   def reset_state(self, V, batch_size=None):
     self.p.value = self.f_p_inf(V)
     if batch_size is not None:
       assert self.p.shape[0] == batch_size
 
   def f_p_inf(self, V):
-    raise 1. / (1. + bm.exp(-(V - self.V_sh + 35.) / 10.))
+    return 1. / (1. + bm.exp(-(V - self.V_sh + 35.) / 10.))
 
   def f_p_tau(self, V):
     temp = V - self.V_sh + 35.
-    raise self.tau_max / (3.3 * bm.exp(temp / 20.) + bm.exp(-temp / 20.))
+    return self.tau_max / (3.3 * bm.exp(temp / 20.) + bm.exp(-temp / 20.))
```

## brainpy/_src/dyn/neurons/__init__.py

```diff
@@ -1,7 +1,3 @@
-# -*- coding: utf-8 -*-
+from .lif import *
+
 
-from .biological_models import *
-from .fractional_models import *
-from .reduced_models import *
-from .input_groups import *
-from .noise_groups import *
```

## brainpy/_src/dyn/synapses/__init__.py

```diff
@@ -1,14 +0,0 @@
-00000000: 2320 2d2a 2d20 636f 6469 6e67 3a20 7574  # -*- coding: ut
-00000010: 662d 3820 2d2a 2d0a 0a66 726f 6d20 2e61  f-8 -*-..from .a
-00000020: 6273 7472 6163 745f 6d6f 6465 6c73 2069  bstract_models i
-00000030: 6d70 6f72 7420 2a0a 6672 6f6d 202e 6269  mport *.from .bi
-00000040: 6f6c 6f67 6963 616c 5f6d 6f64 656c 7320  ological_models 
-00000050: 696d 706f 7274 202a 0a66 726f 6d20 2e6c  import *.from .l
-00000060: 6561 726e 696e 675f 7275 6c65 7320 696d  earning_rules im
-00000070: 706f 7274 202a 0a66 726f 6d20 2e67 6170  port *.from .gap
-00000080: 5f6a 756e 6374 696f 6e20 696d 706f 7274  _junction import
-00000090: 202a 0a66 726f 6d20 2e64 656c 6179 5f63   *.from .delay_c
-000000a0: 6f75 706c 696e 6773 2069 6d70 6f72 7420  ouplings import 
-000000b0: 2a0a 0a23 2063 6f6d 7061 7469 626c 6520  *..# compatible 
-000000c0: 696e 7465 7266 6163 650a 6672 6f6d 202e  interface.from .
-000000d0: 2069 6d70 6f72 7420 636f 6d70 6174 0a     import compat.
```

## brainpy/_src/encoding/stateless_encoding.py

```diff
@@ -29,21 +29,19 @@
     The maximum value in the given data `x`, used to the data normalization.
   seed: int, ArrayType
     The seed or key for random generation.
   """
 
   def __init__(self,
                min_val: Optional[float] = None,
-               max_val: Optional[float] = None,
-               seed: Union[int, ArrayType] = None):
+               max_val: Optional[float] = None):
     super().__init__()
 
     self.min_val = check.is_float(min_val, 'min_val', allow_none=True)
     self.max_val = check.is_float(max_val, 'max_val', allow_none=True)
-    self.rng = bm.random.default_rng(seed)
 
   def __call__(self, x: ArrayType, num_step: int = None):
     """
 
     Parameters
     ----------
     x: ArrayType
@@ -62,9 +60,9 @@
       The encoded spike train.
     """
     with jax.ensure_compile_time_eval():
       check.is_integer(num_step, 'time_len', min_bound=1, allow_none=True)
     if not (self.min_val is None or self.max_val is None):
       x = (x - self.min_val) / (self.max_val - self.min_val)
     shape = x.shape if (num_step is None) else ((num_step,) + x.shape)
-    d = bm.as_jax(self.rng.rand(*shape)) < x
+    d = bm.as_jax(bm.random.rand(*shape)) < x
     return d.astype(x.dtype)
```

## brainpy/_src/initialize/decay_inits.py

```diff
@@ -1,22 +1,40 @@
 # -*- coding: utf-8 -*-
-
 import numpy as np
 
+from jax import vmap, jit, numpy as jnp
+from functools import partial
+
 from brainpy import math as bm
 from brainpy.tools import to_size, size2num
 from .base import _IntraLayerInitializer
 
-
 __all__ = [
   'GaussianDecay',
   'DOGDecay',
 ]
 
 
+@jit
+@partial(vmap, in_axes=(0, None, None))
+def gaussian_decay_dist_cal1(i_value, post_values, sigma):
+  dists = jnp.abs(i_value - post_values)
+  exp_dists = jnp.exp(-(jnp.sqrt(jnp.sum(dists ** 2, axis=0)) / sigma) ** 2 / 2)
+  return bm.asarray(exp_dists)
+
+
+@jit
+@partial(vmap, in_axes=(0, None, None, None))
+def gaussian_decay_dist_cal2(i_value, post_values, value_sizes, sigma):
+  dists = jnp.abs(i_value - post_values)
+  dists = jnp.where(dists > (value_sizes / 2), value_sizes - dists, dists)
+  exp_dists = jnp.exp(-(jnp.sqrt(jnp.sum(dists ** 2, axis=0)) / sigma) ** 2 / 2)
+  return bm.asarray(exp_dists)
+
+
 class GaussianDecay(_IntraLayerInitializer):
   r"""Builds a Gaussian connectivity pattern within a population of neurons,
   where the weights decay with gaussian function.
 
   Specifically, for any pair of neurons :math:`(i, j)`, the weight is computed as
 
   .. math::
@@ -102,51 +120,93 @@
     values = [np.linspace(vs[0], vs[1], n + 1)[:n] for vs, n in zip(value_ranges, shape)]
     post_values = np.stack([v.flatten() for v in np.meshgrid(*values)])
     value_sizes = np.array([v[1] - v[0] for v in value_ranges])
     if value_sizes.ndim < post_values.ndim:
       value_sizes = np.expand_dims(value_sizes, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
 
     # connectivity matrix
-    conn_mat = []
+    i_value_list = np.zeros(shape=(net_size, len(shape), 1))
     for i in range(net_size):
+      list_index = i
       # values for node i
       i_coordinate = tuple()
       for s in shape[:-1]:
         i, pos = divmod(i, s)
         i_coordinate += (pos,)
       i_coordinate += (i,)
       i_value = np.array([values[i][c] for i, c in enumerate(i_coordinate)])
       if i_value.ndim < post_values.ndim:
         i_value = np.expand_dims(i_value, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
-      # distances
-      dists = np.abs(i_value - post_values)
-      if self.periodic_boundary:
-        dists = np.where(dists > value_sizes / 2, value_sizes - dists, dists)
-      exp_dists = np.exp(-(np.linalg.norm(dists, axis=0) / self.sigma) ** 2 / 2)
-      conn_mat.append(exp_dists)
-    conn_mat = np.stack(conn_mat)
+      i_value_list[list_index] = i_value
+
+    if self.periodic_boundary:
+      conn_mat = gaussian_decay_dist_cal2(i_value_list, post_values, value_sizes, self.sigma)
+    else:
+      conn_mat = gaussian_decay_dist_cal1(i_value_list, post_values, self.sigma)
+
     if self.normalize:
       conn_mat /= conn_mat.max()
     if not self.include_self:
-      np.fill_diagonal(conn_mat, 0.)
+      bm.fill_diagonal(conn_mat, 0.)
 
     # connectivity weights
-    conn_weights = conn_mat * self.max_w
-    conn_weights = np.where(conn_weights < self.min_w, 0., conn_weights)
-    return bm.asarray(conn_weights, dtype=dtype)
+    conn_mat *= self.max_w
+    conn_mat = bm.where(conn_mat < self.min_w, 0., conn_mat)
+    return bm.asarray(conn_mat, dtype=dtype)
 
   def __repr__(self):
     name = self.__class__.__name__
     bank = ' ' * len(name)
     return (f'{name}(sigma={self.sigma}, max_w={self.max_w}, min_w={self.min_w}, \n'
             f'{bank}periodic_boundary={self.periodic_boundary}, '
             f'include_self={self.include_self}, '
             f'normalize={self.normalize})')
 
 
+@jit
+@partial(vmap, in_axes=(0, None, None, None, None, None, None, None))
+def _dog_decay_pd(voxel_ids,
+                  values, post_values, value_sizes,
+                  max_w_p, sigma_p,
+                  max_w_n, sigma_n):
+  i_value = []
+  for i in range(len(voxel_ids)):
+    p_id = voxel_ids[i]  # position id
+    i_value.append(values[i][p_id])
+  i_value = bm.array(i_value)
+  if i_value.ndim < post_values.ndim:
+    i_value = bm.expand_dims(i_value, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
+  # distances
+  dists = bm.abs(i_value - post_values)
+  dists = bm.where(dists > value_sizes / 2, value_sizes - dists, dists)
+  dists_exp_p = max_w_p * bm.exp(-(bm.linalg.norm(dists, axis=0) / sigma_p) ** 2 / 2)
+  dists_exp_n = max_w_n * bm.exp(-(bm.linalg.norm(dists, axis=0) / sigma_n) ** 2 / 2)
+  return dists_exp_p - dists_exp_n
+
+
+@jit
+@partial(vmap, in_axes=(0, None, None, None, None, None, None))
+def _dog_decay(voxel_ids,
+               values, post_values,
+               max_w_p, sigma_p,
+               max_w_n, sigma_n):
+  i_value = []
+  for i in range(len(voxel_ids)):
+    p_id = voxel_ids[i]  # position id
+    i_value.append(values[i][p_id])
+  i_value = bm.array(i_value)
+  if i_value.ndim < post_values.ndim:
+    i_value = bm.expand_dims(i_value, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
+  # distances
+  dists = bm.abs(i_value - post_values)
+  dists_exp_p = max_w_p * bm.exp(-(bm.linalg.norm(dists, axis=0) / sigma_p) ** 2 / 2)
+  dists_exp_n = max_w_n * bm.exp(-(bm.linalg.norm(dists, axis=0) / sigma_n) ** 2 / 2)
+  return dists_exp_p - dists_exp_n
+
+
 class DOGDecay(_IntraLayerInitializer):
   r"""Builds a Difference-Of-Gaussian (dog) connectivity pattern within a population of neurons.
 
   Mathematically, for the given pair of neurons :math:`(i, j)`, the weight between them is computed as
 
   .. math::
 
@@ -235,37 +295,28 @@
     if value_sizes.ndim < post_values.ndim:
       value_sizes = np.expand_dims(value_sizes, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
     voxel_ids = np.meshgrid(*[np.arange(s) for s in shape])
     if np.ndim(voxel_ids[0]) > 1:
       voxel_ids = tuple(np.moveaxis(m, 0, 1).flatten() for m in voxel_ids)
 
     # connectivity matrix
-    ndim = len(voxel_ids)
-    conn_weights = []
-    for v_id in range(voxel_ids[0].shape[0]):
-      i_value = []
-      for i in range(ndim):
-        p_id = voxel_ids[i][v_id]  # position id
-        i_value.append(values[i][p_id])
-      i_value = np.array(i_value)
-      if i_value.ndim < post_values.ndim:
-        i_value = np.expand_dims(i_value, axis=tuple([i + 1 for i in range(post_values.ndim - 1)]))
-      # distances
-      dists = np.abs(i_value - post_values)
-      if self.periodic_boundary:
-        dists = np.where(dists > value_sizes / 2, value_sizes - dists, dists)
-      dists_exp_p = self.max_w_p * np.exp(-(np.linalg.norm(dists, axis=0) / self.sigma_p) ** 2 / 2)
-      dists_exp_n = self.max_w_n * np.exp(-(np.linalg.norm(dists, axis=0) / self.sigma_n) ** 2 / 2)
-      conn_weights.append(dists_exp_p - dists_exp_n)
-    conn_weights = np.stack(conn_weights)
+    if self.periodic_boundary:
+      conn_weights = _dog_decay_pd(voxel_ids, values, post_values, value_sizes,
+                                   self.max_w_p, self.sigma_p,
+                                   self.max_w_n, self.sigma_n)
+    else:
+      conn_weights = _dog_decay(voxel_ids, values, post_values,
+                                self.max_w_p, self.sigma_p,
+                                self.max_w_n, self.sigma_n)
     if not self.include_self:
-      np.fill_diagonal(conn_weights, 0.)
+      conn_weights = bm.asarray(conn_weights)
+      bm.fill_diagonal(conn_weights, 0.)
 
     # connectivity weights
-    conn_weights = np.where(np.abs(conn_weights) < self.min_w, 0., conn_weights)
+    conn_weights = bm.where(np.abs(conn_weights) < self.min_w, 0., conn_weights)
     return bm.asarray(conn_weights, dtype=dtype)
 
   def __repr__(self):
     name = self.__class__.__name__
     bank = ' ' * len(name)
     return (f'{name}(sigmas={(self.sigma_p, self.sigma_n)}, '
             f'max_ws={(self.max_w_p, self.max_w_n)}, min_w={self.min_w}, \n'
```

## brainpy/_src/initialize/generic.py

```diff
@@ -1,53 +1,62 @@
 # -*- coding: utf-8 -*-
 
-from typing import Union, Callable, Optional
+from typing import Union, Callable, Optional, Sequence
 
+import jax
 import jax.numpy as jnp
 import numpy as np
 
 import brainpy.math as bm
 from brainpy.tools import to_size
-from brainpy.types import Shape, ArrayType
+from brainpy.types import Shape, ArrayType, Sharding
 from .base import Initializer
 
 __all__ = [
   'parameter',
   'variable',
   'variable_',
   'noise',
   'delay',
-
-  # deprecated
-  'init_param',
 ]
 
 
+def _check_none(x, allow_none: bool = False):
+  pass
+
+
+def _is_scalar(x):
+  return isinstance(x, (float, int, bool, complex))
+
+
 def parameter(
     param: Union[Callable, Initializer, bm.ndarray, np.ndarray, jnp.ndarray, float, int, bool],
-    size: Shape,
+    sizes: Shape,
     allow_none: bool = True,
     allow_scalar: bool = True,
+    sharding: Optional[Sharding] = None
 ):
   """Initialize parameters.
 
   Parameters
   ----------
   param: callable, Initializer, bm.ndarray, jnp.ndarray, onp.ndarray, float, int, bool
     The initialization of the parameter.
     - If it is None, the created parameter will be None.
     - If it is a callable function :math:`f`, the ``f(size)`` will be returned.
     - If it is an instance of :py:class:`brainpy.init.Initializer``, the ``f(size)`` will be returned.
     - If it is a tensor, then this function check whether ``tensor.shape`` is equal to the given ``size``.
-  size: int, sequence of int
+  sizes: int, sequence of int
     The shape of the parameter.
   allow_none: bool
     Whether allow the parameter is None.
   allow_scalar: bool
     Whether allow the parameter is a scalar value.
+  sharding: Sharding
+    The axes for automatic array sharding.
 
   Returns
   -------
   param: ArrayType, float, int, bool, None
     The initialized parameter.
 
   See Also
@@ -56,152 +65,170 @@
   """
   if param is None:
     if allow_none:
       return None
     else:
       raise ValueError(f'Expect a parameter with type of float, ArrayType, Initializer, or '
                        f'Callable function, but we got None. ')
-  size = to_size(size)
-  if allow_scalar and isinstance(param, (float, int, bool)):
+  sizes = to_size(sizes)
+  if allow_scalar and _is_scalar(param):
     return param
+
   if callable(param):
-    param = param(size)
+    param = param(sizes)  # TODO
+    # return bm.jit(param, static_argnums=0, out_shardings=bm.sharding.get_sharding(axis_names))(size)
+
   elif isinstance(param, (np.ndarray, jnp.ndarray)):
     param = bm.asarray(param)
   elif isinstance(param, bm.Variable):
     param = param
   elif isinstance(param, bm.Array):
     param = param
   else:
     raise ValueError(f'Unknown param type {type(param)}: {param}')
+
   if allow_scalar:
     if param.shape == () or param.shape == (1,):
       return param
-  if param.shape != size:
-    raise ValueError(f'The shape of the parameters should be {size}, but we got {param.shape}')
-  return param
-
-
-def init_param(
-    param: Union[Callable, Initializer, bm.ndarray, jnp.ndarray, float, int, bool],
-    size: Shape,
-    allow_none: bool = True,
-):
-  """Initialize parameters. Same as ``parameter()``.
-
-  .. deprecated:: 2.2.3.4
-     Will be removed since version 2.4.0.
-  """
-  return parameter(param, size, allow_none)
+  if param.shape != sizes:
+    raise ValueError(f'The shape of the parameters should be {sizes}, but we got {param.shape}')
+  return bm.sharding.partition(param, sharding)
 
 
 def variable_(
-    init: Union[Callable, ArrayType],
-    size: Shape = None,
-    batch_size_or_mode: Optional[Union[int, bool, bm.Mode]] = None,
+    init: Union[Callable, bm.Array, jax.Array],
+    sizes: Shape = None,
+    batch_or_mode: Optional[Union[int, bool, bm.Mode]] = None,
     batch_axis: int = 0,
+    axis_names: Optional[Sequence[str]] = None,
+    batch_axis_name: Optional[str] = None,
 ):
   """Initialize a :math:`~.Variable` from a callable function or a data.
 
   Parameters
   ----------
   init: callable, function, ArrayType
     The data to be initialized as a ``Variable``.
-  batch_size_or_mode: int, bool, Mode, optional
+  batch_or_mode: int, bool, Mode, optional
     The batch size, model ``Mode``, boolean state.
     This is used to specify the batch size of this variable.
     If it is a boolean or an instance of ``Mode``, the batch size will be 1.
     If it is None, the variable has no batch axis.
-  size: Shape
+  sizes: Shape
     The shape of the variable.
   batch_axis: int
     The batch axis.
+  axis_names: sequence of str
+    The name for each axis. These names should match the given ``axes``.
+  batch_axis_name: str
+    The name for the batch axis. The name will be used if ``batch_size_or_mode`` is given.
 
   Returns
   -------
   variable: bm.Variable
     The target ``Variable`` instance.
 
   See Also
   --------
   variable, parameter, noise, delay
 
   """
-  return variable(init, batch_size_or_mode, size, batch_axis)
+  return variable(init,
+                  batch_or_mode,
+                  sizes=sizes,
+                  batch_axis=batch_axis,
+                  axis_names=axis_names,
+                  batch_axis_name=batch_axis_name)
 
 
 def variable(
     init: Union[Callable, ArrayType],
-    batch_size_or_mode: Optional[Union[int, bool, bm.Mode]] = None,
-    size: Shape = None,
+    batch_or_mode: Optional[Union[int, bool, bm.Mode]] = None,
+    sizes: Shape = None,
     batch_axis: int = 0,
+    axis_names: Optional[Sequence[str]] = None,
+    batch_axis_name: Optional[str] = None,
 ):
   """Initialize variables.
 
   Parameters
   ----------
   init: callable, function, ArrayType
     The data to be initialized as a ``Variable``.
-  batch_size_or_mode: int, bool, Mode, optional
+  batch_or_mode: int, bool, Mode, optional
     The batch size, model ``Mode``, boolean state.
     This is used to specify the batch size of this variable.
     If it is a boolean or an instance of ``Mode``, the batch size will be 1.
     If it is None, the variable has no batch axis.
-  size: Shape
+  sizes: Shape
     The shape of the variable.
   batch_axis: int
     The batch axis.
+  axis_names: sequence of str
+    The name for each axis. These names should match the given ``axes``.
+  batch_axis_name: str
+    The name for the batch axis. The name will be used if ``batch_size_or_mode`` is given.
 
   Returns
   -------
   variable: bm.Variable
     The target ``Variable`` instance.
 
   See Also
   --------
   variable_, parameter, noise, delay
 
   """
-  size = to_size(size)
+
+  sizes = to_size(sizes)
+  if axis_names is not None:
+    axis_names = list(axis_names)
+    assert len(sizes) == len(axis_names)
+    if batch_or_mode is not None and not isinstance(batch_or_mode, bm.NonBatchingMode):
+      axis_names.insert(batch_axis, batch_axis_name)
+
   if callable(init):
-    if size is None:
+    if sizes is None:
       raise ValueError('"varshape" cannot be None when data is a callable function.')
-    if isinstance(batch_size_or_mode, bm.NonBatchingMode):
-      return bm.Variable(init(size))
-    elif isinstance(batch_size_or_mode, bm.BatchingMode):
-      new_shape = size[:batch_axis] + (batch_size_or_mode.batch_size,) + size[batch_axis:]
-      return bm.Variable(init(new_shape), batch_axis=batch_axis)
-    elif batch_size_or_mode in (None, False):
-      return bm.Variable(init(size))
-    elif isinstance(batch_size_or_mode, int):
-      new_shape = size[:batch_axis] + (int(batch_size_or_mode),) + size[batch_axis:]
-      return bm.Variable(init(new_shape), batch_axis=batch_axis)
+    if isinstance(batch_or_mode, bm.NonBatchingMode):
+      data = bm.Variable(init(sizes), axis_names=axis_names)
+    elif isinstance(batch_or_mode, bm.BatchingMode):
+      new_shape = sizes[:batch_axis] + (batch_or_mode.batch_size,) + sizes[batch_axis:]
+      data = bm.Variable(init(new_shape), batch_axis=batch_axis, axis_names=axis_names)
+    elif batch_or_mode in (None, False):
+      data = bm.Variable(init(sizes), axis_names=axis_names)
+    elif isinstance(batch_or_mode, int):
+      new_shape = sizes[:batch_axis] + (int(batch_or_mode),) + sizes[batch_axis:]
+      data = bm.Variable(init(new_shape), batch_axis=batch_axis, axis_names=axis_names)
     else:
-      raise ValueError(f'Unknown batch_size_or_mode: {batch_size_or_mode}')
+      raise ValueError(f'Unknown batch_size_or_mode: {batch_or_mode}')
 
   else:
-    if size is not None:
-      if bm.shape(init) != size:
-        raise ValueError(f'The shape of "data" {bm.shape(init)} does not match with "var_shape" {size}')
-    if isinstance(batch_size_or_mode, bm.NonBatchingMode):
-      return bm.Variable(init)
-    elif isinstance(batch_size_or_mode, bm.BatchingMode):
-      return bm.Variable(bm.repeat(bm.expand_dims(init, axis=batch_axis),
-                                   batch_size_or_mode.batch_size,
+    if sizes is not None:
+      if bm.shape(init) != sizes:
+        raise ValueError(f'The shape of "data" {bm.shape(init)} does not match with "var_shape" {sizes}')
+    if isinstance(batch_or_mode, bm.NonBatchingMode):
+      data = bm.Variable(init, axis_names=axis_names)
+    elif isinstance(batch_or_mode, bm.BatchingMode):
+      data = bm.Variable(bm.repeat(bm.expand_dims(init, axis=batch_axis),
+                                   batch_or_mode.batch_size,
                                    axis=batch_axis),
-                         batch_axis=batch_axis)
-    elif batch_size_or_mode in (None, False):
-      return bm.Variable(init)
-    elif isinstance(batch_size_or_mode, int):
-      return bm.Variable(bm.repeat(bm.expand_dims(init, axis=batch_axis),
-                                   int(batch_size_or_mode),
+                         batch_axis=batch_axis,
+                         axis_names=axis_names)
+    elif batch_or_mode in (None, False):
+      data = bm.Variable(init, axis_names=axis_names)
+    elif isinstance(batch_or_mode, int):
+      data = bm.Variable(bm.repeat(bm.expand_dims(init, axis=batch_axis),
+                                   int(batch_or_mode),
                                    axis=batch_axis),
-                         batch_axis=batch_axis)
+                         batch_axis=batch_axis,
+                         axis_names=axis_names)
     else:
       raise ValueError('Unknown batch_size_or_mode.')
+  return bm.sharding.partition_by_axname(data, axis_names)
 
 
 def noise(
     noises: Optional[Union[int, float, bm.ndarray, jnp.ndarray, Initializer, Callable]],
     size: Shape,
     num_vars: int = 1,
     noise_idx: int = 0,
```

## brainpy/_src/inputs/currents.py

```diff
@@ -256,15 +256,15 @@
     The end time.
   seed: int
     The noise seed.
   """
   dt = bm.get_dt() if dt is None else dt
   is_float(dt, 'dt', allow_none=False, min_bound=0.)
   is_integer(n, 'n', allow_none=False, min_bound=0)
-  rng = bm.random.default_rng(seed)
+  rng = bm.random.default_rng(seed, clone=False)
   t_end = duration if t_end is None else t_end
   i_start = int(t_start / dt)
   i_end = int(t_end / dt)
   noises = rng.standard_normal((i_end - i_start, n)) * jnp.sqrt(dt)
   currents = bm.zeros((int(duration / dt), n))
   currents[i_start: i_end] = noises
   return currents
@@ -298,15 +298,15 @@
   seed: optional, int
     The random seed.
   """
   dt = bm.get_dt() if dt is None else dt
   dt_sqrt = jnp.sqrt(dt)
   is_float(dt, 'dt', allow_none=False, min_bound=0.)
   is_integer(n, 'n', allow_none=False, min_bound=0)
-  rng = bm.random.default_rng(seed)
+  rng = bm.random.default_rng(seed, clone=False)
   x = bm.Variable(jnp.ones(n) * mean)
 
   def _f(t):
     x.value = x + dt * ((mean - x) / tau) + sigma * dt_sqrt * rng.rand(n)
     return x.value
 
   noises = bm.for_loop(_f, jnp.arange(t_start, t_end, dt))
```

## brainpy/_src/integrators/fde/Caputo.py

```diff
@@ -159,15 +159,15 @@
 
   def _integral_func(self, *args, **kwargs):
     # format arguments
     all_args = format_args(args, kwargs, self.arg_names)
     t = all_args['t']
     dt = all_args.pop(DT, self.dt)
     if check.is_checking():
-      check.jit_error_checking(self.num_memory * dt < t, self._check_step, (dt, t))
+      check.jit_error(self.num_memory * dt < t, self._check_step, (dt, t))
 
     # derivative values
     devs = self.f(**all_args)
     if len(self.variables) == 1:
       if not isinstance(devs, (bm.ndarray, jax.Array)):
         raise ValueError('Derivative values must be a tensor when there '
                          'is only one variable in the equation.')
@@ -380,15 +380,15 @@
 
   def _integral_func(self, *args, **kwargs):
     # format arguments
     all_args = format_args(args, kwargs, self.arg_names)
     t = all_args['t']
     dt = all_args.pop(DT, self.dt)
     if check.is_checking():
-      check.jit_error_checking(self.num_memory * dt < t, self._check_step, (dt, t))
+      check.jit_error(self.num_memory * dt < t, self._check_step, (dt, t))
 
     # derivative values
     devs = self.f(**all_args)
     if len(self.variables) == 1:
       if not isinstance(devs, (bm.Array, jax.Array)):
         raise ValueError('Derivative values must be a tensor when there '
                          'is only one variable in the equation.')
```

## brainpy/_src/integrators/ode/exponential.py

```diff
@@ -134,15 +134,15 @@
 
   .. plot::
     :include-source: True
 
     >>> import brainpy as bp
     >>> import brainpy.math as bm
     >>>
-    >>> class HH(bp.dyn.NeuGroup):
+    >>> class HH(bp.NeuGroup):
     >>>   def __init__(self, size, ENa=55., EK=-90., EL=-65, C=1.0, gNa=35., gK=9.,
     >>>                gL=0.1, V_th=20., phi=5.0, name=None):
     >>>     super(HH, self).__init__(size=size, name=name)
     >>>
     >>>     # parameters
     >>>     self.ENa = ENa
     >>>     self.EK = EK
@@ -207,15 +207,15 @@
 
   .. plot::
     :include-source: True
 
     >>> import brainpy as bp
     >>> import brainpy.math as bm
     >>>
-    >>> class HH(bp.dyn.NeuGroup):
+    >>> class HH(bp.NeuGroup):
     >>>   def __init__(self, size, ENa=55., EK=-90., EL=-65, C=1.0, gNa=35., gK=9.,
     >>>                gL=0.1, V_th=20., phi=5.0, name=None):
     >>>     super(HH, self).__init__(size=size, name=name)
     >>>
     >>>     # parameters
     >>>     self.ENa = ENa
     >>>     self.EK = EK
```

## brainpy/_src/integrators/sde/base.py

```diff
@@ -71,15 +71,15 @@
                                    f'Process types: {constants.SUPPORTED_WIENER_TYPE}. '
                                    f'But we got {wiener_type}.')
     self.var_type = var_type  # variable type
     self.intg_type = intg_type  # integral type
     self.wiener_type = wiener_type  # wiener process type
 
     # random seed
-    self.rng = bm.random.default_rng()
+    self.rng = bm.random.default_rng(clone=False)
 
     # code scope
     self.code_scope = {constants.F: f, constants.G: g, 'math': jnp, 'random': self.rng}
     # code lines
     self.func_name = f_names(f)
     self.code_lines = [f'def {self.func_name}({", ".join(self.arguments)}):']
     # others
```

## brainpy/_src/losses/__init__.py

```diff
@@ -5,9 +5,7 @@
 """
 
 # - https://github.com/deepmind/optax/blob/master/optax/_src/loss.py
 # - https://github.com/google/jaxopt/blob/main/jaxopt/_src/loss.py
 
 from .comparison import *
 from .regularization import *
-
-
```

## brainpy/_src/losses/comparison.py

```diff
@@ -1,48 +1,196 @@
 # -*- coding: utf-8 -*-
 
 """
 This module implements several loss functions.
 """
 
-# - https://github.com/deepmind/optax/blob/master/optax/_src/loss.py
-# - https://github.com/google/jaxopt/blob/main/jaxopt/_src/loss.py
-
-
-from typing import Tuple
+from typing import Tuple, Optional
 
 import jax.numpy as jnp
 from jax.lax import scan
 from jax.scipy.special import logsumexp
 from jax.tree_util import tree_map
 
 import brainpy.math as bm
 from brainpy.types import ArrayType
+from .base import Loss, WeightedLoss
 from .utils import _reduce, _multi_return, _is_leaf
 
 __all__ = [
-  'cross_entropy_loss',
+  'CrossEntropyLoss', 'cross_entropy_loss',
+
   'cross_entropy_sparse',
   'cross_entropy_sigmoid',
-  'l1_loos',
+
+  'NLLLoss', 'nll_loss',
+  'L1Loss', 'l1_loss',
+
   'l2_loss',
   'huber_loss',
-  'mean_absolute_error',
-  'mean_squared_error',
+
+  'MAELoss', 'mean_absolute_error',
+  'MSELoss', 'mean_squared_error',
+
   'mean_squared_log_error',
   'binary_logistic_loss',
   'multiclass_logistic_loss',
   'sigmoid_binary_cross_entropy',
   'softmax_cross_entropy',
   'log_cosh_loss',
   'ctc_loss_with_forward_probs',
   'ctc_loss',
 ]
 
 
+class CrossEntropyLoss(WeightedLoss):
+  r"""This criterion computes the cross entropy loss between input logits
+  and target.
+
+  It is useful when training a classification problem with `C` classes.
+  If provided, the optional argument :attr:`weight` should be a 1D `Tensor`
+  assigning weight to each of the classes.
+  This is particularly useful when you have an unbalanced training set.
+
+  The `input` is expected to contain the unnormalized logits for each class (which do `not` need
+  to be positive or sum to 1, in general).
+  `input` has to be a Tensor of size :math:`(C)` for unbatched input,
+  :math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1` for the
+  `K`-dimensional case. The last being useful for higher dimension inputs, such
+  as computing cross entropy loss per-pixel for 2D images.
+
+  The `target` that this criterion expects should contain either:
+
+  - Class indices in the range :math:`[0, C)` where :math:`C` is the number of classes; if
+    `ignore_index` is specified, this loss also accepts this class index (this index
+    may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`
+    set to ``'none'``) loss for this case can be described as:
+
+    .. math::
+        \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
+        l_n = - w_{y_n} \log \frac{\exp(x_{n,y_n})}{\sum_{c=1}^C \exp(x_{n,c})}
+        \cdot \mathbb{1}\{y_n \not= \text{ignore\_index}\}
+
+    where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,
+    :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as
+    :math:`d_1, ..., d_k` for the `K`-dimensional case. If
+    :attr:`reduction` is not ``'none'`` (default ``'mean'``), then
+
+    .. math::
+        \ell(x, y) = \begin{cases}
+            \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n} \cdot \mathbb{1}\{y_n \not= \text{ignore\_index}\}} l_n, &
+             \text{if reduction} = \text{`mean';}\\
+              \sum_{n=1}^N l_n,  &
+              \text{if reduction} = \text{`sum'.}
+          \end{cases}
+
+    Note that this case is equivalent to the combination of :class:`~torch.nn.LogSoftmax` and
+    :class:`~torch.nn.NLLLoss`.
+
+  - Probabilities for each class; useful when labels beyond a single class per minibatch item
+    are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with
+    :attr:`reduction` set to ``'none'``) loss for this case can be described as:
+
+    .. math::
+        \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
+        l_n = - \sum_{c=1}^C w_c \log \frac{\exp(x_{n,c})}{\sum_{i=1}^C \exp(x_{n,i})} y_{n,c}
+
+    where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,
+    :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as
+    :math:`d_1, ..., d_k` for the `K`-dimensional case. If
+    :attr:`reduction` is not ``'none'`` (default ``'mean'``), then
+
+    .. math::
+        \ell(x, y) = \begin{cases}
+            \frac{\sum_{n=1}^N l_n}{N}, &
+             \text{if reduction} = \text{`mean';}\\
+              \sum_{n=1}^N l_n,  &
+              \text{if reduction} = \text{`sum'.}
+          \end{cases}
+
+  .. note::
+      The performance of this criterion is generally better when `target` contains class
+      indices, as this allows for optimized computation. Consider providing `target` as
+      class probabilities only when a single class label per minibatch item is too restrictive.
+
+  Args:
+      weight (Tensor, optional): a manual rescaling weight given to each class.
+          If given, has to be a Tensor of size `C`
+      size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
+          the losses are averaged over each loss element in the batch. Note that for
+          some losses, there are multiple elements per sample. If the field :attr:`size_average`
+          is set to ``False``, the losses are instead summed for each minibatch. Ignored
+          when :attr:`reduce` is ``False``. Default: ``True``
+      ignore_index (int, optional): Specifies a target value that is ignored
+          and does not contribute to the input gradient. When :attr:`size_average` is
+          ``True``, the loss is averaged over non-ignored targets. Note that
+          :attr:`ignore_index` is only applicable when the target contains class indices.
+      reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
+          losses are averaged or summed over observations for each minibatch depending
+          on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
+          batch element instead and ignores :attr:`size_average`. Default: ``True``
+      reduction (str, optional): Specifies the reduction to apply to the output:
+          ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will
+          be applied, ``'mean'``: the weighted mean of the output is taken,
+          ``'sum'``: the output will be summed. Note: :attr:`size_average`
+          and :attr:`reduce` are in the process of being deprecated, and in
+          the meantime, specifying either of those two args will override
+          :attr:`reduction`. Default: ``'mean'``
+      label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount
+          of smoothing when computing the loss, where 0.0 means no smoothing. The targets
+          become a mixture of the original ground truth and a uniform distribution as described in
+          `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.
+
+  Shape:
+      - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
+        in the case of `K`-dimensional loss.
+      - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with
+        :math:`K \geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.
+        If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.
+      - Output: If reduction is 'none', shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
+        in the case of K-dimensional loss, depending on the shape of the input. Otherwise, scalar.
+
+
+      where:
+
+      .. math::
+          \begin{aligned}
+              C ={} & \text{number of classes} \\
+              N ={} & \text{batch size} \\
+          \end{aligned}
+
+  Examples::
+
+      >>> # Example of target with class indices
+      >>> loss = nn.CrossEntropyLoss()
+      >>> input = torch.randn(3, 5, requires_grad=True)
+      >>> target = torch.empty(3, dtype=torch.long).random_(5)
+      >>> output = loss(input, target)
+      >>> output.backward()
+      >>>
+      >>> # Example of target with class probabilities
+      >>> input = torch.randn(3, 5, requires_grad=True)
+      >>> target = torch.randn(3, 5).softmax(dim=1)
+      >>> output = loss(input, target)
+      >>> output.backward()
+  """
+  __constants__ = ['ignore_index', 'reduction', 'label_smoothing']
+  ignore_index: int
+  label_smoothing: float
+
+  def __init__(self, weight: Optional[ArrayType] = None, ignore_index: int = -100,
+               reduction: str = 'mean', label_smoothing: float = 0.0) -> None:
+    super().__init__(weight, reduction)
+    self.ignore_index = ignore_index
+    self.label_smoothing = label_smoothing
+
+  def update(self, input: ArrayType, target: ArrayType) -> ArrayType:
+    return cross_entropy_loss(input, target, weight=self.weight, reduction=self.reduction)
+
+
 def cross_entropy_loss(predicts, targets, weight=None, reduction='mean'):
   r"""This criterion combines ``LogSoftmax`` and `NLLLoss`` in one single class.
 
   It is useful when training a classification problem with `C` classes.
   If provided, the optional argument :attr:`weight` should be a 1D `Array`
   assigning weight to each of the classes. This is particularly useful when
   you have an unbalanced training set.
@@ -92,14 +240,15 @@
   Returns
   -------
   output : scalar, ArrayType
     If :attr:`reduction` is ``'none'``, then the same size as the target:
     :math:`(N)`, or  :math:`(d_1, d_2, ..., d_K, N)` with :math:`K \geq 1`
     in the case of K-dimensional loss.
   """
+
   def _cel(_pred, _tar):
     if bm.ndim(_tar) + 1 == bm.ndim(_pred):
       _tar = bm.one_hot(_tar, _pred.shape[-1])
     loss = logsumexp(bm.as_jax(_pred), axis=-1) - (_pred * _tar).sum(axis=-1)
     if weight is not None:
       loss *= weight
     return _reduce(outputs=loss, reduction=reduction)
@@ -147,15 +296,231 @@
     predicts,
     targets,
     is_leaf=_is_leaf
   )
   return _multi_return(r)
 
 
-def l1_loos(logits, targets, reduction='sum'):
+class NLLLoss(Loss):
+  r"""The negative log likelihood loss.
+
+  The negative log likelihood loss. It is useful to train a classification
+  problem with `C` classes.
+
+  If provided, the optional argument :attr:`weight` should be a 1D Tensor assigning
+  weight to each of the classes. This is particularly useful when you have an
+  unbalanced training set.
+
+  The `input` given through a forward call is expected to contain
+  log-probabilities of each class. `input` has to be a Tensor of size either
+  :math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)`
+  with :math:`K \geq 1` for the `K`-dimensional case. The latter is useful for
+  higher dimension inputs, such as computing NLL loss per-pixel for 2D images.
+
+  Obtaining log-probabilities in a neural network is easily achieved by
+  adding a  `LogSoftmax`  layer in the last layer of your network.
+  You may use `CrossEntropyLoss` instead, if you prefer not to add an extra
+  layer.
+
+  The `target` that this loss expects should be a class index in the range :math:`[0, C-1]`
+  where `C = number of classes`; if `ignore_index` is specified, this loss also accepts
+  this class index (this index may not necessarily be in the class range).
+
+  The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:
+
+  .. math::
+      \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
+      l_n = - w_{y_n} x_{n,y_n}, \quad
+      w_{c} = \text{weight}[c] \cdot \mathbb{1}\{c \not= \text{ignore\_index}\},
+
+  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight, and
+  :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
+  (default ``'mean'``), then
+
+  .. math::
+      \ell(x, y) = \begin{cases}
+          \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n}} l_n, &
+          \text{if reduction} = \text{`mean';}\\
+          \sum_{n=1}^N l_n,  &
+          \text{if reduction} = \text{`sum'.}
+      \end{cases}
+
+  Args:
+      reduction (str, optional): Specifies the reduction to apply to the output:
+          ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will
+          be applied, ``'mean'``: the weighted mean of the output is taken,
+          ``'sum'``: the output will be summed. Note: :attr:`size_average`
+          and :attr:`reduce` are in the process of being deprecated, and in
+          the meantime, specifying either of those two args will override
+          :attr:`reduction`. Default: ``'mean'``
+
+  Shape:
+      - Input: :math:`(N, C)` or :math:`(C)`, where `C = number of classes`, or
+        :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
+        in the case of `K`-dimensional loss.
+      - Target: :math:`(N)` or :math:`()`, where each value is
+        :math:`0 \leq \text{targets}[i] \leq C-1`, or
+        :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of
+        K-dimensional loss.
+      - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or
+        :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of K-dimensional loss.
+        Otherwise, scalar.
+
+  """
+
+  def __init__(self, reduction: str = 'mean'):
+    super().__init__(reduction=reduction)
+
+  def update(self, input, target):
+    return nll_loss(input, target, reduction=self.reduction)
+
+
+def nll_loss(input, target, reduction: str = 'mean'):
+  r"""The negative log likelihood loss.
+
+  The negative log likelihood loss. It is useful to train a classification
+  problem with `C` classes.
+
+  If provided, the optional argument :attr:`weight` should be a 1D Tensor assigning
+  weight to each of the classes. This is particularly useful when you have an
+  unbalanced training set.
+
+  The `input` given through a forward call is expected to contain
+  log-probabilities of each class. `input` has to be a Tensor of size either
+  :math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)`
+  with :math:`K \geq 1` for the `K`-dimensional case. The latter is useful for
+  higher dimension inputs, such as computing NLL loss per-pixel for 2D images.
+
+  Obtaining log-probabilities in a neural network is easily achieved by
+  adding a  `LogSoftmax`  layer in the last layer of your network.
+  You may use `CrossEntropyLoss` instead, if you prefer not to add an extra
+  layer.
+
+  The `target` that this loss expects should be a class index in the range :math:`[0, C-1]`
+  where `C = number of classes`; if `ignore_index` is specified, this loss also accepts
+  this class index (this index may not necessarily be in the class range).
+
+  The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:
+
+  .. math::
+      \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
+      l_n = - w_{y_n} x_{n,y_n}, \quad
+      w_{c} = \text{weight}[c] \cdot \mathbb{1}\{c \not= \text{ignore\_index}\},
+
+  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight, and
+  :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
+  (default ``'mean'``), then
+
+  .. math::
+      \ell(x, y) = \begin{cases}
+          \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n}} l_n, &
+          \text{if reduction} = \text{`mean';}\\
+          \sum_{n=1}^N l_n,  &
+          \text{if reduction} = \text{`sum'.}
+      \end{cases}
+
+  Args:
+      reduction (str, optional): Specifies the reduction to apply to the output:
+          ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will
+          be applied, ``'mean'``: the weighted mean of the output is taken,
+          ``'sum'``: the output will be summed. Note: :attr:`size_average`
+          and :attr:`reduce` are in the process of being deprecated, and in
+          the meantime, specifying either of those two args will override
+          :attr:`reduction`. Default: ``'mean'``
+
+  Shape:
+      - Input: :math:`(N, C)` or :math:`(C)`, where `C = number of classes`, or
+        :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
+        in the case of `K`-dimensional loss.
+      - Target: :math:`(N)` or :math:`()`, where each value is
+        :math:`0 \leq \text{targets}[i] \leq C-1`, or
+        :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of
+        K-dimensional loss.
+      - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or
+        :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of K-dimensional loss.
+        Otherwise, scalar.
+
+  """
+  assert target.ndim + 1 == input.ndim
+  input = bm.as_jax(input)
+  target = bm.as_jax(target)
+  loss = input[jnp.arange(len(target)), target]
+  if reduction == 'mean':
+    return loss.mean()
+  elif reduction == 'sum':
+    return loss.sum()
+  elif reduction == 'none':
+    return loss
+  elif reduction is None:
+    return loss
+  else:
+    raise ValueError
+
+
+class L1Loss(Loss):
+  r"""Creates a criterion that measures the mean absolute error (MAE) between each element in
+  the input :math:`x` and target :math:`y`.
+
+  The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:
+
+  .. math::
+      \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
+      l_n = \left| x_n - y_n \right|,
+
+  where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
+  (default ``'mean'``), then:
+
+  .. math::
+      \ell(x, y) =
+      \begin{cases}
+          \operatorname{mean}(L), & \text{if reduction} = \text{`mean';}\\
+          \operatorname{sum}(L),  & \text{if reduction} = \text{`sum'.}
+      \end{cases}
+
+  :math:`x` and :math:`y` are tensors of arbitrary shapes with a total
+  of :math:`n` elements each.
+
+  The sum operation still operates over all the elements, and divides by :math:`n`.
+
+  The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.
+
+  Supports real-valued and complex-valued inputs.
+
+  Args:
+      reduction (str, optional): Specifies the reduction to apply to the output:
+          ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
+          ``'mean'``: the sum of the output will be divided by the number of
+          elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
+          and :attr:`reduce` are in the process of being deprecated, and in the meantime,
+          specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
+
+  Shape:
+      - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
+      - Target: :math:`(*)`, same shape as the input.
+      - Output: scalar. If :attr:`reduction` is ``'none'``, then
+        :math:`(*)`, same shape as the input.
+
+  Examples::
+
+      >>> loss = nn.L1Loss()
+      >>> input = bm.random.randn(3, 5)
+      >>> target = bm.random.randn(3, 5)
+      >>> output = loss(input, target)
+      >>> output.backward()
+  """
+  __constants__ = ['reduction']
+
+  def __init__(self, reduction: str = 'mean') -> None:
+    super().__init__(reduction=reduction)
+
+  def update(self, input: ArrayType, target: ArrayType) -> ArrayType:
+    return l1_loss(input, target, reduction=self.reduction)
+
+
+def l1_loss(logits, targets, reduction='sum'):
   r"""Creates a criterion that measures the mean absolute error (MAE) between each element in
   the logits :math:`x` and targets :math:`y`. It is useful in regression problems.
 
   The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:
 
   .. math::
       \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
@@ -233,14 +598,26 @@
   """
   r = tree_map(lambda pred, tar: 0.5 * (pred - tar) ** 2,
                predicts,
                targets)
   return _multi_return(r)
 
 
+
+class MAELoss(Loss):
+  def __init__(self, axis=None, reduction: str = 'mean'):
+    super().__init__(reduction=reduction)
+    self.axis = axis
+
+  def update(self, input, target):
+    return mean_absolute_error(input, target, self.axis, reduction=self.reduction)
+
+
+
+
 def mean_absolute_error(x, y, axis=None, reduction: str = 'mean'):
   r"""Computes the mean absolute error between x and y.
 
   Args:
       x: a tensor of shape (d0, .. dN-1).
       y: a tensor of shape (d0, .. dN-1).
       axis: a sequence of the dimensions to keep, use `None` to return a scalar value.
@@ -251,14 +628,70 @@
   r = tree_map(lambda a, b: _reduce(bm.abs(a - b), reduction=reduction, axis=axis),
                x,
                y,
                is_leaf=_is_leaf)
   return _multi_return(r)
 
 
+class MSELoss(Loss):
+  r"""Creates a criterion that measures the mean squared error (squared L2 norm) between
+  each element in the input :math:`x` and target :math:`y`.
+
+  The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:
+
+  .. math::
+      \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
+      l_n = \left( x_n - y_n \right)^2,
+
+  where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
+  (default ``'mean'``), then:
+
+  .. math::
+      \ell(x, y) =
+      \begin{cases}
+          \operatorname{mean}(L), &  \text{if reduction} = \text{`mean';}\\
+          \operatorname{sum}(L),  &  \text{if reduction} = \text{`sum'.}
+      \end{cases}
+
+  :math:`x` and :math:`y` are tensors of arbitrary shapes with a total
+  of :math:`n` elements each.
+
+  The mean operation still operates over all the elements, and divides by :math:`n`.
+
+  The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.
+
+  Args:
+      reduction (str, optional): Specifies the reduction to apply to the output:
+          ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
+          ``'mean'``: the sum of the output will be divided by the number of
+          elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
+          and :attr:`reduce` are in the process of being deprecated, and in the meantime,
+          specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
+
+  Shape:
+      - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
+      - Target: :math:`(*)`, same shape as the input.
+
+  Examples::
+
+      >>> loss = nn.MSELoss()
+      >>> input = torch.randn(3, 5, requires_grad=True)
+      >>> target = torch.randn(3, 5)
+      >>> output = loss(input, target)
+      >>> output.backward()
+  """
+  __constants__ = ['reduction']
+
+  def __init__(self, reduction: str = 'mean') -> None:
+    super().__init__(reduction=reduction)
+
+  def update(self, input: ArrayType, target: ArrayType) -> ArrayType:
+    return mean_squared_error(input, target, reduction=self.reduction)
+
+
 def mean_squared_error(predicts, targets, axis=None, reduction: str = 'mean'):
   r"""Computes the mean squared error between x and y.
 
   Args:
       predicts: a tensor of shape (d0, .. dN-1).
       targets: a tensor of shape (d0, .. dN-1).
       axis: a sequence of the dimensions to keep, use `None` to return a scalar value.
```

## brainpy/_src/losses/regularization.py

```diff
@@ -2,15 +2,14 @@
 
 from jax.tree_util import tree_flatten, tree_map
 
 import jax.numpy as jnp
 import brainpy.math as bm
 from .utils import _is_leaf, _multi_return
 
-
 __all__ = [
   'l2_norm',
   'mean_absolute',
   'mean_square',
   'log_cosh',
   'smooth_labels',
 ]
@@ -74,8 +73,7 @@
       probability `(1-alpha) + alpha / num_categories`
   Returns:
     a smoothed version of the one hot input labels.
   """
   r = tree_map(lambda tar: (1.0 - alpha) * tar + alpha / tar.shape[-1],
                labels, is_leaf=lambda x: isinstance(x, bm.Array))
   return _multi_return(r)
-
```

## brainpy/_src/math/activations.py

```diff
@@ -15,36 +15,44 @@
 
 import jax
 import jax.numpy as jnp
 import jax.scipy
 import numpy as np
 
 from .ndarray import Array
+from .random import uniform
 
 __all__ = [
   'celu',
   'elu',
   'gelu',
   'glu',
+  'prelu',
   'hard_tanh',
   'hard_sigmoid',
+  'tanh_shrink',
   'hard_silu',
   'hard_swish',
+  'hard_shrink',
   'leaky_relu',
   'log_sigmoid',
   'log_softmax',
   'one_hot',
   'normalize',
   'relu',
   'relu6',
+  'rrelu',
   'sigmoid',
   'soft_sign',
   'softmax',
+  'softmin',
   'softplus',
+  'soft_shrink',
   'silu',
+  'mish',
   'swish',
   'selu',
   'identity',
 ]
 
 
 def get(activation):
@@ -167,15 +175,15 @@
   size = x.shape[axis]
   assert size % 2 == 0, "axis size must be divisible by 2"
   x = x.value if isinstance(x, Array) else x
   x1, x2 = jnp.split(x, 2, axis)
   return x1 * sigmoid(x2)
 
 
-def hard_tanh(x):
+def hard_tanh(x, min_val=- 1.0, max_val=1.0):
   r"""Hard :math:`\mathrm{tanh}` activation function.
 
   Computes the element-wise function:
 
   .. math::
     \mathrm{hard\_tanh}(x) = \begin{cases}
       -1, & x < -1\\
@@ -183,17 +191,21 @@
       1, & 1 < x
     \end{cases}
 
   Parameters
   ----------
   x: ArrayType
     The input array.
+  min_val: float
+    minimum value of the linear region range. Default: -1
+  max_val: float
+    maximum value of the linear region range. Default: 1
   """
   x = x.value if isinstance(x, Array) else x
-  return jnp.where(x > 1, 1, jnp.where(x < -1, -1, x))
+  return jnp.where(x > max_val, max_val, jnp.where(x < min_val, min_val, x))
 
 
 def hard_sigmoid(x):
   r"""Hard Sigmoid activation function.
 
   Computes the element-wise function
 
@@ -204,14 +216,24 @@
   ----------
   x: ArrayType
     The input array.
   """
   return relu6(x + 3.) / 6.
 
 
+def tanh_shrink(x):
+  r"""Applies the element-wise function:
+
+  .. math::
+      \text{Tanhshrink}(x) = x - \tanh(x)
+  """
+  x = x.value if isinstance(x, Array) else x
+  return x - jnp.tanh(x)
+
+
 def hard_silu(x):
   r"""Hard SiLU activation function
 
   Computes the element-wise function
 
   .. math::
     \mathrm{hard\_silu}(x) = x \cdot \mathrm{hard\_sigmoid}(x)
@@ -223,14 +245,39 @@
   """
   return x * hard_sigmoid(x)
 
 
 hard_swish = hard_silu
 
 
+def hard_shrink(x, lambd=0.5):
+  r"""Applies the Hard Shrinkage (Hardshrink) function element-wise.
+
+  Hardshrink is defined as:
+
+  .. math::
+      \text{HardShrink}(x) =
+      \begin{cases}
+      x, & \text{ if } x > \lambda \\
+      x, & \text{ if } x < -\lambda \\
+      0, & \text{ otherwise }
+      \end{cases}
+
+  Args:
+      lambd: the :math:`\lambda` value for the Hardshrink formulation. Default: 0.5
+
+  Shape:
+      - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
+      - Output: :math:`(*)`, same shape as the input.
+
+  """
+  x = x.value if isinstance(x, Array) else x
+  return jnp.where(x > lambd, x, jnp.where(x < -lambd, x, 0.))
+
+
 def leaky_relu(x, negative_slope=1e-2):
   r"""Leaky rectified linear unit activation function.
 
   Computes the element-wise function:
 
   .. math::
     \mathrm{leaky\_relu}(x) = \begin{cases}
@@ -247,29 +294,37 @@
   negative_slope : float
     The scalar specifying the negative slope (default: 0.01)
   """
   x = x.value if isinstance(x, Array) else x
   return jnp.where(x >= 0, x, negative_slope * x)
 
 
-def softplus(x):
+def softplus(x, beta=1, threshold=20):
   r"""Softplus activation function.
 
   Computes the element-wise function
 
   .. math::
-    \mathrm{softplus}(x) = \log(1 + e^x)
+    \text{Softplus}(x) = \frac{1}{\beta} * \log(1 + \exp(\beta * x))
+
+  SoftPlus is a smooth approximation to the ReLU function and can be used
+  to constrain the output of a machine to always be positive.
+
+  For numerical stability the implementation reverts to the linear function
+  when :math:`input \times \beta > threshold`.
 
   Parameters
   ----------
-  x: ArrayType
-    The input array.
+  x: The input array.
+  beta: the :math:`\beta` value for the Softplus formulation. Default: 1
+  threshold: values above this revert to a linear function. Default: 20
+
   """
   x = x.value if isinstance(x, Array) else x
-  return jnp.logaddexp(x, 0)
+  return jnp.where(x > threshold, x * beta, 1 / beta * jnp.logaddexp(beta * x, 0))
 
 
 def log_sigmoid(x):
   r"""Log-sigmoid activation function.
 
   Computes the element-wise function:
 
@@ -280,14 +335,36 @@
   ----------
   x: ArrayType
     The input array.
   """
   return -softplus(-x)
 
 
+def soft_shrink(x, lambd=0.5):
+  r"""Applies the soft shrinkage function elementwise:
+
+  .. math::
+      \text{SoftShrinkage}(x) =
+      \begin{cases}
+      x - \lambda, & \text{ if } x > \lambda \\
+      x + \lambda, & \text{ if } x < -\lambda \\
+      0, & \text{ otherwise }
+      \end{cases}
+
+  Args:
+      lambd: the :math:`\lambda` (must be no less than zero) value for the Softshrink formulation. Default: 0.5
+
+  Shape:
+      - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
+      - Output: :math:`(*)`, same shape as the input.
+  """
+  x = x.value if isinstance(x, Array) else x
+  return jnp.where(x > lambd, x - lambd, jnp.where(x < -lambd, x + lambd, 0.))
+
+
 def log_softmax(x, axis=-1):
   r"""Log-Softmax function.
 
   Computes the logarithm of the :code:`softmax` function, which rescales
   elements to the range :math:`[-\infty, 0)`.
 
   .. math ::
@@ -301,14 +378,16 @@
   axis: int
     The axis or axes along which the :code:`log_softmax` should be
     computed. Either an integer or a tuple of integers.
   """
   x = x.value if isinstance(x, Array) else x
   shifted = x - jax.lax.stop_gradient(x.max(axis, keepdims=True))
   return shifted - jnp.log(jnp.sum(jnp.exp(shifted), axis, keepdims=True))
+  # exp = jnp.exp(x)
+  # return jnp.log(exp / exp.sum(axis=axis, keepdims=True))
 
 
 def _canonicalize_axis(axis, num_dims) -> int:
   """Canonicalize an axis in [-num_dims, num_dims) to [0, num_dims)."""
   axis = operator.index(axis)
   if not -num_dims <= axis < num_dims:
     raise ValueError(
@@ -430,14 +509,73 @@
   x: ArrayType
     The input array.
   """
   x = x.value if isinstance(x, Array) else x
   return jnp.minimum(jnp.maximum(x, 0), 6.)
 
 
+def rrelu(x, lower=0.125, upper=0.3333333333333333, ):
+  r"""Applies the randomized leaky rectified liner unit function, element-wise,
+  as described in the paper:
+
+  `Empirical Evaluation of Rectified Activations in Convolutional Network`_.
+
+  The function is defined as:
+
+  .. math::
+      \text{RReLU}(x) =
+      \begin{cases}
+          x & \text{if } x \geq 0 \\
+          ax & \text{ otherwise }
+      \end{cases}
+
+  where :math:`a` is randomly sampled from uniform distribution
+  :math:`\mathcal{U}(\text{lower}, \text{upper})`.
+
+   See: https://arxiv.org/pdf/1505.00853.pdf
+
+  Args:
+      lower: lower bound of the uniform distribution. Default: :math:`\frac{1}{8}`
+      upper: upper bound of the uniform distribution. Default: :math:`\frac{1}{3}`
+
+  Shape:
+      - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
+      - Output: :math:`(*)`, same shape as the input.
+
+  .. _`Empirical Evaluation of Rectified Activations in Convolutional Network`:
+      https://arxiv.org/abs/1505.00853
+  """
+  x = x.value if isinstance(x, Array) else x
+  a = uniform(lower, upper, size=x.shape)
+  return jnp.where(x >= 0., x, a * x)
+
+
+def prelu(x, a=0.25):
+  r"""Applies the element-wise function:
+
+  .. math::
+      \text{PReLU}(x) = \max(0,x) + a * \min(0,x)
+
+  or
+
+  .. math::
+      \text{PReLU}(x) =
+      \begin{cases}
+      x, & \text{ if } x \geq 0 \\
+      ax, & \text{ otherwise }
+      \end{cases}
+
+  Here :math:`a` is a learnable parameter. When called without arguments, `nn.PReLU()` uses a single
+  parameter :math:`a` across all input channels. If called with `nn.PReLU(nChannels)`,
+  a separate :math:`a` is used for each input channel.
+  """
+  x = x.value if isinstance(x, Array) else x
+  return jnp.where(x >= 0., x, a * x)
+
+
 def sigmoid(x):
   r"""Sigmoid activation function.
 
   Computes the element-wise function:
 
   .. math::
     \mathrm{sigmoid}(x) = \frac{1}{1 + e^{-x}}
@@ -487,14 +625,41 @@
     Either an integer or a tuple of integers.
   """
   x = x.value if isinstance(x, Array) else x
   unnormalized = jnp.exp(x - jax.lax.stop_gradient(x.max(axis, keepdims=True)))
   return unnormalized / unnormalized.sum(axis, keepdims=True)
 
 
+def softmin(x, axis=-1):
+  r"""Applies the Softmin function to an n-dimensional input Tensor
+  rescaling them so that the elements of the n-dimensional output Tensor
+  lie in the range `[0, 1]` and sum to 1.
+
+  Softmin is defined as:
+
+  .. math::
+      \text{Softmin}(x_{i}) = \frac{\exp(-x_i)}{\sum_j \exp(-x_j)}
+
+  Shape:
+      - Input: :math:`(*)` where `*` means, any number of additional
+        dimensions
+      - Output: :math:`(*)`, same shape as the input
+
+  Args:
+      axis (int): A dimension along which Softmin will be computed (so every slice
+          along dim will sum to 1).
+  """
+  x = x.value if isinstance(x, Array) else x
+  unnormalized = jnp.exp(-x)
+  return unnormalized / unnormalized.sum(axis, keepdims=True)
+
+
+soft_max = softmax
+
+
 def silu(x):
   r"""SiLU activation function.
 
   Computes the element-wise function:
 
   .. math::
     \mathrm{silu}(x) = x \cdot \mathrm{sigmoid}(x) = \frac{x}{1 + e^{-x}}
@@ -507,14 +672,33 @@
   x = x.value if isinstance(x, Array) else x
   return x * sigmoid(x)
 
 
 swish = silu
 
 
+def mish(x):
+  r"""Applies the Mish function, element-wise.
+
+  Mish: A Self Regularized Non-Monotonic Neural Activation Function.
+
+  .. math::
+      \text{Mish}(x) = x * \text{Tanh}(\text{Softplus}(x))
+
+  .. note::
+      See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_
+
+  Shape:
+      - Input: :math:`(*)`, where :math:`*` means any number of dimensions.
+      - Output: :math:`(*)`, same shape as the input.
+  """
+  x = x.value if isinstance(x, Array) else x
+  return x * jnp.tanh(softplus(x))
+
+
 def selu(x):
   r"""Scaled exponential linear unit activation.
 
   Computes the element-wise function:
 
   .. math::
     \mathrm{selu}(x) = \lambda \begin{cases}
```

## brainpy/_src/math/delayvars.py

```diff
@@ -1,18 +1,19 @@
 # -*- coding: utf-8 -*-
 
 from typing import Union, Callable
+import numbers
 
 import jax
 import jax.numpy as jnp
 from jax import vmap
 from jax.lax import stop_gradient
 
 from brainpy import check
-from brainpy.check import is_float, is_integer, jit_error_checking
+from brainpy.check import is_float, is_integer, jit_error
 from brainpy.errors import UnsupportedError
 from .compat_numpy import vstack, broadcast_to
 from .environment import get_dt, get_float
 from .interoperability import as_jax
 from .ndarray import ndarray, Array
 from .object_transform.base import BrainPyObject
 from .object_transform.controls import cond
@@ -217,20 +218,20 @@
                      f'[{current_time - self.delay_len}, {current_time}], '
                      f'but we got {prev_time}')
 
   def __call__(self, time, indices=None):
     # check
     if check.is_checking():
       current_time = self.current_time[0]
-      jit_error_checking(time > current_time + 1e-6,
-                         self._check_time1,
-                         (time, current_time))
-      jit_error_checking(time < current_time - self.delay_len - self.dt,
-                         self._check_time2,
-                         (time, current_time))
+      jit_error(time > current_time + 1e-6,
+                self._check_time1,
+                (time, current_time))
+      jit_error(time < current_time - self.delay_len - self.dt,
+                self._check_time2,
+                (time, current_time))
     if self._before_type == _FUNC_BEFORE:
       res = cond(time < self.t0,
                  self._before_t0,
                  self._after_t0,
                  time)
     else:
       res = self._after_t0(time)
@@ -422,15 +423,15 @@
 
     Parameters
     ----------
     delay_len: int, ArrayType
       The delay length used to retrieve the data.
     """
     if check.is_checking():
-      jit_error_checking(jnp.any(delay_len >= self.num_delay_step), self._check_delay, delay_len)
+      jit_error(jnp.any(as_jax(delay_len >= self.num_delay_step)), self._check_delay, delay_len)
 
     if self.update_method == ROTATE_UPDATE:
       delay_idx = (self.idx[0] + delay_len) % self.num_delay_step
       delay_idx = stop_gradient(delay_idx)
 
     elif self.update_method == CONCAT_UPDATE:
       delay_idx = delay_len
@@ -443,15 +444,15 @@
       pass
     elif hasattr(delay_idx, 'dtype') and not jnp.issubdtype(delay_idx.dtype, jnp.integer):
       raise ValueError(f'"delay_len" must be integer, but we got {delay_idx}')
     indices = (delay_idx,) + tuple(indices)
     # the delay data
     return self.data[indices]
 
-  def update(self, value: Union[float, int, bool, Array, jnp.DeviceArray]):
+  def update(self, value: Union[numbers.Number, Array, jax.Array]):
     """Update delay variable with the new data.
 
     Parameters
     ----------
     value: Any
       The value of the latest data, used to update this delay variable.
     """
```

## brainpy/_src/math/ndarray.py

```diff
@@ -864,25 +864,25 @@
     :meth:`contiguous`) otherwise.
 
     Args:
         shape (int...): the desired size
 
     Example::
 
-        >>> x = brainpy.math.randn(4, 4)
+        >>> x = brainpy.math.random.randn(4, 4)
         >>> x.size
        [4, 4]
         >>> y = x.view(16)
         >>> y.size
         [16]
         >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
         >>> z.size
         [2, 8]
 
-        >>> a = brainpy.math.randn(1, 2, 3, 4)
+        >>> a = brainpy.math.random.randn(1, 2, 3, 4)
         >>> a.size
         [1, 2, 3, 4]
         >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension
         >>> b.size
         [1, 3, 2, 4]
         >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory
         >>> c.size
@@ -925,15 +925,15 @@
 
 
     Args:
         dtype (:class:`dtype`): the desired dtype
 
     Example::
 
-        >>> x = brainpy.math.randn(4, 4)
+        >>> x = brainpy.math.random.randn(4, 4)
         >>> x
         Array([[ 0.9482, -0.0310,  1.4999, -0.5316],
                 [-0.1520,  0.7472,  0.5617, -0.8649],
                 [-2.4724, -0.0334, -0.2976, -0.8499],
                 [-0.2109,  1.9913, -0.9607, -0.6123]])
         >>> x.dtype
         brainpy.math.float32
@@ -1013,16 +1013,15 @@
     return np.asarray(self.value, dtype=dtype)
 
   def __jax_array__(self):
     return self.value
 
   def as_variable(self):
     """As an instance of Variable."""
-    from brainpy.math import Variable
-    return Variable(self)
+    return brainpy.math.Variable(self)
 
   def __format__(self, specification):
     return self.value.__format__(specification)
 
   def __bool__(self) -> bool:
     return self.value.__bool__()
 
@@ -1046,17 +1045,17 @@
   def __index__(self):
     return operator.index(self.value)
 
   def __dlpack__(self):
     from jax.dlpack import to_dlpack  # pylint: disable=g-import-not-at-top
     return to_dlpack(self.value)
 
-  # **********************************
-  # For Pytorch compitable
-  # **********************************
+  # ----------------------
+  # PyTorch compatibility
+  # ----------------------
 
   def unsqueeze(self, dim: int) -> 'Array':
     """
     Array.unsqueeze(dim) -> Array, or so called Tensor
     equals
     Array.expand_dims(dim)
 
@@ -1161,135 +1160,178 @@
       beta: float = 1.0,
       alpha: float = 1.0
   ) -> None:
     vec1 = _as_jax_array_(vec1)
     vec2 = _as_jax_array_(vec2)
     r = alpha * jnp.outer(vec1, vec2) + beta * self.value
     self.value = r
+    return self
 
   def outer(self, other: Union['Array', jax.Array, np.ndarray]) -> 'Array':
     other = _as_jax_array_(other)
     return _return(jnp.outer(self.value, other.value))
 
   def abs(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.abs(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
-  def abs_(self) -> None:
+  def abs_(self):
     """
     in-place version of Array.abs()
     """
     self.value = jnp.abs(self.value)
+    return self
+
+  def add_(self, value):
+    self.value += value
+    return self
 
   def absolute(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     """
     alias of Array.abs
     """
     return self.abs(out=out)
 
   def absolute_(self) -> None:
     """
     alias of Array.abs_()
     """
     return self.abs_()
 
+
+  def mul(self, value):
+    return Array(self.value * value)
+
+  def mul_(self, value):
+    """
+    In-place version of :meth:`~Array.mul`.
+    """
+    self.value *= value
+    return self
+
+  def multiply(self, value):  # real signature unknown; restored from __doc__
+    """
+    multiply(value) -> Tensor
+
+    See :func:`torch.multiply`.
+    """
+    return self.value * value
+
+  def multiply_(self, value):  # real signature unknown; restored from __doc__
+    """
+    multiply_(value) -> Tensor
+
+    In-place version of :meth:`~Tensor.multiply`.
+    """
+    self.value *= value
+    return self
+
   def sin(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.sin(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
   def sin_(self) -> None:
     self.value = jnp.sin(self.value)
+    return self
 
   def cos_(self) -> None:
     self.value = jnp.cos(self.value)
+    return self
 
   def cos(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.cos(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
   def tan_(self) -> None:
     self.value = jnp.tan(self.value)
+    return self
 
   def tan(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.tan(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
   def sinh_(self) -> None:
     self.value = jnp.tanh(self.value)
+    return self
 
   def sinh(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.tanh(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
   def cosh_(self) -> None:
     self.value = jnp.cosh(self.value)
+    return self
 
   def cosh(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.cosh(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
   def tanh_(self) -> None:
     self.value = jnp.tanh(self.value)
+    return self
 
   def tanh(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.tanh(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
   def arcsin_(self) -> None:
     self.value = jnp.arcsin(self.value)
+    return self
 
   def arcsin(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.arcsin(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
   def arccos_(self) -> None:
     self.value = jnp.arccos(self.value)
+    return self
 
   def arccos(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.arccos(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
       out.value = r
 
   def arctan_(self) -> None:
     self.value = jnp.arctan(self.value)
+    return self
 
   def arctan(self, *, out: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> Optional['Array']:
     r = jnp.arctan(self.value)
     if out is None:
       return _return(r)
     else:
       _check_out(out)
@@ -1321,28 +1363,31 @@
              max_value: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> None:
     """
     return the value between min_value and max_value,
     if min_value is None, then no lower bound,
     if max_value is None, then no upper bound.
     """
     self.clamp(min_value, max_value, out=self)
+    return self
 
   def clip_(self,
             min_value: Optional[Union['Array', jax.Array, np.ndarray]] = None,
             max_value: Optional[Union['Array', jax.Array, np.ndarray]] = None) -> None:
     """
     alias for clamp_
     """
-    return self.clip(min_value, max_value, out=self)
+    self.value = self.clip(min_value, max_value, out=self)
+    return self
 
   def clone(self) -> 'Array':
     return Array(self.value.copy())
 
   def copy_(self, src: Union['Array', jax.Array, np.ndarray]) -> None:
     self.value = jnp.copy(_as_jax_array_(src))
+    return self
 
   def cov_with(
       self,
       y: Optional[Union['Array', jax.Array, np.ndarray]] = None,
       rowvar: bool = True,
       bias: bool = False,
       ddof: Optional[int] = None,
@@ -1357,15 +1402,15 @@
 
   def expand(self, *sizes) -> 'Array':
     """
     Expand an array to a new shape.
 
     Parameters
     ----------
-    shape : tuple or int
+    sizes : tuple or int
         The shape of the desired array. A single integer ``i`` is interpreted
         as ``(i,)``.
 
     Returns
     -------
     expanded : Array
         A readonly view on the original array with the given shape. It is
@@ -1394,10 +1439,53 @@
   def tree_flatten(self):
     return (self._value,), None
 
   @classmethod
   def tree_unflatten(cls, aux_data, flat_contents):
     return cls(*flat_contents)
 
+  def zero_(self):
+    self.value = jnp.zeros_like(self.value)
+    return self
+
+  def fill_(self, value):
+    self.fill(value)
+    return self
+
+  def uniform_(self, low=0., high=1.):
+    self.value = brainpy.math.random.uniform(low, high, self.shape)
+    return self
+
+  def log_normal_(self, mean=1, std=2):
+    r"""Fills self tensor with numbers samples from the log-normal distribution parameterized by the given mean
+    :math:`\mu` and standard deviation :math:`\sigma`. Note that mean and std are the mean and standard
+    deviation of the underlying normal distribution, and not of the returned distribution:
+
+    .. math::
+
+       f(x)=\frac{1}{x \sigma \sqrt{2 \pi}} e^{-\frac{(\ln x-\mu)^2}{2 \sigma^2}}
+
+    Args:
+      mean: the mean value.
+      std: the standard deviation.
+    """
+    self.value = brainpy.math.random.lognormal(mean, std, self.shape)
+    return self
+
+  def normal_(self, ):
+    """
+    Fills self tensor with elements samples from the normal distribution parameterized by mean and std.
+    """
+    self.value = brainpy.math.random.randn(*self.shape)
+    return self
+
+  def cuda(self):
+    self.value = jax.device_put(self.value, jax.devices('cuda')[0])
+    return self
+
+  def cpu(self):
+    self.value = jax.device_put(self.value, jax.devices('cpu')[0])
+    return self
+
 
 JaxArray = Array
 ndarray = Array
```

## brainpy/_src/math/random.py

```diff
@@ -19,4896 +19,4894 @@
 00000120: 656e 7461 6c2e 686f 7374 5f63 616c 6c62  ental.host_callb
 00000130: 6163 6b20 696d 706f 7274 2063 616c 6c0a  ack import call.
 00000140: 6672 6f6d 206a 6178 2e74 7265 655f 7574  from jax.tree_ut
 00000150: 696c 2069 6d70 6f72 7420 7265 6769 7374  il import regist
 00000160: 6572 5f70 7974 7265 655f 6e6f 6465 5f63  er_pytree_node_c
 00000170: 6c61 7373 0a0a 6672 6f6d 2062 7261 696e  lass..from brain
 00000180: 7079 2e63 6865 636b 2069 6d70 6f72 7420  py.check import 
-00000190: 6a69 745f 6572 726f 725f 6368 6563 6b69  jit_error_checki
-000001a0: 6e67 0a66 726f 6d20 2e63 6f6d 7061 745f  ng.from .compat_
-000001b0: 6e75 6d70 7920 696d 706f 7274 2073 6861  numpy import sha
-000001c0: 7065 0a66 726f 6d20 2e65 6e76 6972 6f6e  pe.from .environ
-000001d0: 6d65 6e74 2069 6d70 6f72 7420 6765 745f  ment import get_
-000001e0: 696e 740a 6672 6f6d 202e 6e64 6172 7261  int.from .ndarra
-000001f0: 7920 696d 706f 7274 2041 7272 6179 2c20  y import Array, 
-00000200: 5f72 6574 7572 6e0a 6672 6f6d 202e 6f62  _return.from .ob
-00000210: 6a65 6374 5f74 7261 6e73 666f 726d 2e76  ject_transform.v
-00000220: 6172 6961 626c 6573 2069 6d70 6f72 7420  ariables import 
-00000230: 5661 7269 6162 6c65 0a0a 5f5f 616c 6c5f  Variable..__all_
-00000240: 5f20 3d20 5b0a 2020 2752 616e 646f 6d53  _ = [.  'RandomS
-00000250: 7461 7465 272c 2027 4765 6e65 7261 746f  tate', 'Generato
-00000260: 7227 2c20 2744 4546 4155 4c54 272c 0a0a  r', 'DEFAULT',..
-00000270: 2020 2773 6565 6427 2c20 2764 6566 6175    'seed', 'defau
-00000280: 6c74 5f72 6e67 272c 2027 7370 6c69 745f  lt_rng', 'split_
-00000290: 6b65 7927 2c0a 0a20 2023 206e 756d 7079  key',..  # numpy
-000002a0: 2063 6f6d 7061 7469 6269 6c69 7479 0a20   compatibility. 
-000002b0: 2027 7261 6e64 272c 2027 7261 6e64 696e   'rand', 'randin
-000002c0: 7427 2c20 2772 616e 646f 6d5f 696e 7465  t', 'random_inte
-000002d0: 6765 7273 272c 2027 7261 6e64 6e27 2c20  gers', 'randn', 
-000002e0: 2772 616e 646f 6d27 2c0a 2020 2772 616e  'random',.  'ran
-000002f0: 646f 6d5f 7361 6d70 6c65 272c 2027 7261  dom_sample', 'ra
-00000300: 6e66 272c 2027 7361 6d70 6c65 272c 2027  nf', 'sample', '
-00000310: 6368 6f69 6365 272c 2027 7065 726d 7574  choice', 'permut
-00000320: 6174 696f 6e27 2c20 2773 6875 6666 6c65  ation', 'shuffle
-00000330: 272c 2027 6265 7461 272c 0a20 2027 6578  ', 'beta',.  'ex
-00000340: 706f 6e65 6e74 6961 6c27 2c20 2767 616d  ponential', 'gam
-00000350: 6d61 272c 2027 6775 6d62 656c 272c 2027  ma', 'gumbel', '
-00000360: 6c61 706c 6163 6527 2c20 276c 6f67 6973  laplace', 'logis
-00000370: 7469 6327 2c20 276e 6f72 6d61 6c27 2c20  tic', 'normal', 
-00000380: 2770 6172 6574 6f27 2c0a 2020 2770 6f69  'pareto',.  'poi
-00000390: 7373 6f6e 272c 2027 7374 616e 6461 7264  sson', 'standard
-000003a0: 5f63 6175 6368 7927 2c20 2773 7461 6e64  _cauchy', 'stand
-000003b0: 6172 645f 6578 706f 6e65 6e74 6961 6c27  ard_exponential'
-000003c0: 2c20 2773 7461 6e64 6172 645f 6761 6d6d  , 'standard_gamm
-000003d0: 6127 2c0a 2020 2773 7461 6e64 6172 645f  a',.  'standard_
-000003e0: 6e6f 726d 616c 272c 2027 7374 616e 6461  normal', 'standa
-000003f0: 7264 5f74 272c 2027 756e 6966 6f72 6d27  rd_t', 'uniform'
-00000400: 2c20 2774 7275 6e63 6174 6564 5f6e 6f72  , 'truncated_nor
-00000410: 6d61 6c27 2c20 2762 6572 6e6f 756c 6c69  mal', 'bernoulli
-00000420: 272c 0a20 2027 6c6f 676e 6f72 6d61 6c27  ',.  'lognormal'
-00000430: 2c20 2762 696e 6f6d 6961 6c27 2c20 2763  , 'binomial', 'c
-00000440: 6869 7371 7561 7265 272c 2027 6469 7269  hisquare', 'diri
-00000450: 6368 6c65 7427 2c20 2767 656f 6d65 7472  chlet', 'geometr
-00000460: 6963 272c 2027 6627 2c0a 2020 2768 7970  ic', 'f',.  'hyp
-00000470: 6572 6765 6f6d 6574 7269 6327 2c20 276c  ergeometric', 'l
-00000480: 6f67 7365 7269 6573 272c 2027 6d75 6c74  ogseries', 'mult
-00000490: 696e 6f6d 6961 6c27 2c20 276d 756c 7469  inomial', 'multi
-000004a0: 7661 7269 6174 655f 6e6f 726d 616c 272c  variate_normal',
-000004b0: 0a20 2027 6e65 6761 7469 7665 5f62 696e  .  'negative_bin
-000004c0: 6f6d 6961 6c27 2c20 276e 6f6e 6365 6e74  omial', 'noncent
-000004d0: 7261 6c5f 6368 6973 7175 6172 6527 2c20  ral_chisquare', 
-000004e0: 276e 6f6e 6365 6e74 7261 6c5f 6627 2c20  'noncentral_f', 
-000004f0: 2770 6f77 6572 272c 0a20 2027 7261 796c  'power',.  'rayl
-00000500: 6569 6768 272c 2027 7472 6961 6e67 756c  eigh', 'triangul
-00000510: 6172 272c 2027 766f 6e6d 6973 6573 272c  ar', 'vonmises',
-00000520: 2027 7761 6c64 272c 2027 7765 6962 756c   'wald', 'weibul
-00000530: 6c27 2c20 2777 6569 6275 6c6c 5f6d 696e  l', 'weibull_min
-00000540: 272c 0a20 2027 7a69 7066 272c 2027 6d61  ',.  'zipf', 'ma
-00000550: 7877 656c 6c27 2c20 2774 272c 2027 6f72  xwell', 't', 'or
-00000560: 7468 6f67 6f6e 616c 272c 2027 6c6f 6767  thogonal', 'logg
-00000570: 616d 6d61 272c 2027 6361 7465 676f 7269  amma', 'categori
-00000580: 6361 6c27 2c0a 0a20 2023 2070 7974 6f72  cal',..  # pytor
-00000590: 6368 2063 6f6d 7061 7469 6269 6c69 7479  ch compatibility
-000005a0: 0a20 2027 7261 6e64 5f6c 696b 6527 2c20  .  'rand_like', 
-000005b0: 2772 616e 6469 6e74 5f6c 696b 6527 2c20  'randint_like', 
-000005c0: 2772 616e 646e 5f6c 696b 6527 2c0a 5d0a  'randn_like',.].
-000005d0: 0a0a 6465 6620 5f66 6f72 6d61 6c69 7a65  ..def _formalize
-000005e0: 5f6b 6579 286b 6579 293a 0a20 2069 6620  _key(key):.  if 
-000005f0: 6973 696e 7374 616e 6365 286b 6579 2c20  isinstance(key, 
-00000600: 696e 7429 3a0a 2020 2020 7265 7475 726e  int):.    return
-00000610: 206a 722e 5052 4e47 4b65 7928 6b65 7929   jr.PRNGKey(key)
-00000620: 0a20 2065 6c69 6620 6973 696e 7374 616e  .  elif isinstan
-00000630: 6365 286b 6579 2c20 2841 7272 6179 2c20  ce(key, (Array, 
-00000640: 6a6e 702e 6e64 6172 7261 792c 206e 702e  jnp.ndarray, np.
-00000650: 6e64 6172 7261 7929 293a 0a20 2020 2069  ndarray)):.    i
-00000660: 6620 6b65 792e 6474 7970 6520 213d 206a  f key.dtype != j
-00000670: 6e70 2e75 696e 7433 323a 0a20 2020 2020  np.uint32:.     
-00000680: 2072 6169 7365 2054 7970 6545 7272 6f72   raise TypeError
-00000690: 2827 6b65 7920 6d75 7374 2062 6520 6120  ('key must be a 
-000006a0: 696e 7420 6f72 2061 6e20 6172 7261 7920  int or an array 
-000006b0: 7769 7468 2074 776f 2075 696e 7433 322e  with two uint32.
-000006c0: 2729 0a20 2020 2069 6620 6b65 792e 7369  ').    if key.si
-000006d0: 7a65 2021 3d20 323a 0a20 2020 2020 2072  ze != 2:.      r
-000006e0: 6169 7365 2054 7970 6545 7272 6f72 2827  aise TypeError('
-000006f0: 6b65 7920 6d75 7374 2062 6520 6120 696e  key must be a in
-00000700: 7420 6f72 2061 6e20 6172 7261 7920 7769  t or an array wi
-00000710: 7468 2074 776f 2075 696e 7433 322e 2729  th two uint32.')
-00000720: 0a20 2020 2072 6574 7572 6e20 6a6e 702e  .    return jnp.
-00000730: 6173 6172 7261 7928 6b65 7929 0a20 2065  asarray(key).  e
-00000740: 6c73 653a 0a20 2020 2072 6169 7365 2054  lse:.    raise T
-00000750: 7970 6545 7272 6f72 2827 6b65 7920 6d75  ypeError('key mu
-00000760: 7374 2062 6520 6120 696e 7420 6f72 2061  st be a int or a
-00000770: 6e20 6172 7261 7920 7769 7468 2074 776f  n array with two
-00000780: 2075 696e 7433 322e 2729 0a0a 0a64 6566   uint32.')...def
-00000790: 205f 7369 7a65 3273 6861 7065 2873 697a   _size2shape(siz
-000007a0: 6529 3a0a 2020 6966 2073 697a 6520 6973  e):.  if size is
-000007b0: 204e 6f6e 653a 0a20 2020 2072 6574 7572   None:.    retur
-000007c0: 6e20 2829 0a20 2065 6c69 6620 6973 696e  n ().  elif isin
-000007d0: 7374 616e 6365 2873 697a 652c 2069 6e74  stance(size, int
-000007e0: 293a 0a20 2020 2072 6574 7572 6e20 2873  ):.    return (s
-000007f0: 697a 652c 290a 2020 656c 6966 2069 7369  ize,).  elif isi
-00000800: 6e73 7461 6e63 6528 7369 7a65 2c20 2874  nstance(size, (t
-00000810: 7570 6c65 2c20 6c69 7374 2929 3a0a 2020  uple, list)):.  
-00000820: 2020 7265 7475 726e 2074 7570 6c65 2873    return tuple(s
-00000830: 697a 6529 0a20 2065 6c73 653a 0a20 2020  ize).  else:.   
-00000840: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-00000850: 7228 6627 4d75 7374 2062 6520 6120 6c69  r(f'Must be a li
-00000860: 7374 2f74 7570 6c65 206f 6620 696e 742c  st/tuple of int,
-00000870: 2062 7574 2067 6f74 207b 7369 7a65 7d27   but got {size}'
-00000880: 290a 0a0a 6465 6620 5f63 6865 636b 5f73  )...def _check_s
-00000890: 6861 7065 286e 616d 652c 2073 6861 7065  hape(name, shape
-000008a0: 2c20 2a70 6172 616d 5f73 6861 7065 7329  , *param_shapes)
-000008b0: 3a0a 2020 7368 6170 6520 3d20 636f 7265  :.  shape = core
-000008c0: 2e61 735f 6e61 6d65 645f 7368 6170 6528  .as_named_shape(
-000008d0: 7368 6170 6529 0a20 2069 6620 7061 7261  shape).  if para
-000008e0: 6d5f 7368 6170 6573 3a0a 2020 2020 7368  m_shapes:.    sh
-000008f0: 6170 655f 203d 206c 6178 2e62 726f 6164  ape_ = lax.broad
-00000900: 6361 7374 5f73 6861 7065 7328 7368 6170  cast_shapes(shap
-00000910: 652e 706f 7369 7469 6f6e 616c 2c20 2a70  e.positional, *p
-00000920: 6172 616d 5f73 6861 7065 7329 0a20 2020  aram_shapes).   
-00000930: 2069 6620 7368 6170 652e 706f 7369 7469   if shape.positi
-00000940: 6f6e 616c 2021 3d20 7368 6170 655f 3a0a  onal != shape_:.
-00000950: 2020 2020 2020 6d73 6720 3d20 2822 7b7d        msg = ("{}
-00000960: 2070 6172 616d 6574 6572 2073 6861 7065   parameter shape
-00000970: 7320 6d75 7374 2062 6520 6272 6f61 6463  s must be broadc
-00000980: 6173 742d 636f 6d70 6174 6962 6c65 2077  ast-compatible w
-00000990: 6974 6820 7368 6170 6520 220a 2020 2020  ith shape ".    
-000009a0: 2020 2020 2020 2020 2022 6172 6775 6d65           "argume
-000009b0: 6e74 2c20 616e 6420 7468 6520 7265 7375  nt, and the resu
-000009c0: 6c74 206f 6620 6272 6f61 6463 6173 7469  lt of broadcasti
-000009d0: 6e67 2074 6865 2073 6861 7065 7320 6d75  ng the shapes mu
-000009e0: 7374 2065 7175 616c 2022 0a20 2020 2020  st equal ".     
-000009f0: 2020 2020 2020 2020 2274 6865 2073 6861          "the sha
-00000a00: 7065 2061 7267 756d 656e 742c 2062 7574  pe argument, but
-00000a10: 2067 6f74 2072 6573 756c 7420 7b7d 2066   got result {} f
-00000a20: 6f72 2073 6861 7065 2061 7267 756d 656e  or shape argumen
-00000a30: 7420 7b7d 2e22 290a 2020 2020 2020 7261  t {}.").      ra
-00000a40: 6973 6520 5661 6c75 6545 7272 6f72 286d  ise ValueError(m
-00000a50: 7367 2e66 6f72 6d61 7428 6e61 6d65 2c20  sg.format(name, 
-00000a60: 7368 6170 655f 2c20 7368 6170 6529 290a  shape_, shape)).
-00000a70: 0a0a 6465 6620 5f61 735f 6a61 785f 6172  ..def _as_jax_ar
-00000a80: 7261 7928 6129 3a0a 2020 7265 7475 726e  ray(a):.  return
-00000a90: 2061 2e76 616c 7565 2069 6620 6973 696e   a.value if isin
-00000aa0: 7374 616e 6365 2861 2c20 4172 7261 7929  stance(a, Array)
-00000ab0: 2065 6c73 6520 610a 0a0a 6465 6620 5f69   else a...def _i
-00000ac0: 735f 7079 7468 6f6e 5f73 6361 6c61 7228  s_python_scalar(
-00000ad0: 7829 3a0a 2020 6966 2068 6173 6174 7472  x):.  if hasattr
-00000ae0: 2878 2c20 2761 7661 6c27 293a 0a20 2020  (x, 'aval'):.   
-00000af0: 2072 6574 7572 6e20 782e 6176 616c 2e77   return x.aval.w
-00000b00: 6561 6b5f 7479 7065 0a20 2065 6c69 6620  eak_type.  elif 
-00000b10: 6e70 2e6e 6469 6d28 7829 203d 3d20 303a  np.ndim(x) == 0:
-00000b20: 0a20 2020 2072 6574 7572 6e20 5472 7565  .    return True
-00000b30: 0a20 2065 6c69 6620 6973 696e 7374 616e  .  elif isinstan
-00000b40: 6365 2878 2c20 2862 6f6f 6c2c 2069 6e74  ce(x, (bool, int
-00000b50: 2c20 666c 6f61 742c 2063 6f6d 706c 6578  , float, complex
-00000b60: 2929 3a0a 2020 2020 7265 7475 726e 2054  )):.    return T
-00000b70: 7275 650a 2020 656c 7365 3a0a 2020 2020  rue.  else:.    
-00000b80: 7265 7475 726e 2046 616c 7365 0a0a 0a70  return False...p
-00000b90: 7974 686f 6e5f 7363 616c 6172 5f64 7479  ython_scalar_dty
-00000ba0: 7065 7320 3d20 7b0a 2020 626f 6f6c 3a20  pes = {.  bool: 
-00000bb0: 6e70 2e64 7479 7065 2827 626f 6f6c 2729  np.dtype('bool')
-00000bc0: 2c0a 2020 696e 743a 206e 702e 6474 7970  ,.  int: np.dtyp
-00000bd0: 6528 2769 6e74 3634 2729 2c0a 2020 666c  e('int64'),.  fl
-00000be0: 6f61 743a 206e 702e 6474 7970 6528 2766  oat: np.dtype('f
-00000bf0: 6c6f 6174 3634 2729 2c0a 2020 636f 6d70  loat64'),.  comp
-00000c00: 6c65 783a 206e 702e 6474 7970 6528 2763  lex: np.dtype('c
-00000c10: 6f6d 706c 6578 3132 3827 292c 0a7d 0a0a  omplex128'),.}..
-00000c20: 0a64 6566 205f 6474 7970 6528 782c 202a  .def _dtype(x, *
-00000c30: 2c20 6361 6e6f 6e69 6361 6c69 7a65 3a20  , canonicalize: 
-00000c40: 626f 6f6c 203d 2046 616c 7365 293a 0a20  bool = False):. 
-00000c50: 2022 2222 5265 7475 726e 2074 6865 2064   """Return the d
-00000c60: 7479 7065 206f 626a 6563 7420 666f 7220  type object for 
-00000c70: 6120 7661 6c75 6520 6f72 2074 7970 652c  a value or type,
-00000c80: 206f 7074 696f 6e61 6c6c 7920 6361 6e6f   optionally cano
-00000c90: 6e69 6361 6c69 7a65 6420 6261 7365 6420  nicalized based 
-00000ca0: 6f6e 2058 3634 206d 6f64 652e 2222 220a  on X64 mode.""".
-00000cb0: 2020 6966 2078 2069 7320 4e6f 6e65 3a0a    if x is None:.
-00000cc0: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-00000cd0: 7272 6f72 2866 2249 6e76 616c 6964 2061  rror(f"Invalid a
-00000ce0: 7267 756d 656e 7420 746f 2064 7479 7065  rgument to dtype
-00000cf0: 3a20 7b78 7d2e 2229 0a20 2065 6c69 6620  : {x}.").  elif 
-00000d00: 6973 696e 7374 616e 6365 2878 2c20 7479  isinstance(x, ty
-00000d10: 7065 2920 616e 6420 7820 696e 2070 7974  pe) and x in pyt
-00000d20: 686f 6e5f 7363 616c 6172 5f64 7479 7065  hon_scalar_dtype
-00000d30: 733a 0a20 2020 2064 7420 3d20 7079 7468  s:.    dt = pyth
-00000d40: 6f6e 5f73 6361 6c61 725f 6474 7970 6573  on_scalar_dtypes
-00000d50: 5b78 5d0a 2020 656c 6966 2074 7970 6528  [x].  elif type(
-00000d60: 7829 2069 6e20 7079 7468 6f6e 5f73 6361  x) in python_sca
-00000d70: 6c61 725f 6474 7970 6573 3a0a 2020 2020  lar_dtypes:.    
-00000d80: 6474 203d 2070 7974 686f 6e5f 7363 616c  dt = python_scal
-00000d90: 6172 5f64 7479 7065 735b 7479 7065 2878  ar_dtypes[type(x
-00000da0: 295d 0a20 2065 6c69 6620 6a61 782e 636f  )].  elif jax.co
-00000db0: 7265 2e69 735f 6f70 6171 7565 5f64 7479  re.is_opaque_dty
-00000dc0: 7065 2867 6574 6174 7472 2878 2c20 2764  pe(getattr(x, 'd
-00000dd0: 7479 7065 272c 204e 6f6e 6529 293a 0a20  type', None)):. 
-00000de0: 2020 2064 7420 3d20 782e 6474 7970 650a     dt = x.dtype.
-00000df0: 2020 656c 7365 3a0a 2020 2020 6474 203d    else:.    dt =
-00000e00: 206e 702e 7265 7375 6c74 5f74 7970 6528   np.result_type(
-00000e10: 7829 0a20 2072 6574 7572 6e20 6474 7970  x).  return dtyp
-00000e20: 6573 2e63 616e 6f6e 6963 616c 697a 655f  es.canonicalize_
-00000e30: 6474 7970 6528 6474 2920 6966 2063 616e  dtype(dt) if can
-00000e40: 6f6e 6963 616c 697a 6520 656c 7365 2064  onicalize else d
-00000e50: 740a 0a0a 6465 6620 5f63 6f6e 7374 2865  t...def _const(e
-00000e60: 7861 6d70 6c65 2c20 7661 6c29 3a0a 2020  xample, val):.  
-00000e70: 6966 205f 6973 5f70 7974 686f 6e5f 7363  if _is_python_sc
-00000e80: 616c 6172 2865 7861 6d70 6c65 293a 0a20  alar(example):. 
-00000e90: 2020 2064 7479 7065 203d 2064 7479 7065     dtype = dtype
-00000ea0: 732e 6361 6e6f 6e69 6361 6c69 7a65 5f64  s.canonicalize_d
-00000eb0: 7479 7065 2874 7970 6528 6578 616d 706c  type(type(exampl
-00000ec0: 6529 290a 2020 2020 7661 6c20 3d20 6474  e)).    val = dt
-00000ed0: 7970 6573 2e73 6361 6c61 725f 7479 7065  ypes.scalar_type
-00000ee0: 5f6f 6628 6578 616d 706c 6529 2876 616c  _of(example)(val
-00000ef0: 290a 2020 2020 7265 7475 726e 2076 616c  ).    return val
-00000f00: 2069 6620 6474 7970 6520 3d3d 205f 6474   if dtype == _dt
-00000f10: 7970 6528 7661 6c2c 2063 616e 6f6e 6963  ype(val, canonic
-00000f20: 616c 697a 653d 5472 7565 2920 656c 7365  alize=True) else
-00000f30: 206e 702e 6172 7261 7928 7661 6c2c 2064   np.array(val, d
-00000f40: 7479 7065 290a 2020 656c 7365 3a0a 2020  type).  else:.  
-00000f50: 2020 6474 7970 6520 3d20 6474 7970 6573    dtype = dtypes
-00000f60: 2e63 616e 6f6e 6963 616c 697a 655f 6474  .canonicalize_dt
-00000f70: 7970 6528 6578 616d 706c 652e 6474 7970  ype(example.dtyp
-00000f80: 6529 0a20 2072 6574 7572 6e20 6e70 2e61  e).  return np.a
-00000f90: 7272 6179 2876 616c 2c20 6474 7970 6529  rray(val, dtype)
-00000fa0: 0a0a 0a5f 7472 5f70 6172 616d 7320 3d20  ..._tr_params = 
-00000fb0: 6e61 6d65 6474 7570 6c65 280a 2020 2274  namedtuple(.  "t
-00000fc0: 725f 7061 7261 6d73 222c 205b 2263 222c  r_params", ["c",
-00000fd0: 2022 6222 2c20 2261 222c 2022 616c 7068   "b", "a", "alph
-00000fe0: 6122 2c20 2275 5f72 222c 2022 765f 7222  a", "u_r", "v_r"
-00000ff0: 2c20 226d 222c 2022 6c6f 675f 7022 2c20  , "m", "log_p", 
-00001000: 226c 6f67 315f 7022 2c20 226c 6f67 5f68  "log1_p", "log_h
-00001010: 225d 0a29 0a0a 0a64 6566 205f 6765 745f  "].)...def _get_
-00001020: 7472 5f70 6172 616d 7328 6e2c 2070 293a  tr_params(n, p):
-00001030: 0a20 2023 2053 6565 2054 6162 6c65 2031  .  # See Table 1
-00001040: 2e20 4164 6469 7469 6f6e 616c 6c79 2c20  . Additionally, 
-00001050: 7765 2070 7265 2d63 6f6d 7075 7465 206c  we pre-compute l
-00001060: 6f67 2870 292c 206c 6f67 3128 2d70 2920  og(p), log1(-p) 
-00001070: 616e 6420 7468 650a 2020 2320 636f 6e73  and the.  # cons
-00001080: 7461 6e74 2074 6572 6d73 2c20 7468 6174  tant terms, that
-00001090: 2064 6570 656e 6420 6f6e 6c79 206f 6e20   depend only on 
-000010a0: 286e 2c20 702c 206d 2920 696e 206c 6f67  (n, p, m) in log
-000010b0: 2866 286b 2929 2028 626f 7474 6f6d 206f  (f(k)) (bottom o
-000010c0: 6620 7061 6765 2035 292e 0a20 206d 7520  f page 5)..  mu 
-000010d0: 3d20 6e20 2a20 700a 2020 7370 7120 3d20  = n * p.  spq = 
-000010e0: 6a6e 702e 7371 7274 286d 7520 2a20 2831  jnp.sqrt(mu * (1
-000010f0: 202d 2070 2929 0a20 2063 203d 206d 7520   - p)).  c = mu 
-00001100: 2b20 302e 350a 2020 6220 3d20 312e 3135  + 0.5.  b = 1.15
-00001110: 202b 2032 2e35 3320 2a20 7370 710a 2020   + 2.53 * spq.  
-00001120: 6120 3d20 2d30 2e30 3837 3320 2b20 302e  a = -0.0873 + 0.
-00001130: 3032 3438 202a 2062 202b 2030 2e30 3120  0248 * b + 0.01 
-00001140: 2a20 700a 2020 616c 7068 6120 3d20 2832  * p.  alpha = (2
-00001150: 2e38 3320 2b20 352e 3120 2f20 6229 202a  .83 + 5.1 / b) *
-00001160: 2073 7071 0a20 2075 5f72 203d 2030 2e34   spq.  u_r = 0.4
-00001170: 330a 2020 765f 7220 3d20 302e 3932 202d  3.  v_r = 0.92 -
-00001180: 2034 2e32 202f 2062 0a20 206d 203d 206a   4.2 / b.  m = j
-00001190: 6e70 2e66 6c6f 6f72 2828 6e20 2b20 3129  np.floor((n + 1)
-000011a0: 202a 2070 292e 6173 7479 7065 286e 2e64   * p).astype(n.d
-000011b0: 7479 7065 290a 2020 6c6f 675f 7020 3d20  type).  log_p = 
-000011c0: 6a6e 702e 6c6f 6728 7029 0a20 206c 6f67  jnp.log(p).  log
-000011d0: 315f 7020 3d20 6a6e 702e 6c6f 6731 7028  1_p = jnp.log1p(
-000011e0: 2d70 290a 2020 6c6f 675f 6820 3d20 2828  -p).  log_h = ((
-000011f0: 6d20 2b20 302e 3529 202a 2028 6a6e 702e  m + 0.5) * (jnp.
-00001200: 6c6f 6728 286d 202b 2031 2e30 2920 2f20  log((m + 1.0) / 
-00001210: 286e 202d 206d 202b 2031 2e30 2929 202b  (n - m + 1.0)) +
-00001220: 206c 6f67 315f 7020 2d20 6c6f 675f 7029   log1_p - log_p)
-00001230: 202b 0a20 2020 2020 2020 2020 2020 5f73   +.           _s
-00001240: 7469 726c 696e 675f 6170 7072 6f78 5f74  tirling_approx_t
-00001250: 6169 6c28 6d29 202b 205f 7374 6972 6c69  ail(m) + _stirli
-00001260: 6e67 5f61 7070 726f 785f 7461 696c 286e  ng_approx_tail(n
-00001270: 202d 206d 2929 0a20 2072 6574 7572 6e20   - m)).  return 
-00001280: 5f74 725f 7061 7261 6d73 2863 2c20 622c  _tr_params(c, b,
-00001290: 2061 2c20 616c 7068 612c 2075 5f72 2c20   a, alpha, u_r, 
-000012a0: 765f 722c 206d 2c20 6c6f 675f 702c 206c  v_r, m, log_p, l
-000012b0: 6f67 315f 702c 206c 6f67 5f68 290a 0a0a  og1_p, log_h)...
-000012c0: 6465 6620 5f73 7469 726c 696e 675f 6170  def _stirling_ap
-000012d0: 7072 6f78 5f74 6169 6c28 6b29 3a0a 2020  prox_tail(k):.  
-000012e0: 7072 6563 6f6d 7075 7465 6420 3d20 6a6e  precomputed = jn
-000012f0: 702e 6172 7261 7928 5b30 2e30 3831 3036  p.array([0.08106
-00001300: 3134 3636 3739 3533 3237 3236 2c0a 2020  146679532726,.  
+00000190: 6a69 745f 6572 726f 720a 6672 6f6d 202e  jit_error.from .
+000001a0: 636f 6d70 6174 5f6e 756d 7079 2069 6d70  compat_numpy imp
+000001b0: 6f72 7420 7368 6170 650a 6672 6f6d 202e  ort shape.from .
+000001c0: 656e 7669 726f 6e6d 656e 7420 696d 706f  environment impo
+000001d0: 7274 2067 6574 5f69 6e74 0a66 726f 6d20  rt get_int.from 
+000001e0: 2e6e 6461 7272 6179 2069 6d70 6f72 7420  .ndarray import 
+000001f0: 4172 7261 792c 205f 7265 7475 726e 0a66  Array, _return.f
+00000200: 726f 6d20 2e6f 626a 6563 745f 7472 616e  rom .object_tran
+00000210: 7366 6f72 6d2e 7661 7269 6162 6c65 7320  sform.variables 
+00000220: 696d 706f 7274 2056 6172 6961 626c 650a  import Variable.
+00000230: 0a5f 5f61 6c6c 5f5f 203d 205b 0a20 2027  .__all__ = [.  '
+00000240: 5261 6e64 6f6d 5374 6174 6527 2c20 2747  RandomState', 'G
+00000250: 656e 6572 6174 6f72 272c 2027 4445 4641  enerator', 'DEFA
+00000260: 554c 5427 2c0a 0a20 2027 7365 6564 272c  ULT',..  'seed',
+00000270: 2027 6465 6661 756c 745f 726e 6727 2c20   'default_rng', 
+00000280: 2773 706c 6974 5f6b 6579 272c 0a0a 2020  'split_key',..  
+00000290: 2320 6e75 6d70 7920 636f 6d70 6174 6962  # numpy compatib
+000002a0: 696c 6974 790a 2020 2772 616e 6427 2c20  ility.  'rand', 
+000002b0: 2772 616e 6469 6e74 272c 2027 7261 6e64  'randint', 'rand
+000002c0: 6f6d 5f69 6e74 6567 6572 7327 2c20 2772  om_integers', 'r
+000002d0: 616e 646e 272c 2027 7261 6e64 6f6d 272c  andn', 'random',
+000002e0: 0a20 2027 7261 6e64 6f6d 5f73 616d 706c  .  'random_sampl
+000002f0: 6527 2c20 2772 616e 6627 2c20 2773 616d  e', 'ranf', 'sam
+00000300: 706c 6527 2c20 2763 686f 6963 6527 2c20  ple', 'choice', 
+00000310: 2770 6572 6d75 7461 7469 6f6e 272c 2027  'permutation', '
+00000320: 7368 7566 666c 6527 2c20 2762 6574 6127  shuffle', 'beta'
+00000330: 2c0a 2020 2765 7870 6f6e 656e 7469 616c  ,.  'exponential
+00000340: 272c 2027 6761 6d6d 6127 2c20 2767 756d  ', 'gamma', 'gum
+00000350: 6265 6c27 2c20 276c 6170 6c61 6365 272c  bel', 'laplace',
+00000360: 2027 6c6f 6769 7374 6963 272c 2027 6e6f   'logistic', 'no
+00000370: 726d 616c 272c 2027 7061 7265 746f 272c  rmal', 'pareto',
+00000380: 0a20 2027 706f 6973 736f 6e27 2c20 2773  .  'poisson', 's
+00000390: 7461 6e64 6172 645f 6361 7563 6879 272c  tandard_cauchy',
+000003a0: 2027 7374 616e 6461 7264 5f65 7870 6f6e   'standard_expon
+000003b0: 656e 7469 616c 272c 2027 7374 616e 6461  ential', 'standa
+000003c0: 7264 5f67 616d 6d61 272c 0a20 2027 7374  rd_gamma',.  'st
+000003d0: 616e 6461 7264 5f6e 6f72 6d61 6c27 2c20  andard_normal', 
+000003e0: 2773 7461 6e64 6172 645f 7427 2c20 2775  'standard_t', 'u
+000003f0: 6e69 666f 726d 272c 2027 7472 756e 6361  niform', 'trunca
+00000400: 7465 645f 6e6f 726d 616c 272c 2027 6265  ted_normal', 'be
+00000410: 726e 6f75 6c6c 6927 2c0a 2020 276c 6f67  rnoulli',.  'log
+00000420: 6e6f 726d 616c 272c 2027 6269 6e6f 6d69  normal', 'binomi
+00000430: 616c 272c 2027 6368 6973 7175 6172 6527  al', 'chisquare'
+00000440: 2c20 2764 6972 6963 686c 6574 272c 2027  , 'dirichlet', '
+00000450: 6765 6f6d 6574 7269 6327 2c20 2766 272c  geometric', 'f',
+00000460: 0a20 2027 6879 7065 7267 656f 6d65 7472  .  'hypergeometr
+00000470: 6963 272c 2027 6c6f 6773 6572 6965 7327  ic', 'logseries'
+00000480: 2c20 276d 756c 7469 6e6f 6d69 616c 272c  , 'multinomial',
+00000490: 2027 6d75 6c74 6976 6172 6961 7465 5f6e   'multivariate_n
+000004a0: 6f72 6d61 6c27 2c0a 2020 276e 6567 6174  ormal',.  'negat
+000004b0: 6976 655f 6269 6e6f 6d69 616c 272c 2027  ive_binomial', '
+000004c0: 6e6f 6e63 656e 7472 616c 5f63 6869 7371  noncentral_chisq
+000004d0: 7561 7265 272c 2027 6e6f 6e63 656e 7472  uare', 'noncentr
+000004e0: 616c 5f66 272c 2027 706f 7765 7227 2c0a  al_f', 'power',.
+000004f0: 2020 2772 6179 6c65 6967 6827 2c20 2774    'rayleigh', 't
+00000500: 7269 616e 6775 6c61 7227 2c20 2776 6f6e  riangular', 'von
+00000510: 6d69 7365 7327 2c20 2777 616c 6427 2c20  mises', 'wald', 
+00000520: 2777 6569 6275 6c6c 272c 2027 7765 6962  'weibull', 'weib
+00000530: 756c 6c5f 6d69 6e27 2c0a 2020 277a 6970  ull_min',.  'zip
+00000540: 6627 2c20 276d 6178 7765 6c6c 272c 2027  f', 'maxwell', '
+00000550: 7427 2c20 276f 7274 686f 676f 6e61 6c27  t', 'orthogonal'
+00000560: 2c20 276c 6f67 6761 6d6d 6127 2c20 2763  , 'loggamma', 'c
+00000570: 6174 6567 6f72 6963 616c 272c 0a0a 2020  ategorical',..  
+00000580: 2320 7079 746f 7263 6820 636f 6d70 6174  # pytorch compat
+00000590: 6962 696c 6974 790a 2020 2772 616e 645f  ibility.  'rand_
+000005a0: 6c69 6b65 272c 2027 7261 6e64 696e 745f  like', 'randint_
+000005b0: 6c69 6b65 272c 2027 7261 6e64 6e5f 6c69  like', 'randn_li
+000005c0: 6b65 272c 0a5d 0a0a 0a64 6566 205f 666f  ke',.]...def _fo
+000005d0: 726d 616c 697a 655f 6b65 7928 6b65 7929  rmalize_key(key)
+000005e0: 3a0a 2020 6966 2069 7369 6e73 7461 6e63  :.  if isinstanc
+000005f0: 6528 6b65 792c 2069 6e74 293a 0a20 2020  e(key, int):.   
+00000600: 2072 6574 7572 6e20 6a72 2e50 524e 474b   return jr.PRNGK
+00000610: 6579 286b 6579 290a 2020 656c 6966 2069  ey(key).  elif i
+00000620: 7369 6e73 7461 6e63 6528 6b65 792c 2028  sinstance(key, (
+00000630: 4172 7261 792c 206a 6e70 2e6e 6461 7272  Array, jnp.ndarr
+00000640: 6179 2c20 6e70 2e6e 6461 7272 6179 2929  ay, np.ndarray))
+00000650: 3a0a 2020 2020 6966 206b 6579 2e64 7479  :.    if key.dty
+00000660: 7065 2021 3d20 6a6e 702e 7569 6e74 3332  pe != jnp.uint32
+00000670: 3a0a 2020 2020 2020 7261 6973 6520 5479  :.      raise Ty
+00000680: 7065 4572 726f 7228 276b 6579 206d 7573  peError('key mus
+00000690: 7420 6265 2061 2069 6e74 206f 7220 616e  t be a int or an
+000006a0: 2061 7272 6179 2077 6974 6820 7477 6f20   array with two 
+000006b0: 7569 6e74 3332 2e27 290a 2020 2020 6966  uint32.').    if
+000006c0: 206b 6579 2e73 697a 6520 213d 2032 3a0a   key.size != 2:.
+000006d0: 2020 2020 2020 7261 6973 6520 5479 7065        raise Type
+000006e0: 4572 726f 7228 276b 6579 206d 7573 7420  Error('key must 
+000006f0: 6265 2061 2069 6e74 206f 7220 616e 2061  be a int or an a
+00000700: 7272 6179 2077 6974 6820 7477 6f20 7569  rray with two ui
+00000710: 6e74 3332 2e27 290a 2020 2020 7265 7475  nt32.').    retu
+00000720: 726e 206a 6e70 2e61 7361 7272 6179 286b  rn jnp.asarray(k
+00000730: 6579 290a 2020 656c 7365 3a0a 2020 2020  ey).  else:.    
+00000740: 7261 6973 6520 5479 7065 4572 726f 7228  raise TypeError(
+00000750: 276b 6579 206d 7573 7420 6265 2061 2069  'key must be a i
+00000760: 6e74 206f 7220 616e 2061 7272 6179 2077  nt or an array w
+00000770: 6974 6820 7477 6f20 7569 6e74 3332 2e27  ith two uint32.'
+00000780: 290a 0a0a 6465 6620 5f73 697a 6532 7368  )...def _size2sh
+00000790: 6170 6528 7369 7a65 293a 0a20 2069 6620  ape(size):.  if 
+000007a0: 7369 7a65 2069 7320 4e6f 6e65 3a0a 2020  size is None:.  
+000007b0: 2020 7265 7475 726e 2028 290a 2020 656c    return ().  el
+000007c0: 6966 2069 7369 6e73 7461 6e63 6528 7369  if isinstance(si
+000007d0: 7a65 2c20 696e 7429 3a0a 2020 2020 7265  ze, int):.    re
+000007e0: 7475 726e 2028 7369 7a65 2c29 0a20 2065  turn (size,).  e
+000007f0: 6c69 6620 6973 696e 7374 616e 6365 2873  lif isinstance(s
+00000800: 697a 652c 2028 7475 706c 652c 206c 6973  ize, (tuple, lis
+00000810: 7429 293a 0a20 2020 2072 6574 7572 6e20  t)):.    return 
+00000820: 7475 706c 6528 7369 7a65 290a 2020 656c  tuple(size).  el
+00000830: 7365 3a0a 2020 2020 7261 6973 6520 5661  se:.    raise Va
+00000840: 6c75 6545 7272 6f72 2866 274d 7573 7420  lueError(f'Must 
+00000850: 6265 2061 206c 6973 742f 7475 706c 6520  be a list/tuple 
+00000860: 6f66 2069 6e74 2c20 6275 7420 676f 7420  of int, but got 
+00000870: 7b73 697a 657d 2729 0a0a 0a64 6566 205f  {size}')...def _
+00000880: 6368 6563 6b5f 7368 6170 6528 6e61 6d65  check_shape(name
+00000890: 2c20 7368 6170 652c 202a 7061 7261 6d5f  , shape, *param_
+000008a0: 7368 6170 6573 293a 0a20 2073 6861 7065  shapes):.  shape
+000008b0: 203d 2063 6f72 652e 6173 5f6e 616d 6564   = core.as_named
+000008c0: 5f73 6861 7065 2873 6861 7065 290a 2020  _shape(shape).  
+000008d0: 6966 2070 6172 616d 5f73 6861 7065 733a  if param_shapes:
+000008e0: 0a20 2020 2073 6861 7065 5f20 3d20 6c61  .    shape_ = la
+000008f0: 782e 6272 6f61 6463 6173 745f 7368 6170  x.broadcast_shap
+00000900: 6573 2873 6861 7065 2e70 6f73 6974 696f  es(shape.positio
+00000910: 6e61 6c2c 202a 7061 7261 6d5f 7368 6170  nal, *param_shap
+00000920: 6573 290a 2020 2020 6966 2073 6861 7065  es).    if shape
+00000930: 2e70 6f73 6974 696f 6e61 6c20 213d 2073  .positional != s
+00000940: 6861 7065 5f3a 0a20 2020 2020 206d 7367  hape_:.      msg
+00000950: 203d 2028 227b 7d20 7061 7261 6d65 7465   = ("{} paramete
+00000960: 7220 7368 6170 6573 206d 7573 7420 6265  r shapes must be
+00000970: 2062 726f 6164 6361 7374 2d63 6f6d 7061   broadcast-compa
+00000980: 7469 626c 6520 7769 7468 2073 6861 7065  tible with shape
+00000990: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
+000009a0: 2261 7267 756d 656e 742c 2061 6e64 2074  "argument, and t
+000009b0: 6865 2072 6573 756c 7420 6f66 2062 726f  he result of bro
+000009c0: 6164 6361 7374 696e 6720 7468 6520 7368  adcasting the sh
+000009d0: 6170 6573 206d 7573 7420 6571 7561 6c20  apes must equal 
+000009e0: 220a 2020 2020 2020 2020 2020 2020 2022  ".             "
+000009f0: 7468 6520 7368 6170 6520 6172 6775 6d65  the shape argume
+00000a00: 6e74 2c20 6275 7420 676f 7420 7265 7375  nt, but got resu
+00000a10: 6c74 207b 7d20 666f 7220 7368 6170 6520  lt {} for shape 
+00000a20: 6172 6775 6d65 6e74 207b 7d2e 2229 0a20  argument {}."). 
+00000a30: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+00000a40: 4572 726f 7228 6d73 672e 666f 726d 6174  Error(msg.format
+00000a50: 286e 616d 652c 2073 6861 7065 5f2c 2073  (name, shape_, s
+00000a60: 6861 7065 2929 0a0a 0a64 6566 205f 6173  hape))...def _as
+00000a70: 5f6a 6178 5f61 7272 6179 2861 293a 0a20  _jax_array(a):. 
+00000a80: 2072 6574 7572 6e20 612e 7661 6c75 6520   return a.value 
+00000a90: 6966 2069 7369 6e73 7461 6e63 6528 612c  if isinstance(a,
+00000aa0: 2041 7272 6179 2920 656c 7365 2061 0a0a   Array) else a..
+00000ab0: 0a64 6566 205f 6973 5f70 7974 686f 6e5f  .def _is_python_
+00000ac0: 7363 616c 6172 2878 293a 0a20 2069 6620  scalar(x):.  if 
+00000ad0: 6861 7361 7474 7228 782c 2027 6176 616c  hasattr(x, 'aval
+00000ae0: 2729 3a0a 2020 2020 7265 7475 726e 2078  '):.    return x
+00000af0: 2e61 7661 6c2e 7765 616b 5f74 7970 650a  .aval.weak_type.
+00000b00: 2020 656c 6966 206e 702e 6e64 696d 2878    elif np.ndim(x
+00000b10: 2920 3d3d 2030 3a0a 2020 2020 7265 7475  ) == 0:.    retu
+00000b20: 726e 2054 7275 650a 2020 656c 6966 2069  rn True.  elif i
+00000b30: 7369 6e73 7461 6e63 6528 782c 2028 626f  sinstance(x, (bo
+00000b40: 6f6c 2c20 696e 742c 2066 6c6f 6174 2c20  ol, int, float, 
+00000b50: 636f 6d70 6c65 7829 293a 0a20 2020 2072  complex)):.    r
+00000b60: 6574 7572 6e20 5472 7565 0a20 2065 6c73  eturn True.  els
+00000b70: 653a 0a20 2020 2072 6574 7572 6e20 4661  e:.    return Fa
+00000b80: 6c73 650a 0a0a 7079 7468 6f6e 5f73 6361  lse...python_sca
+00000b90: 6c61 725f 6474 7970 6573 203d 207b 0a20  lar_dtypes = {. 
+00000ba0: 2062 6f6f 6c3a 206e 702e 6474 7970 6528   bool: np.dtype(
+00000bb0: 2762 6f6f 6c27 292c 0a20 2069 6e74 3a20  'bool'),.  int: 
+00000bc0: 6e70 2e64 7479 7065 2827 696e 7436 3427  np.dtype('int64'
+00000bd0: 292c 0a20 2066 6c6f 6174 3a20 6e70 2e64  ),.  float: np.d
+00000be0: 7479 7065 2827 666c 6f61 7436 3427 292c  type('float64'),
+00000bf0: 0a20 2063 6f6d 706c 6578 3a20 6e70 2e64  .  complex: np.d
+00000c00: 7479 7065 2827 636f 6d70 6c65 7831 3238  type('complex128
+00000c10: 2729 2c0a 7d0a 0a0a 6465 6620 5f64 7479  '),.}...def _dty
+00000c20: 7065 2878 2c20 2a2c 2063 616e 6f6e 6963  pe(x, *, canonic
+00000c30: 616c 697a 653a 2062 6f6f 6c20 3d20 4661  alize: bool = Fa
+00000c40: 6c73 6529 3a0a 2020 2222 2252 6574 7572  lse):.  """Retur
+00000c50: 6e20 7468 6520 6474 7970 6520 6f62 6a65  n the dtype obje
+00000c60: 6374 2066 6f72 2061 2076 616c 7565 206f  ct for a value o
+00000c70: 7220 7479 7065 2c20 6f70 7469 6f6e 616c  r type, optional
+00000c80: 6c79 2063 616e 6f6e 6963 616c 697a 6564  ly canonicalized
+00000c90: 2062 6173 6564 206f 6e20 5836 3420 6d6f   based on X64 mo
+00000ca0: 6465 2e22 2222 0a20 2069 6620 7820 6973  de.""".  if x is
+00000cb0: 204e 6f6e 653a 0a20 2020 2072 6169 7365   None:.    raise
+00000cc0: 2056 616c 7565 4572 726f 7228 6622 496e   ValueError(f"In
+00000cd0: 7661 6c69 6420 6172 6775 6d65 6e74 2074  valid argument t
+00000ce0: 6f20 6474 7970 653a 207b 787d 2e22 290a  o dtype: {x}.").
+00000cf0: 2020 656c 6966 2069 7369 6e73 7461 6e63    elif isinstanc
+00000d00: 6528 782c 2074 7970 6529 2061 6e64 2078  e(x, type) and x
+00000d10: 2069 6e20 7079 7468 6f6e 5f73 6361 6c61   in python_scala
+00000d20: 725f 6474 7970 6573 3a0a 2020 2020 6474  r_dtypes:.    dt
+00000d30: 203d 2070 7974 686f 6e5f 7363 616c 6172   = python_scalar
+00000d40: 5f64 7479 7065 735b 785d 0a20 2065 6c69  _dtypes[x].  eli
+00000d50: 6620 7479 7065 2878 2920 696e 2070 7974  f type(x) in pyt
+00000d60: 686f 6e5f 7363 616c 6172 5f64 7479 7065  hon_scalar_dtype
+00000d70: 733a 0a20 2020 2064 7420 3d20 7079 7468  s:.    dt = pyth
+00000d80: 6f6e 5f73 6361 6c61 725f 6474 7970 6573  on_scalar_dtypes
+00000d90: 5b74 7970 6528 7829 5d0a 2020 656c 6966  [type(x)].  elif
+00000da0: 206a 6178 2e63 6f72 652e 6973 5f6f 7061   jax.core.is_opa
+00000db0: 7175 655f 6474 7970 6528 6765 7461 7474  que_dtype(getatt
+00000dc0: 7228 782c 2027 6474 7970 6527 2c20 4e6f  r(x, 'dtype', No
+00000dd0: 6e65 2929 3a0a 2020 2020 6474 203d 2078  ne)):.    dt = x
+00000de0: 2e64 7479 7065 0a20 2065 6c73 653a 0a20  .dtype.  else:. 
+00000df0: 2020 2064 7420 3d20 6e70 2e72 6573 756c     dt = np.resul
+00000e00: 745f 7479 7065 2878 290a 2020 7265 7475  t_type(x).  retu
+00000e10: 726e 2064 7479 7065 732e 6361 6e6f 6e69  rn dtypes.canoni
+00000e20: 6361 6c69 7a65 5f64 7479 7065 2864 7429  calize_dtype(dt)
+00000e30: 2069 6620 6361 6e6f 6e69 6361 6c69 7a65   if canonicalize
+00000e40: 2065 6c73 6520 6474 0a0a 0a64 6566 205f   else dt...def _
+00000e50: 636f 6e73 7428 6578 616d 706c 652c 2076  const(example, v
+00000e60: 616c 293a 0a20 2069 6620 5f69 735f 7079  al):.  if _is_py
+00000e70: 7468 6f6e 5f73 6361 6c61 7228 6578 616d  thon_scalar(exam
+00000e80: 706c 6529 3a0a 2020 2020 6474 7970 6520  ple):.    dtype 
+00000e90: 3d20 6474 7970 6573 2e63 616e 6f6e 6963  = dtypes.canonic
+00000ea0: 616c 697a 655f 6474 7970 6528 7479 7065  alize_dtype(type
+00000eb0: 2865 7861 6d70 6c65 2929 0a20 2020 2076  (example)).    v
+00000ec0: 616c 203d 2064 7479 7065 732e 7363 616c  al = dtypes.scal
+00000ed0: 6172 5f74 7970 655f 6f66 2865 7861 6d70  ar_type_of(examp
+00000ee0: 6c65 2928 7661 6c29 0a20 2020 2072 6574  le)(val).    ret
+00000ef0: 7572 6e20 7661 6c20 6966 2064 7479 7065  urn val if dtype
+00000f00: 203d 3d20 5f64 7479 7065 2876 616c 2c20   == _dtype(val, 
+00000f10: 6361 6e6f 6e69 6361 6c69 7a65 3d54 7275  canonicalize=Tru
+00000f20: 6529 2065 6c73 6520 6e70 2e61 7272 6179  e) else np.array
+00000f30: 2876 616c 2c20 6474 7970 6529 0a20 2065  (val, dtype).  e
+00000f40: 6c73 653a 0a20 2020 2064 7479 7065 203d  lse:.    dtype =
+00000f50: 2064 7479 7065 732e 6361 6e6f 6e69 6361   dtypes.canonica
+00000f60: 6c69 7a65 5f64 7479 7065 2865 7861 6d70  lize_dtype(examp
+00000f70: 6c65 2e64 7479 7065 290a 2020 7265 7475  le.dtype).  retu
+00000f80: 726e 206e 702e 6172 7261 7928 7661 6c2c  rn np.array(val,
+00000f90: 2064 7479 7065 290a 0a0a 5f74 725f 7061   dtype)..._tr_pa
+00000fa0: 7261 6d73 203d 206e 616d 6564 7475 706c  rams = namedtupl
+00000fb0: 6528 0a20 2022 7472 5f70 6172 616d 7322  e(.  "tr_params"
+00000fc0: 2c20 5b22 6322 2c20 2262 222c 2022 6122  , ["c", "b", "a"
+00000fd0: 2c20 2261 6c70 6861 222c 2022 755f 7222  , "alpha", "u_r"
+00000fe0: 2c20 2276 5f72 222c 2022 6d22 2c20 226c  , "v_r", "m", "l
+00000ff0: 6f67 5f70 222c 2022 6c6f 6731 5f70 222c  og_p", "log1_p",
+00001000: 2022 6c6f 675f 6822 5d0a 290a 0a0a 6465   "log_h"].)...de
+00001010: 6620 5f67 6574 5f74 725f 7061 7261 6d73  f _get_tr_params
+00001020: 286e 2c20 7029 3a0a 2020 2320 5365 6520  (n, p):.  # See 
+00001030: 5461 626c 6520 312e 2041 6464 6974 696f  Table 1. Additio
+00001040: 6e61 6c6c 792c 2077 6520 7072 652d 636f  nally, we pre-co
+00001050: 6d70 7574 6520 6c6f 6728 7029 2c20 6c6f  mpute log(p), lo
+00001060: 6731 282d 7029 2061 6e64 2074 6865 0a20  g1(-p) and the. 
+00001070: 2023 2063 6f6e 7374 616e 7420 7465 726d   # constant term
+00001080: 732c 2074 6861 7420 6465 7065 6e64 206f  s, that depend o
+00001090: 6e6c 7920 6f6e 2028 6e2c 2070 2c20 6d29  nly on (n, p, m)
+000010a0: 2069 6e20 6c6f 6728 6628 6b29 2920 2862   in log(f(k)) (b
+000010b0: 6f74 746f 6d20 6f66 2070 6167 6520 3529  ottom of page 5)
+000010c0: 2e0a 2020 6d75 203d 206e 202a 2070 0a20  ..  mu = n * p. 
+000010d0: 2073 7071 203d 206a 6e70 2e73 7172 7428   spq = jnp.sqrt(
+000010e0: 6d75 202a 2028 3120 2d20 7029 290a 2020  mu * (1 - p)).  
+000010f0: 6320 3d20 6d75 202b 2030 2e35 0a20 2062  c = mu + 0.5.  b
+00001100: 203d 2031 2e31 3520 2b20 322e 3533 202a   = 1.15 + 2.53 *
+00001110: 2073 7071 0a20 2061 203d 202d 302e 3038   spq.  a = -0.08
+00001120: 3733 202b 2030 2e30 3234 3820 2a20 6220  73 + 0.0248 * b 
+00001130: 2b20 302e 3031 202a 2070 0a20 2061 6c70  + 0.01 * p.  alp
+00001140: 6861 203d 2028 322e 3833 202b 2035 2e31  ha = (2.83 + 5.1
+00001150: 202f 2062 2920 2a20 7370 710a 2020 755f   / b) * spq.  u_
+00001160: 7220 3d20 302e 3433 0a20 2076 5f72 203d  r = 0.43.  v_r =
+00001170: 2030 2e39 3220 2d20 342e 3220 2f20 620a   0.92 - 4.2 / b.
+00001180: 2020 6d20 3d20 6a6e 702e 666c 6f6f 7228    m = jnp.floor(
+00001190: 286e 202b 2031 2920 2a20 7029 2e61 7374  (n + 1) * p).ast
+000011a0: 7970 6528 6e2e 6474 7970 6529 0a20 206c  ype(n.dtype).  l
+000011b0: 6f67 5f70 203d 206a 6e70 2e6c 6f67 2870  og_p = jnp.log(p
+000011c0: 290a 2020 6c6f 6731 5f70 203d 206a 6e70  ).  log1_p = jnp
+000011d0: 2e6c 6f67 3170 282d 7029 0a20 206c 6f67  .log1p(-p).  log
+000011e0: 5f68 203d 2028 286d 202b 2030 2e35 2920  _h = ((m + 0.5) 
+000011f0: 2a20 286a 6e70 2e6c 6f67 2828 6d20 2b20  * (jnp.log((m + 
+00001200: 312e 3029 202f 2028 6e20 2d20 6d20 2b20  1.0) / (n - m + 
+00001210: 312e 3029 2920 2b20 6c6f 6731 5f70 202d  1.0)) + log1_p -
+00001220: 206c 6f67 5f70 2920 2b0a 2020 2020 2020   log_p) +.      
+00001230: 2020 2020 205f 7374 6972 6c69 6e67 5f61       _stirling_a
+00001240: 7070 726f 785f 7461 696c 286d 2920 2b20  pprox_tail(m) + 
+00001250: 5f73 7469 726c 696e 675f 6170 7072 6f78  _stirling_approx
+00001260: 5f74 6169 6c28 6e20 2d20 6d29 290a 2020  _tail(n - m)).  
+00001270: 7265 7475 726e 205f 7472 5f70 6172 616d  return _tr_param
+00001280: 7328 632c 2062 2c20 612c 2061 6c70 6861  s(c, b, a, alpha
+00001290: 2c20 755f 722c 2076 5f72 2c20 6d2c 206c  , u_r, v_r, m, l
+000012a0: 6f67 5f70 2c20 6c6f 6731 5f70 2c20 6c6f  og_p, log1_p, lo
+000012b0: 675f 6829 0a0a 0a64 6566 205f 7374 6972  g_h)...def _stir
+000012c0: 6c69 6e67 5f61 7070 726f 785f 7461 696c  ling_approx_tail
+000012d0: 286b 293a 0a20 2070 7265 636f 6d70 7574  (k):.  precomput
+000012e0: 6564 203d 206a 6e70 2e61 7272 6179 285b  ed = jnp.array([
+000012f0: 302e 3038 3130 3631 3436 3637 3935 3332  0.08106146679532
+00001300: 3732 362c 0a20 2020 2020 2020 2020 2020  726,.           
 00001310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001320: 2020 2020 2020 2020 2030 2e30 3431 3334           0.04134
-00001330: 3036 3935 3935 3534 3039 3239 2c0a 2020  069595540929,.  
+00001320: 302e 3034 3133 3430 3639 3539 3535 3430  0.04134069595540
+00001330: 3932 392c 0a20 2020 2020 2020 2020 2020  929,.           
 00001340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001350: 2020 2020 2020 2020 2030 2e30 3237 3637           0.02767
-00001360: 3739 3235 3638 3439 3938 3334 2c0a 2020  792568499834,.  
+00001350: 302e 3032 3736 3737 3932 3536 3834 3939  0.02767792568499
+00001360: 3833 342c 0a20 2020 2020 2020 2020 2020  834,.           
 00001370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001380: 2020 2020 2020 2020 2030 2e30 3230 3739           0.02079
-00001390: 3036 3732 3130 3337 3635 3039 2c0a 2020  067210376509,.  
+00001380: 302e 3032 3037 3930 3637 3231 3033 3736  0.02079067210376
+00001390: 3530 392c 0a20 2020 2020 2020 2020 2020  509,.           
 000013a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000013b0: 2020 2020 2020 2020 2030 2e30 3136 3634           0.01664
-000013c0: 3436 3931 3138 3938 3231 3139 2c0a 2020  469118982119,.  
+000013b0: 302e 3031 3636 3434 3639 3131 3839 3832  0.01664469118982
+000013c0: 3131 392c 0a20 2020 2020 2020 2020 2020  119,.           
 000013d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000013e0: 2020 2020 2020 2020 2030 2e30 3133 3837           0.01387
-000013f0: 3631 3238 3832 3330 3730 3735 2c0a 2020  612882307075,.  
+000013e0: 302e 3031 3338 3736 3132 3838 3233 3037  0.01387612882307
+000013f0: 3037 352c 0a20 2020 2020 2020 2020 2020  075,.           
 00001400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001410: 2020 2020 2020 2020 2030 2e30 3131 3839           0.01189
-00001420: 3637 3039 3934 3538 3931 3737 2c0a 2020  670994589177,.  
+00001410: 302e 3031 3138 3936 3730 3939 3435 3839  0.01189670994589
+00001420: 3137 372c 0a20 2020 2020 2020 2020 2020  177,.           
 00001430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001440: 2020 2020 2020 2020 2030 2e30 3130 3431           0.01041
-00001450: 3132 3635 3236 3139 3732 3039 2c0a 2020  126526197209,.  
+00001440: 302e 3031 3034 3131 3236 3532 3631 3937  0.01041126526197
+00001450: 3230 392c 0a20 2020 2020 2020 2020 2020  209,.           
 00001460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001470: 2020 2020 2020 2020 2030 2e30 3039 3235           0.00925
-00001480: 3534 3632 3138 3237 3132 3733 332c 0a20  5462182712733,. 
+00001470: 302e 3030 3932 3535 3436 3231 3832 3731  0.00925546218271
+00001480: 3237 3333 2c0a 2020 2020 2020 2020 2020  2733,.          
 00001490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000014a0: 2020 2020 2020 2020 2020 302e 3030 3833            0.0083
-000014b0: 3330 3536 3334 3333 3336 3238 3731 2c20  30563433362871, 
-000014c0: 5d29 0a20 206b 7031 203d 206b 202b 2031  ]).  kp1 = k + 1
-000014d0: 0a20 206b 7031 7371 203d 2028 6b20 2b20  .  kp1sq = (k + 
-000014e0: 3129 202a 2a20 320a 2020 7265 7475 726e  1) ** 2.  return
-000014f0: 206a 6e70 2e77 6865 7265 286b 203c 2031   jnp.where(k < 1
-00001500: 302c 0a20 2020 2020 2020 2020 2020 2020  0,.             
-00001510: 2020 2020 2020 7072 6563 6f6d 7075 7465        precompute
-00001520: 645b 6b5d 2c0a 2020 2020 2020 2020 2020  d[k],.          
-00001530: 2020 2020 2020 2020 2028 312e 3020 2f20           (1.0 / 
-00001540: 3132 202d 2028 312e 3020 2f20 3336 3020  12 - (1.0 / 360 
-00001550: 2d20 2831 2e30 202f 2031 3236 3029 202f  - (1.0 / 1260) /
-00001560: 206b 7031 7371 2920 2f20 6b70 3173 7129   kp1sq) / kp1sq)
-00001570: 202f 206b 7031 290a 0a0a 6465 6620 5f62   / kp1)...def _b
-00001580: 696e 6f6d 6961 6c5f 6274 7273 286b 6579  inomial_btrs(key
-00001590: 2c20 702c 206e 293a 0a20 2022 2222 0a20  , p, n):.  """. 
-000015a0: 2042 6173 6564 206f 6e20 7468 6520 7472   Based on the tr
-000015b0: 616e 7366 6f72 6d65 6420 7265 6a65 6374  ansformed reject
-000015c0: 696f 6e20 7361 6d70 6c69 6e67 2061 6c67  ion sampling alg
-000015d0: 6f72 6974 686d 2028 4254 5253 2920 6672  orithm (BTRS) fr
-000015e0: 6f6d 2074 6865 0a20 2066 6f6c 6c6f 7769  om the.  followi
-000015f0: 6e67 2072 6566 6572 656e 6365 3a0a 0a20  ng reference:.. 
-00001600: 2048 6f72 6d61 6e6e 2c20 2254 6865 2047   Hormann, "The G
-00001610: 656e 6572 6174 696f 6e20 6f66 2042 696e  eneration of Bin
-00001620: 6f6e 6d69 616c 2052 616e 646f 6d20 5661  onmial Random Va
-00001630: 7269 6174 6573 220a 2020 2868 7474 7073  riates".  (https
-00001640: 3a2f 2f63 6f72 652e 6163 2e75 6b2f 646f  ://core.ac.uk/do
-00001650: 776e 6c6f 6164 2f70 6466 2f31 3130 3037  wnload/pdf/11007
-00001660: 3235 342e 7064 6629 0a20 2022 2222 0a0a  254.pdf).  """..
-00001670: 2020 6465 6620 5f62 7472 735f 626f 6479    def _btrs_body
-00001680: 5f66 6e28 7661 6c29 3a0a 2020 2020 5f2c  _fn(val):.    _,
-00001690: 206b 6579 2c20 5f2c 205f 203d 2076 616c   key, _, _ = val
-000016a0: 0a20 2020 206b 6579 2c20 6b65 795f 752c  .    key, key_u,
-000016b0: 206b 6579 5f76 203d 206a 722e 7370 6c69   key_v = jr.spli
-000016c0: 7428 6b65 792c 2033 290a 2020 2020 7520  t(key, 3).    u 
-000016d0: 3d20 6a72 2e75 6e69 666f 726d 286b 6579  = jr.uniform(key
-000016e0: 5f75 290a 2020 2020 7620 3d20 6a72 2e75  _u).    v = jr.u
-000016f0: 6e69 666f 726d 286b 6579 5f76 290a 2020  niform(key_v).  
-00001700: 2020 7520 3d20 7520 2d20 302e 350a 2020    u = u - 0.5.  
-00001710: 2020 6b20 3d20 6a6e 702e 666c 6f6f 7228    k = jnp.floor(
-00001720: 0a20 2020 2020 2028 3220 2a20 7472 5f70  .      (2 * tr_p
-00001730: 6172 616d 732e 6120 2f20 2830 2e35 202d  arams.a / (0.5 -
-00001740: 206a 6e70 2e61 6273 2875 2929 202b 2074   jnp.abs(u)) + t
-00001750: 725f 7061 7261 6d73 2e62 2920 2a20 7520  r_params.b) * u 
-00001760: 2b20 7472 5f70 6172 616d 732e 630a 2020  + tr_params.c.  
-00001770: 2020 292e 6173 7479 7065 286e 2e64 7479    ).astype(n.dty
-00001780: 7065 290a 2020 2020 7265 7475 726e 206b  pe).    return k
-00001790: 2c20 6b65 792c 2075 2c20 760a 0a20 2064  , key, u, v..  d
-000017a0: 6566 205f 6274 7273 5f63 6f6e 645f 666e  ef _btrs_cond_fn
-000017b0: 2876 616c 293a 0a20 2020 2064 6566 2061  (val):.    def a
-000017c0: 6363 6570 745f 666e 286b 2c20 752c 2076  ccept_fn(k, u, v
-000017d0: 293a 0a20 2020 2020 2023 2053 6565 2061  ):.      # See a
-000017e0: 6363 6570 7461 6e63 6520 636f 6e64 6974  cceptance condit
-000017f0: 696f 6e20 696e 2053 7465 7020 332e 2028  ion in Step 3. (
-00001800: 5061 6765 2033 2920 6f66 2054 5253 2061  Page 3) of TRS a
-00001810: 6c67 6f72 6974 686d 0a20 2020 2020 2023  lgorithm.      #
-00001820: 2076 203c 3d20 6628 6b29 202a 2067 5f67   v <= f(k) * g_g
-00001830: 7261 6428 7529 202f 2061 6c70 6861 0a0a  rad(u) / alpha..
-00001840: 2020 2020 2020 6d20 3d20 7472 5f70 6172        m = tr_par
-00001850: 616d 732e 6d0a 2020 2020 2020 6c6f 675f  ams.m.      log_
-00001860: 7020 3d20 7472 5f70 6172 616d 732e 6c6f  p = tr_params.lo
-00001870: 675f 700a 2020 2020 2020 6c6f 6731 5f70  g_p.      log1_p
-00001880: 203d 2074 725f 7061 7261 6d73 2e6c 6f67   = tr_params.log
-00001890: 315f 700a 2020 2020 2020 2320 5365 653a  1_p.      # See:
-000018a0: 2066 6f72 6d75 6c61 2066 6f72 206c 6f67   formula for log
-000018b0: 2866 286b 2929 2061 7420 626f 7474 6f6d  (f(k)) at bottom
-000018c0: 206f 6620 5061 6765 2035 2e0a 2020 2020   of Page 5..    
-000018d0: 2020 6c6f 675f 6620 3d20 280a 2020 2020    log_f = (.    
-000018e0: 2020 2020 2020 286e 202b 2031 2e30 2920        (n + 1.0) 
-000018f0: 2a20 6a6e 702e 6c6f 6728 286e 202d 206d  * jnp.log((n - m
-00001900: 202b 2031 2e30 2920 2f20 286e 202d 206b   + 1.0) / (n - k
-00001910: 202b 2031 2e30 2929 0a20 2020 2020 2020   + 1.0)).       
-00001920: 2020 202b 2028 6b20 2b20 302e 3529 202a     + (k + 0.5) *
-00001930: 2028 6a6e 702e 6c6f 6728 286e 202d 206b   (jnp.log((n - k
-00001940: 202b 2031 2e30 2920 2f20 286b 202b 2031   + 1.0) / (k + 1
-00001950: 2e30 2929 202b 206c 6f67 5f70 202d 206c  .0)) + log_p - l
-00001960: 6f67 315f 7029 0a20 2020 2020 2020 2020  og1_p).         
-00001970: 202b 2028 5f73 7469 726c 696e 675f 6170   + (_stirling_ap
-00001980: 7072 6f78 5f74 6169 6c28 6b29 202d 205f  prox_tail(k) - _
-00001990: 7374 6972 6c69 6e67 5f61 7070 726f 785f  stirling_approx_
-000019a0: 7461 696c 286e 202d 206b 2929 0a20 2020  tail(n - k)).   
-000019b0: 2020 2020 2020 202b 2074 725f 7061 7261         + tr_para
-000019c0: 6d73 2e6c 6f67 5f68 0a20 2020 2020 2029  ms.log_h.      )
-000019d0: 0a20 2020 2020 2067 203d 2028 7472 5f70  .      g = (tr_p
-000019e0: 6172 616d 732e 6120 2f20 2830 2e35 202d  arams.a / (0.5 -
-000019f0: 206a 6e70 2e61 6273 2875 2929 202a 2a20   jnp.abs(u)) ** 
-00001a00: 3229 202b 2074 725f 7061 7261 6d73 2e62  2) + tr_params.b
-00001a10: 0a20 2020 2020 2072 6574 7572 6e20 6a6e  .      return jn
-00001a20: 702e 6c6f 6728 2876 202a 2074 725f 7061  p.log((v * tr_pa
-00001a30: 7261 6d73 2e61 6c70 6861 2920 2f20 6729  rams.alpha) / g)
-00001a40: 203c 3d20 6c6f 675f 660a 0a20 2020 206b   <= log_f..    k
-00001a50: 2c20 6b65 792c 2075 2c20 7620 3d20 7661  , key, u, v = va
-00001a60: 6c0a 2020 2020 6561 726c 795f 6163 6365  l.    early_acce
-00001a70: 7074 203d 2028 6a6e 702e 6162 7328 7529  pt = (jnp.abs(u)
-00001a80: 203c 3d20 7472 5f70 6172 616d 732e 755f   <= tr_params.u_
-00001a90: 7229 2026 2028 7620 3c3d 2074 725f 7061  r) & (v <= tr_pa
-00001aa0: 7261 6d73 2e76 5f72 290a 2020 2020 6561  rams.v_r).    ea
-00001ab0: 726c 795f 7265 6a65 6374 203d 2028 6b20  rly_reject = (k 
-00001ac0: 3c20 3029 207c 2028 6b20 3e20 6e29 0a20  < 0) | (k > n). 
-00001ad0: 2020 2072 6574 7572 6e20 6c61 782e 636f     return lax.co
-00001ae0: 6e64 280a 2020 2020 2020 6561 726c 795f  nd(.      early_
-00001af0: 6163 6365 7074 207c 2065 6172 6c79 5f72  accept | early_r
-00001b00: 656a 6563 742c 0a20 2020 2020 2028 292c  eject,.      (),
-00001b10: 0a20 2020 2020 206c 616d 6264 6120 5f3a  .      lambda _:
-00001b20: 207e 6561 726c 795f 6163 6365 7074 2c0a   ~early_accept,.
-00001b30: 2020 2020 2020 286b 2c20 752c 2076 292c        (k, u, v),
-00001b40: 0a20 2020 2020 206c 616d 6264 6120 783a  .      lambda x:
-00001b50: 207e 6163 6365 7074 5f66 6e28 2a78 292c   ~accept_fn(*x),
-00001b60: 0a20 2020 2029 0a0a 2020 7472 5f70 6172  .    )..  tr_par
-00001b70: 616d 7320 3d20 5f67 6574 5f74 725f 7061  ams = _get_tr_pa
-00001b80: 7261 6d73 286e 2c20 7029 0a20 2072 6574  rams(n, p).  ret
-00001b90: 203d 206c 6178 2e77 6869 6c65 5f6c 6f6f   = lax.while_loo
-00001ba0: 7028 0a20 2020 205f 6274 7273 5f63 6f6e  p(.    _btrs_con
-00001bb0: 645f 666e 2c20 5f62 7472 735f 626f 6479  d_fn, _btrs_body
-00001bc0: 5f66 6e2c 2028 2d31 2c20 6b65 792c 2031  _fn, (-1, key, 1
-00001bd0: 2e30 2c20 312e 3029 0a20 2029 2020 2320  .0, 1.0).  )  # 
-00001be0: 7573 6520 6b3d 2d31 2069 6e69 7469 616c  use k=-1 initial
-00001bf0: 6c79 2073 6f20 7468 6174 2063 6f6e 645f  ly so that cond_
-00001c00: 666e 2072 6574 7572 6e73 2054 7275 650a  fn returns True.
-00001c10: 2020 7265 7475 726e 2072 6574 5b30 5d0a    return ret[0].
-00001c20: 0a0a 6465 6620 5f62 696e 6f6d 6961 6c5f  ..def _binomial_
-00001c30: 696e 7665 7273 696f 6e28 6b65 792c 2070  inversion(key, p
-00001c40: 2c20 6e29 3a0a 2020 6465 6620 5f62 696e  , n):.  def _bin
-00001c50: 6f6d 5f69 6e76 5f62 6f64 795f 666e 2876  om_inv_body_fn(v
-00001c60: 616c 293a 0a20 2020 2069 2c20 6b65 792c  al):.    i, key,
-00001c70: 2067 656f 6d5f 6163 6320 3d20 7661 6c0a   geom_acc = val.
-00001c80: 2020 2020 6b65 792c 206b 6579 5f75 203d      key, key_u =
-00001c90: 206a 722e 7370 6c69 7428 6b65 7929 0a20   jr.split(key). 
-00001ca0: 2020 2075 203d 206a 722e 756e 6966 6f72     u = jr.unifor
-00001cb0: 6d28 6b65 795f 7529 0a20 2020 2067 656f  m(key_u).    geo
-00001cc0: 6d20 3d20 6a6e 702e 666c 6f6f 7228 6a6e  m = jnp.floor(jn
-00001cd0: 702e 6c6f 6731 7028 2d75 2920 2f20 6c6f  p.log1p(-u) / lo
-00001ce0: 6731 5f70 2920 2b20 310a 2020 2020 6765  g1_p) + 1.    ge
-00001cf0: 6f6d 5f61 6363 203d 2067 656f 6d5f 6163  om_acc = geom_ac
-00001d00: 6320 2b20 6765 6f6d 0a20 2020 2072 6574  c + geom.    ret
-00001d10: 7572 6e20 6920 2b20 312c 206b 6579 2c20  urn i + 1, key, 
-00001d20: 6765 6f6d 5f61 6363 0a0a 2020 6465 6620  geom_acc..  def 
-00001d30: 5f62 696e 6f6d 5f69 6e76 5f63 6f6e 645f  _binom_inv_cond_
-00001d40: 666e 2876 616c 293a 0a20 2020 2069 2c20  fn(val):.    i, 
-00001d50: 5f2c 2067 656f 6d5f 6163 6320 3d20 7661  _, geom_acc = va
-00001d60: 6c0a 2020 2020 7265 7475 726e 2067 656f  l.    return geo
-00001d70: 6d5f 6163 6320 3c3d 206e 0a0a 2020 6c6f  m_acc <= n..  lo
-00001d80: 6731 5f70 203d 206a 6e70 2e6c 6f67 3170  g1_p = jnp.log1p
-00001d90: 282d 7029 0a20 2072 6574 203d 206c 6178  (-p).  ret = lax
-00001da0: 2e77 6869 6c65 5f6c 6f6f 7028 5f62 696e  .while_loop(_bin
-00001db0: 6f6d 5f69 6e76 5f63 6f6e 645f 666e 2c20  om_inv_cond_fn, 
-00001dc0: 5f62 696e 6f6d 5f69 6e76 5f62 6f64 795f  _binom_inv_body_
-00001dd0: 666e 2c20 282d 312c 206b 6579 2c20 302e  fn, (-1, key, 0.
-00001de0: 3029 290a 2020 7265 7475 726e 2072 6574  0)).  return ret
-00001df0: 5b30 5d0a 0a0a 6465 6620 5f62 696e 6f6d  [0]...def _binom
-00001e00: 6961 6c5f 6469 7370 6174 6368 286b 6579  ial_dispatch(key
-00001e10: 2c20 702c 206e 293a 0a20 2064 6566 2064  , p, n):.  def d
-00001e20: 6973 7061 7463 6828 6b65 792c 2070 2c20  ispatch(key, p, 
-00001e30: 6e29 3a0a 2020 2020 6973 5f6c 655f 6d69  n):.    is_le_mi
-00001e40: 6420 3d20 7020 3c3d 2030 2e35 0a20 2020  d = p <= 0.5.   
-00001e50: 2070 7120 3d20 6a6e 702e 7768 6572 6528   pq = jnp.where(
-00001e60: 6973 5f6c 655f 6d69 642c 2070 2c20 3120  is_le_mid, p, 1 
-00001e70: 2d20 7029 0a20 2020 206d 7520 3d20 6e20  - p).    mu = n 
-00001e80: 2a20 7071 0a20 2020 206b 203d 206c 6178  * pq.    k = lax
-00001e90: 2e63 6f6e 6428 0a20 2020 2020 206d 7520  .cond(.      mu 
-00001ea0: 3c20 3130 2c0a 2020 2020 2020 286b 6579  < 10,.      (key
-00001eb0: 2c20 7071 2c20 6e29 2c0a 2020 2020 2020  , pq, n),.      
-00001ec0: 6c61 6d62 6461 2078 3a20 5f62 696e 6f6d  lambda x: _binom
-00001ed0: 6961 6c5f 696e 7665 7273 696f 6e28 2a78  ial_inversion(*x
-00001ee0: 292c 0a20 2020 2020 2028 6b65 792c 2070  ),.      (key, p
-00001ef0: 712c 206e 292c 0a20 2020 2020 206c 616d  q, n),.      lam
-00001f00: 6264 6120 783a 205f 6269 6e6f 6d69 616c  bda x: _binomial
-00001f10: 5f62 7472 7328 2a78 292c 0a20 2020 2029  _btrs(*x),.    )
-00001f20: 0a20 2020 2072 6574 7572 6e20 6a6e 702e  .    return jnp.
-00001f30: 7768 6572 6528 6973 5f6c 655f 6d69 642c  where(is_le_mid,
-00001f40: 206b 2c20 6e20 2d20 6b29 0a0a 2020 2320   k, n - k)..  # 
-00001f50: 5265 7475 726e 2030 2066 6f72 206e 616e  Return 0 for nan
-00001f60: 2060 7060 206f 7220 6e65 6761 7469 7665   `p` or negative
-00001f70: 2060 6e60 2c20 7369 6e63 6520 6e61 6e20   `n`, since nan 
-00001f80: 7661 6c75 6573 2061 7265 206e 6f74 2061  values are not a
-00001f90: 6c6c 6f77 6564 2066 6f72 2069 6e74 6567  llowed for integ
-00001fa0: 6572 2074 7970 6573 0a20 2063 6f6e 6430  er types.  cond0
-00001fb0: 203d 206a 6e70 2e69 7366 696e 6974 6528   = jnp.isfinite(
-00001fc0: 7029 2026 2028 6e20 3e20 3029 2026 2028  p) & (n > 0) & (
-00001fd0: 7020 3e20 3029 0a20 2072 6574 7572 6e20  p > 0).  return 
-00001fe0: 6c61 782e 636f 6e64 280a 2020 2020 636f  lax.cond(.    co
-00001ff0: 6e64 3020 2620 2870 203c 2031 292c 0a20  nd0 & (p < 1),. 
-00002000: 2020 2028 6b65 792c 2070 2c20 6e29 2c0a     (key, p, n),.
-00002010: 2020 2020 6c61 6d62 6461 2078 3a20 6469      lambda x: di
-00002020: 7370 6174 6368 282a 7829 2c0a 2020 2020  spatch(*x),.    
-00002030: 2829 2c0a 2020 2020 6c61 6d62 6461 205f  (),.    lambda _
-00002040: 3a20 6a6e 702e 7768 6572 6528 636f 6e64  : jnp.where(cond
-00002050: 302c 206e 2c20 3029 2c0a 2020 290a 0a0a  0, n, 0),.  )...
-00002060: 4070 6172 7469 616c 286a 6974 2c20 7374  @partial(jit, st
-00002070: 6174 6963 5f61 7267 6e75 6d73 3d28 332c  atic_argnums=(3,
-00002080: 2929 0a64 6566 205f 6269 6e6f 6d69 616c  )).def _binomial
-00002090: 286b 6579 2c20 702c 206e 2c20 7368 6170  (key, p, n, shap
-000020a0: 6529 3a0a 2020 7368 6170 6520 3d20 7368  e):.  shape = sh
-000020b0: 6170 6520 6f72 206c 6178 2e62 726f 6164  ape or lax.broad
-000020c0: 6361 7374 5f73 6861 7065 7328 6a6e 702e  cast_shapes(jnp.
-000020d0: 7368 6170 6528 7029 2c20 6a6e 702e 7368  shape(p), jnp.sh
-000020e0: 6170 6528 6e29 290a 2020 2320 7265 7368  ape(n)).  # resh
-000020f0: 6170 6520 746f 206d 6170 206f 7665 7220  ape to map over 
-00002100: 6178 6973 2030 0a20 2070 203d 206a 6e70  axis 0.  p = jnp
-00002110: 2e72 6573 6861 7065 286a 6e70 2e62 726f  .reshape(jnp.bro
-00002120: 6164 6361 7374 5f74 6f28 702c 2073 6861  adcast_to(p, sha
-00002130: 7065 292c 202d 3129 0a20 206e 203d 206a  pe), -1).  n = j
-00002140: 6e70 2e72 6573 6861 7065 286a 6e70 2e62  np.reshape(jnp.b
-00002150: 726f 6164 6361 7374 5f74 6f28 6e2c 2073  roadcast_to(n, s
-00002160: 6861 7065 292c 202d 3129 0a20 206b 6579  hape), -1).  key
-00002170: 203d 206a 722e 7370 6c69 7428 6b65 792c   = jr.split(key,
-00002180: 206a 6e70 2e73 697a 6528 7029 290a 2020   jnp.size(p)).  
-00002190: 6966 206a 6178 2e64 6566 6175 6c74 5f62  if jax.default_b
-000021a0: 6163 6b65 6e64 2829 203d 3d20 2263 7075  ackend() == "cpu
-000021b0: 223a 0a20 2020 2072 6574 203d 206c 6178  ":.    ret = lax
-000021c0: 2e6d 6170 286c 616d 6264 6120 783a 205f  .map(lambda x: _
-000021d0: 6269 6e6f 6d69 616c 5f64 6973 7061 7463  binomial_dispatc
-000021e0: 6828 2a78 292c 2028 6b65 792c 2070 2c20  h(*x), (key, p, 
-000021f0: 6e29 290a 2020 656c 7365 3a0a 2020 2020  n)).  else:.    
-00002200: 7265 7420 3d20 766d 6170 286c 616d 6264  ret = vmap(lambd
-00002210: 6120 2a78 3a20 5f62 696e 6f6d 6961 6c5f  a *x: _binomial_
-00002220: 6469 7370 6174 6368 282a 7829 2928 6b65  dispatch(*x))(ke
-00002230: 792c 2070 2c20 6e29 0a20 2072 6574 7572  y, p, n).  retur
-00002240: 6e20 6a6e 702e 7265 7368 6170 6528 7265  n jnp.reshape(re
-00002250: 742c 2073 6861 7065 290a 0a0a 4070 6172  t, shape)...@par
-00002260: 7469 616c 286a 6974 2c20 7374 6174 6963  tial(jit, static
-00002270: 5f61 7267 6e75 6d73 3d28 322c 2929 0a64  _argnums=(2,)).d
-00002280: 6566 205f 6361 7465 676f 7269 6361 6c28  ef _categorical(
-00002290: 6b65 792c 2070 2c20 7368 6170 6529 3a0a  key, p, shape):.
-000022a0: 2020 2320 7468 6973 2069 6d70 6c65 6d65    # this impleme
-000022b0: 6e74 6174 696f 6e20 6973 2066 6173 7420  ntation is fast 
-000022c0: 7768 656e 2065 7665 6e74 2073 6861 7065  when event shape
-000022d0: 2069 7320 736d 616c 6c2c 2061 6e64 2073   is small, and s
-000022e0: 6c6f 7720 6f74 6865 7277 6973 650a 2020  low otherwise.  
-000022f0: 2320 5265 663a 2068 7474 7073 3a2f 2f73  # Ref: https://s
-00002300: 7461 636b 6f76 6572 666c 6f77 2e63 6f6d  tackoverflow.com
-00002310: 2f61 2f33 3431 3930 3033 350a 2020 7368  /a/34190035.  sh
-00002320: 6170 6520 3d20 7368 6170 6520 6f72 2070  ape = shape or p
-00002330: 2e73 6861 7065 5b3a 2d31 5d0a 2020 7320  .shape[:-1].  s 
-00002340: 3d20 6a6e 702e 6375 6d73 756d 2870 2c20  = jnp.cumsum(p, 
-00002350: 6178 6973 3d2d 3129 0a20 2072 203d 206a  axis=-1).  r = j
-00002360: 722e 756e 6966 6f72 6d28 6b65 792c 2073  r.uniform(key, s
-00002370: 6861 7065 3d73 6861 7065 202b 2028 312c  hape=shape + (1,
-00002380: 2929 0a20 2072 6574 7572 6e20 6a6e 702e  )).  return jnp.
-00002390: 7375 6d28 7320 3c20 722c 2061 7869 733d  sum(s < r, axis=
-000023a0: 2d31 290a 0a0a 6465 6620 5f73 6361 7474  -1)...def _scatt
-000023b0: 6572 5f61 6464 5f6f 6e65 286f 7065 7261  er_add_one(opera
-000023c0: 6e64 2c20 696e 6469 6365 732c 2075 7064  nd, indices, upd
-000023d0: 6174 6573 293a 0a20 2072 6574 7572 6e20  ates):.  return 
-000023e0: 6c61 782e 7363 6174 7465 725f 6164 6428  lax.scatter_add(
-000023f0: 0a20 2020 206f 7065 7261 6e64 2c0a 2020  .    operand,.  
-00002400: 2020 696e 6469 6365 732c 0a20 2020 2075    indices,.    u
-00002410: 7064 6174 6573 2c0a 2020 2020 6c61 782e  pdates,.    lax.
-00002420: 5363 6174 7465 7244 696d 656e 7369 6f6e  ScatterDimension
-00002430: 4e75 6d62 6572 7328 0a20 2020 2020 2075  Numbers(.      u
-00002440: 7064 6174 655f 7769 6e64 6f77 5f64 696d  pdate_window_dim
-00002450: 733d 2829 2c0a 2020 2020 2020 696e 7365  s=(),.      inse
-00002460: 7274 6564 5f77 696e 646f 775f 6469 6d73  rted_window_dims
-00002470: 3d28 302c 292c 0a20 2020 2020 2073 6361  =(0,),.      sca
-00002480: 7474 6572 5f64 696d 735f 746f 5f6f 7065  tter_dims_to_ope
-00002490: 7261 6e64 5f64 696d 733d 2830 2c29 2c0a  rand_dims=(0,),.
-000024a0: 2020 2020 292c 0a20 2029 0a0a 0a64 6566      ),.  )...def
-000024b0: 205f 7265 7368 6170 6528 782c 2073 6861   _reshape(x, sha
-000024c0: 7065 293a 0a20 2069 6620 6973 696e 7374  pe):.  if isinst
-000024d0: 616e 6365 2878 2c20 2869 6e74 2c20 666c  ance(x, (int, fl
-000024e0: 6f61 742c 206e 702e 6e64 6172 7261 792c  oat, np.ndarray,
-000024f0: 206e 702e 6765 6e65 7269 6329 293a 0a20   np.generic)):. 
-00002500: 2020 2072 6574 7572 6e20 6e70 2e72 6573     return np.res
-00002510: 6861 7065 2878 2c20 7368 6170 6529 0a20  hape(x, shape). 
-00002520: 2065 6c73 653a 0a20 2020 2072 6574 7572   else:.    retur
-00002530: 6e20 6a6e 702e 7265 7368 6170 6528 782c  n jnp.reshape(x,
-00002540: 2073 6861 7065 290a 0a0a 6465 6620 5f70   shape)...def _p
-00002550: 726f 6d6f 7465 5f73 6861 7065 7328 2a61  romote_shapes(*a
-00002560: 7267 732c 2073 6861 7065 3d28 2929 3a0a  rgs, shape=()):.
-00002570: 2020 2320 6164 6170 7465 6420 6672 6f6d    # adapted from
-00002580: 206c 6178 2e6c 6178 5f6e 756d 7079 0a20   lax.lax_numpy. 
-00002590: 2069 6620 6c65 6e28 6172 6773 2920 3c20   if len(args) < 
-000025a0: 3220 616e 6420 6e6f 7420 7368 6170 653a  2 and not shape:
-000025b0: 0a20 2020 2072 6574 7572 6e20 6172 6773  .    return args
-000025c0: 0a20 2065 6c73 653a 0a20 2020 2073 6861  .  else:.    sha
-000025d0: 7065 7320 3d20 5b6a 6e70 2e73 6861 7065  pes = [jnp.shape
-000025e0: 2861 7267 2920 666f 7220 6172 6720 696e  (arg) for arg in
-000025f0: 2061 7267 735d 0a20 2020 206e 756d 5f64   args].    num_d
-00002600: 696d 7320 3d20 6c65 6e28 6c61 782e 6272  ims = len(lax.br
-00002610: 6f61 6463 6173 745f 7368 6170 6573 2873  oadcast_shapes(s
-00002620: 6861 7065 2c20 2a73 6861 7065 7329 290a  hape, *shapes)).
-00002630: 2020 2020 7265 7475 726e 205b 0a20 2020      return [.   
-00002640: 2020 205f 7265 7368 6170 6528 6172 672c     _reshape(arg,
-00002650: 2028 312c 2920 2a20 286e 756d 5f64 696d   (1,) * (num_dim
-00002660: 7320 2d20 6c65 6e28 7329 2920 2b20 7329  s - len(s)) + s)
-00002670: 2069 6620 6c65 6e28 7329 203c 206e 756d   if len(s) < num
-00002680: 5f64 696d 7320 656c 7365 2061 7267 0a20  _dims else arg. 
-00002690: 2020 2020 2066 6f72 2061 7267 2c20 7320       for arg, s 
-000026a0: 696e 207a 6970 2861 7267 732c 2073 6861  in zip(args, sha
-000026b0: 7065 7329 0a20 2020 205d 0a0a 0a40 7061  pes).    ]...@pa
-000026c0: 7274 6961 6c28 6a69 742c 2073 7461 7469  rtial(jit, stati
-000026d0: 635f 6172 676e 756d 733d 2833 2c20 3429  c_argnums=(3, 4)
-000026e0: 290a 6465 6620 5f6d 756c 7469 6e6f 6d69  ).def _multinomi
-000026f0: 616c 286b 6579 2c20 702c 206e 2c20 6e5f  al(key, p, n, n_
-00002700: 6d61 782c 2073 6861 7065 3d28 2929 3a0a  max, shape=()):.
-00002710: 2020 6966 206a 6e70 2e73 6861 7065 286e    if jnp.shape(n
-00002720: 2920 213d 206a 6e70 2e73 6861 7065 2870  ) != jnp.shape(p
-00002730: 295b 3a2d 315d 3a0a 2020 2020 6272 6f61  )[:-1]:.    broa
-00002740: 6463 6173 745f 7368 6170 6520 3d20 6c61  dcast_shape = la
-00002750: 782e 6272 6f61 6463 6173 745f 7368 6170  x.broadcast_shap
-00002760: 6573 286a 6e70 2e73 6861 7065 286e 292c  es(jnp.shape(n),
-00002770: 206a 6e70 2e73 6861 7065 2870 295b 3a2d   jnp.shape(p)[:-
-00002780: 315d 290a 2020 2020 6e20 3d20 6a6e 702e  1]).    n = jnp.
-00002790: 6272 6f61 6463 6173 745f 746f 286e 2c20  broadcast_to(n, 
-000027a0: 6272 6f61 6463 6173 745f 7368 6170 6529  broadcast_shape)
-000027b0: 0a20 2020 2070 203d 206a 6e70 2e62 726f  .    p = jnp.bro
-000027c0: 6164 6361 7374 5f74 6f28 702c 2062 726f  adcast_to(p, bro
-000027d0: 6164 6361 7374 5f73 6861 7065 202b 206a  adcast_shape + j
-000027e0: 6e70 2e73 6861 7065 2870 295b 2d31 3a5d  np.shape(p)[-1:]
-000027f0: 290a 2020 7368 6170 6520 3d20 7368 6170  ).  shape = shap
-00002800: 6520 6f72 2070 2e73 6861 7065 5b3a 2d31  e or p.shape[:-1
-00002810: 5d0a 2020 6966 206e 5f6d 6178 203d 3d20  ].  if n_max == 
-00002820: 303a 0a20 2020 2072 6574 7572 6e20 6a6e  0:.    return jn
-00002830: 702e 7a65 726f 7328 7368 6170 6520 2b20  p.zeros(shape + 
-00002840: 702e 7368 6170 655b 2d31 3a5d 2c20 6474  p.shape[-1:], dt
-00002850: 7970 653d 6a6e 702e 7265 7375 6c74 5f74  ype=jnp.result_t
-00002860: 7970 6528 696e 7429 290a 2020 2320 6765  ype(int)).  # ge
-00002870: 7420 696e 6469 6365 7320 6672 6f6d 2063  t indices from c
-00002880: 6174 6567 6f72 6963 616c 2064 6973 7472  ategorical distr
-00002890: 6962 7574 696f 6e20 7468 656e 2067 6174  ibution then gat
-000028a0: 6865 7220 7468 6520 7265 7375 6c74 0a20  her the result. 
-000028b0: 2069 6e64 6963 6573 203d 205f 6361 7465   indices = _cate
-000028c0: 676f 7269 6361 6c28 6b65 792c 2070 2c20  gorical(key, p, 
-000028d0: 286e 5f6d 6178 2c29 202b 2073 6861 7065  (n_max,) + shape
-000028e0: 290a 2020 2320 6d61 736b 206f 7574 2076  ).  # mask out v
-000028f0: 616c 7565 7320 7768 656e 2063 6f75 6e74  alues when count
-00002900: 7320 6973 2068 6574 6572 6f67 656e 656f  s is heterogeneo
-00002910: 7573 0a20 2069 6620 6a6e 702e 6e64 696d  us.  if jnp.ndim
-00002920: 286e 2920 3e20 303a 0a20 2020 206d 6173  (n) > 0:.    mas
-00002930: 6b20 3d20 5f70 726f 6d6f 7465 5f73 6861  k = _promote_sha
-00002940: 7065 7328 6a6e 702e 6172 616e 6765 286e  pes(jnp.arange(n
-00002950: 5f6d 6178 2920 3c20 6a6e 702e 6578 7061  _max) < jnp.expa
-00002960: 6e64 5f64 696d 7328 6e2c 202d 3129 2c20  nd_dims(n, -1), 
-00002970: 7368 6170 653d 7368 6170 6520 2b20 286e  shape=shape + (n
-00002980: 5f6d 6178 2c29 295b 305d 0a20 2020 206d  _max,))[0].    m
-00002990: 6173 6b20 3d20 6a6e 702e 6d6f 7665 6178  ask = jnp.moveax
-000029a0: 6973 286d 6173 6b2c 202d 312c 2030 292e  is(mask, -1, 0).
-000029b0: 6173 7479 7065 2869 6e64 6963 6573 2e64  astype(indices.d
-000029c0: 7479 7065 290a 2020 2020 6578 6365 7373  type).    excess
-000029d0: 203d 206a 6e70 2e63 6f6e 6361 7465 6e61   = jnp.concatena
-000029e0: 7465 285b 6a6e 702e 6578 7061 6e64 5f64  te([jnp.expand_d
-000029f0: 696d 7328 6e5f 6d61 7820 2d20 6e2c 202d  ims(n_max - n, -
-00002a00: 3129 2c0a 2020 2020 2020 2020 2020 2020  1),.            
-00002a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a20: 2020 6a6e 702e 7a65 726f 7328 6a6e 702e    jnp.zeros(jnp.
-00002a30: 7368 6170 6528 6e29 202b 2028 702e 7368  shape(n) + (p.sh
-00002a40: 6170 655b 2d31 5d20 2d20 312c 2929 5d2c  ape[-1] - 1,))],
-00002a50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002a60: 2020 2020 2020 2020 2020 2020 2020 2d31                -1
-00002a70: 290a 2020 656c 7365 3a0a 2020 2020 6d61  ).  else:.    ma
-00002a80: 736b 203d 2031 0a20 2020 2065 7863 6573  sk = 1.    exces
-00002a90: 7320 3d20 300a 2020 2320 4e42 3a20 7765  s = 0.  # NB: we
-00002aa0: 2074 7261 6e73 706f 7365 2074 6f20 6d6f   transpose to mo
-00002ab0: 7665 2062 6174 6368 2073 6861 7065 2074  ve batch shape t
-00002ac0: 6f20 7468 6520 6672 6f6e 740a 2020 696e  o the front.  in
-00002ad0: 6469 6365 735f 3244 203d 2028 6a6e 702e  dices_2D = (jnp.
-00002ae0: 7265 7368 6170 6528 696e 6469 6365 7320  reshape(indices 
-00002af0: 2a20 6d61 736b 2c20 286e 5f6d 6178 2c20  * mask, (n_max, 
-00002b00: 2d31 2929 292e 540a 2020 7361 6d70 6c65  -1))).T.  sample
-00002b10: 735f 3244 203d 2076 6d61 7028 5f73 6361  s_2D = vmap(_sca
-00002b20: 7474 6572 5f61 6464 5f6f 6e65 2928 6a6e  tter_add_one)(jn
-00002b30: 702e 7a65 726f 7328 2869 6e64 6963 6573  p.zeros((indices
-00002b40: 5f32 442e 7368 6170 655b 305d 2c20 702e  _2D.shape[0], p.
-00002b50: 7368 6170 655b 2d31 5d29 2c20 6474 7970  shape[-1]), dtyp
-00002b60: 653d 696e 6469 6365 732e 6474 7970 6529  e=indices.dtype)
-00002b70: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00002b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b90: 2020 2020 2020 2020 6a6e 702e 6578 7061          jnp.expa
-00002ba0: 6e64 5f64 696d 7328 696e 6469 6365 735f  nd_dims(indices_
-00002bb0: 3244 2c20 6178 6973 3d2d 3129 2c0a 2020  2D, axis=-1),.  
+000014a0: 2030 2e30 3038 3333 3035 3633 3433 3333   0.0083305634333
+000014b0: 3632 3837 312c 205d 290a 2020 6b70 3120  62871, ]).  kp1 
+000014c0: 3d20 6b20 2b20 310a 2020 6b70 3173 7120  = k + 1.  kp1sq 
+000014d0: 3d20 286b 202b 2031 2920 2a2a 2032 0a20  = (k + 1) ** 2. 
+000014e0: 2072 6574 7572 6e20 6a6e 702e 7768 6572   return jnp.wher
+000014f0: 6528 6b20 3c20 3130 2c0a 2020 2020 2020  e(k < 10,.      
+00001500: 2020 2020 2020 2020 2020 2020 2070 7265               pre
+00001510: 636f 6d70 7574 6564 5b6b 5d2c 0a20 2020  computed[k],.   
+00001520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001530: 2831 2e30 202f 2031 3220 2d20 2831 2e30  (1.0 / 12 - (1.0
+00001540: 202f 2033 3630 202d 2028 312e 3020 2f20   / 360 - (1.0 / 
+00001550: 3132 3630 2920 2f20 6b70 3173 7129 202f  1260) / kp1sq) /
+00001560: 206b 7031 7371 2920 2f20 6b70 3129 0a0a   kp1sq) / kp1)..
+00001570: 0a64 6566 205f 6269 6e6f 6d69 616c 5f62  .def _binomial_b
+00001580: 7472 7328 6b65 792c 2070 2c20 6e29 3a0a  trs(key, p, n):.
+00001590: 2020 2222 220a 2020 4261 7365 6420 6f6e    """.  Based on
+000015a0: 2074 6865 2074 7261 6e73 666f 726d 6564   the transformed
+000015b0: 2072 656a 6563 7469 6f6e 2073 616d 706c   rejection sampl
+000015c0: 696e 6720 616c 676f 7269 7468 6d20 2842  ing algorithm (B
+000015d0: 5452 5329 2066 726f 6d20 7468 650a 2020  TRS) from the.  
+000015e0: 666f 6c6c 6f77 696e 6720 7265 6665 7265  following refere
+000015f0: 6e63 653a 0a0a 2020 486f 726d 616e 6e2c  nce:..  Hormann,
+00001600: 2022 5468 6520 4765 6e65 7261 7469 6f6e   "The Generation
+00001610: 206f 6620 4269 6e6f 6e6d 6961 6c20 5261   of Binonmial Ra
+00001620: 6e64 6f6d 2056 6172 6961 7465 7322 0a20  ndom Variates". 
+00001630: 2028 6874 7470 733a 2f2f 636f 7265 2e61   (https://core.a
+00001640: 632e 756b 2f64 6f77 6e6c 6f61 642f 7064  c.uk/download/pd
+00001650: 662f 3131 3030 3732 3534 2e70 6466 290a  f/11007254.pdf).
+00001660: 2020 2222 220a 0a20 2064 6566 205f 6274    """..  def _bt
+00001670: 7273 5f62 6f64 795f 666e 2876 616c 293a  rs_body_fn(val):
+00001680: 0a20 2020 205f 2c20 6b65 792c 205f 2c20  .    _, key, _, 
+00001690: 5f20 3d20 7661 6c0a 2020 2020 6b65 792c  _ = val.    key,
+000016a0: 206b 6579 5f75 2c20 6b65 795f 7620 3d20   key_u, key_v = 
+000016b0: 6a72 2e73 706c 6974 286b 6579 2c20 3329  jr.split(key, 3)
+000016c0: 0a20 2020 2075 203d 206a 722e 756e 6966  .    u = jr.unif
+000016d0: 6f72 6d28 6b65 795f 7529 0a20 2020 2076  orm(key_u).    v
+000016e0: 203d 206a 722e 756e 6966 6f72 6d28 6b65   = jr.uniform(ke
+000016f0: 795f 7629 0a20 2020 2075 203d 2075 202d  y_v).    u = u -
+00001700: 2030 2e35 0a20 2020 206b 203d 206a 6e70   0.5.    k = jnp
+00001710: 2e66 6c6f 6f72 280a 2020 2020 2020 2832  .floor(.      (2
+00001720: 202a 2074 725f 7061 7261 6d73 2e61 202f   * tr_params.a /
+00001730: 2028 302e 3520 2d20 6a6e 702e 6162 7328   (0.5 - jnp.abs(
+00001740: 7529 2920 2b20 7472 5f70 6172 616d 732e  u)) + tr_params.
+00001750: 6229 202a 2075 202b 2074 725f 7061 7261  b) * u + tr_para
+00001760: 6d73 2e63 0a20 2020 2029 2e61 7374 7970  ms.c.    ).astyp
+00001770: 6528 6e2e 6474 7970 6529 0a20 2020 2072  e(n.dtype).    r
+00001780: 6574 7572 6e20 6b2c 206b 6579 2c20 752c  eturn k, key, u,
+00001790: 2076 0a0a 2020 6465 6620 5f62 7472 735f   v..  def _btrs_
+000017a0: 636f 6e64 5f66 6e28 7661 6c29 3a0a 2020  cond_fn(val):.  
+000017b0: 2020 6465 6620 6163 6365 7074 5f66 6e28    def accept_fn(
+000017c0: 6b2c 2075 2c20 7629 3a0a 2020 2020 2020  k, u, v):.      
+000017d0: 2320 5365 6520 6163 6365 7074 616e 6365  # See acceptance
+000017e0: 2063 6f6e 6469 7469 6f6e 2069 6e20 5374   condition in St
+000017f0: 6570 2033 2e20 2850 6167 6520 3329 206f  ep 3. (Page 3) o
+00001800: 6620 5452 5320 616c 676f 7269 7468 6d0a  f TRS algorithm.
+00001810: 2020 2020 2020 2320 7620 3c3d 2066 286b        # v <= f(k
+00001820: 2920 2a20 675f 6772 6164 2875 2920 2f20  ) * g_grad(u) / 
+00001830: 616c 7068 610a 0a20 2020 2020 206d 203d  alpha..      m =
+00001840: 2074 725f 7061 7261 6d73 2e6d 0a20 2020   tr_params.m.   
+00001850: 2020 206c 6f67 5f70 203d 2074 725f 7061     log_p = tr_pa
+00001860: 7261 6d73 2e6c 6f67 5f70 0a20 2020 2020  rams.log_p.     
+00001870: 206c 6f67 315f 7020 3d20 7472 5f70 6172   log1_p = tr_par
+00001880: 616d 732e 6c6f 6731 5f70 0a20 2020 2020  ams.log1_p.     
+00001890: 2023 2053 6565 3a20 666f 726d 756c 6120   # See: formula 
+000018a0: 666f 7220 6c6f 6728 6628 6b29 2920 6174  for log(f(k)) at
+000018b0: 2062 6f74 746f 6d20 6f66 2050 6167 6520   bottom of Page 
+000018c0: 352e 0a20 2020 2020 206c 6f67 5f66 203d  5..      log_f =
+000018d0: 2028 0a20 2020 2020 2020 2020 2028 6e20   (.          (n 
+000018e0: 2b20 312e 3029 202a 206a 6e70 2e6c 6f67  + 1.0) * jnp.log
+000018f0: 2828 6e20 2d20 6d20 2b20 312e 3029 202f  ((n - m + 1.0) /
+00001900: 2028 6e20 2d20 6b20 2b20 312e 3029 290a   (n - k + 1.0)).
+00001910: 2020 2020 2020 2020 2020 2b20 286b 202b            + (k +
+00001920: 2030 2e35 2920 2a20 286a 6e70 2e6c 6f67   0.5) * (jnp.log
+00001930: 2828 6e20 2d20 6b20 2b20 312e 3029 202f  ((n - k + 1.0) /
+00001940: 2028 6b20 2b20 312e 3029 2920 2b20 6c6f   (k + 1.0)) + lo
+00001950: 675f 7020 2d20 6c6f 6731 5f70 290a 2020  g_p - log1_p).  
+00001960: 2020 2020 2020 2020 2b20 285f 7374 6972          + (_stir
+00001970: 6c69 6e67 5f61 7070 726f 785f 7461 696c  ling_approx_tail
+00001980: 286b 2920 2d20 5f73 7469 726c 696e 675f  (k) - _stirling_
+00001990: 6170 7072 6f78 5f74 6169 6c28 6e20 2d20  approx_tail(n - 
+000019a0: 6b29 290a 2020 2020 2020 2020 2020 2b20  k)).          + 
+000019b0: 7472 5f70 6172 616d 732e 6c6f 675f 680a  tr_params.log_h.
+000019c0: 2020 2020 2020 290a 2020 2020 2020 6720        ).      g 
+000019d0: 3d20 2874 725f 7061 7261 6d73 2e61 202f  = (tr_params.a /
+000019e0: 2028 302e 3520 2d20 6a6e 702e 6162 7328   (0.5 - jnp.abs(
+000019f0: 7529 2920 2a2a 2032 2920 2b20 7472 5f70  u)) ** 2) + tr_p
+00001a00: 6172 616d 732e 620a 2020 2020 2020 7265  arams.b.      re
+00001a10: 7475 726e 206a 6e70 2e6c 6f67 2828 7620  turn jnp.log((v 
+00001a20: 2a20 7472 5f70 6172 616d 732e 616c 7068  * tr_params.alph
+00001a30: 6129 202f 2067 2920 3c3d 206c 6f67 5f66  a) / g) <= log_f
+00001a40: 0a0a 2020 2020 6b2c 206b 6579 2c20 752c  ..    k, key, u,
+00001a50: 2076 203d 2076 616c 0a20 2020 2065 6172   v = val.    ear
+00001a60: 6c79 5f61 6363 6570 7420 3d20 286a 6e70  ly_accept = (jnp
+00001a70: 2e61 6273 2875 2920 3c3d 2074 725f 7061  .abs(u) <= tr_pa
+00001a80: 7261 6d73 2e75 5f72 2920 2620 2876 203c  rams.u_r) & (v <
+00001a90: 3d20 7472 5f70 6172 616d 732e 765f 7229  = tr_params.v_r)
+00001aa0: 0a20 2020 2065 6172 6c79 5f72 656a 6563  .    early_rejec
+00001ab0: 7420 3d20 286b 203c 2030 2920 7c20 286b  t = (k < 0) | (k
+00001ac0: 203e 206e 290a 2020 2020 7265 7475 726e   > n).    return
+00001ad0: 206c 6178 2e63 6f6e 6428 0a20 2020 2020   lax.cond(.     
+00001ae0: 2065 6172 6c79 5f61 6363 6570 7420 7c20   early_accept | 
+00001af0: 6561 726c 795f 7265 6a65 6374 2c0a 2020  early_reject,.  
+00001b00: 2020 2020 2829 2c0a 2020 2020 2020 6c61      (),.      la
+00001b10: 6d62 6461 205f 3a20 7e65 6172 6c79 5f61  mbda _: ~early_a
+00001b20: 6363 6570 742c 0a20 2020 2020 2028 6b2c  ccept,.      (k,
+00001b30: 2075 2c20 7629 2c0a 2020 2020 2020 6c61   u, v),.      la
+00001b40: 6d62 6461 2078 3a20 7e61 6363 6570 745f  mbda x: ~accept_
+00001b50: 666e 282a 7829 2c0a 2020 2020 290a 0a20  fn(*x),.    ).. 
+00001b60: 2074 725f 7061 7261 6d73 203d 205f 6765   tr_params = _ge
+00001b70: 745f 7472 5f70 6172 616d 7328 6e2c 2070  t_tr_params(n, p
+00001b80: 290a 2020 7265 7420 3d20 6c61 782e 7768  ).  ret = lax.wh
+00001b90: 696c 655f 6c6f 6f70 280a 2020 2020 5f62  ile_loop(.    _b
+00001ba0: 7472 735f 636f 6e64 5f66 6e2c 205f 6274  trs_cond_fn, _bt
+00001bb0: 7273 5f62 6f64 795f 666e 2c20 282d 312c  rs_body_fn, (-1,
+00001bc0: 206b 6579 2c20 312e 302c 2031 2e30 290a   key, 1.0, 1.0).
+00001bd0: 2020 2920 2023 2075 7365 206b 3d2d 3120    )  # use k=-1 
+00001be0: 696e 6974 6961 6c6c 7920 736f 2074 6861  initially so tha
+00001bf0: 7420 636f 6e64 5f66 6e20 7265 7475 726e  t cond_fn return
+00001c00: 7320 5472 7565 0a20 2072 6574 7572 6e20  s True.  return 
+00001c10: 7265 745b 305d 0a0a 0a64 6566 205f 6269  ret[0]...def _bi
+00001c20: 6e6f 6d69 616c 5f69 6e76 6572 7369 6f6e  nomial_inversion
+00001c30: 286b 6579 2c20 702c 206e 293a 0a20 2064  (key, p, n):.  d
+00001c40: 6566 205f 6269 6e6f 6d5f 696e 765f 626f  ef _binom_inv_bo
+00001c50: 6479 5f66 6e28 7661 6c29 3a0a 2020 2020  dy_fn(val):.    
+00001c60: 692c 206b 6579 2c20 6765 6f6d 5f61 6363  i, key, geom_acc
+00001c70: 203d 2076 616c 0a20 2020 206b 6579 2c20   = val.    key, 
+00001c80: 6b65 795f 7520 3d20 6a72 2e73 706c 6974  key_u = jr.split
+00001c90: 286b 6579 290a 2020 2020 7520 3d20 6a72  (key).    u = jr
+00001ca0: 2e75 6e69 666f 726d 286b 6579 5f75 290a  .uniform(key_u).
+00001cb0: 2020 2020 6765 6f6d 203d 206a 6e70 2e66      geom = jnp.f
+00001cc0: 6c6f 6f72 286a 6e70 2e6c 6f67 3170 282d  loor(jnp.log1p(-
+00001cd0: 7529 202f 206c 6f67 315f 7029 202b 2031  u) / log1_p) + 1
+00001ce0: 0a20 2020 2067 656f 6d5f 6163 6320 3d20  .    geom_acc = 
+00001cf0: 6765 6f6d 5f61 6363 202b 2067 656f 6d0a  geom_acc + geom.
+00001d00: 2020 2020 7265 7475 726e 2069 202b 2031      return i + 1
+00001d10: 2c20 6b65 792c 2067 656f 6d5f 6163 630a  , key, geom_acc.
+00001d20: 0a20 2064 6566 205f 6269 6e6f 6d5f 696e  .  def _binom_in
+00001d30: 765f 636f 6e64 5f66 6e28 7661 6c29 3a0a  v_cond_fn(val):.
+00001d40: 2020 2020 692c 205f 2c20 6765 6f6d 5f61      i, _, geom_a
+00001d50: 6363 203d 2076 616c 0a20 2020 2072 6574  cc = val.    ret
+00001d60: 7572 6e20 6765 6f6d 5f61 6363 203c 3d20  urn geom_acc <= 
+00001d70: 6e0a 0a20 206c 6f67 315f 7020 3d20 6a6e  n..  log1_p = jn
+00001d80: 702e 6c6f 6731 7028 2d70 290a 2020 7265  p.log1p(-p).  re
+00001d90: 7420 3d20 6c61 782e 7768 696c 655f 6c6f  t = lax.while_lo
+00001da0: 6f70 285f 6269 6e6f 6d5f 696e 765f 636f  op(_binom_inv_co
+00001db0: 6e64 5f66 6e2c 205f 6269 6e6f 6d5f 696e  nd_fn, _binom_in
+00001dc0: 765f 626f 6479 5f66 6e2c 2028 2d31 2c20  v_body_fn, (-1, 
+00001dd0: 6b65 792c 2030 2e30 2929 0a20 2072 6574  key, 0.0)).  ret
+00001de0: 7572 6e20 7265 745b 305d 0a0a 0a64 6566  urn ret[0]...def
+00001df0: 205f 6269 6e6f 6d69 616c 5f64 6973 7061   _binomial_dispa
+00001e00: 7463 6828 6b65 792c 2070 2c20 6e29 3a0a  tch(key, p, n):.
+00001e10: 2020 6465 6620 6469 7370 6174 6368 286b    def dispatch(k
+00001e20: 6579 2c20 702c 206e 293a 0a20 2020 2069  ey, p, n):.    i
+00001e30: 735f 6c65 5f6d 6964 203d 2070 203c 3d20  s_le_mid = p <= 
+00001e40: 302e 350a 2020 2020 7071 203d 206a 6e70  0.5.    pq = jnp
+00001e50: 2e77 6865 7265 2869 735f 6c65 5f6d 6964  .where(is_le_mid
+00001e60: 2c20 702c 2031 202d 2070 290a 2020 2020  , p, 1 - p).    
+00001e70: 6d75 203d 206e 202a 2070 710a 2020 2020  mu = n * pq.    
+00001e80: 6b20 3d20 6c61 782e 636f 6e64 280a 2020  k = lax.cond(.  
+00001e90: 2020 2020 6d75 203c 2031 302c 0a20 2020      mu < 10,.   
+00001ea0: 2020 2028 6b65 792c 2070 712c 206e 292c     (key, pq, n),
+00001eb0: 0a20 2020 2020 206c 616d 6264 6120 783a  .      lambda x:
+00001ec0: 205f 6269 6e6f 6d69 616c 5f69 6e76 6572   _binomial_inver
+00001ed0: 7369 6f6e 282a 7829 2c0a 2020 2020 2020  sion(*x),.      
+00001ee0: 286b 6579 2c20 7071 2c20 6e29 2c0a 2020  (key, pq, n),.  
+00001ef0: 2020 2020 6c61 6d62 6461 2078 3a20 5f62      lambda x: _b
+00001f00: 696e 6f6d 6961 6c5f 6274 7273 282a 7829  inomial_btrs(*x)
+00001f10: 2c0a 2020 2020 290a 2020 2020 7265 7475  ,.    ).    retu
+00001f20: 726e 206a 6e70 2e77 6865 7265 2869 735f  rn jnp.where(is_
+00001f30: 6c65 5f6d 6964 2c20 6b2c 206e 202d 206b  le_mid, k, n - k
+00001f40: 290a 0a20 2023 2052 6574 7572 6e20 3020  )..  # Return 0 
+00001f50: 666f 7220 6e61 6e20 6070 6020 6f72 206e  for nan `p` or n
+00001f60: 6567 6174 6976 6520 606e 602c 2073 696e  egative `n`, sin
+00001f70: 6365 206e 616e 2076 616c 7565 7320 6172  ce nan values ar
+00001f80: 6520 6e6f 7420 616c 6c6f 7765 6420 666f  e not allowed fo
+00001f90: 7220 696e 7465 6765 7220 7479 7065 730a  r integer types.
+00001fa0: 2020 636f 6e64 3020 3d20 6a6e 702e 6973    cond0 = jnp.is
+00001fb0: 6669 6e69 7465 2870 2920 2620 286e 203e  finite(p) & (n >
+00001fc0: 2030 2920 2620 2870 203e 2030 290a 2020   0) & (p > 0).  
+00001fd0: 7265 7475 726e 206c 6178 2e63 6f6e 6428  return lax.cond(
+00001fe0: 0a20 2020 2063 6f6e 6430 2026 2028 7020  .    cond0 & (p 
+00001ff0: 3c20 3129 2c0a 2020 2020 286b 6579 2c20  < 1),.    (key, 
+00002000: 702c 206e 292c 0a20 2020 206c 616d 6264  p, n),.    lambd
+00002010: 6120 783a 2064 6973 7061 7463 6828 2a78  a x: dispatch(*x
+00002020: 292c 0a20 2020 2028 292c 0a20 2020 206c  ),.    (),.    l
+00002030: 616d 6264 6120 5f3a 206a 6e70 2e77 6865  ambda _: jnp.whe
+00002040: 7265 2863 6f6e 6430 2c20 6e2c 2030 292c  re(cond0, n, 0),
+00002050: 0a20 2029 0a0a 0a40 7061 7274 6961 6c28  .  )...@partial(
+00002060: 6a69 742c 2073 7461 7469 635f 6172 676e  jit, static_argn
+00002070: 756d 733d 2833 2c29 290a 6465 6620 5f62  ums=(3,)).def _b
+00002080: 696e 6f6d 6961 6c28 6b65 792c 2070 2c20  inomial(key, p, 
+00002090: 6e2c 2073 6861 7065 293a 0a20 2073 6861  n, shape):.  sha
+000020a0: 7065 203d 2073 6861 7065 206f 7220 6c61  pe = shape or la
+000020b0: 782e 6272 6f61 6463 6173 745f 7368 6170  x.broadcast_shap
+000020c0: 6573 286a 6e70 2e73 6861 7065 2870 292c  es(jnp.shape(p),
+000020d0: 206a 6e70 2e73 6861 7065 286e 2929 0a20   jnp.shape(n)). 
+000020e0: 2023 2072 6573 6861 7065 2074 6f20 6d61   # reshape to ma
+000020f0: 7020 6f76 6572 2061 7869 7320 300a 2020  p over axis 0.  
+00002100: 7020 3d20 6a6e 702e 7265 7368 6170 6528  p = jnp.reshape(
+00002110: 6a6e 702e 6272 6f61 6463 6173 745f 746f  jnp.broadcast_to
+00002120: 2870 2c20 7368 6170 6529 2c20 2d31 290a  (p, shape), -1).
+00002130: 2020 6e20 3d20 6a6e 702e 7265 7368 6170    n = jnp.reshap
+00002140: 6528 6a6e 702e 6272 6f61 6463 6173 745f  e(jnp.broadcast_
+00002150: 746f 286e 2c20 7368 6170 6529 2c20 2d31  to(n, shape), -1
+00002160: 290a 2020 6b65 7920 3d20 6a72 2e73 706c  ).  key = jr.spl
+00002170: 6974 286b 6579 2c20 6a6e 702e 7369 7a65  it(key, jnp.size
+00002180: 2870 2929 0a20 2069 6620 6a61 782e 6465  (p)).  if jax.de
+00002190: 6661 756c 745f 6261 636b 656e 6428 2920  fault_backend() 
+000021a0: 3d3d 2022 6370 7522 3a0a 2020 2020 7265  == "cpu":.    re
+000021b0: 7420 3d20 6c61 782e 6d61 7028 6c61 6d62  t = lax.map(lamb
+000021c0: 6461 2078 3a20 5f62 696e 6f6d 6961 6c5f  da x: _binomial_
+000021d0: 6469 7370 6174 6368 282a 7829 2c20 286b  dispatch(*x), (k
+000021e0: 6579 2c20 702c 206e 2929 0a20 2065 6c73  ey, p, n)).  els
+000021f0: 653a 0a20 2020 2072 6574 203d 2076 6d61  e:.    ret = vma
+00002200: 7028 6c61 6d62 6461 202a 783a 205f 6269  p(lambda *x: _bi
+00002210: 6e6f 6d69 616c 5f64 6973 7061 7463 6828  nomial_dispatch(
+00002220: 2a78 2929 286b 6579 2c20 702c 206e 290a  *x))(key, p, n).
+00002230: 2020 7265 7475 726e 206a 6e70 2e72 6573    return jnp.res
+00002240: 6861 7065 2872 6574 2c20 7368 6170 6529  hape(ret, shape)
+00002250: 0a0a 0a40 7061 7274 6961 6c28 6a69 742c  ...@partial(jit,
+00002260: 2073 7461 7469 635f 6172 676e 756d 733d   static_argnums=
+00002270: 2832 2c29 290a 6465 6620 5f63 6174 6567  (2,)).def _categ
+00002280: 6f72 6963 616c 286b 6579 2c20 702c 2073  orical(key, p, s
+00002290: 6861 7065 293a 0a20 2023 2074 6869 7320  hape):.  # this 
+000022a0: 696d 706c 656d 656e 7461 7469 6f6e 2069  implementation i
+000022b0: 7320 6661 7374 2077 6865 6e20 6576 656e  s fast when even
+000022c0: 7420 7368 6170 6520 6973 2073 6d61 6c6c  t shape is small
+000022d0: 2c20 616e 6420 736c 6f77 206f 7468 6572  , and slow other
+000022e0: 7769 7365 0a20 2023 2052 6566 3a20 6874  wise.  # Ref: ht
+000022f0: 7470 733a 2f2f 7374 6163 6b6f 7665 7266  tps://stackoverf
+00002300: 6c6f 772e 636f 6d2f 612f 3334 3139 3030  low.com/a/341900
+00002310: 3335 0a20 2073 6861 7065 203d 2073 6861  35.  shape = sha
+00002320: 7065 206f 7220 702e 7368 6170 655b 3a2d  pe or p.shape[:-
+00002330: 315d 0a20 2073 203d 206a 6e70 2e63 756d  1].  s = jnp.cum
+00002340: 7375 6d28 702c 2061 7869 733d 2d31 290a  sum(p, axis=-1).
+00002350: 2020 7220 3d20 6a72 2e75 6e69 666f 726d    r = jr.uniform
+00002360: 286b 6579 2c20 7368 6170 653d 7368 6170  (key, shape=shap
+00002370: 6520 2b20 2831 2c29 290a 2020 7265 7475  e + (1,)).  retu
+00002380: 726e 206a 6e70 2e73 756d 2873 203c 2072  rn jnp.sum(s < r
+00002390: 2c20 6178 6973 3d2d 3129 0a0a 0a64 6566  , axis=-1)...def
+000023a0: 205f 7363 6174 7465 725f 6164 645f 6f6e   _scatter_add_on
+000023b0: 6528 6f70 6572 616e 642c 2069 6e64 6963  e(operand, indic
+000023c0: 6573 2c20 7570 6461 7465 7329 3a0a 2020  es, updates):.  
+000023d0: 7265 7475 726e 206c 6178 2e73 6361 7474  return lax.scatt
+000023e0: 6572 5f61 6464 280a 2020 2020 6f70 6572  er_add(.    oper
+000023f0: 616e 642c 0a20 2020 2069 6e64 6963 6573  and,.    indices
+00002400: 2c0a 2020 2020 7570 6461 7465 732c 0a20  ,.    updates,. 
+00002410: 2020 206c 6178 2e53 6361 7474 6572 4469     lax.ScatterDi
+00002420: 6d65 6e73 696f 6e4e 756d 6265 7273 280a  mensionNumbers(.
+00002430: 2020 2020 2020 7570 6461 7465 5f77 696e        update_win
+00002440: 646f 775f 6469 6d73 3d28 292c 0a20 2020  dow_dims=(),.   
+00002450: 2020 2069 6e73 6572 7465 645f 7769 6e64     inserted_wind
+00002460: 6f77 5f64 696d 733d 2830 2c29 2c0a 2020  ow_dims=(0,),.  
+00002470: 2020 2020 7363 6174 7465 725f 6469 6d73      scatter_dims
+00002480: 5f74 6f5f 6f70 6572 616e 645f 6469 6d73  _to_operand_dims
+00002490: 3d28 302c 292c 0a20 2020 2029 2c0a 2020  =(0,),.    ),.  
+000024a0: 290a 0a0a 6465 6620 5f72 6573 6861 7065  )...def _reshape
+000024b0: 2878 2c20 7368 6170 6529 3a0a 2020 6966  (x, shape):.  if
+000024c0: 2069 7369 6e73 7461 6e63 6528 782c 2028   isinstance(x, (
+000024d0: 696e 742c 2066 6c6f 6174 2c20 6e70 2e6e  int, float, np.n
+000024e0: 6461 7272 6179 2c20 6e70 2e67 656e 6572  darray, np.gener
+000024f0: 6963 2929 3a0a 2020 2020 7265 7475 726e  ic)):.    return
+00002500: 206e 702e 7265 7368 6170 6528 782c 2073   np.reshape(x, s
+00002510: 6861 7065 290a 2020 656c 7365 3a0a 2020  hape).  else:.  
+00002520: 2020 7265 7475 726e 206a 6e70 2e72 6573    return jnp.res
+00002530: 6861 7065 2878 2c20 7368 6170 6529 0a0a  hape(x, shape)..
+00002540: 0a64 6566 205f 7072 6f6d 6f74 655f 7368  .def _promote_sh
+00002550: 6170 6573 282a 6172 6773 2c20 7368 6170  apes(*args, shap
+00002560: 653d 2829 293a 0a20 2023 2061 6461 7074  e=()):.  # adapt
+00002570: 6564 2066 726f 6d20 6c61 782e 6c61 785f  ed from lax.lax_
+00002580: 6e75 6d70 790a 2020 6966 206c 656e 2861  numpy.  if len(a
+00002590: 7267 7329 203c 2032 2061 6e64 206e 6f74  rgs) < 2 and not
+000025a0: 2073 6861 7065 3a0a 2020 2020 7265 7475   shape:.    retu
+000025b0: 726e 2061 7267 730a 2020 656c 7365 3a0a  rn args.  else:.
+000025c0: 2020 2020 7368 6170 6573 203d 205b 6a6e      shapes = [jn
+000025d0: 702e 7368 6170 6528 6172 6729 2066 6f72  p.shape(arg) for
+000025e0: 2061 7267 2069 6e20 6172 6773 5d0a 2020   arg in args].  
+000025f0: 2020 6e75 6d5f 6469 6d73 203d 206c 656e    num_dims = len
+00002600: 286c 6178 2e62 726f 6164 6361 7374 5f73  (lax.broadcast_s
+00002610: 6861 7065 7328 7368 6170 652c 202a 7368  hapes(shape, *sh
+00002620: 6170 6573 2929 0a20 2020 2072 6574 7572  apes)).    retur
+00002630: 6e20 5b0a 2020 2020 2020 5f72 6573 6861  n [.      _resha
+00002640: 7065 2861 7267 2c20 2831 2c29 202a 2028  pe(arg, (1,) * (
+00002650: 6e75 6d5f 6469 6d73 202d 206c 656e 2873  num_dims - len(s
+00002660: 2929 202b 2073 2920 6966 206c 656e 2873  )) + s) if len(s
+00002670: 2920 3c20 6e75 6d5f 6469 6d73 2065 6c73  ) < num_dims els
+00002680: 6520 6172 670a 2020 2020 2020 666f 7220  e arg.      for 
+00002690: 6172 672c 2073 2069 6e20 7a69 7028 6172  arg, s in zip(ar
+000026a0: 6773 2c20 7368 6170 6573 290a 2020 2020  gs, shapes).    
+000026b0: 5d0a 0a0a 4070 6172 7469 616c 286a 6974  ]...@partial(jit
+000026c0: 2c20 7374 6174 6963 5f61 7267 6e75 6d73  , static_argnums
+000026d0: 3d28 332c 2034 2929 0a64 6566 205f 6d75  =(3, 4)).def _mu
+000026e0: 6c74 696e 6f6d 6961 6c28 6b65 792c 2070  ltinomial(key, p
+000026f0: 2c20 6e2c 206e 5f6d 6178 2c20 7368 6170  , n, n_max, shap
+00002700: 653d 2829 293a 0a20 2069 6620 6a6e 702e  e=()):.  if jnp.
+00002710: 7368 6170 6528 6e29 2021 3d20 6a6e 702e  shape(n) != jnp.
+00002720: 7368 6170 6528 7029 5b3a 2d31 5d3a 0a20  shape(p)[:-1]:. 
+00002730: 2020 2062 726f 6164 6361 7374 5f73 6861     broadcast_sha
+00002740: 7065 203d 206c 6178 2e62 726f 6164 6361  pe = lax.broadca
+00002750: 7374 5f73 6861 7065 7328 6a6e 702e 7368  st_shapes(jnp.sh
+00002760: 6170 6528 6e29 2c20 6a6e 702e 7368 6170  ape(n), jnp.shap
+00002770: 6528 7029 5b3a 2d31 5d29 0a20 2020 206e  e(p)[:-1]).    n
+00002780: 203d 206a 6e70 2e62 726f 6164 6361 7374   = jnp.broadcast
+00002790: 5f74 6f28 6e2c 2062 726f 6164 6361 7374  _to(n, broadcast
+000027a0: 5f73 6861 7065 290a 2020 2020 7020 3d20  _shape).    p = 
+000027b0: 6a6e 702e 6272 6f61 6463 6173 745f 746f  jnp.broadcast_to
+000027c0: 2870 2c20 6272 6f61 6463 6173 745f 7368  (p, broadcast_sh
+000027d0: 6170 6520 2b20 6a6e 702e 7368 6170 6528  ape + jnp.shape(
+000027e0: 7029 5b2d 313a 5d29 0a20 2073 6861 7065  p)[-1:]).  shape
+000027f0: 203d 2073 6861 7065 206f 7220 702e 7368   = shape or p.sh
+00002800: 6170 655b 3a2d 315d 0a20 2069 6620 6e5f  ape[:-1].  if n_
+00002810: 6d61 7820 3d3d 2030 3a0a 2020 2020 7265  max == 0:.    re
+00002820: 7475 726e 206a 6e70 2e7a 6572 6f73 2873  turn jnp.zeros(s
+00002830: 6861 7065 202b 2070 2e73 6861 7065 5b2d  hape + p.shape[-
+00002840: 313a 5d2c 2064 7479 7065 3d6a 6e70 2e72  1:], dtype=jnp.r
+00002850: 6573 756c 745f 7479 7065 2869 6e74 2929  esult_type(int))
+00002860: 0a20 2023 2067 6574 2069 6e64 6963 6573  .  # get indices
+00002870: 2066 726f 6d20 6361 7465 676f 7269 6361   from categorica
+00002880: 6c20 6469 7374 7269 6275 7469 6f6e 2074  l distribution t
+00002890: 6865 6e20 6761 7468 6572 2074 6865 2072  hen gather the r
+000028a0: 6573 756c 740a 2020 696e 6469 6365 7320  esult.  indices 
+000028b0: 3d20 5f63 6174 6567 6f72 6963 616c 286b  = _categorical(k
+000028c0: 6579 2c20 702c 2028 6e5f 6d61 782c 2920  ey, p, (n_max,) 
+000028d0: 2b20 7368 6170 6529 0a20 2023 206d 6173  + shape).  # mas
+000028e0: 6b20 6f75 7420 7661 6c75 6573 2077 6865  k out values whe
+000028f0: 6e20 636f 756e 7473 2069 7320 6865 7465  n counts is hete
+00002900: 726f 6765 6e65 6f75 730a 2020 6966 206a  rogeneous.  if j
+00002910: 6e70 2e6e 6469 6d28 6e29 203e 2030 3a0a  np.ndim(n) > 0:.
+00002920: 2020 2020 6d61 736b 203d 205f 7072 6f6d      mask = _prom
+00002930: 6f74 655f 7368 6170 6573 286a 6e70 2e61  ote_shapes(jnp.a
+00002940: 7261 6e67 6528 6e5f 6d61 7829 203c 206a  range(n_max) < j
+00002950: 6e70 2e65 7870 616e 645f 6469 6d73 286e  np.expand_dims(n
+00002960: 2c20 2d31 292c 2073 6861 7065 3d73 6861  , -1), shape=sha
+00002970: 7065 202b 2028 6e5f 6d61 782c 2929 5b30  pe + (n_max,))[0
+00002980: 5d0a 2020 2020 6d61 736b 203d 206a 6e70  ].    mask = jnp
+00002990: 2e6d 6f76 6561 7869 7328 6d61 736b 2c20  .moveaxis(mask, 
+000029a0: 2d31 2c20 3029 2e61 7374 7970 6528 696e  -1, 0).astype(in
+000029b0: 6469 6365 732e 6474 7970 6529 0a20 2020  dices.dtype).   
+000029c0: 2065 7863 6573 7320 3d20 6a6e 702e 636f   excess = jnp.co
+000029d0: 6e63 6174 656e 6174 6528 5b6a 6e70 2e65  ncatenate([jnp.e
+000029e0: 7870 616e 645f 6469 6d73 286e 5f6d 6178  xpand_dims(n_max
+000029f0: 202d 206e 2c20 2d31 292c 0a20 2020 2020   - n, -1),.     
+00002a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002a10: 2020 2020 2020 2020 206a 6e70 2e7a 6572           jnp.zer
+00002a20: 6f73 286a 6e70 2e73 6861 7065 286e 2920  os(jnp.shape(n) 
+00002a30: 2b20 2870 2e73 6861 7065 5b2d 315d 202d  + (p.shape[-1] -
+00002a40: 2031 2c29 295d 2c0a 2020 2020 2020 2020   1,))],.        
+00002a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002a60: 2020 2020 202d 3129 0a20 2065 6c73 653a       -1).  else:
+00002a70: 0a20 2020 206d 6173 6b20 3d20 310a 2020  .    mask = 1.  
+00002a80: 2020 6578 6365 7373 203d 2030 0a20 2023    excess = 0.  #
+00002a90: 204e 423a 2077 6520 7472 616e 7370 6f73   NB: we transpos
+00002aa0: 6520 746f 206d 6f76 6520 6261 7463 6820  e to move batch 
+00002ab0: 7368 6170 6520 746f 2074 6865 2066 726f  shape to the fro
+00002ac0: 6e74 0a20 2069 6e64 6963 6573 5f32 4420  nt.  indices_2D 
+00002ad0: 3d20 286a 6e70 2e72 6573 6861 7065 2869  = (jnp.reshape(i
+00002ae0: 6e64 6963 6573 202a 206d 6173 6b2c 2028  ndices * mask, (
+00002af0: 6e5f 6d61 782c 202d 3129 2929 2e54 0a20  n_max, -1))).T. 
+00002b00: 2073 616d 706c 6573 5f32 4420 3d20 766d   samples_2D = vm
+00002b10: 6170 285f 7363 6174 7465 725f 6164 645f  ap(_scatter_add_
+00002b20: 6f6e 6529 286a 6e70 2e7a 6572 6f73 2828  one)(jnp.zeros((
+00002b30: 696e 6469 6365 735f 3244 2e73 6861 7065  indices_2D.shape
+00002b40: 5b30 5d2c 2070 2e73 6861 7065 5b2d 315d  [0], p.shape[-1]
+00002b50: 292c 2064 7479 7065 3d69 6e64 6963 6573  ), dtype=indices
+00002b60: 2e64 7479 7065 292c 0a20 2020 2020 2020  .dtype),.       
+00002b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b80: 2020 2020 2020 2020 2020 2020 2020 206a                 j
+00002b90: 6e70 2e65 7870 616e 645f 6469 6d73 2869  np.expand_dims(i
+00002ba0: 6e64 6963 6573 5f32 442c 2061 7869 733d  ndices_2D, axis=
+00002bb0: 2d31 292c 0a20 2020 2020 2020 2020 2020  -1),.           
 00002bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002be0: 2020 2020 6a6e 702e 6f6e 6573 2869 6e64      jnp.ones(ind
-00002bf0: 6963 6573 5f32 442e 7368 6170 652c 2064  ices_2D.shape, d
-00002c00: 7479 7065 3d69 6e64 6963 6573 2e64 7479  type=indices.dty
-00002c10: 7065 2929 0a20 2072 6574 7572 6e20 6a6e  pe)).  return jn
-00002c20: 702e 7265 7368 6170 6528 7361 6d70 6c65  p.reshape(sample
-00002c30: 735f 3244 2c20 7368 6170 6520 2b20 702e  s_2D, shape + p.
-00002c40: 7368 6170 655b 2d31 3a5d 2920 2d20 6578  shape[-1:]) - ex
-00002c50: 6365 7373 0a0a 0a40 7061 7274 6961 6c28  cess...@partial(
-00002c60: 6a69 742c 2073 7461 7469 635f 6172 676e  jit, static_argn
-00002c70: 756d 733d 2832 2c20 3329 290a 6465 6620  ums=(2, 3)).def 
-00002c80: 5f76 6f6e 5f6d 6973 6573 5f63 656e 7465  _von_mises_cente
-00002c90: 7265 6428 6b65 792c 2063 6f6e 6365 6e74  red(key, concent
-00002ca0: 7261 7469 6f6e 2c20 7368 6170 652c 2064  ration, shape, d
-00002cb0: 7479 7065 3d6a 6e70 2e66 6c6f 6174 3634  type=jnp.float64
-00002cc0: 293a 0a20 2022 2222 436f 6d70 7574 6520  ):.  """Compute 
-00002cd0: 6365 6e74 6572 6564 2076 6f6e 204d 6973  centered von Mis
-00002ce0: 6573 2073 616d 706c 6573 2075 7369 6e67  es samples using
-00002cf0: 2072 656a 6563 7469 6f6e 2073 616d 706c   rejection sampl
-00002d00: 696e 6720 6672 6f6d 205b 315d 5f20 7769  ing from [1]_ wi
-00002d10: 7468 2077 7261 7070 6564 2043 6175 6368  th wrapped Cauch
-00002d20: 7920 7072 6f70 6f73 616c 2e0a 0a20 2052  y proposal...  R
-00002d30: 6574 7572 6e73 0a20 202d 2d2d 2d2d 2d2d  eturns.  -------
-00002d40: 0a20 206f 7574 3a20 6172 7261 795f 6c69  .  out: array_li
-00002d50: 6b65 0a20 2020 2020 6365 6e74 6572 6564  ke.     centered
-00002d60: 2073 616d 706c 6573 2066 726f 6d20 766f   samples from vo
-00002d70: 6e20 4d69 7365 730a 0a20 2052 6566 6572  n Mises..  Refer
-00002d80: 656e 6365 730a 2020 2d2d 2d2d 2d2d 2d2d  ences.  --------
-00002d90: 2d2d 0a20 202e 2e20 5b31 5d20 4c75 6320  --.  .. [1] Luc 
-00002da0: 4465 7672 6f79 6520 224e 6f6e 2d55 6e69  Devroye "Non-Uni
-00002db0: 666f 726d 2052 616e 646f 6d20 5661 7269  form Random Vari
-00002dc0: 6174 6520 4765 6e65 7261 7469 6f6e 222c  ate Generation",
-00002dd0: 2053 7072 696e 6765 722d 5665 726c 6167   Springer-Verlag
-00002de0: 2c20 3139 3836 3b0a 2020 2020 2020 2020  , 1986;.        
-00002df0: 2043 6861 7074 6572 2039 2c20 702e 2034   Chapter 9, p. 4
-00002e00: 3733 2d34 3736 2e20 6874 7470 3a2f 2f77  73-476. http://w
-00002e10: 7777 2e6e 7262 6f6f 6b2e 636f 6d2f 6465  ww.nrbook.com/de
-00002e20: 7672 6f79 652f 4465 7672 6f79 655f 6669  vroye/Devroye_fi
-00002e30: 6c65 732f 6368 6170 7465 725f 6e69 6e65  les/chapter_nine
-00002e40: 2e70 6466 0a0a 2020 2222 220a 2020 7368  .pdf..  """.  sh
-00002e50: 6170 6520 3d20 7368 6170 6520 6f72 206a  ape = shape or j
-00002e60: 6e70 2e73 6861 7065 2863 6f6e 6365 6e74  np.shape(concent
-00002e70: 7261 7469 6f6e 290a 2020 6474 7970 6520  ration).  dtype 
-00002e80: 3d20 6a6e 702e 7265 7375 6c74 5f74 7970  = jnp.result_typ
-00002e90: 6528 6474 7970 6529 0a20 2063 6f6e 6365  e(dtype).  conce
-00002ea0: 6e74 7261 7469 6f6e 203d 206c 6178 2e63  ntration = lax.c
-00002eb0: 6f6e 7665 7274 5f65 6c65 6d65 6e74 5f74  onvert_element_t
-00002ec0: 7970 6528 636f 6e63 656e 7472 6174 696f  ype(concentratio
-00002ed0: 6e2c 2064 7479 7065 290a 2020 636f 6e63  n, dtype).  conc
-00002ee0: 656e 7472 6174 696f 6e20 3d20 6a6e 702e  entration = jnp.
-00002ef0: 6272 6f61 6463 6173 745f 746f 2863 6f6e  broadcast_to(con
-00002f00: 6365 6e74 7261 7469 6f6e 2c20 7368 6170  centration, shap
-00002f10: 6529 0a0a 2020 735f 6375 746f 6666 5f6d  e)..  s_cutoff_m
-00002f20: 6170 203d 207b 0a20 2020 206a 6e70 2e64  ap = {.    jnp.d
-00002f30: 7479 7065 286a 6e70 2e66 6c6f 6174 3136  type(jnp.float16
-00002f40: 293a 2031 2e38 652d 312c 0a20 2020 206a  ): 1.8e-1,.    j
-00002f50: 6e70 2e64 7479 7065 286a 6e70 2e66 6c6f  np.dtype(jnp.flo
-00002f60: 6174 3332 293a 2032 652d 322c 0a20 2020  at32): 2e-2,.   
-00002f70: 206a 6e70 2e64 7479 7065 286a 6e70 2e66   jnp.dtype(jnp.f
-00002f80: 6c6f 6174 3634 293a 2031 2e32 652d 342c  loat64): 1.2e-4,
-00002f90: 0a20 207d 0a20 2073 5f63 7574 6f66 6620  .  }.  s_cutoff 
-00002fa0: 3d20 735f 6375 746f 6666 5f6d 6170 2e67  = s_cutoff_map.g
-00002fb0: 6574 2864 7479 7065 290a 0a20 2072 203d  et(dtype)..  r =
-00002fc0: 2031 2e30 202b 206a 6e70 2e73 7172 7428   1.0 + jnp.sqrt(
-00002fd0: 312e 3020 2b20 342e 3020 2a20 636f 6e63  1.0 + 4.0 * conc
-00002fe0: 656e 7472 6174 696f 6e20 2a2a 2032 290a  entration ** 2).
-00002ff0: 2020 7268 6f20 3d20 2872 202d 206a 6e70    rho = (r - jnp
-00003000: 2e73 7172 7428 322e 3020 2a20 7229 2920  .sqrt(2.0 * r)) 
-00003010: 2f20 2832 2e30 202a 2063 6f6e 6365 6e74  / (2.0 * concent
-00003020: 7261 7469 6f6e 290a 2020 735f 6578 6163  ration).  s_exac
-00003030: 7420 3d20 2831 2e30 202b 2072 686f 202a  t = (1.0 + rho *
-00003040: 2a20 3229 202f 2028 322e 3020 2a20 7268  * 2) / (2.0 * rh
-00003050: 6f29 0a0a 2020 735f 6170 7072 6f78 696d  o)..  s_approxim
-00003060: 6174 6520 3d20 312e 3020 2f20 636f 6e63  ate = 1.0 / conc
-00003070: 656e 7472 6174 696f 6e0a 0a20 2073 203d  entration..  s =
-00003080: 206a 6e70 2e77 6865 7265 2863 6f6e 6365   jnp.where(conce
-00003090: 6e74 7261 7469 6f6e 203e 2073 5f63 7574  ntration > s_cut
-000030a0: 6f66 662c 2073 5f65 7861 6374 2c20 735f  off, s_exact, s_
-000030b0: 6170 7072 6f78 696d 6174 6529 0a0a 2020  approximate)..  
-000030c0: 6465 6620 636f 6e64 5f66 6e28 2a61 7267  def cond_fn(*arg
-000030d0: 7329 3a0a 2020 2020 2222 2263 6865 636b  s):.    """check
-000030e0: 2069 6620 616c 6c20 6172 6520 646f 6e65   if all are done
-000030f0: 206f 7220 7265 6163 6865 6420 6d61 7820   or reached max 
-00003100: 6e75 6d62 6572 206f 6620 6974 6572 6174  number of iterat
-00003110: 696f 6e73 2222 220a 2020 2020 692c 205f  ions""".    i, _
-00003120: 2c20 646f 6e65 2c20 5f2c 205f 203d 2061  , done, _, _ = a
-00003130: 7267 735b 305d 0a20 2020 2072 6574 7572  rgs[0].    retur
-00003140: 6e20 6a6e 702e 6269 7477 6973 655f 616e  n jnp.bitwise_an
-00003150: 6428 6920 3c20 3130 302c 206a 6e70 2e6c  d(i < 100, jnp.l
-00003160: 6f67 6963 616c 5f6e 6f74 286a 6e70 2e61  ogical_not(jnp.a
-00003170: 6c6c 2864 6f6e 6529 2929 0a0a 2020 6465  ll(done)))..  de
-00003180: 6620 626f 6479 5f66 6e28 2a61 7267 7329  f body_fn(*args)
-00003190: 3a0a 2020 2020 692c 206b 6579 2c20 646f  :.    i, key, do
-000031a0: 6e65 2c20 5f2c 2077 203d 2061 7267 735b  ne, _, w = args[
-000031b0: 305d 0a20 2020 2075 6e69 5f75 6b65 792c  0].    uni_ukey,
-000031c0: 2075 6e69 5f76 6b65 792c 206b 6579 203d   uni_vkey, key =
-000031d0: 206a 722e 7370 6c69 7428 6b65 792c 2033   jr.split(key, 3
-000031e0: 290a 2020 2020 7520 3d20 6a72 2e75 6e69  ).    u = jr.uni
-000031f0: 666f 726d 280a 2020 2020 2020 6b65 793d  form(.      key=
-00003200: 756e 695f 756b 6579 2c0a 2020 2020 2020  uni_ukey,.      
-00003210: 7368 6170 653d 7368 6170 652c 0a20 2020  shape=shape,.   
-00003220: 2020 2064 7479 7065 3d63 6f6e 6365 6e74     dtype=concent
-00003230: 7261 7469 6f6e 2e64 7479 7065 2c0a 2020  ration.dtype,.  
-00003240: 2020 2020 6d69 6e76 616c 3d2d 312e 302c      minval=-1.0,
-00003250: 0a20 2020 2020 206d 6178 7661 6c3d 312e  .      maxval=1.
-00003260: 302c 0a20 2020 2029 0a20 2020 207a 203d  0,.    ).    z =
-00003270: 206a 6e70 2e63 6f73 286a 6e70 2e70 6920   jnp.cos(jnp.pi 
-00003280: 2a20 7529 0a20 2020 2077 203d 206a 6e70  * u).    w = jnp
-00003290: 2e77 6865 7265 2864 6f6e 652c 2077 2c20  .where(done, w, 
-000032a0: 2831 2e30 202b 2073 202a 207a 2920 2f20  (1.0 + s * z) / 
-000032b0: 2873 202b 207a 2929 2020 2320 5570 6461  (s + z))  # Upda
-000032c0: 7465 2077 6865 7265 206e 6f74 2064 6f6e  te where not don
-000032d0: 650a 2020 2020 7920 3d20 636f 6e63 656e  e.    y = concen
-000032e0: 7472 6174 696f 6e20 2a20 2873 202d 2077  tration * (s - w
-000032f0: 290a 2020 2020 7620 3d20 6a72 2e75 6e69  ).    v = jr.uni
-00003300: 666f 726d 286b 6579 3d75 6e69 5f76 6b65  form(key=uni_vke
-00003310: 792c 2073 6861 7065 3d73 6861 7065 2c20  y, shape=shape, 
-00003320: 6474 7970 653d 636f 6e63 656e 7472 6174  dtype=concentrat
-00003330: 696f 6e2e 6474 7970 6529 0a20 2020 2061  ion.dtype).    a
-00003340: 6363 6570 7420 3d20 2879 202a 2028 322e  ccept = (y * (2.
-00003350: 3020 2d20 7929 203e 3d20 7629 207c 2028  0 - y) >= v) | (
-00003360: 6a6e 702e 6c6f 6728 7920 2f20 7629 202b  jnp.log(y / v) +
-00003370: 2031 2e30 203e 3d20 7929 0a20 2020 2072   1.0 >= y).    r
-00003380: 6574 7572 6e20 6920 2b20 312c 206b 6579  eturn i + 1, key
-00003390: 2c20 6163 6365 7074 207c 2064 6f6e 652c  , accept | done,
-000033a0: 2075 2c20 770a 0a20 2069 6e69 745f 646f   u, w..  init_do
-000033b0: 6e65 203d 206a 6e70 2e7a 6572 6f73 2873  ne = jnp.zeros(s
-000033c0: 6861 7065 2c20 6474 7970 653d 626f 6f6c  hape, dtype=bool
-000033d0: 290a 2020 696e 6974 5f75 203d 206a 6e70  ).  init_u = jnp
-000033e0: 2e7a 6572 6f73 2873 6861 7065 290a 2020  .zeros(shape).  
-000033f0: 696e 6974 5f77 203d 206a 6e70 2e7a 6572  init_w = jnp.zer
-00003400: 6f73 2873 6861 7065 290a 0a20 205f 2c20  os(shape)..  _, 
-00003410: 5f2c 2064 6f6e 652c 2075 2c20 7720 3d20  _, done, u, w = 
-00003420: 6c61 782e 7768 696c 655f 6c6f 6f70 280a  lax.while_loop(.
-00003430: 2020 2020 636f 6e64 5f66 756e 3d63 6f6e      cond_fun=con
-00003440: 645f 666e 2c0a 2020 2020 626f 6479 5f66  d_fn,.    body_f
-00003450: 756e 3d62 6f64 795f 666e 2c0a 2020 2020  un=body_fn,.    
-00003460: 696e 6974 5f76 616c 3d28 6a6e 702e 6172  init_val=(jnp.ar
-00003470: 7261 7928 3029 2c20 6b65 792c 2069 6e69  ray(0), key, ini
-00003480: 745f 646f 6e65 2c20 696e 6974 5f75 2c20  t_done, init_u, 
-00003490: 696e 6974 5f77 292c 0a20 2029 0a0a 2020  init_w),.  )..  
-000034a0: 7265 7475 726e 206a 6e70 2e73 6967 6e28  return jnp.sign(
-000034b0: 7529 202a 206a 6e70 2e61 7263 636f 7328  u) * jnp.arccos(
-000034c0: 7729 0a0a 0a64 6566 205f 6c6f 635f 7363  w)...def _loc_sc
-000034d0: 616c 6528 6c6f 632c 2073 6361 6c65 2c20  ale(loc, scale, 
-000034e0: 7661 6c75 6529 3a0a 2020 6966 206c 6f63  value):.  if loc
-000034f0: 2069 7320 4e6f 6e65 3a0a 2020 2020 6966   is None:.    if
-00003500: 2073 6361 6c65 2069 7320 4e6f 6e65 3a0a   scale is None:.
-00003510: 2020 2020 2020 7265 7475 726e 2076 616c        return val
-00003520: 7565 0a20 2020 2065 6c73 653a 0a20 2020  ue.    else:.   
-00003530: 2020 2072 6574 7572 6e20 7661 6c75 6520     return value 
-00003540: 2a20 7363 616c 650a 2020 656c 7365 3a0a  * scale.  else:.
-00003550: 2020 2020 6966 2073 6361 6c65 2069 7320      if scale is 
-00003560: 4e6f 6e65 3a0a 2020 2020 2020 7265 7475  None:.      retu
-00003570: 726e 2076 616c 7565 202b 206c 6f63 0a20  rn value + loc. 
-00003580: 2020 2065 6c73 653a 0a20 2020 2020 2072     else:.      r
-00003590: 6574 7572 6e20 7661 6c75 6520 2a20 7363  eturn value * sc
-000035a0: 616c 6520 2b20 6c6f 630a 0a0a 6465 6620  ale + loc...def 
-000035b0: 5f63 6865 636b 5f70 795f 7365 7128 7365  _check_py_seq(se
-000035c0: 7129 3a0a 2020 7265 7475 726e 206a 6e70  q):.  return jnp
-000035d0: 2e61 7361 7272 6179 2873 6571 2920 6966  .asarray(seq) if
-000035e0: 2069 7369 6e73 7461 6e63 6528 7365 712c   isinstance(seq,
-000035f0: 2028 7475 706c 652c 206c 6973 7429 2920   (tuple, list)) 
-00003600: 656c 7365 2073 6571 0a0a 0a40 7265 6769  else seq...@regi
-00003610: 7374 6572 5f70 7974 7265 655f 6e6f 6465  ster_pytree_node
-00003620: 5f63 6c61 7373 0a63 6c61 7373 2052 616e  _class.class Ran
-00003630: 646f 6d53 7461 7465 2856 6172 6961 626c  domState(Variabl
-00003640: 6529 3a0a 2020 2222 2252 616e 646f 6d53  e):.  """RandomS
-00003650: 7461 7465 2074 6861 7420 7472 6163 6b20  tate that track 
-00003660: 7468 6520 7261 6e64 6f6d 2067 656e 6572  the random gener
-00003670: 6174 6f72 2073 7461 7465 2e20 2222 220a  ator state. """.
-00003680: 2020 5f5f 736c 6f74 735f 5f20 3d20 2829    __slots__ = ()
-00003690: 0a0a 2020 6465 6620 5f5f 696e 6974 5f5f  ..  def __init__
-000036a0: 280a 2020 2020 2020 7365 6c66 2c0a 2020  (.      self,.  
-000036b0: 2020 2020 7365 6564 5f6f 725f 6b65 793a      seed_or_key:
-000036c0: 204f 7074 696f 6e61 6c5b 556e 696f 6e5b   Optional[Union[
-000036d0: 696e 742c 2041 7272 6179 2c20 6a61 782e  int, Array, jax.
-000036e0: 4172 7261 792c 206e 702e 6e64 6172 7261  Array, np.ndarra
-000036f0: 795d 5d20 3d20 4e6f 6e65 2c0a 2020 2020  y]] = None,.    
-00003700: 2020 7365 6564 3a20 4f70 7469 6f6e 616c    seed: Optional
-00003710: 5b69 6e74 5d20 3d20 4e6f 6e65 2c0a 2020  [int] = None,.  
-00003720: 2020 2020 5f72 6561 6479 5f74 6f5f 7472      _ready_to_tr
-00003730: 6163 653a 2062 6f6f 6c20 3d20 5472 7565  ace: bool = True
-00003740: 2c0a 2020 293a 0a20 2020 2022 2222 5261  ,.  ):.    """Ra
-00003750: 6e64 6f6d 5374 6174 6520 636f 6e73 7472  ndomState constr
-00003760: 7563 746f 722e 0a0a 2020 2020 5061 7261  uctor...    Para
-00003770: 6d65 7465 7273 0a20 2020 202d 2d2d 2d2d  meters.    -----
-00003780: 2d2d 2d2d 2d0a 2020 2020 7365 6564 5f6f  -----.    seed_o
-00003790: 725f 6b65 793a 2069 6e74 2c20 4172 7261  r_key: int, Arra
-000037a0: 792c 206f 7074 696f 6e61 6c0a 2020 2020  y, optional.    
-000037b0: 2020 4974 2063 616e 2062 6520 616e 2069    It can be an i
-000037c0: 6e74 6567 6572 2066 6f72 2069 6e69 7469  nteger for initi
-000037d0: 616c 2073 6565 6420 6f66 2074 6865 2072  al seed of the r
-000037e0: 616e 646f 6d20 6e75 6d62 6572 2067 656e  andom number gen
-000037f0: 6572 6174 6f72 2c0a 2020 2020 2020 6f72  erator,.      or
-00003800: 2069 7420 6361 6e20 6265 2061 204a 4158   it can be a JAX
-00003810: 2773 2050 524e 4b65 792c 2077 6869 6368  's PRNKey, which
-00003820: 2069 7320 616e 2061 7272 6179 2077 6974   is an array wit
-00003830: 6820 7477 6f20 656c 656d 656e 7473 2061  h two elements a
-00003840: 6e64 2060 7569 6e74 3332 6020 6474 7970  nd `uint32` dtyp
-00003850: 652e 0a0a 2020 2020 2020 2e2e 2076 6572  e...      .. ver
-00003860: 7369 6f6e 6164 6465 643a 3a20 322e 322e  sionadded:: 2.2.
-00003870: 332e 340a 0a20 2020 2073 6565 6420 3a20  3.4..    seed : 
-00003880: 696e 742c 2041 7272 6179 5479 7065 2c20  int, ArrayType, 
-00003890: 6f70 7469 6f6e 616c 0a20 2020 2020 2053  optional.      S
-000038a0: 616d 6520 6173 2060 7365 6564 5f6f 725f  ame as `seed_or_
-000038b0: 6b65 7960 2e0a 0a20 2020 2020 202e 2e20  key`...      .. 
-000038c0: 6465 7072 6563 6174 6564 3a3a 2032 2e32  deprecated:: 2.2
-000038d0: 2e33 2e34 0a20 2020 2020 2020 2020 5769  .3.4.         Wi
-000038e0: 6c6c 2062 6520 7265 6d6f 7665 6420 7369  ll be removed si
-000038f0: 6e63 6520 7665 7273 696f 6e20 322e 342e  nce version 2.4.
-00003900: 0a20 2020 2022 2222 0a20 2020 2069 6620  .    """.    if 
-00003910: 7365 6564 2069 7320 6e6f 7420 4e6f 6e65  seed is not None
-00003920: 3a0a 2020 2020 2020 6966 2073 6565 645f  :.      if seed_
-00003930: 6f72 5f6b 6579 2069 7320 6e6f 7420 4e6f  or_key is not No
-00003940: 6e65 3a0a 2020 2020 2020 2020 7261 6973  ne:.        rais
-00003950: 6520 5661 6c75 6545 7272 6f72 2827 506c  e ValueError('Pl
-00003960: 6561 7365 2073 6574 2022 7365 6564 5f6f  ease set "seed_o
-00003970: 725f 6b65 7922 206f 7220 2273 6565 6422  r_key" or "seed"
-00003980: 2c20 6e6f 7420 626f 7468 2e27 290a 2020  , not both.').  
-00003990: 2020 2020 7365 6564 5f6f 725f 6b65 7920      seed_or_key 
-000039a0: 3d20 7365 6564 0a20 2020 2020 2077 6172  = seed.      war
-000039b0: 6e69 6e67 732e 7761 726e 2827 506c 6561  nings.warn('Plea
-000039c0: 7365 2075 7365 2060 7365 6564 5f6f 725f  se use `seed_or_
-000039d0: 6b65 7960 2069 6e73 7465 6164 2e20 270a  key` instead. '.
-000039e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000039f0: 2020 2020 2773 6565 6420 7769 6c6c 2062      'seed will b
-00003a00: 6520 7265 6d6f 7665 6420 7369 6e63 6520  e removed since 
-00003a10: 322e 342e 3027 2c20 5573 6572 5761 726e  2.4.0', UserWarn
-00003a20: 696e 6729 0a0a 2020 2020 7769 7468 206a  ing)..    with j
-00003a30: 6178 2e65 6e73 7572 655f 636f 6d70 696c  ax.ensure_compil
-00003a40: 655f 7469 6d65 5f65 7661 6c28 293a 0a20  e_time_eval():. 
-00003a50: 2020 2020 2069 6620 7365 6564 5f6f 725f       if seed_or_
-00003a60: 6b65 7920 6973 204e 6f6e 653a 0a20 2020  key is None:.   
-00003a70: 2020 2020 2073 6565 645f 6f72 5f6b 6579       seed_or_key
-00003a80: 203d 206e 702e 7261 6e64 6f6d 2e72 616e   = np.random.ran
-00003a90: 6469 6e74 2830 2c20 3130 3030 3030 2c20  dint(0, 100000, 
-00003aa0: 322c 2064 7479 7065 3d6e 702e 7569 6e74  2, dtype=np.uint
-00003ab0: 3332 290a 2020 2020 6966 2069 7369 6e73  32).    if isins
-00003ac0: 7461 6e63 6528 7365 6564 5f6f 725f 6b65  tance(seed_or_ke
-00003ad0: 792c 2069 6e74 293a 0a20 2020 2020 206b  y, int):.      k
-00003ae0: 6579 203d 206a 722e 5052 4e47 4b65 7928  ey = jr.PRNGKey(
-00003af0: 7365 6564 5f6f 725f 6b65 7929 0a20 2020  seed_or_key).   
-00003b00: 2065 6c73 653a 0a20 2020 2020 2069 6620   else:.      if 
-00003b10: 6c65 6e28 7365 6564 5f6f 725f 6b65 7929  len(seed_or_key)
-00003b20: 2021 3d20 3220 616e 6420 7365 6564 5f6f   != 2 and seed_o
-00003b30: 725f 6b65 792e 6474 7970 6520 213d 206e  r_key.dtype != n
-00003b40: 702e 7569 6e74 3332 3a0a 2020 2020 2020  p.uint32:.      
-00003b50: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-00003b60: 6f72 2827 6b65 7920 6d75 7374 2062 6520  or('key must be 
-00003b70: 616e 2061 7272 6179 2077 6974 6820 6474  an array with dt
-00003b80: 7970 6520 7569 6e74 3332 2e20 270a 2020  ype uint32. '.  
-00003b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003ba0: 2020 2020 2020 2066 2742 7574 2077 6520         f'But we 
-00003bb0: 676f 7420 7b73 6565 645f 6f72 5f6b 6579  got {seed_or_key
-00003bc0: 7d27 290a 2020 2020 2020 6b65 7920 3d20  }').      key = 
-00003bd0: 7365 6564 5f6f 725f 6b65 790a 2020 2020  seed_or_key.    
-00003be0: 7375 7065 7228 5261 6e64 6f6d 5374 6174  super(RandomStat
-00003bf0: 652c 2073 656c 6629 2e5f 5f69 6e69 745f  e, self).__init_
-00003c00: 5f28 6b65 792c 205f 7265 6164 795f 746f  _(key, _ready_to
-00003c10: 5f74 7261 6365 3d5f 7265 6164 795f 746f  _trace=_ready_to
-00003c20: 5f74 7261 6365 290a 0a20 2064 6566 205f  _trace)..  def _
-00003c30: 5f72 6570 725f 5f28 7365 6c66 2920 2d3e  _repr__(self) ->
-00003c40: 2073 7472 3a0a 2020 2020 7072 696e 745f   str:.    print_
-00003c50: 636f 6465 203d 2072 6570 7228 7365 6c66  code = repr(self
-00003c60: 2e76 616c 7565 290a 2020 2020 6920 3d20  .value).    i = 
-00003c70: 7072 696e 745f 636f 6465 2e69 6e64 6578  print_code.index
-00003c80: 2827 2827 290a 2020 2020 6e61 6d65 203d  ('(').    name =
-00003c90: 2073 656c 662e 5f5f 636c 6173 735f 5f2e   self.__class__.
-00003ca0: 5f5f 6e61 6d65 5f5f 0a20 2020 2072 6574  __name__.    ret
-00003cb0: 7572 6e20 6627 7b6e 616d 657d 286b 6579  urn f'{name}(key
-00003cc0: 3d7b 7072 696e 745f 636f 6465 5b69 3a5d  ={print_code[i:]
-00003cd0: 7d29 270a 0a20 2023 202d 2d2d 2d2d 2d2d  })'..  # -------
-00003ce0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2023 0a20  ------------ #. 
-00003cf0: 2023 2073 6565 6420 616e 6420 7261 6e64   # seed and rand
-00003d00: 6f6d 206b 6579 2023 0a20 2023 202d 2d2d  om key #.  # ---
-00003d10: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00003d20: 2023 0a0a 2020 6465 6620 636c 6f6e 6528   #..  def clone(
-00003d30: 7365 6c66 293a 0a20 2020 2072 6574 7572  self):.    retur
-00003d40: 6e20 7479 7065 2873 656c 6629 2873 656c  n type(self)(sel
-00003d50: 662e 7370 6c69 745f 6b65 7928 2929 0a0a  f.split_key())..
-00003d60: 2020 6465 6620 7365 6564 2873 656c 662c    def seed(self,
-00003d70: 2073 6565 645f 6f72 5f6b 6579 3d4e 6f6e   seed_or_key=Non
-00003d80: 652c 2073 6565 643d 4e6f 6e65 293a 0a20  e, seed=None):. 
-00003d90: 2020 2022 2222 5365 7473 2061 206e 6577     """Sets a new
-00003da0: 2072 616e 646f 6d20 7365 6564 2e0a 0a20   random seed... 
-00003db0: 2020 2050 6172 616d 6574 6572 730a 2020     Parameters.  
-00003dc0: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020    ----------.   
-00003dd0: 2073 6565 645f 6f72 5f6b 6579 3a20 696e   seed_or_key: in
-00003de0: 742c 2041 7272 6179 5479 7065 2c20 6f70  t, ArrayType, op
-00003df0: 7469 6f6e 616c 0a20 2020 2020 2049 7420  tional.      It 
-00003e00: 6361 6e20 6265 2061 6e20 696e 7465 6765  can be an intege
-00003e10: 7220 666f 7220 696e 6974 6961 6c20 7365  r for initial se
-00003e20: 6564 206f 6620 7468 6520 7261 6e64 6f6d  ed of the random
-00003e30: 206e 756d 6265 7220 6765 6e65 7261 746f   number generato
-00003e40: 722c 0a20 2020 2020 206f 7220 6974 2063  r,.      or it c
-00003e50: 616e 2062 6520 6120 4a41 5827 7320 5052  an be a JAX's PR
-00003e60: 4e4b 6579 2c20 7768 6963 6820 6973 2061  NKey, which is a
-00003e70: 6e20 6172 7261 7920 7769 7468 2074 776f  n array with two
-00003e80: 2065 6c65 6d65 6e74 7320 616e 6420 6075   elements and `u
-00003e90: 696e 7433 3260 2064 7479 7065 2e0a 0a20  int32` dtype... 
-00003ea0: 2020 2020 202e 2e20 7665 7273 696f 6e61       .. versiona
-00003eb0: 6464 6564 3a3a 2032 2e32 2e33 2e34 0a0a  dded:: 2.2.3.4..
-00003ec0: 2020 2020 7365 6564 203a 2069 6e74 2c20      seed : int, 
-00003ed0: 4172 7261 7954 7970 652c 206f 7074 696f  ArrayType, optio
-00003ee0: 6e61 6c0a 2020 2020 2020 5361 6d65 2061  nal.      Same a
-00003ef0: 7320 6073 6565 645f 6f72 5f6b 6579 602e  s `seed_or_key`.
-00003f00: 0a0a 2020 2020 2020 2e2e 2064 6570 7265  ..      .. depre
-00003f10: 6361 7465 643a 3a20 322e 322e 332e 340a  cated:: 2.2.3.4.
-00003f20: 2020 2020 2020 2020 2057 696c 6c20 6265           Will be
-00003f30: 2072 656d 6f76 6564 2073 696e 6365 2076   removed since v
-00003f40: 6572 7369 6f6e 2032 2e34 2e0a 2020 2020  ersion 2.4..    
-00003f50: 2222 220a 2020 2020 6966 2073 6565 6420  """.    if seed 
-00003f60: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-00003f70: 2020 2069 6620 7365 6564 5f6f 725f 6b65     if seed_or_ke
-00003f80: 7920 6973 206e 6f74 204e 6f6e 653a 0a20  y is not None:. 
-00003f90: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-00003fa0: 7565 4572 726f 7228 2750 6c65 6173 6520  ueError('Please 
-00003fb0: 7365 7420 2273 6565 645f 6f72 5f6b 6579  set "seed_or_key
-00003fc0: 2220 6f72 2022 7365 6564 222c 206e 6f74  " or "seed", not
-00003fd0: 2062 6f74 682e 2729 0a20 2020 2020 2073   both.').      s
-00003fe0: 6565 645f 6f72 5f6b 6579 203d 2073 6565  eed_or_key = see
-00003ff0: 640a 2020 2020 2020 7761 726e 696e 6773  d.      warnings
-00004000: 2e77 6172 6e28 2750 6c65 6173 6520 7573  .warn('Please us
-00004010: 6520 7365 6564 5f6f 725f 6b65 7920 696e  e seed_or_key in
-00004020: 7374 6561 642e 2027 0a20 2020 2020 2020  stead. '.       
-00004030: 2020 2020 2020 2020 2020 2020 2027 7365               'se
-00004040: 6564 2077 696c 6c20 6265 2072 656d 6f76  ed will be remov
-00004050: 6564 2073 696e 6365 2032 2e34 2e30 272c  ed since 2.4.0',
-00004060: 2055 7365 7257 6172 6e69 6e67 290a 0a20   UserWarning).. 
-00004070: 2020 2069 6620 7365 6564 5f6f 725f 6b65     if seed_or_ke
-00004080: 7920 6973 204e 6f6e 653a 0a20 2020 2020  y is None:.     
-00004090: 2073 6565 645f 6f72 5f6b 6579 203d 206e   seed_or_key = n
-000040a0: 702e 7261 6e64 6f6d 2e72 616e 6469 6e74  p.random.randint
-000040b0: 2830 2c20 3130 3030 3030 2c20 322c 2064  (0, 100000, 2, d
-000040c0: 7479 7065 3d6e 702e 7569 6e74 3332 290a  type=np.uint32).
-000040d0: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
-000040e0: 6528 7365 6564 5f6f 725f 6b65 792c 2069  e(seed_or_key, i
-000040f0: 6e74 293a 0a20 2020 2020 206b 6579 203d  nt):.      key =
-00004100: 206a 722e 5052 4e47 4b65 7928 7365 6564   jr.PRNGKey(seed
-00004110: 5f6f 725f 6b65 7929 0a20 2020 2065 6c73  _or_key).    els
-00004120: 653a 0a20 2020 2020 2069 6620 6c65 6e28  e:.      if len(
-00004130: 7365 6564 5f6f 725f 6b65 7929 2021 3d20  seed_or_key) != 
-00004140: 3220 616e 6420 7365 6564 5f6f 725f 6b65  2 and seed_or_ke
-00004150: 792e 6474 7970 6520 213d 206e 702e 7569  y.dtype != np.ui
-00004160: 6e74 3332 3a0a 2020 2020 2020 2020 7261  nt32:.        ra
-00004170: 6973 6520 5661 6c75 6545 7272 6f72 2827  ise ValueError('
-00004180: 6b65 7920 6d75 7374 2062 6520 616e 2061  key must be an a
-00004190: 7272 6179 2077 6974 6820 6474 7970 6520  rray with dtype 
-000041a0: 7569 6e74 3332 2e20 270a 2020 2020 2020  uint32. '.      
-000041b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000041c0: 2020 2066 2742 7574 2077 6520 676f 7420     f'But we got 
-000041d0: 7b73 6565 645f 6f72 5f6b 6579 7d27 290a  {seed_or_key}').
-000041e0: 2020 2020 2020 6b65 7920 3d20 7365 6564        key = seed
-000041f0: 5f6f 725f 6b65 790a 2020 2020 7365 6c66  _or_key.    self
-00004200: 2e5f 7661 6c75 6520 3d20 6b65 790a 0a20  ._value = key.. 
-00004210: 2064 6566 2073 706c 6974 5f6b 6579 2873   def split_key(s
-00004220: 656c 6629 3a0a 2020 2020 2222 2243 7265  elf):.    """Cre
-00004230: 6174 6520 6120 6e65 7720 7365 6564 2066  ate a new seed f
-00004240: 726f 6d20 7468 6520 6375 7272 656e 7420  rom the current 
-00004250: 7365 6564 2e0a 2020 2020 2222 220a 2020  seed..    """.  
-00004260: 2020 6966 206e 6f74 2069 7369 6e73 7461    if not isinsta
-00004270: 6e63 6528 7365 6c66 2e76 616c 7565 2c20  nce(self.value, 
-00004280: 6a6e 702e 6e64 6172 7261 7929 3a0a 2020  jnp.ndarray):.  
-00004290: 2020 2020 7365 6c66 2e5f 7661 6c75 6520      self._value 
-000042a0: 3d20 6a6e 702e 6173 6172 7261 7928 7365  = jnp.asarray(se
-000042b0: 6c66 2e76 616c 7565 290a 2020 2020 6b65  lf.value).    ke
-000042c0: 7973 203d 206a 722e 7370 6c69 7428 7365  ys = jr.split(se
-000042d0: 6c66 2e76 616c 7565 2c20 6e75 6d3d 3229  lf.value, num=2)
-000042e0: 0a20 2020 2073 656c 662e 5f76 616c 7565  .    self._value
-000042f0: 203d 206b 6579 735b 305d 0a20 2020 2072   = keys[0].    r
-00004300: 6574 7572 6e20 6b65 7973 5b31 5d0a 0a20  eturn keys[1].. 
-00004310: 2064 6566 2073 706c 6974 5f6b 6579 7328   def split_keys(
-00004320: 7365 6c66 2c20 6e29 3a0a 2020 2020 2222  self, n):.    ""
-00004330: 2243 7265 6174 6520 6d75 6c74 6970 6c65  "Create multiple
-00004340: 2073 6565 6473 2066 726f 6d20 7468 6520   seeds from the 
-00004350: 6375 7272 656e 7420 7365 6564 2e20 5468  current seed. Th
-00004360: 6973 2069 7320 7573 6564 0a20 2020 2069  is is used.    i
-00004370: 6e74 6572 6e61 6c6c 7920 6279 2060 706d  nternally by `pm
-00004380: 6170 6020 616e 6420 6076 6d61 7060 2074  ap` and `vmap` t
-00004390: 6f20 656e 7375 7265 2074 6861 7420 7261  o ensure that ra
-000043a0: 6e64 6f6d 206e 756d 6265 7273 0a20 2020  ndom numbers.   
-000043b0: 2061 7265 2064 6966 6665 7265 6e74 2069   are different i
-000043c0: 6e20 7061 7261 6c6c 656c 2074 6872 6561  n parallel threa
-000043d0: 6473 2e0a 0a20 2020 2050 6172 616d 6574  ds...    Paramet
-000043e0: 6572 730a 2020 2020 2d2d 2d2d 2d2d 2d2d  ers.    --------
-000043f0: 2d2d 0a20 2020 206e 203a 2069 6e74 0a20  --.    n : int. 
-00004400: 2020 2020 2054 6865 206e 756d 6265 7220       The number 
-00004410: 6f66 2073 6565 6473 2074 6f20 6765 6e65  of seeds to gene
-00004420: 7261 7465 2e0a 2020 2020 2222 220a 2020  rate..    """.  
-00004430: 2020 6b65 7973 203d 206a 722e 7370 6c69    keys = jr.spli
-00004440: 7428 7365 6c66 2e76 616c 7565 2c20 6e20  t(self.value, n 
-00004450: 2b20 3129 0a20 2020 2073 656c 662e 5f76  + 1).    self._v
-00004460: 616c 7565 203d 206b 6579 735b 305d 0a20  alue = keys[0]. 
-00004470: 2020 2072 6574 7572 6e20 6b65 7973 5b31     return keys[1
-00004480: 3a5d 0a0a 2020 2320 2d2d 2d2d 2d2d 2d2d  :]..  # --------
-00004490: 2d2d 2d2d 2d2d 2d2d 2023 0a20 2023 2072  -------- #.  # r
-000044a0: 616e 646f 6d20 6675 6e63 7469 6f6e 7320  andom functions 
-000044b0: 230a 2020 2320 2d2d 2d2d 2d2d 2d2d 2d2d  #.  # ----------
-000044c0: 2d2d 2d2d 2d2d 2023 0a0a 2020 6465 6620  ------ #..  def 
-000044d0: 7261 6e64 2873 656c 662c 202a 646e 2c20  rand(self, *dn, 
-000044e0: 6b65 793d 4e6f 6e65 293a 0a20 2020 206b  key=None):.    k
-000044f0: 6579 203d 2073 656c 662e 7370 6c69 745f  ey = self.split_
-00004500: 6b65 7928 2920 6966 206b 6579 2069 7320  key() if key is 
-00004510: 4e6f 6e65 2065 6c73 6520 5f66 6f72 6d61  None else _forma
-00004520: 6c69 7a65 5f6b 6579 286b 6579 290a 2020  lize_key(key).  
-00004530: 2020 7220 3d20 6a72 2e75 6e69 666f 726d    r = jr.uniform
-00004540: 286b 6579 2c20 7368 6170 653d 646e 2c20  (key, shape=dn, 
-00004550: 6d69 6e76 616c 3d30 2e2c 206d 6178 7661  minval=0., maxva
-00004560: 6c3d 312e 290a 2020 2020 7265 7475 726e  l=1.).    return
-00004570: 205f 7265 7475 726e 2872 290a 0a20 2064   _return(r)..  d
-00004580: 6566 2072 616e 6469 6e74 2873 656c 662c  ef randint(self,
-00004590: 206c 6f77 2c20 6869 6768 3d4e 6f6e 652c   low, high=None,
-000045a0: 2073 697a 653d 4e6f 6e65 2c20 6474 7970   size=None, dtyp
-000045b0: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
-000045c0: 293a 0a20 2020 2064 7479 7065 203d 2067  ):.    dtype = g
-000045d0: 6574 5f69 6e74 2829 2069 6620 6474 7970  et_int() if dtyp
-000045e0: 6520 6973 204e 6f6e 6520 656c 7365 2064  e is None else d
-000045f0: 7479 7065 0a20 2020 206c 6f77 203d 205f  type.    low = _
-00004600: 6173 5f6a 6178 5f61 7272 6179 286c 6f77  as_jax_array(low
-00004610: 290a 2020 2020 6869 6768 203d 205f 6173  ).    high = _as
-00004620: 5f6a 6178 5f61 7272 6179 2868 6967 6829  _jax_array(high)
-00004630: 0a20 2020 2069 6620 6869 6768 2069 7320  .    if high is 
-00004640: 4e6f 6e65 3a0a 2020 2020 2020 6869 6768  None:.      high
-00004650: 203d 206c 6f77 0a20 2020 2020 206c 6f77   = low.      low
-00004660: 203d 2030 0a20 2020 2068 6967 6820 3d20   = 0.    high = 
-00004670: 5f63 6865 636b 5f70 795f 7365 7128 6869  _check_py_seq(hi
-00004680: 6768 290a 2020 2020 6c6f 7720 3d20 5f63  gh).    low = _c
-00004690: 6865 636b 5f70 795f 7365 7128 6c6f 7729  heck_py_seq(low)
-000046a0: 0a20 2020 2069 6620 7369 7a65 2069 7320  .    if size is 
-000046b0: 4e6f 6e65 3a0a 2020 2020 2020 7369 7a65  None:.      size
-000046c0: 203d 206c 6178 2e62 726f 6164 6361 7374   = lax.broadcast
-000046d0: 5f73 6861 7065 7328 6a6e 702e 7368 6170  _shapes(jnp.shap
-000046e0: 6528 6c6f 7729 2c0a 2020 2020 2020 2020  e(low),.        
+00002bd0: 2020 2020 2020 2020 2020 206a 6e70 2e6f             jnp.o
+00002be0: 6e65 7328 696e 6469 6365 735f 3244 2e73  nes(indices_2D.s
+00002bf0: 6861 7065 2c20 6474 7970 653d 696e 6469  hape, dtype=indi
+00002c00: 6365 732e 6474 7970 6529 290a 2020 7265  ces.dtype)).  re
+00002c10: 7475 726e 206a 6e70 2e72 6573 6861 7065  turn jnp.reshape
+00002c20: 2873 616d 706c 6573 5f32 442c 2073 6861  (samples_2D, sha
+00002c30: 7065 202b 2070 2e73 6861 7065 5b2d 313a  pe + p.shape[-1:
+00002c40: 5d29 202d 2065 7863 6573 730a 0a0a 4070  ]) - excess...@p
+00002c50: 6172 7469 616c 286a 6974 2c20 7374 6174  artial(jit, stat
+00002c60: 6963 5f61 7267 6e75 6d73 3d28 322c 2033  ic_argnums=(2, 3
+00002c70: 2929 0a64 6566 205f 766f 6e5f 6d69 7365  )).def _von_mise
+00002c80: 735f 6365 6e74 6572 6564 286b 6579 2c20  s_centered(key, 
+00002c90: 636f 6e63 656e 7472 6174 696f 6e2c 2073  concentration, s
+00002ca0: 6861 7065 2c20 6474 7970 653d 6a6e 702e  hape, dtype=jnp.
+00002cb0: 666c 6f61 7436 3429 3a0a 2020 2222 2243  float64):.  """C
+00002cc0: 6f6d 7075 7465 2063 656e 7465 7265 6420  ompute centered 
+00002cd0: 766f 6e20 4d69 7365 7320 7361 6d70 6c65  von Mises sample
+00002ce0: 7320 7573 696e 6720 7265 6a65 6374 696f  s using rejectio
+00002cf0: 6e20 7361 6d70 6c69 6e67 2066 726f 6d20  n sampling from 
+00002d00: 5b31 5d5f 2077 6974 6820 7772 6170 7065  [1]_ with wrappe
+00002d10: 6420 4361 7563 6879 2070 726f 706f 7361  d Cauchy proposa
+00002d20: 6c2e 0a0a 2020 5265 7475 726e 730a 2020  l...  Returns.  
+00002d30: 2d2d 2d2d 2d2d 2d0a 2020 6f75 743a 2061  -------.  out: a
+00002d40: 7272 6179 5f6c 696b 650a 2020 2020 2063  rray_like.     c
+00002d50: 656e 7465 7265 6420 7361 6d70 6c65 7320  entered samples 
+00002d60: 6672 6f6d 2076 6f6e 204d 6973 6573 0a0a  from von Mises..
+00002d70: 2020 5265 6665 7265 6e63 6573 0a20 202d    References.  -
+00002d80: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2e2e 205b  ---------.  .. [
+00002d90: 315d 204c 7563 2044 6576 726f 7965 2022  1] Luc Devroye "
+00002da0: 4e6f 6e2d 556e 6966 6f72 6d20 5261 6e64  Non-Uniform Rand
+00002db0: 6f6d 2056 6172 6961 7465 2047 656e 6572  om Variate Gener
+00002dc0: 6174 696f 6e22 2c20 5370 7269 6e67 6572  ation", Springer
+00002dd0: 2d56 6572 6c61 672c 2031 3938 363b 0a20  -Verlag, 1986;. 
+00002de0: 2020 2020 2020 2020 4368 6170 7465 7220          Chapter 
+00002df0: 392c 2070 2e20 3437 332d 3437 362e 2068  9, p. 473-476. h
+00002e00: 7474 703a 2f2f 7777 772e 6e72 626f 6f6b  ttp://www.nrbook
+00002e10: 2e63 6f6d 2f64 6576 726f 7965 2f44 6576  .com/devroye/Dev
+00002e20: 726f 7965 5f66 696c 6573 2f63 6861 7074  roye_files/chapt
+00002e30: 6572 5f6e 696e 652e 7064 660a 0a20 2022  er_nine.pdf..  "
+00002e40: 2222 0a20 2073 6861 7065 203d 2073 6861  "".  shape = sha
+00002e50: 7065 206f 7220 6a6e 702e 7368 6170 6528  pe or jnp.shape(
+00002e60: 636f 6e63 656e 7472 6174 696f 6e29 0a20  concentration). 
+00002e70: 2064 7479 7065 203d 206a 6e70 2e72 6573   dtype = jnp.res
+00002e80: 756c 745f 7479 7065 2864 7479 7065 290a  ult_type(dtype).
+00002e90: 2020 636f 6e63 656e 7472 6174 696f 6e20    concentration 
+00002ea0: 3d20 6c61 782e 636f 6e76 6572 745f 656c  = lax.convert_el
+00002eb0: 656d 656e 745f 7479 7065 2863 6f6e 6365  ement_type(conce
+00002ec0: 6e74 7261 7469 6f6e 2c20 6474 7970 6529  ntration, dtype)
+00002ed0: 0a20 2063 6f6e 6365 6e74 7261 7469 6f6e  .  concentration
+00002ee0: 203d 206a 6e70 2e62 726f 6164 6361 7374   = jnp.broadcast
+00002ef0: 5f74 6f28 636f 6e63 656e 7472 6174 696f  _to(concentratio
+00002f00: 6e2c 2073 6861 7065 290a 0a20 2073 5f63  n, shape)..  s_c
+00002f10: 7574 6f66 665f 6d61 7020 3d20 7b0a 2020  utoff_map = {.  
+00002f20: 2020 6a6e 702e 6474 7970 6528 6a6e 702e    jnp.dtype(jnp.
+00002f30: 666c 6f61 7431 3629 3a20 312e 3865 2d31  float16): 1.8e-1
+00002f40: 2c0a 2020 2020 6a6e 702e 6474 7970 6528  ,.    jnp.dtype(
+00002f50: 6a6e 702e 666c 6f61 7433 3229 3a20 3265  jnp.float32): 2e
+00002f60: 2d32 2c0a 2020 2020 6a6e 702e 6474 7970  -2,.    jnp.dtyp
+00002f70: 6528 6a6e 702e 666c 6f61 7436 3429 3a20  e(jnp.float64): 
+00002f80: 312e 3265 2d34 2c0a 2020 7d0a 2020 735f  1.2e-4,.  }.  s_
+00002f90: 6375 746f 6666 203d 2073 5f63 7574 6f66  cutoff = s_cutof
+00002fa0: 665f 6d61 702e 6765 7428 6474 7970 6529  f_map.get(dtype)
+00002fb0: 0a0a 2020 7220 3d20 312e 3020 2b20 6a6e  ..  r = 1.0 + jn
+00002fc0: 702e 7371 7274 2831 2e30 202b 2034 2e30  p.sqrt(1.0 + 4.0
+00002fd0: 202a 2063 6f6e 6365 6e74 7261 7469 6f6e   * concentration
+00002fe0: 202a 2a20 3229 0a20 2072 686f 203d 2028   ** 2).  rho = (
+00002ff0: 7220 2d20 6a6e 702e 7371 7274 2832 2e30  r - jnp.sqrt(2.0
+00003000: 202a 2072 2929 202f 2028 322e 3020 2a20   * r)) / (2.0 * 
+00003010: 636f 6e63 656e 7472 6174 696f 6e29 0a20  concentration). 
+00003020: 2073 5f65 7861 6374 203d 2028 312e 3020   s_exact = (1.0 
+00003030: 2b20 7268 6f20 2a2a 2032 2920 2f20 2832  + rho ** 2) / (2
+00003040: 2e30 202a 2072 686f 290a 0a20 2073 5f61  .0 * rho)..  s_a
+00003050: 7070 726f 7869 6d61 7465 203d 2031 2e30  pproximate = 1.0
+00003060: 202f 2063 6f6e 6365 6e74 7261 7469 6f6e   / concentration
+00003070: 0a0a 2020 7320 3d20 6a6e 702e 7768 6572  ..  s = jnp.wher
+00003080: 6528 636f 6e63 656e 7472 6174 696f 6e20  e(concentration 
+00003090: 3e20 735f 6375 746f 6666 2c20 735f 6578  > s_cutoff, s_ex
+000030a0: 6163 742c 2073 5f61 7070 726f 7869 6d61  act, s_approxima
+000030b0: 7465 290a 0a20 2064 6566 2063 6f6e 645f  te)..  def cond_
+000030c0: 666e 282a 6172 6773 293a 0a20 2020 2022  fn(*args):.    "
+000030d0: 2222 6368 6563 6b20 6966 2061 6c6c 2061  ""check if all a
+000030e0: 7265 2064 6f6e 6520 6f72 2072 6561 6368  re done or reach
+000030f0: 6564 206d 6178 206e 756d 6265 7220 6f66  ed max number of
+00003100: 2069 7465 7261 7469 6f6e 7322 2222 0a20   iterations""". 
+00003110: 2020 2069 2c20 5f2c 2064 6f6e 652c 205f     i, _, done, _
+00003120: 2c20 5f20 3d20 6172 6773 5b30 5d0a 2020  , _ = args[0].  
+00003130: 2020 7265 7475 726e 206a 6e70 2e62 6974    return jnp.bit
+00003140: 7769 7365 5f61 6e64 2869 203c 2031 3030  wise_and(i < 100
+00003150: 2c20 6a6e 702e 6c6f 6769 6361 6c5f 6e6f  , jnp.logical_no
+00003160: 7428 6a6e 702e 616c 6c28 646f 6e65 2929  t(jnp.all(done))
+00003170: 290a 0a20 2064 6566 2062 6f64 795f 666e  )..  def body_fn
+00003180: 282a 6172 6773 293a 0a20 2020 2069 2c20  (*args):.    i, 
+00003190: 6b65 792c 2064 6f6e 652c 205f 2c20 7720  key, done, _, w 
+000031a0: 3d20 6172 6773 5b30 5d0a 2020 2020 756e  = args[0].    un
+000031b0: 695f 756b 6579 2c20 756e 695f 766b 6579  i_ukey, uni_vkey
+000031c0: 2c20 6b65 7920 3d20 6a72 2e73 706c 6974  , key = jr.split
+000031d0: 286b 6579 2c20 3329 0a20 2020 2075 203d  (key, 3).    u =
+000031e0: 206a 722e 756e 6966 6f72 6d28 0a20 2020   jr.uniform(.   
+000031f0: 2020 206b 6579 3d75 6e69 5f75 6b65 792c     key=uni_ukey,
+00003200: 0a20 2020 2020 2073 6861 7065 3d73 6861  .      shape=sha
+00003210: 7065 2c0a 2020 2020 2020 6474 7970 653d  pe,.      dtype=
+00003220: 636f 6e63 656e 7472 6174 696f 6e2e 6474  concentration.dt
+00003230: 7970 652c 0a20 2020 2020 206d 696e 7661  ype,.      minva
+00003240: 6c3d 2d31 2e30 2c0a 2020 2020 2020 6d61  l=-1.0,.      ma
+00003250: 7876 616c 3d31 2e30 2c0a 2020 2020 290a  xval=1.0,.    ).
+00003260: 2020 2020 7a20 3d20 6a6e 702e 636f 7328      z = jnp.cos(
+00003270: 6a6e 702e 7069 202a 2075 290a 2020 2020  jnp.pi * u).    
+00003280: 7720 3d20 6a6e 702e 7768 6572 6528 646f  w = jnp.where(do
+00003290: 6e65 2c20 772c 2028 312e 3020 2b20 7320  ne, w, (1.0 + s 
+000032a0: 2a20 7a29 202f 2028 7320 2b20 7a29 2920  * z) / (s + z)) 
+000032b0: 2023 2055 7064 6174 6520 7768 6572 6520   # Update where 
+000032c0: 6e6f 7420 646f 6e65 0a20 2020 2079 203d  not done.    y =
+000032d0: 2063 6f6e 6365 6e74 7261 7469 6f6e 202a   concentration *
+000032e0: 2028 7320 2d20 7729 0a20 2020 2076 203d   (s - w).    v =
+000032f0: 206a 722e 756e 6966 6f72 6d28 6b65 793d   jr.uniform(key=
+00003300: 756e 695f 766b 6579 2c20 7368 6170 653d  uni_vkey, shape=
+00003310: 7368 6170 652c 2064 7479 7065 3d63 6f6e  shape, dtype=con
+00003320: 6365 6e74 7261 7469 6f6e 2e64 7479 7065  centration.dtype
+00003330: 290a 2020 2020 6163 6365 7074 203d 2028  ).    accept = (
+00003340: 7920 2a20 2832 2e30 202d 2079 2920 3e3d  y * (2.0 - y) >=
+00003350: 2076 2920 7c20 286a 6e70 2e6c 6f67 2879   v) | (jnp.log(y
+00003360: 202f 2076 2920 2b20 312e 3020 3e3d 2079   / v) + 1.0 >= y
+00003370: 290a 2020 2020 7265 7475 726e 2069 202b  ).    return i +
+00003380: 2031 2c20 6b65 792c 2061 6363 6570 7420   1, key, accept 
+00003390: 7c20 646f 6e65 2c20 752c 2077 0a0a 2020  | done, u, w..  
+000033a0: 696e 6974 5f64 6f6e 6520 3d20 6a6e 702e  init_done = jnp.
+000033b0: 7a65 726f 7328 7368 6170 652c 2064 7479  zeros(shape, dty
+000033c0: 7065 3d62 6f6f 6c29 0a20 2069 6e69 745f  pe=bool).  init_
+000033d0: 7520 3d20 6a6e 702e 7a65 726f 7328 7368  u = jnp.zeros(sh
+000033e0: 6170 6529 0a20 2069 6e69 745f 7720 3d20  ape).  init_w = 
+000033f0: 6a6e 702e 7a65 726f 7328 7368 6170 6529  jnp.zeros(shape)
+00003400: 0a0a 2020 5f2c 205f 2c20 646f 6e65 2c20  ..  _, _, done, 
+00003410: 752c 2077 203d 206c 6178 2e77 6869 6c65  u, w = lax.while
+00003420: 5f6c 6f6f 7028 0a20 2020 2063 6f6e 645f  _loop(.    cond_
+00003430: 6675 6e3d 636f 6e64 5f66 6e2c 0a20 2020  fun=cond_fn,.   
+00003440: 2062 6f64 795f 6675 6e3d 626f 6479 5f66   body_fun=body_f
+00003450: 6e2c 0a20 2020 2069 6e69 745f 7661 6c3d  n,.    init_val=
+00003460: 286a 6e70 2e61 7272 6179 2830 292c 206b  (jnp.array(0), k
+00003470: 6579 2c20 696e 6974 5f64 6f6e 652c 2069  ey, init_done, i
+00003480: 6e69 745f 752c 2069 6e69 745f 7729 2c0a  nit_u, init_w),.
+00003490: 2020 290a 0a20 2072 6574 7572 6e20 6a6e    )..  return jn
+000034a0: 702e 7369 676e 2875 2920 2a20 6a6e 702e  p.sign(u) * jnp.
+000034b0: 6172 6363 6f73 2877 290a 0a0a 6465 6620  arccos(w)...def 
+000034c0: 5f6c 6f63 5f73 6361 6c65 286c 6f63 2c20  _loc_scale(loc, 
+000034d0: 7363 616c 652c 2076 616c 7565 293a 0a20  scale, value):. 
+000034e0: 2069 6620 6c6f 6320 6973 204e 6f6e 653a   if loc is None:
+000034f0: 0a20 2020 2069 6620 7363 616c 6520 6973  .    if scale is
+00003500: 204e 6f6e 653a 0a20 2020 2020 2072 6574   None:.      ret
+00003510: 7572 6e20 7661 6c75 650a 2020 2020 656c  urn value.    el
+00003520: 7365 3a0a 2020 2020 2020 7265 7475 726e  se:.      return
+00003530: 2076 616c 7565 202a 2073 6361 6c65 0a20   value * scale. 
+00003540: 2065 6c73 653a 0a20 2020 2069 6620 7363   else:.    if sc
+00003550: 616c 6520 6973 204e 6f6e 653a 0a20 2020  ale is None:.   
+00003560: 2020 2072 6574 7572 6e20 7661 6c75 6520     return value 
+00003570: 2b20 6c6f 630a 2020 2020 656c 7365 3a0a  + loc.    else:.
+00003580: 2020 2020 2020 7265 7475 726e 2076 616c        return val
+00003590: 7565 202a 2073 6361 6c65 202b 206c 6f63  ue * scale + loc
+000035a0: 0a0a 0a64 6566 205f 6368 6563 6b5f 7079  ...def _check_py
+000035b0: 5f73 6571 2873 6571 293a 0a20 2072 6574  _seq(seq):.  ret
+000035c0: 7572 6e20 6a6e 702e 6173 6172 7261 7928  urn jnp.asarray(
+000035d0: 7365 7129 2069 6620 6973 696e 7374 616e  seq) if isinstan
+000035e0: 6365 2873 6571 2c20 2874 7570 6c65 2c20  ce(seq, (tuple, 
+000035f0: 6c69 7374 2929 2065 6c73 6520 7365 710a  list)) else seq.
+00003600: 0a0a 4072 6567 6973 7465 725f 7079 7472  ..@register_pytr
+00003610: 6565 5f6e 6f64 655f 636c 6173 730a 636c  ee_node_class.cl
+00003620: 6173 7320 5261 6e64 6f6d 5374 6174 6528  ass RandomState(
+00003630: 5661 7269 6162 6c65 293a 0a20 2022 2222  Variable):.  """
+00003640: 5261 6e64 6f6d 5374 6174 6520 7468 6174  RandomState that
+00003650: 2074 7261 636b 2074 6865 2072 616e 646f   track the rando
+00003660: 6d20 6765 6e65 7261 746f 7220 7374 6174  m generator stat
+00003670: 652e 2022 2222 0a20 205f 5f73 6c6f 7473  e. """.  __slots
+00003680: 5f5f 203d 2028 290a 0a20 2064 6566 205f  __ = ()..  def _
+00003690: 5f69 6e69 745f 5f28 0a20 2020 2020 2073  _init__(.      s
+000036a0: 656c 662c 0a20 2020 2020 2073 6565 645f  elf,.      seed_
+000036b0: 6f72 5f6b 6579 3a20 4f70 7469 6f6e 616c  or_key: Optional
+000036c0: 5b55 6e69 6f6e 5b69 6e74 2c20 4172 7261  [Union[int, Arra
+000036d0: 792c 206a 6178 2e41 7272 6179 2c20 6e70  y, jax.Array, np
+000036e0: 2e6e 6461 7272 6179 5d5d 203d 204e 6f6e  .ndarray]] = Non
+000036f0: 652c 0a20 2020 2020 2073 6565 643a 204f  e,.      seed: O
+00003700: 7074 696f 6e61 6c5b 696e 745d 203d 204e  ptional[int] = N
+00003710: 6f6e 652c 0a20 2020 2020 205f 7265 6164  one,.      _read
+00003720: 795f 746f 5f74 7261 6365 3a20 626f 6f6c  y_to_trace: bool
+00003730: 203d 2054 7275 652c 0a20 2029 3a0a 2020   = True,.  ):.  
+00003740: 2020 2222 2252 616e 646f 6d53 7461 7465    """RandomState
+00003750: 2063 6f6e 7374 7275 6374 6f72 2e0a 0a20   constructor... 
+00003760: 2020 2050 6172 616d 6574 6572 730a 2020     Parameters.  
+00003770: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020    ----------.   
+00003780: 2073 6565 645f 6f72 5f6b 6579 3a20 696e   seed_or_key: in
+00003790: 742c 2041 7272 6179 2c20 6f70 7469 6f6e  t, Array, option
+000037a0: 616c 0a20 2020 2020 2049 7420 6361 6e20  al.      It can 
+000037b0: 6265 2061 6e20 696e 7465 6765 7220 666f  be an integer fo
+000037c0: 7220 696e 6974 6961 6c20 7365 6564 206f  r initial seed o
+000037d0: 6620 7468 6520 7261 6e64 6f6d 206e 756d  f the random num
+000037e0: 6265 7220 6765 6e65 7261 746f 722c 0a20  ber generator,. 
+000037f0: 2020 2020 206f 7220 6974 2063 616e 2062       or it can b
+00003800: 6520 6120 4a41 5827 7320 5052 4e4b 6579  e a JAX's PRNKey
+00003810: 2c20 7768 6963 6820 6973 2061 6e20 6172  , which is an ar
+00003820: 7261 7920 7769 7468 2074 776f 2065 6c65  ray with two ele
+00003830: 6d65 6e74 7320 616e 6420 6075 696e 7433  ments and `uint3
+00003840: 3260 2064 7479 7065 2e0a 0a20 2020 2020  2` dtype...     
+00003850: 202e 2e20 7665 7273 696f 6e61 6464 6564   .. versionadded
+00003860: 3a3a 2032 2e32 2e33 2e34 0a0a 2020 2020  :: 2.2.3.4..    
+00003870: 7365 6564 203a 2069 6e74 2c20 4172 7261  seed : int, Arra
+00003880: 7954 7970 652c 206f 7074 696f 6e61 6c0a  yType, optional.
+00003890: 2020 2020 2020 5361 6d65 2061 7320 6073        Same as `s
+000038a0: 6565 645f 6f72 5f6b 6579 602e 0a0a 2020  eed_or_key`...  
+000038b0: 2020 2020 2e2e 2064 6570 7265 6361 7465      .. deprecate
+000038c0: 643a 3a20 322e 322e 332e 340a 2020 2020  d:: 2.2.3.4.    
+000038d0: 2020 2020 2057 696c 6c20 6265 2072 656d       Will be rem
+000038e0: 6f76 6564 2073 696e 6365 2076 6572 7369  oved since versi
+000038f0: 6f6e 2032 2e34 2e0a 2020 2020 2222 220a  on 2.4..    """.
+00003900: 2020 2020 6966 2073 6565 6420 6973 206e      if seed is n
+00003910: 6f74 204e 6f6e 653a 0a20 2020 2020 2069  ot None:.      i
+00003920: 6620 7365 6564 5f6f 725f 6b65 7920 6973  f seed_or_key is
+00003930: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+00003940: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+00003950: 726f 7228 2750 6c65 6173 6520 7365 7420  ror('Please set 
+00003960: 2273 6565 645f 6f72 5f6b 6579 2220 6f72  "seed_or_key" or
+00003970: 2022 7365 6564 222c 206e 6f74 2062 6f74   "seed", not bot
+00003980: 682e 2729 0a20 2020 2020 2073 6565 645f  h.').      seed_
+00003990: 6f72 5f6b 6579 203d 2073 6565 640a 2020  or_key = seed.  
+000039a0: 2020 2020 7761 726e 696e 6773 2e77 6172      warnings.war
+000039b0: 6e28 2750 6c65 6173 6520 7573 6520 6073  n('Please use `s
+000039c0: 6565 645f 6f72 5f6b 6579 6020 696e 7374  eed_or_key` inst
+000039d0: 6561 642e 2027 0a20 2020 2020 2020 2020  ead. '.         
+000039e0: 2020 2020 2020 2020 2020 2027 7365 6564             'seed
+000039f0: 2077 696c 6c20 6265 2072 656d 6f76 6564   will be removed
+00003a00: 2073 696e 6365 2032 2e34 2e30 272c 2055   since 2.4.0', U
+00003a10: 7365 7257 6172 6e69 6e67 290a 0a20 2020  serWarning)..   
+00003a20: 2077 6974 6820 6a61 782e 656e 7375 7265   with jax.ensure
+00003a30: 5f63 6f6d 7069 6c65 5f74 696d 655f 6576  _compile_time_ev
+00003a40: 616c 2829 3a0a 2020 2020 2020 6966 2073  al():.      if s
+00003a50: 6565 645f 6f72 5f6b 6579 2069 7320 4e6f  eed_or_key is No
+00003a60: 6e65 3a0a 2020 2020 2020 2020 7365 6564  ne:.        seed
+00003a70: 5f6f 725f 6b65 7920 3d20 6e70 2e72 616e  _or_key = np.ran
+00003a80: 646f 6d2e 7261 6e64 696e 7428 302c 2031  dom.randint(0, 1
+00003a90: 3030 3030 302c 2032 2c20 6474 7970 653d  00000, 2, dtype=
+00003aa0: 6e70 2e75 696e 7433 3229 0a20 2020 2069  np.uint32).    i
+00003ab0: 6620 6973 696e 7374 616e 6365 2873 6565  f isinstance(see
+00003ac0: 645f 6f72 5f6b 6579 2c20 696e 7429 3a0a  d_or_key, int):.
+00003ad0: 2020 2020 2020 6b65 7920 3d20 6a72 2e50        key = jr.P
+00003ae0: 524e 474b 6579 2873 6565 645f 6f72 5f6b  RNGKey(seed_or_k
+00003af0: 6579 290a 2020 2020 656c 7365 3a0a 2020  ey).    else:.  
+00003b00: 2020 2020 6966 206c 656e 2873 6565 645f      if len(seed_
+00003b10: 6f72 5f6b 6579 2920 213d 2032 2061 6e64  or_key) != 2 and
+00003b20: 2073 6565 645f 6f72 5f6b 6579 2e64 7479   seed_or_key.dty
+00003b30: 7065 2021 3d20 6e70 2e75 696e 7433 323a  pe != np.uint32:
+00003b40: 0a20 2020 2020 2020 2072 6169 7365 2056  .        raise V
+00003b50: 616c 7565 4572 726f 7228 276b 6579 206d  alueError('key m
+00003b60: 7573 7420 6265 2061 6e20 6172 7261 7920  ust be an array 
+00003b70: 7769 7468 2064 7479 7065 2075 696e 7433  with dtype uint3
+00003b80: 322e 2027 0a20 2020 2020 2020 2020 2020  2. '.           
+00003b90: 2020 2020 2020 2020 2020 2020 2020 6627                f'
+00003ba0: 4275 7420 7765 2067 6f74 207b 7365 6564  But we got {seed
+00003bb0: 5f6f 725f 6b65 797d 2729 0a20 2020 2020  _or_key}').     
+00003bc0: 206b 6579 203d 2073 6565 645f 6f72 5f6b   key = seed_or_k
+00003bd0: 6579 0a20 2020 2073 7570 6572 2852 616e  ey.    super(Ran
+00003be0: 646f 6d53 7461 7465 2c20 7365 6c66 292e  domState, self).
+00003bf0: 5f5f 696e 6974 5f5f 286b 6579 2c20 5f72  __init__(key, _r
+00003c00: 6561 6479 5f74 6f5f 7472 6163 653d 5f72  eady_to_trace=_r
+00003c10: 6561 6479 5f74 6f5f 7472 6163 6529 0a0a  eady_to_trace)..
+00003c20: 2020 6465 6620 5f5f 7265 7072 5f5f 2873    def __repr__(s
+00003c30: 656c 6629 202d 3e20 7374 723a 0a20 2020  elf) -> str:.   
+00003c40: 2070 7269 6e74 5f63 6f64 6520 3d20 7265   print_code = re
+00003c50: 7072 2873 656c 662e 7661 6c75 6529 0a20  pr(self.value). 
+00003c60: 2020 2069 203d 2070 7269 6e74 5f63 6f64     i = print_cod
+00003c70: 652e 696e 6465 7828 2728 2729 0a20 2020  e.index('(').   
+00003c80: 206e 616d 6520 3d20 7365 6c66 2e5f 5f63   name = self.__c
+00003c90: 6c61 7373 5f5f 2e5f 5f6e 616d 655f 5f0a  lass__.__name__.
+00003ca0: 2020 2020 7265 7475 726e 2066 277b 6e61      return f'{na
+00003cb0: 6d65 7d28 6b65 793d 7b70 7269 6e74 5f63  me}(key={print_c
+00003cc0: 6f64 655b 693a 5d7d 2927 0a0a 2020 2320  ode[i:]})'..  # 
+00003cd0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003ce0: 2d2d 2d20 230a 2020 2320 7365 6564 2061  --- #.  # seed a
+00003cf0: 6e64 2072 616e 646f 6d20 6b65 7920 230a  nd random key #.
+00003d00: 2020 2320 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d    # ------------
+00003d10: 2d2d 2d2d 2d2d 2d20 230a 0a20 2064 6566  ------- #..  def
+00003d20: 2063 6c6f 6e65 2873 656c 6629 3a0a 2020   clone(self):.  
+00003d30: 2020 7265 7475 726e 2074 7970 6528 7365    return type(se
+00003d40: 6c66 2928 7365 6c66 2e73 706c 6974 5f6b  lf)(self.split_k
+00003d50: 6579 2829 290a 0a20 2064 6566 2073 6565  ey())..  def see
+00003d60: 6428 7365 6c66 2c20 7365 6564 5f6f 725f  d(self, seed_or_
+00003d70: 6b65 793d 4e6f 6e65 2c20 7365 6564 3d4e  key=None, seed=N
+00003d80: 6f6e 6529 3a0a 2020 2020 2222 2253 6574  one):.    """Set
+00003d90: 7320 6120 6e65 7720 7261 6e64 6f6d 2073  s a new random s
+00003da0: 6565 642e 0a0a 2020 2020 5061 7261 6d65  eed...    Parame
+00003db0: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+00003dc0: 2d2d 2d0a 2020 2020 7365 6564 5f6f 725f  ---.    seed_or_
+00003dd0: 6b65 793a 2069 6e74 2c20 4172 7261 7954  key: int, ArrayT
+00003de0: 7970 652c 206f 7074 696f 6e61 6c0a 2020  ype, optional.  
+00003df0: 2020 2020 4974 2063 616e 2062 6520 616e      It can be an
+00003e00: 2069 6e74 6567 6572 2066 6f72 2069 6e69   integer for ini
+00003e10: 7469 616c 2073 6565 6420 6f66 2074 6865  tial seed of the
+00003e20: 2072 616e 646f 6d20 6e75 6d62 6572 2067   random number g
+00003e30: 656e 6572 6174 6f72 2c0a 2020 2020 2020  enerator,.      
+00003e40: 6f72 2069 7420 6361 6e20 6265 2061 204a  or it can be a J
+00003e50: 4158 2773 2050 524e 4b65 792c 2077 6869  AX's PRNKey, whi
+00003e60: 6368 2069 7320 616e 2061 7272 6179 2077  ch is an array w
+00003e70: 6974 6820 7477 6f20 656c 656d 656e 7473  ith two elements
+00003e80: 2061 6e64 2060 7569 6e74 3332 6020 6474   and `uint32` dt
+00003e90: 7970 652e 0a0a 2020 2020 2020 2e2e 2076  ype...      .. v
+00003ea0: 6572 7369 6f6e 6164 6465 643a 3a20 322e  ersionadded:: 2.
+00003eb0: 322e 332e 340a 0a20 2020 2073 6565 6420  2.3.4..    seed 
+00003ec0: 3a20 696e 742c 2041 7272 6179 5479 7065  : int, ArrayType
+00003ed0: 2c20 6f70 7469 6f6e 616c 0a20 2020 2020  , optional.     
+00003ee0: 2053 616d 6520 6173 2060 7365 6564 5f6f   Same as `seed_o
+00003ef0: 725f 6b65 7960 2e0a 0a20 2020 2020 202e  r_key`...      .
+00003f00: 2e20 6465 7072 6563 6174 6564 3a3a 2032  . deprecated:: 2
+00003f10: 2e32 2e33 2e34 0a20 2020 2020 2020 2020  .2.3.4.         
+00003f20: 5769 6c6c 2062 6520 7265 6d6f 7665 6420  Will be removed 
+00003f30: 7369 6e63 6520 7665 7273 696f 6e20 322e  since version 2.
+00003f40: 342e 0a20 2020 2022 2222 0a20 2020 2069  4..    """.    i
+00003f50: 6620 7365 6564 2069 7320 6e6f 7420 4e6f  f seed is not No
+00003f60: 6e65 3a0a 2020 2020 2020 6966 2073 6565  ne:.      if see
+00003f70: 645f 6f72 5f6b 6579 2069 7320 6e6f 7420  d_or_key is not 
+00003f80: 4e6f 6e65 3a0a 2020 2020 2020 2020 7261  None:.        ra
+00003f90: 6973 6520 5661 6c75 6545 7272 6f72 2827  ise ValueError('
+00003fa0: 506c 6561 7365 2073 6574 2022 7365 6564  Please set "seed
+00003fb0: 5f6f 725f 6b65 7922 206f 7220 2273 6565  _or_key" or "see
+00003fc0: 6422 2c20 6e6f 7420 626f 7468 2e27 290a  d", not both.').
+00003fd0: 2020 2020 2020 7365 6564 5f6f 725f 6b65        seed_or_ke
+00003fe0: 7920 3d20 7365 6564 0a20 2020 2020 2077  y = seed.      w
+00003ff0: 6172 6e69 6e67 732e 7761 726e 2827 506c  arnings.warn('Pl
+00004000: 6561 7365 2075 7365 2073 6565 645f 6f72  ease use seed_or
+00004010: 5f6b 6579 2069 6e73 7465 6164 2e20 270a  _key instead. '.
+00004020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004030: 2020 2020 2773 6565 6420 7769 6c6c 2062      'seed will b
+00004040: 6520 7265 6d6f 7665 6420 7369 6e63 6520  e removed since 
+00004050: 322e 342e 3027 2c20 5573 6572 5761 726e  2.4.0', UserWarn
+00004060: 696e 6729 0a0a 2020 2020 6966 2073 6565  ing)..    if see
+00004070: 645f 6f72 5f6b 6579 2069 7320 4e6f 6e65  d_or_key is None
+00004080: 3a0a 2020 2020 2020 7365 6564 5f6f 725f  :.      seed_or_
+00004090: 6b65 7920 3d20 6e70 2e72 616e 646f 6d2e  key = np.random.
+000040a0: 7261 6e64 696e 7428 302c 2031 3030 3030  randint(0, 10000
+000040b0: 302c 2032 2c20 6474 7970 653d 6e70 2e75  0, 2, dtype=np.u
+000040c0: 696e 7433 3229 0a20 2020 2069 6620 6973  int32).    if is
+000040d0: 696e 7374 616e 6365 2873 6565 645f 6f72  instance(seed_or
+000040e0: 5f6b 6579 2c20 696e 7429 3a0a 2020 2020  _key, int):.    
+000040f0: 2020 6b65 7920 3d20 6a72 2e50 524e 474b    key = jr.PRNGK
+00004100: 6579 2873 6565 645f 6f72 5f6b 6579 290a  ey(seed_or_key).
+00004110: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00004120: 6966 206c 656e 2873 6565 645f 6f72 5f6b  if len(seed_or_k
+00004130: 6579 2920 213d 2032 2061 6e64 2073 6565  ey) != 2 and see
+00004140: 645f 6f72 5f6b 6579 2e64 7479 7065 2021  d_or_key.dtype !
+00004150: 3d20 6e70 2e75 696e 7433 323a 0a20 2020  = np.uint32:.   
+00004160: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+00004170: 4572 726f 7228 276b 6579 206d 7573 7420  Error('key must 
+00004180: 6265 2061 6e20 6172 7261 7920 7769 7468  be an array with
+00004190: 2064 7479 7065 2075 696e 7433 322e 2027   dtype uint32. '
+000041a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000041b0: 2020 2020 2020 2020 2020 6627 4275 7420            f'But 
+000041c0: 7765 2067 6f74 207b 7365 6564 5f6f 725f  we got {seed_or_
+000041d0: 6b65 797d 2729 0a20 2020 2020 206b 6579  key}').      key
+000041e0: 203d 2073 6565 645f 6f72 5f6b 6579 0a20   = seed_or_key. 
+000041f0: 2020 2073 656c 662e 5f76 616c 7565 203d     self._value =
+00004200: 206b 6579 0a0a 2020 6465 6620 7370 6c69   key..  def spli
+00004210: 745f 6b65 7928 7365 6c66 293a 0a20 2020  t_key(self):.   
+00004220: 2022 2222 4372 6561 7465 2061 206e 6577   """Create a new
+00004230: 2073 6565 6420 6672 6f6d 2074 6865 2063   seed from the c
+00004240: 7572 7265 6e74 2073 6565 642e 0a20 2020  urrent seed..   
+00004250: 2022 2222 0a20 2020 2069 6620 6e6f 7420   """.    if not 
+00004260: 6973 696e 7374 616e 6365 2873 656c 662e  isinstance(self.
+00004270: 7661 6c75 652c 206a 6e70 2e6e 6461 7272  value, jnp.ndarr
+00004280: 6179 293a 0a20 2020 2020 2073 656c 662e  ay):.      self.
+00004290: 5f76 616c 7565 203d 206a 6e70 2e61 7361  _value = jnp.asa
+000042a0: 7272 6179 2873 656c 662e 7661 6c75 6529  rray(self.value)
+000042b0: 0a20 2020 206b 6579 7320 3d20 6a72 2e73  .    keys = jr.s
+000042c0: 706c 6974 2873 656c 662e 7661 6c75 652c  plit(self.value,
+000042d0: 206e 756d 3d32 290a 2020 2020 7365 6c66   num=2).    self
+000042e0: 2e5f 7661 6c75 6520 3d20 6b65 7973 5b30  ._value = keys[0
+000042f0: 5d0a 2020 2020 7265 7475 726e 206b 6579  ].    return key
+00004300: 735b 315d 0a0a 2020 6465 6620 7370 6c69  s[1]..  def spli
+00004310: 745f 6b65 7973 2873 656c 662c 206e 293a  t_keys(self, n):
+00004320: 0a20 2020 2022 2222 4372 6561 7465 206d  .    """Create m
+00004330: 756c 7469 706c 6520 7365 6564 7320 6672  ultiple seeds fr
+00004340: 6f6d 2074 6865 2063 7572 7265 6e74 2073  om the current s
+00004350: 6565 642e 2054 6869 7320 6973 2075 7365  eed. This is use
+00004360: 640a 2020 2020 696e 7465 726e 616c 6c79  d.    internally
+00004370: 2062 7920 6070 6d61 7060 2061 6e64 2060   by `pmap` and `
+00004380: 766d 6170 6020 746f 2065 6e73 7572 6520  vmap` to ensure 
+00004390: 7468 6174 2072 616e 646f 6d20 6e75 6d62  that random numb
+000043a0: 6572 730a 2020 2020 6172 6520 6469 6666  ers.    are diff
+000043b0: 6572 656e 7420 696e 2070 6172 616c 6c65  erent in paralle
+000043c0: 6c20 7468 7265 6164 732e 0a0a 2020 2020  l threads...    
+000043d0: 5061 7261 6d65 7465 7273 0a20 2020 202d  Parameters.    -
+000043e0: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 6e20  ---------.    n 
+000043f0: 3a20 696e 740a 2020 2020 2020 5468 6520  : int.      The 
+00004400: 6e75 6d62 6572 206f 6620 7365 6564 7320  number of seeds 
+00004410: 746f 2067 656e 6572 6174 652e 0a20 2020  to generate..   
+00004420: 2022 2222 0a20 2020 206b 6579 7320 3d20   """.    keys = 
+00004430: 6a72 2e73 706c 6974 2873 656c 662e 7661  jr.split(self.va
+00004440: 6c75 652c 206e 202b 2031 290a 2020 2020  lue, n + 1).    
+00004450: 7365 6c66 2e5f 7661 6c75 6520 3d20 6b65  self._value = ke
+00004460: 7973 5b30 5d0a 2020 2020 7265 7475 726e  ys[0].    return
+00004470: 206b 6579 735b 313a 5d0a 0a20 2023 202d   keys[1:]..  # -
+00004480: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d20  --------------- 
+00004490: 230a 2020 2320 7261 6e64 6f6d 2066 756e  #.  # random fun
+000044a0: 6374 696f 6e73 2023 0a20 2023 202d 2d2d  ctions #.  # ---
+000044b0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d20 230a  ------------- #.
+000044c0: 0a20 2064 6566 2072 616e 6428 7365 6c66  .  def rand(self
+000044d0: 2c20 2a64 6e2c 206b 6579 3d4e 6f6e 6529  , *dn, key=None)
+000044e0: 3a0a 2020 2020 6b65 7920 3d20 7365 6c66  :.    key = self
+000044f0: 2e73 706c 6974 5f6b 6579 2829 2069 6620  .split_key() if 
+00004500: 6b65 7920 6973 204e 6f6e 6520 656c 7365  key is None else
+00004510: 205f 666f 726d 616c 697a 655f 6b65 7928   _formalize_key(
+00004520: 6b65 7929 0a20 2020 2072 203d 206a 722e  key).    r = jr.
+00004530: 756e 6966 6f72 6d28 6b65 792c 2073 6861  uniform(key, sha
+00004540: 7065 3d64 6e2c 206d 696e 7661 6c3d 302e  pe=dn, minval=0.
+00004550: 2c20 6d61 7876 616c 3d31 2e29 0a20 2020  , maxval=1.).   
+00004560: 2072 6574 7572 6e20 5f72 6574 7572 6e28   return _return(
+00004570: 7229 0a0a 2020 6465 6620 7261 6e64 696e  r)..  def randin
+00004580: 7428 7365 6c66 2c20 6c6f 772c 2068 6967  t(self, low, hig
+00004590: 683d 4e6f 6e65 2c20 7369 7a65 3d4e 6f6e  h=None, size=Non
+000045a0: 652c 2064 7479 7065 3d4e 6f6e 652c 206b  e, dtype=None, k
+000045b0: 6579 3d4e 6f6e 6529 3a0a 2020 2020 6474  ey=None):.    dt
+000045c0: 7970 6520 3d20 6765 745f 696e 7428 2920  ype = get_int() 
+000045d0: 6966 2064 7479 7065 2069 7320 4e6f 6e65  if dtype is None
+000045e0: 2065 6c73 6520 6474 7970 650a 2020 2020   else dtype.    
+000045f0: 6c6f 7720 3d20 5f61 735f 6a61 785f 6172  low = _as_jax_ar
+00004600: 7261 7928 6c6f 7729 0a20 2020 2068 6967  ray(low).    hig
+00004610: 6820 3d20 5f61 735f 6a61 785f 6172 7261  h = _as_jax_arra
+00004620: 7928 6869 6768 290a 2020 2020 6966 2068  y(high).    if h
+00004630: 6967 6820 6973 204e 6f6e 653a 0a20 2020  igh is None:.   
+00004640: 2020 2068 6967 6820 3d20 6c6f 770a 2020     high = low.  
+00004650: 2020 2020 6c6f 7720 3d20 300a 2020 2020      low = 0.    
+00004660: 6869 6768 203d 205f 6368 6563 6b5f 7079  high = _check_py
+00004670: 5f73 6571 2868 6967 6829 0a20 2020 206c  _seq(high).    l
+00004680: 6f77 203d 205f 6368 6563 6b5f 7079 5f73  ow = _check_py_s
+00004690: 6571 286c 6f77 290a 2020 2020 6966 2073  eq(low).    if s
+000046a0: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
+000046b0: 2020 2073 697a 6520 3d20 6c61 782e 6272     size = lax.br
+000046c0: 6f61 6463 6173 745f 7368 6170 6573 286a  oadcast_shapes(j
+000046d0: 6e70 2e73 6861 7065 286c 6f77 292c 0a20  np.shape(low),. 
+000046e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000046f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004700: 2020 2020 2020 2020 2020 6a6e 702e 7368            jnp.sh
-00004710: 6170 6528 6869 6768 2929 0a20 2020 206b  ape(high)).    k
-00004720: 6579 203d 2073 656c 662e 7370 6c69 745f  ey = self.split_
-00004730: 6b65 7928 2920 6966 206b 6579 2069 7320  key() if key is 
-00004740: 4e6f 6e65 2065 6c73 6520 5f66 6f72 6d61  None else _forma
-00004750: 6c69 7a65 5f6b 6579 286b 6579 290a 2020  lize_key(key).  
-00004760: 2020 7220 3d20 6a72 2e72 616e 6469 6e74    r = jr.randint
-00004770: 286b 6579 2c0a 2020 2020 2020 2020 2020  (key,.          
-00004780: 2020 2020 2020 2020 2073 6861 7065 3d5f           shape=_
-00004790: 7369 7a65 3273 6861 7065 2873 697a 6529  size2shape(size)
-000047a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000047b0: 2020 2020 206d 696e 7661 6c3d 6c6f 772c       minval=low,
-000047c0: 206d 6178 7661 6c3d 6869 6768 2c20 6474   maxval=high, dt
-000047d0: 7970 653d 6474 7970 6529 0a20 2020 2072  ype=dtype).    r
-000047e0: 6574 7572 6e20 5f72 6574 7572 6e28 7229  eturn _return(r)
-000047f0: 0a0a 2020 6465 6620 7261 6e64 6f6d 5f69  ..  def random_i
-00004800: 6e74 6567 6572 7328 7365 6c66 2c20 6c6f  ntegers(self, lo
-00004810: 772c 2068 6967 683d 4e6f 6e65 2c20 7369  w, high=None, si
-00004820: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
-00004830: 6529 3a0a 2020 2020 6c6f 7720 3d20 5f61  e):.    low = _a
-00004840: 735f 6a61 785f 6172 7261 7928 6c6f 7729  s_jax_array(low)
-00004850: 0a20 2020 2068 6967 6820 3d20 5f61 735f  .    high = _as_
-00004860: 6a61 785f 6172 7261 7928 6869 6768 290a  jax_array(high).
-00004870: 2020 2020 6c6f 7720 3d20 5f63 6865 636b      low = _check
-00004880: 5f70 795f 7365 7128 6c6f 7729 0a20 2020  _py_seq(low).   
-00004890: 2068 6967 6820 3d20 5f63 6865 636b 5f70   high = _check_p
-000048a0: 795f 7365 7128 6869 6768 290a 2020 2020  y_seq(high).    
-000048b0: 6966 2068 6967 6820 6973 204e 6f6e 653a  if high is None:
-000048c0: 0a20 2020 2020 2068 6967 6820 3d20 6c6f  .      high = lo
-000048d0: 770a 2020 2020 2020 6c6f 7720 3d20 310a  w.      low = 1.
-000048e0: 2020 2020 6869 6768 202b 3d20 310a 2020      high += 1.  
-000048f0: 2020 6966 2073 697a 6520 6973 204e 6f6e    if size is Non
-00004900: 653a 0a20 2020 2020 2073 697a 6520 3d20  e:.      size = 
-00004910: 6c61 782e 6272 6f61 6463 6173 745f 7368  lax.broadcast_sh
-00004920: 6170 6573 286a 6e70 2e73 6861 7065 286c  apes(jnp.shape(l
-00004930: 6f77 292c 206a 6e70 2e73 6861 7065 2868  ow), jnp.shape(h
-00004940: 6967 6829 290a 2020 2020 6b65 7920 3d20  igh)).    key = 
-00004950: 7365 6c66 2e73 706c 6974 5f6b 6579 2829  self.split_key()
-00004960: 2069 6620 6b65 7920 6973 204e 6f6e 6520   if key is None 
-00004970: 656c 7365 205f 666f 726d 616c 697a 655f  else _formalize_
-00004980: 6b65 7928 6b65 7929 0a20 2020 2072 203d  key(key).    r =
-00004990: 206a 722e 7261 6e64 696e 7428 6b65 792c   jr.randint(key,
-000049a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000049b0: 2020 2020 7368 6170 653d 5f73 697a 6532      shape=_size2
-000049c0: 7368 6170 6528 7369 7a65 292c 0a20 2020  shape(size),.   
-000049d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000049e0: 6d69 6e76 616c 3d6c 6f77 2c0a 2020 2020  minval=low,.    
-000049f0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-00004a00: 6178 7661 6c3d 6869 6768 290a 2020 2020  axval=high).    
-00004a10: 7265 7475 726e 205f 7265 7475 726e 2872  return _return(r
-00004a20: 290a 0a20 2064 6566 2072 616e 646e 2873  )..  def randn(s
-00004a30: 656c 662c 202a 646e 2c20 6b65 793d 4e6f  elf, *dn, key=No
-00004a40: 6e65 293a 0a20 2020 206b 6579 203d 2073  ne):.    key = s
-00004a50: 656c 662e 7370 6c69 745f 6b65 7928 2920  elf.split_key() 
-00004a60: 6966 206b 6579 2069 7320 4e6f 6e65 2065  if key is None e
-00004a70: 6c73 6520 5f66 6f72 6d61 6c69 7a65 5f6b  lse _formalize_k
-00004a80: 6579 286b 6579 290a 2020 2020 7220 3d20  ey(key).    r = 
-00004a90: 6a72 2e6e 6f72 6d61 6c28 6b65 792c 2073  jr.normal(key, s
-00004aa0: 6861 7065 3d64 6e29 0a20 2020 2072 6574  hape=dn).    ret
-00004ab0: 7572 6e20 5f72 6574 7572 6e28 7229 0a0a  urn _return(r)..
-00004ac0: 2020 6465 6620 7261 6e64 6f6d 2873 656c    def random(sel
-00004ad0: 662c 2073 697a 653d 4e6f 6e65 2c20 6b65  f, size=None, ke
-00004ae0: 793d 4e6f 6e65 293a 0a20 2020 206b 6579  y=None):.    key
-00004af0: 203d 2073 656c 662e 7370 6c69 745f 6b65   = self.split_ke
-00004b00: 7928 2920 6966 206b 6579 2069 7320 4e6f  y() if key is No
-00004b10: 6e65 2065 6c73 6520 5f66 6f72 6d61 6c69  ne else _formali
-00004b20: 7a65 5f6b 6579 286b 6579 290a 2020 2020  ze_key(key).    
-00004b30: 7220 3d20 6a72 2e75 6e69 666f 726d 286b  r = jr.uniform(k
-00004b40: 6579 2c20 7368 6170 653d 5f73 697a 6532  ey, shape=_size2
-00004b50: 7368 6170 6528 7369 7a65 292c 206d 696e  shape(size), min
-00004b60: 7661 6c3d 302e 2c20 6d61 7876 616c 3d31  val=0., maxval=1
-00004b70: 2e29 0a20 2020 2072 6574 7572 6e20 5f72  .).    return _r
-00004b80: 6574 7572 6e28 7229 0a0a 2020 6465 6620  eturn(r)..  def 
-00004b90: 7261 6e64 6f6d 5f73 616d 706c 6528 7365  random_sample(se
-00004ba0: 6c66 2c20 7369 7a65 3d4e 6f6e 652c 206b  lf, size=None, k
-00004bb0: 6579 3d4e 6f6e 6529 3a0a 2020 2020 7220  ey=None):.    r 
-00004bc0: 3d20 7365 6c66 2e72 616e 646f 6d28 7369  = self.random(si
-00004bd0: 7a65 3d73 697a 652c 206b 6579 3d6b 6579  ze=size, key=key
-00004be0: 290a 2020 2020 7265 7475 726e 205f 7265  ).    return _re
-00004bf0: 7475 726e 2872 290a 0a20 2064 6566 2072  turn(r)..  def r
-00004c00: 616e 6628 7365 6c66 2c20 7369 7a65 3d4e  anf(self, size=N
-00004c10: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-00004c20: 2020 2020 7220 3d20 7365 6c66 2e72 616e      r = self.ran
-00004c30: 646f 6d28 7369 7a65 3d73 697a 652c 206b  dom(size=size, k
-00004c40: 6579 3d6b 6579 290a 2020 2020 7265 7475  ey=key).    retu
-00004c50: 726e 205f 7265 7475 726e 2872 290a 0a20  rn _return(r).. 
-00004c60: 2064 6566 2073 616d 706c 6528 7365 6c66   def sample(self
-00004c70: 2c20 7369 7a65 3d4e 6f6e 652c 206b 6579  , size=None, key
-00004c80: 3d4e 6f6e 6529 3a0a 2020 2020 7220 3d20  =None):.    r = 
-00004c90: 7365 6c66 2e72 616e 646f 6d28 7369 7a65  self.random(size
-00004ca0: 3d73 697a 652c 206b 6579 3d6b 6579 290a  =size, key=key).
-00004cb0: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
-00004cc0: 726e 2872 290a 0a20 2064 6566 2063 686f  rn(r)..  def cho
-00004cd0: 6963 6528 7365 6c66 2c20 612c 2073 697a  ice(self, a, siz
-00004ce0: 653d 4e6f 6e65 2c20 7265 706c 6163 653d  e=None, replace=
-00004cf0: 5472 7565 2c20 703d 4e6f 6e65 2c20 6b65  True, p=None, ke
-00004d00: 793d 4e6f 6e65 293a 0a20 2020 2061 203d  y=None):.    a =
-00004d10: 205f 6173 5f6a 6178 5f61 7272 6179 2861   _as_jax_array(a
-00004d20: 290a 2020 2020 7020 3d20 5f61 735f 6a61  ).    p = _as_ja
-00004d30: 785f 6172 7261 7928 7029 0a20 2020 2061  x_array(p).    a
-00004d40: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
-00004d50: 2861 290a 2020 2020 7020 3d20 5f63 6865  (a).    p = _che
-00004d60: 636b 5f70 795f 7365 7128 7029 0a20 2020  ck_py_seq(p).   
-00004d70: 206b 6579 203d 2073 656c 662e 7370 6c69   key = self.spli
-00004d80: 745f 6b65 7928 2920 6966 206b 6579 2069  t_key() if key i
-00004d90: 7320 4e6f 6e65 2065 6c73 6520 5f66 6f72  s None else _for
-00004da0: 6d61 6c69 7a65 5f6b 6579 286b 6579 290a  malize_key(key).
-00004db0: 2020 2020 7220 3d20 6a72 2e63 686f 6963      r = jr.choic
-00004dc0: 6528 6b65 792c 2061 3d61 2c20 7368 6170  e(key, a=a, shap
-00004dd0: 653d 5f73 697a 6532 7368 6170 6528 7369  e=_size2shape(si
-00004de0: 7a65 292c 2072 6570 6c61 6365 3d72 6570  ze), replace=rep
-00004df0: 6c61 6365 2c20 703d 7029 0a20 2020 2072  lace, p=p).    r
-00004e00: 6574 7572 6e20 5f72 6574 7572 6e28 7229  eturn _return(r)
-00004e10: 0a0a 2020 6465 6620 7065 726d 7574 6174  ..  def permutat
-00004e20: 696f 6e28 7365 6c66 2c20 782c 2061 7869  ion(self, x, axi
-00004e30: 733a 2069 6e74 203d 2030 2c20 696e 6465  s: int = 0, inde
-00004e40: 7065 6e64 656e 743a 2062 6f6f 6c20 3d20  pendent: bool = 
-00004e50: 4661 6c73 652c 206b 6579 3d4e 6f6e 6529  False, key=None)
-00004e60: 3a0a 2020 2020 7820 3d20 782e 7661 6c75  :.    x = x.valu
-00004e70: 6520 6966 2069 7369 6e73 7461 6e63 6528  e if isinstance(
-00004e80: 782c 2041 7272 6179 2920 656c 7365 2078  x, Array) else x
-00004e90: 0a20 2020 2078 203d 205f 6368 6563 6b5f  .    x = _check_
-00004ea0: 7079 5f73 6571 2878 290a 2020 2020 6b65  py_seq(x).    ke
-00004eb0: 7920 3d20 7365 6c66 2e73 706c 6974 5f6b  y = self.split_k
-00004ec0: 6579 2829 2069 6620 6b65 7920 6973 204e  ey() if key is N
-00004ed0: 6f6e 6520 656c 7365 205f 666f 726d 616c  one else _formal
-00004ee0: 697a 655f 6b65 7928 6b65 7929 0a20 2020  ize_key(key).   
-00004ef0: 2072 203d 206a 722e 7065 726d 7574 6174   r = jr.permutat
-00004f00: 696f 6e28 6b65 792c 2078 2c20 6178 6973  ion(key, x, axis
-00004f10: 3d61 7869 732c 2069 6e64 6570 656e 6465  =axis, independe
-00004f20: 6e74 3d69 6e64 6570 656e 6465 6e74 290a  nt=independent).
-00004f30: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
-00004f40: 726e 2872 290a 0a20 2064 6566 2073 6875  rn(r)..  def shu
-00004f50: 6666 6c65 2873 656c 662c 2078 2c20 6178  ffle(self, x, ax
-00004f60: 6973 3d30 2c20 6b65 793d 4e6f 6e65 293a  is=0, key=None):
-00004f70: 0a20 2020 2069 6620 6e6f 7420 6973 696e  .    if not isin
-00004f80: 7374 616e 6365 2878 2c20 4172 7261 7929  stance(x, Array)
-00004f90: 3a0a 2020 2020 2020 7261 6973 6520 5479  :.      raise Ty
-00004fa0: 7065 4572 726f 7228 2754 6869 7320 6e75  peError('This nu
-00004fb0: 6d70 7920 6f70 6572 6174 6f72 206e 6565  mpy operator nee
-00004fc0: 6473 2069 6e2d 706c 6163 6520 7570 6461  ds in-place upda
-00004fd0: 7469 6e67 2c20 7468 6572 6566 6f72 6520  ting, therefore 
-00004fe0: 270a 2020 2020 2020 2020 2020 2020 2020  '.              
-00004ff0: 2020 2020 2020 2020 2769 6e70 7574 7320          'inputs 
-00005000: 7368 6f75 6c64 2062 6520 6272 6169 6e70  should be brainp
-00005010: 7920 4172 7261 792e 2729 0a20 2020 206b  y Array.').    k
-00005020: 6579 203d 2073 656c 662e 7370 6c69 745f  ey = self.split_
-00005030: 6b65 7928 2920 6966 206b 6579 2069 7320  key() if key is 
-00005040: 4e6f 6e65 2065 6c73 6520 5f66 6f72 6d61  None else _forma
-00005050: 6c69 7a65 5f6b 6579 286b 6579 290a 2020  lize_key(key).  
-00005060: 2020 782e 7661 6c75 6520 3d20 6a72 2e70    x.value = jr.p
-00005070: 6572 6d75 7461 7469 6f6e 286b 6579 2c20  ermutation(key, 
-00005080: 782e 7661 6c75 652c 2061 7869 733d 6178  x.value, axis=ax
-00005090: 6973 290a 0a20 2064 6566 2062 6574 6128  is)..  def beta(
-000050a0: 7365 6c66 2c20 612c 2062 2c20 7369 7a65  self, a, b, size
-000050b0: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
-000050c0: 3a0a 2020 2020 6120 3d20 612e 7661 6c75  :.    a = a.valu
-000050d0: 6520 6966 2069 7369 6e73 7461 6e63 6528  e if isinstance(
-000050e0: 612c 2041 7272 6179 2920 656c 7365 2061  a, Array) else a
-000050f0: 0a20 2020 2062 203d 2062 2e76 616c 7565  .    b = b.value
-00005100: 2069 6620 6973 696e 7374 616e 6365 2862   if isinstance(b
-00005110: 2c20 4172 7261 7929 2065 6c73 6520 620a  , Array) else b.
-00005120: 2020 2020 6120 3d20 5f63 6865 636b 5f70      a = _check_p
-00005130: 795f 7365 7128 6129 0a20 2020 2062 203d  y_seq(a).    b =
-00005140: 205f 6368 6563 6b5f 7079 5f73 6571 2862   _check_py_seq(b
-00005150: 290a 2020 2020 6966 2073 697a 6520 6973  ).    if size is
-00005160: 204e 6f6e 653a 0a20 2020 2020 2073 697a   None:.      siz
-00005170: 6520 3d20 6c61 782e 6272 6f61 6463 6173  e = lax.broadcas
-00005180: 745f 7368 6170 6573 286a 6e70 2e73 6861  t_shapes(jnp.sha
-00005190: 7065 2861 292c 206a 6e70 2e73 6861 7065  pe(a), jnp.shape
-000051a0: 2862 2929 0a20 2020 206b 6579 203d 2073  (b)).    key = s
-000051b0: 656c 662e 7370 6c69 745f 6b65 7928 2920  elf.split_key() 
-000051c0: 6966 206b 6579 2069 7320 4e6f 6e65 2065  if key is None e
-000051d0: 6c73 6520 5f66 6f72 6d61 6c69 7a65 5f6b  lse _formalize_k
-000051e0: 6579 286b 6579 290a 2020 2020 7220 3d20  ey(key).    r = 
-000051f0: 6a72 2e62 6574 6128 6b65 792c 2061 3d61  jr.beta(key, a=a
-00005200: 2c20 623d 622c 2073 6861 7065 3d5f 7369  , b=b, shape=_si
-00005210: 7a65 3273 6861 7065 2873 697a 6529 290a  ze2shape(size)).
-00005220: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
-00005230: 726e 2872 290a 0a20 2064 6566 2065 7870  rn(r)..  def exp
-00005240: 6f6e 656e 7469 616c 2873 656c 662c 2073  onential(self, s
-00005250: 6361 6c65 3d4e 6f6e 652c 2073 697a 653d  cale=None, size=
-00005260: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
-00005270: 0a20 2020 2073 6361 6c65 203d 205f 6173  .    scale = _as
-00005280: 5f6a 6178 5f61 7272 6179 2873 6361 6c65  _jax_array(scale
-00005290: 290a 2020 2020 7363 616c 6520 3d20 5f63  ).    scale = _c
-000052a0: 6865 636b 5f70 795f 7365 7128 7363 616c  heck_py_seq(scal
-000052b0: 6529 0a20 2020 2069 6620 7369 7a65 2069  e).    if size i
-000052c0: 7320 4e6f 6e65 3a0a 2020 2020 2020 7369  s None:.      si
-000052d0: 7a65 203d 206a 6e70 2e73 6861 7065 2873  ze = jnp.shape(s
-000052e0: 6361 6c65 290a 2020 2020 6b65 7920 3d20  cale).    key = 
-000052f0: 7365 6c66 2e73 706c 6974 5f6b 6579 2829  self.split_key()
-00005300: 2069 6620 6b65 7920 6973 204e 6f6e 6520   if key is None 
-00005310: 656c 7365 205f 666f 726d 616c 697a 655f  else _formalize_
-00005320: 6b65 7928 6b65 7929 0a20 2020 2072 203d  key(key).    r =
-00005330: 206a 722e 6578 706f 6e65 6e74 6961 6c28   jr.exponential(
-00005340: 6b65 792c 2073 6861 7065 3d5f 7369 7a65  key, shape=_size
-00005350: 3273 6861 7065 2873 697a 6529 290a 2020  2shape(size)).  
-00005360: 2020 6966 2073 6361 6c65 2069 7320 6e6f    if scale is no
-00005370: 7420 4e6f 6e65 3a0a 2020 2020 2020 7220  t None:.      r 
-00005380: 3d20 7220 2f20 7363 616c 650a 2020 2020  = r / scale.    
-00005390: 7265 7475 726e 205f 7265 7475 726e 2872  return _return(r
-000053a0: 290a 0a20 2064 6566 2067 616d 6d61 2873  )..  def gamma(s
-000053b0: 656c 662c 2073 6861 7065 2c20 7363 616c  elf, shape, scal
-000053c0: 653d 4e6f 6e65 2c20 7369 7a65 3d4e 6f6e  e=None, size=Non
-000053d0: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
-000053e0: 2020 7368 6170 6520 3d20 5f61 735f 6a61    shape = _as_ja
-000053f0: 785f 6172 7261 7928 7368 6170 6529 0a20  x_array(shape). 
-00005400: 2020 2073 6361 6c65 203d 205f 6173 5f6a     scale = _as_j
-00005410: 6178 5f61 7272 6179 2873 6361 6c65 290a  ax_array(scale).
-00005420: 2020 2020 7368 6170 6520 3d20 5f63 6865      shape = _che
-00005430: 636b 5f70 795f 7365 7128 7368 6170 6529  ck_py_seq(shape)
-00005440: 0a20 2020 2073 6361 6c65 203d 205f 6368  .    scale = _ch
-00005450: 6563 6b5f 7079 5f73 6571 2873 6361 6c65  eck_py_seq(scale
-00005460: 290a 2020 2020 6966 2073 697a 6520 6973  ).    if size is
-00005470: 204e 6f6e 653a 0a20 2020 2020 2073 697a   None:.      siz
-00005480: 6520 3d20 6c61 782e 6272 6f61 6463 6173  e = lax.broadcas
-00005490: 745f 7368 6170 6573 286a 6e70 2e73 6861  t_shapes(jnp.sha
-000054a0: 7065 2873 6861 7065 292c 206a 6e70 2e73  pe(shape), jnp.s
-000054b0: 6861 7065 2873 6361 6c65 2929 0a20 2020  hape(scale)).   
-000054c0: 206b 6579 203d 2073 656c 662e 7370 6c69   key = self.spli
-000054d0: 745f 6b65 7928 2920 6966 206b 6579 2069  t_key() if key i
-000054e0: 7320 4e6f 6e65 2065 6c73 6520 5f66 6f72  s None else _for
-000054f0: 6d61 6c69 7a65 5f6b 6579 286b 6579 290a  malize_key(key).
-00005500: 2020 2020 7220 3d20 6a72 2e67 616d 6d61      r = jr.gamma
-00005510: 286b 6579 2c20 613d 7368 6170 652c 2073  (key, a=shape, s
-00005520: 6861 7065 3d5f 7369 7a65 3273 6861 7065  hape=_size2shape
-00005530: 2873 697a 6529 290a 2020 2020 6966 2073  (size)).    if s
-00005540: 6361 6c65 2069 7320 6e6f 7420 4e6f 6e65  cale is not None
-00005550: 3a0a 2020 2020 2020 7220 3d20 7220 2a20  :.      r = r * 
-00005560: 7363 616c 650a 2020 2020 7265 7475 726e  scale.    return
-00005570: 205f 7265 7475 726e 2872 290a 0a20 2064   _return(r)..  d
-00005580: 6566 2067 756d 6265 6c28 7365 6c66 2c20  ef gumbel(self, 
-00005590: 6c6f 633d 4e6f 6e65 2c20 7363 616c 653d  loc=None, scale=
-000055a0: 4e6f 6e65 2c20 7369 7a65 3d4e 6f6e 652c  None, size=None,
-000055b0: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2020   key=None):.    
-000055c0: 6c6f 6320 3d20 5f61 735f 6a61 785f 6172  loc = _as_jax_ar
-000055d0: 7261 7928 6c6f 6329 0a20 2020 2073 6361  ray(loc).    sca
-000055e0: 6c65 203d 205f 6173 5f6a 6178 5f61 7272  le = _as_jax_arr
-000055f0: 6179 2873 6361 6c65 290a 2020 2020 6c6f  ay(scale).    lo
-00005600: 6320 3d20 5f63 6865 636b 5f70 795f 7365  c = _check_py_se
-00005610: 7128 6c6f 6329 0a20 2020 2073 6361 6c65  q(loc).    scale
-00005620: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
-00005630: 2873 6361 6c65 290a 2020 2020 6966 2073  (scale).    if s
-00005640: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
-00005650: 2020 2073 697a 6520 3d20 6c61 782e 6272     size = lax.br
-00005660: 6f61 6463 6173 745f 7368 6170 6573 286a  oadcast_shapes(j
-00005670: 6e70 2e73 6861 7065 286c 6f63 292c 206a  np.shape(loc), j
-00005680: 6e70 2e73 6861 7065 2873 6361 6c65 2929  np.shape(scale))
-00005690: 0a20 2020 206b 6579 203d 2073 656c 662e  .    key = self.
-000056a0: 7370 6c69 745f 6b65 7928 2920 6966 206b  split_key() if k
-000056b0: 6579 2069 7320 4e6f 6e65 2065 6c73 6520  ey is None else 
-000056c0: 5f66 6f72 6d61 6c69 7a65 5f6b 6579 286b  _formalize_key(k
-000056d0: 6579 290a 2020 2020 7220 3d20 5f6c 6f63  ey).    r = _loc
-000056e0: 5f73 6361 6c65 286c 6f63 2c20 7363 616c  _scale(loc, scal
-000056f0: 652c 206a 722e 6775 6d62 656c 286b 6579  e, jr.gumbel(key
-00005700: 2c20 7368 6170 653d 5f73 697a 6532 7368  , shape=_size2sh
-00005710: 6170 6528 7369 7a65 2929 290a 2020 2020  ape(size))).    
-00005720: 7265 7475 726e 205f 7265 7475 726e 2872  return _return(r
-00005730: 290a 0a20 2064 6566 206c 6170 6c61 6365  )..  def laplace
-00005740: 2873 656c 662c 206c 6f63 3d4e 6f6e 652c  (self, loc=None,
-00005750: 2073 6361 6c65 3d4e 6f6e 652c 2073 697a   scale=None, siz
-00005760: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
-00005770: 293a 0a20 2020 206c 6f63 203d 205f 6173  ):.    loc = _as
-00005780: 5f6a 6178 5f61 7272 6179 286c 6f63 290a  _jax_array(loc).
-00005790: 2020 2020 7363 616c 6520 3d20 5f61 735f      scale = _as_
-000057a0: 6a61 785f 6172 7261 7928 7363 616c 6529  jax_array(scale)
-000057b0: 0a20 2020 206c 6f63 203d 205f 6368 6563  .    loc = _chec
-000057c0: 6b5f 7079 5f73 6571 286c 6f63 290a 2020  k_py_seq(loc).  
-000057d0: 2020 7363 616c 6520 3d20 5f63 6865 636b    scale = _check
-000057e0: 5f70 795f 7365 7128 7363 616c 6529 0a20  _py_seq(scale). 
-000057f0: 2020 2069 6620 7369 7a65 2069 7320 4e6f     if size is No
-00005800: 6e65 3a0a 2020 2020 2020 7369 7a65 203d  ne:.      size =
-00005810: 206c 6178 2e62 726f 6164 6361 7374 5f73   lax.broadcast_s
-00005820: 6861 7065 7328 6a6e 702e 7368 6170 6528  hapes(jnp.shape(
-00005830: 6c6f 6329 2c20 6a6e 702e 7368 6170 6528  loc), jnp.shape(
-00005840: 7363 616c 6529 290a 2020 2020 6b65 7920  scale)).    key 
-00005850: 3d20 7365 6c66 2e73 706c 6974 5f6b 6579  = self.split_key
-00005860: 2829 2069 6620 6b65 7920 6973 204e 6f6e  () if key is Non
-00005870: 6520 656c 7365 205f 666f 726d 616c 697a  e else _formaliz
-00005880: 655f 6b65 7928 6b65 7929 0a20 2020 2072  e_key(key).    r
-00005890: 203d 205f 6c6f 635f 7363 616c 6528 6c6f   = _loc_scale(lo
-000058a0: 632c 2073 6361 6c65 2c20 6a72 2e6c 6170  c, scale, jr.lap
-000058b0: 6c61 6365 286b 6579 2c20 7368 6170 653d  lace(key, shape=
-000058c0: 5f73 697a 6532 7368 6170 6528 7369 7a65  _size2shape(size
-000058d0: 2929 290a 2020 2020 7265 7475 726e 205f  ))).    return _
-000058e0: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
-000058f0: 206c 6f67 6973 7469 6328 7365 6c66 2c20   logistic(self, 
-00005900: 6c6f 633d 4e6f 6e65 2c20 7363 616c 653d  loc=None, scale=
-00005910: 4e6f 6e65 2c20 7369 7a65 3d4e 6f6e 652c  None, size=None,
-00005920: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2020   key=None):.    
-00005930: 6c6f 6320 3d20 5f61 735f 6a61 785f 6172  loc = _as_jax_ar
-00005940: 7261 7928 6c6f 6329 0a20 2020 2073 6361  ray(loc).    sca
-00005950: 6c65 203d 205f 6173 5f6a 6178 5f61 7272  le = _as_jax_arr
-00005960: 6179 2873 6361 6c65 290a 2020 2020 6c6f  ay(scale).    lo
-00005970: 6320 3d20 5f63 6865 636b 5f70 795f 7365  c = _check_py_se
-00005980: 7128 6c6f 6329 0a20 2020 2073 6361 6c65  q(loc).    scale
-00005990: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
-000059a0: 2873 6361 6c65 290a 2020 2020 6966 2073  (scale).    if s
-000059b0: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
-000059c0: 2020 2073 697a 6520 3d20 6c61 782e 6272     size = lax.br
-000059d0: 6f61 6463 6173 745f 7368 6170 6573 286a  oadcast_shapes(j
-000059e0: 6e70 2e73 6861 7065 286c 6f63 292c 206a  np.shape(loc), j
-000059f0: 6e70 2e73 6861 7065 2873 6361 6c65 2929  np.shape(scale))
-00005a00: 0a20 2020 206b 6579 203d 2073 656c 662e  .    key = self.
-00005a10: 7370 6c69 745f 6b65 7928 2920 6966 206b  split_key() if k
-00005a20: 6579 2069 7320 4e6f 6e65 2065 6c73 6520  ey is None else 
-00005a30: 5f66 6f72 6d61 6c69 7a65 5f6b 6579 286b  _formalize_key(k
-00005a40: 6579 290a 2020 2020 7220 3d20 5f6c 6f63  ey).    r = _loc
-00005a50: 5f73 6361 6c65 286c 6f63 2c20 7363 616c  _scale(loc, scal
-00005a60: 652c 206a 722e 6c6f 6769 7374 6963 286b  e, jr.logistic(k
-00005a70: 6579 2c20 7368 6170 653d 5f73 697a 6532  ey, shape=_size2
-00005a80: 7368 6170 6528 7369 7a65 2929 290a 2020  shape(size))).  
-00005a90: 2020 7265 7475 726e 205f 7265 7475 726e    return _return
-00005aa0: 2872 290a 0a20 2064 6566 206e 6f72 6d61  (r)..  def norma
-00005ab0: 6c28 7365 6c66 2c20 6c6f 633d 4e6f 6e65  l(self, loc=None
-00005ac0: 2c20 7363 616c 653d 4e6f 6e65 2c20 7369  , scale=None, si
-00005ad0: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
-00005ae0: 6529 3a0a 2020 2020 6c6f 6320 3d20 5f61  e):.    loc = _a
-00005af0: 735f 6a61 785f 6172 7261 7928 6c6f 6329  s_jax_array(loc)
-00005b00: 0a20 2020 2073 6361 6c65 203d 205f 6173  .    scale = _as
-00005b10: 5f6a 6178 5f61 7272 6179 2873 6361 6c65  _jax_array(scale
-00005b20: 290a 2020 2020 6c6f 6320 3d20 5f63 6865  ).    loc = _che
-00005b30: 636b 5f70 795f 7365 7128 6c6f 6329 0a20  ck_py_seq(loc). 
-00005b40: 2020 2073 6361 6c65 203d 205f 6368 6563     scale = _chec
-00005b50: 6b5f 7079 5f73 6571 2873 6361 6c65 290a  k_py_seq(scale).
-00005b60: 2020 2020 6966 2073 697a 6520 6973 204e      if size is N
-00005b70: 6f6e 653a 0a20 2020 2020 2073 697a 6520  one:.      size 
-00005b80: 3d20 6c61 782e 6272 6f61 6463 6173 745f  = lax.broadcast_
-00005b90: 7368 6170 6573 286a 6e70 2e73 6861 7065  shapes(jnp.shape
-00005ba0: 2873 6361 6c65 292c 206a 6e70 2e73 6861  (scale), jnp.sha
-00005bb0: 7065 286c 6f63 2929 0a20 2020 206b 6579  pe(loc)).    key
-00005bc0: 203d 2073 656c 662e 7370 6c69 745f 6b65   = self.split_ke
-00005bd0: 7928 2920 6966 206b 6579 2069 7320 4e6f  y() if key is No
-00005be0: 6e65 2065 6c73 6520 5f66 6f72 6d61 6c69  ne else _formali
-00005bf0: 7a65 5f6b 6579 286b 6579 290a 2020 2020  ze_key(key).    
-00005c00: 7220 3d20 5f6c 6f63 5f73 6361 6c65 286c  r = _loc_scale(l
-00005c10: 6f63 2c20 7363 616c 652c 206a 722e 6e6f  oc, scale, jr.no
-00005c20: 726d 616c 286b 6579 2c20 7368 6170 653d  rmal(key, shape=
-00005c30: 5f73 697a 6532 7368 6170 6528 7369 7a65  _size2shape(size
-00005c40: 2929 290a 2020 2020 7265 7475 726e 205f  ))).    return _
-00005c50: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
-00005c60: 2070 6172 6574 6f28 7365 6c66 2c20 612c   pareto(self, a,
-00005c70: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
-00005c80: 4e6f 6e65 293a 0a20 2020 2061 203d 205f  None):.    a = _
-00005c90: 6173 5f6a 6178 5f61 7272 6179 2861 290a  as_jax_array(a).
-00005ca0: 2020 2020 6120 3d20 5f63 6865 636b 5f70      a = _check_p
-00005cb0: 795f 7365 7128 6129 0a20 2020 2069 6620  y_seq(a).    if 
-00005cc0: 7369 7a65 2069 7320 4e6f 6e65 3a0a 2020  size is None:.  
-00005cd0: 2020 2020 7369 7a65 203d 206a 6e70 2e73      size = jnp.s
-00005ce0: 6861 7065 2861 290a 2020 2020 6b65 7920  hape(a).    key 
-00005cf0: 3d20 7365 6c66 2e73 706c 6974 5f6b 6579  = self.split_key
-00005d00: 2829 2069 6620 6b65 7920 6973 204e 6f6e  () if key is Non
-00005d10: 6520 656c 7365 205f 666f 726d 616c 697a  e else _formaliz
-00005d20: 655f 6b65 7928 6b65 7929 0a20 2020 2072  e_key(key).    r
-00005d30: 203d 206a 722e 7061 7265 746f 286b 6579   = jr.pareto(key
-00005d40: 2c20 623d 612c 2073 6861 7065 3d5f 7369  , b=a, shape=_si
-00005d50: 7a65 3273 6861 7065 2873 697a 6529 290a  ze2shape(size)).
-00005d60: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
-00005d70: 726e 2872 290a 0a20 2064 6566 2070 6f69  rn(r)..  def poi
-00005d80: 7373 6f6e 2873 656c 662c 206c 616d 3d31  sson(self, lam=1
-00005d90: 2e30 2c20 7369 7a65 3d4e 6f6e 652c 206b  .0, size=None, k
-00005da0: 6579 3d4e 6f6e 6529 3a0a 2020 2020 6c61  ey=None):.    la
-00005db0: 6d20 3d20 5f63 6865 636b 5f70 795f 7365  m = _check_py_se
-00005dc0: 7128 5f61 735f 6a61 785f 6172 7261 7928  q(_as_jax_array(
-00005dd0: 6c61 6d29 290a 2020 2020 6966 2073 697a  lam)).    if siz
-00005de0: 6520 6973 204e 6f6e 653a 0a20 2020 2020  e is None:.     
-00005df0: 2073 697a 6520 3d20 6a6e 702e 7368 6170   size = jnp.shap
-00005e00: 6528 6c61 6d29 0a20 2020 206b 6579 203d  e(lam).    key =
-00005e10: 2073 656c 662e 7370 6c69 745f 6b65 7928   self.split_key(
-00005e20: 2920 6966 206b 6579 2069 7320 4e6f 6e65  ) if key is None
-00005e30: 2065 6c73 6520 5f66 6f72 6d61 6c69 7a65   else _formalize
-00005e40: 5f6b 6579 286b 6579 290a 2020 2020 7220  _key(key).    r 
-00005e50: 3d20 6a72 2e70 6f69 7373 6f6e 286b 6579  = jr.poisson(key
-00005e60: 2c20 6c61 6d3d 6c61 6d2c 2073 6861 7065  , lam=lam, shape
-00005e70: 3d5f 7369 7a65 3273 6861 7065 2873 697a  =_size2shape(siz
-00005e80: 6529 290a 2020 2020 7265 7475 726e 205f  e)).    return _
-00005e90: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
-00005ea0: 2073 7461 6e64 6172 645f 6361 7563 6879   standard_cauchy
-00005eb0: 2873 656c 662c 2073 697a 653d 4e6f 6e65  (self, size=None
-00005ec0: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2020  , key=None):.   
-00005ed0: 206b 6579 203d 2073 656c 662e 7370 6c69   key = self.spli
-00005ee0: 745f 6b65 7928 2920 6966 206b 6579 2069  t_key() if key i
-00005ef0: 7320 4e6f 6e65 2065 6c73 6520 5f66 6f72  s None else _for
-00005f00: 6d61 6c69 7a65 5f6b 6579 286b 6579 290a  malize_key(key).
-00005f10: 2020 2020 7220 3d20 6a72 2e63 6175 6368      r = jr.cauch
-00005f20: 7928 6b65 792c 2073 6861 7065 3d5f 7369  y(key, shape=_si
-00005f30: 7a65 3273 6861 7065 2873 697a 6529 290a  ze2shape(size)).
-00005f40: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
-00005f50: 726e 2872 290a 0a20 2064 6566 2073 7461  rn(r)..  def sta
-00005f60: 6e64 6172 645f 6578 706f 6e65 6e74 6961  ndard_exponentia
-00005f70: 6c28 7365 6c66 2c20 7369 7a65 3d4e 6f6e  l(self, size=Non
-00005f80: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
-00005f90: 2020 6b65 7920 3d20 7365 6c66 2e73 706c    key = self.spl
-00005fa0: 6974 5f6b 6579 2829 2069 6620 6b65 7920  it_key() if key 
-00005fb0: 6973 204e 6f6e 6520 656c 7365 205f 666f  is None else _fo
-00005fc0: 726d 616c 697a 655f 6b65 7928 6b65 7929  rmalize_key(key)
-00005fd0: 0a20 2020 2072 203d 206a 722e 6578 706f  .    r = jr.expo
-00005fe0: 6e65 6e74 6961 6c28 6b65 792c 2073 6861  nential(key, sha
-00005ff0: 7065 3d5f 7369 7a65 3273 6861 7065 2873  pe=_size2shape(s
-00006000: 697a 6529 290a 2020 2020 7265 7475 726e  ize)).    return
-00006010: 205f 7265 7475 726e 2872 290a 0a20 2064   _return(r)..  d
-00006020: 6566 2073 7461 6e64 6172 645f 6761 6d6d  ef standard_gamm
-00006030: 6128 7365 6c66 2c20 7368 6170 652c 2073  a(self, shape, s
-00006040: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
-00006050: 6e65 293a 0a20 2020 2073 6861 7065 203d  ne):.    shape =
-00006060: 205f 6173 5f6a 6178 5f61 7272 6179 2873   _as_jax_array(s
-00006070: 6861 7065 290a 2020 2020 7368 6170 6520  hape).    shape 
-00006080: 3d20 5f63 6865 636b 5f70 795f 7365 7128  = _check_py_seq(
-00006090: 7368 6170 6529 0a20 2020 2069 6620 7369  shape).    if si
-000060a0: 7a65 2069 7320 4e6f 6e65 3a0a 2020 2020  ze is None:.    
-000060b0: 2020 7369 7a65 203d 206a 6e70 2e73 6861    size = jnp.sha
-000060c0: 7065 2873 6861 7065 290a 2020 2020 6b65  pe(shape).    ke
-000060d0: 7920 3d20 7365 6c66 2e73 706c 6974 5f6b  y = self.split_k
-000060e0: 6579 2829 2069 6620 6b65 7920 6973 204e  ey() if key is N
-000060f0: 6f6e 6520 656c 7365 205f 666f 726d 616c  one else _formal
-00006100: 697a 655f 6b65 7928 6b65 7929 0a20 2020  ize_key(key).   
-00006110: 2072 203d 206a 722e 6761 6d6d 6128 6b65   r = jr.gamma(ke
-00006120: 792c 2061 3d73 6861 7065 2c20 7368 6170  y, a=shape, shap
-00006130: 653d 5f73 697a 6532 7368 6170 6528 7369  e=_size2shape(si
-00006140: 7a65 2929 0a20 2020 2072 6574 7572 6e20  ze)).    return 
-00006150: 5f72 6574 7572 6e28 7229 0a0a 2020 6465  _return(r)..  de
-00006160: 6620 7374 616e 6461 7264 5f6e 6f72 6d61  f standard_norma
-00006170: 6c28 7365 6c66 2c20 7369 7a65 3d4e 6f6e  l(self, size=Non
-00006180: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
-00006190: 2020 6b65 7920 3d20 7365 6c66 2e73 706c    key = self.spl
-000061a0: 6974 5f6b 6579 2829 2069 6620 6b65 7920  it_key() if key 
-000061b0: 6973 204e 6f6e 6520 656c 7365 205f 666f  is None else _fo
-000061c0: 726d 616c 697a 655f 6b65 7928 6b65 7929  rmalize_key(key)
-000061d0: 0a20 2020 2072 203d 206a 722e 6e6f 726d  .    r = jr.norm
-000061e0: 616c 286b 6579 2c20 7368 6170 653d 5f73  al(key, shape=_s
-000061f0: 697a 6532 7368 6170 6528 7369 7a65 2929  ize2shape(size))
-00006200: 0a20 2020 2072 6574 7572 6e20 5f72 6574  .    return _ret
-00006210: 7572 6e28 7229 0a0a 2020 6465 6620 7374  urn(r)..  def st
-00006220: 616e 6461 7264 5f74 2873 656c 662c 2064  andard_t(self, d
-00006230: 662c 2073 697a 653d 4e6f 6e65 2c20 6b65  f, size=None, ke
-00006240: 793d 4e6f 6e65 293a 0a20 2020 2064 6620  y=None):.    df 
-00006250: 3d20 5f61 735f 6a61 785f 6172 7261 7928  = _as_jax_array(
-00006260: 6466 290a 2020 2020 6466 203d 205f 6368  df).    df = _ch
-00006270: 6563 6b5f 7079 5f73 6571 2864 6629 0a20  eck_py_seq(df). 
-00006280: 2020 2069 6620 7369 7a65 2069 7320 4e6f     if size is No
-00006290: 6e65 3a0a 2020 2020 2020 7369 7a65 203d  ne:.      size =
-000062a0: 206a 6e70 2e73 6861 7065 2873 697a 6529   jnp.shape(size)
-000062b0: 0a20 2020 206b 6579 203d 2073 656c 662e  .    key = self.
-000062c0: 7370 6c69 745f 6b65 7928 2920 6966 206b  split_key() if k
-000062d0: 6579 2069 7320 4e6f 6e65 2065 6c73 6520  ey is None else 
-000062e0: 5f66 6f72 6d61 6c69 7a65 5f6b 6579 286b  _formalize_key(k
-000062f0: 6579 290a 2020 2020 7220 3d20 6a72 2e74  ey).    r = jr.t
-00006300: 286b 6579 2c20 6466 3d64 662c 2073 6861  (key, df=df, sha
-00006310: 7065 3d5f 7369 7a65 3273 6861 7065 2873  pe=_size2shape(s
-00006320: 697a 6529 290a 2020 2020 7265 7475 726e  ize)).    return
-00006330: 205f 7265 7475 726e 2872 290a 0a20 2064   _return(r)..  d
-00006340: 6566 2075 6e69 666f 726d 2873 656c 662c  ef uniform(self,
-00006350: 206c 6f77 3d30 2e30 2c20 6869 6768 3d31   low=0.0, high=1
-00006360: 2e30 2c20 7369 7a65 3d4e 6f6e 652c 206b  .0, size=None, k
-00006370: 6579 3d4e 6f6e 6529 3a0a 2020 2020 6c6f  ey=None):.    lo
-00006380: 7720 3d20 5f61 735f 6a61 785f 6172 7261  w = _as_jax_arra
-00006390: 7928 6c6f 7729 0a20 2020 2068 6967 6820  y(low).    high 
-000063a0: 3d20 5f61 735f 6a61 785f 6172 7261 7928  = _as_jax_array(
-000063b0: 6869 6768 290a 2020 2020 6c6f 7720 3d20  high).    low = 
-000063c0: 5f63 6865 636b 5f70 795f 7365 7128 6c6f  _check_py_seq(lo
-000063d0: 7729 0a20 2020 2068 6967 6820 3d20 5f63  w).    high = _c
-000063e0: 6865 636b 5f70 795f 7365 7128 6869 6768  heck_py_seq(high
-000063f0: 290a 2020 2020 6966 2073 697a 6520 6973  ).    if size is
-00006400: 204e 6f6e 653a 0a20 2020 2020 2073 697a   None:.      siz
-00006410: 6520 3d20 6c61 782e 6272 6f61 6463 6173  e = lax.broadcas
-00006420: 745f 7368 6170 6573 286a 6e70 2e73 6861  t_shapes(jnp.sha
-00006430: 7065 286c 6f77 292c 206a 6e70 2e73 6861  pe(low), jnp.sha
-00006440: 7065 2868 6967 6829 290a 2020 2020 6b65  pe(high)).    ke
-00006450: 7920 3d20 7365 6c66 2e73 706c 6974 5f6b  y = self.split_k
-00006460: 6579 2829 2069 6620 6b65 7920 6973 204e  ey() if key is N
-00006470: 6f6e 6520 656c 7365 205f 666f 726d 616c  one else _formal
-00006480: 697a 655f 6b65 7928 6b65 7929 0a20 2020  ize_key(key).   
-00006490: 2072 203d 206a 722e 756e 6966 6f72 6d28   r = jr.uniform(
-000064a0: 6b65 792c 2073 6861 7065 3d5f 7369 7a65  key, shape=_size
-000064b0: 3273 6861 7065 2873 697a 6529 2c20 6d69  2shape(size), mi
-000064c0: 6e76 616c 3d6c 6f77 2c20 6d61 7876 616c  nval=low, maxval
-000064d0: 3d68 6967 6829 0a20 2020 2072 6574 7572  =high).    retur
-000064e0: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
-000064f0: 6465 6620 7472 756e 6361 7465 645f 6e6f  def truncated_no
-00006500: 726d 616c 2873 656c 662c 206c 6f77 6572  rmal(self, lower
-00006510: 2c20 7570 7065 722c 2073 697a 653d 4e6f  , upper, size=No
-00006520: 6e65 2c20 7363 616c 653d 4e6f 6e65 2c20  ne, scale=None, 
-00006530: 6b65 793d 4e6f 6e65 293a 0a20 2020 206c  key=None):.    l
-00006540: 6f77 6572 203d 205f 6173 5f6a 6178 5f61  ower = _as_jax_a
-00006550: 7272 6179 286c 6f77 6572 290a 2020 2020  rray(lower).    
-00006560: 6c6f 7765 7220 3d20 5f63 6865 636b 5f70  lower = _check_p
-00006570: 795f 7365 7128 6c6f 7765 7229 0a20 2020  y_seq(lower).   
-00006580: 2075 7070 6572 203d 205f 6173 5f6a 6178   upper = _as_jax
-00006590: 5f61 7272 6179 2875 7070 6572 290a 2020  _array(upper).  
-000065a0: 2020 7570 7065 7220 3d20 5f63 6865 636b    upper = _check
-000065b0: 5f70 795f 7365 7128 7570 7065 7229 0a20  _py_seq(upper). 
-000065c0: 2020 2073 6361 6c65 203d 205f 6173 5f6a     scale = _as_j
-000065d0: 6178 5f61 7272 6179 2873 6361 6c65 290a  ax_array(scale).
-000065e0: 2020 2020 7363 616c 6520 3d20 5f63 6865      scale = _che
-000065f0: 636b 5f70 795f 7365 7128 7363 616c 6529  ck_py_seq(scale)
-00006600: 0a20 2020 2069 6620 7369 7a65 2069 7320  .    if size is 
-00006610: 4e6f 6e65 3a0a 2020 2020 2020 7369 7a65  None:.      size
-00006620: 203d 206c 6178 2e62 726f 6164 6361 7374   = lax.broadcast
-00006630: 5f73 6861 7065 7328 6a6e 702e 7368 6170  _shapes(jnp.shap
-00006640: 6528 6c6f 7765 7229 2c0a 2020 2020 2020  e(lower),.      
+00004700: 206a 6e70 2e73 6861 7065 2868 6967 6829   jnp.shape(high)
+00004710: 290a 2020 2020 6b65 7920 3d20 7365 6c66  ).    key = self
+00004720: 2e73 706c 6974 5f6b 6579 2829 2069 6620  .split_key() if 
+00004730: 6b65 7920 6973 204e 6f6e 6520 656c 7365  key is None else
+00004740: 205f 666f 726d 616c 697a 655f 6b65 7928   _formalize_key(
+00004750: 6b65 7929 0a20 2020 2072 203d 206a 722e  key).    r = jr.
+00004760: 7261 6e64 696e 7428 6b65 792c 0a20 2020  randint(key,.   
+00004770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004780: 7368 6170 653d 5f73 697a 6532 7368 6170  shape=_size2shap
+00004790: 6528 7369 7a65 292c 0a20 2020 2020 2020  e(size),.       
+000047a0: 2020 2020 2020 2020 2020 2020 6d69 6e76              minv
+000047b0: 616c 3d6c 6f77 2c20 6d61 7876 616c 3d68  al=low, maxval=h
+000047c0: 6967 682c 2064 7479 7065 3d64 7479 7065  igh, dtype=dtype
+000047d0: 290a 2020 2020 7265 7475 726e 205f 7265  ).    return _re
+000047e0: 7475 726e 2872 290a 0a20 2064 6566 2072  turn(r)..  def r
+000047f0: 616e 646f 6d5f 696e 7465 6765 7273 2873  andom_integers(s
+00004800: 656c 662c 206c 6f77 2c20 6869 6768 3d4e  elf, low, high=N
+00004810: 6f6e 652c 2073 697a 653d 4e6f 6e65 2c20  one, size=None, 
+00004820: 6b65 793d 4e6f 6e65 293a 0a20 2020 206c  key=None):.    l
+00004830: 6f77 203d 205f 6173 5f6a 6178 5f61 7272  ow = _as_jax_arr
+00004840: 6179 286c 6f77 290a 2020 2020 6869 6768  ay(low).    high
+00004850: 203d 205f 6173 5f6a 6178 5f61 7272 6179   = _as_jax_array
+00004860: 2868 6967 6829 0a20 2020 206c 6f77 203d  (high).    low =
+00004870: 205f 6368 6563 6b5f 7079 5f73 6571 286c   _check_py_seq(l
+00004880: 6f77 290a 2020 2020 6869 6768 203d 205f  ow).    high = _
+00004890: 6368 6563 6b5f 7079 5f73 6571 2868 6967  check_py_seq(hig
+000048a0: 6829 0a20 2020 2069 6620 6869 6768 2069  h).    if high i
+000048b0: 7320 4e6f 6e65 3a0a 2020 2020 2020 6869  s None:.      hi
+000048c0: 6768 203d 206c 6f77 0a20 2020 2020 206c  gh = low.      l
+000048d0: 6f77 203d 2031 0a20 2020 2068 6967 6820  ow = 1.    high 
+000048e0: 2b3d 2031 0a20 2020 2069 6620 7369 7a65  += 1.    if size
+000048f0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00004900: 7369 7a65 203d 206c 6178 2e62 726f 6164  size = lax.broad
+00004910: 6361 7374 5f73 6861 7065 7328 6a6e 702e  cast_shapes(jnp.
+00004920: 7368 6170 6528 6c6f 7729 2c20 6a6e 702e  shape(low), jnp.
+00004930: 7368 6170 6528 6869 6768 2929 0a20 2020  shape(high)).   
+00004940: 206b 6579 203d 2073 656c 662e 7370 6c69   key = self.spli
+00004950: 745f 6b65 7928 2920 6966 206b 6579 2069  t_key() if key i
+00004960: 7320 4e6f 6e65 2065 6c73 6520 5f66 6f72  s None else _for
+00004970: 6d61 6c69 7a65 5f6b 6579 286b 6579 290a  malize_key(key).
+00004980: 2020 2020 7220 3d20 6a72 2e72 616e 6469      r = jr.randi
+00004990: 6e74 286b 6579 2c0a 2020 2020 2020 2020  nt(key,.        
+000049a0: 2020 2020 2020 2020 2020 2073 6861 7065             shape
+000049b0: 3d5f 7369 7a65 3273 6861 7065 2873 697a  =_size2shape(siz
+000049c0: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
+000049d0: 2020 2020 2020 206d 696e 7661 6c3d 6c6f         minval=lo
+000049e0: 772c 0a20 2020 2020 2020 2020 2020 2020  w,.             
+000049f0: 2020 2020 2020 6d61 7876 616c 3d68 6967        maxval=hig
+00004a00: 6829 0a20 2020 2072 6574 7572 6e20 5f72  h).    return _r
+00004a10: 6574 7572 6e28 7229 0a0a 2020 6465 6620  eturn(r)..  def 
+00004a20: 7261 6e64 6e28 7365 6c66 2c20 2a64 6e2c  randn(self, *dn,
+00004a30: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2020   key=None):.    
+00004a40: 6b65 7920 3d20 7365 6c66 2e73 706c 6974  key = self.split
+00004a50: 5f6b 6579 2829 2069 6620 6b65 7920 6973  _key() if key is
+00004a60: 204e 6f6e 6520 656c 7365 205f 666f 726d   None else _form
+00004a70: 616c 697a 655f 6b65 7928 6b65 7929 0a20  alize_key(key). 
+00004a80: 2020 2072 203d 206a 722e 6e6f 726d 616c     r = jr.normal
+00004a90: 286b 6579 2c20 7368 6170 653d 646e 290a  (key, shape=dn).
+00004aa0: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
+00004ab0: 726e 2872 290a 0a20 2064 6566 2072 616e  rn(r)..  def ran
+00004ac0: 646f 6d28 7365 6c66 2c20 7369 7a65 3d4e  dom(self, size=N
+00004ad0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+00004ae0: 2020 2020 6b65 7920 3d20 7365 6c66 2e73      key = self.s
+00004af0: 706c 6974 5f6b 6579 2829 2069 6620 6b65  plit_key() if ke
+00004b00: 7920 6973 204e 6f6e 6520 656c 7365 205f  y is None else _
+00004b10: 666f 726d 616c 697a 655f 6b65 7928 6b65  formalize_key(ke
+00004b20: 7929 0a20 2020 2072 203d 206a 722e 756e  y).    r = jr.un
+00004b30: 6966 6f72 6d28 6b65 792c 2073 6861 7065  iform(key, shape
+00004b40: 3d5f 7369 7a65 3273 6861 7065 2873 697a  =_size2shape(siz
+00004b50: 6529 2c20 6d69 6e76 616c 3d30 2e2c 206d  e), minval=0., m
+00004b60: 6178 7661 6c3d 312e 290a 2020 2020 7265  axval=1.).    re
+00004b70: 7475 726e 205f 7265 7475 726e 2872 290a  turn _return(r).
+00004b80: 0a20 2064 6566 2072 616e 646f 6d5f 7361  .  def random_sa
+00004b90: 6d70 6c65 2873 656c 662c 2073 697a 653d  mple(self, size=
+00004ba0: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
+00004bb0: 0a20 2020 2072 203d 2073 656c 662e 7261  .    r = self.ra
+00004bc0: 6e64 6f6d 2873 697a 653d 7369 7a65 2c20  ndom(size=size, 
+00004bd0: 6b65 793d 6b65 7929 0a20 2020 2072 6574  key=key).    ret
+00004be0: 7572 6e20 5f72 6574 7572 6e28 7229 0a0a  urn _return(r)..
+00004bf0: 2020 6465 6620 7261 6e66 2873 656c 662c    def ranf(self,
+00004c00: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
+00004c10: 4e6f 6e65 293a 0a20 2020 2072 203d 2073  None):.    r = s
+00004c20: 656c 662e 7261 6e64 6f6d 2873 697a 653d  elf.random(size=
+00004c30: 7369 7a65 2c20 6b65 793d 6b65 7929 0a20  size, key=key). 
+00004c40: 2020 2072 6574 7572 6e20 5f72 6574 7572     return _retur
+00004c50: 6e28 7229 0a0a 2020 6465 6620 7361 6d70  n(r)..  def samp
+00004c60: 6c65 2873 656c 662c 2073 697a 653d 4e6f  le(self, size=No
+00004c70: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
+00004c80: 2020 2072 203d 2073 656c 662e 7261 6e64     r = self.rand
+00004c90: 6f6d 2873 697a 653d 7369 7a65 2c20 6b65  om(size=size, ke
+00004ca0: 793d 6b65 7929 0a20 2020 2072 6574 7572  y=key).    retur
+00004cb0: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
+00004cc0: 6465 6620 6368 6f69 6365 2873 656c 662c  def choice(self,
+00004cd0: 2061 2c20 7369 7a65 3d4e 6f6e 652c 2072   a, size=None, r
+00004ce0: 6570 6c61 6365 3d54 7275 652c 2070 3d4e  eplace=True, p=N
+00004cf0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+00004d00: 2020 2020 6120 3d20 5f61 735f 6a61 785f      a = _as_jax_
+00004d10: 6172 7261 7928 6129 0a20 2020 2070 203d  array(a).    p =
+00004d20: 205f 6173 5f6a 6178 5f61 7272 6179 2870   _as_jax_array(p
+00004d30: 290a 2020 2020 6120 3d20 5f63 6865 636b  ).    a = _check
+00004d40: 5f70 795f 7365 7128 6129 0a20 2020 2070  _py_seq(a).    p
+00004d50: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+00004d60: 2870 290a 2020 2020 6b65 7920 3d20 7365  (p).    key = se
+00004d70: 6c66 2e73 706c 6974 5f6b 6579 2829 2069  lf.split_key() i
+00004d80: 6620 6b65 7920 6973 204e 6f6e 6520 656c  f key is None el
+00004d90: 7365 205f 666f 726d 616c 697a 655f 6b65  se _formalize_ke
+00004da0: 7928 6b65 7929 0a20 2020 2072 203d 206a  y(key).    r = j
+00004db0: 722e 6368 6f69 6365 286b 6579 2c20 613d  r.choice(key, a=
+00004dc0: 612c 2073 6861 7065 3d5f 7369 7a65 3273  a, shape=_size2s
+00004dd0: 6861 7065 2873 697a 6529 2c20 7265 706c  hape(size), repl
+00004de0: 6163 653d 7265 706c 6163 652c 2070 3d70  ace=replace, p=p
+00004df0: 290a 2020 2020 7265 7475 726e 205f 7265  ).    return _re
+00004e00: 7475 726e 2872 290a 0a20 2064 6566 2070  turn(r)..  def p
+00004e10: 6572 6d75 7461 7469 6f6e 2873 656c 662c  ermutation(self,
+00004e20: 2078 2c20 6178 6973 3a20 696e 7420 3d20   x, axis: int = 
+00004e30: 302c 2069 6e64 6570 656e 6465 6e74 3a20  0, independent: 
+00004e40: 626f 6f6c 203d 2046 616c 7365 2c20 6b65  bool = False, ke
+00004e50: 793d 4e6f 6e65 293a 0a20 2020 2078 203d  y=None):.    x =
+00004e60: 2078 2e76 616c 7565 2069 6620 6973 696e   x.value if isin
+00004e70: 7374 616e 6365 2878 2c20 4172 7261 7929  stance(x, Array)
+00004e80: 2065 6c73 6520 780a 2020 2020 7820 3d20   else x.    x = 
+00004e90: 5f63 6865 636b 5f70 795f 7365 7128 7829  _check_py_seq(x)
+00004ea0: 0a20 2020 206b 6579 203d 2073 656c 662e  .    key = self.
+00004eb0: 7370 6c69 745f 6b65 7928 2920 6966 206b  split_key() if k
+00004ec0: 6579 2069 7320 4e6f 6e65 2065 6c73 6520  ey is None else 
+00004ed0: 5f66 6f72 6d61 6c69 7a65 5f6b 6579 286b  _formalize_key(k
+00004ee0: 6579 290a 2020 2020 7220 3d20 6a72 2e70  ey).    r = jr.p
+00004ef0: 6572 6d75 7461 7469 6f6e 286b 6579 2c20  ermutation(key, 
+00004f00: 782c 2061 7869 733d 6178 6973 2c20 696e  x, axis=axis, in
+00004f10: 6465 7065 6e64 656e 743d 696e 6465 7065  dependent=indepe
+00004f20: 6e64 656e 7429 0a20 2020 2072 6574 7572  ndent).    retur
+00004f30: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
+00004f40: 6465 6620 7368 7566 666c 6528 7365 6c66  def shuffle(self
+00004f50: 2c20 782c 2061 7869 733d 302c 206b 6579  , x, axis=0, key
+00004f60: 3d4e 6f6e 6529 3a0a 2020 2020 6966 206e  =None):.    if n
+00004f70: 6f74 2069 7369 6e73 7461 6e63 6528 782c  ot isinstance(x,
+00004f80: 2041 7272 6179 293a 0a20 2020 2020 2072   Array):.      r
+00004f90: 6169 7365 2054 7970 6545 7272 6f72 2827  aise TypeError('
+00004fa0: 5468 6973 206e 756d 7079 206f 7065 7261  This numpy opera
+00004fb0: 746f 7220 6e65 6564 7320 696e 2d70 6c61  tor needs in-pla
+00004fc0: 6365 2075 7064 6174 696e 672c 2074 6865  ce updating, the
+00004fd0: 7265 666f 7265 2027 0a20 2020 2020 2020  refore '.       
+00004fe0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
+00004ff0: 696e 7075 7473 2073 686f 756c 6420 6265  inputs should be
+00005000: 2062 7261 696e 7079 2041 7272 6179 2e27   brainpy Array.'
+00005010: 290a 2020 2020 6b65 7920 3d20 7365 6c66  ).    key = self
+00005020: 2e73 706c 6974 5f6b 6579 2829 2069 6620  .split_key() if 
+00005030: 6b65 7920 6973 204e 6f6e 6520 656c 7365  key is None else
+00005040: 205f 666f 726d 616c 697a 655f 6b65 7928   _formalize_key(
+00005050: 6b65 7929 0a20 2020 2078 2e76 616c 7565  key).    x.value
+00005060: 203d 206a 722e 7065 726d 7574 6174 696f   = jr.permutatio
+00005070: 6e28 6b65 792c 2078 2e76 616c 7565 2c20  n(key, x.value, 
+00005080: 6178 6973 3d61 7869 7329 0a0a 2020 6465  axis=axis)..  de
+00005090: 6620 6265 7461 2873 656c 662c 2061 2c20  f beta(self, a, 
+000050a0: 622c 2073 697a 653d 4e6f 6e65 2c20 6b65  b, size=None, ke
+000050b0: 793d 4e6f 6e65 293a 0a20 2020 2061 203d  y=None):.    a =
+000050c0: 2061 2e76 616c 7565 2069 6620 6973 696e   a.value if isin
+000050d0: 7374 616e 6365 2861 2c20 4172 7261 7929  stance(a, Array)
+000050e0: 2065 6c73 6520 610a 2020 2020 6220 3d20   else a.    b = 
+000050f0: 622e 7661 6c75 6520 6966 2069 7369 6e73  b.value if isins
+00005100: 7461 6e63 6528 622c 2041 7272 6179 2920  tance(b, Array) 
+00005110: 656c 7365 2062 0a20 2020 2061 203d 205f  else b.    a = _
+00005120: 6368 6563 6b5f 7079 5f73 6571 2861 290a  check_py_seq(a).
+00005130: 2020 2020 6220 3d20 5f63 6865 636b 5f70      b = _check_p
+00005140: 795f 7365 7128 6229 0a20 2020 2069 6620  y_seq(b).    if 
+00005150: 7369 7a65 2069 7320 4e6f 6e65 3a0a 2020  size is None:.  
+00005160: 2020 2020 7369 7a65 203d 206c 6178 2e62      size = lax.b
+00005170: 726f 6164 6361 7374 5f73 6861 7065 7328  roadcast_shapes(
+00005180: 6a6e 702e 7368 6170 6528 6129 2c20 6a6e  jnp.shape(a), jn
+00005190: 702e 7368 6170 6528 6229 290a 2020 2020  p.shape(b)).    
+000051a0: 6b65 7920 3d20 7365 6c66 2e73 706c 6974  key = self.split
+000051b0: 5f6b 6579 2829 2069 6620 6b65 7920 6973  _key() if key is
+000051c0: 204e 6f6e 6520 656c 7365 205f 666f 726d   None else _form
+000051d0: 616c 697a 655f 6b65 7928 6b65 7929 0a20  alize_key(key). 
+000051e0: 2020 2072 203d 206a 722e 6265 7461 286b     r = jr.beta(k
+000051f0: 6579 2c20 613d 612c 2062 3d62 2c20 7368  ey, a=a, b=b, sh
+00005200: 6170 653d 5f73 697a 6532 7368 6170 6528  ape=_size2shape(
+00005210: 7369 7a65 2929 0a20 2020 2072 6574 7572  size)).    retur
+00005220: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
+00005230: 6465 6620 6578 706f 6e65 6e74 6961 6c28  def exponential(
+00005240: 7365 6c66 2c20 7363 616c 653d 4e6f 6e65  self, scale=None
+00005250: 2c20 7369 7a65 3d4e 6f6e 652c 206b 6579  , size=None, key
+00005260: 3d4e 6f6e 6529 3a0a 2020 2020 7363 616c  =None):.    scal
+00005270: 6520 3d20 5f61 735f 6a61 785f 6172 7261  e = _as_jax_arra
+00005280: 7928 7363 616c 6529 0a20 2020 2073 6361  y(scale).    sca
+00005290: 6c65 203d 205f 6368 6563 6b5f 7079 5f73  le = _check_py_s
+000052a0: 6571 2873 6361 6c65 290a 2020 2020 6966  eq(scale).    if
+000052b0: 2073 697a 6520 6973 204e 6f6e 653a 0a20   size is None:. 
+000052c0: 2020 2020 2073 697a 6520 3d20 6a6e 702e       size = jnp.
+000052d0: 7368 6170 6528 7363 616c 6529 0a20 2020  shape(scale).   
+000052e0: 206b 6579 203d 2073 656c 662e 7370 6c69   key = self.spli
+000052f0: 745f 6b65 7928 2920 6966 206b 6579 2069  t_key() if key i
+00005300: 7320 4e6f 6e65 2065 6c73 6520 5f66 6f72  s None else _for
+00005310: 6d61 6c69 7a65 5f6b 6579 286b 6579 290a  malize_key(key).
+00005320: 2020 2020 7220 3d20 6a72 2e65 7870 6f6e      r = jr.expon
+00005330: 656e 7469 616c 286b 6579 2c20 7368 6170  ential(key, shap
+00005340: 653d 5f73 697a 6532 7368 6170 6528 7369  e=_size2shape(si
+00005350: 7a65 2929 0a20 2020 2069 6620 7363 616c  ze)).    if scal
+00005360: 6520 6973 206e 6f74 204e 6f6e 653a 0a20  e is not None:. 
+00005370: 2020 2020 2072 203d 2072 202f 2073 6361       r = r / sca
+00005380: 6c65 0a20 2020 2072 6574 7572 6e20 5f72  le.    return _r
+00005390: 6574 7572 6e28 7229 0a0a 2020 6465 6620  eturn(r)..  def 
+000053a0: 6761 6d6d 6128 7365 6c66 2c20 7368 6170  gamma(self, shap
+000053b0: 652c 2073 6361 6c65 3d4e 6f6e 652c 2073  e, scale=None, s
+000053c0: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+000053d0: 6e65 293a 0a20 2020 2073 6861 7065 203d  ne):.    shape =
+000053e0: 205f 6173 5f6a 6178 5f61 7272 6179 2873   _as_jax_array(s
+000053f0: 6861 7065 290a 2020 2020 7363 616c 6520  hape).    scale 
+00005400: 3d20 5f61 735f 6a61 785f 6172 7261 7928  = _as_jax_array(
+00005410: 7363 616c 6529 0a20 2020 2073 6861 7065  scale).    shape
+00005420: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+00005430: 2873 6861 7065 290a 2020 2020 7363 616c  (shape).    scal
+00005440: 6520 3d20 5f63 6865 636b 5f70 795f 7365  e = _check_py_se
+00005450: 7128 7363 616c 6529 0a20 2020 2069 6620  q(scale).    if 
+00005460: 7369 7a65 2069 7320 4e6f 6e65 3a0a 2020  size is None:.  
+00005470: 2020 2020 7369 7a65 203d 206c 6178 2e62      size = lax.b
+00005480: 726f 6164 6361 7374 5f73 6861 7065 7328  roadcast_shapes(
+00005490: 6a6e 702e 7368 6170 6528 7368 6170 6529  jnp.shape(shape)
+000054a0: 2c20 6a6e 702e 7368 6170 6528 7363 616c  , jnp.shape(scal
+000054b0: 6529 290a 2020 2020 6b65 7920 3d20 7365  e)).    key = se
+000054c0: 6c66 2e73 706c 6974 5f6b 6579 2829 2069  lf.split_key() i
+000054d0: 6620 6b65 7920 6973 204e 6f6e 6520 656c  f key is None el
+000054e0: 7365 205f 666f 726d 616c 697a 655f 6b65  se _formalize_ke
+000054f0: 7928 6b65 7929 0a20 2020 2072 203d 206a  y(key).    r = j
+00005500: 722e 6761 6d6d 6128 6b65 792c 2061 3d73  r.gamma(key, a=s
+00005510: 6861 7065 2c20 7368 6170 653d 5f73 697a  hape, shape=_siz
+00005520: 6532 7368 6170 6528 7369 7a65 2929 0a20  e2shape(size)). 
+00005530: 2020 2069 6620 7363 616c 6520 6973 206e     if scale is n
+00005540: 6f74 204e 6f6e 653a 0a20 2020 2020 2072  ot None:.      r
+00005550: 203d 2072 202a 2073 6361 6c65 0a20 2020   = r * scale.   
+00005560: 2072 6574 7572 6e20 5f72 6574 7572 6e28   return _return(
+00005570: 7229 0a0a 2020 6465 6620 6775 6d62 656c  r)..  def gumbel
+00005580: 2873 656c 662c 206c 6f63 3d4e 6f6e 652c  (self, loc=None,
+00005590: 2073 6361 6c65 3d4e 6f6e 652c 2073 697a   scale=None, siz
+000055a0: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
+000055b0: 293a 0a20 2020 206c 6f63 203d 205f 6173  ):.    loc = _as
+000055c0: 5f6a 6178 5f61 7272 6179 286c 6f63 290a  _jax_array(loc).
+000055d0: 2020 2020 7363 616c 6520 3d20 5f61 735f      scale = _as_
+000055e0: 6a61 785f 6172 7261 7928 7363 616c 6529  jax_array(scale)
+000055f0: 0a20 2020 206c 6f63 203d 205f 6368 6563  .    loc = _chec
+00005600: 6b5f 7079 5f73 6571 286c 6f63 290a 2020  k_py_seq(loc).  
+00005610: 2020 7363 616c 6520 3d20 5f63 6865 636b    scale = _check
+00005620: 5f70 795f 7365 7128 7363 616c 6529 0a20  _py_seq(scale). 
+00005630: 2020 2069 6620 7369 7a65 2069 7320 4e6f     if size is No
+00005640: 6e65 3a0a 2020 2020 2020 7369 7a65 203d  ne:.      size =
+00005650: 206c 6178 2e62 726f 6164 6361 7374 5f73   lax.broadcast_s
+00005660: 6861 7065 7328 6a6e 702e 7368 6170 6528  hapes(jnp.shape(
+00005670: 6c6f 6329 2c20 6a6e 702e 7368 6170 6528  loc), jnp.shape(
+00005680: 7363 616c 6529 290a 2020 2020 6b65 7920  scale)).    key 
+00005690: 3d20 7365 6c66 2e73 706c 6974 5f6b 6579  = self.split_key
+000056a0: 2829 2069 6620 6b65 7920 6973 204e 6f6e  () if key is Non
+000056b0: 6520 656c 7365 205f 666f 726d 616c 697a  e else _formaliz
+000056c0: 655f 6b65 7928 6b65 7929 0a20 2020 2072  e_key(key).    r
+000056d0: 203d 205f 6c6f 635f 7363 616c 6528 6c6f   = _loc_scale(lo
+000056e0: 632c 2073 6361 6c65 2c20 6a72 2e67 756d  c, scale, jr.gum
+000056f0: 6265 6c28 6b65 792c 2073 6861 7065 3d5f  bel(key, shape=_
+00005700: 7369 7a65 3273 6861 7065 2873 697a 6529  size2shape(size)
+00005710: 2929 0a20 2020 2072 6574 7572 6e20 5f72  )).    return _r
+00005720: 6574 7572 6e28 7229 0a0a 2020 6465 6620  eturn(r)..  def 
+00005730: 6c61 706c 6163 6528 7365 6c66 2c20 6c6f  laplace(self, lo
+00005740: 633d 4e6f 6e65 2c20 7363 616c 653d 4e6f  c=None, scale=No
+00005750: 6e65 2c20 7369 7a65 3d4e 6f6e 652c 206b  ne, size=None, k
+00005760: 6579 3d4e 6f6e 6529 3a0a 2020 2020 6c6f  ey=None):.    lo
+00005770: 6320 3d20 5f61 735f 6a61 785f 6172 7261  c = _as_jax_arra
+00005780: 7928 6c6f 6329 0a20 2020 2073 6361 6c65  y(loc).    scale
+00005790: 203d 205f 6173 5f6a 6178 5f61 7272 6179   = _as_jax_array
+000057a0: 2873 6361 6c65 290a 2020 2020 6c6f 6320  (scale).    loc 
+000057b0: 3d20 5f63 6865 636b 5f70 795f 7365 7128  = _check_py_seq(
+000057c0: 6c6f 6329 0a20 2020 2073 6361 6c65 203d  loc).    scale =
+000057d0: 205f 6368 6563 6b5f 7079 5f73 6571 2873   _check_py_seq(s
+000057e0: 6361 6c65 290a 2020 2020 6966 2073 697a  cale).    if siz
+000057f0: 6520 6973 204e 6f6e 653a 0a20 2020 2020  e is None:.     
+00005800: 2073 697a 6520 3d20 6c61 782e 6272 6f61   size = lax.broa
+00005810: 6463 6173 745f 7368 6170 6573 286a 6e70  dcast_shapes(jnp
+00005820: 2e73 6861 7065 286c 6f63 292c 206a 6e70  .shape(loc), jnp
+00005830: 2e73 6861 7065 2873 6361 6c65 2929 0a20  .shape(scale)). 
+00005840: 2020 206b 6579 203d 2073 656c 662e 7370     key = self.sp
+00005850: 6c69 745f 6b65 7928 2920 6966 206b 6579  lit_key() if key
+00005860: 2069 7320 4e6f 6e65 2065 6c73 6520 5f66   is None else _f
+00005870: 6f72 6d61 6c69 7a65 5f6b 6579 286b 6579  ormalize_key(key
+00005880: 290a 2020 2020 7220 3d20 5f6c 6f63 5f73  ).    r = _loc_s
+00005890: 6361 6c65 286c 6f63 2c20 7363 616c 652c  cale(loc, scale,
+000058a0: 206a 722e 6c61 706c 6163 6528 6b65 792c   jr.laplace(key,
+000058b0: 2073 6861 7065 3d5f 7369 7a65 3273 6861   shape=_size2sha
+000058c0: 7065 2873 697a 6529 2929 0a20 2020 2072  pe(size))).    r
+000058d0: 6574 7572 6e20 5f72 6574 7572 6e28 7229  eturn _return(r)
+000058e0: 0a0a 2020 6465 6620 6c6f 6769 7374 6963  ..  def logistic
+000058f0: 2873 656c 662c 206c 6f63 3d4e 6f6e 652c  (self, loc=None,
+00005900: 2073 6361 6c65 3d4e 6f6e 652c 2073 697a   scale=None, siz
+00005910: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
+00005920: 293a 0a20 2020 206c 6f63 203d 205f 6173  ):.    loc = _as
+00005930: 5f6a 6178 5f61 7272 6179 286c 6f63 290a  _jax_array(loc).
+00005940: 2020 2020 7363 616c 6520 3d20 5f61 735f      scale = _as_
+00005950: 6a61 785f 6172 7261 7928 7363 616c 6529  jax_array(scale)
+00005960: 0a20 2020 206c 6f63 203d 205f 6368 6563  .    loc = _chec
+00005970: 6b5f 7079 5f73 6571 286c 6f63 290a 2020  k_py_seq(loc).  
+00005980: 2020 7363 616c 6520 3d20 5f63 6865 636b    scale = _check
+00005990: 5f70 795f 7365 7128 7363 616c 6529 0a20  _py_seq(scale). 
+000059a0: 2020 2069 6620 7369 7a65 2069 7320 4e6f     if size is No
+000059b0: 6e65 3a0a 2020 2020 2020 7369 7a65 203d  ne:.      size =
+000059c0: 206c 6178 2e62 726f 6164 6361 7374 5f73   lax.broadcast_s
+000059d0: 6861 7065 7328 6a6e 702e 7368 6170 6528  hapes(jnp.shape(
+000059e0: 6c6f 6329 2c20 6a6e 702e 7368 6170 6528  loc), jnp.shape(
+000059f0: 7363 616c 6529 290a 2020 2020 6b65 7920  scale)).    key 
+00005a00: 3d20 7365 6c66 2e73 706c 6974 5f6b 6579  = self.split_key
+00005a10: 2829 2069 6620 6b65 7920 6973 204e 6f6e  () if key is Non
+00005a20: 6520 656c 7365 205f 666f 726d 616c 697a  e else _formaliz
+00005a30: 655f 6b65 7928 6b65 7929 0a20 2020 2072  e_key(key).    r
+00005a40: 203d 205f 6c6f 635f 7363 616c 6528 6c6f   = _loc_scale(lo
+00005a50: 632c 2073 6361 6c65 2c20 6a72 2e6c 6f67  c, scale, jr.log
+00005a60: 6973 7469 6328 6b65 792c 2073 6861 7065  istic(key, shape
+00005a70: 3d5f 7369 7a65 3273 6861 7065 2873 697a  =_size2shape(siz
+00005a80: 6529 2929 0a20 2020 2072 6574 7572 6e20  e))).    return 
+00005a90: 5f72 6574 7572 6e28 7229 0a0a 2020 6465  _return(r)..  de
+00005aa0: 6620 6e6f 726d 616c 2873 656c 662c 206c  f normal(self, l
+00005ab0: 6f63 3d4e 6f6e 652c 2073 6361 6c65 3d4e  oc=None, scale=N
+00005ac0: 6f6e 652c 2073 697a 653d 4e6f 6e65 2c20  one, size=None, 
+00005ad0: 6b65 793d 4e6f 6e65 293a 0a20 2020 206c  key=None):.    l
+00005ae0: 6f63 203d 205f 6173 5f6a 6178 5f61 7272  oc = _as_jax_arr
+00005af0: 6179 286c 6f63 290a 2020 2020 7363 616c  ay(loc).    scal
+00005b00: 6520 3d20 5f61 735f 6a61 785f 6172 7261  e = _as_jax_arra
+00005b10: 7928 7363 616c 6529 0a20 2020 206c 6f63  y(scale).    loc
+00005b20: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+00005b30: 286c 6f63 290a 2020 2020 7363 616c 6520  (loc).    scale 
+00005b40: 3d20 5f63 6865 636b 5f70 795f 7365 7128  = _check_py_seq(
+00005b50: 7363 616c 6529 0a20 2020 2069 6620 7369  scale).    if si
+00005b60: 7a65 2069 7320 4e6f 6e65 3a0a 2020 2020  ze is None:.    
+00005b70: 2020 7369 7a65 203d 206c 6178 2e62 726f    size = lax.bro
+00005b80: 6164 6361 7374 5f73 6861 7065 7328 6a6e  adcast_shapes(jn
+00005b90: 702e 7368 6170 6528 7363 616c 6529 2c20  p.shape(scale), 
+00005ba0: 6a6e 702e 7368 6170 6528 6c6f 6329 290a  jnp.shape(loc)).
+00005bb0: 2020 2020 6b65 7920 3d20 7365 6c66 2e73      key = self.s
+00005bc0: 706c 6974 5f6b 6579 2829 2069 6620 6b65  plit_key() if ke
+00005bd0: 7920 6973 204e 6f6e 6520 656c 7365 205f  y is None else _
+00005be0: 666f 726d 616c 697a 655f 6b65 7928 6b65  formalize_key(ke
+00005bf0: 7929 0a20 2020 2072 203d 205f 6c6f 635f  y).    r = _loc_
+00005c00: 7363 616c 6528 6c6f 632c 2073 6361 6c65  scale(loc, scale
+00005c10: 2c20 6a72 2e6e 6f72 6d61 6c28 6b65 792c  , jr.normal(key,
+00005c20: 2073 6861 7065 3d5f 7369 7a65 3273 6861   shape=_size2sha
+00005c30: 7065 2873 697a 6529 2929 0a20 2020 2072  pe(size))).    r
+00005c40: 6574 7572 6e20 5f72 6574 7572 6e28 7229  eturn _return(r)
+00005c50: 0a0a 2020 6465 6620 7061 7265 746f 2873  ..  def pareto(s
+00005c60: 656c 662c 2061 2c20 7369 7a65 3d4e 6f6e  elf, a, size=Non
+00005c70: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
+00005c80: 2020 6120 3d20 5f61 735f 6a61 785f 6172    a = _as_jax_ar
+00005c90: 7261 7928 6129 0a20 2020 2061 203d 205f  ray(a).    a = _
+00005ca0: 6368 6563 6b5f 7079 5f73 6571 2861 290a  check_py_seq(a).
+00005cb0: 2020 2020 6966 2073 697a 6520 6973 204e      if size is N
+00005cc0: 6f6e 653a 0a20 2020 2020 2073 697a 6520  one:.      size 
+00005cd0: 3d20 6a6e 702e 7368 6170 6528 6129 0a20  = jnp.shape(a). 
+00005ce0: 2020 206b 6579 203d 2073 656c 662e 7370     key = self.sp
+00005cf0: 6c69 745f 6b65 7928 2920 6966 206b 6579  lit_key() if key
+00005d00: 2069 7320 4e6f 6e65 2065 6c73 6520 5f66   is None else _f
+00005d10: 6f72 6d61 6c69 7a65 5f6b 6579 286b 6579  ormalize_key(key
+00005d20: 290a 2020 2020 7220 3d20 6a72 2e70 6172  ).    r = jr.par
+00005d30: 6574 6f28 6b65 792c 2062 3d61 2c20 7368  eto(key, b=a, sh
+00005d40: 6170 653d 5f73 697a 6532 7368 6170 6528  ape=_size2shape(
+00005d50: 7369 7a65 2929 0a20 2020 2072 6574 7572  size)).    retur
+00005d60: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
+00005d70: 6465 6620 706f 6973 736f 6e28 7365 6c66  def poisson(self
+00005d80: 2c20 6c61 6d3d 312e 302c 2073 697a 653d  , lam=1.0, size=
+00005d90: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
+00005da0: 0a20 2020 206c 616d 203d 205f 6368 6563  .    lam = _chec
+00005db0: 6b5f 7079 5f73 6571 285f 6173 5f6a 6178  k_py_seq(_as_jax
+00005dc0: 5f61 7272 6179 286c 616d 2929 0a20 2020  _array(lam)).   
+00005dd0: 2069 6620 7369 7a65 2069 7320 4e6f 6e65   if size is None
+00005de0: 3a0a 2020 2020 2020 7369 7a65 203d 206a  :.      size = j
+00005df0: 6e70 2e73 6861 7065 286c 616d 290a 2020  np.shape(lam).  
+00005e00: 2020 6b65 7920 3d20 7365 6c66 2e73 706c    key = self.spl
+00005e10: 6974 5f6b 6579 2829 2069 6620 6b65 7920  it_key() if key 
+00005e20: 6973 204e 6f6e 6520 656c 7365 205f 666f  is None else _fo
+00005e30: 726d 616c 697a 655f 6b65 7928 6b65 7929  rmalize_key(key)
+00005e40: 0a20 2020 2072 203d 206a 722e 706f 6973  .    r = jr.pois
+00005e50: 736f 6e28 6b65 792c 206c 616d 3d6c 616d  son(key, lam=lam
+00005e60: 2c20 7368 6170 653d 5f73 697a 6532 7368  , shape=_size2sh
+00005e70: 6170 6528 7369 7a65 2929 0a20 2020 2072  ape(size)).    r
+00005e80: 6574 7572 6e20 5f72 6574 7572 6e28 7229  eturn _return(r)
+00005e90: 0a0a 2020 6465 6620 7374 616e 6461 7264  ..  def standard
+00005ea0: 5f63 6175 6368 7928 7365 6c66 2c20 7369  _cauchy(self, si
+00005eb0: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
+00005ec0: 6529 3a0a 2020 2020 6b65 7920 3d20 7365  e):.    key = se
+00005ed0: 6c66 2e73 706c 6974 5f6b 6579 2829 2069  lf.split_key() i
+00005ee0: 6620 6b65 7920 6973 204e 6f6e 6520 656c  f key is None el
+00005ef0: 7365 205f 666f 726d 616c 697a 655f 6b65  se _formalize_ke
+00005f00: 7928 6b65 7929 0a20 2020 2072 203d 206a  y(key).    r = j
+00005f10: 722e 6361 7563 6879 286b 6579 2c20 7368  r.cauchy(key, sh
+00005f20: 6170 653d 5f73 697a 6532 7368 6170 6528  ape=_size2shape(
+00005f30: 7369 7a65 2929 0a20 2020 2072 6574 7572  size)).    retur
+00005f40: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
+00005f50: 6465 6620 7374 616e 6461 7264 5f65 7870  def standard_exp
+00005f60: 6f6e 656e 7469 616c 2873 656c 662c 2073  onential(self, s
+00005f70: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+00005f80: 6e65 293a 0a20 2020 206b 6579 203d 2073  ne):.    key = s
+00005f90: 656c 662e 7370 6c69 745f 6b65 7928 2920  elf.split_key() 
+00005fa0: 6966 206b 6579 2069 7320 4e6f 6e65 2065  if key is None e
+00005fb0: 6c73 6520 5f66 6f72 6d61 6c69 7a65 5f6b  lse _formalize_k
+00005fc0: 6579 286b 6579 290a 2020 2020 7220 3d20  ey(key).    r = 
+00005fd0: 6a72 2e65 7870 6f6e 656e 7469 616c 286b  jr.exponential(k
+00005fe0: 6579 2c20 7368 6170 653d 5f73 697a 6532  ey, shape=_size2
+00005ff0: 7368 6170 6528 7369 7a65 2929 0a20 2020  shape(size)).   
+00006000: 2072 6574 7572 6e20 5f72 6574 7572 6e28   return _return(
+00006010: 7229 0a0a 2020 6465 6620 7374 616e 6461  r)..  def standa
+00006020: 7264 5f67 616d 6d61 2873 656c 662c 2073  rd_gamma(self, s
+00006030: 6861 7065 2c20 7369 7a65 3d4e 6f6e 652c  hape, size=None,
+00006040: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2020   key=None):.    
+00006050: 7368 6170 6520 3d20 5f61 735f 6a61 785f  shape = _as_jax_
+00006060: 6172 7261 7928 7368 6170 6529 0a20 2020  array(shape).   
+00006070: 2073 6861 7065 203d 205f 6368 6563 6b5f   shape = _check_
+00006080: 7079 5f73 6571 2873 6861 7065 290a 2020  py_seq(shape).  
+00006090: 2020 6966 2073 697a 6520 6973 204e 6f6e    if size is Non
+000060a0: 653a 0a20 2020 2020 2073 697a 6520 3d20  e:.      size = 
+000060b0: 6a6e 702e 7368 6170 6528 7368 6170 6529  jnp.shape(shape)
+000060c0: 0a20 2020 206b 6579 203d 2073 656c 662e  .    key = self.
+000060d0: 7370 6c69 745f 6b65 7928 2920 6966 206b  split_key() if k
+000060e0: 6579 2069 7320 4e6f 6e65 2065 6c73 6520  ey is None else 
+000060f0: 5f66 6f72 6d61 6c69 7a65 5f6b 6579 286b  _formalize_key(k
+00006100: 6579 290a 2020 2020 7220 3d20 6a72 2e67  ey).    r = jr.g
+00006110: 616d 6d61 286b 6579 2c20 613d 7368 6170  amma(key, a=shap
+00006120: 652c 2073 6861 7065 3d5f 7369 7a65 3273  e, shape=_size2s
+00006130: 6861 7065 2873 697a 6529 290a 2020 2020  hape(size)).    
+00006140: 7265 7475 726e 205f 7265 7475 726e 2872  return _return(r
+00006150: 290a 0a20 2064 6566 2073 7461 6e64 6172  )..  def standar
+00006160: 645f 6e6f 726d 616c 2873 656c 662c 2073  d_normal(self, s
+00006170: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+00006180: 6e65 293a 0a20 2020 206b 6579 203d 2073  ne):.    key = s
+00006190: 656c 662e 7370 6c69 745f 6b65 7928 2920  elf.split_key() 
+000061a0: 6966 206b 6579 2069 7320 4e6f 6e65 2065  if key is None e
+000061b0: 6c73 6520 5f66 6f72 6d61 6c69 7a65 5f6b  lse _formalize_k
+000061c0: 6579 286b 6579 290a 2020 2020 7220 3d20  ey(key).    r = 
+000061d0: 6a72 2e6e 6f72 6d61 6c28 6b65 792c 2073  jr.normal(key, s
+000061e0: 6861 7065 3d5f 7369 7a65 3273 6861 7065  hape=_size2shape
+000061f0: 2873 697a 6529 290a 2020 2020 7265 7475  (size)).    retu
+00006200: 726e 205f 7265 7475 726e 2872 290a 0a20  rn _return(r).. 
+00006210: 2064 6566 2073 7461 6e64 6172 645f 7428   def standard_t(
+00006220: 7365 6c66 2c20 6466 2c20 7369 7a65 3d4e  self, df, size=N
+00006230: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+00006240: 2020 2020 6466 203d 205f 6173 5f6a 6178      df = _as_jax
+00006250: 5f61 7272 6179 2864 6629 0a20 2020 2064  _array(df).    d
+00006260: 6620 3d20 5f63 6865 636b 5f70 795f 7365  f = _check_py_se
+00006270: 7128 6466 290a 2020 2020 6966 2073 697a  q(df).    if siz
+00006280: 6520 6973 204e 6f6e 653a 0a20 2020 2020  e is None:.     
+00006290: 2073 697a 6520 3d20 6a6e 702e 7368 6170   size = jnp.shap
+000062a0: 6528 7369 7a65 290a 2020 2020 6b65 7920  e(size).    key 
+000062b0: 3d20 7365 6c66 2e73 706c 6974 5f6b 6579  = self.split_key
+000062c0: 2829 2069 6620 6b65 7920 6973 204e 6f6e  () if key is Non
+000062d0: 6520 656c 7365 205f 666f 726d 616c 697a  e else _formaliz
+000062e0: 655f 6b65 7928 6b65 7929 0a20 2020 2072  e_key(key).    r
+000062f0: 203d 206a 722e 7428 6b65 792c 2064 663d   = jr.t(key, df=
+00006300: 6466 2c20 7368 6170 653d 5f73 697a 6532  df, shape=_size2
+00006310: 7368 6170 6528 7369 7a65 2929 0a20 2020  shape(size)).   
+00006320: 2072 6574 7572 6e20 5f72 6574 7572 6e28   return _return(
+00006330: 7229 0a0a 2020 6465 6620 756e 6966 6f72  r)..  def unifor
+00006340: 6d28 7365 6c66 2c20 6c6f 773d 302e 302c  m(self, low=0.0,
+00006350: 2068 6967 683d 312e 302c 2073 697a 653d   high=1.0, size=
+00006360: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
+00006370: 0a20 2020 206c 6f77 203d 205f 6173 5f6a  .    low = _as_j
+00006380: 6178 5f61 7272 6179 286c 6f77 290a 2020  ax_array(low).  
+00006390: 2020 6869 6768 203d 205f 6173 5f6a 6178    high = _as_jax
+000063a0: 5f61 7272 6179 2868 6967 6829 0a20 2020  _array(high).   
+000063b0: 206c 6f77 203d 205f 6368 6563 6b5f 7079   low = _check_py
+000063c0: 5f73 6571 286c 6f77 290a 2020 2020 6869  _seq(low).    hi
+000063d0: 6768 203d 205f 6368 6563 6b5f 7079 5f73  gh = _check_py_s
+000063e0: 6571 2868 6967 6829 0a20 2020 2069 6620  eq(high).    if 
+000063f0: 7369 7a65 2069 7320 4e6f 6e65 3a0a 2020  size is None:.  
+00006400: 2020 2020 7369 7a65 203d 206c 6178 2e62      size = lax.b
+00006410: 726f 6164 6361 7374 5f73 6861 7065 7328  roadcast_shapes(
+00006420: 6a6e 702e 7368 6170 6528 6c6f 7729 2c20  jnp.shape(low), 
+00006430: 6a6e 702e 7368 6170 6528 6869 6768 2929  jnp.shape(high))
+00006440: 0a20 2020 206b 6579 203d 2073 656c 662e  .    key = self.
+00006450: 7370 6c69 745f 6b65 7928 2920 6966 206b  split_key() if k
+00006460: 6579 2069 7320 4e6f 6e65 2065 6c73 6520  ey is None else 
+00006470: 5f66 6f72 6d61 6c69 7a65 5f6b 6579 286b  _formalize_key(k
+00006480: 6579 290a 2020 2020 7220 3d20 6a72 2e75  ey).    r = jr.u
+00006490: 6e69 666f 726d 286b 6579 2c20 7368 6170  niform(key, shap
+000064a0: 653d 5f73 697a 6532 7368 6170 6528 7369  e=_size2shape(si
+000064b0: 7a65 292c 206d 696e 7661 6c3d 6c6f 772c  ze), minval=low,
+000064c0: 206d 6178 7661 6c3d 6869 6768 290a 2020   maxval=high).  
+000064d0: 2020 7265 7475 726e 205f 7265 7475 726e    return _return
+000064e0: 2872 290a 0a20 2064 6566 2074 7275 6e63  (r)..  def trunc
+000064f0: 6174 6564 5f6e 6f72 6d61 6c28 7365 6c66  ated_normal(self
+00006500: 2c20 6c6f 7765 722c 2075 7070 6572 2c20  , lower, upper, 
+00006510: 7369 7a65 3d4e 6f6e 652c 2073 6361 6c65  size=None, scale
+00006520: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
+00006530: 3a0a 2020 2020 6c6f 7765 7220 3d20 5f61  :.    lower = _a
+00006540: 735f 6a61 785f 6172 7261 7928 6c6f 7765  s_jax_array(lowe
+00006550: 7229 0a20 2020 206c 6f77 6572 203d 205f  r).    lower = _
+00006560: 6368 6563 6b5f 7079 5f73 6571 286c 6f77  check_py_seq(low
+00006570: 6572 290a 2020 2020 7570 7065 7220 3d20  er).    upper = 
+00006580: 5f61 735f 6a61 785f 6172 7261 7928 7570  _as_jax_array(up
+00006590: 7065 7229 0a20 2020 2075 7070 6572 203d  per).    upper =
+000065a0: 205f 6368 6563 6b5f 7079 5f73 6571 2875   _check_py_seq(u
+000065b0: 7070 6572 290a 2020 2020 7363 616c 6520  pper).    scale 
+000065c0: 3d20 5f61 735f 6a61 785f 6172 7261 7928  = _as_jax_array(
+000065d0: 7363 616c 6529 0a20 2020 2073 6361 6c65  scale).    scale
+000065e0: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+000065f0: 2873 6361 6c65 290a 2020 2020 6966 2073  (scale).    if s
+00006600: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
+00006610: 2020 2073 697a 6520 3d20 6c61 782e 6272     size = lax.br
+00006620: 6f61 6463 6173 745f 7368 6170 6573 286a  oadcast_shapes(j
+00006630: 6e70 2e73 6861 7065 286c 6f77 6572 292c  np.shape(lower),
+00006640: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 00006650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006660: 2020 2020 2020 2020 2020 2020 6a6e 702e              jnp.
-00006670: 7368 6170 6528 7570 7065 7229 2c0a 2020  shape(upper),.  
+00006660: 2020 206a 6e70 2e73 6861 7065 2875 7070     jnp.shape(upp
+00006670: 6572 292c 0a20 2020 2020 2020 2020 2020  er),.           
 00006680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000066a0: 6a6e 702e 7368 6170 6528 7363 616c 6529  jnp.shape(scale)
-000066b0: 290a 2020 2020 6b65 7920 3d20 7365 6c66  ).    key = self
-000066c0: 2e73 706c 6974 5f6b 6579 2829 2069 6620  .split_key() if 
-000066d0: 6b65 7920 6973 204e 6f6e 6520 656c 7365  key is None else
-000066e0: 205f 666f 726d 616c 697a 655f 6b65 7928   _formalize_key(
-000066f0: 6b65 7929 0a20 2020 2072 616e 6473 203d  key).    rands =
-00006700: 206a 722e 7472 756e 6361 7465 645f 6e6f   jr.truncated_no
-00006710: 726d 616c 286b 6579 2c0a 2020 2020 2020  rmal(key,.      
+00006690: 2020 2020 2020 206a 6e70 2e73 6861 7065         jnp.shape
+000066a0: 2873 6361 6c65 2929 0a20 2020 206b 6579  (scale)).    key
+000066b0: 203d 2073 656c 662e 7370 6c69 745f 6b65   = self.split_ke
+000066c0: 7928 2920 6966 206b 6579 2069 7320 4e6f  y() if key is No
+000066d0: 6e65 2065 6c73 6520 5f66 6f72 6d61 6c69  ne else _formali
+000066e0: 7a65 5f6b 6579 286b 6579 290a 2020 2020  ze_key(key).    
+000066f0: 7261 6e64 7320 3d20 6a72 2e74 7275 6e63  rands = jr.trunc
+00006700: 6174 6564 5f6e 6f72 6d61 6c28 6b65 792c  ated_normal(key,
+00006710: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 00006720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006730: 2020 2020 2020 2020 2020 6c6f 7765 723d            lower=
-00006740: 6c6f 7765 722c 0a20 2020 2020 2020 2020  lower,.         
-00006750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006760: 2020 2020 2020 2075 7070 6572 3d75 7070         upper=upp
-00006770: 6572 2c0a 2020 2020 2020 2020 2020 2020  er,.            
-00006780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006790: 2020 2020 7368 6170 653d 5f73 697a 6532      shape=_size2
-000067a0: 7368 6170 6528 7369 7a65 2929 0a20 2020  shape(size)).   
-000067b0: 2069 6620 7363 616c 6520 6973 206e 6f74   if scale is not
-000067c0: 204e 6f6e 653a 0a20 2020 2020 2072 616e   None:.      ran
-000067d0: 6473 203d 2072 616e 6473 202a 2073 6361  ds = rands * sca
-000067e0: 6c65 0a20 2020 2072 6574 7572 6e20 5f72  le.    return _r
-000067f0: 6574 7572 6e28 7261 6e64 7329 0a0a 2020  eturn(rands)..  
-00006800: 6465 6620 5f63 6865 636b 5f70 2873 656c  def _check_p(sel
-00006810: 662c 2070 293a 0a20 2020 2072 6169 7365  f, p):.    raise
-00006820: 2056 616c 7565 4572 726f 7228 6627 5061   ValueError(f'Pa
-00006830: 7261 6d65 7465 7220 7020 7368 6f75 6c64  rameter p should
-00006840: 2062 6520 7769 7468 696e 205b 302c 2031   be within [0, 1
-00006850: 5d2c 2062 7574 2077 6520 676f 7420 7b70  ], but we got {p
-00006860: 7d27 290a 0a20 2064 6566 2062 6572 6e6f  }')..  def berno
-00006870: 756c 6c69 2873 656c 662c 2070 2c20 7369  ulli(self, p, si
-00006880: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
-00006890: 6529 3a0a 2020 2020 7020 3d20 5f63 6865  e):.    p = _che
-000068a0: 636b 5f70 795f 7365 7128 5f61 735f 6a61  ck_py_seq(_as_ja
-000068b0: 785f 6172 7261 7928 7029 290a 2020 2020  x_array(p)).    
-000068c0: 6a69 745f 6572 726f 725f 6368 6563 6b69  jit_error_checki
-000068d0: 6e67 286a 6e70 2e61 6e79 286a 6e70 2e6c  ng(jnp.any(jnp.l
-000068e0: 6f67 6963 616c 5f61 6e64 2870 203c 2030  ogical_and(p < 0
-000068f0: 2c20 7020 3e20 3129 292c 2073 656c 662e  , p > 1)), self.
-00006900: 5f63 6865 636b 5f70 2c20 7029 0a20 2020  _check_p, p).   
-00006910: 2069 6620 7369 7a65 2069 7320 4e6f 6e65   if size is None
-00006920: 3a0a 2020 2020 2020 7369 7a65 203d 206a  :.      size = j
-00006930: 6e70 2e73 6861 7065 2870 290a 2020 2020  np.shape(p).    
-00006940: 6b65 7920 3d20 7365 6c66 2e73 706c 6974  key = self.split
-00006950: 5f6b 6579 2829 2069 6620 6b65 7920 6973  _key() if key is
-00006960: 204e 6f6e 6520 656c 7365 205f 666f 726d   None else _form
-00006970: 616c 697a 655f 6b65 7928 6b65 7929 0a20  alize_key(key). 
-00006980: 2020 2072 203d 206a 722e 6265 726e 6f75     r = jr.bernou
-00006990: 6c6c 6928 6b65 792c 2070 3d70 2c20 7368  lli(key, p=p, sh
-000069a0: 6170 653d 5f73 697a 6532 7368 6170 6528  ape=_size2shape(
-000069b0: 7369 7a65 2929 0a20 2020 2072 6574 7572  size)).    retur
-000069c0: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
-000069d0: 6465 6620 6c6f 676e 6f72 6d61 6c28 7365  def lognormal(se
-000069e0: 6c66 2c20 6d65 616e 3d4e 6f6e 652c 2073  lf, mean=None, s
-000069f0: 6967 6d61 3d4e 6f6e 652c 2073 697a 653d  igma=None, size=
-00006a00: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
-00006a10: 0a20 2020 206d 6561 6e20 3d20 5f63 6865  .    mean = _che
-00006a20: 636b 5f70 795f 7365 7128 5f61 735f 6a61  ck_py_seq(_as_ja
-00006a30: 785f 6172 7261 7928 6d65 616e 2929 0a20  x_array(mean)). 
-00006a40: 2020 2073 6967 6d61 203d 205f 6368 6563     sigma = _chec
-00006a50: 6b5f 7079 5f73 6571 285f 6173 5f6a 6178  k_py_seq(_as_jax
-00006a60: 5f61 7272 6179 2873 6967 6d61 2929 0a20  _array(sigma)). 
-00006a70: 2020 2069 6620 7369 7a65 2069 7320 4e6f     if size is No
-00006a80: 6e65 3a0a 2020 2020 2020 7369 7a65 203d  ne:.      size =
-00006a90: 206a 6e70 2e62 726f 6164 6361 7374 5f73   jnp.broadcast_s
-00006aa0: 6861 7065 7328 6a6e 702e 7368 6170 6528  hapes(jnp.shape(
-00006ab0: 6d65 616e 292c 0a20 2020 2020 2020 2020  mean),.         
-00006ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006ad0: 2020 2020 2020 2020 206a 6e70 2e73 6861           jnp.sha
-00006ae0: 7065 2873 6967 6d61 2929 0a20 2020 206b  pe(sigma)).    k
-00006af0: 6579 203d 2073 656c 662e 7370 6c69 745f  ey = self.split_
-00006b00: 6b65 7928 2920 6966 206b 6579 2069 7320  key() if key is 
-00006b10: 4e6f 6e65 2065 6c73 6520 5f66 6f72 6d61  None else _forma
-00006b20: 6c69 7a65 5f6b 6579 286b 6579 290a 2020  lize_key(key).  
-00006b30: 2020 7361 6d70 6c65 7320 3d20 6a72 2e6e    samples = jr.n
-00006b40: 6f72 6d61 6c28 6b65 792c 2073 6861 7065  ormal(key, shape
-00006b50: 3d5f 7369 7a65 3273 6861 7065 2873 697a  =_size2shape(siz
-00006b60: 6529 290a 2020 2020 7361 6d70 6c65 7320  e)).    samples 
-00006b70: 3d20 5f6c 6f63 5f73 6361 6c65 286d 6561  = _loc_scale(mea
-00006b80: 6e2c 2073 6967 6d61 2c20 7361 6d70 6c65  n, sigma, sample
-00006b90: 7329 0a20 2020 2073 616d 706c 6573 203d  s).    samples =
-00006ba0: 206a 6e70 2e65 7870 2873 616d 706c 6573   jnp.exp(samples
-00006bb0: 290a 2020 2020 7265 7475 726e 205f 7265  ).    return _re
-00006bc0: 7475 726e 2873 616d 706c 6573 290a 0a20  turn(samples).. 
-00006bd0: 2064 6566 2062 696e 6f6d 6961 6c28 7365   def binomial(se
-00006be0: 6c66 2c20 6e2c 2070 2c20 7369 7a65 3d4e  lf, n, p, size=N
-00006bf0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-00006c00: 2020 2020 6e20 3d20 5f63 6865 636b 5f70      n = _check_p
-00006c10: 795f 7365 7128 6e2e 7661 6c75 6520 6966  y_seq(n.value if
-00006c20: 2069 7369 6e73 7461 6e63 6528 6e2c 2041   isinstance(n, A
-00006c30: 7272 6179 2920 656c 7365 206e 290a 2020  rray) else n).  
-00006c40: 2020 7020 3d20 5f63 6865 636b 5f70 795f    p = _check_py_
-00006c50: 7365 7128 702e 7661 6c75 6520 6966 2069  seq(p.value if i
-00006c60: 7369 6e73 7461 6e63 6528 702c 2041 7272  sinstance(p, Arr
-00006c70: 6179 2920 656c 7365 2070 290a 2020 2020  ay) else p).    
-00006c80: 6a69 745f 6572 726f 725f 6368 6563 6b69  jit_error_checki
-00006c90: 6e67 286a 6e70 2e61 6e79 286a 6e70 2e6c  ng(jnp.any(jnp.l
-00006ca0: 6f67 6963 616c 5f61 6e64 2870 203c 2030  ogical_and(p < 0
-00006cb0: 2c20 7020 3e20 3129 292c 2073 656c 662e  , p > 1)), self.
-00006cc0: 5f63 6865 636b 5f70 2c20 7029 0a20 2020  _check_p, p).   
-00006cd0: 2069 6620 7369 7a65 2069 7320 4e6f 6e65   if size is None
-00006ce0: 3a0a 2020 2020 2020 7369 7a65 203d 206a  :.      size = j
-00006cf0: 6e70 2e62 726f 6164 6361 7374 5f73 6861  np.broadcast_sha
-00006d00: 7065 7328 6a6e 702e 7368 6170 6528 6e29  pes(jnp.shape(n)
-00006d10: 2c20 6a6e 702e 7368 6170 6528 7029 290a  , jnp.shape(p)).
-00006d20: 2020 2020 6b65 7920 3d20 7365 6c66 2e73      key = self.s
-00006d30: 706c 6974 5f6b 6579 2829 2069 6620 6b65  plit_key() if ke
-00006d40: 7920 6973 204e 6f6e 6520 656c 7365 205f  y is None else _
-00006d50: 666f 726d 616c 697a 655f 6b65 7928 6b65  formalize_key(ke
-00006d60: 7929 0a20 2020 2072 203d 205f 6269 6e6f  y).    r = _bino
-00006d70: 6d69 616c 286b 6579 2c20 702c 206e 2c20  mial(key, p, n, 
-00006d80: 7368 6170 653d 5f73 697a 6532 7368 6170  shape=_size2shap
-00006d90: 6528 7369 7a65 2929 0a20 2020 2072 6574  e(size)).    ret
-00006da0: 7572 6e20 5f72 6574 7572 6e28 7229 0a0a  urn _return(r)..
-00006db0: 2020 6465 6620 6368 6973 7175 6172 6528    def chisquare(
-00006dc0: 7365 6c66 2c20 6466 2c20 7369 7a65 3d4e  self, df, size=N
-00006dd0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-00006de0: 2020 2020 6466 203d 205f 6368 6563 6b5f      df = _check_
-00006df0: 7079 5f73 6571 285f 6173 5f6a 6178 5f61  py_seq(_as_jax_a
-00006e00: 7272 6179 2864 6629 290a 2020 2020 6b65  rray(df)).    ke
-00006e10: 7920 3d20 7365 6c66 2e73 706c 6974 5f6b  y = self.split_k
-00006e20: 6579 2829 2069 6620 6b65 7920 6973 204e  ey() if key is N
-00006e30: 6f6e 6520 656c 7365 205f 666f 726d 616c  one else _formal
-00006e40: 697a 655f 6b65 7928 6b65 7929 0a20 2020  ize_key(key).   
-00006e50: 2069 6620 7369 7a65 2069 7320 4e6f 6e65   if size is None
-00006e60: 3a0a 2020 2020 2020 6966 206a 6e70 2e6e  :.      if jnp.n
-00006e70: 6469 6d28 6466 2920 3d3d 2030 3a0a 2020  dim(df) == 0:.  
-00006e80: 2020 2020 2020 6469 7374 203d 206a 722e        dist = jr.
-00006e90: 6e6f 726d 616c 286b 6579 2c20 2864 662c  normal(key, (df,
-00006ea0: 2929 202a 2a20 320a 2020 2020 2020 2020  )) ** 2.        
-00006eb0: 6469 7374 203d 2064 6973 742e 7375 6d28  dist = dist.sum(
-00006ec0: 290a 2020 2020 2020 656c 7365 3a0a 2020  ).      else:.  
-00006ed0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
-00006ee0: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
-00006ef0: 2744 6f20 6e6f 7420 7375 7070 6f72 7420  'Do not support 
-00006f00: 6e6f 6e2d 7363 616c 6520 2264 6622 2077  non-scale "df" w
-00006f10: 6865 6e20 2273 697a 6522 2069 7320 4e6f  hen "size" is No
-00006f20: 6e65 2729 0a20 2020 2065 6c73 653a 0a20  ne').    else:. 
-00006f30: 2020 2020 2064 6973 7420 3d20 6a72 2e6e       dist = jr.n
-00006f40: 6f72 6d61 6c28 6b65 792c 2028 6466 2c29  ormal(key, (df,)
-00006f50: 202b 205f 7369 7a65 3273 6861 7065 2873   + _size2shape(s
-00006f60: 697a 6529 2920 2a2a 2032 0a20 2020 2020  ize)) ** 2.     
-00006f70: 2064 6973 7420 3d20 6469 7374 2e73 756d   dist = dist.sum
-00006f80: 2861 7869 733d 3029 0a20 2020 2072 6574  (axis=0).    ret
-00006f90: 7572 6e20 5f72 6574 7572 6e28 6469 7374  urn _return(dist
-00006fa0: 290a 0a20 2064 6566 2064 6972 6963 686c  )..  def dirichl
-00006fb0: 6574 2873 656c 662c 2061 6c70 6861 2c20  et(self, alpha, 
-00006fc0: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
-00006fd0: 6f6e 6529 3a0a 2020 2020 6b65 7920 3d20  one):.    key = 
-00006fe0: 7365 6c66 2e73 706c 6974 5f6b 6579 2829  self.split_key()
-00006ff0: 2069 6620 6b65 7920 6973 204e 6f6e 6520   if key is None 
-00007000: 656c 7365 205f 666f 726d 616c 697a 655f  else _formalize_
-00007010: 6b65 7928 6b65 7929 0a20 2020 2061 6c70  key(key).    alp
-00007020: 6861 203d 205f 6368 6563 6b5f 7079 5f73  ha = _check_py_s
-00007030: 6571 285f 6173 5f6a 6178 5f61 7272 6179  eq(_as_jax_array
-00007040: 2861 6c70 6861 2929 0a20 2020 2072 203d  (alpha)).    r =
-00007050: 206a 722e 6469 7269 6368 6c65 7428 6b65   jr.dirichlet(ke
-00007060: 792c 2061 6c70 6861 3d61 6c70 6861 2c20  y, alpha=alpha, 
-00007070: 7368 6170 653d 5f73 697a 6532 7368 6170  shape=_size2shap
-00007080: 6528 7369 7a65 2929 0a20 2020 2072 6574  e(size)).    ret
-00007090: 7572 6e20 5f72 6574 7572 6e28 7229 0a0a  urn _return(r)..
-000070a0: 2020 6465 6620 6765 6f6d 6574 7269 6328    def geometric(
-000070b0: 7365 6c66 2c20 702c 2073 697a 653d 4e6f  self, p, size=No
-000070c0: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
-000070d0: 2020 2070 203d 205f 6173 5f6a 6178 5f61     p = _as_jax_a
-000070e0: 7272 6179 2870 290a 2020 2020 7020 3d20  rray(p).    p = 
-000070f0: 5f63 6865 636b 5f70 795f 7365 7128 7029  _check_py_seq(p)
-00007100: 0a20 2020 2069 6620 7369 7a65 2069 7320  .    if size is 
-00007110: 4e6f 6e65 3a0a 2020 2020 2020 7369 7a65  None:.      size
-00007120: 203d 206a 6e70 2e73 6861 7065 2870 290a   = jnp.shape(p).
-00007130: 2020 2020 6b65 7920 3d20 7365 6c66 2e73      key = self.s
-00007140: 706c 6974 5f6b 6579 2829 2069 6620 6b65  plit_key() if ke
-00007150: 7920 6973 204e 6f6e 6520 656c 7365 205f  y is None else _
-00007160: 666f 726d 616c 697a 655f 6b65 7928 6b65  formalize_key(ke
-00007170: 7929 0a20 2020 2075 203d 206a 722e 756e  y).    u = jr.un
-00007180: 6966 6f72 6d28 6b65 792c 2073 697a 6529  iform(key, size)
-00007190: 0a20 2020 2072 203d 206a 6e70 2e66 6c6f  .    r = jnp.flo
-000071a0: 6f72 286a 6e70 2e6c 6f67 3170 282d 7529  or(jnp.log1p(-u)
-000071b0: 202f 206a 6e70 2e6c 6f67 3170 282d 7029   / jnp.log1p(-p)
-000071c0: 290a 2020 2020 7265 7475 726e 205f 7265  ).    return _re
-000071d0: 7475 726e 2872 290a 0a20 2064 6566 205f  turn(r)..  def _
-000071e0: 6368 6563 6b5f 7032 2873 656c 662c 2070  check_p2(self, p
-000071f0: 293a 0a20 2020 2072 6169 7365 2056 616c  ):.    raise Val
-00007200: 7565 4572 726f 7228 6627 5765 2072 6571  ueError(f'We req
-00007210: 7569 7265 2060 7375 6d28 7076 616c 735b  uire `sum(pvals[
-00007220: 3a2d 315d 2920 3c3d 2031 602e 2042 7574  :-1]) <= 1`. But
-00007230: 2077 6520 676f 7420 7b70 7d27 290a 0a20   we got {p}').. 
-00007240: 2064 6566 206d 756c 7469 6e6f 6d69 616c   def multinomial
-00007250: 2873 656c 662c 206e 2c20 7076 616c 732c  (self, n, pvals,
-00007260: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
-00007270: 4e6f 6e65 293a 0a20 2020 206b 6579 203d  None):.    key =
-00007280: 2073 656c 662e 7370 6c69 745f 6b65 7928   self.split_key(
-00007290: 2920 6966 206b 6579 2069 7320 4e6f 6e65  ) if key is None
-000072a0: 2065 6c73 6520 5f66 6f72 6d61 6c69 7a65   else _formalize
-000072b0: 5f6b 6579 286b 6579 290a 2020 2020 6e20  _key(key).    n 
-000072c0: 3d20 5f63 6865 636b 5f70 795f 7365 7128  = _check_py_seq(
-000072d0: 5f61 735f 6a61 785f 6172 7261 7928 6e29  _as_jax_array(n)
-000072e0: 290a 2020 2020 7076 616c 7320 3d20 5f63  ).    pvals = _c
-000072f0: 6865 636b 5f70 795f 7365 7128 5f61 735f  heck_py_seq(_as_
-00007300: 6a61 785f 6172 7261 7928 7076 616c 7329  jax_array(pvals)
-00007310: 290a 2020 2020 6a69 745f 6572 726f 725f  ).    jit_error_
-00007320: 6368 6563 6b69 6e67 286a 6e70 2e73 756d  checking(jnp.sum
-00007330: 2870 7661 6c73 5b3a 2d31 5d29 203e 2031  (pvals[:-1]) > 1
-00007340: 2e2c 2073 656c 662e 5f63 6865 636b 5f70  ., self._check_p
-00007350: 322c 2070 7661 6c73 290a 2020 2020 6966  2, pvals).    if
-00007360: 2069 7369 6e73 7461 6e63 6528 6e2c 206a   isinstance(n, j
-00007370: 6178 2e63 6f72 652e 5472 6163 6572 293a  ax.core.Tracer):
-00007380: 0a20 2020 2020 2072 6169 7365 2056 616c  .      raise Val
-00007390: 7565 4572 726f 7228 2254 6865 2074 6f74  ueError("The tot
-000073a0: 616c 2063 6f75 6e74 2070 6172 616d 6574  al count paramet
-000073b0: 6572 2060 6e60 2073 686f 756c 6420 6e6f  er `n` should no
-000073c0: 7420 6265 2061 206a 6178 2061 6273 7472  t be a jax abstr
-000073d0: 6163 7420 6172 7261 792e 2229 0a20 2020  act array.").   
-000073e0: 2073 697a 6520 3d20 5f73 697a 6532 7368   size = _size2sh
-000073f0: 6170 6528 7369 7a65 290a 2020 2020 6e5f  ape(size).    n_
-00007400: 6d61 7820 3d20 696e 7428 6e70 2e6d 6178  max = int(np.max
-00007410: 286a 6178 2e64 6576 6963 655f 6765 7428  (jax.device_get(
-00007420: 6e29 2929 0a20 2020 2062 6174 6368 5f73  n))).    batch_s
-00007430: 6861 7065 203d 206c 6178 2e62 726f 6164  hape = lax.broad
-00007440: 6361 7374 5f73 6861 7065 7328 6a6e 702e  cast_shapes(jnp.
-00007450: 7368 6170 6528 7076 616c 7329 5b3a 2d31  shape(pvals)[:-1
-00007460: 5d2c 206a 6e70 2e73 6861 7065 286e 2929  ], jnp.shape(n))
-00007470: 0a20 2020 2072 203d 205f 6d75 6c74 696e  .    r = _multin
-00007480: 6f6d 6961 6c28 6b65 792c 2070 7661 6c73  omial(key, pvals
-00007490: 2c20 6e2c 206e 5f6d 6178 2c20 6261 7463  , n, n_max, batc
-000074a0: 685f 7368 6170 6520 2b20 7369 7a65 290a  h_shape + size).
-000074b0: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
-000074c0: 726e 2872 290a 0a20 2064 6566 206d 756c  rn(r)..  def mul
-000074d0: 7469 7661 7269 6174 655f 6e6f 726d 616c  tivariate_normal
-000074e0: 2873 656c 662c 206d 6561 6e2c 2063 6f76  (self, mean, cov
-000074f0: 2c20 7369 7a65 3d4e 6f6e 652c 206d 6574  , size=None, met
-00007500: 686f 643a 2073 7472 203d 2027 6368 6f6c  hod: str = 'chol
-00007510: 6573 6b79 272c 206b 6579 3d4e 6f6e 6529  esky', key=None)
-00007520: 3a0a 2020 2020 6966 206d 6574 686f 6420  :.    if method 
-00007530: 6e6f 7420 696e 207b 2773 7664 272c 2027  not in {'svd', '
-00007540: 6569 6768 272c 2027 6368 6f6c 6573 6b79  eigh', 'cholesky
-00007550: 277d 3a0a 2020 2020 2020 7261 6973 6520  '}:.      raise 
-00007560: 5661 6c75 6545 7272 6f72 2822 6d65 7468  ValueError("meth
-00007570: 6f64 206d 7573 7420 6265 206f 6e65 206f  od must be one o
-00007580: 6620 7b27 7376 6427 2c20 2765 6967 6827  f {'svd', 'eigh'
-00007590: 2c20 2763 686f 6c65 736b 7927 7d22 290a  , 'cholesky'}").
-000075a0: 2020 2020 6d65 616e 203d 205f 6368 6563      mean = _chec
-000075b0: 6b5f 7079 5f73 6571 285f 6173 5f6a 6178  k_py_seq(_as_jax
-000075c0: 5f61 7272 6179 286d 6561 6e29 290a 2020  _array(mean)).  
-000075d0: 2020 636f 7620 3d20 5f63 6865 636b 5f70    cov = _check_p
-000075e0: 795f 7365 7128 5f61 735f 6a61 785f 6172  y_seq(_as_jax_ar
-000075f0: 7261 7928 636f 7629 290a 2020 2020 6b65  ray(cov)).    ke
-00007600: 7920 3d20 7365 6c66 2e73 706c 6974 5f6b  y = self.split_k
-00007610: 6579 2829 2069 6620 6b65 7920 6973 204e  ey() if key is N
-00007620: 6f6e 6520 656c 7365 205f 666f 726d 616c  one else _formal
-00007630: 697a 655f 6b65 7928 6b65 7929 0a0a 2020  ize_key(key)..  
-00007640: 2020 6966 206e 6f74 206a 6e70 2e6e 6469    if not jnp.ndi
-00007650: 6d28 6d65 616e 2920 3e3d 2031 3a0a 2020  m(mean) >= 1:.  
-00007660: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-00007670: 7272 6f72 2866 226d 756c 7469 7661 7269  rror(f"multivari
-00007680: 6174 655f 6e6f 726d 616c 2072 6571 7569  ate_normal requi
-00007690: 7265 7320 6d65 616e 2e6e 6469 6d20 3e3d  res mean.ndim >=
-000076a0: 2031 2c20 676f 7420 6d65 616e 2e6e 6469   1, got mean.ndi
-000076b0: 6d20 3d3d 207b 6a6e 702e 6e64 696d 286d  m == {jnp.ndim(m
-000076c0: 6561 6e29 7d22 290a 2020 2020 6966 206e  ean)}").    if n
-000076d0: 6f74 206a 6e70 2e6e 6469 6d28 636f 7629  ot jnp.ndim(cov)
-000076e0: 203e 3d20 323a 0a20 2020 2020 2072 6169   >= 2:.      rai
-000076f0: 7365 2056 616c 7565 4572 726f 7228 6622  se ValueError(f"
-00007700: 6d75 6c74 6976 6172 6961 7465 5f6e 6f72  multivariate_nor
-00007710: 6d61 6c20 7265 7175 6972 6573 2063 6f76  mal requires cov
-00007720: 2e6e 6469 6d20 3e3d 2032 2c20 676f 7420  .ndim >= 2, got 
-00007730: 636f 762e 6e64 696d 203d 3d20 7b6a 6e70  cov.ndim == {jnp
-00007740: 2e6e 6469 6d28 636f 7629 7d22 290a 2020  .ndim(cov)}").  
-00007750: 2020 6e20 3d20 6d65 616e 2e73 6861 7065    n = mean.shape
-00007760: 5b2d 315d 0a20 2020 2069 6620 6a6e 702e  [-1].    if jnp.
-00007770: 7368 6170 6528 636f 7629 5b2d 323a 5d20  shape(cov)[-2:] 
-00007780: 213d 2028 6e2c 206e 293a 0a20 2020 2020  != (n, n):.     
-00007790: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-000077a0: 7228 6622 6d75 6c74 6976 6172 6961 7465  r(f"multivariate
-000077b0: 5f6e 6f72 6d61 6c20 7265 7175 6972 6573  _normal requires
-000077c0: 2063 6f76 2e73 6861 7065 203d 3d20 282e   cov.shape == (.
-000077d0: 2e2e 2c20 6e2c 206e 2920 666f 7220 6e3d  .., n, n) for n=
-000077e0: 7b6e 7d2c 2022 0a20 2020 2020 2020 2020  {n}, ".         
-000077f0: 2020 2020 2020 2020 2020 2020 2020 6622                f"
-00007800: 6275 7420 676f 7420 636f 762e 7368 6170  but got cov.shap
-00007810: 6520 3d3d 207b 6a6e 702e 7368 6170 6528  e == {jnp.shape(
-00007820: 636f 7629 7d2e 2229 0a20 2020 2069 6620  cov)}.").    if 
-00007830: 7369 7a65 2069 7320 4e6f 6e65 3a0a 2020  size is None:.  
-00007840: 2020 2020 7369 7a65 203d 206c 6178 2e62      size = lax.b
-00007850: 726f 6164 6361 7374 5f73 6861 7065 7328  roadcast_shapes(
-00007860: 6d65 616e 2e73 6861 7065 5b3a 2d31 5d2c  mean.shape[:-1],
-00007870: 2063 6f76 2e73 6861 7065 5b3a 2d32 5d29   cov.shape[:-2])
-00007880: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
-00007890: 2073 697a 6520 3d20 5f73 697a 6532 7368   size = _size2sh
-000078a0: 6170 6528 7369 7a65 290a 2020 2020 2020  ape(size).      
-000078b0: 5f63 6865 636b 5f73 6861 7065 2822 6e6f  _check_shape("no
-000078c0: 726d 616c 222c 2073 697a 652c 206d 6561  rmal", size, mea
-000078d0: 6e2e 7368 6170 655b 3a2d 315d 2c20 636f  n.shape[:-1], co
-000078e0: 762e 7368 6170 655b 3a2d 325d 290a 0a20  v.shape[:-2]).. 
-000078f0: 2020 2069 6620 6d65 7468 6f64 203d 3d20     if method == 
-00007900: 2773 7664 273a 0a20 2020 2020 2028 752c  'svd':.      (u,
-00007910: 2073 2c20 5f29 203d 206a 6e70 2e6c 696e   s, _) = jnp.lin
-00007920: 616c 672e 7376 6428 636f 7629 0a20 2020  alg.svd(cov).   
-00007930: 2020 2066 6163 746f 7220 3d20 7520 2a20     factor = u * 
-00007940: 6a6e 702e 7371 7274 2873 5b2e 2e2e 2c20  jnp.sqrt(s[..., 
-00007950: 4e6f 6e65 2c20 3a5d 290a 2020 2020 656c  None, :]).    el
-00007960: 6966 206d 6574 686f 6420 3d3d 2027 6569  if method == 'ei
-00007970: 6768 273a 0a20 2020 2020 2028 772c 2076  gh':.      (w, v
-00007980: 2920 3d20 6a6e 702e 6c69 6e61 6c67 2e65  ) = jnp.linalg.e
-00007990: 6967 6828 636f 7629 0a20 2020 2020 2066  igh(cov).      f
-000079a0: 6163 746f 7220 3d20 7620 2a20 6a6e 702e  actor = v * jnp.
-000079b0: 7371 7274 2877 5b2e 2e2e 2c20 4e6f 6e65  sqrt(w[..., None
-000079c0: 2c20 3a5d 290a 2020 2020 656c 7365 3a20  , :]).    else: 
-000079d0: 2023 2027 6368 6f6c 6573 6b79 270a 2020   # 'cholesky'.  
-000079e0: 2020 2020 6661 6374 6f72 203d 206a 6e70      factor = jnp
-000079f0: 2e6c 696e 616c 672e 6368 6f6c 6573 6b79  .linalg.cholesky
-00007a00: 2863 6f76 290a 2020 2020 6e6f 726d 616c  (cov).    normal
-00007a10: 5f73 616d 706c 6573 203d 206a 722e 6e6f  _samples = jr.no
-00007a20: 726d 616c 286b 6579 2c20 7369 7a65 202b  rmal(key, size +
-00007a30: 206d 6561 6e2e 7368 6170 655b 2d31 3a5d   mean.shape[-1:]
-00007a40: 290a 2020 2020 7220 3d20 6d65 616e 202b  ).    r = mean +
-00007a50: 206a 6e70 2e65 696e 7375 6d28 272e 2e2e   jnp.einsum('...
-00007a60: 696a 2c2e 2e2e 6a2d 3e2e 2e2e 6927 2c20  ij,...j->...i', 
-00007a70: 6661 6374 6f72 2c20 6e6f 726d 616c 5f73  factor, normal_s
-00007a80: 616d 706c 6573 290a 2020 2020 7265 7475  amples).    retu
-00007a90: 726e 205f 7265 7475 726e 2872 290a 0a20  rn _return(r).. 
-00007aa0: 2064 6566 2072 6179 6c65 6967 6828 7365   def rayleigh(se
-00007ab0: 6c66 2c20 7363 616c 653d 312e 302c 2073  lf, scale=1.0, s
-00007ac0: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
-00007ad0: 6e65 293a 0a20 2020 2073 6361 6c65 203d  ne):.    scale =
-00007ae0: 205f 6368 6563 6b5f 7079 5f73 6571 285f   _check_py_seq(_
-00007af0: 6173 5f6a 6178 5f61 7272 6179 2873 6361  as_jax_array(sca
-00007b00: 6c65 2929 0a20 2020 2069 6620 7369 7a65  le)).    if size
-00007b10: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
-00007b20: 7369 7a65 203d 206a 6e70 2e73 6861 7065  size = jnp.shape
-00007b30: 2873 6361 6c65 290a 2020 2020 6b65 7920  (scale).    key 
-00007b40: 3d20 7365 6c66 2e73 706c 6974 5f6b 6579  = self.split_key
-00007b50: 2829 2069 6620 6b65 7920 6973 204e 6f6e  () if key is Non
-00007b60: 6520 656c 7365 205f 666f 726d 616c 697a  e else _formaliz
-00007b70: 655f 6b65 7928 6b65 7929 0a20 2020 2078  e_key(key).    x
-00007b80: 203d 206a 6e70 2e73 7172 7428 2d32 2e20   = jnp.sqrt(-2. 
-00007b90: 2a20 6a6e 702e 6c6f 6728 6a72 2e75 6e69  * jnp.log(jr.uni
-00007ba0: 666f 726d 286b 6579 2c20 7368 6170 653d  form(key, shape=
-00007bb0: 5f73 697a 6532 7368 6170 6528 7369 7a65  _size2shape(size
-00007bc0: 292c 206d 696e 7661 6c3d 302c 206d 6178  ), minval=0, max
-00007bd0: 7661 6c3d 3129 2929 0a20 2020 2072 203d  val=1))).    r =
-00007be0: 2078 202a 2073 6361 6c65 0a20 2020 2072   x * scale.    r
-00007bf0: 6574 7572 6e20 5f72 6574 7572 6e28 7229  eturn _return(r)
-00007c00: 0a0a 2020 6465 6620 7472 6961 6e67 756c  ..  def triangul
-00007c10: 6172 2873 656c 662c 2073 697a 653d 4e6f  ar(self, size=No
-00007c20: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
-00007c30: 2020 206b 6579 203d 2073 656c 662e 7370     key = self.sp
-00007c40: 6c69 745f 6b65 7928 2920 6966 206b 6579  lit_key() if key
-00007c50: 2069 7320 4e6f 6e65 2065 6c73 6520 5f66   is None else _f
-00007c60: 6f72 6d61 6c69 7a65 5f6b 6579 286b 6579  ormalize_key(key
-00007c70: 290a 2020 2020 6265 726e 6f75 6c6c 695f  ).    bernoulli_
-00007c80: 7361 6d70 6c65 7320 3d20 6a72 2e62 6572  samples = jr.ber
-00007c90: 6e6f 756c 6c69 286b 6579 2c20 703d 302e  noulli(key, p=0.
-00007ca0: 352c 2073 6861 7065 3d5f 7369 7a65 3273  5, shape=_size2s
-00007cb0: 6861 7065 2873 697a 6529 290a 2020 2020  hape(size)).    
-00007cc0: 7220 3d20 3220 2a20 6265 726e 6f75 6c6c  r = 2 * bernoull
-00007cd0: 695f 7361 6d70 6c65 7320 2d20 310a 2020  i_samples - 1.  
-00007ce0: 2020 7265 7475 726e 205f 7265 7475 726e    return _return
-00007cf0: 2872 290a 0a20 2064 6566 2076 6f6e 6d69  (r)..  def vonmi
-00007d00: 7365 7328 7365 6c66 2c20 6d75 2c20 6b61  ses(self, mu, ka
-00007d10: 7070 612c 2073 697a 653d 4e6f 6e65 2c20  ppa, size=None, 
-00007d20: 6b65 793d 4e6f 6e65 293a 0a20 2020 206b  key=None):.    k
-00007d30: 6579 203d 2073 656c 662e 7370 6c69 745f  ey = self.split_
-00007d40: 6b65 7928 2920 6966 206b 6579 2069 7320  key() if key is 
-00007d50: 4e6f 6e65 2065 6c73 6520 5f66 6f72 6d61  None else _forma
-00007d60: 6c69 7a65 5f6b 6579 286b 6579 290a 2020  lize_key(key).  
-00007d70: 2020 6d75 203d 205f 6368 6563 6b5f 7079    mu = _check_py
-00007d80: 5f73 6571 285f 6173 5f6a 6178 5f61 7272  _seq(_as_jax_arr
-00007d90: 6179 286d 7529 290a 2020 2020 6b61 7070  ay(mu)).    kapp
-00007da0: 6120 3d20 5f63 6865 636b 5f70 795f 7365  a = _check_py_se
-00007db0: 7128 5f61 735f 6a61 785f 6172 7261 7928  q(_as_jax_array(
-00007dc0: 6b61 7070 6129 290a 2020 2020 6966 2073  kappa)).    if s
-00007dd0: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
-00007de0: 2020 2073 697a 6520 3d20 6c61 782e 6272     size = lax.br
-00007df0: 6f61 6463 6173 745f 7368 6170 6573 286a  oadcast_shapes(j
-00007e00: 6e70 2e73 6861 7065 286d 7529 2c20 6a6e  np.shape(mu), jn
-00007e10: 702e 7368 6170 6528 6b61 7070 6129 290a  p.shape(kappa)).
-00007e20: 2020 2020 7369 7a65 203d 205f 7369 7a65      size = _size
-00007e30: 3273 6861 7065 2873 697a 6529 0a20 2020  2shape(size).   
-00007e40: 2073 616d 706c 6573 203d 205f 766f 6e5f   samples = _von_
-00007e50: 6d69 7365 735f 6365 6e74 6572 6564 286b  mises_centered(k
-00007e60: 6579 2c20 6b61 7070 612c 2073 697a 6529  ey, kappa, size)
-00007e70: 0a20 2020 2073 616d 706c 6573 203d 2073  .    samples = s
-00007e80: 616d 706c 6573 202b 206d 750a 2020 2020  amples + mu.    
-00007e90: 7361 6d70 6c65 7320 3d20 2873 616d 706c  samples = (sampl
-00007ea0: 6573 202b 206a 6e70 2e70 6929 2025 2028  es + jnp.pi) % (
-00007eb0: 322e 3020 2a20 6a6e 702e 7069 2920 2d20  2.0 * jnp.pi) - 
-00007ec0: 6a6e 702e 7069 0a20 2020 2072 6574 7572  jnp.pi.    retur
-00007ed0: 6e20 5f72 6574 7572 6e28 7361 6d70 6c65  n _return(sample
-00007ee0: 7329 0a0a 2020 6465 6620 7765 6962 756c  s)..  def weibul
-00007ef0: 6c28 7365 6c66 2c20 612c 2073 697a 653d  l(self, a, size=
-00007f00: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
-00007f10: 0a20 2020 206b 6579 203d 2073 656c 662e  .    key = self.
-00007f20: 7370 6c69 745f 6b65 7928 2920 6966 206b  split_key() if k
-00007f30: 6579 2069 7320 4e6f 6e65 2065 6c73 6520  ey is None else 
-00007f40: 5f66 6f72 6d61 6c69 7a65 5f6b 6579 286b  _formalize_key(k
-00007f50: 6579 290a 2020 2020 6120 3d20 5f63 6865  ey).    a = _che
-00007f60: 636b 5f70 795f 7365 7128 5f61 735f 6a61  ck_py_seq(_as_ja
-00007f70: 785f 6172 7261 7928 6129 290a 2020 2020  x_array(a)).    
-00007f80: 6966 2073 697a 6520 6973 204e 6f6e 653a  if size is None:
-00007f90: 0a20 2020 2020 2073 697a 6520 3d20 6a6e  .      size = jn
-00007fa0: 702e 7368 6170 6528 6129 0a20 2020 2065  p.shape(a).    e
-00007fb0: 6c73 653a 0a20 2020 2020 2069 6620 6a6e  lse:.      if jn
-00007fc0: 702e 7369 7a65 2861 2920 3e20 313a 0a20  p.size(a) > 1:. 
-00007fd0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-00007fe0: 7565 4572 726f 7228 6627 2261 2220 7368  ueError(f'"a" sh
-00007ff0: 6f75 6c64 2062 6520 6120 7363 616c 6172  ould be a scalar
-00008000: 2077 6865 6e20 2273 697a 6522 2069 7320   when "size" is 
-00008010: 7072 6f76 6964 6564 2e20 4275 7420 7765  provided. But we
-00008020: 2067 6f74 207b 617d 2729 0a20 2020 2073   got {a}').    s
-00008030: 697a 6520 3d20 5f73 697a 6532 7368 6170  ize = _size2shap
-00008040: 6528 7369 7a65 290a 2020 2020 7261 6e64  e(size).    rand
-00008050: 6f6d 5f75 6e69 666f 726d 203d 206a 722e  om_uniform = jr.
-00008060: 756e 6966 6f72 6d28 6b65 793d 6b65 792c  uniform(key=key,
-00008070: 2073 6861 7065 3d73 697a 652c 206d 696e   shape=size, min
-00008080: 7661 6c3d 302c 206d 6178 7661 6c3d 3129  val=0, maxval=1)
-00008090: 0a20 2020 2072 203d 206a 6e70 2e70 6f77  .    r = jnp.pow
-000080a0: 6572 282d 6a6e 702e 6c6f 6731 7028 2d72  er(-jnp.log1p(-r
-000080b0: 616e 646f 6d5f 756e 6966 6f72 6d29 2c20  andom_uniform), 
-000080c0: 312e 3020 2f20 6129 0a20 2020 2072 6574  1.0 / a).    ret
-000080d0: 7572 6e20 5f72 6574 7572 6e28 7229 0a0a  urn _return(r)..
-000080e0: 2020 6465 6620 7765 6962 756c 6c5f 6d69    def weibull_mi
-000080f0: 6e28 7365 6c66 2c20 612c 2073 6361 6c65  n(self, a, scale
-00008100: 3d4e 6f6e 652c 2073 697a 653d 4e6f 6e65  =None, size=None
-00008110: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2020  , key=None):.   
-00008120: 2022 2222 5361 6d70 6c65 2066 726f 6d20   """Sample from 
-00008130: 6120 5765 6962 756c 6c20 6d69 6e69 6d75  a Weibull minimu
-00008140: 6d20 6469 7374 7269 6275 7469 6f6e 2e0a  m distribution..
-00008150: 0a20 2020 2050 6172 616d 6574 6572 730a  .    Parameters.
-00008160: 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20      ----------. 
-00008170: 2020 2061 3a20 666c 6f61 742c 2061 7272     a: float, arr
-00008180: 6179 5f6c 696b 650a 2020 2020 2020 5468  ay_like.      Th
-00008190: 6520 636f 6e63 656e 7472 6174 696f 6e20  e concentration 
-000081a0: 7061 7261 6d65 7465 7220 6f66 2074 6865  parameter of the
-000081b0: 2064 6973 7472 6962 7574 696f 6e2e 0a20   distribution.. 
-000081c0: 2020 2073 6361 6c65 3a20 666c 6f61 742c     scale: float,
-000081d0: 2061 7272 6179 5f6c 696b 650a 2020 2020   array_like.    
-000081e0: 2020 5468 6520 7363 616c 6520 7061 7261    The scale para
-000081f0: 6d65 7465 7220 6f66 2074 6865 2064 6973  meter of the dis
-00008200: 7472 6962 7574 696f 6e2e 0a20 2020 2073  tribution..    s
-00008210: 697a 653a 206f 7074 696f 6e61 6c2c 2069  ize: optional, i
-00008220: 6e74 2c20 7475 706c 6520 6f66 2069 6e74  nt, tuple of int
-00008230: 0a20 2020 2020 2054 6865 2073 6861 7065  .      The shape
-00008240: 2061 6464 6564 2074 6f20 7468 6520 7061   added to the pa
-00008250: 7261 6d65 7465 7273 206c 6f63 2061 6e64  rameters loc and
-00008260: 2073 6361 6c65 2062 726f 6164 6361 7374   scale broadcast
-00008270: 6162 6c65 2073 6861 7065 2e0a 0a20 2020  able shape...   
-00008280: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
-00008290: 2d2d 2d2d 0a20 2020 206f 7574 3a20 6172  ----.    out: ar
-000082a0: 7261 795f 6c69 6b65 0a20 2020 2020 2054  ray_like.      T
-000082b0: 6865 2073 616d 706c 696e 6720 7265 7375  he sampling resu
-000082c0: 6c74 732e 0a20 2020 2022 2222 0a20 2020  lts..    """.   
-000082d0: 206b 6579 203d 2073 656c 662e 7370 6c69   key = self.spli
-000082e0: 745f 6b65 7928 2920 6966 206b 6579 2069  t_key() if key i
-000082f0: 7320 4e6f 6e65 2065 6c73 6520 5f66 6f72  s None else _for
-00008300: 6d61 6c69 7a65 5f6b 6579 286b 6579 290a  malize_key(key).
-00008310: 2020 2020 6120 3d20 5f63 6865 636b 5f70      a = _check_p
-00008320: 795f 7365 7128 5f61 735f 6a61 785f 6172  y_seq(_as_jax_ar
-00008330: 7261 7928 6129 290a 2020 2020 7363 616c  ray(a)).    scal
-00008340: 6520 3d20 5f63 6865 636b 5f70 795f 7365  e = _check_py_se
-00008350: 7128 5f61 735f 6a61 785f 6172 7261 7928  q(_as_jax_array(
-00008360: 7363 616c 6529 290a 2020 2020 6966 2073  scale)).    if s
-00008370: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
-00008380: 2020 2073 697a 6520 3d20 6a6e 702e 6272     size = jnp.br
-00008390: 6f61 6463 6173 745f 7368 6170 6573 286a  oadcast_shapes(j
-000083a0: 6e70 2e73 6861 7065 2861 292c 206a 6e70  np.shape(a), jnp
-000083b0: 2e73 6861 7065 2873 6361 6c65 2929 0a20  .shape(scale)). 
-000083c0: 2020 2065 6c73 653a 0a20 2020 2020 2069     else:.      i
-000083d0: 6620 6a6e 702e 7369 7a65 2861 2920 3e20  f jnp.size(a) > 
-000083e0: 313a 0a20 2020 2020 2020 2072 6169 7365  1:.        raise
-000083f0: 2056 616c 7565 4572 726f 7228 6627 2261   ValueError(f'"a
-00008400: 2220 7368 6f75 6c64 2062 6520 6120 7363  " should be a sc
-00008410: 616c 6172 2077 6865 6e20 2273 697a 6522  alar when "size"
-00008420: 2069 7320 7072 6f76 6964 6564 2e20 4275   is provided. Bu
-00008430: 7420 7765 2067 6f74 207b 617d 2729 0a20  t we got {a}'). 
-00008440: 2020 2073 697a 6520 3d20 5f73 697a 6532     size = _size2
-00008450: 7368 6170 6528 7369 7a65 290a 2020 2020  shape(size).    
-00008460: 7261 6e64 6f6d 5f75 6e69 666f 726d 203d  random_uniform =
-00008470: 206a 722e 756e 6966 6f72 6d28 6b65 793d   jr.uniform(key=
-00008480: 6b65 792c 2073 6861 7065 3d73 697a 652c  key, shape=size,
-00008490: 206d 696e 7661 6c3d 302c 206d 6178 7661   minval=0, maxva
-000084a0: 6c3d 3129 0a20 2020 2072 203d 206a 6e70  l=1).    r = jnp
-000084b0: 2e70 6f77 6572 282d 6a6e 702e 6c6f 6731  .power(-jnp.log1
-000084c0: 7028 2d72 616e 646f 6d5f 756e 6966 6f72  p(-random_unifor
-000084d0: 6d29 2c20 312e 3020 2f20 6129 0a20 2020  m), 1.0 / a).   
-000084e0: 2069 6620 7363 616c 6520 6973 206e 6f74   if scale is not
-000084f0: 204e 6f6e 653a 0a20 2020 2020 2072 202f   None:.      r /
-00008500: 3d20 7363 616c 650a 2020 2020 7265 7475  = scale.    retu
-00008510: 726e 205f 7265 7475 726e 2872 290a 0a20  rn _return(r).. 
-00008520: 2064 6566 206d 6178 7765 6c6c 2873 656c   def maxwell(sel
-00008530: 662c 2073 697a 653d 4e6f 6e65 2c20 6b65  f, size=None, ke
-00008540: 793d 4e6f 6e65 293a 0a20 2020 206b 6579  y=None):.    key
-00008550: 203d 2073 656c 662e 7370 6c69 745f 6b65   = self.split_ke
-00008560: 7928 2920 6966 206b 6579 2069 7320 4e6f  y() if key is No
-00008570: 6e65 2065 6c73 6520 5f66 6f72 6d61 6c69  ne else _formali
-00008580: 7a65 5f6b 6579 286b 6579 290a 2020 2020  ze_key(key).    
-00008590: 7368 6170 6520 3d20 636f 7265 2e63 616e  shape = core.can
-000085a0: 6f6e 6963 616c 697a 655f 7368 6170 6528  onicalize_shape(
-000085b0: 5f73 697a 6532 7368 6170 6528 7369 7a65  _size2shape(size
-000085c0: 2929 202b 2028 332c 290a 2020 2020 6e6f  )) + (3,).    no
-000085d0: 726d 5f72 7673 203d 206a 722e 6e6f 726d  rm_rvs = jr.norm
-000085e0: 616c 286b 6579 3d6b 6579 2c20 7368 6170  al(key=key, shap
-000085f0: 653d 7368 6170 6529 0a20 2020 2072 203d  e=shape).    r =
-00008600: 206a 6e70 2e6c 696e 616c 672e 6e6f 726d   jnp.linalg.norm
-00008610: 286e 6f72 6d5f 7276 732c 2061 7869 733d  (norm_rvs, axis=
-00008620: 2d31 290a 2020 2020 7265 7475 726e 205f  -1).    return _
-00008630: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
-00008640: 206e 6567 6174 6976 655f 6269 6e6f 6d69   negative_binomi
-00008650: 616c 2873 656c 662c 206e 2c20 702c 2073  al(self, n, p, s
-00008660: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
-00008670: 6e65 293a 0a20 2020 206e 203d 205f 6368  ne):.    n = _ch
-00008680: 6563 6b5f 7079 5f73 6571 285f 6173 5f6a  eck_py_seq(_as_j
-00008690: 6178 5f61 7272 6179 286e 2929 0a20 2020  ax_array(n)).   
-000086a0: 2070 203d 205f 6368 6563 6b5f 7079 5f73   p = _check_py_s
-000086b0: 6571 285f 6173 5f6a 6178 5f61 7272 6179  eq(_as_jax_array
-000086c0: 2870 2929 0a20 2020 2069 6620 7369 7a65  (p)).    if size
-000086d0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
-000086e0: 7369 7a65 203d 206c 6178 2e62 726f 6164  size = lax.broad
-000086f0: 6361 7374 5f73 6861 7065 7328 6a6e 702e  cast_shapes(jnp.
-00008700: 7368 6170 6528 6e29 2c20 6a6e 702e 7368  shape(n), jnp.sh
-00008710: 6170 6528 7029 290a 2020 2020 7369 7a65  ape(p)).    size
-00008720: 203d 205f 7369 7a65 3273 6861 7065 2873   = _size2shape(s
-00008730: 697a 6529 0a20 2020 206c 6f67 6974 7320  ize).    logits 
-00008740: 3d20 6a6e 702e 6c6f 6728 7029 202d 206a  = jnp.log(p) - j
-00008750: 6e70 2e6c 6f67 3170 282d 7029 0a20 2020  np.log1p(-p).   
-00008760: 2069 6620 6b65 7920 6973 204e 6f6e 653a   if key is None:
-00008770: 0a20 2020 2020 206b 6579 7320 3d20 7365  .      keys = se
-00008780: 6c66 2e73 706c 6974 5f6b 6579 7328 3229  lf.split_keys(2)
-00008790: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
-000087a0: 206b 6579 7320 3d20 6a72 2e73 706c 6974   keys = jr.split
-000087b0: 285f 666f 726d 616c 697a 655f 6b65 7928  (_formalize_key(
-000087c0: 6b65 7929 2c20 3229 0a20 2020 2072 6174  key), 2).    rat
-000087d0: 6520 3d20 7365 6c66 2e67 616d 6d61 2873  e = self.gamma(s
-000087e0: 6861 7065 3d6e 2c20 7363 616c 653d 6a6e  hape=n, scale=jn
-000087f0: 702e 6578 7028 2d6c 6f67 6974 7329 2c20  p.exp(-logits), 
-00008800: 7369 7a65 3d73 697a 652c 206b 6579 3d6b  size=size, key=k
-00008810: 6579 735b 305d 290a 2020 2020 7220 3d20  eys[0]).    r = 
-00008820: 7365 6c66 2e70 6f69 7373 6f6e 286c 616d  self.poisson(lam
-00008830: 3d72 6174 652c 206b 6579 3d6b 6579 735b  =rate, key=keys[
-00008840: 315d 290a 2020 2020 7265 7475 726e 205f  1]).    return _
-00008850: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
-00008860: 2077 616c 6428 7365 6c66 2c20 6d65 616e   wald(self, mean
-00008870: 2c20 7363 616c 652c 2073 697a 653d 4e6f  , scale, size=No
-00008880: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
-00008890: 2020 206b 6579 203d 2073 656c 662e 7370     key = self.sp
-000088a0: 6c69 745f 6b65 7928 2920 6966 206b 6579  lit_key() if key
-000088b0: 2069 7320 4e6f 6e65 2065 6c73 6520 5f66   is None else _f
-000088c0: 6f72 6d61 6c69 7a65 5f6b 6579 286b 6579  ormalize_key(key
-000088d0: 290a 2020 2020 6d65 616e 203d 205f 6368  ).    mean = _ch
-000088e0: 6563 6b5f 7079 5f73 6571 285f 6173 5f6a  eck_py_seq(_as_j
-000088f0: 6178 5f61 7272 6179 286d 6561 6e29 290a  ax_array(mean)).
-00008900: 2020 2020 7363 616c 6520 3d20 5f63 6865      scale = _che
-00008910: 636b 5f70 795f 7365 7128 5f61 735f 6a61  ck_py_seq(_as_ja
-00008920: 785f 6172 7261 7928 7363 616c 6529 290a  x_array(scale)).
-00008930: 2020 2020 6966 2073 697a 6520 6973 204e      if size is N
-00008940: 6f6e 653a 0a20 2020 2020 2073 697a 6520  one:.      size 
-00008950: 3d20 6c61 782e 6272 6f61 6463 6173 745f  = lax.broadcast_
-00008960: 7368 6170 6573 286a 6e70 2e73 6861 7065  shapes(jnp.shape
-00008970: 286d 6561 6e29 2c20 6a6e 702e 7368 6170  (mean), jnp.shap
-00008980: 6528 7363 616c 6529 290a 2020 2020 7369  e(scale)).    si
-00008990: 7a65 203d 205f 7369 7a65 3273 6861 7065  ze = _size2shape
-000089a0: 2873 697a 6529 0a20 2020 2073 616d 706c  (size).    sampl
-000089b0: 6564 5f63 6869 3220 3d20 6a6e 702e 7371  ed_chi2 = jnp.sq
-000089c0: 7561 7265 285f 6173 5f6a 6178 5f61 7272  uare(_as_jax_arr
-000089d0: 6179 2873 656c 662e 7261 6e64 6e28 2a73  ay(self.randn(*s
-000089e0: 697a 6529 2929 0a20 2020 2073 616d 706c  ize))).    sampl
-000089f0: 6564 5f75 6e69 666f 726d 203d 205f 6173  ed_uniform = _as
-00008a00: 5f6a 6178 5f61 7272 6179 2873 656c 662e  _jax_array(self.
-00008a10: 756e 6966 6f72 6d28 7369 7a65 3d73 697a  uniform(size=siz
-00008a20: 652c 206b 6579 3d6b 6579 2929 0a20 2020  e, key=key)).   
-00008a30: 2023 2057 696b 6970 6564 6961 2064 6566   # Wikipedia def
-00008a40: 696e 6573 2061 6e20 696e 7465 726d 6564  ines an intermed
-00008a50: 6961 7465 2078 2077 6974 6820 7468 6520  iate x with the 
-00008a60: 666f 726d 756c 610a 2020 2020 2320 2020  formula.    #   
-00008a70: 7820 3d20 6c6f 6320 2b20 6c6f 6320 2a2a  x = loc + loc **
-00008a80: 2032 202a 2079 202f 2028 3220 2a20 636f   2 * y / (2 * co
-00008a90: 6e63 2920 2d20 6c6f 6320 2f20 2832 202a  nc) - loc / (2 *
-00008aa0: 2063 6f6e 6329 202a 2073 7172 7428 3420   conc) * sqrt(4 
-00008ab0: 2a20 6c6f 6320 2a20 636f 6e63 202a 2079  * loc * conc * y
-00008ac0: 202b 206c 6f63 202a 2a20 3220 2a20 7920   + loc ** 2 * y 
-00008ad0: 2a2a 2032 290a 2020 2020 2320 7768 6572  ** 2).    # wher
-00008ae0: 6520 7920 7e20 4e28 302c 2031 292a 2a32  e y ~ N(0, 1)**2
-00008af0: 2028 7361 6d70 6c65 645f 6368 6932 2061   (sampled_chi2 a
-00008b00: 626f 7665 2920 616e 6420 636f 6e63 2069  bove) and conc i
-00008b10: 7320 7468 6520 636f 6e63 656e 7472 6174  s the concentrat
-00008b20: 696f 6e2e 0a20 2020 2023 204c 6574 2075  ion..    # Let u
-00008b30: 7320 7772 6974 650a 2020 2020 2320 2020  s write.    #   
-00008b40: 7720 3d20 6c6f 6320 2a20 7920 2f20 2832  w = loc * y / (2
-00008b50: 202a 2063 6f6e 6329 0a20 2020 2023 2054   * conc).    # T
-00008b60: 6865 6e20 7765 2063 616e 2065 7874 7261  hen we can extra
-00008b70: 6374 2074 6865 2063 6f6d 6d6f 6e20 6661  ct the common fa
-00008b80: 6374 6f72 2069 6e20 7468 6520 6c61 7374  ctor in the last
-00008b90: 2074 776f 2074 6572 6d73 2074 6f20 6f62   two terms to ob
-00008ba0: 7461 696e 0a20 2020 2023 2020 2078 203d  tain.    #   x =
-00008bb0: 206c 6f63 202b 206c 6f63 202a 2077 202a   loc + loc * w *
-00008bc0: 2028 3120 2d20 7371 7274 2832 202f 2077   (1 - sqrt(2 / w
-00008bd0: 202b 2031 2929 0a20 2020 2023 204e 6f77   + 1)).    # Now
-00008be0: 2077 6520 7365 6520 7468 6174 2074 6865   we see that the
-00008bf0: 2057 696b 6970 6564 6961 2066 6f72 6d75   Wikipedia formu
-00008c00: 6c61 2073 7566 6665 7273 2066 726f 6d20  la suffers from 
-00008c10: 6361 7461 7374 7270 6869 630a 2020 2020  catastrphic.    
-00008c20: 2320 6361 6e63 656c 6c61 7469 6f6e 2066  # cancellation f
-00008c30: 6f72 206c 6172 6765 2077 2028 652e 672e  or large w (e.g.
-00008c40: 2c20 6966 2063 6f6e 6320 3c3c 206c 6f63  , if conc << loc
-00008c50: 292e 0a20 2020 2023 0a20 2020 2023 2046  )..    #.    # F
-00008c60: 6f72 7475 6e61 7465 6c79 2c20 7765 2063  ortunately, we c
-00008c70: 616e 2066 6978 2074 6869 7320 6279 206d  an fix this by m
-00008c80: 756c 7469 706c 7969 6e67 2062 6f74 6820  ultiplying both 
-00008c90: 7369 6465 730a 2020 2020 2320 6279 2031  sides.    # by 1
-00008ca0: 202b 2073 7172 7428 3220 2f20 7720 2b20   + sqrt(2 / w + 
-00008cb0: 3129 2e20 2057 6520 6765 740a 2020 2020  1).  We get.    
-00008cc0: 2320 2020 7820 2a20 2831 202b 2073 7172  #   x * (1 + sqr
-00008cd0: 7428 3220 2f20 7720 2b20 3129 2920 3d0a  t(2 / w + 1)) =.
-00008ce0: 2020 2020 2320 2020 2020 3d20 6c6f 6320      #     = loc 
-00008cf0: 2a20 2831 202b 2073 7172 7428 3220 2f20  * (1 + sqrt(2 / 
-00008d00: 7720 2b20 3129 2920 2b20 6c6f 6320 2a20  w + 1)) + loc * 
-00008d10: 7720 2a20 2831 202d 2028 3220 2f20 7720  w * (1 - (2 / w 
-00008d20: 2b20 3129 290a 2020 2020 2320 2020 2020  + 1)).    #     
-00008d30: 3d20 6c6f 6320 2a20 2873 7172 7428 3220  = loc * (sqrt(2 
-00008d40: 2f20 7720 2b20 3129 202d 2031 290a 2020  / w + 1) - 1).  
-00008d50: 2020 2320 5468 6520 7465 726d 2073 7172    # The term sqr
-00008d60: 7428 3220 2f20 7720 2b20 3129 202b 2031  t(2 / w + 1) + 1
-00008d70: 206e 6f20 6c6f 6e67 6572 2070 7265 7365   no longer prese
-00008d80: 6e74 7320 6e75 6d65 7269 6361 6c0a 2020  nts numerical.  
-00008d90: 2020 2320 6469 6666 6963 756c 7469 6573    # difficulties
-00008da0: 2066 6f72 206c 6172 6765 2077 2c20 616e   for large w, an
-00008db0: 6420 7371 7274 2832 202f 2077 202b 2031  d sqrt(2 / w + 1
-00008dc0: 2920 2d20 3120 6973 206a 7573 740a 2020  ) - 1 is just.  
-00008dd0: 2020 2320 7371 7274 3170 6d31 2832 202f    # sqrt1pm1(2 /
-00008de0: 2077 292c 2077 6869 6368 2077 6520 6b6e   w), which we kn
-00008df0: 6f77 2068 6f77 2074 6f20 636f 6d70 7574  ow how to comput
-00008e00: 6520 6163 6375 7261 7465 6c79 2e0a 2020  e accurately..  
-00008e10: 2020 2320 5468 6973 206a 7573 7420 6c65    # This just le
-00008e20: 6176 6573 2074 6865 206d 6174 7465 7220  aves the matter 
-00008e30: 6f66 2073 6d61 6c6c 2077 2c20 7768 6572  of small w, wher
-00008e40: 6520 3220 2f20 7720 6d61 790a 2020 2020  e 2 / w may.    
-00008e50: 2320 6f76 6572 666c 6f77 2e20 2049 6e20  # overflow.  In 
-00008e60: 7468 6520 6c69 6d69 7420 6120 7720 2d3e  the limit a w ->
-00008e70: 2030 2c20 7820 2d3e 206c 6f63 2c20 736f   0, x -> loc, so
-00008e80: 2077 6520 6a75 7374 206d 6173 6b0a 2020   we just mask.  
-00008e90: 2020 2320 7468 6174 2063 6173 652e 0a20    # that case.. 
-00008ea0: 2020 2073 7172 7431 706d 315f 6172 6720     sqrt1pm1_arg 
-00008eb0: 3d20 3420 2a20 7363 616c 6520 2f20 286d  = 4 * scale / (m
-00008ec0: 6561 6e20 2a20 7361 6d70 6c65 645f 6368  ean * sampled_ch
-00008ed0: 6932 2920 2023 2032 202f 2077 2061 626f  i2)  # 2 / w abo
-00008ee0: 7665 0a20 2020 2073 6166 655f 7371 7274  ve.    safe_sqrt
-00008ef0: 3170 6d31 5f61 7267 203d 206a 6e70 2e77  1pm1_arg = jnp.w
-00008f00: 6865 7265 2873 7172 7431 706d 315f 6172  here(sqrt1pm1_ar
-00008f10: 6720 3c20 6e70 2e69 6e66 2c20 7371 7274  g < np.inf, sqrt
-00008f20: 3170 6d31 5f61 7267 2c20 312e 3029 0a20  1pm1_arg, 1.0). 
-00008f30: 2020 2064 656e 6f6d 696e 6174 6f72 203d     denominator =
-00008f40: 2031 2e30 202b 206a 6e70 2e73 7172 7428   1.0 + jnp.sqrt(
-00008f50: 7361 6665 5f73 7172 7431 706d 315f 6172  safe_sqrt1pm1_ar
-00008f60: 6720 2b20 312e 3029 0a20 2020 2072 6174  g + 1.0).    rat
-00008f70: 696f 203d 206a 6e70 2e65 7870 6d31 2830  io = jnp.expm1(0
-00008f80: 2e35 202a 206a 6e70 2e6c 6f67 3170 2873  .5 * jnp.log1p(s
-00008f90: 6166 655f 7371 7274 3170 6d31 5f61 7267  afe_sqrt1pm1_arg
-00008fa0: 2929 202f 2064 656e 6f6d 696e 6174 6f72  )) / denominator
-00008fb0: 0a20 2020 2073 616d 706c 6564 203d 206d  .    sampled = m
-00008fc0: 6561 6e20 2a20 6a6e 702e 7768 6572 6528  ean * jnp.where(
-00008fd0: 7371 7274 3170 6d31 5f61 7267 203c 206e  sqrt1pm1_arg < n
-00008fe0: 702e 696e 662c 2072 6174 696f 2c20 312e  p.inf, ratio, 1.
-00008ff0: 3029 2020 2320 7820 6162 6f76 650a 2020  0)  # x above.  
-00009000: 2020 7265 7320 3d20 6a6e 702e 7768 6572    res = jnp.wher
-00009010: 6528 7361 6d70 6c65 645f 756e 6966 6f72  e(sampled_unifor
-00009020: 6d20 3c3d 206d 6561 6e20 2f20 286d 6561  m <= mean / (mea
-00009030: 6e20 2b20 7361 6d70 6c65 6429 2c0a 2020  n + sampled),.  
-00009040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009050: 2020 7361 6d70 6c65 642c 0a20 2020 2020    sampled,.     
-00009060: 2020 2020 2020 2020 2020 2020 2020 206a                 j
-00009070: 6e70 2e73 7175 6172 6528 6d65 616e 2920  np.square(mean) 
-00009080: 2f20 7361 6d70 6c65 6429 0a20 2020 2072  / sampled).    r
-00009090: 6574 7572 6e20 5f72 6574 7572 6e28 7265  eturn _return(re
-000090a0: 7329 0a0a 2020 6465 6620 7428 7365 6c66  s)..  def t(self
-000090b0: 2c20 6466 2c20 7369 7a65 3d4e 6f6e 652c  , df, size=None,
-000090c0: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2020   key=None):.    
-000090d0: 6466 203d 205f 6368 6563 6b5f 7079 5f73  df = _check_py_s
-000090e0: 6571 285f 6173 5f6a 6178 5f61 7272 6179  eq(_as_jax_array
-000090f0: 2864 6629 290a 2020 2020 6966 2073 697a  (df)).    if siz
-00009100: 6520 6973 204e 6f6e 653a 0a20 2020 2020  e is None:.     
-00009110: 2073 697a 6520 3d20 6e70 2e73 6861 7065   size = np.shape
-00009120: 2864 6629 0a20 2020 2065 6c73 653a 0a20  (df).    else:. 
-00009130: 2020 2020 2073 697a 6520 3d20 5f73 697a       size = _siz
-00009140: 6532 7368 6170 6528 7369 7a65 290a 2020  e2shape(size).  
-00009150: 2020 2020 5f63 6865 636b 5f73 6861 7065      _check_shape
-00009160: 2822 7422 2c20 7369 7a65 2c20 6e70 2e73  ("t", size, np.s
-00009170: 6861 7065 2864 6629 290a 2020 2020 6966  hape(df)).    if
-00009180: 206b 6579 2069 7320 4e6f 6e65 3a0a 2020   key is None:.  
-00009190: 2020 2020 6b65 7973 203d 2073 656c 662e      keys = self.
-000091a0: 7370 6c69 745f 6b65 7973 2832 290a 2020  split_keys(2).  
-000091b0: 2020 656c 7365 3a0a 2020 2020 2020 6b65    else:.      ke
-000091c0: 7973 203d 206a 722e 7370 6c69 7428 5f66  ys = jr.split(_f
-000091d0: 6f72 6d61 6c69 7a65 5f6b 6579 286b 6579  ormalize_key(key
-000091e0: 292c 2032 290a 2020 2020 6e20 3d20 6a72  ), 2).    n = jr
-000091f0: 2e6e 6f72 6d61 6c28 6b65 7973 5b30 5d2c  .normal(keys[0],
-00009200: 2073 697a 6529 0a20 2020 2074 776f 203d   size).    two =
-00009210: 205f 636f 6e73 7428 6e2c 2032 290a 2020   _const(n, 2).  
-00009220: 2020 6861 6c66 5f64 6620 3d20 6c61 782e    half_df = lax.
-00009230: 6469 7628 6466 2c20 7477 6f29 0a20 2020  div(df, two).   
-00009240: 2067 203d 206a 722e 6761 6d6d 6128 6b65   g = jr.gamma(ke
-00009250: 7973 5b31 5d2c 2068 616c 665f 6466 2c20  ys[1], half_df, 
-00009260: 7369 7a65 290a 2020 2020 7220 3d20 6e20  size).    r = n 
-00009270: 2a20 6a6e 702e 7371 7274 2868 616c 665f  * jnp.sqrt(half_
-00009280: 6466 202f 2067 290a 2020 2020 7265 7475  df / g).    retu
-00009290: 726e 205f 7265 7475 726e 2872 290a 0a20  rn _return(r).. 
-000092a0: 2064 6566 206f 7274 686f 676f 6e61 6c28   def orthogonal(
-000092b0: 7365 6c66 2c20 6e3a 2069 6e74 2c20 7369  self, n: int, si
-000092c0: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
-000092d0: 6529 3a0a 2020 2020 6b65 7920 3d20 7365  e):.    key = se
-000092e0: 6c66 2e73 706c 6974 5f6b 6579 2829 2069  lf.split_key() i
-000092f0: 6620 6b65 7920 6973 204e 6f6e 6520 656c  f key is None el
-00009300: 7365 205f 666f 726d 616c 697a 655f 6b65  se _formalize_ke
-00009310: 7928 6b65 7929 0a20 2020 2073 697a 6520  y(key).    size 
-00009320: 3d20 5f73 697a 6532 7368 6170 6528 7369  = _size2shape(si
-00009330: 7a65 290a 2020 2020 5f63 6865 636b 5f73  ze).    _check_s
-00009340: 6861 7065 2822 6f72 7468 6f67 6f6e 616c  hape("orthogonal
-00009350: 222c 2073 697a 6529 0a20 2020 206e 203d  ", size).    n =
-00009360: 2063 6f72 652e 636f 6e63 7265 7465 5f6f   core.concrete_o
-00009370: 725f 6572 726f 7228 696e 6465 782c 206e  r_error(index, n
-00009380: 2c20 2254 6865 2065 7272 6f72 206f 6363  , "The error occ
-00009390: 7572 7265 6420 696e 206a 6178 2e72 616e  urred in jax.ran
-000093a0: 646f 6d2e 6f72 7468 6f67 6f6e 616c 2829  dom.orthogonal()
-000093b0: 2229 0a20 2020 207a 203d 206a 722e 6e6f  ").    z = jr.no
-000093c0: 726d 616c 286b 6579 2c20 7369 7a65 202b  rmal(key, size +
-000093d0: 2028 6e2c 206e 2929 0a20 2020 2071 2c20   (n, n)).    q, 
-000093e0: 7220 3d20 6a6e 702e 6c69 6e61 6c67 2e71  r = jnp.linalg.q
-000093f0: 7228 7a29 0a20 2020 2064 203d 206a 6e70  r(z).    d = jnp
-00009400: 2e64 6961 676f 6e61 6c28 722c 2030 2c20  .diagonal(r, 0, 
-00009410: 2d32 2c20 2d31 290a 2020 2020 7220 3d20  -2, -1).    r = 
-00009420: 7120 2a20 6a6e 702e 6578 7061 6e64 5f64  q * jnp.expand_d
-00009430: 696d 7328 6420 2f20 6162 7328 6429 2c20  ims(d / abs(d), 
-00009440: 2d32 290a 2020 2020 7265 7475 726e 205f  -2).    return _
-00009450: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
-00009460: 206e 6f6e 6365 6e74 7261 6c5f 6368 6973   noncentral_chis
-00009470: 7175 6172 6528 7365 6c66 2c20 6466 2c20  quare(self, df, 
-00009480: 6e6f 6e63 2c20 7369 7a65 3d4e 6f6e 652c  nonc, size=None,
-00009490: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2020   key=None):.    
-000094a0: 6466 203d 205f 6368 6563 6b5f 7079 5f73  df = _check_py_s
-000094b0: 6571 285f 6173 5f6a 6178 5f61 7272 6179  eq(_as_jax_array
-000094c0: 2864 6629 290a 2020 2020 6e6f 6e63 203d  (df)).    nonc =
-000094d0: 205f 6368 6563 6b5f 7079 5f73 6571 285f   _check_py_seq(_
-000094e0: 6173 5f6a 6178 5f61 7272 6179 286e 6f6e  as_jax_array(non
-000094f0: 6329 290a 2020 2020 6966 2073 697a 6520  c)).    if size 
-00009500: 6973 204e 6f6e 653a 0a20 2020 2020 2073  is None:.      s
-00009510: 697a 6520 3d20 6c61 782e 6272 6f61 6463  ize = lax.broadc
-00009520: 6173 745f 7368 6170 6573 286a 6e70 2e73  ast_shapes(jnp.s
-00009530: 6861 7065 2864 6629 2c20 6a6e 702e 7368  hape(df), jnp.sh
-00009540: 6170 6528 6e6f 6e63 2929 0a20 2020 2073  ape(nonc)).    s
-00009550: 697a 6520 3d20 5f73 697a 6532 7368 6170  ize = _size2shap
-00009560: 6528 7369 7a65 290a 2020 2020 6966 206b  e(size).    if k
-00009570: 6579 2069 7320 4e6f 6e65 3a0a 2020 2020  ey is None:.    
-00009580: 2020 6b65 7973 203d 2073 656c 662e 7370    keys = self.sp
-00009590: 6c69 745f 6b65 7973 2833 290a 2020 2020  lit_keys(3).    
-000095a0: 656c 7365 3a0a 2020 2020 2020 6b65 7973  else:.      keys
-000095b0: 203d 206a 722e 7370 6c69 7428 5f66 6f72   = jr.split(_for
-000095c0: 6d61 6c69 7a65 5f6b 6579 286b 6579 292c  malize_key(key),
-000095d0: 2033 290a 2020 2020 6920 3d20 6a72 2e70   3).    i = jr.p
-000095e0: 6f69 7373 6f6e 286b 6579 735b 305d 2c20  oisson(keys[0], 
-000095f0: 302e 3520 2a20 6e6f 6e63 2c20 7368 6170  0.5 * nonc, shap
-00009600: 653d 7369 7a65 290a 2020 2020 6e20 3d20  e=size).    n = 
-00009610: 6a72 2e6e 6f72 6d61 6c28 6b65 7973 5b31  jr.normal(keys[1
-00009620: 5d2c 2073 6861 7065 3d73 697a 6529 202b  ], shape=size) +
-00009630: 206a 6e70 2e73 7172 7428 6e6f 6e63 290a   jnp.sqrt(nonc).
-00009640: 2020 2020 636f 6e64 203d 206a 6e70 2e67      cond = jnp.g
-00009650: 7265 6174 6572 2864 662c 2031 2e30 290a  reater(df, 1.0).
-00009660: 2020 2020 6466 3220 3d20 6a6e 702e 7768      df2 = jnp.wh
-00009670: 6572 6528 636f 6e64 2c20 6466 202d 2031  ere(cond, df - 1
-00009680: 2e30 2c20 6466 202b 2032 2e30 202a 2069  .0, df + 2.0 * i
-00009690: 290a 2020 2020 6368 6932 203d 2032 2e30  ).    chi2 = 2.0
-000096a0: 202a 206a 722e 6761 6d6d 6128 6b65 7973   * jr.gamma(keys
-000096b0: 5b32 5d2c 2030 2e35 202a 2064 6632 2c20  [2], 0.5 * df2, 
-000096c0: 7368 6170 653d 7369 7a65 290a 2020 2020  shape=size).    
-000096d0: 7220 3d20 6a6e 702e 7768 6572 6528 636f  r = jnp.where(co
-000096e0: 6e64 2c20 6368 6932 202b 206e 202a 206e  nd, chi2 + n * n
-000096f0: 2c20 6368 6932 290a 2020 2020 7265 7475  , chi2).    retu
-00009700: 726e 205f 7265 7475 726e 2872 290a 0a20  rn _return(r).. 
-00009710: 2064 6566 206c 6f67 6761 6d6d 6128 7365   def loggamma(se
-00009720: 6c66 2c20 612c 2073 697a 653d 4e6f 6e65  lf, a, size=None
-00009730: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2020  , key=None):.   
-00009740: 206b 6579 203d 2073 656c 662e 7370 6c69   key = self.spli
-00009750: 745f 6b65 7928 2920 6966 206b 6579 2069  t_key() if key i
-00009760: 7320 4e6f 6e65 2065 6c73 6520 5f66 6f72  s None else _for
-00009770: 6d61 6c69 7a65 5f6b 6579 286b 6579 290a  malize_key(key).
-00009780: 2020 2020 6120 3d20 5f63 6865 636b 5f70      a = _check_p
-00009790: 795f 7365 7128 5f61 735f 6a61 785f 6172  y_seq(_as_jax_ar
-000097a0: 7261 7928 6129 290a 2020 2020 6966 2073  ray(a)).    if s
-000097b0: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
-000097c0: 2020 2073 697a 6520 3d20 6a6e 702e 7368     size = jnp.sh
-000097d0: 6170 6528 6129 0a20 2020 2072 203d 206a  ape(a).    r = j
-000097e0: 722e 6c6f 6767 616d 6d61 286b 6579 2c20  r.loggamma(key, 
-000097f0: 612c 2073 6861 7065 3d5f 7369 7a65 3273  a, shape=_size2s
-00009800: 6861 7065 2873 697a 6529 290a 2020 2020  hape(size)).    
-00009810: 7265 7475 726e 205f 7265 7475 726e 2872  return _return(r
-00009820: 290a 0a20 2064 6566 2063 6174 6567 6f72  )..  def categor
-00009830: 6963 616c 2873 656c 662c 206c 6f67 6974  ical(self, logit
-00009840: 732c 2061 7869 733a 2069 6e74 203d 202d  s, axis: int = -
-00009850: 312c 2073 697a 653d 4e6f 6e65 2c20 6b65  1, size=None, ke
-00009860: 793d 4e6f 6e65 293a 0a20 2020 206b 6579  y=None):.    key
-00009870: 203d 2073 656c 662e 7370 6c69 745f 6b65   = self.split_ke
-00009880: 7928 2920 6966 206b 6579 2069 7320 4e6f  y() if key is No
-00009890: 6e65 2065 6c73 6520 5f66 6f72 6d61 6c69  ne else _formali
-000098a0: 7a65 5f6b 6579 286b 6579 290a 2020 2020  ze_key(key).    
-000098b0: 6c6f 6769 7473 203d 205f 6368 6563 6b5f  logits = _check_
-000098c0: 7079 5f73 6571 285f 6173 5f6a 6178 5f61  py_seq(_as_jax_a
-000098d0: 7272 6179 286c 6f67 6974 7329 290a 2020  rray(logits)).  
-000098e0: 2020 6966 2073 697a 6520 6973 204e 6f6e    if size is Non
-000098f0: 653a 0a20 2020 2020 2073 697a 6520 3d20  e:.      size = 
-00009900: 6c69 7374 286a 6e70 2e73 6861 7065 286c  list(jnp.shape(l
-00009910: 6f67 6974 7329 290a 2020 2020 2020 7369  ogits)).      si
-00009920: 7a65 2e70 6f70 2861 7869 7329 0a20 2020  ze.pop(axis).   
-00009930: 2072 203d 206a 722e 6361 7465 676f 7269   r = jr.categori
-00009940: 6361 6c28 6b65 792c 206c 6f67 6974 732c  cal(key, logits,
-00009950: 2061 7869 733d 6178 6973 2c20 7368 6170   axis=axis, shap
-00009960: 653d 5f73 697a 6532 7368 6170 6528 7369  e=_size2shape(si
-00009970: 7a65 2929 0a20 2020 2072 6574 7572 6e20  ze)).    return 
-00009980: 5f72 6574 7572 6e28 7229 0a0a 2020 6465  _return(r)..  de
-00009990: 6620 7a69 7066 2873 656c 662c 2061 2c20  f zipf(self, a, 
-000099a0: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
-000099b0: 6f6e 6529 3a0a 2020 2020 6120 3d20 5f63  one):.    a = _c
-000099c0: 6865 636b 5f70 795f 7365 7128 5f61 735f  heck_py_seq(_as_
-000099d0: 6a61 785f 6172 7261 7928 6129 290a 2020  jax_array(a)).  
-000099e0: 2020 6966 2073 697a 6520 6973 204e 6f6e    if size is Non
-000099f0: 653a 0a20 2020 2020 2073 697a 6520 3d20  e:.      size = 
-00009a00: 6a6e 702e 7368 6170 6528 6129 0a20 2020  jnp.shape(a).   
-00009a10: 2072 203d 2063 616c 6c28 6c61 6d62 6461   r = call(lambda
-00009a20: 2078 3a20 6e70 2e72 616e 646f 6d2e 7a69   x: np.random.zi
-00009a30: 7066 2878 2c20 7369 7a65 292c 0a20 2020  pf(x, size),.   
-00009a40: 2020 2020 2020 2020 2020 612c 0a20 2020            a,.   
-00009a50: 2020 2020 2020 2020 2020 7265 7375 6c74            result
-00009a60: 5f73 6861 7065 3d6a 6178 2e53 6861 7065  _shape=jax.Shape
-00009a70: 4474 7970 6553 7472 7563 7428 7369 7a65  DtypeStruct(size
-00009a80: 2c20 6a6e 702e 696e 745f 2929 0a20 2020  , jnp.int_)).   
-00009a90: 2072 6574 7572 6e20 5f72 6574 7572 6e28   return _return(
-00009aa0: 7229 0a0a 2020 6465 6620 706f 7765 7228  r)..  def power(
-00009ab0: 7365 6c66 2c20 612c 2073 697a 653d 4e6f  self, a, size=No
-00009ac0: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
-00009ad0: 2020 2061 203d 205f 6368 6563 6b5f 7079     a = _check_py
-00009ae0: 5f73 6571 285f 6173 5f6a 6178 5f61 7272  _seq(_as_jax_arr
-00009af0: 6179 2861 2929 0a20 2020 2069 6620 7369  ay(a)).    if si
-00009b00: 7a65 2069 7320 4e6f 6e65 3a0a 2020 2020  ze is None:.    
-00009b10: 2020 7369 7a65 203d 206a 6e70 2e73 6861    size = jnp.sha
-00009b20: 7065 2861 290a 2020 2020 7369 7a65 203d  pe(a).    size =
-00009b30: 205f 7369 7a65 3273 6861 7065 2873 697a   _size2shape(siz
-00009b40: 6529 0a20 2020 2072 203d 2063 616c 6c28  e).    r = call(
-00009b50: 6c61 6d62 6461 2061 3a20 6e70 2e72 616e  lambda a: np.ran
-00009b60: 646f 6d2e 706f 7765 7228 613d 612c 2073  dom.power(a=a, s
-00009b70: 697a 653d 7369 7a65 292c 0a20 2020 2020  ize=size),.     
-00009b80: 2020 2020 2020 2020 612c 2072 6573 756c          a, resul
-00009b90: 745f 7368 6170 653d 6a61 782e 5368 6170  t_shape=jax.Shap
-00009ba0: 6544 7479 7065 5374 7275 6374 2873 697a  eDtypeStruct(siz
-00009bb0: 652c 206a 6e70 2e66 6c6f 6174 5f29 290a  e, jnp.float_)).
-00009bc0: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
-00009bd0: 726e 2872 290a 0a20 2064 6566 2066 2873  rn(r)..  def f(s
-00009be0: 656c 662c 2064 666e 756d 2c20 6466 6465  elf, dfnum, dfde
-00009bf0: 6e2c 2073 697a 653d 4e6f 6e65 2c20 6b65  n, size=None, ke
-00009c00: 793d 4e6f 6e65 293a 0a20 2020 2064 666e  y=None):.    dfn
-00009c10: 756d 203d 205f 6173 5f6a 6178 5f61 7272  um = _as_jax_arr
-00009c20: 6179 2864 666e 756d 290a 2020 2020 6466  ay(dfnum).    df
-00009c30: 6465 6e20 3d20 5f61 735f 6a61 785f 6172  den = _as_jax_ar
-00009c40: 7261 7928 6466 6465 6e29 0a20 2020 2064  ray(dfden).    d
-00009c50: 666e 756d 203d 205f 6368 6563 6b5f 7079  fnum = _check_py
-00009c60: 5f73 6571 2864 666e 756d 290a 2020 2020  _seq(dfnum).    
-00009c70: 6466 6465 6e20 3d20 5f63 6865 636b 5f70  dfden = _check_p
-00009c80: 795f 7365 7128 6466 6465 6e29 0a20 2020  y_seq(dfden).   
-00009c90: 2069 6620 7369 7a65 2069 7320 4e6f 6e65   if size is None
-00009ca0: 3a0a 2020 2020 2020 7369 7a65 203d 206a  :.      size = j
-00009cb0: 6e70 2e62 726f 6164 6361 7374 5f73 6861  np.broadcast_sha
-00009cc0: 7065 7328 6a6e 702e 7368 6170 6528 6466  pes(jnp.shape(df
-00009cd0: 6e75 6d29 2c20 6a6e 702e 7368 6170 6528  num), jnp.shape(
-00009ce0: 6466 6465 6e29 290a 2020 2020 7369 7a65  dfden)).    size
-00009cf0: 203d 205f 7369 7a65 3273 6861 7065 2873   = _size2shape(s
-00009d00: 697a 6529 0a20 2020 2064 203d 207b 2764  ize).    d = {'d
-00009d10: 666e 756d 273a 2064 666e 756d 2c20 2764  fnum': dfnum, 'd
-00009d20: 6664 656e 273a 2064 6664 656e 7d0a 2020  fden': dfden}.  
-00009d30: 2020 7220 3d20 6361 6c6c 286c 616d 6264    r = call(lambd
-00009d40: 6120 783a 206e 702e 7261 6e64 6f6d 2e66  a x: np.random.f
-00009d50: 2864 666e 756d 3d78 5b27 6466 6e75 6d27  (dfnum=x['dfnum'
-00009d60: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00009d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009d80: 2020 2020 2020 6466 6465 6e3d 785b 2764        dfden=x['d
-00009d90: 6664 656e 275d 2c0a 2020 2020 2020 2020  fden'],.        
-00009da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009db0: 2020 2020 2020 2020 2020 2073 697a 653d             size=
-00009dc0: 7369 7a65 292c 0a20 2020 2020 2020 2020  size),.         
-00009dd0: 2020 2020 642c 0a20 2020 2020 2020 2020      d,.         
-00009de0: 2020 2020 7265 7375 6c74 5f73 6861 7065      result_shape
-00009df0: 3d6a 6178 2e53 6861 7065 4474 7970 6553  =jax.ShapeDtypeS
-00009e00: 7472 7563 7428 7369 7a65 2c20 6a6e 702e  truct(size, jnp.
-00009e10: 666c 6f61 745f 2929 0a20 2020 2072 6574  float_)).    ret
-00009e20: 7572 6e20 5f72 6574 7572 6e28 7229 0a0a  urn _return(r)..
-00009e30: 2020 6465 6620 6879 7065 7267 656f 6d65    def hypergeome
-00009e40: 7472 6963 2873 656c 662c 206e 676f 6f64  tric(self, ngood
-00009e50: 2c20 6e62 6164 2c20 6e73 616d 706c 652c  , nbad, nsample,
-00009e60: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
-00009e70: 4e6f 6e65 293a 0a20 2020 206e 676f 6f64  None):.    ngood
-00009e80: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
-00009e90: 285f 6173 5f6a 6178 5f61 7272 6179 286e  (_as_jax_array(n
-00009ea0: 676f 6f64 2929 0a20 2020 206e 6261 6420  good)).    nbad 
-00009eb0: 3d20 5f63 6865 636b 5f70 795f 7365 7128  = _check_py_seq(
-00009ec0: 5f61 735f 6a61 785f 6172 7261 7928 6e62  _as_jax_array(nb
-00009ed0: 6164 2929 0a20 2020 206e 7361 6d70 6c65  ad)).    nsample
-00009ee0: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
-00009ef0: 285f 6173 5f6a 6178 5f61 7272 6179 286e  (_as_jax_array(n
-00009f00: 7361 6d70 6c65 2929 0a0a 2020 2020 6966  sample))..    if
-00009f10: 2073 697a 6520 6973 204e 6f6e 653a 0a20   size is None:. 
-00009f20: 2020 2020 2073 697a 6520 3d20 6c61 782e       size = lax.
-00009f30: 6272 6f61 6463 6173 745f 7368 6170 6573  broadcast_shapes
-00009f40: 286a 6e70 2e73 6861 7065 286e 676f 6f64  (jnp.shape(ngood
-00009f50: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
-00009f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009f70: 2020 2020 206a 6e70 2e73 6861 7065 286e       jnp.shape(n
-00009f80: 6261 6429 2c0a 2020 2020 2020 2020 2020  bad),.          
-00009f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009fa0: 2020 2020 2020 2020 6a6e 702e 7368 6170          jnp.shap
-00009fb0: 6528 6e73 616d 706c 6529 290a 2020 2020  e(nsample)).    
-00009fc0: 7369 7a65 203d 205f 7369 7a65 3273 6861  size = _size2sha
-00009fd0: 7065 2873 697a 6529 0a20 2020 2064 203d  pe(size).    d =
-00009fe0: 207b 276e 676f 6f64 273a 206e 676f 6f64   {'ngood': ngood
-00009ff0: 2c20 276e 6261 6427 3a20 6e62 6164 2c20  , 'nbad': nbad, 
-0000a000: 276e 7361 6d70 6c65 273a 206e 7361 6d70  'nsample': nsamp
-0000a010: 6c65 7d0a 2020 2020 7220 3d20 6361 6c6c  le}.    r = call
-0000a020: 286c 616d 6264 6120 783a 206e 702e 7261  (lambda x: np.ra
-0000a030: 6e64 6f6d 2e68 7970 6572 6765 6f6d 6574  ndom.hypergeomet
-0000a040: 7269 6328 6e67 6f6f 643d 785b 276e 676f  ric(ngood=x['ngo
-0000a050: 6f64 275d 2c0a 2020 2020 2020 2020 2020  od'],.          
-0000a060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a080: 2020 2020 2020 6e62 6164 3d78 5b27 6e62        nbad=x['nb
-0000a090: 6164 275d 2c0a 2020 2020 2020 2020 2020  ad'],.          
-0000a0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a0c0: 2020 2020 2020 6e73 616d 706c 653d 785b        nsample=x[
-0000a0d0: 276e 7361 6d70 6c65 275d 2c0a 2020 2020  'nsample'],.    
-0000a0e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a100: 2020 2020 2020 2020 2020 2020 7369 7a65              size
-0000a110: 3d73 697a 6529 2c0a 2020 2020 2020 2020  =size),.        
-0000a120: 2020 2020 2064 2c20 7265 7375 6c74 5f73       d, result_s
-0000a130: 6861 7065 3d6a 6178 2e53 6861 7065 4474  hape=jax.ShapeDt
-0000a140: 7970 6553 7472 7563 7428 7369 7a65 2c20  ypeStruct(size, 
-0000a150: 6a6e 702e 696e 745f 2929 0a20 2020 2072  jnp.int_)).    r
-0000a160: 6574 7572 6e20 5f72 6574 7572 6e28 7229  eturn _return(r)
-0000a170: 0a0a 2020 6465 6620 6c6f 6773 6572 6965  ..  def logserie
-0000a180: 7328 7365 6c66 2c20 702c 2073 697a 653d  s(self, p, size=
-0000a190: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
-0000a1a0: 0a20 2020 2070 203d 205f 6368 6563 6b5f  .    p = _check_
-0000a1b0: 7079 5f73 6571 285f 6173 5f6a 6178 5f61  py_seq(_as_jax_a
-0000a1c0: 7272 6179 2870 2929 0a20 2020 2069 6620  rray(p)).    if 
-0000a1d0: 7369 7a65 2069 7320 4e6f 6e65 3a0a 2020  size is None:.  
-0000a1e0: 2020 2020 7369 7a65 203d 206a 6e70 2e73      size = jnp.s
-0000a1f0: 6861 7065 2870 290a 2020 2020 7369 7a65  hape(p).    size
-0000a200: 203d 205f 7369 7a65 3273 6861 7065 2873   = _size2shape(s
-0000a210: 697a 6529 0a20 2020 2072 203d 2063 616c  ize).    r = cal
-0000a220: 6c28 6c61 6d62 6461 2070 3a20 6e70 2e72  l(lambda p: np.r
-0000a230: 616e 646f 6d2e 6c6f 6773 6572 6965 7328  andom.logseries(
-0000a240: 703d 702c 2073 697a 653d 7369 7a65 292c  p=p, size=size),
-0000a250: 0a20 2020 2020 2020 2020 2020 2020 702c  .             p,
-0000a260: 2072 6573 756c 745f 7368 6170 653d 6a61   result_shape=ja
-0000a270: 782e 5368 6170 6544 7479 7065 5374 7275  x.ShapeDtypeStru
-0000a280: 6374 2873 697a 652c 206a 6e70 2e69 6e74  ct(size, jnp.int
-0000a290: 5f29 290a 2020 2020 7265 7475 726e 205f  _)).    return _
-0000a2a0: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
-0000a2b0: 206e 6f6e 6365 6e74 7261 6c5f 6628 7365   noncentral_f(se
-0000a2c0: 6c66 2c20 6466 6e75 6d2c 2064 6664 656e  lf, dfnum, dfden
-0000a2d0: 2c20 6e6f 6e63 2c20 7369 7a65 3d4e 6f6e  , nonc, size=Non
-0000a2e0: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
-0000a2f0: 2020 6466 6e75 6d20 3d20 5f63 6865 636b    dfnum = _check
-0000a300: 5f70 795f 7365 7128 5f61 735f 6a61 785f  _py_seq(_as_jax_
-0000a310: 6172 7261 7928 6466 6e75 6d29 290a 2020  array(dfnum)).  
-0000a320: 2020 6466 6465 6e20 3d20 5f63 6865 636b    dfden = _check
-0000a330: 5f70 795f 7365 7128 5f61 735f 6a61 785f  _py_seq(_as_jax_
-0000a340: 6172 7261 7928 6466 6465 6e29 290a 2020  array(dfden)).  
-0000a350: 2020 6e6f 6e63 203d 205f 6368 6563 6b5f    nonc = _check_
-0000a360: 7079 5f73 6571 285f 6173 5f6a 6178 5f61  py_seq(_as_jax_a
-0000a370: 7272 6179 286e 6f6e 6329 290a 2020 2020  rray(nonc)).    
-0000a380: 6966 2073 697a 6520 6973 204e 6f6e 653a  if size is None:
-0000a390: 0a20 2020 2020 2073 697a 6520 3d20 6c61  .      size = la
-0000a3a0: 782e 6272 6f61 6463 6173 745f 7368 6170  x.broadcast_shap
-0000a3b0: 6573 286a 6e70 2e73 6861 7065 2864 666e  es(jnp.shape(dfn
-0000a3c0: 756d 292c 0a20 2020 2020 2020 2020 2020  um),.           
-0000a3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a3e0: 2020 2020 2020 206a 6e70 2e73 6861 7065         jnp.shape
-0000a3f0: 2864 6664 656e 292c 0a20 2020 2020 2020  (dfden),.       
-0000a400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a410: 2020 2020 2020 2020 2020 206a 6e70 2e73             jnp.s
-0000a420: 6861 7065 286e 6f6e 6329 290a 2020 2020  hape(nonc)).    
-0000a430: 7369 7a65 203d 205f 7369 7a65 3273 6861  size = _size2sha
-0000a440: 7065 2873 697a 6529 0a20 2020 2064 203d  pe(size).    d =
-0000a450: 207b 2764 666e 756d 273a 2064 666e 756d   {'dfnum': dfnum
-0000a460: 2c20 2764 6664 656e 273a 2064 6664 656e  , 'dfden': dfden
-0000a470: 2c20 276e 6f6e 6327 3a20 6e6f 6e63 7d0a  , 'nonc': nonc}.
-0000a480: 2020 2020 7220 3d20 6361 6c6c 286c 616d      r = call(lam
-0000a490: 6264 6120 783a 206e 702e 7261 6e64 6f6d  bda x: np.random
-0000a4a0: 2e6e 6f6e 6365 6e74 7261 6c5f 6628 6466  .noncentral_f(df
-0000a4b0: 6e75 6d3d 785b 2764 666e 756d 275d 2c0a  num=x['dfnum'],.
-0000a4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a4e0: 2020 2020 2020 2020 2020 2020 2020 6466                df
-0000a4f0: 6465 6e3d 785b 2764 6664 656e 275d 2c0a  den=x['dfden'],.
-0000a500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a520: 2020 2020 2020 2020 2020 2020 2020 6e6f                no
-0000a530: 6e63 3d78 5b27 6e6f 6e63 275d 2c0a 2020  nc=x['nonc'],.  
-0000a540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a560: 2020 2020 2020 2020 2020 2020 7369 7a65              size
-0000a570: 3d73 697a 6529 2c0a 2020 2020 2020 2020  =size),.        
-0000a580: 2020 2020 2064 2c20 7265 7375 6c74 5f73       d, result_s
-0000a590: 6861 7065 3d6a 6178 2e53 6861 7065 4474  hape=jax.ShapeDt
-0000a5a0: 7970 6553 7472 7563 7428 7369 7a65 2c20  ypeStruct(size, 
-0000a5b0: 6a6e 702e 666c 6f61 745f 2929 0a20 2020  jnp.float_)).   
-0000a5c0: 2072 6574 7572 6e20 5f72 6574 7572 6e28   return _return(
-0000a5d0: 7229 0a0a 2020 2320 5079 546f 7263 6820  r)..  # PyTorch 
-0000a5e0: 636f 6d70 6174 6962 696c 6974 7920 230a  compatibility #.
-0000a5f0: 2020 2320 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d    # ------------
-0000a600: 2d2d 2d2d 2d2d 2d2d 2d20 230a 0a20 2064  --------- #..  d
-0000a610: 6566 2072 616e 645f 6c69 6b65 2873 656c  ef rand_like(sel
-0000a620: 662c 2069 6e70 7574 2c20 2a2c 2064 7479  f, input, *, dty
-0000a630: 7065 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  pe=None, key=Non
-0000a640: 6529 3a0a 2020 2020 2222 2252 6574 7572  e):.    """Retur
-0000a650: 6e73 2061 2074 656e 736f 7220 7769 7468  ns a tensor with
-0000a660: 2074 6865 2073 616d 6520 7369 7a65 2061   the same size a
-0000a670: 7320 696e 7075 7420 7468 6174 2069 7320  s input that is 
-0000a680: 6669 6c6c 6564 2077 6974 6820 7261 6e64  filled with rand
-0000a690: 6f6d 0a20 2020 206e 756d 6265 7273 2066  om.    numbers f
-0000a6a0: 726f 6d20 6120 756e 6966 6f72 6d20 6469  rom a uniform di
-0000a6b0: 7374 7269 6275 7469 6f6e 206f 6e20 7468  stribution on th
-0000a6c0: 6520 696e 7465 7276 616c 2060 605b 302c  e interval ``[0,
-0000a6d0: 2031 2960 602e 0a0a 2020 2020 4172 6773   1)``...    Args
-0000a6e0: 3a0a 2020 2020 2020 696e 7075 743a 2020  :.      input:  
-0000a6f0: 7468 6520 6060 7369 7a65 6060 206f 6620  the ``size`` of 
-0000a700: 696e 7075 7420 7769 6c6c 2064 6574 6572  input will deter
-0000a710: 6d69 6e65 2073 697a 6520 6f66 2074 6865  mine size of the
-0000a720: 206f 7574 7075 7420 7465 6e73 6f72 2e0a   output tensor..
-0000a730: 2020 2020 2020 6474 7970 653a 2020 7468        dtype:  th
-0000a740: 6520 6465 7369 7265 6420 6461 7461 2074  e desired data t
-0000a750: 7970 6520 6f66 2072 6574 7572 6e65 6420  ype of returned 
-0000a760: 5465 6e73 6f72 2e20 4465 6661 756c 743a  Tensor. Default:
-0000a770: 2069 6620 6060 4e6f 6e65 6060 2c20 6465   if ``None``, de
-0000a780: 6661 756c 7473 2074 6f20 7468 6520 6474  faults to the dt
-0000a790: 7970 6520 6f66 2069 6e70 7574 2e0a 2020  ype of input..  
-0000a7a0: 2020 2020 6b65 793a 2074 6865 2073 6565      key: the see
-0000a7b0: 6420 6f72 206b 6579 2066 6f72 2074 6865  d or key for the
-0000a7c0: 2072 616e 646f 6d2e 0a0a 2020 2020 5265   random...    Re
-0000a7d0: 7475 726e 733a 0a20 2020 2020 2054 6865  turns:.      The
-0000a7e0: 2072 616e 646f 6d20 6461 7461 2e0a 2020   random data..  
-0000a7f0: 2020 2222 220a 2020 2020 7265 7475 726e    """.    return
-0000a800: 2073 656c 662e 7261 6e64 6f6d 2873 6861   self.random(sha
-0000a810: 7065 2869 6e70 7574 292c 206b 6579 3d6b  pe(input), key=k
-0000a820: 6579 292e 6173 7479 7065 2864 7479 7065  ey).astype(dtype
-0000a830: 290a 0a20 2064 6566 2072 616e 646e 5f6c  )..  def randn_l
-0000a840: 696b 6528 7365 6c66 2c20 696e 7075 742c  ike(self, input,
-0000a850: 202a 2c20 6474 7970 653d 4e6f 6e65 2c20   *, dtype=None, 
-0000a860: 6b65 793d 4e6f 6e65 293a 0a20 2020 2022  key=None):.    "
-0000a870: 2222 5265 7475 726e 7320 6120 7465 6e73  ""Returns a tens
-0000a880: 6f72 2077 6974 6820 7468 6520 7361 6d65  or with the same
-0000a890: 2073 697a 6520 6173 2060 6069 6e70 7574   size as ``input
-0000a8a0: 6060 2074 6861 7420 6973 2066 696c 6c65  `` that is fille
-0000a8b0: 6420 7769 7468 0a20 2020 2072 616e 646f  d with.    rando
-0000a8c0: 6d20 6e75 6d62 6572 7320 6672 6f6d 2061  m numbers from a
-0000a8d0: 206e 6f72 6d61 6c20 6469 7374 7269 6275   normal distribu
-0000a8e0: 7469 6f6e 2077 6974 6820 6d65 616e 2030  tion with mean 0
-0000a8f0: 2061 6e64 2076 6172 6961 6e63 6520 312e   and variance 1.
-0000a900: 0a0a 2020 2020 4172 6773 3a0a 2020 2020  ..    Args:.    
-0000a910: 2020 696e 7075 743a 2020 7468 6520 6060    input:  the ``
-0000a920: 7369 7a65 6060 206f 6620 696e 7075 7420  size`` of input 
-0000a930: 7769 6c6c 2064 6574 6572 6d69 6e65 2073  will determine s
-0000a940: 697a 6520 6f66 2074 6865 206f 7574 7075  ize of the outpu
-0000a950: 7420 7465 6e73 6f72 2e0a 2020 2020 2020  t tensor..      
-0000a960: 6474 7970 653a 2020 7468 6520 6465 7369  dtype:  the desi
-0000a970: 7265 6420 6461 7461 2074 7970 6520 6f66  red data type of
-0000a980: 2072 6574 7572 6e65 6420 5465 6e73 6f72   returned Tensor
-0000a990: 2e20 4465 6661 756c 743a 2069 6620 6060  . Default: if ``
-0000a9a0: 4e6f 6e65 6060 2c20 6465 6661 756c 7473  None``, defaults
-0000a9b0: 2074 6f20 7468 6520 6474 7970 6520 6f66   to the dtype of
-0000a9c0: 2069 6e70 7574 2e0a 2020 2020 2020 6b65   input..      ke
-0000a9d0: 793a 2074 6865 2073 6565 6420 6f72 206b  y: the seed or k
-0000a9e0: 6579 2066 6f72 2074 6865 2072 616e 646f  ey for the rando
-0000a9f0: 6d2e 0a0a 2020 2020 5265 7475 726e 733a  m...    Returns:
-0000aa00: 0a20 2020 2020 2054 6865 2072 616e 646f  .      The rando
-0000aa10: 6d20 6461 7461 2e0a 2020 2020 2222 220a  m data..    """.
-0000aa20: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-0000aa30: 7261 6e64 6e28 2a73 6861 7065 2869 6e70  randn(*shape(inp
-0000aa40: 7574 292c 206b 6579 3d6b 6579 292e 6173  ut), key=key).as
-0000aa50: 7479 7065 2864 7479 7065 290a 0a20 2064  type(dtype)..  d
-0000aa60: 6566 2072 616e 6469 6e74 5f6c 696b 6528  ef randint_like(
-0000aa70: 7365 6c66 2c20 696e 7075 742c 206c 6f77  self, input, low
-0000aa80: 3d30 2c20 6869 6768 3d4e 6f6e 652c 202a  =0, high=None, *
-0000aa90: 2c20 6474 7970 653d 4e6f 6e65 2c20 6b65  , dtype=None, ke
-0000aaa0: 793d 4e6f 6e65 293a 0a20 2020 2069 6620  y=None):.    if 
-0000aab0: 6869 6768 2069 7320 4e6f 6e65 3a0a 2020  high is None:.  
-0000aac0: 2020 2020 6869 6768 203d 206d 6178 2869      high = max(i
-0000aad0: 6e70 7574 290a 2020 2020 7265 7475 726e  nput).    return
-0000aae0: 2073 656c 662e 7261 6e64 696e 7428 6c6f   self.randint(lo
-0000aaf0: 772c 2068 6967 683d 6869 6768 2c20 7369  w, high=high, si
-0000ab00: 7a65 3d73 6861 7065 2869 6e70 7574 292c  ze=shape(input),
-0000ab10: 2064 7479 7065 3d64 7479 7065 2c20 6b65   dtype=dtype, ke
-0000ab20: 793d 6b65 7929 0a0a 0a23 2061 6c69 6173  y=key)...# alias
-0000ab30: 0a47 656e 6572 6174 6f72 203d 2052 616e  .Generator = Ran
-0000ab40: 646f 6d53 7461 7465 0a0a 2320 6465 6661  domState..# defa
-0000ab50: 756c 7420 7261 6e64 6f6d 2067 656e 6572  ult random gener
-0000ab60: 6174 6f72 0a5f 5f61 203d 2041 7272 6179  ator.__a = Array
-0000ab70: 284e 6f6e 6529 0a5f 5f61 2e5f 7661 6c75  (None).__a._valu
-0000ab80: 6520 3d20 6e70 2e72 616e 646f 6d2e 7261  e = np.random.ra
-0000ab90: 6e64 696e 7428 302c 2031 3030 3030 2c20  ndint(0, 10000, 
-0000aba0: 7369 7a65 3d32 2c20 6474 7970 653d 6e70  size=2, dtype=np
-0000abb0: 2e75 696e 7433 3229 0a44 4546 4155 4c54  .uint32).DEFAULT
-0000abc0: 203d 2052 616e 646f 6d53 7461 7465 285f   = RandomState(_
-0000abd0: 5f61 290a 6465 6c20 5f5f 610a 0a0a 6465  _a).del __a...de
-0000abe0: 6620 7370 6c69 745f 6b65 7928 293a 0a20  f split_key():. 
-0000abf0: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
-0000ac00: 7370 6c69 745f 6b65 7928 290a 0a0a 6465  split_key()...de
-0000ac10: 6620 636c 6f6e 655f 726e 6728 7365 6564  f clone_rng(seed
-0000ac20: 5f6f 725f 6b65 793d 4e6f 6e65 2c20 636c  _or_key=None, cl
-0000ac30: 6f6e 653a 2062 6f6f 6c20 3d20 5472 7565  one: bool = True
-0000ac40: 2920 2d3e 2052 616e 646f 6d53 7461 7465  ) -> RandomState
-0000ac50: 3a0a 2020 6966 2073 6565 645f 6f72 5f6b  :.  if seed_or_k
-0000ac60: 6579 2069 7320 4e6f 6e65 3a0a 2020 2020  ey is None:.    
-0000ac70: 7265 7475 726e 2044 4546 4155 4c54 2e63  return DEFAULT.c
-0000ac80: 6c6f 6e65 2829 2069 6620 636c 6f6e 6520  lone() if clone 
-0000ac90: 656c 7365 2044 4546 4155 4c54 0a20 2065  else DEFAULT.  e
-0000aca0: 6c73 653a 0a20 2020 2072 6574 7572 6e20  lse:.    return 
-0000acb0: 5261 6e64 6f6d 5374 6174 6528 7365 6564  RandomState(seed
-0000acc0: 5f6f 725f 6b65 7929 0a0a 0a64 6566 2064  _or_key)...def d
-0000acd0: 6566 6175 6c74 5f72 6e67 2873 6565 645f  efault_rng(seed_
-0000ace0: 6f72 5f6b 6579 3d4e 6f6e 652c 2063 6c6f  or_key=None, clo
-0000acf0: 6e65 3d54 7275 6529 202d 3e20 5261 6e64  ne=True) -> Rand
-0000ad00: 6f6d 5374 6174 653a 0a20 2069 6620 7365  omState:.  if se
-0000ad10: 6564 5f6f 725f 6b65 7920 6973 204e 6f6e  ed_or_key is Non
-0000ad20: 653a 0a20 2020 2072 6574 7572 6e20 4445  e:.    return DE
-0000ad30: 4641 554c 542e 636c 6f6e 6528 2920 6966  FAULT.clone() if
-0000ad40: 2063 6c6f 6e65 2065 6c73 6520 4445 4641   clone else DEFA
-0000ad50: 554c 540a 2020 656c 7365 3a0a 2020 2020  ULT.  else:.    
-0000ad60: 7265 7475 726e 2052 616e 646f 6d53 7461  return RandomSta
-0000ad70: 7465 2873 6565 645f 6f72 5f6b 6579 290a  te(seed_or_key).
-0000ad80: 0a0a 6465 6620 7365 6564 2873 6565 643a  ..def seed(seed:
-0000ad90: 2069 6e74 203d 204e 6f6e 6529 3a0a 2020   int = None):.  
-0000ada0: 2222 2253 6574 7320 6120 6e65 7720 7261  """Sets a new ra
-0000adb0: 6e64 6f6d 2073 6565 642e 0a0a 2020 5061  ndom seed...  Pa
-0000adc0: 7261 6d65 7465 7273 0a20 202d 2d2d 2d2d  rameters.  -----
-0000add0: 2d2d 2d2d 2d0a 2020 7365 6564 3a20 696e  -----.  seed: in
-0000ade0: 742c 206f 7074 696f 6e61 6c0a 2020 2020  t, optional.    
-0000adf0: 5468 6520 7261 6e64 6f6d 2073 6565 642e  The random seed.
-0000ae00: 0a20 2022 2222 0a20 2077 6974 6820 6a61  .  """.  with ja
-0000ae10: 782e 656e 7375 7265 5f63 6f6d 7069 6c65  x.ensure_compile
-0000ae20: 5f74 696d 655f 6576 616c 2829 3a0a 2020  _time_eval():.  
-0000ae30: 2020 6966 2073 6565 6420 6973 204e 6f6e    if seed is Non
-0000ae40: 653a 0a20 2020 2020 2073 6565 6420 3d20  e:.      seed = 
-0000ae50: 6e70 2e72 616e 646f 6d2e 7261 6e64 696e  np.random.randin
-0000ae60: 7428 302c 2031 3030 3030 3029 0a20 2020  t(0, 100000).   
-0000ae70: 206e 702e 7261 6e64 6f6d 2e73 6565 6428   np.random.seed(
-0000ae80: 7365 6564 290a 2020 4445 4641 554c 542e  seed).  DEFAULT.
-0000ae90: 7365 6564 2873 6565 6429 0a0a 0a64 6566  seed(seed)...def
-0000aea0: 2072 616e 6428 2a64 6e2c 206b 6579 3d4e   rand(*dn, key=N
-0000aeb0: 6f6e 6529 3a0a 2020 7222 2222 5261 6e64  one):.  r"""Rand
-0000aec0: 6f6d 2076 616c 7565 7320 696e 2061 2067  om values in a g
-0000aed0: 6976 656e 2073 6861 7065 2e0a 0a20 202e  iven shape...  .
-0000aee0: 2e20 6e6f 7465 3a3a 0a20 2020 2020 2054  . note::.      T
-0000aef0: 6869 7320 6973 2061 2063 6f6e 7665 6e69  his is a conveni
-0000af00: 656e 6365 2066 756e 6374 696f 6e20 666f  ence function fo
-0000af10: 7220 7573 6572 7320 706f 7274 696e 6720  r users porting 
-0000af20: 636f 6465 2066 726f 6d20 4d61 746c 6162  code from Matlab
-0000af30: 2c0a 2020 2020 2020 616e 6420 7772 6170  ,.      and wrap
-0000af40: 7320 6072 616e 646f 6d5f 7361 6d70 6c65  s `random_sample
-0000af50: 602e 2054 6861 7420 6675 6e63 7469 6f6e  `. That function
-0000af60: 2074 616b 6573 2061 0a20 2020 2020 2074   takes a.      t
-0000af70: 7570 6c65 2074 6f20 7370 6563 6966 7920  uple to specify 
-0000af80: 7468 6520 7369 7a65 206f 6620 7468 6520  the size of the 
-0000af90: 6f75 7470 7574 2c20 7768 6963 6820 6973  output, which is
-0000afa0: 2063 6f6e 7369 7374 656e 7420 7769 7468   consistent with
-0000afb0: 0a20 2020 2020 206f 7468 6572 204e 756d  .      other Num
-0000afc0: 5079 2066 756e 6374 696f 6e73 206c 696b  Py functions lik
-0000afd0: 6520 606e 756d 7079 2e7a 6572 6f73 6020  e `numpy.zeros` 
-0000afe0: 616e 6420 606e 756d 7079 2e6f 6e65 7360  and `numpy.ones`
-0000aff0: 2e0a 0a20 2043 7265 6174 6520 616e 2061  ...  Create an a
-0000b000: 7272 6179 206f 6620 7468 6520 6769 7665  rray of the give
-0000b010: 6e20 7368 6170 6520 616e 6420 706f 7075  n shape and popu
-0000b020: 6c61 7465 2069 7420 7769 7468 0a20 2072  late it with.  r
-0000b030: 616e 646f 6d20 7361 6d70 6c65 7320 6672  andom samples fr
-0000b040: 6f6d 2061 2075 6e69 666f 726d 2064 6973  om a uniform dis
-0000b050: 7472 6962 7574 696f 6e0a 2020 6f76 6572  tribution.  over
-0000b060: 2060 605b 302c 2031 2960 602e 0a0a 2020   ``[0, 1)``...  
-0000b070: 5061 7261 6d65 7465 7273 0a20 202d 2d2d  Parameters.  ---
-0000b080: 2d2d 2d2d 2d2d 2d0a 2020 6430 2c20 6431  -------.  d0, d1
-0000b090: 2c20 2e2e 2e2c 2064 6e20 3a20 696e 742c  , ..., dn : int,
-0000b0a0: 206f 7074 696f 6e61 6c0a 2020 2020 2020   optional.      
-0000b0b0: 5468 6520 6469 6d65 6e73 696f 6e73 206f  The dimensions o
-0000b0c0: 6620 7468 6520 7265 7475 726e 6564 2061  f the returned a
-0000b0d0: 7272 6179 2c20 6d75 7374 2062 6520 6e6f  rray, must be no
-0000b0e0: 6e2d 6e65 6761 7469 7665 2e0a 2020 2020  n-negative..    
-0000b0f0: 2020 4966 206e 6f20 6172 6775 6d65 6e74    If no argument
-0000b100: 2069 7320 6769 7665 6e20 6120 7369 6e67   is given a sing
-0000b110: 6c65 2050 7974 686f 6e20 666c 6f61 7420  le Python float 
-0000b120: 6973 2072 6574 7572 6e65 642e 0a0a 2020  is returned...  
-0000b130: 5265 7475 726e 730a 2020 2d2d 2d2d 2d2d  Returns.  ------
-0000b140: 2d0a 2020 6f75 7420 3a20 6e64 6172 7261  -.  out : ndarra
-0000b150: 792c 2073 6861 7065 2060 6028 6430 2c20  y, shape ``(d0, 
-0000b160: 6431 2c20 2e2e 2e2c 2064 6e29 6060 0a20  d1, ..., dn)``. 
-0000b170: 2020 2020 2052 616e 646f 6d20 7661 6c75       Random valu
-0000b180: 6573 2e0a 0a20 2053 6565 2041 6c73 6f0a  es...  See Also.
-0000b190: 2020 2d2d 2d2d 2d2d 2d2d 0a20 2072 616e    --------.  ran
-0000b1a0: 646f 6d0a 0a20 2045 7861 6d70 6c65 730a  dom..  Examples.
-0000b1b0: 2020 2d2d 2d2d 2d2d 2d2d 0a20 203e 3e3e    --------.  >>>
-0000b1c0: 2062 7261 696e 7079 2e6d 6174 682e 7261   brainpy.math.ra
-0000b1d0: 6e64 6f6d 2e72 616e 6428 332c 3229 0a20  ndom.rand(3,2). 
-0000b1e0: 2061 7272 6179 285b 5b20 302e 3134 3032   array([[ 0.1402
-0000b1f0: 3234 3731 2c20 2030 2e39 3633 3630 3631  2471,  0.9636061
-0000b200: 385d 2c20 2023 7261 6e64 6f6d 0a20 2020  8],  #random.   
-0000b210: 2020 2020 2020 5b20 302e 3337 3630 3130        [ 0.376010
-0000b220: 3332 2c20 2030 2e32 3535 3238 3431 315d  32,  0.25528411]
-0000b230: 2c20 2023 7261 6e64 6f6d 0a20 2020 2020  ,  #random.     
-0000b240: 2020 2020 5b20 302e 3439 3331 3330 3439      [ 0.49313049
-0000b250: 2c20 2030 2e39 3439 3039 3837 385d 5d29  ,  0.94909878]])
-0000b260: 2023 7261 6e64 6f6d 0a20 2022 2222 0a20   #random.  """. 
-0000b270: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
-0000b280: 7261 6e64 282a 646e 2c20 6b65 793d 6b65  rand(*dn, key=ke
-0000b290: 7929 0a0a 0a64 6566 2072 616e 6469 6e74  y)...def randint
-0000b2a0: 286c 6f77 2c20 6869 6768 3d4e 6f6e 652c  (low, high=None,
-0000b2b0: 2073 697a 653d 4e6f 6e65 2c20 6474 7970   size=None, dtyp
-0000b2c0: 653d 6a6e 702e 696e 745f 2c20 6b65 793d  e=jnp.int_, key=
-0000b2d0: 4e6f 6e65 293a 0a20 2072 2222 2252 6574  None):.  r"""Ret
-0000b2e0: 7572 6e20 7261 6e64 6f6d 2069 6e74 6567  urn random integ
-0000b2f0: 6572 7320 6672 6f6d 2060 6c6f 7760 2028  ers from `low` (
-0000b300: 696e 636c 7573 6976 6529 2074 6f20 6068  inclusive) to `h
-0000b310: 6967 6860 2028 6578 636c 7573 6976 6529  igh` (exclusive)
-0000b320: 2e0a 0a20 2052 6574 7572 6e20 7261 6e64  ...  Return rand
-0000b330: 6f6d 2069 6e74 6567 6572 7320 6672 6f6d  om integers from
-0000b340: 2074 6865 2022 6469 7363 7265 7465 2075   the "discrete u
-0000b350: 6e69 666f 726d 2220 6469 7374 7269 6275  niform" distribu
-0000b360: 7469 6f6e 206f 660a 2020 7468 6520 7370  tion of.  the sp
-0000b370: 6563 6966 6965 6420 6474 7970 6520 696e  ecified dtype in
-0000b380: 2074 6865 2022 6861 6c66 2d6f 7065 6e22   the "half-open"
-0000b390: 2069 6e74 6572 7661 6c20 5b60 6c6f 7760   interval [`low`
-0000b3a0: 2c20 6068 6967 6860 292e 2049 660a 2020  , `high`). If.  
-0000b3b0: 6068 6967 6860 2069 7320 4e6f 6e65 2028  `high` is None (
-0000b3c0: 7468 6520 6465 6661 756c 7429 2c20 7468  the default), th
-0000b3d0: 656e 2072 6573 756c 7473 2061 7265 2066  en results are f
-0000b3e0: 726f 6d20 5b30 2c20 606c 6f77 6029 2e0a  rom [0, `low`)..
-0000b3f0: 0a20 2050 6172 616d 6574 6572 730a 2020  .  Parameters.  
-0000b400: 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 206c 6f77  ----------.  low
-0000b410: 203a 2069 6e74 206f 7220 6172 7261 792d   : int or array-
-0000b420: 6c69 6b65 206f 6620 696e 7473 0a20 2020  like of ints.   
-0000b430: 2020 204c 6f77 6573 7420 2873 6967 6e65     Lowest (signe
-0000b440: 6429 2069 6e74 6567 6572 7320 746f 2062  d) integers to b
-0000b450: 6520 6472 6177 6e20 6672 6f6d 2074 6865  e drawn from the
-0000b460: 2064 6973 7472 6962 7574 696f 6e20 2875   distribution (u
-0000b470: 6e6c 6573 730a 2020 2020 2020 6060 6869  nless.      ``hi
-0000b480: 6768 3d4e 6f6e 6560 602c 2069 6e20 7768  gh=None``, in wh
-0000b490: 6963 6820 6361 7365 2074 6869 7320 7061  ich case this pa
-0000b4a0: 7261 6d65 7465 7220 6973 206f 6e65 2061  rameter is one a
-0000b4b0: 626f 7665 2074 6865 0a20 2020 2020 202a  bove the.      *
-0000b4c0: 6869 6768 6573 742a 2073 7563 6820 696e  highest* such in
-0000b4d0: 7465 6765 7229 2e0a 2020 6869 6768 203a  teger)..  high :
-0000b4e0: 2069 6e74 206f 7220 6172 7261 792d 6c69   int or array-li
-0000b4f0: 6b65 206f 6620 696e 7473 2c20 6f70 7469  ke of ints, opti
-0000b500: 6f6e 616c 0a20 2020 2020 2049 6620 7072  onal.      If pr
-0000b510: 6f76 6964 6564 2c20 6f6e 6520 6162 6f76  ovided, one abov
-0000b520: 6520 7468 6520 6c61 7267 6573 7420 2873  e the largest (s
-0000b530: 6967 6e65 6429 2069 6e74 6567 6572 2074  igned) integer t
-0000b540: 6f20 6265 2064 7261 776e 0a20 2020 2020  o be drawn.     
-0000b550: 2066 726f 6d20 7468 6520 6469 7374 7269   from the distri
-0000b560: 6275 7469 6f6e 2028 7365 6520 6162 6f76  bution (see abov
-0000b570: 6520 666f 7220 6265 6861 7669 6f72 2069  e for behavior i
-0000b580: 6620 6060 6869 6768 3d4e 6f6e 6560 6029  f ``high=None``)
-0000b590: 2e0a 2020 2020 2020 4966 2061 7272 6179  ..      If array
-0000b5a0: 2d6c 696b 652c 206d 7573 7420 636f 6e74  -like, must cont
-0000b5b0: 6169 6e20 696e 7465 6765 7220 7661 6c75  ain integer valu
-0000b5c0: 6573 0a20 2073 697a 6520 3a20 696e 7420  es.  size : int 
-0000b5d0: 6f72 2074 7570 6c65 206f 6620 696e 7473  or tuple of ints
-0000b5e0: 2c20 6f70 7469 6f6e 616c 0a20 2020 2020  , optional.     
-0000b5f0: 204f 7574 7075 7420 7368 6170 652e 2020   Output shape.  
-0000b600: 4966 2074 6865 2067 6976 656e 2073 6861  If the given sha
-0000b610: 7065 2069 732c 2065 2e67 2e2c 2060 6028  pe is, e.g., ``(
-0000b620: 6d2c 206e 2c20 6b29 6060 2c20 7468 656e  m, n, k)``, then
-0000b630: 0a20 2020 2020 2060 606d 202a 206e 202a  .      ``m * n *
-0000b640: 206b 6060 2073 616d 706c 6573 2061 7265   k`` samples are
-0000b650: 2064 7261 776e 2e20 2044 6566 6175 6c74   drawn.  Default
-0000b660: 2069 7320 4e6f 6e65 2c20 696e 2077 6869   is None, in whi
-0000b670: 6368 2063 6173 6520 610a 2020 2020 2020  ch case a.      
-0000b680: 7369 6e67 6c65 2076 616c 7565 2069 7320  single value is 
-0000b690: 7265 7475 726e 6564 2e0a 2020 6474 7970  returned..  dtyp
-0000b6a0: 6520 3a20 6474 7970 652c 206f 7074 696f  e : dtype, optio
-0000b6b0: 6e61 6c0a 2020 2020 2020 4465 7369 7265  nal.      Desire
-0000b6c0: 6420 6474 7970 6520 6f66 2074 6865 2072  d dtype of the r
-0000b6d0: 6573 756c 742e 2042 7974 656f 7264 6572  esult. Byteorder
-0000b6e0: 206d 7573 7420 6265 206e 6174 6976 652e   must be native.
-0000b6f0: 0a20 2020 2020 2054 6865 2064 6566 6175  .      The defau
-0000b700: 6c74 2076 616c 7565 2069 7320 696e 742e  lt value is int.
-0000b710: 0a0a 2020 5265 7475 726e 730a 2020 2d2d  ..  Returns.  --
-0000b720: 2d2d 2d2d 2d0a 2020 6f75 7420 3a20 696e  -----.  out : in
-0000b730: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
-0000b740: 696e 7473 0a20 2020 2020 2060 7369 7a65  ints.      `size
-0000b750: 602d 7368 6170 6564 2061 7272 6179 206f  `-shaped array o
-0000b760: 6620 7261 6e64 6f6d 2069 6e74 6567 6572  f random integer
-0000b770: 7320 6672 6f6d 2074 6865 2061 7070 726f  s from the appro
-0000b780: 7072 6961 7465 0a20 2020 2020 2064 6973  priate.      dis
-0000b790: 7472 6962 7574 696f 6e2c 206f 7220 6120  tribution, or a 
-0000b7a0: 7369 6e67 6c65 2073 7563 6820 7261 6e64  single such rand
-0000b7b0: 6f6d 2069 6e74 2069 6620 6073 697a 6560  om int if `size`
-0000b7c0: 206e 6f74 2070 726f 7669 6465 642e 0a0a   not provided...
-0000b7d0: 2020 5365 6520 416c 736f 0a20 202d 2d2d    See Also.  ---
-0000b7e0: 2d2d 2d2d 2d0a 2020 7261 6e64 6f6d 5f69  -----.  random_i
-0000b7f0: 6e74 6567 6572 7320 3a20 7369 6d69 6c61  ntegers : simila
-0000b800: 7220 746f 2060 7261 6e64 696e 7460 2c20  r to `randint`, 
-0000b810: 6f6e 6c79 2066 6f72 2074 6865 2063 6c6f  only for the clo
-0000b820: 7365 640a 2020 2020 2020 696e 7465 7276  sed.      interv
-0000b830: 616c 205b 606c 6f77 602c 2060 6869 6768  al [`low`, `high
-0000b840: 605d 2c20 616e 6420 3120 6973 2074 6865  `], and 1 is the
-0000b850: 206c 6f77 6573 7420 7661 6c75 6520 6966   lowest value if
-0000b860: 2060 6869 6768 6020 6973 0a20 2020 2020   `high` is.     
-0000b870: 206f 6d69 7474 6564 2e0a 2020 4765 6e65   omitted..  Gene
-0000b880: 7261 746f 722e 696e 7465 6765 7273 3a20  rator.integers: 
-0000b890: 7768 6963 6820 7368 6f75 6c64 2062 6520  which should be 
-0000b8a0: 7573 6564 2066 6f72 206e 6577 2063 6f64  used for new cod
-0000b8b0: 652e 0a0a 2020 4578 616d 706c 6573 0a20  e...  Examples. 
-0000b8c0: 202d 2d2d 2d2d 2d2d 2d0a 2020 3e3e 3e20   --------.  >>> 
-0000b8d0: 696d 706f 7274 2062 7261 696e 7079 2e6d  import brainpy.m
-0000b8e0: 6174 6820 6173 2062 6d0a 2020 3e3e 3e20  ath as bm.  >>> 
-0000b8f0: 626d 2e72 616e 646f 6d2e 7261 6e64 696e  bm.random.randin
-0000b900: 7428 322c 2073 697a 653d 3130 290a 2020  t(2, size=10).  
-0000b910: 6172 7261 7928 5b31 2c20 302c 2030 2c20  array([1, 0, 0, 
-0000b920: 302c 2031 2c20 312c 2030 2c20 302c 2031  0, 1, 1, 0, 0, 1
-0000b930: 2c20 305d 2920 2320 7261 6e64 6f6d 0a20  , 0]) # random. 
-0000b940: 203e 3e3e 2062 6d2e 7261 6e64 6f6d 2e72   >>> bm.random.r
-0000b950: 616e 6469 6e74 2831 2c20 7369 7a65 3d31  andint(1, size=1
-0000b960: 3029 0a20 2061 7272 6179 285b 302c 2030  0).  array([0, 0
-0000b970: 2c20 302c 2030 2c20 302c 2030 2c20 302c  , 0, 0, 0, 0, 0,
-0000b980: 2030 2c20 302c 2030 5d29 0a0a 2020 4765   0, 0, 0])..  Ge
-0000b990: 6e65 7261 7465 2061 2032 2078 2034 2061  nerate a 2 x 4 a
-0000b9a0: 7272 6179 206f 6620 696e 7473 2062 6574  rray of ints bet
-0000b9b0: 7765 656e 2030 2061 6e64 2034 2c20 696e  ween 0 and 4, in
-0000b9c0: 636c 7573 6976 653a 0a0a 2020 3e3e 3e20  clusive:..  >>> 
-0000b9d0: 626d 2e72 616e 646f 6d2e 7261 6e64 696e  bm.random.randin
-0000b9e0: 7428 352c 2073 697a 653d 2832 2c20 3429  t(5, size=(2, 4)
-0000b9f0: 290a 2020 6172 7261 7928 5b5b 342c 2030  ).  array([[4, 0
-0000ba00: 2c20 322c 2031 5d2c 2023 2072 616e 646f  , 2, 1], # rando
-0000ba10: 6d0a 2020 2020 2020 2020 205b 332c 2032  m.         [3, 2
-0000ba20: 2c20 322c 2030 5d5d 290a 0a20 2047 656e  , 2, 0]])..  Gen
-0000ba30: 6572 6174 6520 6120 3120 7820 3320 6172  erate a 1 x 3 ar
-0000ba40: 7261 7920 7769 7468 2033 2064 6966 6665  ray with 3 diffe
-0000ba50: 7265 6e74 2075 7070 6572 2062 6f75 6e64  rent upper bound
-0000ba60: 730a 0a20 203e 3e3e 2062 6d2e 7261 6e64  s..  >>> bm.rand
-0000ba70: 6f6d 2e72 616e 6469 6e74 2831 2c20 5b33  om.randint(1, [3
-0000ba80: 2c20 352c 2031 305d 290a 2020 6172 7261  , 5, 10]).  arra
-0000ba90: 7928 5b32 2c20 322c 2039 5d29 2023 2072  y([2, 2, 9]) # r
-0000baa0: 616e 646f 6d0a 0a20 2047 656e 6572 6174  andom..  Generat
-0000bab0: 6520 6120 3120 6279 2033 2061 7272 6179  e a 1 by 3 array
-0000bac0: 2077 6974 6820 3320 6469 6666 6572 656e   with 3 differen
-0000bad0: 7420 6c6f 7765 7220 626f 756e 6473 0a0a  t lower bounds..
-0000bae0: 2020 3e3e 3e20 626d 2e72 616e 646f 6d2e    >>> bm.random.
-0000baf0: 7261 6e64 696e 7428 5b31 2c20 352c 2037  randint([1, 5, 7
-0000bb00: 5d2c 2031 3029 0a20 2061 7272 6179 285b  ], 10).  array([
-0000bb10: 392c 2038 2c20 375d 2920 2320 7261 6e64  9, 8, 7]) # rand
-0000bb20: 6f6d 0a0a 2020 4765 6e65 7261 7465 2061  om..  Generate a
-0000bb30: 2032 2062 7920 3420 6172 7261 7920 7573   2 by 4 array us
-0000bb40: 696e 6720 6272 6f61 6463 6173 7469 6e67  ing broadcasting
-0000bb50: 2077 6974 6820 6474 7970 6520 6f66 2075   with dtype of u
-0000bb60: 696e 7438 0a0a 2020 3e3e 3e20 626d 2e72  int8..  >>> bm.r
-0000bb70: 616e 646f 6d2e 7261 6e64 696e 7428 5b31  andom.randint([1
-0000bb80: 2c20 332c 2035 2c20 375d 2c20 5b5b 3130  , 3, 5, 7], [[10
-0000bb90: 5d2c 205b 3230 5d5d 2c20 6474 7970 653d  ], [20]], dtype=
-0000bba0: 6e70 2e75 696e 7438 290a 2020 6172 7261  np.uint8).  arra
-0000bbb0: 7928 5b5b 2038 2c20 2036 2c20 2039 2c20  y([[ 8,  6,  9, 
-0000bbc0: 2037 5d2c 2023 2072 616e 646f 6d0a 2020   7], # random.  
-0000bbd0: 2020 2020 2020 205b 2031 2c20 3136 2c20         [ 1, 16, 
-0000bbe0: 2039 2c20 3132 5d5d 2c20 6474 7970 653d   9, 12]], dtype=
-0000bbf0: 7569 6e74 3829 0a20 2022 2222 0a0a 2020  uint8).  """..  
-0000bc00: 7265 7475 726e 2044 4546 4155 4c54 2e72  return DEFAULT.r
-0000bc10: 616e 6469 6e74 286c 6f77 2c20 6869 6768  andint(low, high
-0000bc20: 3d68 6967 682c 2073 697a 653d 7369 7a65  =high, size=size
-0000bc30: 2c20 6474 7970 653d 6474 7970 652c 206b  , dtype=dtype, k
-0000bc40: 6579 3d6b 6579 290a 0a0a 6465 6620 7261  ey=key)...def ra
-0000bc50: 6e64 6f6d 5f69 6e74 6567 6572 7328 6c6f  ndom_integers(lo
-0000bc60: 772c 2068 6967 683d 4e6f 6e65 2c20 7369  w, high=None, si
-0000bc70: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
-0000bc80: 6529 3a0a 2020 7222 2222 0a20 2052 616e  e):.  r""".  Ran
-0000bc90: 646f 6d20 696e 7465 6765 7273 206f 6620  dom integers of 
-0000bca0: 7479 7065 2060 6e70 2e69 6e74 5f60 2062  type `np.int_` b
-0000bcb0: 6574 7765 656e 2060 6c6f 7760 2061 6e64  etween `low` and
-0000bcc0: 2060 6869 6768 602c 2069 6e63 6c75 7369   `high`, inclusi
-0000bcd0: 7665 2e0a 0a20 2052 6574 7572 6e20 7261  ve...  Return ra
-0000bce0: 6e64 6f6d 2069 6e74 6567 6572 7320 6f66  ndom integers of
-0000bcf0: 2074 7970 6520 606e 702e 696e 745f 6020   type `np.int_` 
-0000bd00: 6672 6f6d 2074 6865 2022 6469 7363 7265  from the "discre
-0000bd10: 7465 2075 6e69 666f 726d 220a 2020 6469  te uniform".  di
-0000bd20: 7374 7269 6275 7469 6f6e 2069 6e20 7468  stribution in th
-0000bd30: 6520 636c 6f73 6564 2069 6e74 6572 7661  e closed interva
-0000bd40: 6c20 5b60 6c6f 7760 2c20 6068 6967 6860  l [`low`, `high`
-0000bd50: 5d2e 2020 4966 2060 6869 6768 6020 6973  ].  If `high` is
-0000bd60: 0a20 204e 6f6e 6520 2874 6865 2064 6566  .  None (the def
-0000bd70: 6175 6c74 292c 2074 6865 6e20 7265 7375  ault), then resu
-0000bd80: 6c74 7320 6172 6520 6672 6f6d 205b 312c  lts are from [1,
-0000bd90: 2060 6c6f 7760 5d2e 2054 6865 2060 6e70   `low`]. The `np
-0000bda0: 2e69 6e74 5f60 0a20 2074 7970 6520 7472  .int_`.  type tr
-0000bdb0: 616e 736c 6174 6573 2074 6f20 7468 6520  anslates to the 
-0000bdc0: 4320 6c6f 6e67 2069 6e74 6567 6572 2074  C long integer t
-0000bdd0: 7970 6520 616e 6420 6974 7320 7072 6563  ype and its prec
-0000bde0: 6973 696f 6e0a 2020 6973 2070 6c61 7466  ision.  is platf
-0000bdf0: 6f72 6d20 6465 7065 6e64 656e 742e 0a0a  orm dependent...
-0000be00: 2020 5061 7261 6d65 7465 7273 0a20 202d    Parameters.  -
-0000be10: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 6c6f 7720  ---------.  low 
-0000be20: 3a20 696e 740a 2020 2020 2020 4c6f 7765  : int.      Lowe
-0000be30: 7374 2028 7369 676e 6564 2920 696e 7465  st (signed) inte
-0000be40: 6765 7220 746f 2062 6520 6472 6177 6e20  ger to be drawn 
-0000be50: 6672 6f6d 2074 6865 2064 6973 7472 6962  from the distrib
-0000be60: 7574 696f 6e20 2875 6e6c 6573 730a 2020  ution (unless.  
-0000be70: 2020 2020 6060 6869 6768 3d4e 6f6e 6560      ``high=None`
-0000be80: 602c 2069 6e20 7768 6963 6820 6361 7365  `, in which case
-0000be90: 2074 6869 7320 7061 7261 6d65 7465 7220   this parameter 
-0000bea0: 6973 2074 6865 202a 6869 6768 6573 742a  is the *highest*
-0000beb0: 2073 7563 680a 2020 2020 2020 696e 7465   such.      inte
-0000bec0: 6765 7229 2e0a 2020 6869 6768 203a 2069  ger)..  high : i
-0000bed0: 6e74 2c20 6f70 7469 6f6e 616c 0a20 2020  nt, optional.   
-0000bee0: 2020 2049 6620 7072 6f76 6964 6564 2c20     If provided, 
-0000bef0: 7468 6520 6c61 7267 6573 7420 2873 6967  the largest (sig
-0000bf00: 6e65 6429 2069 6e74 6567 6572 2074 6f20  ned) integer to 
-0000bf10: 6265 2064 7261 776e 2066 726f 6d20 7468  be drawn from th
-0000bf20: 650a 2020 2020 2020 6469 7374 7269 6275  e.      distribu
-0000bf30: 7469 6f6e 2028 7365 6520 6162 6f76 6520  tion (see above 
-0000bf40: 666f 7220 6265 6861 7669 6f72 2069 6620  for behavior if 
-0000bf50: 6060 6869 6768 3d4e 6f6e 6560 6029 2e0a  ``high=None``)..
-0000bf60: 2020 7369 7a65 203a 2069 6e74 206f 7220    size : int or 
-0000bf70: 7475 706c 6520 6f66 2069 6e74 732c 206f  tuple of ints, o
-0000bf80: 7074 696f 6e61 6c0a 2020 2020 2020 4f75  ptional.      Ou
-0000bf90: 7470 7574 2073 6861 7065 2e20 2049 6620  tput shape.  If 
-0000bfa0: 7468 6520 6769 7665 6e20 7368 6170 6520  the given shape 
-0000bfb0: 6973 2c20 652e 672e 2c20 6060 286d 2c20  is, e.g., ``(m, 
-0000bfc0: 6e2c 206b 2960 602c 2074 6865 6e0a 2020  n, k)``, then.  
-0000bfd0: 2020 2020 6060 6d20 2a20 6e20 2a20 6b60      ``m * n * k`
-0000bfe0: 6020 7361 6d70 6c65 7320 6172 6520 6472  ` samples are dr
-0000bff0: 6177 6e2e 2020 4465 6661 756c 7420 6973  awn.  Default is
-0000c000: 204e 6f6e 652c 2069 6e20 7768 6963 6820   None, in which 
-0000c010: 6361 7365 2061 0a20 2020 2020 2073 696e  case a.      sin
-0000c020: 676c 6520 7661 6c75 6520 6973 2072 6574  gle value is ret
-0000c030: 7572 6e65 642e 0a0a 2020 5265 7475 726e  urned...  Return
-0000c040: 730a 2020 2d2d 2d2d 2d2d 2d0a 2020 6f75  s.  -------.  ou
-0000c050: 7420 3a20 696e 7420 6f72 206e 6461 7272  t : int or ndarr
-0000c060: 6179 206f 6620 696e 7473 0a20 2020 2020  ay of ints.     
-0000c070: 2060 7369 7a65 602d 7368 6170 6564 2061   `size`-shaped a
-0000c080: 7272 6179 206f 6620 7261 6e64 6f6d 2069  rray of random i
-0000c090: 6e74 6567 6572 7320 6672 6f6d 2074 6865  ntegers from the
-0000c0a0: 2061 7070 726f 7072 6961 7465 0a20 2020   appropriate.   
-0000c0b0: 2020 2064 6973 7472 6962 7574 696f 6e2c     distribution,
-0000c0c0: 206f 7220 6120 7369 6e67 6c65 2073 7563   or a single suc
-0000c0d0: 6820 7261 6e64 6f6d 2069 6e74 2069 6620  h random int if 
-0000c0e0: 6073 697a 6560 206e 6f74 2070 726f 7669  `size` not provi
-0000c0f0: 6465 642e 0a0a 2020 5365 6520 416c 736f  ded...  See Also
-0000c100: 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020 7261  .  --------.  ra
-0000c110: 6e64 696e 7420 3a20 5369 6d69 6c61 7220  ndint : Similar 
-0000c120: 746f 2060 7261 6e64 6f6d 5f69 6e74 6567  to `random_integ
-0000c130: 6572 7360 2c20 6f6e 6c79 2066 6f72 2074  ers`, only for t
-0000c140: 6865 2068 616c 662d 6f70 656e 0a20 2020  he half-open.   
-0000c150: 2020 2069 6e74 6572 7661 6c20 5b60 6c6f     interval [`lo
-0000c160: 7760 2c20 6068 6967 6860 292c 2061 6e64  w`, `high`), and
-0000c170: 2030 2069 7320 7468 6520 6c6f 7765 7374   0 is the lowest
-0000c180: 2076 616c 7565 2069 6620 6068 6967 6860   value if `high`
-0000c190: 2069 730a 2020 2020 2020 6f6d 6974 7465   is.      omitte
-0000c1a0: 642e 0a0a 2020 4e6f 7465 730a 2020 2d2d  d...  Notes.  --
-0000c1b0: 2d2d 2d0a 2020 546f 2073 616d 706c 6520  ---.  To sample 
-0000c1c0: 6672 6f6d 204e 2065 7665 6e6c 7920 7370  from N evenly sp
-0000c1d0: 6163 6564 2066 6c6f 6174 696e 672d 706f  aced floating-po
-0000c1e0: 696e 7420 6e75 6d62 6572 7320 6265 7477  int numbers betw
-0000c1f0: 6565 6e20 6120 616e 6420 622c 0a20 2075  een a and b,.  u
-0000c200: 7365 3a3a 0a0a 2020 2020 6120 2b20 2862  se::..    a + (b
-0000c210: 202d 2061 2920 2a20 2862 6d2e 7261 6e64   - a) * (bm.rand
-0000c220: 6f6d 2e72 616e 646f 6d5f 696e 7465 6765  om.random_intege
-0000c230: 7273 284e 2920 2d20 3129 202f 2028 4e20  rs(N) - 1) / (N 
-0000c240: 2d20 312e 290a 0a20 2045 7861 6d70 6c65  - 1.)..  Example
-0000c250: 730a 2020 2d2d 2d2d 2d2d 2d2d 0a20 203e  s.  --------.  >
-0000c260: 3e3e 2069 6d70 6f72 7420 6272 6169 6e70  >> import brainp
-0000c270: 792e 6d61 7468 2061 7320 626d 0a20 203e  y.math as bm.  >
-0000c280: 3e3e 2062 6d2e 7261 6e64 6f6d 2e72 616e  >> bm.random.ran
-0000c290: 646f 6d5f 696e 7465 6765 7273 2835 290a  dom_integers(5).
-0000c2a0: 2020 3420 2320 7261 6e64 6f6d 0a20 203e    4 # random.  >
-0000c2b0: 3e3e 2074 7970 6528 626d 2e72 616e 646f  >> type(bm.rando
-0000c2c0: 6d2e 7261 6e64 6f6d 5f69 6e74 6567 6572  m.random_integer
-0000c2d0: 7328 3529 290a 2020 3c63 6c61 7373 2027  s(5)).  <class '
-0000c2e0: 6e75 6d70 792e 696e 7436 3427 3e0a 2020  numpy.int64'>.  
-0000c2f0: 3e3e 3e20 626d 2e72 616e 646f 6d2e 7261  >>> bm.random.ra
-0000c300: 6e64 6f6d 5f69 6e74 6567 6572 7328 352c  ndom_integers(5,
-0000c310: 2073 697a 653d 2833 2c32 2929 0a20 2061   size=(3,2)).  a
-0000c320: 7272 6179 285b 5b35 2c20 345d 2c20 2320  rray([[5, 4], # 
-0000c330: 7261 6e64 6f6d 0a20 2020 2020 2020 2020  random.         
-0000c340: 5b33 2c20 335d 2c0a 2020 2020 2020 2020  [3, 3],.        
-0000c350: 205b 342c 2035 5d5d 290a 0a20 2043 686f   [4, 5]])..  Cho
-0000c360: 6f73 6520 6669 7665 2072 616e 646f 6d20  ose five random 
-0000c370: 6e75 6d62 6572 7320 6672 6f6d 2074 6865  numbers from the
-0000c380: 2073 6574 206f 6620 6669 7665 2065 7665   set of five eve
-0000c390: 6e6c 792d 7370 6163 6564 0a20 206e 756d  nly-spaced.  num
-0000c3a0: 6265 7273 2062 6574 7765 656e 2030 2061  bers between 0 a
-0000c3b0: 6e64 2032 2e35 2c20 696e 636c 7573 6976  nd 2.5, inclusiv
-0000c3c0: 6520 282a 692e 652e 2a2c 2066 726f 6d20  e (*i.e.*, from 
-0000c3d0: 7468 6520 7365 740a 2020 3a6d 6174 683a  the set.  :math:
-0000c3e0: 607b 302c 2035 2f38 2c20 3130 2f38 2c20  `{0, 5/8, 10/8, 
-0000c3f0: 3135 2f38 2c20 3230 2f38 7d60 293a 0a0a  15/8, 20/8}`):..
-0000c400: 2020 3e3e 3e20 322e 3520 2a20 2862 6d2e    >>> 2.5 * (bm.
-0000c410: 7261 6e64 6f6d 2e72 616e 646f 6d5f 696e  random.random_in
-0000c420: 7465 6765 7273 2835 2c20 7369 7a65 3d28  tegers(5, size=(
-0000c430: 352c 2929 202d 2031 2920 2f20 342e 0a20  5,)) - 1) / 4.. 
-0000c440: 2061 7272 6179 285b 2030 2e36 3235 2c20   array([ 0.625, 
-0000c450: 2031 2e32 3520 2c20 2030 2e36 3235 2c20   1.25 ,  0.625, 
-0000c460: 2030 2e36 3235 2c20 2032 2e35 2020 5d29   0.625,  2.5  ])
-0000c470: 2023 2072 616e 646f 6d0a 0a20 2052 6f6c   # random..  Rol
-0000c480: 6c20 7477 6f20 7369 7820 7369 6465 6420  l two six sided 
-0000c490: 6469 6365 2031 3030 3020 7469 6d65 7320  dice 1000 times 
-0000c4a0: 616e 6420 7375 6d20 7468 6520 7265 7375  and sum the resu
-0000c4b0: 6c74 733a 0a0a 2020 3e3e 3e20 6431 203d  lts:..  >>> d1 =
-0000c4c0: 2062 6d2e 7261 6e64 6f6d 2e72 616e 646f   bm.random.rando
-0000c4d0: 6d5f 696e 7465 6765 7273 2831 2c20 362c  m_integers(1, 6,
-0000c4e0: 2031 3030 3029 0a20 203e 3e3e 2064 3220   1000).  >>> d2 
-0000c4f0: 3d20 626d 2e72 616e 646f 6d2e 7261 6e64  = bm.random.rand
-0000c500: 6f6d 5f69 6e74 6567 6572 7328 312c 2036  om_integers(1, 6
-0000c510: 2c20 3130 3030 290a 2020 3e3e 3e20 6473  , 1000).  >>> ds
-0000c520: 756d 7320 3d20 6431 202b 2064 320a 0a20  ums = d1 + d2.. 
-0000c530: 2044 6973 706c 6179 2072 6573 756c 7473   Display results
-0000c540: 2061 7320 6120 6869 7374 6f67 7261 6d3a   as a histogram:
-0000c550: 0a0a 2020 3e3e 3e20 696d 706f 7274 206d  ..  >>> import m
-0000c560: 6174 706c 6f74 6c69 622e 7079 706c 6f74  atplotlib.pyplot
-0000c570: 2061 7320 706c 740a 2020 3e3e 3e20 636f   as plt.  >>> co
-0000c580: 756e 742c 2062 696e 732c 2069 676e 6f72  unt, bins, ignor
-0000c590: 6564 203d 2070 6c74 2e68 6973 7428 6473  ed = plt.hist(ds
-0000c5a0: 756d 732c 2031 312c 2064 656e 7369 7479  ums, 11, density
-0000c5b0: 3d54 7275 6529 0a20 203e 3e3e 2070 6c74  =True).  >>> plt
-0000c5c0: 2e73 686f 7728 290a 2020 2222 220a 0a20  .show().  """.. 
-0000c5d0: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
-0000c5e0: 7261 6e64 6f6d 5f69 6e74 6567 6572 7328  random_integers(
-0000c5f0: 6c6f 772c 2068 6967 683d 6869 6768 2c20  low, high=high, 
-0000c600: 7369 7a65 3d73 697a 652c 206b 6579 3d6b  size=size, key=k
-0000c610: 6579 290a 0a0a 6465 6620 7261 6e64 6e28  ey)...def randn(
-0000c620: 2a64 6e2c 206b 6579 3d4e 6f6e 6529 3a0a  *dn, key=None):.
-0000c630: 2020 7222 2222 0a20 2052 6574 7572 6e20    r""".  Return 
-0000c640: 6120 7361 6d70 6c65 2028 6f72 2073 616d  a sample (or sam
-0000c650: 706c 6573 2920 6672 6f6d 2074 6865 2022  ples) from the "
-0000c660: 7374 616e 6461 7264 206e 6f72 6d61 6c22  standard normal"
-0000c670: 2064 6973 7472 6962 7574 696f 6e2e 0a0a   distribution...
-0000c680: 2020 2e2e 206e 6f74 653a 3a0a 2020 2020    .. note::.    
-0000c690: 2020 5468 6973 2069 7320 6120 636f 6e76    This is a conv
-0000c6a0: 656e 6965 6e63 6520 6675 6e63 7469 6f6e  enience function
-0000c6b0: 2066 6f72 2075 7365 7273 2070 6f72 7469   for users porti
-0000c6c0: 6e67 2063 6f64 6520 6672 6f6d 204d 6174  ng code from Mat
-0000c6d0: 6c61 622c 0a20 2020 2020 2061 6e64 2077  lab,.      and w
-0000c6e0: 7261 7073 2060 7374 616e 6461 7264 5f6e  raps `standard_n
-0000c6f0: 6f72 6d61 6c60 2e20 5468 6174 2066 756e  ormal`. That fun
-0000c700: 6374 696f 6e20 7461 6b65 7320 610a 2020  ction takes a.  
-0000c710: 2020 2020 7475 706c 6520 746f 2073 7065      tuple to spe
-0000c720: 6369 6679 2074 6865 2073 697a 6520 6f66  cify the size of
-0000c730: 2074 6865 206f 7574 7075 742c 2077 6869   the output, whi
-0000c740: 6368 2069 7320 636f 6e73 6973 7465 6e74  ch is consistent
-0000c750: 2077 6974 680a 2020 2020 2020 6f74 6865   with.      othe
-0000c760: 7220 4e75 6d50 7920 6675 6e63 7469 6f6e  r NumPy function
-0000c770: 7320 6c69 6b65 2060 6e75 6d70 792e 7a65  s like `numpy.ze
-0000c780: 726f 7360 2061 6e64 2060 6e75 6d70 792e  ros` and `numpy.
-0000c790: 6f6e 6573 602e 0a0a 2020 2e2e 206e 6f74  ones`...  .. not
-0000c7a0: 653a 3a0a 2020 2020 2020 4e65 7720 636f  e::.      New co
-0000c7b0: 6465 2073 686f 756c 6420 7573 6520 7468  de should use th
-0000c7c0: 6520 6060 7374 616e 6461 7264 5f6e 6f72  e ``standard_nor
-0000c7d0: 6d61 6c60 6020 6d65 7468 6f64 206f 6620  mal`` method of 
-0000c7e0: 6120 6060 6465 6661 756c 745f 726e 6728  a ``default_rng(
-0000c7f0: 2960 600a 2020 2020 2020 696e 7374 616e  )``.      instan
-0000c800: 6365 2069 6e73 7465 6164 3b20 706c 6561  ce instead; plea
-0000c810: 7365 2073 6565 2074 6865 203a 7265 663a  se see the :ref:
-0000c820: 6072 616e 646f 6d2d 7175 6963 6b2d 7374  `random-quick-st
-0000c830: 6172 7460 2e0a 0a20 2049 6620 706f 7369  art`...  If posi
-0000c840: 7469 7665 2069 6e74 5f6c 696b 6520 6172  tive int_like ar
-0000c850: 6775 6d65 6e74 7320 6172 6520 7072 6f76  guments are prov
-0000c860: 6964 6564 2c20 6072 616e 646e 6020 6765  ided, `randn` ge
-0000c870: 6e65 7261 7465 7320 616e 2061 7272 6179  nerates an array
-0000c880: 0a20 206f 6620 7368 6170 6520 6060 2864  .  of shape ``(d
-0000c890: 302c 2064 312c 202e 2e2e 2c20 646e 2960  0, d1, ..., dn)`
-0000c8a0: 602c 2066 696c 6c65 640a 2020 7769 7468  `, filled.  with
-0000c8b0: 2072 616e 646f 6d20 666c 6f61 7473 2073   random floats s
-0000c8c0: 616d 706c 6564 2066 726f 6d20 6120 756e  ampled from a un
-0000c8d0: 6976 6172 6961 7465 2022 6e6f 726d 616c  ivariate "normal
-0000c8e0: 2220 2847 6175 7373 6961 6e29 0a20 2064  " (Gaussian).  d
-0000c8f0: 6973 7472 6962 7574 696f 6e20 6f66 206d  istribution of m
-0000c900: 6561 6e20 3020 616e 6420 7661 7269 616e  ean 0 and varian
-0000c910: 6365 2031 2e20 4120 7369 6e67 6c65 2066  ce 1. A single f
-0000c920: 6c6f 6174 2072 616e 646f 6d6c 7920 7361  loat randomly sa
-0000c930: 6d70 6c65 640a 2020 6672 6f6d 2074 6865  mpled.  from the
-0000c940: 2064 6973 7472 6962 7574 696f 6e20 6973   distribution is
-0000c950: 2072 6574 7572 6e65 6420 6966 206e 6f20   returned if no 
-0000c960: 6172 6775 6d65 6e74 2069 7320 7072 6f76  argument is prov
-0000c970: 6964 6564 2e0a 0a20 2050 6172 616d 6574  ided...  Paramet
-0000c980: 6572 730a 2020 2d2d 2d2d 2d2d 2d2d 2d2d  ers.  ----------
-0000c990: 0a20 2064 302c 2064 312c 202e 2e2e 2c20  .  d0, d1, ..., 
-0000c9a0: 646e 203a 2069 6e74 2c20 6f70 7469 6f6e  dn : int, option
-0000c9b0: 616c 0a20 2020 2020 2054 6865 2064 696d  al.      The dim
-0000c9c0: 656e 7369 6f6e 7320 6f66 2074 6865 2072  ensions of the r
-0000c9d0: 6574 7572 6e65 6420 6172 7261 792c 206d  eturned array, m
-0000c9e0: 7573 7420 6265 206e 6f6e 2d6e 6567 6174  ust be non-negat
-0000c9f0: 6976 652e 0a20 2020 2020 2049 6620 6e6f  ive..      If no
-0000ca00: 2061 7267 756d 656e 7420 6973 2067 6976   argument is giv
-0000ca10: 656e 2061 2073 696e 676c 6520 5079 7468  en a single Pyth
-0000ca20: 6f6e 2066 6c6f 6174 2069 7320 7265 7475  on float is retu
-0000ca30: 726e 6564 2e0a 0a20 2052 6574 7572 6e73  rned...  Returns
-0000ca40: 0a20 202d 2d2d 2d2d 2d2d 0a20 205a 203a  .  -------.  Z :
-0000ca50: 206e 6461 7272 6179 206f 7220 666c 6f61   ndarray or floa
-0000ca60: 740a 2020 2020 2020 4120 6060 2864 302c  t.      A ``(d0,
-0000ca70: 2064 312c 202e 2e2e 2c20 646e 2960 602d   d1, ..., dn)``-
-0000ca80: 7368 6170 6564 2061 7272 6179 206f 6620  shaped array of 
-0000ca90: 666c 6f61 7469 6e67 2d70 6f69 6e74 2073  floating-point s
-0000caa0: 616d 706c 6573 2066 726f 6d0a 2020 2020  amples from.    
-0000cab0: 2020 7468 6520 7374 616e 6461 7264 206e    the standard n
-0000cac0: 6f72 6d61 6c20 6469 7374 7269 6275 7469  ormal distributi
-0000cad0: 6f6e 2c20 6f72 2061 2073 696e 676c 6520  on, or a single 
-0000cae0: 7375 6368 2066 6c6f 6174 2069 660a 2020  such float if.  
-0000caf0: 2020 2020 6e6f 2070 6172 616d 6574 6572      no parameter
-0000cb00: 7320 7765 7265 2073 7570 706c 6965 642e  s were supplied.
-0000cb10: 0a0a 2020 5365 6520 416c 736f 0a20 202d  ..  See Also.  -
-0000cb20: 2d2d 2d2d 2d2d 2d0a 2020 7374 616e 6461  -------.  standa
-0000cb30: 7264 5f6e 6f72 6d61 6c20 3a20 5369 6d69  rd_normal : Simi
-0000cb40: 6c61 722c 2062 7574 2074 616b 6573 2061  lar, but takes a
-0000cb50: 2074 7570 6c65 2061 7320 6974 7320 6172   tuple as its ar
-0000cb60: 6775 6d65 6e74 2e0a 2020 6e6f 726d 616c  gument..  normal
-0000cb70: 203a 2041 6c73 6f20 6163 6365 7074 7320   : Also accepts 
-0000cb80: 6d75 2061 6e64 2073 6967 6d61 2061 7267  mu and sigma arg
-0000cb90: 756d 656e 7473 2e0a 2020 7261 6e64 6f6d  uments..  random
-0000cba0: 2e47 656e 6572 6174 6f72 2e73 7461 6e64  .Generator.stand
-0000cbb0: 6172 645f 6e6f 726d 616c 3a20 7768 6963  ard_normal: whic
-0000cbc0: 6820 7368 6f75 6c64 2062 6520 7573 6564  h should be used
-0000cbd0: 2066 6f72 206e 6577 2063 6f64 652e 0a0a   for new code...
-0000cbe0: 2020 4e6f 7465 730a 2020 2d2d 2d2d 2d0a    Notes.  -----.
-0000cbf0: 2020 466f 7220 7261 6e64 6f6d 2073 616d    For random sam
-0000cc00: 706c 6573 2066 726f 6d20 3a6d 6174 683a  ples from :math:
-0000cc10: 604e 285c 6d75 2c20 5c73 6967 6d61 5e32  `N(\mu, \sigma^2
-0000cc20: 2960 2c20 7573 653a 0a0a 2020 6060 7369  )`, use:..  ``si
-0000cc30: 676d 6120 2a20 626d 2e72 616e 646f 6d2e  gma * bm.random.
-0000cc40: 7261 6e64 6e28 2e2e 2e29 202b 206d 7560  randn(...) + mu`
-0000cc50: 600a 0a20 2045 7861 6d70 6c65 730a 2020  `..  Examples.  
-0000cc60: 2d2d 2d2d 2d2d 2d2d 0a20 203e 3e3e 2069  --------.  >>> i
-0000cc70: 6d70 6f72 7420 6272 6169 6e70 792e 6d61  mport brainpy.ma
-0000cc80: 7468 2061 7320 626d 0a20 203e 3e3e 2062  th as bm.  >>> b
-0000cc90: 6d2e 7261 6e64 6f6d 2e72 616e 646e 2829  m.random.randn()
-0000cca0: 0a20 2032 2e31 3932 3338 3735 3333 3535  .  2.19238753355
-0000ccb0: 3337 3331 3520 2023 2072 616e 646f 6d0a  37315  # random.
-0000ccc0: 0a20 2054 776f 2d62 792d 666f 7572 2061  .  Two-by-four a
-0000ccd0: 7272 6179 206f 6620 7361 6d70 6c65 7320  rray of samples 
-0000cce0: 6672 6f6d 204e 2833 2c20 362e 3235 293a  from N(3, 6.25):
-0000ccf0: 0a0a 2020 3e3e 3e20 3320 2b20 322e 3520  ..  >>> 3 + 2.5 
-0000cd00: 2a20 626d 2e72 616e 646f 6d2e 7261 6e64  * bm.random.rand
-0000cd10: 6e28 322c 2034 290a 2020 6172 7261 7928  n(2, 4).  array(
-0000cd20: 5b5b 2d34 2e34 3934 3031 3530 312c 2020  [[-4.49401501,  
-0000cd30: 342e 3030 3935 3030 3334 2c20 2d31 2e38  4.00950034, -1.8
-0000cd40: 3138 3134 3836 372c 2020 372e 3239 3731  1814867,  7.2971
-0000cd50: 3836 3737 5d2c 2020 2023 2072 616e 646f  8677],   # rando
-0000cd60: 6d0a 2020 2020 2020 2020 205b 2030 2e33  m.         [ 0.3
-0000cd70: 3939 3234 3830 342c 2020 342e 3638 3435  9924804,  4.6845
-0000cd80: 3633 3136 2c20 2034 2e39 3933 3934 3532  6316,  4.9939452
-0000cd90: 392c 2020 342e 3834 3035 3732 3534 5d5d  9,  4.84057254]]
-0000cda0: 2920 2023 2072 616e 646f 6d0a 2020 2222  )  # random.  ""
-0000cdb0: 220a 0a20 2072 6574 7572 6e20 4445 4641  "..  return DEFA
-0000cdc0: 554c 542e 7261 6e64 6e28 2a64 6e2c 206b  ULT.randn(*dn, k
-0000cdd0: 6579 3d6b 6579 290a 0a0a 6465 6620 7261  ey=key)...def ra
-0000cde0: 6e64 6f6d 2873 697a 653d 4e6f 6e65 2c20  ndom(size=None, 
-0000cdf0: 6b65 793d 4e6f 6e65 293a 0a20 2022 2222  key=None):.  """
-0000ce00: 0a20 2052 6574 7572 6e20 7261 6e64 6f6d  .  Return random
-0000ce10: 2066 6c6f 6174 7320 696e 2074 6865 2068   floats in the h
-0000ce20: 616c 662d 6f70 656e 2069 6e74 6572 7661  alf-open interva
-0000ce30: 6c20 5b30 2e30 2c20 312e 3029 2e20 416c  l [0.0, 1.0). Al
-0000ce40: 6961 7320 666f 720a 2020 6072 616e 646f  ias for.  `rando
-0000ce50: 6d5f 7361 6d70 6c65 6020 746f 2065 6173  m_sample` to eas
-0000ce60: 6520 666f 7277 6172 642d 706f 7274 696e  e forward-portin
-0000ce70: 6720 746f 2074 6865 206e 6577 2072 616e  g to the new ran
-0000ce80: 646f 6d20 4150 492e 0a20 2022 2222 0a20  dom API..  """. 
-0000ce90: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
-0000cea0: 7261 6e64 6f6d 2873 697a 652c 206b 6579  random(size, key
-0000ceb0: 3d6b 6579 290a 0a0a 6465 6620 7261 6e64  =key)...def rand
-0000cec0: 6f6d 5f73 616d 706c 6528 7369 7a65 3d4e  om_sample(size=N
-0000ced0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-0000cee0: 2020 7222 2222 0a20 2052 6574 7572 6e20    r""".  Return 
-0000cef0: 7261 6e64 6f6d 2066 6c6f 6174 7320 696e  random floats in
-0000cf00: 2074 6865 2068 616c 662d 6f70 656e 2069   the half-open i
-0000cf10: 6e74 6572 7661 6c20 5b30 2e30 2c20 312e  nterval [0.0, 1.
-0000cf20: 3029 2e0a 0a20 2052 6573 756c 7473 2061  0)...  Results a
-0000cf30: 7265 2066 726f 6d20 7468 6520 2263 6f6e  re from the "con
-0000cf40: 7469 6e75 6f75 7320 756e 6966 6f72 6d22  tinuous uniform"
-0000cf50: 2064 6973 7472 6962 7574 696f 6e20 6f76   distribution ov
-0000cf60: 6572 2074 6865 0a20 2073 7461 7465 6420  er the.  stated 
-0000cf70: 696e 7465 7276 616c 2e20 2054 6f20 7361  interval.  To sa
-0000cf80: 6d70 6c65 203a 6d61 7468 3a60 556e 6966  mple :math:`Unif
-0000cf90: 5b61 2c20 6229 2c20 6220 3e20 6160 206d  [a, b), b > a` m
-0000cfa0: 756c 7469 706c 790a 2020 7468 6520 6f75  ultiply.  the ou
-0000cfb0: 7470 7574 206f 6620 6072 616e 646f 6d5f  tput of `random_
-0000cfc0: 7361 6d70 6c65 6020 6279 2060 2862 2d61  sample` by `(b-a
-0000cfd0: 2960 2061 6e64 2061 6464 2060 6160 3a3a  )` and add `a`::
-0000cfe0: 0a0a 2020 2020 2862 202d 2061 2920 2a20  ..    (b - a) * 
-0000cff0: 7261 6e64 6f6d 5f73 616d 706c 6528 2920  random_sample() 
-0000d000: 2b20 610a 0a20 202e 2e20 6e6f 7465 3a3a  + a..  .. note::
-0000d010: 0a20 2020 2020 204e 6577 2063 6f64 6520  .      New code 
-0000d020: 7368 6f75 6c64 2075 7365 2074 6865 2060  should use the `
-0000d030: 6072 616e 646f 6d60 6020 6d65 7468 6f64  `random`` method
-0000d040: 206f 6620 6120 6060 6465 6661 756c 745f   of a ``default_
-0000d050: 726e 6728 2960 600a 2020 2020 2020 696e  rng()``.      in
-0000d060: 7374 616e 6365 2069 6e73 7465 6164 3b20  stance instead; 
-0000d070: 706c 6561 7365 2073 6565 2074 6865 203a  please see the :
-0000d080: 7265 663a 6072 616e 646f 6d2d 7175 6963  ref:`random-quic
-0000d090: 6b2d 7374 6172 7460 2e0a 0a20 2050 6172  k-start`...  Par
-0000d0a0: 616d 6574 6572 730a 2020 2d2d 2d2d 2d2d  ameters.  ------
-0000d0b0: 2d2d 2d2d 0a20 2073 697a 6520 3a20 696e  ----.  size : in
-0000d0c0: 7420 6f72 2074 7570 6c65 206f 6620 696e  t or tuple of in
-0000d0d0: 7473 2c20 6f70 7469 6f6e 616c 0a20 2020  ts, optional.   
-0000d0e0: 2020 204f 7574 7075 7420 7368 6170 652e     Output shape.
-0000d0f0: 2020 4966 2074 6865 2067 6976 656e 2073    If the given s
-0000d100: 6861 7065 2069 732c 2065 2e67 2e2c 2060  hape is, e.g., `
-0000d110: 6028 6d2c 206e 2c20 6b29 6060 2c20 7468  `(m, n, k)``, th
-0000d120: 656e 0a20 2020 2020 2060 606d 202a 206e  en.      ``m * n
-0000d130: 202a 206b 6060 2073 616d 706c 6573 2061   * k`` samples a
-0000d140: 7265 2064 7261 776e 2e20 2044 6566 6175  re drawn.  Defau
-0000d150: 6c74 2069 7320 4e6f 6e65 2c20 696e 2077  lt is None, in w
-0000d160: 6869 6368 2063 6173 6520 610a 2020 2020  hich case a.    
-0000d170: 2020 7369 6e67 6c65 2076 616c 7565 2069    single value i
-0000d180: 7320 7265 7475 726e 6564 2e0a 0a20 2052  s returned...  R
-0000d190: 6574 7572 6e73 0a20 202d 2d2d 2d2d 2d2d  eturns.  -------
-0000d1a0: 0a20 206f 7574 203a 2066 6c6f 6174 206f  .  out : float o
-0000d1b0: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
-0000d1c0: 6174 730a 2020 2020 2020 4172 7261 7920  ats.      Array 
-0000d1d0: 6f66 2072 616e 646f 6d20 666c 6f61 7473  of random floats
-0000d1e0: 206f 6620 7368 6170 6520 6073 697a 6560   of shape `size`
-0000d1f0: 2028 756e 6c65 7373 2060 6073 697a 653d   (unless ``size=
-0000d200: 4e6f 6e65 6060 2c20 696e 2077 6869 6368  None``, in which
-0000d210: 0a20 2020 2020 2063 6173 6520 6120 7369  .      case a si
-0000d220: 6e67 6c65 2066 6c6f 6174 2069 7320 7265  ngle float is re
-0000d230: 7475 726e 6564 292e 0a0a 2020 5365 6520  turned)...  See 
-0000d240: 416c 736f 0a20 202d 2d2d 2d2d 2d2d 2d0a  Also.  --------.
-0000d250: 2020 4765 6e65 7261 746f 722e 7261 6e64    Generator.rand
-0000d260: 6f6d 3a20 7768 6963 6820 7368 6f75 6c64  om: which should
-0000d270: 2062 6520 7573 6564 2066 6f72 206e 6577   be used for new
-0000d280: 2063 6f64 652e 0a0a 2020 4578 616d 706c   code...  Exampl
-0000d290: 6573 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020  es.  --------.  
-0000d2a0: 3e3e 3e20 696d 706f 7274 2062 7261 696e  >>> import brain
-0000d2b0: 7079 2e6d 6174 6820 6173 2062 6d0a 2020  py.math as bm.  
-0000d2c0: 3e3e 3e20 626d 2e72 616e 646f 6d2e 7261  >>> bm.random.ra
-0000d2d0: 6e64 6f6d 5f73 616d 706c 6528 290a 2020  ndom_sample().  
-0000d2e0: 302e 3437 3130 3835 3437 3939 3533 3536  0.47108547995356
-0000d2f0: 3039 3820 2320 7261 6e64 6f6d 0a20 203e  098 # random.  >
-0000d300: 3e3e 2074 7970 6528 626d 2e72 616e 646f  >> type(bm.rando
-0000d310: 6d2e 7261 6e64 6f6d 5f73 616d 706c 6528  m.random_sample(
-0000d320: 2929 0a20 203c 636c 6173 7320 2766 6c6f  )).  <class 'flo
-0000d330: 6174 273e 0a20 203e 3e3e 2062 6d2e 7261  at'>.  >>> bm.ra
-0000d340: 6e64 6f6d 2e72 616e 646f 6d5f 7361 6d70  ndom.random_samp
-0000d350: 6c65 2828 352c 2929 0a20 2061 7272 6179  le((5,)).  array
-0000d360: 285b 2030 2e33 3032 3230 3438 322c 2020  ([ 0.30220482,  
-0000d370: 302e 3836 3832 3034 3031 2c20 2030 2e31  0.86820401,  0.1
-0000d380: 3635 3435 3033 202c 2020 302e 3131 3635  654503 ,  0.1165
-0000d390: 3931 3439 2c20 2030 2e35 3433 3233 3432  9149,  0.5432342
-0000d3a0: 385d 2920 2320 7261 6e64 6f6d 0a0a 2020  8]) # random..  
-0000d3b0: 5468 7265 652d 6279 2d74 776f 2061 7272  Three-by-two arr
-0000d3c0: 6179 206f 6620 7261 6e64 6f6d 206e 756d  ay of random num
-0000d3d0: 6265 7273 2066 726f 6d20 5b2d 352c 2030  bers from [-5, 0
-0000d3e0: 293a 0a0a 2020 3e3e 3e20 3520 2a20 626d  ):..  >>> 5 * bm
-0000d3f0: 2e72 616e 646f 6d2e 7261 6e64 6f6d 5f73  .random.random_s
-0000d400: 616d 706c 6528 2833 2c20 3229 2920 2d20  ample((3, 2)) - 
-0000d410: 350a 2020 6172 7261 7928 5b5b 2d33 2e39  5.  array([[-3.9
-0000d420: 3931 3439 3938 392c 202d 302e 3532 3333  9149989, -0.5233
-0000d430: 3839 3834 5d2c 2023 2072 616e 646f 6d0a  8984], # random.
-0000d440: 2020 2020 2020 2020 205b 2d32 2e39 3930           [-2.990
-0000d450: 3931 3835 382c 202d 302e 3739 3437 3935  91858, -0.794795
-0000d460: 3038 5d2c 0a20 2020 2020 2020 2020 5b2d  08],.         [-
-0000d470: 312e 3233 3230 3433 3435 2c20 2d31 2e37  1.23204345, -1.7
-0000d480: 3532 3234 3439 345d 5d29 0a20 2022 2222  5224494]]).  """
-0000d490: 0a20 2072 6574 7572 6e20 4445 4641 554c  .  return DEFAUL
-0000d4a0: 542e 7261 6e64 6f6d 5f73 616d 706c 6528  T.random_sample(
-0000d4b0: 7369 7a65 2c20 6b65 793d 6b65 7929 0a0a  size, key=key)..
-0000d4c0: 0a64 6566 2072 616e 6628 7369 7a65 3d4e  .def ranf(size=N
-0000d4d0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-0000d4e0: 2020 2222 220a 2020 5468 6973 2069 7320    """.  This is 
-0000d4f0: 616e 2061 6c69 6173 206f 6620 6072 616e  an alias of `ran
-0000d500: 646f 6d5f 7361 6d70 6c65 602e 2053 6565  dom_sample`. See
-0000d510: 2060 7261 6e64 6f6d 5f73 616d 706c 6560   `random_sample`
-0000d520: 2020 666f 7220 7468 6520 636f 6d70 6c65    for the comple
-0000d530: 7465 0a20 2020 2020 2064 6f63 756d 656e  te.      documen
-0000d540: 7461 7469 6f6e 2e0a 2020 2222 220a 2020  tation..  """.  
-0000d550: 7265 7475 726e 2044 4546 4155 4c54 2e72  return DEFAULT.r
-0000d560: 616e 6628 7369 7a65 2c20 6b65 793d 6b65  anf(size, key=ke
-0000d570: 7929 0a0a 0a64 6566 2073 616d 706c 6528  y)...def sample(
-0000d580: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
-0000d590: 6f6e 6529 3a0a 2020 2222 220a 2020 5468  one):.  """.  Th
-0000d5a0: 6973 2069 7320 616e 2061 6c69 6173 206f  is is an alias o
-0000d5b0: 6620 6072 616e 646f 6d5f 7361 6d70 6c65  f `random_sample
-0000d5c0: 602e 2053 6565 2060 7261 6e64 6f6d 5f73  `. See `random_s
-0000d5d0: 616d 706c 6560 2020 666f 7220 7468 6520  ample`  for the 
-0000d5e0: 636f 6d70 6c65 7465 0a20 2020 2020 2064  complete.      d
-0000d5f0: 6f63 756d 656e 7461 7469 6f6e 2e0a 2020  ocumentation..  
-0000d600: 2222 220a 2020 7265 7475 726e 2044 4546  """.  return DEF
-0000d610: 4155 4c54 2e73 616d 706c 6528 7369 7a65  AULT.sample(size
-0000d620: 2c20 6b65 793d 6b65 7929 0a0a 0a64 6566  , key=key)...def
-0000d630: 2063 686f 6963 6528 612c 2073 697a 653d   choice(a, size=
-0000d640: 4e6f 6e65 2c20 7265 706c 6163 653d 5472  None, replace=Tr
-0000d650: 7565 2c20 703d 4e6f 6e65 2c20 6b65 793d  ue, p=None, key=
-0000d660: 4e6f 6e65 293a 0a20 2072 2222 220a 2020  None):.  r""".  
-0000d670: 4765 6e65 7261 7465 7320 6120 7261 6e64  Generates a rand
-0000d680: 6f6d 2073 616d 706c 6520 6672 6f6d 2061  om sample from a
-0000d690: 2067 6976 656e 2031 2d44 2061 7272 6179   given 1-D array
-0000d6a0: 0a0a 2020 5061 7261 6d65 7465 7273 0a20  ..  Parameters. 
-0000d6b0: 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020 6120   ----------.  a 
-0000d6c0: 3a20 312d 4420 6172 7261 792d 6c69 6b65  : 1-D array-like
-0000d6d0: 206f 7220 696e 740a 2020 2020 2020 4966   or int.      If
-0000d6e0: 2061 6e20 6e64 6172 7261 792c 2061 2072   an ndarray, a r
-0000d6f0: 616e 646f 6d20 7361 6d70 6c65 2069 7320  andom sample is 
-0000d700: 6765 6e65 7261 7465 6420 6672 6f6d 2069  generated from i
-0000d710: 7473 2065 6c65 6d65 6e74 732e 0a20 2020  ts elements..   
-0000d720: 2020 2049 6620 616e 2069 6e74 2c20 7468     If an int, th
-0000d730: 6520 7261 6e64 6f6d 2073 616d 706c 6520  e random sample 
-0000d740: 6973 2067 656e 6572 6174 6564 2061 7320  is generated as 
-0000d750: 6966 2069 7420 7765 7265 2060 606e 702e  if it were ``np.
-0000d760: 6172 616e 6765 2861 2960 600a 2020 7369  arange(a)``.  si
-0000d770: 7a65 203a 2069 6e74 206f 7220 7475 706c  ze : int or tupl
-0000d780: 6520 6f66 2069 6e74 732c 206f 7074 696f  e of ints, optio
-0000d790: 6e61 6c0a 2020 2020 2020 4f75 7470 7574  nal.      Output
-0000d7a0: 2073 6861 7065 2e20 2049 6620 7468 6520   shape.  If the 
-0000d7b0: 6769 7665 6e20 7368 6170 6520 6973 2c20  given shape is, 
-0000d7c0: 652e 672e 2c20 6060 286d 2c20 6e2c 206b  e.g., ``(m, n, k
-0000d7d0: 2960 602c 2074 6865 6e0a 2020 2020 2020  )``, then.      
-0000d7e0: 6060 6d20 2a20 6e20 2a20 6b60 6020 7361  ``m * n * k`` sa
-0000d7f0: 6d70 6c65 7320 6172 6520 6472 6177 6e2e  mples are drawn.
-0000d800: 2020 4465 6661 756c 7420 6973 204e 6f6e    Default is Non
-0000d810: 652c 2069 6e20 7768 6963 6820 6361 7365  e, in which case
-0000d820: 2061 0a20 2020 2020 2073 696e 676c 6520   a.      single 
-0000d830: 7661 6c75 6520 6973 2072 6574 7572 6e65  value is returne
-0000d840: 642e 0a20 2072 6570 6c61 6365 203a 2062  d..  replace : b
-0000d850: 6f6f 6c65 616e 2c20 6f70 7469 6f6e 616c  oolean, optional
-0000d860: 0a20 2020 2020 2057 6865 7468 6572 2074  .      Whether t
-0000d870: 6865 2073 616d 706c 6520 6973 2077 6974  he sample is wit
-0000d880: 6820 6f72 2077 6974 686f 7574 2072 6570  h or without rep
-0000d890: 6c61 6365 6d65 6e74 2e20 4465 6661 756c  lacement. Defaul
-0000d8a0: 7420 6973 2054 7275 652c 0a20 2020 2020  t is True,.     
-0000d8b0: 206d 6561 6e69 6e67 2074 6861 7420 6120   meaning that a 
-0000d8c0: 7661 6c75 6520 6f66 2060 6061 6060 2063  value of ``a`` c
-0000d8d0: 616e 2062 6520 7365 6c65 6374 6564 206d  an be selected m
-0000d8e0: 756c 7469 706c 6520 7469 6d65 732e 0a20  ultiple times.. 
-0000d8f0: 2070 203a 2031 2d44 2061 7272 6179 2d6c   p : 1-D array-l
-0000d900: 696b 652c 206f 7074 696f 6e61 6c0a 2020  ike, optional.  
-0000d910: 2020 2020 5468 6520 7072 6f62 6162 696c      The probabil
-0000d920: 6974 6965 7320 6173 736f 6369 6174 6564  ities associated
-0000d930: 2077 6974 6820 6561 6368 2065 6e74 7279   with each entry
-0000d940: 2069 6e20 612e 0a20 2020 2020 2049 6620   in a..      If 
-0000d950: 6e6f 7420 6769 7665 6e2c 2074 6865 2073  not given, the s
-0000d960: 616d 706c 6520 6173 7375 6d65 7320 6120  ample assumes a 
-0000d970: 756e 6966 6f72 6d20 6469 7374 7269 6275  uniform distribu
-0000d980: 7469 6f6e 206f 7665 7220 616c 6c0a 2020  tion over all.  
-0000d990: 2020 2020 656e 7472 6965 7320 696e 2060      entries in `
-0000d9a0: 6061 6060 2e0a 0a20 2052 6574 7572 6e73  `a``...  Returns
-0000d9b0: 0a20 202d 2d2d 2d2d 2d2d 0a20 2073 616d  .  -------.  sam
-0000d9c0: 706c 6573 203a 2073 696e 676c 6520 6974  ples : single it
-0000d9d0: 656d 206f 7220 6e64 6172 7261 790a 2020  em or ndarray.  
-0000d9e0: 2020 2020 5468 6520 6765 6e65 7261 7465      The generate
-0000d9f0: 6420 7261 6e64 6f6d 2073 616d 706c 6573  d random samples
-0000da00: 0a0a 2020 5261 6973 6573 0a20 202d 2d2d  ..  Raises.  ---
-0000da10: 2d2d 2d0a 2020 5661 6c75 6545 7272 6f72  ---.  ValueError
-0000da20: 0a20 2020 2020 2049 6620 6120 6973 2061  .      If a is a
-0000da30: 6e20 696e 7420 616e 6420 6c65 7373 2074  n int and less t
-0000da40: 6861 6e20 7a65 726f 2c20 6966 2061 206f  han zero, if a o
-0000da50: 7220 7020 6172 6520 6e6f 7420 312d 6469  r p are not 1-di
-0000da60: 6d65 6e73 696f 6e61 6c2c 0a20 2020 2020  mensional,.     
-0000da70: 2069 6620 6120 6973 2061 6e20 6172 7261   if a is an arra
-0000da80: 792d 6c69 6b65 206f 6620 7369 7a65 2030  y-like of size 0
-0000da90: 2c20 6966 2070 2069 7320 6e6f 7420 6120  , if p is not a 
-0000daa0: 7665 6374 6f72 206f 660a 2020 2020 2020  vector of.      
-0000dab0: 7072 6f62 6162 696c 6974 6965 732c 2069  probabilities, i
-0000dac0: 6620 6120 616e 6420 7020 6861 7665 2064  f a and p have d
-0000dad0: 6966 6665 7265 6e74 206c 656e 6774 6873  ifferent lengths
-0000dae0: 2c20 6f72 2069 660a 2020 2020 2020 7265  , or if.      re
-0000daf0: 706c 6163 653d 4661 6c73 6520 616e 6420  place=False and 
-0000db00: 7468 6520 7361 6d70 6c65 2073 697a 6520  the sample size 
-0000db10: 6973 2067 7265 6174 6572 2074 6861 6e20  is greater than 
-0000db20: 7468 6520 706f 7075 6c61 7469 6f6e 0a20  the population. 
-0000db30: 2020 2020 2073 697a 650a 0a20 2053 6565       size..  See
-0000db40: 2041 6c73 6f0a 2020 2d2d 2d2d 2d2d 2d2d   Also.  --------
-0000db50: 0a20 2072 616e 6469 6e74 2c20 7368 7566  .  randint, shuf
-0000db60: 666c 652c 2070 6572 6d75 7461 7469 6f6e  fle, permutation
-0000db70: 0a20 2047 656e 6572 6174 6f72 2e63 686f  .  Generator.cho
-0000db80: 6963 653a 2077 6869 6368 2073 686f 756c  ice: which shoul
-0000db90: 6420 6265 2075 7365 6420 696e 206e 6577  d be used in new
-0000dba0: 2063 6f64 650a 0a20 204e 6f74 6573 0a20   code..  Notes. 
-0000dbb0: 202d 2d2d 2d2d 0a20 2053 6574 7469 6e67   -----.  Setting
-0000dbc0: 2075 7365 722d 7370 6563 6966 6965 6420   user-specified 
-0000dbd0: 7072 6f62 6162 696c 6974 6965 7320 7468  probabilities th
-0000dbe0: 726f 7567 6820 6060 7060 6020 7573 6573  rough ``p`` uses
-0000dbf0: 2061 206d 6f72 6520 6765 6e65 7261 6c20   a more general 
-0000dc00: 6275 7420 6c65 7373 0a20 2065 6666 6963  but less.  effic
-0000dc10: 6965 6e74 2073 616d 706c 6572 2074 6861  ient sampler tha
-0000dc20: 6e20 7468 6520 6465 6661 756c 742e 2054  n the default. T
-0000dc30: 6865 2067 656e 6572 616c 2073 616d 706c  he general sampl
-0000dc40: 6572 2070 726f 6475 6365 7320 6120 6469  er produces a di
-0000dc50: 6666 6572 656e 7420 7361 6d70 6c65 0a20  fferent sample. 
-0000dc60: 2074 6861 6e20 7468 6520 6f70 7469 6d69   than the optimi
-0000dc70: 7a65 6420 7361 6d70 6c65 7220 6576 656e  zed sampler even
-0000dc80: 2069 6620 6561 6368 2065 6c65 6d65 6e74   if each element
-0000dc90: 206f 6620 6060 7060 6020 6973 2031 202f   of ``p`` is 1 /
-0000dca0: 206c 656e 2861 292e 0a0a 2020 5361 6d70   len(a)...  Samp
-0000dcb0: 6c69 6e67 2072 616e 646f 6d20 726f 7773  ling random rows
-0000dcc0: 2066 726f 6d20 6120 322d 4420 6172 7261   from a 2-D arra
-0000dcd0: 7920 6973 206e 6f74 2070 6f73 7369 626c  y is not possibl
-0000dce0: 6520 7769 7468 2074 6869 7320 6675 6e63  e with this func
-0000dcf0: 7469 6f6e 2c0a 2020 6275 7420 6973 2070  tion,.  but is p
-0000dd00: 6f73 7369 626c 6520 7769 7468 2060 4765  ossible with `Ge
-0000dd10: 6e65 7261 746f 722e 6368 6f69 6365 6020  nerator.choice` 
-0000dd20: 7468 726f 7567 6820 6974 7320 6060 6178  through its ``ax
-0000dd30: 6973 6060 206b 6579 776f 7264 2e0a 0a20  is`` keyword... 
-0000dd40: 2045 7861 6d70 6c65 730a 2020 2d2d 2d2d   Examples.  ----
-0000dd50: 2d2d 2d2d 0a20 2047 656e 6572 6174 6520  ----.  Generate 
-0000dd60: 6120 756e 6966 6f72 6d20 7261 6e64 6f6d  a uniform random
-0000dd70: 2073 616d 706c 6520 6672 6f6d 206e 702e   sample from np.
-0000dd80: 6172 616e 6765 2835 2920 6f66 2073 697a  arange(5) of siz
-0000dd90: 6520 333a 0a0a 2020 3e3e 3e20 696d 706f  e 3:..  >>> impo
-0000dda0: 7274 2062 7261 696e 7079 2e6d 6174 6820  rt brainpy.math 
-0000ddb0: 6173 2062 6d0a 2020 3e3e 3e20 626d 2e72  as bm.  >>> bm.r
-0000ddc0: 616e 646f 6d2e 6368 6f69 6365 2835 2c20  andom.choice(5, 
-0000ddd0: 3329 0a20 2061 7272 6179 285b 302c 2033  3).  array([0, 3
-0000dde0: 2c20 345d 2920 2320 7261 6e64 6f6d 0a20  , 4]) # random. 
-0000ddf0: 203e 3e3e 2023 5468 6973 2069 7320 6571   >>> #This is eq
-0000de00: 7569 7661 6c65 6e74 2074 6f20 6272 6169  uivalent to brai
-0000de10: 6e70 792e 6d61 7468 2e72 616e 646f 6d2e  npy.math.random.
-0000de20: 7261 6e64 696e 7428 302c 352c 3329 0a0a  randint(0,5,3)..
-0000de30: 2020 4765 6e65 7261 7465 2061 206e 6f6e    Generate a non
-0000de40: 2d75 6e69 666f 726d 2072 616e 646f 6d20  -uniform random 
-0000de50: 7361 6d70 6c65 2066 726f 6d20 6e70 2e61  sample from np.a
-0000de60: 7261 6e67 6528 3529 206f 6620 7369 7a65  range(5) of size
-0000de70: 2033 3a0a 0a20 203e 3e3e 2062 6d2e 7261   3:..  >>> bm.ra
-0000de80: 6e64 6f6d 2e63 686f 6963 6528 352c 2033  ndom.choice(5, 3
-0000de90: 2c20 703d 5b30 2e31 2c20 302c 2030 2e33  , p=[0.1, 0, 0.3
-0000dea0: 2c20 302e 362c 2030 5d29 0a20 2061 7272  , 0.6, 0]).  arr
-0000deb0: 6179 285b 332c 2033 2c20 305d 2920 2320  ay([3, 3, 0]) # 
-0000dec0: 7261 6e64 6f6d 0a0a 2020 4765 6e65 7261  random..  Genera
-0000ded0: 7465 2061 2075 6e69 666f 726d 2072 616e  te a uniform ran
-0000dee0: 646f 6d20 7361 6d70 6c65 2066 726f 6d20  dom sample from 
-0000def0: 6e70 2e61 7261 6e67 6528 3529 206f 6620  np.arange(5) of 
-0000df00: 7369 7a65 2033 2077 6974 686f 7574 0a20  size 3 without. 
-0000df10: 2072 6570 6c61 6365 6d65 6e74 3a0a 0a20   replacement:.. 
-0000df20: 203e 3e3e 2062 6d2e 7261 6e64 6f6d 2e63   >>> bm.random.c
-0000df30: 686f 6963 6528 352c 2033 2c20 7265 706c  hoice(5, 3, repl
-0000df40: 6163 653d 4661 6c73 6529 0a20 2061 7272  ace=False).  arr
-0000df50: 6179 285b 332c 312c 305d 2920 2320 7261  ay([3,1,0]) # ra
-0000df60: 6e64 6f6d 0a20 203e 3e3e 2023 5468 6973  ndom.  >>> #This
-0000df70: 2069 7320 6571 7569 7661 6c65 6e74 2074   is equivalent t
-0000df80: 6f20 6272 6169 6e70 792e 6d61 7468 2e72  o brainpy.math.r
-0000df90: 616e 646f 6d2e 7065 726d 7574 6174 696f  andom.permutatio
-0000dfa0: 6e28 6e70 2e61 7261 6e67 6528 3529 295b  n(np.arange(5))[
-0000dfb0: 3a33 5d0a 0a20 2047 656e 6572 6174 6520  :3]..  Generate 
-0000dfc0: 6120 6e6f 6e2d 756e 6966 6f72 6d20 7261  a non-uniform ra
-0000dfd0: 6e64 6f6d 2073 616d 706c 6520 6672 6f6d  ndom sample from
-0000dfe0: 206e 702e 6172 616e 6765 2835 2920 6f66   np.arange(5) of
-0000dff0: 2073 697a 650a 2020 3320 7769 7468 6f75   size.  3 withou
-0000e000: 7420 7265 706c 6163 656d 656e 743a 0a0a  t replacement:..
-0000e010: 2020 3e3e 3e20 626d 2e72 616e 646f 6d2e    >>> bm.random.
-0000e020: 6368 6f69 6365 2835 2c20 332c 2072 6570  choice(5, 3, rep
-0000e030: 6c61 6365 3d46 616c 7365 2c20 703d 5b30  lace=False, p=[0
-0000e040: 2e31 2c20 302c 2030 2e33 2c20 302e 362c  .1, 0, 0.3, 0.6,
-0000e050: 2030 5d29 0a20 2061 7272 6179 285b 322c   0]).  array([2,
-0000e060: 2033 2c20 305d 2920 2320 7261 6e64 6f6d   3, 0]) # random
-0000e070: 0a0a 2020 416e 7920 6f66 2074 6865 2061  ..  Any of the a
-0000e080: 626f 7665 2063 616e 2062 6520 7265 7065  bove can be repe
-0000e090: 6174 6564 2077 6974 6820 616e 2061 7262  ated with an arb
-0000e0a0: 6974 7261 7279 2061 7272 6179 2d6c 696b  itrary array-lik
-0000e0b0: 650a 2020 696e 7374 6561 6420 6f66 206a  e.  instead of j
-0000e0c0: 7573 7420 696e 7465 6765 7273 2e20 466f  ust integers. Fo
-0000e0d0: 7220 696e 7374 616e 6365 3a0a 0a20 203e  r instance:..  >
-0000e0e0: 3e3e 2061 615f 6d69 6c6e 655f 6172 7220  >> aa_milne_arr 
-0000e0f0: 3d20 5b27 706f 6f68 272c 2027 7261 6262  = ['pooh', 'rabb
-0000e100: 6974 272c 2027 7069 676c 6574 272c 2027  it', 'piglet', '
-0000e110: 4368 7269 7374 6f70 6865 7227 5d0a 2020  Christopher'].  
-0000e120: 3e3e 3e20 626d 2e72 616e 646f 6d2e 6368  >>> bm.random.ch
-0000e130: 6f69 6365 2861 615f 6d69 6c6e 655f 6172  oice(aa_milne_ar
-0000e140: 722c 2035 2c20 703d 5b30 2e35 2c20 302e  r, 5, p=[0.5, 0.
-0000e150: 312c 2030 2e31 2c20 302e 335d 290a 2020  1, 0.1, 0.3]).  
-0000e160: 6172 7261 7928 5b27 706f 6f68 272c 2027  array(['pooh', '
-0000e170: 706f 6f68 272c 2027 706f 6f68 272c 2027  pooh', 'pooh', '
-0000e180: 4368 7269 7374 6f70 6865 7227 2c20 2770  Christopher', 'p
-0000e190: 6967 6c65 7427 5d2c 2023 2072 616e 646f  iglet'], # rando
-0000e1a0: 6d0a 2020 2020 2020 2020 6474 7970 653d  m.        dtype=
-0000e1b0: 273c 5531 3127 290a 2020 2222 220a 2020  '<U11').  """.  
-0000e1c0: 6120 3d20 5f61 735f 6a61 785f 6172 7261  a = _as_jax_arra
-0000e1d0: 7928 6129 0a20 2072 6574 7572 6e20 4445  y(a).  return DE
-0000e1e0: 4641 554c 542e 6368 6f69 6365 2861 3d61  FAULT.choice(a=a
-0000e1f0: 2c20 7369 7a65 3d73 697a 652c 2072 6570  , size=size, rep
-0000e200: 6c61 6365 3d72 6570 6c61 6365 2c20 703d  lace=replace, p=
-0000e210: 702c 206b 6579 3d6b 6579 290a 0a0a 6465  p, key=key)...de
-0000e220: 6620 7065 726d 7574 6174 696f 6e28 782c  f permutation(x,
-0000e230: 2061 7869 733a 2069 6e74 203d 2030 2c20   axis: int = 0, 
-0000e240: 696e 6465 7065 6e64 656e 743a 2062 6f6f  independent: boo
-0000e250: 6c20 3d20 4661 6c73 652c 206b 6579 3d4e  l = False, key=N
-0000e260: 6f6e 6529 3a0a 2020 7222 2222 0a20 2052  one):.  r""".  R
-0000e270: 616e 646f 6d6c 7920 7065 726d 7574 6520  andomly permute 
-0000e280: 6120 7365 7175 656e 6365 2c20 6f72 2072  a sequence, or r
-0000e290: 6574 7572 6e20 6120 7065 726d 7574 6564  eturn a permuted
-0000e2a0: 2072 616e 6765 2e0a 0a20 2049 6620 6078   range...  If `x
-0000e2b0: 6020 6973 2061 206d 756c 7469 2d64 696d  ` is a multi-dim
-0000e2c0: 656e 7369 6f6e 616c 2061 7272 6179 2c20  ensional array, 
-0000e2d0: 6974 2069 7320 6f6e 6c79 2073 6875 6666  it is only shuff
-0000e2e0: 6c65 6420 616c 6f6e 6720 6974 730a 2020  led along its.  
-0000e2f0: 6669 7273 7420 696e 6465 782e 0a0a 2020  first index...  
-0000e300: 5061 7261 6d65 7465 7273 0a20 202d 2d2d  Parameters.  ---
-0000e310: 2d2d 2d2d 2d2d 2d0a 2020 7820 3a20 696e  -------.  x : in
-0000e320: 7420 6f72 2061 7272 6179 5f6c 696b 650a  t or array_like.
-0000e330: 2020 2020 2020 4966 2060 7860 2069 7320        If `x` is 
-0000e340: 616e 2069 6e74 6567 6572 2c20 7261 6e64  an integer, rand
-0000e350: 6f6d 6c79 2070 6572 6d75 7465 2060 606e  omly permute ``n
-0000e360: 702e 6172 616e 6765 2878 2960 602e 0a20  p.arange(x)``.. 
-0000e370: 2020 2020 2049 6620 6078 6020 6973 2061       If `x` is a
-0000e380: 6e20 6172 7261 792c 206d 616b 6520 6120  n array, make a 
-0000e390: 636f 7079 2061 6e64 2073 6875 6666 6c65  copy and shuffle
-0000e3a0: 2074 6865 2065 6c65 6d65 6e74 730a 2020   the elements.  
-0000e3b0: 2020 2020 7261 6e64 6f6d 6c79 2e0a 0a20      randomly... 
-0000e3c0: 2052 6574 7572 6e73 0a20 202d 2d2d 2d2d   Returns.  -----
-0000e3d0: 2d2d 0a20 206f 7574 203a 206e 6461 7272  --.  out : ndarr
-0000e3e0: 6179 0a20 2020 2020 2050 6572 6d75 7465  ay.      Permute
-0000e3f0: 6420 7365 7175 656e 6365 206f 7220 6172  d sequence or ar
-0000e400: 7261 7920 7261 6e67 652e 0a0a 2020 5365  ray range...  Se
-0000e410: 6520 416c 736f 0a20 202d 2d2d 2d2d 2d2d  e Also.  -------
-0000e420: 2d0a 2020 7261 6e64 6f6d 2e47 656e 6572  -.  random.Gener
-0000e430: 6174 6f72 2e70 6572 6d75 7461 7469 6f6e  ator.permutation
-0000e440: 3a20 7768 6963 6820 7368 6f75 6c64 2062  : which should b
-0000e450: 6520 7573 6564 2066 6f72 206e 6577 2063  e used for new c
-0000e460: 6f64 652e 0a0a 2020 4578 616d 706c 6573  ode...  Examples
-0000e470: 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020 3e3e  .  --------.  >>
-0000e480: 3e20 696d 706f 7274 2062 7261 696e 7079  > import brainpy
-0000e490: 2e6d 6174 6820 6173 2062 6d0a 2020 3e3e  .math as bm.  >>
-0000e4a0: 3e20 626d 2e72 616e 646f 6d2e 7065 726d  > bm.random.perm
-0000e4b0: 7574 6174 696f 6e28 3130 290a 2020 6172  utation(10).  ar
-0000e4c0: 7261 7928 5b31 2c20 372c 2034 2c20 332c  ray([1, 7, 4, 3,
-0000e4d0: 2030 2c20 392c 2032 2c20 352c 2038 2c20   0, 9, 2, 5, 8, 
-0000e4e0: 365d 2920 2320 7261 6e64 6f6d 0a0a 2020  6]) # random..  
-0000e4f0: 3e3e 3e20 626d 2e72 616e 646f 6d2e 7065  >>> bm.random.pe
-0000e500: 726d 7574 6174 696f 6e28 5b31 2c20 342c  rmutation([1, 4,
-0000e510: 2039 2c20 3132 2c20 3135 5d29 0a20 2061   9, 12, 15]).  a
-0000e520: 7272 6179 285b 3135 2c20 2031 2c20 2039  rray([15,  1,  9
-0000e530: 2c20 2034 2c20 3132 5d29 2023 2072 616e  ,  4, 12]) # ran
-0000e540: 646f 6d0a 0a20 203e 3e3e 2061 7272 203d  dom..  >>> arr =
-0000e550: 206e 702e 6172 616e 6765 2839 292e 7265   np.arange(9).re
-0000e560: 7368 6170 6528 2833 2c20 3329 290a 2020  shape((3, 3)).  
-0000e570: 3e3e 3e20 626d 2e72 616e 646f 6d2e 7065  >>> bm.random.pe
-0000e580: 726d 7574 6174 696f 6e28 6172 7229 0a20  rmutation(arr). 
-0000e590: 2061 7272 6179 285b 5b36 2c20 372c 2038   array([[6, 7, 8
-0000e5a0: 5d2c 2023 2072 616e 646f 6d0a 2020 2020  ], # random.    
-0000e5b0: 2020 2020 205b 302c 2031 2c20 325d 2c0a       [0, 1, 2],.
-0000e5c0: 2020 2020 2020 2020 205b 332c 2034 2c20           [3, 4, 
-0000e5d0: 355d 5d29 0a20 2022 2222 0a20 2072 6574  5]]).  """.  ret
-0000e5e0: 7572 6e20 4445 4641 554c 542e 7065 726d  urn DEFAULT.perm
-0000e5f0: 7574 6174 696f 6e28 782c 2061 7869 733d  utation(x, axis=
-0000e600: 6178 6973 2c20 696e 6465 7065 6e64 656e  axis, independen
-0000e610: 743d 696e 6465 7065 6e64 656e 742c 206b  t=independent, k
-0000e620: 6579 3d6b 6579 290a 0a0a 6465 6620 7368  ey=key)...def sh
-0000e630: 7566 666c 6528 782c 2061 7869 733d 302c  uffle(x, axis=0,
-0000e640: 206b 6579 3d4e 6f6e 6529 3a0a 2020 7222   key=None):.  r"
-0000e650: 2222 0a20 204d 6f64 6966 7920 6120 7365  "".  Modify a se
-0000e660: 7175 656e 6365 2069 6e2d 706c 6163 6520  quence in-place 
-0000e670: 6279 2073 6875 6666 6c69 6e67 2069 7473  by shuffling its
-0000e680: 2063 6f6e 7465 6e74 732e 0a0a 2020 5468   contents...  Th
-0000e690: 6973 2066 756e 6374 696f 6e20 6f6e 6c79  is function only
-0000e6a0: 2073 6875 6666 6c65 7320 7468 6520 6172   shuffles the ar
-0000e6b0: 7261 7920 616c 6f6e 6720 7468 6520 6669  ray along the fi
-0000e6c0: 7273 7420 6178 6973 206f 6620 610a 2020  rst axis of a.  
-0000e6d0: 6d75 6c74 692d 6469 6d65 6e73 696f 6e61  multi-dimensiona
-0000e6e0: 6c20 6172 7261 792e 2054 6865 206f 7264  l array. The ord
-0000e6f0: 6572 206f 6620 7375 622d 6172 7261 7973  er of sub-arrays
-0000e700: 2069 7320 6368 616e 6765 6420 6275 740a   is changed but.
-0000e710: 2020 7468 6569 7220 636f 6e74 656e 7473    their contents
-0000e720: 2072 656d 6169 6e73 2074 6865 2073 616d   remains the sam
-0000e730: 652e 0a0a 2020 5061 7261 6d65 7465 7273  e...  Parameters
-0000e740: 0a20 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  .  ----------.  
-0000e750: 7820 3a20 6e64 6172 7261 7920 6f72 204d  x : ndarray or M
-0000e760: 7574 6162 6c65 5365 7175 656e 6365 0a20  utableSequence. 
-0000e770: 2020 2020 2054 6865 2061 7272 6179 2c20       The array, 
-0000e780: 6c69 7374 206f 7220 6d75 7461 626c 6520  list or mutable 
-0000e790: 7365 7175 656e 6365 2074 6f20 6265 2073  sequence to be s
-0000e7a0: 6875 6666 6c65 642e 0a0a 2020 5265 7475  huffled...  Retu
-0000e7b0: 726e 730a 2020 2d2d 2d2d 2d2d 2d0a 2020  rns.  -------.  
-0000e7c0: 4e6f 6e65 0a0a 2020 5365 6520 416c 736f  None..  See Also
-0000e7d0: 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020 7261  .  --------.  ra
-0000e7e0: 6e64 6f6d 2e47 656e 6572 6174 6f72 2e73  ndom.Generator.s
-0000e7f0: 6875 6666 6c65 3a20 7768 6963 6820 7368  huffle: which sh
-0000e800: 6f75 6c64 2062 6520 7573 6564 2066 6f72  ould be used for
-0000e810: 206e 6577 2063 6f64 652e 0a0a 2020 4578   new code...  Ex
-0000e820: 616d 706c 6573 0a20 202d 2d2d 2d2d 2d2d  amples.  -------
-0000e830: 2d0a 2020 3e3e 3e20 696d 706f 7274 2062  -.  >>> import b
-0000e840: 7261 696e 7079 2e6d 6174 6820 6173 2062  rainpy.math as b
-0000e850: 6d0a 2020 3e3e 3e20 6172 7220 3d20 6e70  m.  >>> arr = np
-0000e860: 2e61 7261 6e67 6528 3130 290a 2020 3e3e  .arange(10).  >>
-0000e870: 3e20 626d 2e72 616e 646f 6d2e 7368 7566  > bm.random.shuf
-0000e880: 666c 6528 6172 7229 0a20 203e 3e3e 2061  fle(arr).  >>> a
-0000e890: 7272 0a20 205b 3120 3720 3520 3220 3920  rr.  [1 7 5 2 9 
-0000e8a0: 3420 3320 3620 3020 385d 2023 2072 616e  4 3 6 0 8] # ran
-0000e8b0: 646f 6d0a 0a20 204d 756c 7469 2d64 696d  dom..  Multi-dim
-0000e8c0: 656e 7369 6f6e 616c 2061 7272 6179 7320  ensional arrays 
-0000e8d0: 6172 6520 6f6e 6c79 2073 6875 6666 6c65  are only shuffle
-0000e8e0: 6420 616c 6f6e 6720 7468 6520 6669 7273  d along the firs
-0000e8f0: 7420 6178 6973 3a0a 0a20 203e 3e3e 2061  t axis:..  >>> a
-0000e900: 7272 203d 206e 702e 6172 616e 6765 2839  rr = np.arange(9
-0000e910: 292e 7265 7368 6170 6528 2833 2c20 3329  ).reshape((3, 3)
-0000e920: 290a 2020 3e3e 3e20 626d 2e72 616e 646f  ).  >>> bm.rando
-0000e930: 6d2e 7368 7566 666c 6528 6172 7229 0a20  m.shuffle(arr). 
-0000e940: 203e 3e3e 2061 7272 0a20 2061 7272 6179   >>> arr.  array
-0000e950: 285b 5b33 2c20 342c 2035 5d2c 2023 2072  ([[3, 4, 5], # r
-0000e960: 616e 646f 6d0a 2020 2020 2020 2020 205b  andom.         [
-0000e970: 362c 2037 2c20 385d 2c0a 2020 2020 2020  6, 7, 8],.      
-0000e980: 2020 205b 302c 2031 2c20 325d 5d29 0a20     [0, 1, 2]]). 
-0000e990: 2022 2222 0a20 2044 4546 4155 4c54 2e73   """.  DEFAULT.s
-0000e9a0: 6875 6666 6c65 2878 2c20 6178 6973 2c20  huffle(x, axis, 
-0000e9b0: 6b65 793d 6b65 7929 0a0a 0a64 6566 2062  key=key)...def b
-0000e9c0: 6574 6128 612c 2062 2c20 7369 7a65 3d4e  eta(a, b, size=N
-0000e9d0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-0000e9e0: 2020 7222 2222 0a20 2044 7261 7720 7361    r""".  Draw sa
-0000e9f0: 6d70 6c65 7320 6672 6f6d 2061 2042 6574  mples from a Bet
-0000ea00: 6120 6469 7374 7269 6275 7469 6f6e 2e0a  a distribution..
-0000ea10: 0a20 2054 6865 2042 6574 6120 6469 7374  .  The Beta dist
-0000ea20: 7269 6275 7469 6f6e 2069 7320 6120 7370  ribution is a sp
-0000ea30: 6563 6961 6c20 6361 7365 206f 6620 7468  ecial case of th
-0000ea40: 6520 4469 7269 6368 6c65 7420 6469 7374  e Dirichlet dist
-0000ea50: 7269 6275 7469 6f6e 2c0a 2020 616e 6420  ribution,.  and 
-0000ea60: 6973 2072 656c 6174 6564 2074 6f20 7468  is related to th
-0000ea70: 6520 4761 6d6d 6120 6469 7374 7269 6275  e Gamma distribu
-0000ea80: 7469 6f6e 2e20 2049 7420 6861 7320 7468  tion.  It has th
-0000ea90: 6520 7072 6f62 6162 696c 6974 790a 2020  e probability.  
-0000eaa0: 6469 7374 7269 6275 7469 6f6e 2066 756e  distribution fun
-0000eab0: 6374 696f 6e0a 0a20 202e 2e20 6d61 7468  ction..  .. math
-0000eac0: 3a3a 2066 2878 3b20 612c 6229 203d 205c  :: f(x; a,b) = \
-0000ead0: 6672 6163 7b31 7d7b 4228 5c61 6c70 6861  frac{1}{B(\alpha
-0000eae0: 2c20 5c62 6574 6129 7d20 785e 7b5c 616c  , \beta)} x^{\al
-0000eaf0: 7068 6120 2d20 317d 0a20 2020 2020 2020  pha - 1}.       
-0000eb00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eb10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eb20: 2020 2020 2020 2020 2020 2020 2831 202d              (1 -
-0000eb30: 2078 295e 7b5c 6265 7461 202d 2031 7d2c   x)^{\beta - 1},
-0000eb40: 0a0a 2020 7768 6572 6520 7468 6520 6e6f  ..  where the no
-0000eb50: 726d 616c 697a 6174 696f 6e2c 2042 2c20  rmalization, B, 
-0000eb60: 6973 2074 6865 2062 6574 6120 6675 6e63  is the beta func
-0000eb70: 7469 6f6e 2c0a 0a20 202e 2e20 6d61 7468  tion,..  .. math
-0000eb80: 3a3a 2042 285c 616c 7068 612c 205c 6265  :: B(\alpha, \be
-0000eb90: 7461 2920 3d20 5c69 6e74 5f30 5e31 2074  ta) = \int_0^1 t
-0000eba0: 5e7b 5c61 6c70 6861 202d 2031 7d0a 2020  ^{\alpha - 1}.  
-0000ebb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ebc0: 2020 2020 2020 2020 2020 2020 2028 3120               (1 
-0000ebd0: 2d20 7429 5e7b 5c62 6574 6120 2d20 317d  - t)^{\beta - 1}
-0000ebe0: 2064 742e 0a0a 2020 4974 2069 7320 6f66   dt...  It is of
-0000ebf0: 7465 6e20 7365 656e 2069 6e20 4261 7965  ten seen in Baye
-0000ec00: 7369 616e 2069 6e66 6572 656e 6365 2061  sian inference a
-0000ec10: 6e64 206f 7264 6572 2073 7461 7469 7374  nd order statist
-0000ec20: 6963 732e 0a0a 2020 5061 7261 6d65 7465  ics...  Paramete
-0000ec30: 7273 0a20 202d 2d2d 2d2d 2d2d 2d2d 2d0a  rs.  ----------.
-0000ec40: 2020 6120 3a20 666c 6f61 7420 6f72 2061    a : float or a
-0000ec50: 7272 6179 5f6c 696b 6520 6f66 2066 6c6f  rray_like of flo
-0000ec60: 6174 730a 2020 2020 2020 416c 7068 612c  ats.      Alpha,
-0000ec70: 2070 6f73 6974 6976 6520 283e 3029 2e0a   positive (>0)..
-0000ec80: 2020 6220 3a20 666c 6f61 7420 6f72 2061    b : float or a
-0000ec90: 7272 6179 5f6c 696b 6520 6f66 2066 6c6f  rray_like of flo
-0000eca0: 6174 730a 2020 2020 2020 4265 7461 2c20  ats.      Beta, 
-0000ecb0: 706f 7369 7469 7665 2028 3e30 292e 0a20  positive (>0).. 
-0000ecc0: 2073 697a 6520 3a20 696e 7420 6f72 2074   size : int or t
-0000ecd0: 7570 6c65 206f 6620 696e 7473 2c20 6f70  uple of ints, op
-0000ece0: 7469 6f6e 616c 0a20 2020 2020 204f 7574  tional.      Out
-0000ecf0: 7075 7420 7368 6170 652e 2020 4966 2074  put shape.  If t
-0000ed00: 6865 2067 6976 656e 2073 6861 7065 2069  he given shape i
-0000ed10: 732c 2065 2e67 2e2c 2060 6028 6d2c 206e  s, e.g., ``(m, n
-0000ed20: 2c20 6b29 6060 2c20 7468 656e 0a20 2020  , k)``, then.   
-0000ed30: 2020 2060 606d 202a 206e 202a 206b 6060     ``m * n * k``
-0000ed40: 2073 616d 706c 6573 2061 7265 2064 7261   samples are dra
-0000ed50: 776e 2e20 2049 6620 7369 7a65 2069 7320  wn.  If size is 
-0000ed60: 6060 4e6f 6e65 6060 2028 6465 6661 756c  ``None`` (defaul
-0000ed70: 7429 2c0a 2020 2020 2020 6120 7369 6e67  t),.      a sing
-0000ed80: 6c65 2076 616c 7565 2069 7320 7265 7475  le value is retu
-0000ed90: 726e 6564 2069 6620 6060 6160 6020 616e  rned if ``a`` an
-0000eda0: 6420 6060 6260 6020 6172 6520 626f 7468  d ``b`` are both
-0000edb0: 2073 6361 6c61 7273 2e0a 2020 2020 2020   scalars..      
-0000edc0: 4f74 6865 7277 6973 652c 2060 606e 702e  Otherwise, ``np.
-0000edd0: 6272 6f61 6463 6173 7428 612c 2062 292e  broadcast(a, b).
-0000ede0: 7369 7a65 6060 2073 616d 706c 6573 2061  size`` samples a
-0000edf0: 7265 2064 7261 776e 2e0a 0a20 2052 6574  re drawn...  Ret
-0000ee00: 7572 6e73 0a20 202d 2d2d 2d2d 2d2d 0a20  urns.  -------. 
-0000ee10: 206f 7574 203a 206e 6461 7272 6179 206f   out : ndarray o
-0000ee20: 7220 7363 616c 6172 0a20 2020 2020 2044  r scalar.      D
-0000ee30: 7261 776e 2073 616d 706c 6573 2066 726f  rawn samples fro
-0000ee40: 6d20 7468 6520 7061 7261 6d65 7465 7269  m the parameteri
-0000ee50: 7a65 6420 6265 7461 2064 6973 7472 6962  zed beta distrib
-0000ee60: 7574 696f 6e2e 0a0a 2020 5365 6520 416c  ution...  See Al
-0000ee70: 736f 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020  so.  --------.  
-0000ee80: 7261 6e64 6f6d 2e47 656e 6572 6174 6f72  random.Generator
-0000ee90: 2e62 6574 613a 2077 6869 6368 2073 686f  .beta: which sho
-0000eea0: 756c 6420 6265 2075 7365 6420 666f 7220  uld be used for 
-0000eeb0: 6e65 7720 636f 6465 2e0a 2020 2222 220a  new code..  """.
-0000eec0: 2020 7265 7475 726e 2044 4546 4155 4c54    return DEFAULT
-0000eed0: 2e62 6574 6128 612c 2062 2c20 7369 7a65  .beta(a, b, size
-0000eee0: 3d73 697a 652c 206b 6579 3d6b 6579 290a  =size, key=key).
-0000eef0: 0a0a 2320 4077 7261 7073 286e 702e 7261  ..# @wraps(np.ra
-0000ef00: 6e64 6f6d 2e65 7870 6f6e 656e 7469 616c  ndom.exponential
-0000ef10: 290a 6465 6620 6578 706f 6e65 6e74 6961  ).def exponentia
-0000ef20: 6c28 7363 616c 653d 4e6f 6e65 2c20 7369  l(scale=None, si
-0000ef30: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
-0000ef40: 6529 3a0a 2020 7265 7475 726e 2044 4546  e):.  return DEF
-0000ef50: 4155 4c54 2e65 7870 6f6e 656e 7469 616c  AULT.exponential
-0000ef60: 2873 6361 6c65 2c20 7369 7a65 2c20 6b65  (scale, size, ke
-0000ef70: 793d 6b65 7929 0a0a 0a23 2040 7772 6170  y=key)...# @wrap
-0000ef80: 7328 6e70 2e72 616e 646f 6d2e 6761 6d6d  s(np.random.gamm
-0000ef90: 6129 0a64 6566 2067 616d 6d61 2873 6861  a).def gamma(sha
-0000efa0: 7065 2c20 7363 616c 653d 4e6f 6e65 2c20  pe, scale=None, 
-0000efb0: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
-0000efc0: 6f6e 6529 3a0a 2020 7265 7475 726e 2044  one):.  return D
-0000efd0: 4546 4155 4c54 2e67 616d 6d61 2873 6861  EFAULT.gamma(sha
-0000efe0: 7065 2c20 7363 616c 652c 2073 697a 653d  pe, scale, size=
-0000eff0: 7369 7a65 2c20 6b65 793d 6b65 7929 0a0a  size, key=key)..
-0000f000: 0a23 2040 7772 6170 7328 6e70 2e72 616e  .# @wraps(np.ran
-0000f010: 646f 6d2e 6775 6d62 656c 290a 6465 6620  dom.gumbel).def 
-0000f020: 6775 6d62 656c 286c 6f63 3d4e 6f6e 652c  gumbel(loc=None,
-0000f030: 2073 6361 6c65 3d4e 6f6e 652c 2073 697a   scale=None, siz
-0000f040: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
-0000f050: 293a 0a20 2072 6574 7572 6e20 4445 4641  ):.  return DEFA
-0000f060: 554c 542e 6775 6d62 656c 286c 6f63 2c20  ULT.gumbel(loc, 
-0000f070: 7363 616c 652c 2073 697a 653d 7369 7a65  scale, size=size
-0000f080: 2c20 6b65 793d 6b65 7929 0a0a 0a23 2040  , key=key)...# @
-0000f090: 7772 6170 7328 6e70 2e72 616e 646f 6d2e  wraps(np.random.
-0000f0a0: 6c61 706c 6163 6529 0a64 6566 206c 6170  laplace).def lap
-0000f0b0: 6c61 6365 286c 6f63 3d4e 6f6e 652c 2073  lace(loc=None, s
-0000f0c0: 6361 6c65 3d4e 6f6e 652c 2073 697a 653d  cale=None, size=
-0000f0d0: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
-0000f0e0: 0a20 2072 6574 7572 6e20 4445 4641 554c  .  return DEFAUL
-0000f0f0: 542e 6c61 706c 6163 6528 6c6f 632c 2073  T.laplace(loc, s
-0000f100: 6361 6c65 2c20 7369 7a65 2c20 6b65 793d  cale, size, key=
-0000f110: 6b65 7929 0a0a 0a23 2040 7772 6170 7328  key)...# @wraps(
-0000f120: 6e70 2e72 616e 646f 6d2e 6c6f 6769 7374  np.random.logist
-0000f130: 6963 290a 6465 6620 6c6f 6769 7374 6963  ic).def logistic
-0000f140: 286c 6f63 3d4e 6f6e 652c 2073 6361 6c65  (loc=None, scale
-0000f150: 3d4e 6f6e 652c 2073 697a 653d 4e6f 6e65  =None, size=None
-0000f160: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2072  , key=None):.  r
-0000f170: 6574 7572 6e20 4445 4641 554c 542e 6c6f  eturn DEFAULT.lo
-0000f180: 6769 7374 6963 286c 6f63 2c20 7363 616c  gistic(loc, scal
-0000f190: 652c 2073 697a 652c 206b 6579 3d6b 6579  e, size, key=key
-0000f1a0: 290a 0a0a 2320 4077 7261 7073 286e 702e  )...# @wraps(np.
-0000f1b0: 7261 6e64 6f6d 2e6e 6f72 6d61 6c29 0a64  random.normal).d
-0000f1c0: 6566 206e 6f72 6d61 6c28 6c6f 633d 4e6f  ef normal(loc=No
-0000f1d0: 6e65 2c20 7363 616c 653d 4e6f 6e65 2c20  ne, scale=None, 
-0000f1e0: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
-0000f1f0: 6f6e 6529 3a0a 2020 7265 7475 726e 2044  one):.  return D
-0000f200: 4546 4155 4c54 2e6e 6f72 6d61 6c28 6c6f  EFAULT.normal(lo
-0000f210: 632c 2073 6361 6c65 2c20 7369 7a65 2c20  c, scale, size, 
-0000f220: 6b65 793d 6b65 7929 0a0a 0a23 2040 7772  key=key)...# @wr
-0000f230: 6170 7328 6e70 2e72 616e 646f 6d2e 7061  aps(np.random.pa
-0000f240: 7265 746f 290a 6465 6620 7061 7265 746f  reto).def pareto
-0000f250: 2861 2c20 7369 7a65 3d4e 6f6e 652c 206b  (a, size=None, k
-0000f260: 6579 3d4e 6f6e 6529 3a0a 2020 7265 7475  ey=None):.  retu
-0000f270: 726e 2044 4546 4155 4c54 2e70 6172 6574  rn DEFAULT.paret
-0000f280: 6f28 612c 2073 697a 652c 206b 6579 3d6b  o(a, size, key=k
-0000f290: 6579 290a 0a0a 2320 4077 7261 7073 286e  ey)...# @wraps(n
-0000f2a0: 702e 7261 6e64 6f6d 2e70 6f69 7373 6f6e  p.random.poisson
-0000f2b0: 290a 6465 6620 706f 6973 736f 6e28 6c61  ).def poisson(la
-0000f2c0: 6d3d 312e 302c 2073 697a 653d 4e6f 6e65  m=1.0, size=None
-0000f2d0: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2072  , key=None):.  r
-0000f2e0: 6574 7572 6e20 4445 4641 554c 542e 706f  eturn DEFAULT.po
-0000f2f0: 6973 736f 6e28 6c61 6d2c 2073 697a 652c  isson(lam, size,
-0000f300: 206b 6579 3d6b 6579 290a 0a0a 2320 4077   key=key)...# @w
-0000f310: 7261 7073 286e 702e 7261 6e64 6f6d 2e73  raps(np.random.s
-0000f320: 7461 6e64 6172 645f 6361 7563 6879 290a  tandard_cauchy).
-0000f330: 6465 6620 7374 616e 6461 7264 5f63 6175  def standard_cau
-0000f340: 6368 7928 7369 7a65 3d4e 6f6e 652c 206b  chy(size=None, k
-0000f350: 6579 3d4e 6f6e 6529 3a0a 2020 7265 7475  ey=None):.  retu
-0000f360: 726e 2044 4546 4155 4c54 2e73 7461 6e64  rn DEFAULT.stand
-0000f370: 6172 645f 6361 7563 6879 2873 697a 652c  ard_cauchy(size,
-0000f380: 206b 6579 3d6b 6579 290a 0a0a 2320 4077   key=key)...# @w
-0000f390: 7261 7073 286e 702e 7261 6e64 6f6d 2e73  raps(np.random.s
-0000f3a0: 7461 6e64 6172 645f 6578 706f 6e65 6e74  tandard_exponent
-0000f3b0: 6961 6c29 0a64 6566 2073 7461 6e64 6172  ial).def standar
-0000f3c0: 645f 6578 706f 6e65 6e74 6961 6c28 7369  d_exponential(si
-0000f3d0: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
-0000f3e0: 6529 3a0a 2020 7265 7475 726e 2044 4546  e):.  return DEF
-0000f3f0: 4155 4c54 2e73 7461 6e64 6172 645f 6578  AULT.standard_ex
-0000f400: 706f 6e65 6e74 6961 6c28 7369 7a65 2c20  ponential(size, 
-0000f410: 6b65 793d 6b65 7929 0a0a 0a23 2040 7772  key=key)...# @wr
-0000f420: 6170 7328 6e70 2e72 616e 646f 6d2e 7374  aps(np.random.st
-0000f430: 616e 6461 7264 5f67 616d 6d61 290a 6465  andard_gamma).de
-0000f440: 6620 7374 616e 6461 7264 5f67 616d 6d61  f standard_gamma
-0000f450: 2873 6861 7065 2c20 7369 7a65 3d4e 6f6e  (shape, size=Non
-0000f460: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
-0000f470: 7265 7475 726e 2044 4546 4155 4c54 2e73  return DEFAULT.s
-0000f480: 7461 6e64 6172 645f 6761 6d6d 6128 7368  tandard_gamma(sh
-0000f490: 6170 652c 2073 697a 652c 206b 6579 3d6b  ape, size, key=k
-0000f4a0: 6579 290a 0a0a 2320 4077 7261 7073 286e  ey)...# @wraps(n
-0000f4b0: 702e 7261 6e64 6f6d 2e73 7461 6e64 6172  p.random.standar
-0000f4c0: 645f 6e6f 726d 616c 290a 6465 6620 7374  d_normal).def st
-0000f4d0: 616e 6461 7264 5f6e 6f72 6d61 6c28 7369  andard_normal(si
-0000f4e0: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
-0000f4f0: 6529 3a0a 2020 7265 7475 726e 2044 4546  e):.  return DEF
-0000f500: 4155 4c54 2e73 7461 6e64 6172 645f 6e6f  AULT.standard_no
-0000f510: 726d 616c 2873 697a 652c 206b 6579 3d6b  rmal(size, key=k
-0000f520: 6579 290a 0a0a 2320 4077 7261 7073 286e  ey)...# @wraps(n
-0000f530: 702e 7261 6e64 6f6d 2e73 7461 6e64 6172  p.random.standar
-0000f540: 645f 7429 0a64 6566 2073 7461 6e64 6172  d_t).def standar
-0000f550: 645f 7428 6466 2c20 7369 7a65 3d4e 6f6e  d_t(df, size=Non
-0000f560: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
-0000f570: 7265 7475 726e 2044 4546 4155 4c54 2e73  return DEFAULT.s
-0000f580: 7461 6e64 6172 645f 7428 6466 2c20 7369  tandard_t(df, si
-0000f590: 7a65 2c20 6b65 793d 6b65 7929 0a0a 0a23  ze, key=key)...#
-0000f5a0: 2040 7772 6170 7328 6e70 2e72 616e 646f   @wraps(np.rando
-0000f5b0: 6d2e 756e 6966 6f72 6d29 0a64 6566 2075  m.uniform).def u
-0000f5c0: 6e69 666f 726d 286c 6f77 3d30 2e30 2c20  niform(low=0.0, 
-0000f5d0: 6869 6768 3d31 2e30 2c20 7369 7a65 3d4e  high=1.0, size=N
-0000f5e0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-0000f5f0: 2020 7265 7475 726e 2044 4546 4155 4c54    return DEFAULT
-0000f600: 2e75 6e69 666f 726d 286c 6f77 2c20 6869  .uniform(low, hi
-0000f610: 6768 2c20 7369 7a65 2c20 6b65 793d 6b65  gh, size, key=ke
-0000f620: 7929 0a0a 0a64 6566 2074 7275 6e63 6174  y)...def truncat
-0000f630: 6564 5f6e 6f72 6d61 6c28 6c6f 7765 722c  ed_normal(lower,
-0000f640: 2075 7070 6572 2c20 7369 7a65 3d4e 6f6e   upper, size=Non
-0000f650: 652c 2073 6361 6c65 3d4e 6f6e 652c 206b  e, scale=None, k
-0000f660: 6579 3d4e 6f6e 6529 3a0a 2020 2222 2253  ey=None):.  """S
-0000f670: 616d 706c 6520 7472 756e 6361 7465 6420  ample truncated 
-0000f680: 7374 616e 6461 7264 206e 6f72 6d61 6c20  standard normal 
-0000f690: 7261 6e64 6f6d 2076 616c 7565 7320 7769  random values wi
-0000f6a0: 7468 2067 6976 656e 2073 6861 7065 2061  th given shape a
-0000f6b0: 6e64 2064 7479 7065 2e0a 0a20 2050 6172  nd dtype...  Par
-0000f6c0: 616d 6574 6572 730a 2020 2d2d 2d2d 2d2d  ameters.  ------
-0000f6d0: 2d2d 2d2d 0a20 206c 6f77 6572 203a 2066  ----.  lower : f
-0000f6e0: 6c6f 6174 2c20 6e64 6172 7261 790a 2020  loat, ndarray.  
-0000f6f0: 2020 4120 666c 6f61 7420 6f72 2061 7272    A float or arr
-0000f700: 6179 206f 6620 666c 6f61 7473 2072 6570  ay of floats rep
-0000f710: 7265 7365 6e74 696e 6720 7468 6520 6c6f  resenting the lo
-0000f720: 7765 7220 626f 756e 6420 666f 720a 2020  wer bound for.  
-0000f730: 2020 7472 756e 6361 7469 6f6e 2e20 4d75    truncation. Mu
-0000f740: 7374 2062 6520 6272 6f61 6463 6173 742d  st be broadcast-
-0000f750: 636f 6d70 6174 6962 6c65 2077 6974 6820  compatible with 
-0000f760: 6060 7570 7065 7260 602e 0a20 2075 7070  ``upper``..  upp
-0000f770: 6572 203a 2066 6c6f 6174 2c20 6e64 6172  er : float, ndar
-0000f780: 7261 790a 2020 2020 4120 666c 6f61 7420  ray.    A float 
-0000f790: 6f72 2061 7272 6179 206f 6620 666c 6f61  or array of floa
-0000f7a0: 7473 2072 6570 7265 7365 6e74 696e 6720  ts representing 
-0000f7b0: 7468 6520 2075 7070 6572 2062 6f75 6e64  the  upper bound
-0000f7c0: 2066 6f72 0a20 2020 2074 7275 6e63 6174   for.    truncat
-0000f7d0: 696f 6e2e 204d 7573 7420 6265 2062 726f  ion. Must be bro
-0000f7e0: 6164 6361 7374 2d63 6f6d 7061 7469 626c  adcast-compatibl
-0000f7f0: 6520 7769 7468 2060 606c 6f77 6572 6060  e with ``lower``
-0000f800: 2e0a 2020 7369 7a65 203a 206f 7074 696f  ..  size : optio
-0000f810: 6e61 6c2c 206c 6973 7420 6f66 2069 6e74  nal, list of int
-0000f820: 2c20 7475 706c 6520 6f66 2069 6e74 0a20  , tuple of int. 
-0000f830: 2020 2041 2074 7570 6c65 206f 6620 6e6f     A tuple of no
-0000f840: 6e6e 6567 6174 6976 6520 696e 7465 6765  nnegative intege
-0000f850: 7273 2073 7065 6369 6679 696e 6720 7468  rs specifying th
-0000f860: 6520 7265 7375 6c74 0a20 2020 2073 6861  e result.    sha
-0000f870: 7065 2e20 4d75 7374 2062 6520 6272 6f61  pe. Must be broa
-0000f880: 6463 6173 742d 636f 6d70 6174 6962 6c65  dcast-compatible
-0000f890: 2077 6974 6820 6060 6c6f 7765 7260 6020   with ``lower`` 
-0000f8a0: 616e 6420 6060 7570 7065 7260 602e 2054  and ``upper``. T
-0000f8b0: 6865 0a20 2020 2064 6566 6175 6c74 2028  he.    default (
-0000f8c0: 4e6f 6e65 2920 7072 6f64 7563 6573 2061  None) produces a
-0000f8d0: 2072 6573 756c 7420 7368 6170 6520 6279   result shape by
-0000f8e0: 2062 726f 6164 6361 7374 696e 6720 6060   broadcasting ``
-0000f8f0: 6c6f 7765 7260 6020 616e 640a 2020 2020  lower`` and.    
-0000f900: 6060 7570 7065 7260 602e 0a20 2073 6361  ``upper``..  sca
-0000f910: 6c65 203a 2066 6c6f 6174 2c20 6e64 6172  le : float, ndar
-0000f920: 7261 790a 2020 2020 5374 616e 6461 7264  ray.    Standard
-0000f930: 2064 6576 6961 7469 6f6e 2028 7370 7265   deviation (spre
-0000f940: 6164 206f 7220 2277 6964 7468 2229 206f  ad or "width") o
-0000f950: 6620 7468 6520 6469 7374 7269 6275 7469  f the distributi
-0000f960: 6f6e 2e20 4d75 7374 2062 650a 2020 2020  on. Must be.    
-0000f970: 6e6f 6e2d 6e65 6761 7469 7665 2e0a 0a20  non-negative... 
-0000f980: 2052 6574 7572 6e73 0a20 202d 2d2d 2d2d   Returns.  -----
-0000f990: 2d2d 0a20 206f 7574 203a 2041 7272 6179  --.  out : Array
-0000f9a0: 0a20 2020 2041 2072 616e 646f 6d20 6172  .    A random ar
-0000f9b0: 7261 7920 7769 7468 2074 6865 2073 7065  ray with the spe
-0000f9c0: 6369 6669 6564 2064 7479 7065 2061 6e64  cified dtype and
-0000f9d0: 2073 6861 7065 2067 6976 656e 2062 7920   shape given by 
-0000f9e0: 6060 7368 6170 6560 6020 6966 0a20 2020  ``shape`` if.   
-0000f9f0: 2060 6073 6861 7065 6060 2069 7320 6e6f   ``shape`` is no
-0000fa00: 7420 4e6f 6e65 2c20 6f72 2065 6c73 6520  t None, or else 
-0000fa10: 6279 2062 726f 6164 6361 7374 696e 6720  by broadcasting 
-0000fa20: 6060 6c6f 7765 7260 6020 616e 6420 6060  ``lower`` and ``
-0000fa30: 7570 7065 7260 602e 0a20 2020 2052 6574  upper``..    Ret
-0000fa40: 7572 6e73 2076 616c 7565 7320 696e 2074  urns values in t
-0000fa50: 6865 206f 7065 6e20 696e 7465 7276 616c  he open interval
-0000fa60: 2060 6028 6c6f 7765 722c 2075 7070 6572   ``(lower, upper
-0000fa70: 2960 602e 0a20 2022 2222 0a20 2072 6574  )``..  """.  ret
-0000fa80: 7572 6e20 4445 4641 554c 542e 7472 756e  urn DEFAULT.trun
-0000fa90: 6361 7465 645f 6e6f 726d 616c 286c 6f77  cated_normal(low
-0000faa0: 6572 2c20 7570 7065 722c 2073 697a 652c  er, upper, size,
-0000fab0: 2073 6361 6c65 2c20 6b65 793d 6b65 7929   scale, key=key)
-0000fac0: 0a0a 0a64 6566 2062 6572 6e6f 756c 6c69  ...def bernoulli
-0000fad0: 2870 3d30 2e35 2c20 7369 7a65 3d4e 6f6e  (p=0.5, size=Non
-0000fae0: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
-0000faf0: 2222 2253 616d 706c 6520 4265 726e 6f75  """Sample Bernou
-0000fb00: 6c6c 6920 7261 6e64 6f6d 2076 616c 7565  lli random value
-0000fb10: 7320 7769 7468 2067 6976 656e 2073 6861  s with given sha
-0000fb20: 7065 2061 6e64 206d 6561 6e2e 0a0a 2020  pe and mean...  
-0000fb30: 5061 7261 6d65 7465 7273 0a20 202d 2d2d  Parameters.  ---
-0000fb40: 2d2d 2d2d 2d2d 2d0a 2020 703a 2066 6c6f  -------.  p: flo
-0000fb50: 6174 2c20 6172 7261 795f 6c69 6b65 2c20  at, array_like, 
-0000fb60: 6f70 7469 6f6e 616c 0a20 2020 2041 2066  optional.    A f
-0000fb70: 6c6f 6174 206f 7220 6172 7261 7920 6f66  loat or array of
-0000fb80: 2066 6c6f 6174 7320 666f 7220 7468 6520   floats for the 
-0000fb90: 6d65 616e 206f 6620 7468 6520 7261 6e64  mean of the rand
-0000fba0: 6f6d 0a20 2020 2076 6172 6961 626c 6573  om.    variables
-0000fbb0: 2e20 4d75 7374 2062 6520 6272 6f61 6463  . Must be broadc
-0000fbc0: 6173 742d 636f 6d70 6174 6962 6c65 2077  ast-compatible w
-0000fbd0: 6974 6820 6060 7368 6170 6560 6020 616e  ith ``shape`` an
-0000fbe0: 6420 7468 6520 7661 6c75 6573 0a20 2020  d the values.   
-0000fbf0: 2073 686f 756c 6420 6265 2077 6974 6869   should be withi
-0000fc00: 6e20 5b30 2c20 315d 2e20 4465 6661 756c  n [0, 1]. Defaul
-0000fc10: 7420 302e 352e 0a20 2073 697a 653a 206f  t 0.5..  size: o
-0000fc20: 7074 696f 6e61 6c2c 2074 7570 6c65 206f  ptional, tuple o
-0000fc30: 6620 696e 742c 2069 6e74 0a20 2020 2041  f int, int.    A
-0000fc40: 2074 7570 6c65 206f 6620 6e6f 6e6e 6567   tuple of nonneg
-0000fc50: 6174 6976 6520 696e 7465 6765 7273 2072  ative integers r
-0000fc60: 6570 7265 7365 6e74 696e 6720 7468 6520  epresenting the 
-0000fc70: 7265 7375 6c74 0a20 2020 2073 6861 7065  result.    shape
-0000fc80: 2e20 4d75 7374 2062 6520 6272 6f61 6463  . Must be broadc
-0000fc90: 6173 742d 636f 6d70 6174 6962 6c65 2077  ast-compatible w
-0000fca0: 6974 6820 6060 702e 7368 6170 6560 602e  ith ``p.shape``.
-0000fcb0: 2054 6865 2064 6566 6175 6c74 2028 4e6f   The default (No
-0000fcc0: 6e65 290a 2020 2020 7072 6f64 7563 6573  ne).    produces
-0000fcd0: 2061 2072 6573 756c 7420 7368 6170 6520   a result shape 
-0000fce0: 6571 7561 6c20 746f 2060 6070 2e73 6861  equal to ``p.sha
-0000fcf0: 7065 6060 2e0a 0a20 2052 6574 7572 6e73  pe``...  Returns
-0000fd00: 0a20 202d 2d2d 2d2d 2d2d 0a20 206f 7574  .  -------.  out
-0000fd10: 3a20 6172 7261 795f 6c69 6b65 0a20 2020  : array_like.   
-0000fd20: 2041 2072 616e 646f 6d20 6172 7261 7920   A random array 
-0000fd30: 7769 7468 2062 6f6f 6c65 616e 2064 7479  with boolean dty
-0000fd40: 7065 2061 6e64 2073 6861 7065 2067 6976  pe and shape giv
-0000fd50: 656e 2062 7920 6060 7368 6170 6560 6020  en by ``shape`` 
-0000fd60: 6966 2060 6073 6861 7065 6060 0a20 2020  if ``shape``.   
-0000fd70: 2069 7320 6e6f 7420 4e6f 6e65 2c20 6f72   is not None, or
-0000fd80: 2065 6c73 6520 6060 702e 7368 6170 6560   else ``p.shape`
-0000fd90: 602e 0a20 2022 2222 0a20 2072 6574 7572  `..  """.  retur
-0000fda0: 6e20 4445 4641 554c 542e 6265 726e 6f75  n DEFAULT.bernou
-0000fdb0: 6c6c 6928 702c 2073 697a 652c 206b 6579  lli(p, size, key
-0000fdc0: 3d6b 6579 290a 0a0a 2320 4077 7261 7073  =key)...# @wraps
-0000fdd0: 286e 702e 7261 6e64 6f6d 2e6c 6f67 6e6f  (np.random.logno
-0000fde0: 726d 616c 290a 6465 6620 6c6f 676e 6f72  rmal).def lognor
-0000fdf0: 6d61 6c28 6d65 616e 3d4e 6f6e 652c 2073  mal(mean=None, s
-0000fe00: 6967 6d61 3d4e 6f6e 652c 2073 697a 653d  igma=None, size=
-0000fe10: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
-0000fe20: 0a20 2072 6574 7572 6e20 4445 4641 554c  .  return DEFAUL
-0000fe30: 542e 6c6f 676e 6f72 6d61 6c28 6d65 616e  T.lognormal(mean
-0000fe40: 2c20 7369 676d 612c 2073 697a 652c 206b  , sigma, size, k
-0000fe50: 6579 3d6b 6579 290a 0a0a 2320 4077 7261  ey=key)...# @wra
-0000fe60: 7073 286e 702e 7261 6e64 6f6d 2e62 696e  ps(np.random.bin
-0000fe70: 6f6d 6961 6c29 0a64 6566 2062 696e 6f6d  omial).def binom
-0000fe80: 6961 6c28 6e2c 2070 2c20 7369 7a65 3d4e  ial(n, p, size=N
-0000fe90: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-0000fea0: 2020 7265 7475 726e 2044 4546 4155 4c54    return DEFAULT
-0000feb0: 2e62 696e 6f6d 6961 6c28 6e2c 2070 2c20  .binomial(n, p, 
-0000fec0: 7369 7a65 2c20 6b65 793d 6b65 7929 0a0a  size, key=key)..
-0000fed0: 0a23 2040 7772 6170 7328 6e70 2e72 616e  .# @wraps(np.ran
-0000fee0: 646f 6d2e 6368 6973 7175 6172 6529 0a64  dom.chisquare).d
-0000fef0: 6566 2063 6869 7371 7561 7265 2864 662c  ef chisquare(df,
-0000ff00: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
-0000ff10: 4e6f 6e65 293a 0a20 2072 6574 7572 6e20  None):.  return 
-0000ff20: 4445 4641 554c 542e 6368 6973 7175 6172  DEFAULT.chisquar
-0000ff30: 6528 6466 2c20 7369 7a65 2c20 6b65 793d  e(df, size, key=
-0000ff40: 6b65 7929 0a0a 0a23 2040 7772 6170 7328  key)...# @wraps(
-0000ff50: 6e70 2e72 616e 646f 6d2e 6469 7269 6368  np.random.dirich
-0000ff60: 6c65 7429 0a64 6566 2064 6972 6963 686c  let).def dirichl
-0000ff70: 6574 2861 6c70 6861 2c20 7369 7a65 3d4e  et(alpha, size=N
-0000ff80: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-0000ff90: 2020 7265 7475 726e 2044 4546 4155 4c54    return DEFAULT
-0000ffa0: 2e64 6972 6963 686c 6574 2861 6c70 6861  .dirichlet(alpha
-0000ffb0: 2c20 7369 7a65 2c20 6b65 793d 6b65 7929  , size, key=key)
-0000ffc0: 0a0a 0a23 2040 7772 6170 7328 6e70 2e72  ...# @wraps(np.r
-0000ffd0: 616e 646f 6d2e 6765 6f6d 6574 7269 6329  andom.geometric)
-0000ffe0: 0a64 6566 2067 656f 6d65 7472 6963 2870  .def geometric(p
-0000fff0: 2c20 7369 7a65 3d4e 6f6e 652c 206b 6579  , size=None, key
-00010000: 3d4e 6f6e 6529 3a0a 2020 7265 7475 726e  =None):.  return
-00010010: 2044 4546 4155 4c54 2e67 656f 6d65 7472   DEFAULT.geometr
-00010020: 6963 2870 2c20 7369 7a65 2c20 6b65 793d  ic(p, size, key=
-00010030: 6b65 7929 0a0a 0a23 2040 7772 6170 7328  key)...# @wraps(
-00010040: 6e70 2e72 616e 646f 6d2e 6629 0a64 6566  np.random.f).def
-00010050: 2066 2864 666e 756d 2c20 6466 6465 6e2c   f(dfnum, dfden,
-00010060: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
-00010070: 4e6f 6e65 293a 0a20 2072 6574 7572 6e20  None):.  return 
-00010080: 4445 4641 554c 542e 6628 6466 6e75 6d2c  DEFAULT.f(dfnum,
-00010090: 2064 6664 656e 2c20 7369 7a65 2c20 6b65   dfden, size, ke
-000100a0: 793d 6b65 7929 0a0a 0a23 2040 7772 6170  y=key)...# @wrap
-000100b0: 7328 6e70 2e72 616e 646f 6d2e 6879 7065  s(np.random.hype
-000100c0: 7267 656f 6d65 7472 6963 290a 6465 6620  rgeometric).def 
-000100d0: 6879 7065 7267 656f 6d65 7472 6963 286e  hypergeometric(n
-000100e0: 676f 6f64 2c20 6e62 6164 2c20 6e73 616d  good, nbad, nsam
-000100f0: 706c 652c 2073 697a 653d 4e6f 6e65 2c20  ple, size=None, 
-00010100: 6b65 793d 4e6f 6e65 293a 0a20 2072 6574  key=None):.  ret
-00010110: 7572 6e20 4445 4641 554c 542e 6879 7065  urn DEFAULT.hype
-00010120: 7267 656f 6d65 7472 6963 286e 676f 6f64  rgeometric(ngood
-00010130: 2c20 6e62 6164 2c20 6e73 616d 706c 652c  , nbad, nsample,
-00010140: 2073 697a 652c 206b 6579 3d6b 6579 290a   size, key=key).
-00010150: 0a0a 2320 4077 7261 7073 286e 702e 7261  ..# @wraps(np.ra
-00010160: 6e64 6f6d 2e6c 6f67 7365 7269 6573 290a  ndom.logseries).
-00010170: 6465 6620 6c6f 6773 6572 6965 7328 702c  def logseries(p,
-00010180: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
-00010190: 4e6f 6e65 293a 0a20 2072 6574 7572 6e20  None):.  return 
-000101a0: 4445 4641 554c 542e 6c6f 6773 6572 6965  DEFAULT.logserie
-000101b0: 7328 702c 2073 697a 652c 206b 6579 3d6b  s(p, size, key=k
-000101c0: 6579 290a 0a0a 2320 4077 7261 7073 286e  ey)...# @wraps(n
-000101d0: 702e 7261 6e64 6f6d 2e6d 756c 7469 6e6f  p.random.multino
-000101e0: 6d69 616c 290a 6465 6620 6d75 6c74 696e  mial).def multin
-000101f0: 6f6d 6961 6c28 6e2c 2070 7661 6c73 2c20  omial(n, pvals, 
-00010200: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
-00010210: 6f6e 6529 3a0a 2020 7265 7475 726e 2044  one):.  return D
-00010220: 4546 4155 4c54 2e6d 756c 7469 6e6f 6d69  EFAULT.multinomi
-00010230: 616c 286e 2c20 7076 616c 732c 2073 697a  al(n, pvals, siz
-00010240: 652c 206b 6579 3d6b 6579 290a 0a0a 2320  e, key=key)...# 
-00010250: 4077 7261 7073 286e 702e 7261 6e64 6f6d  @wraps(np.random
-00010260: 2e6d 756c 7469 7661 7269 6174 655f 6e6f  .multivariate_no
-00010270: 726d 616c 290a 6465 6620 6d75 6c74 6976  rmal).def multiv
-00010280: 6172 6961 7465 5f6e 6f72 6d61 6c28 6d65  ariate_normal(me
-00010290: 616e 2c20 636f 762c 2073 697a 653d 4e6f  an, cov, size=No
-000102a0: 6e65 2c20 6d65 7468 6f64 3a20 7374 7220  ne, method: str 
-000102b0: 3d20 2763 686f 6c65 736b 7927 2c20 6b65  = 'cholesky', ke
-000102c0: 793d 4e6f 6e65 293a 0a20 2072 6574 7572  y=None):.  retur
-000102d0: 6e20 4445 4641 554c 542e 6d75 6c74 6976  n DEFAULT.multiv
-000102e0: 6172 6961 7465 5f6e 6f72 6d61 6c28 6d65  ariate_normal(me
-000102f0: 616e 2c20 636f 762c 2073 697a 652c 206d  an, cov, size, m
-00010300: 6574 686f 642c 206b 6579 3d6b 6579 290a  ethod, key=key).
-00010310: 0a0a 2320 4077 7261 7073 286e 702e 7261  ..# @wraps(np.ra
-00010320: 6e64 6f6d 2e6e 6567 6174 6976 655f 6269  ndom.negative_bi
-00010330: 6e6f 6d69 616c 290a 6465 6620 6e65 6761  nomial).def nega
-00010340: 7469 7665 5f62 696e 6f6d 6961 6c28 6e2c  tive_binomial(n,
-00010350: 2070 2c20 7369 7a65 3d4e 6f6e 652c 206b   p, size=None, k
-00010360: 6579 3d4e 6f6e 6529 3a0a 2020 7265 7475  ey=None):.  retu
-00010370: 726e 2044 4546 4155 4c54 2e6e 6567 6174  rn DEFAULT.negat
-00010380: 6976 655f 6269 6e6f 6d69 616c 286e 2c20  ive_binomial(n, 
-00010390: 702c 2073 697a 652c 206b 6579 3d6b 6579  p, size, key=key
-000103a0: 290a 0a0a 2320 4077 7261 7073 286e 702e  )...# @wraps(np.
-000103b0: 7261 6e64 6f6d 2e6e 6f6e 6365 6e74 7261  random.noncentra
-000103c0: 6c5f 6368 6973 7175 6172 6529 0a64 6566  l_chisquare).def
-000103d0: 206e 6f6e 6365 6e74 7261 6c5f 6368 6973   noncentral_chis
-000103e0: 7175 6172 6528 6466 2c20 6e6f 6e63 2c20  quare(df, nonc, 
-000103f0: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
-00010400: 6f6e 6529 3a0a 2020 7265 7475 726e 2044  one):.  return D
-00010410: 4546 4155 4c54 2e6e 6f6e 6365 6e74 7261  EFAULT.noncentra
-00010420: 6c5f 6368 6973 7175 6172 6528 6466 2c20  l_chisquare(df, 
-00010430: 6e6f 6e63 2c20 7369 7a65 2c20 6b65 793d  nonc, size, key=
-00010440: 6b65 7929 0a0a 0a23 2040 7772 6170 7328  key)...# @wraps(
-00010450: 6e70 2e72 616e 646f 6d2e 6e6f 6e63 656e  np.random.noncen
-00010460: 7472 616c 5f66 290a 6465 6620 6e6f 6e63  tral_f).def nonc
-00010470: 656e 7472 616c 5f66 2864 666e 756d 2c20  entral_f(dfnum, 
-00010480: 6466 6465 6e2c 206e 6f6e 632c 2073 697a  dfden, nonc, siz
-00010490: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
-000104a0: 293a 0a20 2072 6574 7572 6e20 4445 4641  ):.  return DEFA
-000104b0: 554c 542e 6e6f 6e63 656e 7472 616c 5f66  ULT.noncentral_f
-000104c0: 2864 666e 756d 2c20 6466 6465 6e2c 206e  (dfnum, dfden, n
-000104d0: 6f6e 632c 2073 697a 652c 206b 6579 3d6b  onc, size, key=k
-000104e0: 6579 290a 0a0a 2320 4077 7261 7073 286e  ey)...# @wraps(n
-000104f0: 702e 7261 6e64 6f6d 2e70 6f77 6572 290a  p.random.power).
-00010500: 6465 6620 706f 7765 7228 612c 2073 697a  def power(a, siz
-00010510: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
-00010520: 293a 0a20 2072 6574 7572 6e20 4445 4641  ):.  return DEFA
-00010530: 554c 542e 706f 7765 7228 612c 2073 697a  ULT.power(a, siz
-00010540: 652c 206b 6579 3d6b 6579 290a 0a0a 2320  e, key=key)...# 
-00010550: 4077 7261 7073 286e 702e 7261 6e64 6f6d  @wraps(np.random
-00010560: 2e72 6179 6c65 6967 6829 0a64 6566 2072  .rayleigh).def r
-00010570: 6179 6c65 6967 6828 7363 616c 653d 312e  ayleigh(scale=1.
-00010580: 302c 2073 697a 653d 4e6f 6e65 2c20 6b65  0, size=None, ke
-00010590: 793d 4e6f 6e65 293a 0a20 2072 6574 7572  y=None):.  retur
-000105a0: 6e20 4445 4641 554c 542e 7261 796c 6569  n DEFAULT.raylei
-000105b0: 6768 2873 6361 6c65 2c20 7369 7a65 2c20  gh(scale, size, 
-000105c0: 6b65 793d 6b65 7929 0a0a 0a23 2040 7772  key=key)...# @wr
-000105d0: 6170 7328 6e70 2e72 616e 646f 6d2e 7472  aps(np.random.tr
-000105e0: 6961 6e67 756c 6172 290a 6465 6620 7472  iangular).def tr
-000105f0: 6961 6e67 756c 6172 2873 697a 653d 4e6f  iangular(size=No
-00010600: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
-00010610: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
-00010620: 7472 6961 6e67 756c 6172 2873 697a 652c  triangular(size,
-00010630: 206b 6579 3d6b 6579 290a 0a0a 2320 4077   key=key)...# @w
-00010640: 7261 7073 286e 702e 7261 6e64 6f6d 2e76  raps(np.random.v
-00010650: 6f6e 6d69 7365 7329 0a64 6566 2076 6f6e  onmises).def von
-00010660: 6d69 7365 7328 6d75 2c20 6b61 7070 612c  mises(mu, kappa,
-00010670: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
-00010680: 4e6f 6e65 293a 0a20 2072 6574 7572 6e20  None):.  return 
-00010690: 4445 4641 554c 542e 766f 6e6d 6973 6573  DEFAULT.vonmises
-000106a0: 286d 752c 206b 6170 7061 2c20 7369 7a65  (mu, kappa, size
-000106b0: 2c20 6b65 793d 6b65 7929 0a0a 0a23 2040  , key=key)...# @
-000106c0: 7772 6170 7328 6e70 2e72 616e 646f 6d2e  wraps(np.random.
-000106d0: 7761 6c64 290a 6465 6620 7761 6c64 286d  wald).def wald(m
-000106e0: 6561 6e2c 2073 6361 6c65 2c20 7369 7a65  ean, scale, size
-000106f0: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
-00010700: 3a0a 2020 7265 7475 726e 2044 4546 4155  :.  return DEFAU
-00010710: 4c54 2e77 616c 6428 6d65 616e 2c20 7363  LT.wald(mean, sc
-00010720: 616c 652c 2073 697a 652c 206b 6579 3d6b  ale, size, key=k
-00010730: 6579 290a 0a0a 6465 6620 7765 6962 756c  ey)...def weibul
-00010740: 6c28 612c 2073 697a 653d 4e6f 6e65 2c20  l(a, size=None, 
-00010750: 6b65 793d 4e6f 6e65 293a 0a20 2072 2222  key=None):.  r""
-00010760: 220a 2020 4472 6177 2073 616d 706c 6573  ".  Draw samples
-00010770: 2066 726f 6d20 6120 5765 6962 756c 6c20   from a Weibull 
-00010780: 6469 7374 7269 6275 7469 6f6e 2e0a 2020  distribution..  
-00010790: 2020 0a20 2044 7261 7720 7361 6d70 6c65    .  Draw sample
-000107a0: 7320 6672 6f6d 2061 2031 2d70 6172 616d  s from a 1-param
-000107b0: 6574 6572 2057 6569 6275 6c6c 2064 6973  eter Weibull dis
-000107c0: 7472 6962 7574 696f 6e20 7769 7468 2074  tribution with t
-000107d0: 6865 2067 6976 656e 0a20 2073 6861 7065  he given.  shape
-000107e0: 2070 6172 616d 6574 6572 2060 6160 2e0a   parameter `a`..
-000107f0: 0a20 202e 2e20 6d61 7468 3a3a 2058 203d  .  .. math:: X =
-00010800: 2028 2d6c 6e28 5529 295e 7b31 2f61 7d0a   (-ln(U))^{1/a}.
-00010810: 0a20 2048 6572 652c 2055 2069 7320 6472  .  Here, U is dr
-00010820: 6177 6e20 6672 6f6d 2074 6865 2075 6e69  awn from the uni
-00010830: 666f 726d 2064 6973 7472 6962 7574 696f  form distributio
-00010840: 6e20 6f76 6572 2028 302c 315d 2e0a 0a20  n over (0,1]... 
-00010850: 2054 6865 206d 6f72 6520 636f 6d6d 6f6e   The more common
-00010860: 2032 2d70 6172 616d 6574 6572 2057 6569   2-parameter Wei
-00010870: 6275 6c6c 2c20 696e 636c 7564 696e 6720  bull, including 
-00010880: 6120 7363 616c 6520 7061 7261 6d65 7465  a scale paramete
-00010890: 720a 2020 3a6d 6174 683a 605c 6c61 6d62  r.  :math:`\lamb
-000108a0: 6461 6020 6973 206a 7573 7420 3a6d 6174  da` is just :mat
-000108b0: 683a 6058 203d 205c 6c61 6d62 6461 282d  h:`X = \lambda(-
-000108c0: 6c6e 2855 2929 5e7b 312f 617d 602e 0a0a  ln(U))^{1/a}`...
-000108d0: 2020 2e2e 206e 6f74 653a 3a0a 2020 2020    .. note::.    
-000108e0: 2020 4e65 7720 636f 6465 2073 686f 756c    New code shoul
-000108f0: 6420 7573 6520 7468 6520 6060 7765 6962  d use the ``weib
-00010900: 756c 6c60 6020 6d65 7468 6f64 206f 6620  ull`` method of 
-00010910: 6120 6060 6465 6661 756c 745f 726e 6728  a ``default_rng(
-00010920: 2960 600a 2020 2020 2020 696e 7374 616e  )``.      instan
-00010930: 6365 2069 6e73 7465 6164 3b20 706c 6561  ce instead; plea
-00010940: 7365 2073 6565 2074 6865 203a 7265 663a  se see the :ref:
-00010950: 6072 616e 646f 6d2d 7175 6963 6b2d 7374  `random-quick-st
-00010960: 6172 7460 2e0a 0a20 2050 6172 616d 6574  art`...  Paramet
-00010970: 6572 730a 2020 2d2d 2d2d 2d2d 2d2d 2d2d  ers.  ----------
-00010980: 0a20 2061 203a 2066 6c6f 6174 206f 7220  .  a : float or 
-00010990: 6172 7261 795f 6c69 6b65 206f 6620 666c  array_like of fl
-000109a0: 6f61 7473 0a20 2020 2020 2053 6861 7065  oats.      Shape
-000109b0: 2070 6172 616d 6574 6572 206f 6620 7468   parameter of th
-000109c0: 6520 6469 7374 7269 6275 7469 6f6e 2e20  e distribution. 
-000109d0: 204d 7573 7420 6265 206e 6f6e 6e65 6761   Must be nonnega
-000109e0: 7469 7665 2e0a 2020 7369 7a65 203a 2069  tive..  size : i
-000109f0: 6e74 206f 7220 7475 706c 6520 6f66 2069  nt or tuple of i
-00010a00: 6e74 732c 206f 7074 696f 6e61 6c0a 2020  nts, optional.  
-00010a10: 2020 2020 4f75 7470 7574 2073 6861 7065      Output shape
-00010a20: 2e20 2049 6620 7468 6520 6769 7665 6e20  .  If the given 
-00010a30: 7368 6170 6520 6973 2c20 652e 672e 2c20  shape is, e.g., 
-00010a40: 6060 286d 2c20 6e2c 206b 2960 602c 2074  ``(m, n, k)``, t
-00010a50: 6865 6e0a 2020 2020 2020 6060 6d20 2a20  hen.      ``m * 
-00010a60: 6e20 2a20 6b60 6020 7361 6d70 6c65 7320  n * k`` samples 
-00010a70: 6172 6520 6472 6177 6e2e 2020 4966 2073  are drawn.  If s
-00010a80: 697a 6520 6973 2060 604e 6f6e 6560 6020  ize is ``None`` 
-00010a90: 2864 6566 6175 6c74 292c 0a20 2020 2020  (default),.     
-00010aa0: 2061 2073 696e 676c 6520 7661 6c75 6520   a single value 
-00010ab0: 6973 2072 6574 7572 6e65 6420 6966 2060  is returned if `
-00010ac0: 6061 6060 2069 7320 6120 7363 616c 6172  `a`` is a scalar
-00010ad0: 2e20 204f 7468 6572 7769 7365 2c0a 2020  .  Otherwise,.  
-00010ae0: 2020 2020 6060 6e70 2e61 7272 6179 2861      ``np.array(a
-00010af0: 292e 7369 7a65 6060 2073 616d 706c 6573  ).size`` samples
-00010b00: 2061 7265 2064 7261 776e 2e0a 0a20 2052   are drawn...  R
-00010b10: 6574 7572 6e73 0a20 202d 2d2d 2d2d 2d2d  eturns.  -------
-00010b20: 0a20 206f 7574 203a 206e 6461 7272 6179  .  out : ndarray
-00010b30: 206f 7220 7363 616c 6172 0a20 2020 2020   or scalar.     
-00010b40: 2044 7261 776e 2073 616d 706c 6573 2066   Drawn samples f
-00010b50: 726f 6d20 7468 6520 7061 7261 6d65 7465  rom the paramete
-00010b60: 7269 7a65 6420 5765 6962 756c 6c20 6469  rized Weibull di
-00010b70: 7374 7269 6275 7469 6f6e 2e0a 0a20 2053  stribution...  S
-00010b80: 6565 2041 6c73 6f0a 2020 2d2d 2d2d 2d2d  ee Also.  ------
-00010b90: 2d2d 0a20 2073 6369 7079 2e73 7461 7473  --.  scipy.stats
-00010ba0: 2e77 6569 6275 6c6c 5f6d 6178 0a20 2073  .weibull_max.  s
-00010bb0: 6369 7079 2e73 7461 7473 2e77 6569 6275  cipy.stats.weibu
-00010bc0: 6c6c 5f6d 696e 0a20 2073 6369 7079 2e73  ll_min.  scipy.s
-00010bd0: 7461 7473 2e67 656e 6578 7472 656d 650a  tats.genextreme.
-00010be0: 2020 6775 6d62 656c 0a20 2072 616e 646f    gumbel.  rando
-00010bf0: 6d2e 4765 6e65 7261 746f 722e 7765 6962  m.Generator.weib
-00010c00: 756c 6c3a 2077 6869 6368 2073 686f 756c  ull: which shoul
-00010c10: 6420 6265 2075 7365 6420 666f 7220 6e65  d be used for ne
-00010c20: 7720 636f 6465 2e0a 0a20 204e 6f74 6573  w code...  Notes
-00010c30: 0a20 202d 2d2d 2d2d 0a20 2054 6865 2057  .  -----.  The W
-00010c40: 6569 6275 6c6c 2028 6f72 2054 7970 6520  eibull (or Type 
-00010c50: 4949 4920 6173 796d 7074 6f74 6963 2065  III asymptotic e
-00010c60: 7874 7265 6d65 2076 616c 7565 2064 6973  xtreme value dis
-00010c70: 7472 6962 7574 696f 6e0a 2020 666f 7220  tribution.  for 
-00010c80: 736d 616c 6c65 7374 2076 616c 7565 732c  smallest values,
-00010c90: 2053 4556 2054 7970 6520 4949 492c 206f   SEV Type III, o
-00010ca0: 7220 526f 7369 6e2d 5261 6d6d 6c65 720a  r Rosin-Rammler.
-00010cb0: 2020 6469 7374 7269 6275 7469 6f6e 2920    distribution) 
-00010cc0: 6973 206f 6e65 206f 6620 6120 636c 6173  is one of a clas
-00010cd0: 7320 6f66 2047 656e 6572 616c 697a 6564  s of Generalized
-00010ce0: 2045 7874 7265 6d65 2056 616c 7565 0a20   Extreme Value. 
-00010cf0: 2028 4745 5629 2064 6973 7472 6962 7574   (GEV) distribut
-00010d00: 696f 6e73 2075 7365 6420 696e 206d 6f64  ions used in mod
-00010d10: 656c 696e 6720 6578 7472 656d 6520 7661  eling extreme va
-00010d20: 6c75 6520 7072 6f62 6c65 6d73 2e0a 2020  lue problems..  
-00010d30: 5468 6973 2063 6c61 7373 2069 6e63 6c75  This class inclu
-00010d40: 6465 7320 7468 6520 4775 6d62 656c 2061  des the Gumbel a
-00010d50: 6e64 2046 7265 6368 6574 2064 6973 7472  nd Frechet distr
-00010d60: 6962 7574 696f 6e73 2e0a 0a20 2054 6865  ibutions...  The
-00010d70: 2070 726f 6261 6269 6c69 7479 2064 656e   probability den
-00010d80: 7369 7479 2066 6f72 2074 6865 2057 6569  sity for the Wei
-00010d90: 6275 6c6c 2064 6973 7472 6962 7574 696f  bull distributio
-00010da0: 6e20 6973 0a0a 2020 2e2e 206d 6174 683a  n is..  .. math:
-00010db0: 3a20 7028 7829 203d 205c 6672 6163 7b61  : p(x) = \frac{a
-00010dc0: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
-00010dd0: 2020 2020 207b 5c6c 616d 6264 617d 285c       {\lambda}(\
-00010de0: 6672 6163 7b78 7d7b 5c6c 616d 6264 617d  frac{x}{\lambda}
-00010df0: 295e 7b61 2d31 7d65 5e7b 2d28 782f 5c6c  )^{a-1}e^{-(x/\l
-00010e00: 616d 6264 6129 5e61 7d2c 0a0a 2020 7768  ambda)^a},..  wh
-00010e10: 6572 6520 3a6d 6174 683a 6061 6020 6973  ere :math:`a` is
-00010e20: 2074 6865 2073 6861 7065 2061 6e64 203a   the shape and :
-00010e30: 6d61 7468 3a60 5c6c 616d 6264 6160 2074  math:`\lambda` t
-00010e40: 6865 2073 6361 6c65 2e0a 0a20 2054 6865  he scale...  The
-00010e50: 2066 756e 6374 696f 6e20 6861 7320 6974   function has it
-00010e60: 7320 7065 616b 2028 7468 6520 6d6f 6465  s peak (the mode
-00010e70: 2920 6174 0a20 203a 6d61 7468 3a60 5c6c  ) at.  :math:`\l
-00010e80: 616d 6264 6128 5c66 7261 637b 612d 317d  ambda(\frac{a-1}
-00010e90: 7b61 7d29 5e7b 312f 617d 602e 0a0a 2020  {a})^{1/a}`...  
-00010ea0: 5768 656e 2060 6061 203d 2031 6060 2c20  When ``a = 1``, 
-00010eb0: 7468 6520 5765 6962 756c 6c20 6469 7374  the Weibull dist
-00010ec0: 7269 6275 7469 6f6e 2072 6564 7563 6573  ribution reduces
-00010ed0: 2074 6f20 7468 6520 6578 706f 6e65 6e74   to the exponent
-00010ee0: 6961 6c0a 2020 6469 7374 7269 6275 7469  ial.  distributi
-00010ef0: 6f6e 2e0a 0a20 2052 6566 6572 656e 6365  on...  Reference
-00010f00: 730a 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20  s.  ----------. 
-00010f10: 202e 2e20 5b31 5d20 5761 6c6f 6464 6920   .. [1] Waloddi 
-00010f20: 5765 6962 756c 6c2c 2052 6f79 616c 2054  Weibull, Royal T
-00010f30: 6563 686e 6963 616c 2055 6e69 7665 7273  echnical Univers
-00010f40: 6974 792c 2053 746f 636b 686f 6c6d 2c0a  ity, Stockholm,.
-00010f50: 2020 2020 2020 2020 2031 3933 3920 2241           1939 "A
-00010f60: 2053 7461 7469 7374 6963 616c 2054 6865   Statistical The
-00010f70: 6f72 7920 4f66 2054 6865 2053 7472 656e  ory Of The Stren
-00010f80: 6774 6820 4f66 204d 6174 6572 6961 6c73  gth Of Materials
-00010f90: 222c 0a20 2020 2020 2020 2020 496e 6765  ",.         Inge
-00010fa0: 6e69 6f72 7376 6574 656e 736b 6170 7361  niorsvetenskapsa
-00010fb0: 6b61 6465 6d69 656e 7320 4861 6e64 6c69  kademiens Handli
-00010fc0: 6e67 6172 204e 7220 3135 312c 2031 3933  ngar Nr 151, 193
-00010fd0: 392c 0a20 2020 2020 2020 2020 4765 6e65  9,.         Gene
-00010fe0: 7261 6c73 7461 6265 6e73 204c 6974 6f67  ralstabens Litog
-00010ff0: 7261 6669 736b 6120 416e 7374 616c 7473  rafiska Anstalts
-00011000: 2046 6f72 6c61 672c 2053 746f 636b 686f   Forlag, Stockho
-00011010: 6c6d 2e0a 2020 2e2e 205b 325d 2057 616c  lm..  .. [2] Wal
-00011020: 6f64 6469 2057 6569 6275 6c6c 2c20 2241  oddi Weibull, "A
-00011030: 2053 7461 7469 7374 6963 616c 2044 6973   Statistical Dis
-00011040: 7472 6962 7574 696f 6e20 4675 6e63 7469  tribution Functi
-00011050: 6f6e 206f 660a 2020 2020 2020 2020 2057  on of.         W
-00011060: 6964 6520 4170 706c 6963 6162 696c 6974  ide Applicabilit
-00011070: 7922 2c20 4a6f 7572 6e61 6c20 4f66 2041  y", Journal Of A
-00011080: 7070 6c69 6564 204d 6563 6861 6e69 6373  pplied Mechanics
-00011090: 2041 534d 4520 5061 7065 720a 2020 2020   ASME Paper.    
-000110a0: 2020 2020 2031 3935 312e 0a20 202e 2e20       1951..  .. 
-000110b0: 5b33 5d20 5769 6b69 7065 6469 612c 2022  [3] Wikipedia, "
-000110c0: 5765 6962 756c 6c20 6469 7374 7269 6275  Weibull distribu
-000110d0: 7469 6f6e 222c 0a20 2020 2020 2020 2020  tion",.         
-000110e0: 6874 7470 733a 2f2f 656e 2e77 696b 6970  https://en.wikip
-000110f0: 6564 6961 2e6f 7267 2f77 696b 692f 5765  edia.org/wiki/We
-00011100: 6962 756c 6c5f 6469 7374 7269 6275 7469  ibull_distributi
-00011110: 6f6e 0a0a 2020 4578 616d 706c 6573 0a20  on..  Examples. 
-00011120: 202d 2d2d 2d2d 2d2d 2d0a 2020 4472 6177   --------.  Draw
-00011130: 2073 616d 706c 6573 2066 726f 6d20 7468   samples from th
-00011140: 6520 6469 7374 7269 6275 7469 6f6e 3a0a  e distribution:.
-00011150: 0a20 203e 3e3e 2061 203d 2035 2e20 2320  .  >>> a = 5. # 
-00011160: 7368 6170 650a 2020 3e3e 3e20 7320 3d20  shape.  >>> s = 
-00011170: 6272 6169 6e70 792e 6d61 7468 2e72 616e  brainpy.math.ran
-00011180: 646f 6d2e 7765 6962 756c 6c28 612c 2031  dom.weibull(a, 1
-00011190: 3030 3029 0a0a 2020 4469 7370 6c61 7920  000)..  Display 
-000111a0: 7468 6520 6869 7374 6f67 7261 6d20 6f66  the histogram of
-000111b0: 2074 6865 2073 616d 706c 6573 2c20 616c   the samples, al
-000111c0: 6f6e 6720 7769 7468 0a20 2074 6865 2070  ong with.  the p
-000111d0: 726f 6261 6269 6c69 7479 2064 656e 7369  robability densi
-000111e0: 7479 2066 756e 6374 696f 6e3a 0a0a 2020  ty function:..  
-000111f0: 3e3e 3e20 696d 706f 7274 206d 6174 706c  >>> import matpl
-00011200: 6f74 6c69 622e 7079 706c 6f74 2061 7320  otlib.pyplot as 
-00011210: 706c 740a 2020 3e3e 3e20 7820 3d20 6e70  plt.  >>> x = np
-00011220: 2e61 7261 6e67 6528 312c 3130 302e 292f  .arange(1,100.)/
-00011230: 3530 2e0a 2020 3e3e 3e20 6465 6620 7765  50..  >>> def we
-00011240: 6962 2878 2c6e 2c61 293a 0a20 202e 2e2e  ib(x,n,a):.  ...
-00011250: 2020 2020 2072 6574 7572 6e20 2861 202f       return (a /
-00011260: 206e 2920 2a20 2878 202f 206e 292a 2a28   n) * (x / n)**(
-00011270: 6120 2d20 3129 202a 206e 702e 6578 7028  a - 1) * np.exp(
-00011280: 2d28 7820 2f20 6e29 2a2a 6129 0a0a 2020  -(x / n)**a)..  
-00011290: 3e3e 3e20 636f 756e 742c 2062 696e 732c  >>> count, bins,
-000112a0: 2069 676e 6f72 6564 203d 2070 6c74 2e68   ignored = plt.h
-000112b0: 6973 7428 6272 6169 6e70 792e 6d61 7468  ist(brainpy.math
-000112c0: 2e72 616e 646f 6d2e 7765 6962 756c 6c28  .random.weibull(
-000112d0: 352e 2c31 3030 3029 290a 2020 3e3e 3e20  5.,1000)).  >>> 
-000112e0: 7820 3d20 6e70 2e61 7261 6e67 6528 312c  x = np.arange(1,
-000112f0: 3130 302e 292f 3530 2e0a 2020 3e3e 3e20  100.)/50..  >>> 
-00011300: 7363 616c 6520 3d20 636f 756e 742e 6d61  scale = count.ma
-00011310: 7828 292f 7765 6962 2878 2c20 312e 2c20  x()/weib(x, 1., 
-00011320: 352e 292e 6d61 7828 290a 2020 3e3e 3e20  5.).max().  >>> 
-00011330: 706c 742e 706c 6f74 2878 2c20 7765 6962  plt.plot(x, weib
-00011340: 2878 2c20 312e 2c20 352e 292a 7363 616c  (x, 1., 5.)*scal
-00011350: 6529 0a20 203e 3e3e 2070 6c74 2e73 686f  e).  >>> plt.sho
-00011360: 7728 290a 0a20 2022 2222 0a20 2072 6574  w()..  """.  ret
-00011370: 7572 6e20 4445 4641 554c 542e 7765 6962  urn DEFAULT.weib
-00011380: 756c 6c28 612c 2073 697a 652c 206b 6579  ull(a, size, key
-00011390: 3d6b 6579 290a 0a0a 6465 6620 7765 6962  =key)...def weib
-000113a0: 756c 6c5f 6d69 6e28 612c 2073 6361 6c65  ull_min(a, scale
-000113b0: 3d4e 6f6e 652c 2073 697a 653d 4e6f 6e65  =None, size=None
-000113c0: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2022  , key=None):.  "
-000113d0: 2222 5361 6d70 6c65 2066 726f 6d20 6120  ""Sample from a 
-000113e0: 5765 6962 756c 6c20 6469 7374 7269 6275  Weibull distribu
-000113f0: 7469 6f6e 2e0a 0a20 2054 6865 2073 6369  tion...  The sci
-00011400: 7079 2063 6f75 6e74 6572 7061 7274 2069  py counterpart i
-00011410: 7320 6073 6369 7079 2e73 7461 7473 2e77  s `scipy.stats.w
-00011420: 6569 6275 6c6c 5f6d 696e 602e 0a0a 2020  eibull_min`...  
-00011430: 4172 6773 3a0a 2020 2020 7363 616c 653a  Args:.    scale:
-00011440: 2054 6865 2073 6361 6c65 2070 6172 616d   The scale param
-00011450: 6574 6572 206f 6620 7468 6520 6469 7374  eter of the dist
-00011460: 7269 6275 7469 6f6e 2e0a 2020 2020 636f  ribution..    co
-00011470: 6e63 656e 7472 6174 696f 6e3a 2054 6865  ncentration: The
-00011480: 2063 6f6e 6365 6e74 7261 7469 6f6e 2070   concentration p
-00011490: 6172 616d 6574 6572 206f 6620 7468 6520  arameter of the 
-000114a0: 6469 7374 7269 6275 7469 6f6e 2e0a 2020  distribution..  
-000114b0: 2020 7368 6170 653a 2054 6865 2073 6861    shape: The sha
-000114c0: 7065 2061 6464 6564 2074 6f20 7468 6520  pe added to the 
-000114d0: 7061 7261 6d65 7465 7273 206c 6f63 2061  parameters loc a
-000114e0: 6e64 2073 6361 6c65 2062 726f 6164 6361  nd scale broadca
-000114f0: 7374 6162 6c65 2073 6861 7065 2e0a 2020  stable shape..  
-00011500: 2020 6474 7970 653a 2054 6865 2074 7970    dtype: The typ
-00011510: 6520 7573 6564 2066 6f72 2073 616d 706c  e used for sampl
-00011520: 6573 2e0a 2020 2020 6b65 793a 2061 2050  es..    key: a P
-00011530: 524e 4720 6b65 7920 6f72 2061 2073 6565  RNG key or a see
-00011540: 642e 0a0a 2020 5265 7475 726e 733a 0a20  d...  Returns:. 
-00011550: 2020 2041 206a 6e70 2e61 7272 6179 206f     A jnp.array o
-00011560: 6620 7361 6d70 6c65 732e 0a0a 2020 2222  f samples...  ""
-00011570: 220a 2020 7265 7475 726e 2044 4546 4155  ".  return DEFAU
-00011580: 4c54 2e77 6569 6275 6c6c 5f6d 696e 2861  LT.weibull_min(a
-00011590: 2c20 7363 616c 652c 2073 697a 652c 206b  , scale, size, k
-000115a0: 6579 3d6b 6579 290a 0a0a 6465 6620 7a69  ey=key)...def zi
-000115b0: 7066 2861 2c20 7369 7a65 3d4e 6f6e 652c  pf(a, size=None,
-000115c0: 206b 6579 3d4e 6f6e 6529 3a0a 2020 7222   key=None):.  r"
-000115d0: 2222 0a20 2044 7261 7720 7361 6d70 6c65  "".  Draw sample
-000115e0: 7320 6672 6f6d 2061 205a 6970 6620 6469  s from a Zipf di
-000115f0: 7374 7269 6275 7469 6f6e 2e0a 0a20 2053  stribution...  S
-00011600: 616d 706c 6573 2061 7265 2064 7261 776e  amples are drawn
-00011610: 2066 726f 6d20 6120 5a69 7066 2064 6973   from a Zipf dis
-00011620: 7472 6962 7574 696f 6e20 7769 7468 2073  tribution with s
-00011630: 7065 6369 6669 6564 2070 6172 616d 6574  pecified paramet
-00011640: 6572 0a20 2060 6160 203e 2031 2e0a 0a20  er.  `a` > 1... 
-00011650: 2054 6865 205a 6970 6620 6469 7374 7269   The Zipf distri
-00011660: 6275 7469 6f6e 2028 616c 736f 206b 6e6f  bution (also kno
-00011670: 776e 2061 7320 7468 6520 7a65 7461 2064  wn as the zeta d
-00011680: 6973 7472 6962 7574 696f 6e29 2069 7320  istribution) is 
-00011690: 610a 2020 6469 7363 7265 7465 2070 726f  a.  discrete pro
-000116a0: 6261 6269 6c69 7479 2064 6973 7472 6962  bability distrib
-000116b0: 7574 696f 6e20 7468 6174 2073 6174 6973  ution that satis
-000116c0: 6669 6573 205a 6970 6627 7320 6c61 773a  fies Zipf's law:
-000116d0: 2074 6865 0a20 2066 7265 7175 656e 6379   the.  frequency
-000116e0: 206f 6620 616e 2069 7465 6d20 6973 2069   of an item is i
-000116f0: 6e76 6572 7365 6c79 2070 726f 706f 7274  nversely proport
-00011700: 696f 6e61 6c20 746f 2069 7473 2072 616e  ional to its ran
-00011710: 6b20 696e 2061 0a20 2066 7265 7175 656e  k in a.  frequen
-00011720: 6379 2074 6162 6c65 2e0a 0a20 202e 2e20  cy table...  .. 
-00011730: 6e6f 7465 3a3a 0a20 2020 2020 204e 6577  note::.      New
-00011740: 2063 6f64 6520 7368 6f75 6c64 2075 7365   code should use
-00011750: 2074 6865 2060 607a 6970 6660 6020 6d65   the ``zipf`` me
-00011760: 7468 6f64 206f 6620 6120 6060 6465 6661  thod of a ``defa
-00011770: 756c 745f 726e 6728 2960 600a 2020 2020  ult_rng()``.    
-00011780: 2020 696e 7374 616e 6365 2069 6e73 7465    instance inste
-00011790: 6164 3b20 706c 6561 7365 2073 6565 2074  ad; please see t
-000117a0: 6865 203a 7265 663a 6072 616e 646f 6d2d  he :ref:`random-
-000117b0: 7175 6963 6b2d 7374 6172 7460 2e0a 0a20  quick-start`... 
-000117c0: 2050 6172 616d 6574 6572 730a 2020 2d2d   Parameters.  --
-000117d0: 2d2d 2d2d 2d2d 2d2d 0a20 2061 203a 2066  --------.  a : f
-000117e0: 6c6f 6174 206f 7220 6172 7261 795f 6c69  loat or array_li
-000117f0: 6b65 206f 6620 666c 6f61 7473 0a20 2020  ke of floats.   
-00011800: 2020 2044 6973 7472 6962 7574 696f 6e20     Distribution 
-00011810: 7061 7261 6d65 7465 722e 204d 7573 7420  parameter. Must 
-00011820: 6265 2067 7265 6174 6572 2074 6861 6e20  be greater than 
-00011830: 312e 0a20 2073 697a 6520 3a20 696e 7420  1..  size : int 
-00011840: 6f72 2074 7570 6c65 206f 6620 696e 7473  or tuple of ints
-00011850: 2c20 6f70 7469 6f6e 616c 0a20 2020 2020  , optional.     
-00011860: 204f 7574 7075 7420 7368 6170 652e 2020   Output shape.  
-00011870: 4966 2074 6865 2067 6976 656e 2073 6861  If the given sha
-00011880: 7065 2069 732c 2065 2e67 2e2c 2060 6028  pe is, e.g., ``(
-00011890: 6d2c 206e 2c20 6b29 6060 2c20 7468 656e  m, n, k)``, then
-000118a0: 0a20 2020 2020 2060 606d 202a 206e 202a  .      ``m * n *
-000118b0: 206b 6060 2073 616d 706c 6573 2061 7265   k`` samples are
-000118c0: 2064 7261 776e 2e20 2049 6620 7369 7a65   drawn.  If size
-000118d0: 2069 7320 6060 4e6f 6e65 6060 2028 6465   is ``None`` (de
-000118e0: 6661 756c 7429 2c0a 2020 2020 2020 6120  fault),.      a 
-000118f0: 7369 6e67 6c65 2076 616c 7565 2069 7320  single value is 
-00011900: 7265 7475 726e 6564 2069 6620 6060 6160  returned if ``a`
-00011910: 6020 6973 2061 2073 6361 6c61 722e 204f  ` is a scalar. O
-00011920: 7468 6572 7769 7365 2c0a 2020 2020 2020  therwise,.      
-00011930: 6060 6e70 2e61 7272 6179 2861 292e 7369  ``np.array(a).si
-00011940: 7a65 6060 2073 616d 706c 6573 2061 7265  ze`` samples are
-00011950: 2064 7261 776e 2e0a 0a20 2052 6574 7572   drawn...  Retur
-00011960: 6e73 0a20 202d 2d2d 2d2d 2d2d 0a20 206f  ns.  -------.  o
-00011970: 7574 203a 206e 6461 7272 6179 206f 7220  ut : ndarray or 
-00011980: 7363 616c 6172 0a20 2020 2020 2044 7261  scalar.      Dra
-00011990: 776e 2073 616d 706c 6573 2066 726f 6d20  wn samples from 
-000119a0: 7468 6520 7061 7261 6d65 7465 7269 7a65  the parameterize
-000119b0: 6420 5a69 7066 2064 6973 7472 6962 7574  d Zipf distribut
-000119c0: 696f 6e2e 0a0a 2020 5365 6520 416c 736f  ion...  See Also
-000119d0: 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020 7363  .  --------.  sc
-000119e0: 6970 792e 7374 6174 732e 7a69 7066 203a  ipy.stats.zipf :
-000119f0: 2070 726f 6261 6269 6c69 7479 2064 656e   probability den
-00011a00: 7369 7479 2066 756e 6374 696f 6e2c 2064  sity function, d
-00011a10: 6973 7472 6962 7574 696f 6e2c 206f 720a  istribution, or.
-00011a20: 2020 2020 2020 6375 6d75 6c61 7469 7665        cumulative
-00011a30: 2064 656e 7369 7479 2066 756e 6374 696f   density functio
-00011a40: 6e2c 2065 7463 2e0a 2020 7261 6e64 6f6d  n, etc..  random
-00011a50: 2e47 656e 6572 6174 6f72 2e7a 6970 663a  .Generator.zipf:
-00011a60: 2077 6869 6368 2073 686f 756c 6420 6265   which should be
-00011a70: 2075 7365 6420 666f 7220 6e65 7720 636f   used for new co
-00011a80: 6465 2e0a 0a20 204e 6f74 6573 0a20 202d  de...  Notes.  -
-00011a90: 2d2d 2d2d 0a20 2054 6865 2070 726f 6261  ----.  The proba
-00011aa0: 6269 6c69 7479 2064 656e 7369 7479 2066  bility density f
-00011ab0: 6f72 2074 6865 205a 6970 6620 6469 7374  or the Zipf dist
-00011ac0: 7269 6275 7469 6f6e 2069 730a 0a20 202e  ribution is..  .
-00011ad0: 2e20 6d61 7468 3a3a 2070 286b 2920 3d20  . math:: p(k) = 
-00011ae0: 5c66 7261 637b 6b5e 7b2d 617d 7d7b 5c7a  \frac{k^{-a}}{\z
-00011af0: 6574 6128 6129 7d2c 0a0a 2020 666f 7220  eta(a)},..  for 
-00011b00: 696e 7465 6765 7273 203a 6d61 7468 3a60  integers :math:`
-00011b10: 6b20 5c67 6571 2031 602c 2077 6865 7265  k \geq 1`, where
-00011b20: 203a 6d61 7468 3a60 5c7a 6574 6160 2069   :math:`\zeta` i
-00011b30: 7320 7468 6520 5269 656d 616e 6e20 5a65  s the Riemann Ze
-00011b40: 7461 0a20 2066 756e 6374 696f 6e2e 0a0a  ta.  function...
-00011b50: 2020 4974 2069 7320 6e61 6d65 6420 666f    It is named fo
-00011b60: 7220 7468 6520 416d 6572 6963 616e 206c  r the American l
-00011b70: 696e 6775 6973 7420 4765 6f72 6765 204b  inguist George K
-00011b80: 696e 6773 6c65 7920 5a69 7066 2c20 7768  ingsley Zipf, wh
-00011b90: 6f20 6e6f 7465 640a 2020 7468 6174 2074  o noted.  that t
-00011ba0: 6865 2066 7265 7175 656e 6379 206f 6620  he frequency of 
-00011bb0: 616e 7920 776f 7264 2069 6e20 6120 7361  any word in a sa
-00011bc0: 6d70 6c65 206f 6620 6120 6c61 6e67 7561  mple of a langua
-00011bd0: 6765 2069 7320 696e 7665 7273 656c 790a  ge is inversely.
-00011be0: 2020 7072 6f70 6f72 7469 6f6e 616c 2074    proportional t
-00011bf0: 6f20 6974 7320 7261 6e6b 2069 6e20 7468  o its rank in th
-00011c00: 6520 6672 6571 7565 6e63 7920 7461 626c  e frequency tabl
-00011c10: 652e 0a0a 2020 5265 6665 7265 6e63 6573  e...  References
-00011c20: 0a20 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  .  ----------.  
-00011c30: 2e2e 205b 315d 205a 6970 662c 2047 2e20  .. [1] Zipf, G. 
-00011c40: 4b2e 2c20 2253 656c 6563 7465 6420 5374  K., "Selected St
-00011c50: 7564 6965 7320 6f66 2074 6865 2050 7269  udies of the Pri
-00011c60: 6e63 6970 6c65 206f 6620 5265 6c61 7469  nciple of Relati
-00011c70: 7665 0a20 2020 2020 2020 2020 4672 6571  ve.         Freq
-00011c80: 7565 6e63 7920 696e 204c 616e 6775 6167  uency in Languag
-00011c90: 652c 2220 4361 6d62 7269 6467 652c 204d  e," Cambridge, M
-00011ca0: 413a 2048 6172 7661 7264 2055 6e69 762e  A: Harvard Univ.
-00011cb0: 2050 7265 7373 2c0a 2020 2020 2020 2020   Press,.        
-00011cc0: 2031 3933 322e 0a0a 2020 4578 616d 706c   1932...  Exampl
-00011cd0: 6573 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020  es.  --------.  
-00011ce0: 4472 6177 2073 616d 706c 6573 2066 726f  Draw samples fro
-00011cf0: 6d20 7468 6520 6469 7374 7269 6275 7469  m the distributi
-00011d00: 6f6e 3a0a 0a20 203e 3e3e 2061 203d 2034  on:..  >>> a = 4
-00011d10: 2e30 0a20 203e 3e3e 206e 203d 2032 3030  .0.  >>> n = 200
-00011d20: 3030 0a20 203e 3e3e 2073 203d 2062 7261  00.  >>> s = bra
-00011d30: 696e 7079 2e6d 6174 682e 7261 6e64 6f6d  inpy.math.random
-00011d40: 2e7a 6970 6628 612c 206e 290a 0a20 2044  .zipf(a, n)..  D
-00011d50: 6973 706c 6179 2074 6865 2068 6973 746f  isplay the histo
-00011d60: 6772 616d 206f 6620 7468 6520 7361 6d70  gram of the samp
-00011d70: 6c65 732c 2061 6c6f 6e67 2077 6974 680a  les, along with.
-00011d80: 2020 7468 6520 6578 7065 6374 6564 2068    the expected h
-00011d90: 6973 746f 6772 616d 2062 6173 6564 206f  istogram based o
-00011da0: 6e20 7468 6520 7072 6f62 6162 696c 6974  n the probabilit
-00011db0: 790a 2020 6465 6e73 6974 7920 6675 6e63  y.  density func
-00011dc0: 7469 6f6e 3a0a 0a20 203e 3e3e 2069 6d70  tion:..  >>> imp
-00011dd0: 6f72 7420 6d61 7470 6c6f 746c 6962 2e70  ort matplotlib.p
-00011de0: 7970 6c6f 7420 6173 2070 6c74 0a20 203e  yplot as plt.  >
-00011df0: 3e3e 2066 726f 6d20 7363 6970 792e 7370  >> from scipy.sp
-00011e00: 6563 6961 6c20 696d 706f 7274 207a 6574  ecial import zet
-00011e10: 6120 2023 2064 6f63 7465 7374 3a20 2b53  a  # doctest: +S
-00011e20: 4b49 500a 0a20 2060 6269 6e63 6f75 6e74  KIP..  `bincount
-00011e30: 6020 7072 6f76 6964 6573 2061 2066 6173  ` provides a fas
-00011e40: 7420 6869 7374 6f67 7261 6d20 666f 7220  t histogram for 
-00011e50: 736d 616c 6c20 696e 7465 6765 7273 2e0a  small integers..
-00011e60: 0a20 203e 3e3e 2063 6f75 6e74 203d 206e  .  >>> count = n
-00011e70: 702e 6269 6e63 6f75 6e74 2873 290a 2020  p.bincount(s).  
-00011e80: 3e3e 3e20 6b20 3d20 6e70 2e61 7261 6e67  >>> k = np.arang
-00011e90: 6528 312c 2073 2e6d 6178 2829 202b 2031  e(1, s.max() + 1
-00011ea0: 290a 0a20 203e 3e3e 2070 6c74 2e62 6172  )..  >>> plt.bar
-00011eb0: 286b 2c20 636f 756e 745b 313a 5d2c 2061  (k, count[1:], a
-00011ec0: 6c70 6861 3d30 2e35 2c20 6c61 6265 6c3d  lpha=0.5, label=
-00011ed0: 2773 616d 706c 6520 636f 756e 7427 290a  'sample count').
-00011ee0: 2020 3e3e 3e20 706c 742e 706c 6f74 286b    >>> plt.plot(k
-00011ef0: 2c20 6e2a 286b 2a2a 2d61 292f 7a65 7461  , n*(k**-a)/zeta
-00011f00: 2861 292c 2027 6b2e 2d27 2c20 616c 7068  (a), 'k.-', alph
-00011f10: 613d 302e 352c 0a20 202e 2e2e 2020 2020  a=0.5,.  ...    
-00011f20: 2020 2020 2020 6c61 6265 6c3d 2765 7870        label='exp
-00011f30: 6563 7465 6420 636f 756e 7427 2920 2020  ected count')   
-00011f40: 2320 646f 6374 6573 743a 202b 534b 4950  # doctest: +SKIP
-00011f50: 0a20 203e 3e3e 2070 6c74 2e73 656d 696c  .  >>> plt.semil
-00011f60: 6f67 7928 290a 2020 3e3e 3e20 706c 742e  ogy().  >>> plt.
-00011f70: 6772 6964 2861 6c70 6861 3d30 2e34 290a  grid(alpha=0.4).
-00011f80: 2020 3e3e 3e20 706c 742e 6c65 6765 6e64    >>> plt.legend
-00011f90: 2829 0a20 203e 3e3e 2070 6c74 2e74 6974  ().  >>> plt.tit
-00011fa0: 6c65 2866 275a 6970 6620 7361 6d70 6c65  le(f'Zipf sample
-00011fb0: 2c20 613d 7b61 7d2c 2073 697a 653d 7b6e  , a={a}, size={n
-00011fc0: 7d27 290a 2020 3e3e 3e20 706c 742e 7368  }').  >>> plt.sh
-00011fd0: 6f77 2829 0a20 2022 2222 0a20 2072 6574  ow().  """.  ret
-00011fe0: 7572 6e20 4445 4641 554c 542e 7a69 7066  urn DEFAULT.zipf
-00011ff0: 2861 2c20 7369 7a65 2c20 6b65 793d 6b65  (a, size, key=ke
-00012000: 7929 0a0a 0a64 6566 206d 6178 7765 6c6c  y)...def maxwell
-00012010: 2873 697a 653d 4e6f 6e65 2c20 6b65 793d  (size=None, key=
-00012020: 4e6f 6e65 293a 0a20 2022 2222 5361 6d70  None):.  """Samp
-00012030: 6c65 2066 726f 6d20 6120 6f6e 6520 7369  le from a one si
-00012040: 6465 6420 4d61 7877 656c 6c20 6469 7374  ded Maxwell dist
-00012050: 7269 6275 7469 6f6e 2e0a 0a20 2054 6865  ribution...  The
-00012060: 2073 6369 7079 2063 6f75 6e74 6572 7061   scipy counterpa
-00012070: 7274 2069 7320 6073 6369 7079 2e73 7461  rt is `scipy.sta
-00012080: 7473 2e6d 6178 7765 6c6c 602e 0a0a 2020  ts.maxwell`...  
-00012090: 4172 6773 3a0a 2020 2020 6b65 793a 2061  Args:.    key: a
-000120a0: 2050 524e 4720 6b65 792e 0a20 2020 2073   PRNG key..    s
-000120b0: 697a 653a 2054 6865 2073 6861 7065 206f  ize: The shape o
-000120c0: 6620 7468 6520 7265 7475 726e 6564 2073  f the returned s
-000120d0: 616d 706c 6573 2e0a 2020 2020 6474 7970  amples..    dtyp
-000120e0: 653a 2054 6865 2074 7970 6520 7573 6564  e: The type used
-000120f0: 2066 6f72 2073 616d 706c 6573 2e0a 0a20   for samples... 
-00012100: 2052 6574 7572 6e73 3a0a 2020 2020 4120   Returns:.    A 
-00012110: 6a6e 702e 6172 7261 7920 6f66 2073 616d  jnp.array of sam
-00012120: 706c 6573 2c20 6f66 2073 6861 7065 2060  ples, of shape `
-00012130: 7368 6170 6560 2e0a 0a20 2022 2222 0a20  shape`...  """. 
-00012140: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
-00012150: 6d61 7877 656c 6c28 7369 7a65 2c20 6b65  maxwell(size, ke
-00012160: 793d 6b65 7929 0a0a 0a64 6566 2074 2864  y=key)...def t(d
-00012170: 662c 2073 697a 653d 4e6f 6e65 2c20 6b65  f, size=None, ke
-00012180: 793d 4e6f 6e65 293a 0a20 2022 2222 5361  y=None):.  """Sa
-00012190: 6d70 6c65 2053 7475 6465 6e74 e280 9973  mple Student...s
-000121a0: 2074 2072 616e 646f 6d20 7661 6c75 6573   t random values
-000121b0: 2e0a 0a20 2050 6172 616d 6574 6572 730a  ...  Parameters.
-000121c0: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2064    ----------.  d
-000121d0: 663a 2066 6c6f 6174 2c20 6172 7261 795f  f: float, array_
-000121e0: 6c69 6b65 0a20 2020 2041 2066 6c6f 6174  like.    A float
-000121f0: 206f 7220 6172 7261 7920 6f66 2066 6c6f   or array of flo
-00012200: 6174 7320 6272 6f61 6463 6173 742d 636f  ats broadcast-co
-00012210: 6d70 6174 6962 6c65 2077 6974 6820 7368  mpatible with sh
-00012220: 6170 6520 7265 7072 6573 656e 7469 6e67  ape representing
-00012230: 2074 6865 2070 6172 616d 6574 6572 206f   the parameter o
-00012240: 6620 7468 6520 6469 7374 7269 6275 7469  f the distributi
-00012250: 6f6e 2e0a 2020 7369 7a65 3a20 6f70 7469  on..  size: opti
-00012260: 6f6e 616c 2c20 696e 742c 2074 7570 6c65  onal, int, tuple
-00012270: 206f 6620 696e 740a 2020 2020 4120 7475   of int.    A tu
-00012280: 706c 6520 6f66 206e 6f6e 2d6e 6567 6174  ple of non-negat
-00012290: 6976 6520 696e 7465 6765 7273 2073 7065  ive integers spe
-000122a0: 6369 6679 696e 6720 7468 6520 7265 7375  cifying the resu
-000122b0: 6c74 2073 6861 7065 2e0a 2020 2020 4d75  lt shape..    Mu
-000122c0: 7374 2062 6520 6272 6f61 6463 6173 742d  st be broadcast-
-000122d0: 636f 6d70 6174 6962 6c65 2077 6974 6820  compatible with 
-000122e0: 6064 6660 2e20 5468 6520 6465 6661 756c  `df`. The defaul
-000122f0: 7420 284e 6f6e 6529 2070 726f 6475 6365  t (None) produce
-00012300: 7320 6120 7265 7375 6c74 2073 6861 7065  s a result shape
-00012310: 2065 7175 616c 2074 6f20 6064 662e 7368   equal to `df.sh
-00012320: 6170 6560 2e0a 0a20 2052 6574 7572 6e73  ape`...  Returns
-00012330: 0a20 202d 2d2d 2d2d 2d2d 0a20 206f 7574  .  -------.  out
-00012340: 3a20 6172 7261 795f 6c69 6b65 0a20 2020  : array_like.   
-00012350: 2054 6865 2073 616d 706c 6564 2076 616c   The sampled val
-00012360: 7565 2e0a 2020 2222 220a 2020 7265 7475  ue..  """.  retu
-00012370: 726e 2044 4546 4155 4c54 2e74 2864 662c  rn DEFAULT.t(df,
-00012380: 2073 697a 652c 206b 6579 3d6b 6579 290a   size, key=key).
-00012390: 0a0a 6465 6620 6f72 7468 6f67 6f6e 616c  ..def orthogonal
-000123a0: 286e 3a20 696e 742c 2073 697a 653d 4e6f  (n: int, size=No
-000123b0: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
-000123c0: 2022 2222 5361 6d70 6c65 2075 6e69 666f   """Sample unifo
-000123d0: 726d 6c79 2066 726f 6d20 7468 6520 6f72  rmly from the or
-000123e0: 7468 6f67 6f6e 616c 2067 726f 7570 2060  thogonal group `
-000123f0: 4f28 6e29 602e 0a0a 2020 5061 7261 6d65  O(n)`...  Parame
-00012400: 7465 7273 0a20 202d 2d2d 2d2d 2d2d 2d2d  ters.  ---------
-00012410: 2d0a 2020 6e3a 2069 6e74 0a20 2020 2020  -.  n: int.     
-00012420: 416e 2069 6e74 6567 6572 2069 6e64 6963  An integer indic
-00012430: 6174 696e 6720 7468 6520 7265 7375 6c74  ating the result
-00012440: 696e 6720 6469 6d65 6e73 696f 6e2e 0a20  ing dimension.. 
-00012450: 2073 697a 653a 206f 7074 696f 6e61 6c2c   size: optional,
-00012460: 2069 6e74 2c20 7475 706c 6520 6f66 2069   int, tuple of i
-00012470: 6e74 0a20 2020 2054 6865 2062 6174 6368  nt.    The batch
-00012480: 2064 696d 656e 7369 6f6e 7320 6f66 2074   dimensions of t
-00012490: 6865 2072 6573 756c 742e 0a0a 2020 5265  he result...  Re
-000124a0: 7475 726e 730a 2020 2d2d 2d2d 2d2d 2d0a  turns.  -------.
-000124b0: 2020 6f75 743a 2041 7272 6179 0a20 2020    out: Array.   
-000124c0: 2054 6865 2073 616d 706c 6564 2072 6573   The sampled res
-000124d0: 756c 7473 2e0a 2020 2222 220a 2020 7265  ults..  """.  re
-000124e0: 7475 726e 2044 4546 4155 4c54 2e6f 7274  turn DEFAULT.ort
-000124f0: 686f 676f 6e61 6c28 6e2c 2073 697a 652c  hogonal(n, size,
-00012500: 206b 6579 3d6b 6579 290a 0a0a 6465 6620   key=key)...def 
-00012510: 6c6f 6767 616d 6d61 2861 2c20 7369 7a65  loggamma(a, size
-00012520: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
-00012530: 3a0a 2020 2222 2253 616d 706c 6520 6c6f  :.  """Sample lo
-00012540: 672d 6761 6d6d 6120 7261 6e64 6f6d 2076  g-gamma random v
-00012550: 616c 7565 732e 0a0a 2020 5061 7261 6d65  alues...  Parame
-00012560: 7465 7273 0a20 202d 2d2d 2d2d 2d2d 2d2d  ters.  ---------
-00012570: 2d0a 2020 613a 2066 6c6f 6174 2c20 6172  -.  a: float, ar
-00012580: 7261 795f 6c69 6b65 0a20 2020 2041 2066  ray_like.    A f
-00012590: 6c6f 6174 206f 7220 6172 7261 7920 6f66  loat or array of
-000125a0: 2066 6c6f 6174 7320 6272 6f61 6463 6173   floats broadcas
-000125b0: 742d 636f 6d70 6174 6962 6c65 2077 6974  t-compatible wit
-000125c0: 6820 7368 6170 6520 7265 7072 6573 656e  h shape represen
-000125d0: 7469 6e67 2074 6865 2070 6172 616d 6574  ting the paramet
-000125e0: 6572 206f 6620 7468 6520 6469 7374 7269  er of the distri
-000125f0: 6275 7469 6f6e 2e0a 2020 7369 7a65 3a20  bution..  size: 
-00012600: 6f70 7469 6f6e 616c 2c20 696e 742c 2074  optional, int, t
-00012610: 7570 6c65 206f 6620 696e 740a 2020 2020  uple of int.    
-00012620: 4120 7475 706c 6520 6f66 206e 6f6e 6e65  A tuple of nonne
-00012630: 6761 7469 7665 2069 6e74 6567 6572 7320  gative integers 
-00012640: 7370 6563 6966 7969 6e67 2074 6865 2072  specifying the r
-00012650: 6573 756c 7420 7368 6170 652e 0a20 2020  esult shape..   
-00012660: 204d 7573 7420 6265 2062 726f 6164 6361   Must be broadca
-00012670: 7374 2d63 6f6d 7061 7469 626c 6520 7769  st-compatible wi
-00012680: 7468 2060 6160 2e20 5468 6520 6465 6661  th `a`. The defa
-00012690: 756c 7420 284e 6f6e 6529 2070 726f 6475  ult (None) produ
-000126a0: 6365 7320 6120 7265 7375 6c74 2073 6861  ces a result sha
-000126b0: 7065 2065 7175 616c 2074 6f20 6061 2e73  pe equal to `a.s
-000126c0: 6861 7065 602e 0a0a 2020 5265 7475 726e  hape`...  Return
-000126d0: 730a 2020 2d2d 2d2d 2d2d 2d0a 2020 6f75  s.  -------.  ou
-000126e0: 743a 2061 7272 6179 5f6c 696b 650a 2020  t: array_like.  
-000126f0: 2020 5468 6520 7361 6d70 6c65 6420 7265    The sampled re
-00012700: 7375 6c74 732e 0a20 2022 2222 0a20 2072  sults..  """.  r
-00012710: 6574 7572 6e20 4445 4641 554c 542e 6c6f  eturn DEFAULT.lo
-00012720: 6767 616d 6d61 2861 2c20 7369 7a65 290a  ggamma(a, size).
-00012730: 0a0a 6465 6620 6361 7465 676f 7269 6361  ..def categorica
-00012740: 6c28 6c6f 6769 7473 2c20 6178 6973 3a20  l(logits, axis: 
-00012750: 696e 7420 3d20 2d31 2c20 7369 7a65 3d4e  int = -1, size=N
-00012760: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
-00012770: 2020 2222 2253 616d 706c 6520 7261 6e64    """Sample rand
-00012780: 6f6d 2076 616c 7565 7320 6672 6f6d 2063  om values from c
-00012790: 6174 6567 6f72 6963 616c 2064 6973 7472  ategorical distr
-000127a0: 6962 7574 696f 6e73 2e0a 0a20 2041 7267  ibutions...  Arg
-000127b0: 733a 0a20 2020 206c 6f67 6974 733a 2055  s:.    logits: U
-000127c0: 6e6e 6f72 6d61 6c69 7a65 6420 6c6f 6720  nnormalized log 
-000127d0: 7072 6f62 6162 696c 6974 6965 7320 6f66  probabilities of
-000127e0: 2074 6865 2063 6174 6567 6f72 6963 616c   the categorical
-000127f0: 2064 6973 7472 6962 7574 696f 6e28 7329   distribution(s)
-00012800: 2074 6f20 7361 6d70 6c65 2066 726f 6d2c   to sample from,
-00012810: 0a20 2020 2020 2073 6f20 7468 6174 2060  .      so that `
-00012820: 736f 6674 6d61 7828 6c6f 6769 7473 2c20  softmax(logits, 
-00012830: 6178 6973 2960 2067 6976 6573 2074 6865  axis)` gives the
-00012840: 2063 6f72 7265 7370 6f6e 6469 6e67 2070   corresponding p
-00012850: 726f 6261 6269 6c69 7469 6573 2e0a 2020  robabilities..  
-00012860: 2020 6178 6973 3a20 4178 6973 2061 6c6f    axis: Axis alo
-00012870: 6e67 2077 6869 6368 206c 6f67 6974 7320  ng which logits 
-00012880: 6265 6c6f 6e67 2074 6f20 7468 6520 7361  belong to the sa
-00012890: 6d65 2063 6174 6567 6f72 6963 616c 2064  me categorical d
-000128a0: 6973 7472 6962 7574 696f 6e2e 0a20 2020  istribution..   
-000128b0: 2073 6861 7065 3a20 4f70 7469 6f6e 616c   shape: Optional
-000128c0: 2c20 6120 7475 706c 6520 6f66 206e 6f6e  , a tuple of non
-000128d0: 6e65 6761 7469 7665 2069 6e74 6567 6572  negative integer
-000128e0: 7320 7265 7072 6573 656e 7469 6e67 2074  s representing t
-000128f0: 6865 2072 6573 756c 7420 7368 6170 652e  he result shape.
-00012900: 0a20 2020 2020 204d 7573 7420 6265 2062  .      Must be b
-00012910: 726f 6164 6361 7374 2d63 6f6d 7061 7469  roadcast-compati
-00012920: 626c 6520 7769 7468 2060 606e 702e 6465  ble with ``np.de
-00012930: 6c65 7465 286c 6f67 6974 732e 7368 6170  lete(logits.shap
-00012940: 652c 2061 7869 7329 6060 2e0a 2020 2020  e, axis)``..    
-00012950: 2020 5468 6520 6465 6661 756c 7420 284e    The default (N
-00012960: 6f6e 6529 2070 726f 6475 6365 7320 6120  one) produces a 
-00012970: 7265 7375 6c74 2073 6861 7065 2065 7175  result shape equ
-00012980: 616c 2074 6f20 6060 6e70 2e64 656c 6574  al to ``np.delet
-00012990: 6528 6c6f 6769 7473 2e73 6861 7065 2c20  e(logits.shape, 
-000129a0: 6178 6973 2960 602e 0a20 2020 206b 6579  axis)``..    key
-000129b0: 3a20 6120 5052 4e47 206b 6579 2075 7365  : a PRNG key use
-000129c0: 6420 6173 2074 6865 2072 616e 646f 6d20  d as the random 
-000129d0: 6b65 792e 0a0a 2020 5265 7475 726e 733a  key...  Returns:
-000129e0: 0a20 2020 2041 2072 616e 646f 6d20 6172  .    A random ar
-000129f0: 7261 7920 7769 7468 2069 6e74 2064 7479  ray with int dty
-00012a00: 7065 2061 6e64 2073 6861 7065 2067 6976  pe and shape giv
-00012a10: 656e 2062 7920 6060 7368 6170 6560 6020  en by ``shape`` 
-00012a20: 6966 2060 6073 6861 7065 6060 0a20 2020  if ``shape``.   
-00012a30: 2069 7320 6e6f 7420 4e6f 6e65 2c20 6f72   is not None, or
-00012a40: 2065 6c73 6520 6060 6e70 2e64 656c 6574   else ``np.delet
-00012a50: 6528 6c6f 6769 7473 2e73 6861 7065 2c20  e(logits.shape, 
-00012a60: 6178 6973 2960 602e 0a20 2022 2222 0a20  axis)``..  """. 
-00012a70: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
-00012a80: 6361 7465 676f 7269 6361 6c28 6c6f 6769  categorical(logi
-00012a90: 7473 2c20 6178 6973 2c20 7369 7a65 2c20  ts, axis, size, 
-00012aa0: 6b65 793d 6b65 7929 0a0a 0a64 6566 2072  key=key)...def r
-00012ab0: 616e 645f 6c69 6b65 2869 6e70 7574 2c20  and_like(input, 
-00012ac0: 2a2c 2064 7479 7065 3d4e 6f6e 652c 206b  *, dtype=None, k
-00012ad0: 6579 3d4e 6f6e 6529 3a0a 2020 2222 2253  ey=None):.  """S
-00012ae0: 696d 696c 6172 2074 6f20 6060 7261 6e64  imilar to ``rand
-00012af0: 5f6c 696b 6560 6020 696e 2074 6f72 6368  _like`` in torch
-00012b00: 2e20 0a20 200a 2020 5265 7475 726e 7320  . .  .  Returns 
-00012b10: 6120 7465 6e73 6f72 2077 6974 6820 7468  a tensor with th
-00012b20: 6520 7361 6d65 2073 697a 6520 6173 2069  e same size as i
-00012b30: 6e70 7574 2074 6861 7420 6973 2066 696c  nput that is fil
-00012b40: 6c65 6420 7769 7468 2072 616e 646f 6d0a  led with random.
-00012b50: 2020 6e75 6d62 6572 7320 6672 6f6d 2061    numbers from a
-00012b60: 2075 6e69 666f 726d 2064 6973 7472 6962   uniform distrib
-00012b70: 7574 696f 6e20 6f6e 2074 6865 2069 6e74  ution on the int
-00012b80: 6572 7661 6c20 6060 5b30 2c20 3129 6060  erval ``[0, 1)``
-00012b90: 2e0a 0a20 2041 7267 733a 0a20 2020 2069  ...  Args:.    i
-00012ba0: 6e70 7574 3a20 2074 6865 2060 6073 697a  nput:  the ``siz
-00012bb0: 6560 6020 6f66 2069 6e70 7574 2077 696c  e`` of input wil
-00012bc0: 6c20 6465 7465 726d 696e 6520 7369 7a65  l determine size
-00012bd0: 206f 6620 7468 6520 6f75 7470 7574 2074   of the output t
-00012be0: 656e 736f 722e 0a20 2020 2064 7479 7065  ensor..    dtype
-00012bf0: 3a20 2074 6865 2064 6573 6972 6564 2064  :  the desired d
-00012c00: 6174 6120 7479 7065 206f 6620 7265 7475  ata type of retu
-00012c10: 726e 6564 2054 656e 736f 722e 2044 6566  rned Tensor. Def
-00012c20: 6175 6c74 3a20 6966 2060 604e 6f6e 6560  ault: if ``None`
-00012c30: 602c 2064 6566 6175 6c74 7320 746f 2074  `, defaults to t
-00012c40: 6865 2064 7479 7065 206f 6620 696e 7075  he dtype of inpu
-00012c50: 742e 0a20 2020 206b 6579 3a20 7468 6520  t..    key: the 
-00012c60: 7365 6564 206f 7220 6b65 7920 666f 7220  seed or key for 
-00012c70: 7468 6520 7261 6e64 6f6d 2e0a 0a20 2052  the random...  R
-00012c80: 6574 7572 6e73 3a0a 2020 2020 5468 6520  eturns:.    The 
-00012c90: 7261 6e64 6f6d 2064 6174 612e 0a20 2022  random data..  "
-00012ca0: 2222 0a20 2072 6574 7572 6e20 4445 4641  "".  return DEFA
-00012cb0: 554c 542e 7261 6e64 5f6c 696b 6528 696e  ULT.rand_like(in
-00012cc0: 7075 742c 2064 7479 7065 3d64 7479 7065  put, dtype=dtype
-00012cd0: 2c20 6b65 793d 6b65 7929 0a0a 0a64 6566  , key=key)...def
-00012ce0: 2072 616e 646e 5f6c 696b 6528 696e 7075   randn_like(inpu
-00012cf0: 742c 202a 2c20 6474 7970 653d 4e6f 6e65  t, *, dtype=None
-00012d00: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2022  , key=None):.  "
-00012d10: 2222 5369 6d69 6c61 7220 746f 2060 6072  ""Similar to ``r
-00012d20: 616e 646e 5f6c 696b 6560 6020 696e 2074  andn_like`` in t
-00012d30: 6f72 6368 2e20 0a20 200a 2020 5265 7475  orch. .  .  Retu
-00012d40: 726e 7320 6120 7465 6e73 6f72 2077 6974  rns a tensor wit
-00012d50: 6820 7468 6520 7361 6d65 2073 697a 6520  h the same size 
-00012d60: 6173 2060 6069 6e70 7574 6060 2074 6861  as ``input`` tha
-00012d70: 7420 6973 2066 696c 6c65 6420 7769 7468  t is filled with
-00012d80: 0a20 2072 616e 646f 6d20 6e75 6d62 6572  .  random number
-00012d90: 7320 6672 6f6d 2061 206e 6f72 6d61 6c20  s from a normal 
-00012da0: 6469 7374 7269 6275 7469 6f6e 2077 6974  distribution wit
-00012db0: 6820 6d65 616e 2030 2061 6e64 2076 6172  h mean 0 and var
-00012dc0: 6961 6e63 6520 312e 0a0a 2020 4172 6773  iance 1...  Args
-00012dd0: 3a0a 2020 2020 696e 7075 743a 2020 7468  :.    input:  th
-00012de0: 6520 6060 7369 7a65 6060 206f 6620 696e  e ``size`` of in
-00012df0: 7075 7420 7769 6c6c 2064 6574 6572 6d69  put will determi
-00012e00: 6e65 2073 697a 6520 6f66 2074 6865 206f  ne size of the o
-00012e10: 7574 7075 7420 7465 6e73 6f72 2e0a 2020  utput tensor..  
-00012e20: 2020 6474 7970 653a 2020 7468 6520 6465    dtype:  the de
-00012e30: 7369 7265 6420 6461 7461 2074 7970 6520  sired data type 
-00012e40: 6f66 2072 6574 7572 6e65 6420 5465 6e73  of returned Tens
-00012e50: 6f72 2e20 4465 6661 756c 743a 2069 6620  or. Default: if 
-00012e60: 6060 4e6f 6e65 6060 2c20 6465 6661 756c  ``None``, defaul
-00012e70: 7473 2074 6f20 7468 6520 6474 7970 6520  ts to the dtype 
-00012e80: 6f66 2069 6e70 7574 2e0a 2020 2020 6b65  of input..    ke
-00012e90: 793a 2074 6865 2073 6565 6420 6f72 206b  y: the seed or k
-00012ea0: 6579 2066 6f72 2074 6865 2072 616e 646f  ey for the rando
-00012eb0: 6d2e 0a0a 2020 5265 7475 726e 733a 0a20  m...  Returns:. 
-00012ec0: 2020 2054 6865 2072 616e 646f 6d20 6461     The random da
-00012ed0: 7461 2e0a 2020 2222 220a 2020 7265 7475  ta..  """.  retu
-00012ee0: 726e 2044 4546 4155 4c54 2e72 616e 646e  rn DEFAULT.randn
-00012ef0: 5f6c 696b 6528 696e 7075 742c 2064 7479  _like(input, dty
-00012f00: 7065 3d64 7479 7065 2c20 6b65 793d 6b65  pe=dtype, key=ke
-00012f10: 7929 0a0a 0a64 6566 2072 616e 6469 6e74  y)...def randint
-00012f20: 5f6c 696b 6528 696e 7075 742c 206c 6f77  _like(input, low
-00012f30: 3d30 2c20 6869 6768 3d4e 6f6e 652c 202a  =0, high=None, *
-00012f40: 2c20 6474 7970 653d 4e6f 6e65 2c20 6b65  , dtype=None, ke
-00012f50: 793d 4e6f 6e65 293a 0a20 2022 2222 5369  y=None):.  """Si
-00012f60: 6d69 6c61 7220 746f 2060 6072 616e 6469  milar to ``randi
-00012f70: 6e74 5f6c 696b 6560 6020 696e 2074 6f72  nt_like`` in tor
-00012f80: 6368 2e20 0a20 200a 2020 5265 7475 726e  ch. .  .  Return
-00012f90: 7320 6120 7465 6e73 6f72 2077 6974 6820  s a tensor with 
-00012fa0: 7468 6520 7361 6d65 2073 6861 7065 2061  the same shape a
-00012fb0: 7320 5465 6e73 6f72 2060 6069 6e70 7574  s Tensor ``input
-00012fc0: 6060 2066 696c 6c65 6420 7769 7468 0a20  `` filled with. 
-00012fd0: 2072 616e 646f 6d20 696e 7465 6765 7273   random integers
-00012fe0: 2067 656e 6572 6174 6564 2075 6e69 666f   generated unifo
-00012ff0: 726d 6c79 2062 6574 7765 656e 2060 606c  rmly between ``l
-00013000: 6f77 6060 2028 696e 636c 7573 6976 6529  ow`` (inclusive)
-00013010: 2061 6e64 2060 6068 6967 6860 6020 2865   and ``high`` (e
-00013020: 7863 6c75 7369 7665 292e 0a0a 2020 4172  xclusive)...  Ar
-00013030: 6773 3a0a 2020 2020 696e 7075 743a 2020  gs:.    input:  
-00013040: 7468 6520 6060 7369 7a65 6060 206f 6620  the ``size`` of 
-00013050: 696e 7075 7420 7769 6c6c 2064 6574 6572  input will deter
-00013060: 6d69 6e65 2073 697a 6520 6f66 2074 6865  mine size of the
-00013070: 206f 7574 7075 7420 7465 6e73 6f72 2e0a   output tensor..
-00013080: 2020 2020 6c6f 773a 204c 6f77 6573 7420      low: Lowest 
-00013090: 696e 7465 6765 7220 746f 2062 6520 6472  integer to be dr
-000130a0: 6177 6e20 6672 6f6d 2074 6865 2064 6973  awn from the dis
-000130b0: 7472 6962 7574 696f 6e2e 2044 6566 6175  tribution. Defau
-000130c0: 6c74 3a20 302e 0a20 2020 2068 6967 683a  lt: 0..    high:
-000130d0: 204f 6e65 2061 626f 7665 2074 6865 2068   One above the h
-000130e0: 6967 6865 7374 2069 6e74 6567 6572 2074  ighest integer t
-000130f0: 6f20 6265 2064 7261 776e 2066 726f 6d20  o be drawn from 
-00013100: 7468 6520 6469 7374 7269 6275 7469 6f6e  the distribution
-00013110: 2e0a 2020 2020 6474 7970 653a 2074 6865  ..    dtype: the
-00013120: 2064 6573 6972 6564 2064 6174 6120 7479   desired data ty
-00013130: 7065 206f 6620 7265 7475 726e 6564 2054  pe of returned T
-00013140: 656e 736f 722e 2044 6566 6175 6c74 3a20  ensor. Default: 
-00013150: 6966 2060 604e 6f6e 6560 602c 2064 6566  if ``None``, def
-00013160: 6175 6c74 7320 746f 2074 6865 2064 7479  aults to the dty
-00013170: 7065 206f 6620 696e 7075 742e 0a20 2020  pe of input..   
-00013180: 206b 6579 3a20 7468 6520 7365 6564 206f   key: the seed o
-00013190: 7220 6b65 7920 666f 7220 7468 6520 7261  r key for the ra
-000131a0: 6e64 6f6d 2e0a 0a20 2052 6574 7572 6e73  ndom...  Returns
-000131b0: 3a0a 2020 2020 5468 6520 7261 6e64 6f6d  :.    The random
-000131c0: 2064 6174 612e 0a20 2022 2222 0a20 2072   data..  """.  r
-000131d0: 6574 7572 6e20 4445 4641 554c 542e 7261  eturn DEFAULT.ra
-000131e0: 6e64 696e 745f 6c69 6b65 2869 6e70 7574  ndint_like(input
-000131f0: 3d69 6e70 7574 2c20 6c6f 773d 6c6f 772c  =input, low=low,
-00013200: 2068 6967 683d 6869 6768 2c20 6474 7970   high=high, dtyp
-00013210: 653d 6474 7970 652c 206b 6579 3d6b 6579  e=dtype, key=key
-00013220: 290a 0a0a 666f 7220 5f5f 6b20 696e 2064  )...for __k in d
-00013230: 6972 2852 616e 646f 6d53 7461 7465 293a  ir(RandomState):
-00013240: 0a20 205f 5f74 203d 2067 6574 6174 7472  .  __t = getattr
-00013250: 2852 616e 646f 6d53 7461 7465 2c20 5f5f  (RandomState, __
-00013260: 6b29 0a20 2069 6620 6e6f 7420 5f5f 6b2e  k).  if not __k.
-00013270: 7374 6172 7473 7769 7468 2827 5f5f 2729  startswith('__')
-00013280: 2061 6e64 2063 616c 6c61 626c 6528 5f5f   and callable(__
-00013290: 7429 2061 6e64 2028 6e6f 7420 5f5f 742e  t) and (not __t.
-000132a0: 5f5f 646f 635f 5f29 3a0a 2020 2020 5f5f  __doc__):.    __
-000132b0: 7220 3d20 676c 6f62 616c 7328 292e 6765  r = globals().ge
-000132c0: 7428 5f5f 6b2c 204e 6f6e 6529 0a20 2020  t(__k, None).   
-000132d0: 2069 6620 5f5f 7220 6973 206e 6f74 204e   if __r is not N
-000132e0: 6f6e 6520 616e 6420 6361 6c6c 6162 6c65  one and callable
-000132f0: 285f 5f72 293a 0a20 2020 2020 205f 5f74  (__r):.      __t
-00013300: 2e5f 5f64 6f63 5f5f 203d 205f 5f72 2e5f  .__doc__ = __r._
-00013310: 5f64 6f63 5f5f 0a                        _doc__.
+00006730: 206c 6f77 6572 3d6c 6f77 6572 2c0a 2020   lower=lower,.  
+00006740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006750: 2020 2020 2020 2020 2020 2020 2020 7570                up
+00006760: 7065 723d 7570 7065 722c 0a20 2020 2020  per=upper,.     
+00006770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006780: 2020 2020 2020 2020 2020 2073 6861 7065             shape
+00006790: 3d5f 7369 7a65 3273 6861 7065 2873 697a  =_size2shape(siz
+000067a0: 6529 290a 2020 2020 6966 2073 6361 6c65  e)).    if scale
+000067b0: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+000067c0: 2020 2020 7261 6e64 7320 3d20 7261 6e64      rands = rand
+000067d0: 7320 2a20 7363 616c 650a 2020 2020 7265  s * scale.    re
+000067e0: 7475 726e 205f 7265 7475 726e 2872 616e  turn _return(ran
+000067f0: 6473 290a 0a20 2064 6566 205f 6368 6563  ds)..  def _chec
+00006800: 6b5f 7028 7365 6c66 2c20 7029 3a0a 2020  k_p(self, p):.  
+00006810: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00006820: 6f72 2866 2750 6172 616d 6574 6572 2070  or(f'Parameter p
+00006830: 2073 686f 756c 6420 6265 2077 6974 6869   should be withi
+00006840: 6e20 5b30 2c20 315d 2c20 6275 7420 7765  n [0, 1], but we
+00006850: 2067 6f74 207b 707d 2729 0a0a 2020 6465   got {p}')..  de
+00006860: 6620 6265 726e 6f75 6c6c 6928 7365 6c66  f bernoulli(self
+00006870: 2c20 702c 2073 697a 653d 4e6f 6e65 2c20  , p, size=None, 
+00006880: 6b65 793d 4e6f 6e65 293a 0a20 2020 2070  key=None):.    p
+00006890: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+000068a0: 285f 6173 5f6a 6178 5f61 7272 6179 2870  (_as_jax_array(p
+000068b0: 2929 0a20 2020 206a 6974 5f65 7272 6f72  )).    jit_error
+000068c0: 286a 6e70 2e61 6e79 286a 6e70 2e6c 6f67  (jnp.any(jnp.log
+000068d0: 6963 616c 5f61 6e64 2870 203c 2030 2c20  ical_and(p < 0, 
+000068e0: 7020 3e20 3129 292c 2073 656c 662e 5f63  p > 1)), self._c
+000068f0: 6865 636b 5f70 2c20 7029 0a20 2020 2069  heck_p, p).    i
+00006900: 6620 7369 7a65 2069 7320 4e6f 6e65 3a0a  f size is None:.
+00006910: 2020 2020 2020 7369 7a65 203d 206a 6e70        size = jnp
+00006920: 2e73 6861 7065 2870 290a 2020 2020 6b65  .shape(p).    ke
+00006930: 7920 3d20 7365 6c66 2e73 706c 6974 5f6b  y = self.split_k
+00006940: 6579 2829 2069 6620 6b65 7920 6973 204e  ey() if key is N
+00006950: 6f6e 6520 656c 7365 205f 666f 726d 616c  one else _formal
+00006960: 697a 655f 6b65 7928 6b65 7929 0a20 2020  ize_key(key).   
+00006970: 2072 203d 206a 722e 6265 726e 6f75 6c6c   r = jr.bernoull
+00006980: 6928 6b65 792c 2070 3d70 2c20 7368 6170  i(key, p=p, shap
+00006990: 653d 5f73 697a 6532 7368 6170 6528 7369  e=_size2shape(si
+000069a0: 7a65 2929 0a20 2020 2072 6574 7572 6e20  ze)).    return 
+000069b0: 5f72 6574 7572 6e28 7229 0a0a 2020 6465  _return(r)..  de
+000069c0: 6620 6c6f 676e 6f72 6d61 6c28 7365 6c66  f lognormal(self
+000069d0: 2c20 6d65 616e 3d4e 6f6e 652c 2073 6967  , mean=None, sig
+000069e0: 6d61 3d4e 6f6e 652c 2073 697a 653d 4e6f  ma=None, size=No
+000069f0: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
+00006a00: 2020 206d 6561 6e20 3d20 5f63 6865 636b     mean = _check
+00006a10: 5f70 795f 7365 7128 5f61 735f 6a61 785f  _py_seq(_as_jax_
+00006a20: 6172 7261 7928 6d65 616e 2929 0a20 2020  array(mean)).   
+00006a30: 2073 6967 6d61 203d 205f 6368 6563 6b5f   sigma = _check_
+00006a40: 7079 5f73 6571 285f 6173 5f6a 6178 5f61  py_seq(_as_jax_a
+00006a50: 7272 6179 2873 6967 6d61 2929 0a20 2020  rray(sigma)).   
+00006a60: 2069 6620 7369 7a65 2069 7320 4e6f 6e65   if size is None
+00006a70: 3a0a 2020 2020 2020 7369 7a65 203d 206a  :.      size = j
+00006a80: 6e70 2e62 726f 6164 6361 7374 5f73 6861  np.broadcast_sha
+00006a90: 7065 7328 6a6e 702e 7368 6170 6528 6d65  pes(jnp.shape(me
+00006aa0: 616e 292c 0a20 2020 2020 2020 2020 2020  an),.           
+00006ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006ac0: 2020 2020 2020 206a 6e70 2e73 6861 7065         jnp.shape
+00006ad0: 2873 6967 6d61 2929 0a20 2020 206b 6579  (sigma)).    key
+00006ae0: 203d 2073 656c 662e 7370 6c69 745f 6b65   = self.split_ke
+00006af0: 7928 2920 6966 206b 6579 2069 7320 4e6f  y() if key is No
+00006b00: 6e65 2065 6c73 6520 5f66 6f72 6d61 6c69  ne else _formali
+00006b10: 7a65 5f6b 6579 286b 6579 290a 2020 2020  ze_key(key).    
+00006b20: 7361 6d70 6c65 7320 3d20 6a72 2e6e 6f72  samples = jr.nor
+00006b30: 6d61 6c28 6b65 792c 2073 6861 7065 3d5f  mal(key, shape=_
+00006b40: 7369 7a65 3273 6861 7065 2873 697a 6529  size2shape(size)
+00006b50: 290a 2020 2020 7361 6d70 6c65 7320 3d20  ).    samples = 
+00006b60: 5f6c 6f63 5f73 6361 6c65 286d 6561 6e2c  _loc_scale(mean,
+00006b70: 2073 6967 6d61 2c20 7361 6d70 6c65 7329   sigma, samples)
+00006b80: 0a20 2020 2073 616d 706c 6573 203d 206a  .    samples = j
+00006b90: 6e70 2e65 7870 2873 616d 706c 6573 290a  np.exp(samples).
+00006ba0: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
+00006bb0: 726e 2873 616d 706c 6573 290a 0a20 2064  rn(samples)..  d
+00006bc0: 6566 2062 696e 6f6d 6961 6c28 7365 6c66  ef binomial(self
+00006bd0: 2c20 6e2c 2070 2c20 7369 7a65 3d4e 6f6e  , n, p, size=Non
+00006be0: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
+00006bf0: 2020 6e20 3d20 5f63 6865 636b 5f70 795f    n = _check_py_
+00006c00: 7365 7128 6e2e 7661 6c75 6520 6966 2069  seq(n.value if i
+00006c10: 7369 6e73 7461 6e63 6528 6e2c 2041 7272  sinstance(n, Arr
+00006c20: 6179 2920 656c 7365 206e 290a 2020 2020  ay) else n).    
+00006c30: 7020 3d20 5f63 6865 636b 5f70 795f 7365  p = _check_py_se
+00006c40: 7128 702e 7661 6c75 6520 6966 2069 7369  q(p.value if isi
+00006c50: 6e73 7461 6e63 6528 702c 2041 7272 6179  nstance(p, Array
+00006c60: 2920 656c 7365 2070 290a 2020 2020 6a69  ) else p).    ji
+00006c70: 745f 6572 726f 7228 6a6e 702e 616e 7928  t_error(jnp.any(
+00006c80: 6a6e 702e 6c6f 6769 6361 6c5f 616e 6428  jnp.logical_and(
+00006c90: 7020 3c20 302c 2070 203e 2031 2929 2c20  p < 0, p > 1)), 
+00006ca0: 7365 6c66 2e5f 6368 6563 6b5f 702c 2070  self._check_p, p
+00006cb0: 290a 2020 2020 6966 2073 697a 6520 6973  ).    if size is
+00006cc0: 204e 6f6e 653a 0a20 2020 2020 2073 697a   None:.      siz
+00006cd0: 6520 3d20 6a6e 702e 6272 6f61 6463 6173  e = jnp.broadcas
+00006ce0: 745f 7368 6170 6573 286a 6e70 2e73 6861  t_shapes(jnp.sha
+00006cf0: 7065 286e 292c 206a 6e70 2e73 6861 7065  pe(n), jnp.shape
+00006d00: 2870 2929 0a20 2020 206b 6579 203d 2073  (p)).    key = s
+00006d10: 656c 662e 7370 6c69 745f 6b65 7928 2920  elf.split_key() 
+00006d20: 6966 206b 6579 2069 7320 4e6f 6e65 2065  if key is None e
+00006d30: 6c73 6520 5f66 6f72 6d61 6c69 7a65 5f6b  lse _formalize_k
+00006d40: 6579 286b 6579 290a 2020 2020 7220 3d20  ey(key).    r = 
+00006d50: 5f62 696e 6f6d 6961 6c28 6b65 792c 2070  _binomial(key, p
+00006d60: 2c20 6e2c 2073 6861 7065 3d5f 7369 7a65  , n, shape=_size
+00006d70: 3273 6861 7065 2873 697a 6529 290a 2020  2shape(size)).  
+00006d80: 2020 7265 7475 726e 205f 7265 7475 726e    return _return
+00006d90: 2872 290a 0a20 2064 6566 2063 6869 7371  (r)..  def chisq
+00006da0: 7561 7265 2873 656c 662c 2064 662c 2073  uare(self, df, s
+00006db0: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+00006dc0: 6e65 293a 0a20 2020 2064 6620 3d20 5f63  ne):.    df = _c
+00006dd0: 6865 636b 5f70 795f 7365 7128 5f61 735f  heck_py_seq(_as_
+00006de0: 6a61 785f 6172 7261 7928 6466 2929 0a20  jax_array(df)). 
+00006df0: 2020 206b 6579 203d 2073 656c 662e 7370     key = self.sp
+00006e00: 6c69 745f 6b65 7928 2920 6966 206b 6579  lit_key() if key
+00006e10: 2069 7320 4e6f 6e65 2065 6c73 6520 5f66   is None else _f
+00006e20: 6f72 6d61 6c69 7a65 5f6b 6579 286b 6579  ormalize_key(key
+00006e30: 290a 2020 2020 6966 2073 697a 6520 6973  ).    if size is
+00006e40: 204e 6f6e 653a 0a20 2020 2020 2069 6620   None:.      if 
+00006e50: 6a6e 702e 6e64 696d 2864 6629 203d 3d20  jnp.ndim(df) == 
+00006e60: 303a 0a20 2020 2020 2020 2064 6973 7420  0:.        dist 
+00006e70: 3d20 6a72 2e6e 6f72 6d61 6c28 6b65 792c  = jr.normal(key,
+00006e80: 2028 6466 2c29 2920 2a2a 2032 0a20 2020   (df,)) ** 2.   
+00006e90: 2020 2020 2064 6973 7420 3d20 6469 7374       dist = dist
+00006ea0: 2e73 756d 2829 0a20 2020 2020 2065 6c73  .sum().      els
+00006eb0: 653a 0a20 2020 2020 2020 2072 6169 7365  e:.        raise
+00006ec0: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+00006ed0: 7272 6f72 2827 446f 206e 6f74 2073 7570  rror('Do not sup
+00006ee0: 706f 7274 206e 6f6e 2d73 6361 6c65 2022  port non-scale "
+00006ef0: 6466 2220 7768 656e 2022 7369 7a65 2220  df" when "size" 
+00006f00: 6973 204e 6f6e 6527 290a 2020 2020 656c  is None').    el
+00006f10: 7365 3a0a 2020 2020 2020 6469 7374 203d  se:.      dist =
+00006f20: 206a 722e 6e6f 726d 616c 286b 6579 2c20   jr.normal(key, 
+00006f30: 2864 662c 2920 2b20 5f73 697a 6532 7368  (df,) + _size2sh
+00006f40: 6170 6528 7369 7a65 2929 202a 2a20 320a  ape(size)) ** 2.
+00006f50: 2020 2020 2020 6469 7374 203d 2064 6973        dist = dis
+00006f60: 742e 7375 6d28 6178 6973 3d30 290a 2020  t.sum(axis=0).  
+00006f70: 2020 7265 7475 726e 205f 7265 7475 726e    return _return
+00006f80: 2864 6973 7429 0a0a 2020 6465 6620 6469  (dist)..  def di
+00006f90: 7269 6368 6c65 7428 7365 6c66 2c20 616c  richlet(self, al
+00006fa0: 7068 612c 2073 697a 653d 4e6f 6e65 2c20  pha, size=None, 
+00006fb0: 6b65 793d 4e6f 6e65 293a 0a20 2020 206b  key=None):.    k
+00006fc0: 6579 203d 2073 656c 662e 7370 6c69 745f  ey = self.split_
+00006fd0: 6b65 7928 2920 6966 206b 6579 2069 7320  key() if key is 
+00006fe0: 4e6f 6e65 2065 6c73 6520 5f66 6f72 6d61  None else _forma
+00006ff0: 6c69 7a65 5f6b 6579 286b 6579 290a 2020  lize_key(key).  
+00007000: 2020 616c 7068 6120 3d20 5f63 6865 636b    alpha = _check
+00007010: 5f70 795f 7365 7128 5f61 735f 6a61 785f  _py_seq(_as_jax_
+00007020: 6172 7261 7928 616c 7068 6129 290a 2020  array(alpha)).  
+00007030: 2020 7220 3d20 6a72 2e64 6972 6963 686c    r = jr.dirichl
+00007040: 6574 286b 6579 2c20 616c 7068 613d 616c  et(key, alpha=al
+00007050: 7068 612c 2073 6861 7065 3d5f 7369 7a65  pha, shape=_size
+00007060: 3273 6861 7065 2873 697a 6529 290a 2020  2shape(size)).  
+00007070: 2020 7265 7475 726e 205f 7265 7475 726e    return _return
+00007080: 2872 290a 0a20 2064 6566 2067 656f 6d65  (r)..  def geome
+00007090: 7472 6963 2873 656c 662c 2070 2c20 7369  tric(self, p, si
+000070a0: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
+000070b0: 6529 3a0a 2020 2020 7020 3d20 5f61 735f  e):.    p = _as_
+000070c0: 6a61 785f 6172 7261 7928 7029 0a20 2020  jax_array(p).   
+000070d0: 2070 203d 205f 6368 6563 6b5f 7079 5f73   p = _check_py_s
+000070e0: 6571 2870 290a 2020 2020 6966 2073 697a  eq(p).    if siz
+000070f0: 6520 6973 204e 6f6e 653a 0a20 2020 2020  e is None:.     
+00007100: 2073 697a 6520 3d20 6a6e 702e 7368 6170   size = jnp.shap
+00007110: 6528 7029 0a20 2020 206b 6579 203d 2073  e(p).    key = s
+00007120: 656c 662e 7370 6c69 745f 6b65 7928 2920  elf.split_key() 
+00007130: 6966 206b 6579 2069 7320 4e6f 6e65 2065  if key is None e
+00007140: 6c73 6520 5f66 6f72 6d61 6c69 7a65 5f6b  lse _formalize_k
+00007150: 6579 286b 6579 290a 2020 2020 7520 3d20  ey(key).    u = 
+00007160: 6a72 2e75 6e69 666f 726d 286b 6579 2c20  jr.uniform(key, 
+00007170: 7369 7a65 290a 2020 2020 7220 3d20 6a6e  size).    r = jn
+00007180: 702e 666c 6f6f 7228 6a6e 702e 6c6f 6731  p.floor(jnp.log1
+00007190: 7028 2d75 2920 2f20 6a6e 702e 6c6f 6731  p(-u) / jnp.log1
+000071a0: 7028 2d70 2929 0a20 2020 2072 6574 7572  p(-p)).    retur
+000071b0: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
+000071c0: 6465 6620 5f63 6865 636b 5f70 3228 7365  def _check_p2(se
+000071d0: 6c66 2c20 7029 3a0a 2020 2020 7261 6973  lf, p):.    rais
+000071e0: 6520 5661 6c75 6545 7272 6f72 2866 2757  e ValueError(f'W
+000071f0: 6520 7265 7175 6972 6520 6073 756d 2870  e require `sum(p
+00007200: 7661 6c73 5b3a 2d31 5d29 203c 3d20 3160  vals[:-1]) <= 1`
+00007210: 2e20 4275 7420 7765 2067 6f74 207b 707d  . But we got {p}
+00007220: 2729 0a0a 2020 6465 6620 6d75 6c74 696e  ')..  def multin
+00007230: 6f6d 6961 6c28 7365 6c66 2c20 6e2c 2070  omial(self, n, p
+00007240: 7661 6c73 2c20 7369 7a65 3d4e 6f6e 652c  vals, size=None,
+00007250: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2020   key=None):.    
+00007260: 6b65 7920 3d20 7365 6c66 2e73 706c 6974  key = self.split
+00007270: 5f6b 6579 2829 2069 6620 6b65 7920 6973  _key() if key is
+00007280: 204e 6f6e 6520 656c 7365 205f 666f 726d   None else _form
+00007290: 616c 697a 655f 6b65 7928 6b65 7929 0a20  alize_key(key). 
+000072a0: 2020 206e 203d 205f 6368 6563 6b5f 7079     n = _check_py
+000072b0: 5f73 6571 285f 6173 5f6a 6178 5f61 7272  _seq(_as_jax_arr
+000072c0: 6179 286e 2929 0a20 2020 2070 7661 6c73  ay(n)).    pvals
+000072d0: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+000072e0: 285f 6173 5f6a 6178 5f61 7272 6179 2870  (_as_jax_array(p
+000072f0: 7661 6c73 2929 0a20 2020 206a 6974 5f65  vals)).    jit_e
+00007300: 7272 6f72 286a 6e70 2e73 756d 2870 7661  rror(jnp.sum(pva
+00007310: 6c73 5b3a 2d31 5d29 203e 2031 2e2c 2073  ls[:-1]) > 1., s
+00007320: 656c 662e 5f63 6865 636b 5f70 322c 2070  elf._check_p2, p
+00007330: 7661 6c73 290a 2020 2020 6966 2069 7369  vals).    if isi
+00007340: 6e73 7461 6e63 6528 6e2c 206a 6178 2e63  nstance(n, jax.c
+00007350: 6f72 652e 5472 6163 6572 293a 0a20 2020  ore.Tracer):.   
+00007360: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+00007370: 726f 7228 2254 6865 2074 6f74 616c 2063  ror("The total c
+00007380: 6f75 6e74 2070 6172 616d 6574 6572 2060  ount parameter `
+00007390: 6e60 2073 686f 756c 6420 6e6f 7420 6265  n` should not be
+000073a0: 2061 206a 6178 2061 6273 7472 6163 7420   a jax abstract 
+000073b0: 6172 7261 792e 2229 0a20 2020 2073 697a  array.").    siz
+000073c0: 6520 3d20 5f73 697a 6532 7368 6170 6528  e = _size2shape(
+000073d0: 7369 7a65 290a 2020 2020 6e5f 6d61 7820  size).    n_max 
+000073e0: 3d20 696e 7428 6e70 2e6d 6178 286a 6178  = int(np.max(jax
+000073f0: 2e64 6576 6963 655f 6765 7428 6e29 2929  .device_get(n)))
+00007400: 0a20 2020 2062 6174 6368 5f73 6861 7065  .    batch_shape
+00007410: 203d 206c 6178 2e62 726f 6164 6361 7374   = lax.broadcast
+00007420: 5f73 6861 7065 7328 6a6e 702e 7368 6170  _shapes(jnp.shap
+00007430: 6528 7076 616c 7329 5b3a 2d31 5d2c 206a  e(pvals)[:-1], j
+00007440: 6e70 2e73 6861 7065 286e 2929 0a20 2020  np.shape(n)).   
+00007450: 2072 203d 205f 6d75 6c74 696e 6f6d 6961   r = _multinomia
+00007460: 6c28 6b65 792c 2070 7661 6c73 2c20 6e2c  l(key, pvals, n,
+00007470: 206e 5f6d 6178 2c20 6261 7463 685f 7368   n_max, batch_sh
+00007480: 6170 6520 2b20 7369 7a65 290a 2020 2020  ape + size).    
+00007490: 7265 7475 726e 205f 7265 7475 726e 2872  return _return(r
+000074a0: 290a 0a20 2064 6566 206d 756c 7469 7661  )..  def multiva
+000074b0: 7269 6174 655f 6e6f 726d 616c 2873 656c  riate_normal(sel
+000074c0: 662c 206d 6561 6e2c 2063 6f76 2c20 7369  f, mean, cov, si
+000074d0: 7a65 3d4e 6f6e 652c 206d 6574 686f 643a  ze=None, method:
+000074e0: 2073 7472 203d 2027 6368 6f6c 6573 6b79   str = 'cholesky
+000074f0: 272c 206b 6579 3d4e 6f6e 6529 3a0a 2020  ', key=None):.  
+00007500: 2020 6966 206d 6574 686f 6420 6e6f 7420    if method not 
+00007510: 696e 207b 2773 7664 272c 2027 6569 6768  in {'svd', 'eigh
+00007520: 272c 2027 6368 6f6c 6573 6b79 277d 3a0a  ', 'cholesky'}:.
+00007530: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+00007540: 6545 7272 6f72 2822 6d65 7468 6f64 206d  eError("method m
+00007550: 7573 7420 6265 206f 6e65 206f 6620 7b27  ust be one of {'
+00007560: 7376 6427 2c20 2765 6967 6827 2c20 2763  svd', 'eigh', 'c
+00007570: 686f 6c65 736b 7927 7d22 290a 2020 2020  holesky'}").    
+00007580: 6d65 616e 203d 205f 6368 6563 6b5f 7079  mean = _check_py
+00007590: 5f73 6571 285f 6173 5f6a 6178 5f61 7272  _seq(_as_jax_arr
+000075a0: 6179 286d 6561 6e29 290a 2020 2020 636f  ay(mean)).    co
+000075b0: 7620 3d20 5f63 6865 636b 5f70 795f 7365  v = _check_py_se
+000075c0: 7128 5f61 735f 6a61 785f 6172 7261 7928  q(_as_jax_array(
+000075d0: 636f 7629 290a 2020 2020 6b65 7920 3d20  cov)).    key = 
+000075e0: 7365 6c66 2e73 706c 6974 5f6b 6579 2829  self.split_key()
+000075f0: 2069 6620 6b65 7920 6973 204e 6f6e 6520   if key is None 
+00007600: 656c 7365 205f 666f 726d 616c 697a 655f  else _formalize_
+00007610: 6b65 7928 6b65 7929 0a0a 2020 2020 6966  key(key)..    if
+00007620: 206e 6f74 206a 6e70 2e6e 6469 6d28 6d65   not jnp.ndim(me
+00007630: 616e 2920 3e3d 2031 3a0a 2020 2020 2020  an) >= 1:.      
+00007640: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+00007650: 2866 226d 756c 7469 7661 7269 6174 655f  (f"multivariate_
+00007660: 6e6f 726d 616c 2072 6571 7569 7265 7320  normal requires 
+00007670: 6d65 616e 2e6e 6469 6d20 3e3d 2031 2c20  mean.ndim >= 1, 
+00007680: 676f 7420 6d65 616e 2e6e 6469 6d20 3d3d  got mean.ndim ==
+00007690: 207b 6a6e 702e 6e64 696d 286d 6561 6e29   {jnp.ndim(mean)
+000076a0: 7d22 290a 2020 2020 6966 206e 6f74 206a  }").    if not j
+000076b0: 6e70 2e6e 6469 6d28 636f 7629 203e 3d20  np.ndim(cov) >= 
+000076c0: 323a 0a20 2020 2020 2072 6169 7365 2056  2:.      raise V
+000076d0: 616c 7565 4572 726f 7228 6622 6d75 6c74  alueError(f"mult
+000076e0: 6976 6172 6961 7465 5f6e 6f72 6d61 6c20  ivariate_normal 
+000076f0: 7265 7175 6972 6573 2063 6f76 2e6e 6469  requires cov.ndi
+00007700: 6d20 3e3d 2032 2c20 676f 7420 636f 762e  m >= 2, got cov.
+00007710: 6e64 696d 203d 3d20 7b6a 6e70 2e6e 6469  ndim == {jnp.ndi
+00007720: 6d28 636f 7629 7d22 290a 2020 2020 6e20  m(cov)}").    n 
+00007730: 3d20 6d65 616e 2e73 6861 7065 5b2d 315d  = mean.shape[-1]
+00007740: 0a20 2020 2069 6620 6a6e 702e 7368 6170  .    if jnp.shap
+00007750: 6528 636f 7629 5b2d 323a 5d20 213d 2028  e(cov)[-2:] != (
+00007760: 6e2c 206e 293a 0a20 2020 2020 2072 6169  n, n):.      rai
+00007770: 7365 2056 616c 7565 4572 726f 7228 6622  se ValueError(f"
+00007780: 6d75 6c74 6976 6172 6961 7465 5f6e 6f72  multivariate_nor
+00007790: 6d61 6c20 7265 7175 6972 6573 2063 6f76  mal requires cov
+000077a0: 2e73 6861 7065 203d 3d20 282e 2e2e 2c20  .shape == (..., 
+000077b0: 6e2c 206e 2920 666f 7220 6e3d 7b6e 7d2c  n, n) for n={n},
+000077c0: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
+000077d0: 2020 2020 2020 2020 2020 6622 6275 7420            f"but 
+000077e0: 676f 7420 636f 762e 7368 6170 6520 3d3d  got cov.shape ==
+000077f0: 207b 6a6e 702e 7368 6170 6528 636f 7629   {jnp.shape(cov)
+00007800: 7d2e 2229 0a20 2020 2069 6620 7369 7a65  }.").    if size
+00007810: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00007820: 7369 7a65 203d 206c 6178 2e62 726f 6164  size = lax.broad
+00007830: 6361 7374 5f73 6861 7065 7328 6d65 616e  cast_shapes(mean
+00007840: 2e73 6861 7065 5b3a 2d31 5d2c 2063 6f76  .shape[:-1], cov
+00007850: 2e73 6861 7065 5b3a 2d32 5d29 0a20 2020  .shape[:-2]).   
+00007860: 2065 6c73 653a 0a20 2020 2020 2073 697a   else:.      siz
+00007870: 6520 3d20 5f73 697a 6532 7368 6170 6528  e = _size2shape(
+00007880: 7369 7a65 290a 2020 2020 2020 5f63 6865  size).      _che
+00007890: 636b 5f73 6861 7065 2822 6e6f 726d 616c  ck_shape("normal
+000078a0: 222c 2073 697a 652c 206d 6561 6e2e 7368  ", size, mean.sh
+000078b0: 6170 655b 3a2d 315d 2c20 636f 762e 7368  ape[:-1], cov.sh
+000078c0: 6170 655b 3a2d 325d 290a 0a20 2020 2069  ape[:-2])..    i
+000078d0: 6620 6d65 7468 6f64 203d 3d20 2773 7664  f method == 'svd
+000078e0: 273a 0a20 2020 2020 2028 752c 2073 2c20  ':.      (u, s, 
+000078f0: 5f29 203d 206a 6e70 2e6c 696e 616c 672e  _) = jnp.linalg.
+00007900: 7376 6428 636f 7629 0a20 2020 2020 2066  svd(cov).      f
+00007910: 6163 746f 7220 3d20 7520 2a20 6a6e 702e  actor = u * jnp.
+00007920: 7371 7274 2873 5b2e 2e2e 2c20 4e6f 6e65  sqrt(s[..., None
+00007930: 2c20 3a5d 290a 2020 2020 656c 6966 206d  , :]).    elif m
+00007940: 6574 686f 6420 3d3d 2027 6569 6768 273a  ethod == 'eigh':
+00007950: 0a20 2020 2020 2028 772c 2076 2920 3d20  .      (w, v) = 
+00007960: 6a6e 702e 6c69 6e61 6c67 2e65 6967 6828  jnp.linalg.eigh(
+00007970: 636f 7629 0a20 2020 2020 2066 6163 746f  cov).      facto
+00007980: 7220 3d20 7620 2a20 6a6e 702e 7371 7274  r = v * jnp.sqrt
+00007990: 2877 5b2e 2e2e 2c20 4e6f 6e65 2c20 3a5d  (w[..., None, :]
+000079a0: 290a 2020 2020 656c 7365 3a20 2023 2027  ).    else:  # '
+000079b0: 6368 6f6c 6573 6b79 270a 2020 2020 2020  cholesky'.      
+000079c0: 6661 6374 6f72 203d 206a 6e70 2e6c 696e  factor = jnp.lin
+000079d0: 616c 672e 6368 6f6c 6573 6b79 2863 6f76  alg.cholesky(cov
+000079e0: 290a 2020 2020 6e6f 726d 616c 5f73 616d  ).    normal_sam
+000079f0: 706c 6573 203d 206a 722e 6e6f 726d 616c  ples = jr.normal
+00007a00: 286b 6579 2c20 7369 7a65 202b 206d 6561  (key, size + mea
+00007a10: 6e2e 7368 6170 655b 2d31 3a5d 290a 2020  n.shape[-1:]).  
+00007a20: 2020 7220 3d20 6d65 616e 202b 206a 6e70    r = mean + jnp
+00007a30: 2e65 696e 7375 6d28 272e 2e2e 696a 2c2e  .einsum('...ij,.
+00007a40: 2e2e 6a2d 3e2e 2e2e 6927 2c20 6661 6374  ..j->...i', fact
+00007a50: 6f72 2c20 6e6f 726d 616c 5f73 616d 706c  or, normal_sampl
+00007a60: 6573 290a 2020 2020 7265 7475 726e 205f  es).    return _
+00007a70: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
+00007a80: 2072 6179 6c65 6967 6828 7365 6c66 2c20   rayleigh(self, 
+00007a90: 7363 616c 653d 312e 302c 2073 697a 653d  scale=1.0, size=
+00007aa0: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
+00007ab0: 0a20 2020 2073 6361 6c65 203d 205f 6368  .    scale = _ch
+00007ac0: 6563 6b5f 7079 5f73 6571 285f 6173 5f6a  eck_py_seq(_as_j
+00007ad0: 6178 5f61 7272 6179 2873 6361 6c65 2929  ax_array(scale))
+00007ae0: 0a20 2020 2069 6620 7369 7a65 2069 7320  .    if size is 
+00007af0: 4e6f 6e65 3a0a 2020 2020 2020 7369 7a65  None:.      size
+00007b00: 203d 206a 6e70 2e73 6861 7065 2873 6361   = jnp.shape(sca
+00007b10: 6c65 290a 2020 2020 6b65 7920 3d20 7365  le).    key = se
+00007b20: 6c66 2e73 706c 6974 5f6b 6579 2829 2069  lf.split_key() i
+00007b30: 6620 6b65 7920 6973 204e 6f6e 6520 656c  f key is None el
+00007b40: 7365 205f 666f 726d 616c 697a 655f 6b65  se _formalize_ke
+00007b50: 7928 6b65 7929 0a20 2020 2078 203d 206a  y(key).    x = j
+00007b60: 6e70 2e73 7172 7428 2d32 2e20 2a20 6a6e  np.sqrt(-2. * jn
+00007b70: 702e 6c6f 6728 6a72 2e75 6e69 666f 726d  p.log(jr.uniform
+00007b80: 286b 6579 2c20 7368 6170 653d 5f73 697a  (key, shape=_siz
+00007b90: 6532 7368 6170 6528 7369 7a65 292c 206d  e2shape(size), m
+00007ba0: 696e 7661 6c3d 302c 206d 6178 7661 6c3d  inval=0, maxval=
+00007bb0: 3129 2929 0a20 2020 2072 203d 2078 202a  1))).    r = x *
+00007bc0: 2073 6361 6c65 0a20 2020 2072 6574 7572   scale.    retur
+00007bd0: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
+00007be0: 6465 6620 7472 6961 6e67 756c 6172 2873  def triangular(s
+00007bf0: 656c 662c 2073 697a 653d 4e6f 6e65 2c20  elf, size=None, 
+00007c00: 6b65 793d 4e6f 6e65 293a 0a20 2020 206b  key=None):.    k
+00007c10: 6579 203d 2073 656c 662e 7370 6c69 745f  ey = self.split_
+00007c20: 6b65 7928 2920 6966 206b 6579 2069 7320  key() if key is 
+00007c30: 4e6f 6e65 2065 6c73 6520 5f66 6f72 6d61  None else _forma
+00007c40: 6c69 7a65 5f6b 6579 286b 6579 290a 2020  lize_key(key).  
+00007c50: 2020 6265 726e 6f75 6c6c 695f 7361 6d70    bernoulli_samp
+00007c60: 6c65 7320 3d20 6a72 2e62 6572 6e6f 756c  les = jr.bernoul
+00007c70: 6c69 286b 6579 2c20 703d 302e 352c 2073  li(key, p=0.5, s
+00007c80: 6861 7065 3d5f 7369 7a65 3273 6861 7065  hape=_size2shape
+00007c90: 2873 697a 6529 290a 2020 2020 7220 3d20  (size)).    r = 
+00007ca0: 3220 2a20 6265 726e 6f75 6c6c 695f 7361  2 * bernoulli_sa
+00007cb0: 6d70 6c65 7320 2d20 310a 2020 2020 7265  mples - 1.    re
+00007cc0: 7475 726e 205f 7265 7475 726e 2872 290a  turn _return(r).
+00007cd0: 0a20 2064 6566 2076 6f6e 6d69 7365 7328  .  def vonmises(
+00007ce0: 7365 6c66 2c20 6d75 2c20 6b61 7070 612c  self, mu, kappa,
+00007cf0: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
+00007d00: 4e6f 6e65 293a 0a20 2020 206b 6579 203d  None):.    key =
+00007d10: 2073 656c 662e 7370 6c69 745f 6b65 7928   self.split_key(
+00007d20: 2920 6966 206b 6579 2069 7320 4e6f 6e65  ) if key is None
+00007d30: 2065 6c73 6520 5f66 6f72 6d61 6c69 7a65   else _formalize
+00007d40: 5f6b 6579 286b 6579 290a 2020 2020 6d75  _key(key).    mu
+00007d50: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+00007d60: 285f 6173 5f6a 6178 5f61 7272 6179 286d  (_as_jax_array(m
+00007d70: 7529 290a 2020 2020 6b61 7070 6120 3d20  u)).    kappa = 
+00007d80: 5f63 6865 636b 5f70 795f 7365 7128 5f61  _check_py_seq(_a
+00007d90: 735f 6a61 785f 6172 7261 7928 6b61 7070  s_jax_array(kapp
+00007da0: 6129 290a 2020 2020 6966 2073 697a 6520  a)).    if size 
+00007db0: 6973 204e 6f6e 653a 0a20 2020 2020 2073  is None:.      s
+00007dc0: 697a 6520 3d20 6c61 782e 6272 6f61 6463  ize = lax.broadc
+00007dd0: 6173 745f 7368 6170 6573 286a 6e70 2e73  ast_shapes(jnp.s
+00007de0: 6861 7065 286d 7529 2c20 6a6e 702e 7368  hape(mu), jnp.sh
+00007df0: 6170 6528 6b61 7070 6129 290a 2020 2020  ape(kappa)).    
+00007e00: 7369 7a65 203d 205f 7369 7a65 3273 6861  size = _size2sha
+00007e10: 7065 2873 697a 6529 0a20 2020 2073 616d  pe(size).    sam
+00007e20: 706c 6573 203d 205f 766f 6e5f 6d69 7365  ples = _von_mise
+00007e30: 735f 6365 6e74 6572 6564 286b 6579 2c20  s_centered(key, 
+00007e40: 6b61 7070 612c 2073 697a 6529 0a20 2020  kappa, size).   
+00007e50: 2073 616d 706c 6573 203d 2073 616d 706c   samples = sampl
+00007e60: 6573 202b 206d 750a 2020 2020 7361 6d70  es + mu.    samp
+00007e70: 6c65 7320 3d20 2873 616d 706c 6573 202b  les = (samples +
+00007e80: 206a 6e70 2e70 6929 2025 2028 322e 3020   jnp.pi) % (2.0 
+00007e90: 2a20 6a6e 702e 7069 2920 2d20 6a6e 702e  * jnp.pi) - jnp.
+00007ea0: 7069 0a20 2020 2072 6574 7572 6e20 5f72  pi.    return _r
+00007eb0: 6574 7572 6e28 7361 6d70 6c65 7329 0a0a  eturn(samples)..
+00007ec0: 2020 6465 6620 7765 6962 756c 6c28 7365    def weibull(se
+00007ed0: 6c66 2c20 612c 2073 697a 653d 4e6f 6e65  lf, a, size=None
+00007ee0: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2020  , key=None):.   
+00007ef0: 206b 6579 203d 2073 656c 662e 7370 6c69   key = self.spli
+00007f00: 745f 6b65 7928 2920 6966 206b 6579 2069  t_key() if key i
+00007f10: 7320 4e6f 6e65 2065 6c73 6520 5f66 6f72  s None else _for
+00007f20: 6d61 6c69 7a65 5f6b 6579 286b 6579 290a  malize_key(key).
+00007f30: 2020 2020 6120 3d20 5f63 6865 636b 5f70      a = _check_p
+00007f40: 795f 7365 7128 5f61 735f 6a61 785f 6172  y_seq(_as_jax_ar
+00007f50: 7261 7928 6129 290a 2020 2020 6966 2073  ray(a)).    if s
+00007f60: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
+00007f70: 2020 2073 697a 6520 3d20 6a6e 702e 7368     size = jnp.sh
+00007f80: 6170 6528 6129 0a20 2020 2065 6c73 653a  ape(a).    else:
+00007f90: 0a20 2020 2020 2069 6620 6a6e 702e 7369  .      if jnp.si
+00007fa0: 7a65 2861 2920 3e20 313a 0a20 2020 2020  ze(a) > 1:.     
+00007fb0: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+00007fc0: 726f 7228 6627 2261 2220 7368 6f75 6c64  ror(f'"a" should
+00007fd0: 2062 6520 6120 7363 616c 6172 2077 6865   be a scalar whe
+00007fe0: 6e20 2273 697a 6522 2069 7320 7072 6f76  n "size" is prov
+00007ff0: 6964 6564 2e20 4275 7420 7765 2067 6f74  ided. But we got
+00008000: 207b 617d 2729 0a20 2020 2073 697a 6520   {a}').    size 
+00008010: 3d20 5f73 697a 6532 7368 6170 6528 7369  = _size2shape(si
+00008020: 7a65 290a 2020 2020 7261 6e64 6f6d 5f75  ze).    random_u
+00008030: 6e69 666f 726d 203d 206a 722e 756e 6966  niform = jr.unif
+00008040: 6f72 6d28 6b65 793d 6b65 792c 2073 6861  orm(key=key, sha
+00008050: 7065 3d73 697a 652c 206d 696e 7661 6c3d  pe=size, minval=
+00008060: 302c 206d 6178 7661 6c3d 3129 0a20 2020  0, maxval=1).   
+00008070: 2072 203d 206a 6e70 2e70 6f77 6572 282d   r = jnp.power(-
+00008080: 6a6e 702e 6c6f 6731 7028 2d72 616e 646f  jnp.log1p(-rando
+00008090: 6d5f 756e 6966 6f72 6d29 2c20 312e 3020  m_uniform), 1.0 
+000080a0: 2f20 6129 0a20 2020 2072 6574 7572 6e20  / a).    return 
+000080b0: 5f72 6574 7572 6e28 7229 0a0a 2020 6465  _return(r)..  de
+000080c0: 6620 7765 6962 756c 6c5f 6d69 6e28 7365  f weibull_min(se
+000080d0: 6c66 2c20 612c 2073 6361 6c65 3d4e 6f6e  lf, a, scale=Non
+000080e0: 652c 2073 697a 653d 4e6f 6e65 2c20 6b65  e, size=None, ke
+000080f0: 793d 4e6f 6e65 293a 0a20 2020 2022 2222  y=None):.    """
+00008100: 5361 6d70 6c65 2066 726f 6d20 6120 5765  Sample from a We
+00008110: 6962 756c 6c20 6d69 6e69 6d75 6d20 6469  ibull minimum di
+00008120: 7374 7269 6275 7469 6f6e 2e0a 0a20 2020  stribution...   
+00008130: 2050 6172 616d 6574 6572 730a 2020 2020   Parameters.    
+00008140: 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020 2061  ----------.    a
+00008150: 3a20 666c 6f61 742c 2061 7272 6179 5f6c  : float, array_l
+00008160: 696b 650a 2020 2020 2020 5468 6520 636f  ike.      The co
+00008170: 6e63 656e 7472 6174 696f 6e20 7061 7261  ncentration para
+00008180: 6d65 7465 7220 6f66 2074 6865 2064 6973  meter of the dis
+00008190: 7472 6962 7574 696f 6e2e 0a20 2020 2073  tribution..    s
+000081a0: 6361 6c65 3a20 666c 6f61 742c 2061 7272  cale: float, arr
+000081b0: 6179 5f6c 696b 650a 2020 2020 2020 5468  ay_like.      Th
+000081c0: 6520 7363 616c 6520 7061 7261 6d65 7465  e scale paramete
+000081d0: 7220 6f66 2074 6865 2064 6973 7472 6962  r of the distrib
+000081e0: 7574 696f 6e2e 0a20 2020 2073 697a 653a  ution..    size:
+000081f0: 206f 7074 696f 6e61 6c2c 2069 6e74 2c20   optional, int, 
+00008200: 7475 706c 6520 6f66 2069 6e74 0a20 2020  tuple of int.   
+00008210: 2020 2054 6865 2073 6861 7065 2061 6464     The shape add
+00008220: 6564 2074 6f20 7468 6520 7061 7261 6d65  ed to the parame
+00008230: 7465 7273 206c 6f63 2061 6e64 2073 6361  ters loc and sca
+00008240: 6c65 2062 726f 6164 6361 7374 6162 6c65  le broadcastable
+00008250: 2073 6861 7065 2e0a 0a20 2020 2052 6574   shape...    Ret
+00008260: 7572 6e73 0a20 2020 202d 2d2d 2d2d 2d2d  urns.    -------
+00008270: 0a20 2020 206f 7574 3a20 6172 7261 795f  .    out: array_
+00008280: 6c69 6b65 0a20 2020 2020 2054 6865 2073  like.      The s
+00008290: 616d 706c 696e 6720 7265 7375 6c74 732e  ampling results.
+000082a0: 0a20 2020 2022 2222 0a20 2020 206b 6579  .    """.    key
+000082b0: 203d 2073 656c 662e 7370 6c69 745f 6b65   = self.split_ke
+000082c0: 7928 2920 6966 206b 6579 2069 7320 4e6f  y() if key is No
+000082d0: 6e65 2065 6c73 6520 5f66 6f72 6d61 6c69  ne else _formali
+000082e0: 7a65 5f6b 6579 286b 6579 290a 2020 2020  ze_key(key).    
+000082f0: 6120 3d20 5f63 6865 636b 5f70 795f 7365  a = _check_py_se
+00008300: 7128 5f61 735f 6a61 785f 6172 7261 7928  q(_as_jax_array(
+00008310: 6129 290a 2020 2020 7363 616c 6520 3d20  a)).    scale = 
+00008320: 5f63 6865 636b 5f70 795f 7365 7128 5f61  _check_py_seq(_a
+00008330: 735f 6a61 785f 6172 7261 7928 7363 616c  s_jax_array(scal
+00008340: 6529 290a 2020 2020 6966 2073 697a 6520  e)).    if size 
+00008350: 6973 204e 6f6e 653a 0a20 2020 2020 2073  is None:.      s
+00008360: 697a 6520 3d20 6a6e 702e 6272 6f61 6463  ize = jnp.broadc
+00008370: 6173 745f 7368 6170 6573 286a 6e70 2e73  ast_shapes(jnp.s
+00008380: 6861 7065 2861 292c 206a 6e70 2e73 6861  hape(a), jnp.sha
+00008390: 7065 2873 6361 6c65 2929 0a20 2020 2065  pe(scale)).    e
+000083a0: 6c73 653a 0a20 2020 2020 2069 6620 6a6e  lse:.      if jn
+000083b0: 702e 7369 7a65 2861 2920 3e20 313a 0a20  p.size(a) > 1:. 
+000083c0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+000083d0: 7565 4572 726f 7228 6627 2261 2220 7368  ueError(f'"a" sh
+000083e0: 6f75 6c64 2062 6520 6120 7363 616c 6172  ould be a scalar
+000083f0: 2077 6865 6e20 2273 697a 6522 2069 7320   when "size" is 
+00008400: 7072 6f76 6964 6564 2e20 4275 7420 7765  provided. But we
+00008410: 2067 6f74 207b 617d 2729 0a20 2020 2073   got {a}').    s
+00008420: 697a 6520 3d20 5f73 697a 6532 7368 6170  ize = _size2shap
+00008430: 6528 7369 7a65 290a 2020 2020 7261 6e64  e(size).    rand
+00008440: 6f6d 5f75 6e69 666f 726d 203d 206a 722e  om_uniform = jr.
+00008450: 756e 6966 6f72 6d28 6b65 793d 6b65 792c  uniform(key=key,
+00008460: 2073 6861 7065 3d73 697a 652c 206d 696e   shape=size, min
+00008470: 7661 6c3d 302c 206d 6178 7661 6c3d 3129  val=0, maxval=1)
+00008480: 0a20 2020 2072 203d 206a 6e70 2e70 6f77  .    r = jnp.pow
+00008490: 6572 282d 6a6e 702e 6c6f 6731 7028 2d72  er(-jnp.log1p(-r
+000084a0: 616e 646f 6d5f 756e 6966 6f72 6d29 2c20  andom_uniform), 
+000084b0: 312e 3020 2f20 6129 0a20 2020 2069 6620  1.0 / a).    if 
+000084c0: 7363 616c 6520 6973 206e 6f74 204e 6f6e  scale is not Non
+000084d0: 653a 0a20 2020 2020 2072 202f 3d20 7363  e:.      r /= sc
+000084e0: 616c 650a 2020 2020 7265 7475 726e 205f  ale.    return _
+000084f0: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
+00008500: 206d 6178 7765 6c6c 2873 656c 662c 2073   maxwell(self, s
+00008510: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+00008520: 6e65 293a 0a20 2020 206b 6579 203d 2073  ne):.    key = s
+00008530: 656c 662e 7370 6c69 745f 6b65 7928 2920  elf.split_key() 
+00008540: 6966 206b 6579 2069 7320 4e6f 6e65 2065  if key is None e
+00008550: 6c73 6520 5f66 6f72 6d61 6c69 7a65 5f6b  lse _formalize_k
+00008560: 6579 286b 6579 290a 2020 2020 7368 6170  ey(key).    shap
+00008570: 6520 3d20 636f 7265 2e63 616e 6f6e 6963  e = core.canonic
+00008580: 616c 697a 655f 7368 6170 6528 5f73 697a  alize_shape(_siz
+00008590: 6532 7368 6170 6528 7369 7a65 2929 202b  e2shape(size)) +
+000085a0: 2028 332c 290a 2020 2020 6e6f 726d 5f72   (3,).    norm_r
+000085b0: 7673 203d 206a 722e 6e6f 726d 616c 286b  vs = jr.normal(k
+000085c0: 6579 3d6b 6579 2c20 7368 6170 653d 7368  ey=key, shape=sh
+000085d0: 6170 6529 0a20 2020 2072 203d 206a 6e70  ape).    r = jnp
+000085e0: 2e6c 696e 616c 672e 6e6f 726d 286e 6f72  .linalg.norm(nor
+000085f0: 6d5f 7276 732c 2061 7869 733d 2d31 290a  m_rvs, axis=-1).
+00008600: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
+00008610: 726e 2872 290a 0a20 2064 6566 206e 6567  rn(r)..  def neg
+00008620: 6174 6976 655f 6269 6e6f 6d69 616c 2873  ative_binomial(s
+00008630: 656c 662c 206e 2c20 702c 2073 697a 653d  elf, n, p, size=
+00008640: 4e6f 6e65 2c20 6b65 793d 4e6f 6e65 293a  None, key=None):
+00008650: 0a20 2020 206e 203d 205f 6368 6563 6b5f  .    n = _check_
+00008660: 7079 5f73 6571 285f 6173 5f6a 6178 5f61  py_seq(_as_jax_a
+00008670: 7272 6179 286e 2929 0a20 2020 2070 203d  rray(n)).    p =
+00008680: 205f 6368 6563 6b5f 7079 5f73 6571 285f   _check_py_seq(_
+00008690: 6173 5f6a 6178 5f61 7272 6179 2870 2929  as_jax_array(p))
+000086a0: 0a20 2020 2069 6620 7369 7a65 2069 7320  .    if size is 
+000086b0: 4e6f 6e65 3a0a 2020 2020 2020 7369 7a65  None:.      size
+000086c0: 203d 206c 6178 2e62 726f 6164 6361 7374   = lax.broadcast
+000086d0: 5f73 6861 7065 7328 6a6e 702e 7368 6170  _shapes(jnp.shap
+000086e0: 6528 6e29 2c20 6a6e 702e 7368 6170 6528  e(n), jnp.shape(
+000086f0: 7029 290a 2020 2020 7369 7a65 203d 205f  p)).    size = _
+00008700: 7369 7a65 3273 6861 7065 2873 697a 6529  size2shape(size)
+00008710: 0a20 2020 206c 6f67 6974 7320 3d20 6a6e  .    logits = jn
+00008720: 702e 6c6f 6728 7029 202d 206a 6e70 2e6c  p.log(p) - jnp.l
+00008730: 6f67 3170 282d 7029 0a20 2020 2069 6620  og1p(-p).    if 
+00008740: 6b65 7920 6973 204e 6f6e 653a 0a20 2020  key is None:.   
+00008750: 2020 206b 6579 7320 3d20 7365 6c66 2e73     keys = self.s
+00008760: 706c 6974 5f6b 6579 7328 3229 0a20 2020  plit_keys(2).   
+00008770: 2065 6c73 653a 0a20 2020 2020 206b 6579   else:.      key
+00008780: 7320 3d20 6a72 2e73 706c 6974 285f 666f  s = jr.split(_fo
+00008790: 726d 616c 697a 655f 6b65 7928 6b65 7929  rmalize_key(key)
+000087a0: 2c20 3229 0a20 2020 2072 6174 6520 3d20  , 2).    rate = 
+000087b0: 7365 6c66 2e67 616d 6d61 2873 6861 7065  self.gamma(shape
+000087c0: 3d6e 2c20 7363 616c 653d 6a6e 702e 6578  =n, scale=jnp.ex
+000087d0: 7028 2d6c 6f67 6974 7329 2c20 7369 7a65  p(-logits), size
+000087e0: 3d73 697a 652c 206b 6579 3d6b 6579 735b  =size, key=keys[
+000087f0: 305d 290a 2020 2020 7220 3d20 7365 6c66  0]).    r = self
+00008800: 2e70 6f69 7373 6f6e 286c 616d 3d72 6174  .poisson(lam=rat
+00008810: 652c 206b 6579 3d6b 6579 735b 315d 290a  e, key=keys[1]).
+00008820: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
+00008830: 726e 2872 290a 0a20 2064 6566 2077 616c  rn(r)..  def wal
+00008840: 6428 7365 6c66 2c20 6d65 616e 2c20 7363  d(self, mean, sc
+00008850: 616c 652c 2073 697a 653d 4e6f 6e65 2c20  ale, size=None, 
+00008860: 6b65 793d 4e6f 6e65 293a 0a20 2020 206b  key=None):.    k
+00008870: 6579 203d 2073 656c 662e 7370 6c69 745f  ey = self.split_
+00008880: 6b65 7928 2920 6966 206b 6579 2069 7320  key() if key is 
+00008890: 4e6f 6e65 2065 6c73 6520 5f66 6f72 6d61  None else _forma
+000088a0: 6c69 7a65 5f6b 6579 286b 6579 290a 2020  lize_key(key).  
+000088b0: 2020 6d65 616e 203d 205f 6368 6563 6b5f    mean = _check_
+000088c0: 7079 5f73 6571 285f 6173 5f6a 6178 5f61  py_seq(_as_jax_a
+000088d0: 7272 6179 286d 6561 6e29 290a 2020 2020  rray(mean)).    
+000088e0: 7363 616c 6520 3d20 5f63 6865 636b 5f70  scale = _check_p
+000088f0: 795f 7365 7128 5f61 735f 6a61 785f 6172  y_seq(_as_jax_ar
+00008900: 7261 7928 7363 616c 6529 290a 2020 2020  ray(scale)).    
+00008910: 6966 2073 697a 6520 6973 204e 6f6e 653a  if size is None:
+00008920: 0a20 2020 2020 2073 697a 6520 3d20 6c61  .      size = la
+00008930: 782e 6272 6f61 6463 6173 745f 7368 6170  x.broadcast_shap
+00008940: 6573 286a 6e70 2e73 6861 7065 286d 6561  es(jnp.shape(mea
+00008950: 6e29 2c20 6a6e 702e 7368 6170 6528 7363  n), jnp.shape(sc
+00008960: 616c 6529 290a 2020 2020 7369 7a65 203d  ale)).    size =
+00008970: 205f 7369 7a65 3273 6861 7065 2873 697a   _size2shape(siz
+00008980: 6529 0a20 2020 2073 616d 706c 6564 5f63  e).    sampled_c
+00008990: 6869 3220 3d20 6a6e 702e 7371 7561 7265  hi2 = jnp.square
+000089a0: 285f 6173 5f6a 6178 5f61 7272 6179 2873  (_as_jax_array(s
+000089b0: 656c 662e 7261 6e64 6e28 2a73 697a 6529  elf.randn(*size)
+000089c0: 2929 0a20 2020 2073 616d 706c 6564 5f75  )).    sampled_u
+000089d0: 6e69 666f 726d 203d 205f 6173 5f6a 6178  niform = _as_jax
+000089e0: 5f61 7272 6179 2873 656c 662e 756e 6966  _array(self.unif
+000089f0: 6f72 6d28 7369 7a65 3d73 697a 652c 206b  orm(size=size, k
+00008a00: 6579 3d6b 6579 2929 0a20 2020 2023 2057  ey=key)).    # W
+00008a10: 696b 6970 6564 6961 2064 6566 696e 6573  ikipedia defines
+00008a20: 2061 6e20 696e 7465 726d 6564 6961 7465   an intermediate
+00008a30: 2078 2077 6974 6820 7468 6520 666f 726d   x with the form
+00008a40: 756c 610a 2020 2020 2320 2020 7820 3d20  ula.    #   x = 
+00008a50: 6c6f 6320 2b20 6c6f 6320 2a2a 2032 202a  loc + loc ** 2 *
+00008a60: 2079 202f 2028 3220 2a20 636f 6e63 2920   y / (2 * conc) 
+00008a70: 2d20 6c6f 6320 2f20 2832 202a 2063 6f6e  - loc / (2 * con
+00008a80: 6329 202a 2073 7172 7428 3420 2a20 6c6f  c) * sqrt(4 * lo
+00008a90: 6320 2a20 636f 6e63 202a 2079 202b 206c  c * conc * y + l
+00008aa0: 6f63 202a 2a20 3220 2a20 7920 2a2a 2032  oc ** 2 * y ** 2
+00008ab0: 290a 2020 2020 2320 7768 6572 6520 7920  ).    # where y 
+00008ac0: 7e20 4e28 302c 2031 292a 2a32 2028 7361  ~ N(0, 1)**2 (sa
+00008ad0: 6d70 6c65 645f 6368 6932 2061 626f 7665  mpled_chi2 above
+00008ae0: 2920 616e 6420 636f 6e63 2069 7320 7468  ) and conc is th
+00008af0: 6520 636f 6e63 656e 7472 6174 696f 6e2e  e concentration.
+00008b00: 0a20 2020 2023 204c 6574 2075 7320 7772  .    # Let us wr
+00008b10: 6974 650a 2020 2020 2320 2020 7720 3d20  ite.    #   w = 
+00008b20: 6c6f 6320 2a20 7920 2f20 2832 202a 2063  loc * y / (2 * c
+00008b30: 6f6e 6329 0a20 2020 2023 2054 6865 6e20  onc).    # Then 
+00008b40: 7765 2063 616e 2065 7874 7261 6374 2074  we can extract t
+00008b50: 6865 2063 6f6d 6d6f 6e20 6661 6374 6f72  he common factor
+00008b60: 2069 6e20 7468 6520 6c61 7374 2074 776f   in the last two
+00008b70: 2074 6572 6d73 2074 6f20 6f62 7461 696e   terms to obtain
+00008b80: 0a20 2020 2023 2020 2078 203d 206c 6f63  .    #   x = loc
+00008b90: 202b 206c 6f63 202a 2077 202a 2028 3120   + loc * w * (1 
+00008ba0: 2d20 7371 7274 2832 202f 2077 202b 2031  - sqrt(2 / w + 1
+00008bb0: 2929 0a20 2020 2023 204e 6f77 2077 6520  )).    # Now we 
+00008bc0: 7365 6520 7468 6174 2074 6865 2057 696b  see that the Wik
+00008bd0: 6970 6564 6961 2066 6f72 6d75 6c61 2073  ipedia formula s
+00008be0: 7566 6665 7273 2066 726f 6d20 6361 7461  uffers from cata
+00008bf0: 7374 7270 6869 630a 2020 2020 2320 6361  strphic.    # ca
+00008c00: 6e63 656c 6c61 7469 6f6e 2066 6f72 206c  ncellation for l
+00008c10: 6172 6765 2077 2028 652e 672e 2c20 6966  arge w (e.g., if
+00008c20: 2063 6f6e 6320 3c3c 206c 6f63 292e 0a20   conc << loc).. 
+00008c30: 2020 2023 0a20 2020 2023 2046 6f72 7475     #.    # Fortu
+00008c40: 6e61 7465 6c79 2c20 7765 2063 616e 2066  nately, we can f
+00008c50: 6978 2074 6869 7320 6279 206d 756c 7469  ix this by multi
+00008c60: 706c 7969 6e67 2062 6f74 6820 7369 6465  plying both side
+00008c70: 730a 2020 2020 2320 6279 2031 202b 2073  s.    # by 1 + s
+00008c80: 7172 7428 3220 2f20 7720 2b20 3129 2e20  qrt(2 / w + 1). 
+00008c90: 2057 6520 6765 740a 2020 2020 2320 2020   We get.    #   
+00008ca0: 7820 2a20 2831 202b 2073 7172 7428 3220  x * (1 + sqrt(2 
+00008cb0: 2f20 7720 2b20 3129 2920 3d0a 2020 2020  / w + 1)) =.    
+00008cc0: 2320 2020 2020 3d20 6c6f 6320 2a20 2831  #     = loc * (1
+00008cd0: 202b 2073 7172 7428 3220 2f20 7720 2b20   + sqrt(2 / w + 
+00008ce0: 3129 2920 2b20 6c6f 6320 2a20 7720 2a20  1)) + loc * w * 
+00008cf0: 2831 202d 2028 3220 2f20 7720 2b20 3129  (1 - (2 / w + 1)
+00008d00: 290a 2020 2020 2320 2020 2020 3d20 6c6f  ).    #     = lo
+00008d10: 6320 2a20 2873 7172 7428 3220 2f20 7720  c * (sqrt(2 / w 
+00008d20: 2b20 3129 202d 2031 290a 2020 2020 2320  + 1) - 1).    # 
+00008d30: 5468 6520 7465 726d 2073 7172 7428 3220  The term sqrt(2 
+00008d40: 2f20 7720 2b20 3129 202b 2031 206e 6f20  / w + 1) + 1 no 
+00008d50: 6c6f 6e67 6572 2070 7265 7365 6e74 7320  longer presents 
+00008d60: 6e75 6d65 7269 6361 6c0a 2020 2020 2320  numerical.    # 
+00008d70: 6469 6666 6963 756c 7469 6573 2066 6f72  difficulties for
+00008d80: 206c 6172 6765 2077 2c20 616e 6420 7371   large w, and sq
+00008d90: 7274 2832 202f 2077 202b 2031 2920 2d20  rt(2 / w + 1) - 
+00008da0: 3120 6973 206a 7573 740a 2020 2020 2320  1 is just.    # 
+00008db0: 7371 7274 3170 6d31 2832 202f 2077 292c  sqrt1pm1(2 / w),
+00008dc0: 2077 6869 6368 2077 6520 6b6e 6f77 2068   which we know h
+00008dd0: 6f77 2074 6f20 636f 6d70 7574 6520 6163  ow to compute ac
+00008de0: 6375 7261 7465 6c79 2e0a 2020 2020 2320  curately..    # 
+00008df0: 5468 6973 206a 7573 7420 6c65 6176 6573  This just leaves
+00008e00: 2074 6865 206d 6174 7465 7220 6f66 2073   the matter of s
+00008e10: 6d61 6c6c 2077 2c20 7768 6572 6520 3220  mall w, where 2 
+00008e20: 2f20 7720 6d61 790a 2020 2020 2320 6f76  / w may.    # ov
+00008e30: 6572 666c 6f77 2e20 2049 6e20 7468 6520  erflow.  In the 
+00008e40: 6c69 6d69 7420 6120 7720 2d3e 2030 2c20  limit a w -> 0, 
+00008e50: 7820 2d3e 206c 6f63 2c20 736f 2077 6520  x -> loc, so we 
+00008e60: 6a75 7374 206d 6173 6b0a 2020 2020 2320  just mask.    # 
+00008e70: 7468 6174 2063 6173 652e 0a20 2020 2073  that case..    s
+00008e80: 7172 7431 706d 315f 6172 6720 3d20 3420  qrt1pm1_arg = 4 
+00008e90: 2a20 7363 616c 6520 2f20 286d 6561 6e20  * scale / (mean 
+00008ea0: 2a20 7361 6d70 6c65 645f 6368 6932 2920  * sampled_chi2) 
+00008eb0: 2023 2032 202f 2077 2061 626f 7665 0a20   # 2 / w above. 
+00008ec0: 2020 2073 6166 655f 7371 7274 3170 6d31     safe_sqrt1pm1
+00008ed0: 5f61 7267 203d 206a 6e70 2e77 6865 7265  _arg = jnp.where
+00008ee0: 2873 7172 7431 706d 315f 6172 6720 3c20  (sqrt1pm1_arg < 
+00008ef0: 6e70 2e69 6e66 2c20 7371 7274 3170 6d31  np.inf, sqrt1pm1
+00008f00: 5f61 7267 2c20 312e 3029 0a20 2020 2064  _arg, 1.0).    d
+00008f10: 656e 6f6d 696e 6174 6f72 203d 2031 2e30  enominator = 1.0
+00008f20: 202b 206a 6e70 2e73 7172 7428 7361 6665   + jnp.sqrt(safe
+00008f30: 5f73 7172 7431 706d 315f 6172 6720 2b20  _sqrt1pm1_arg + 
+00008f40: 312e 3029 0a20 2020 2072 6174 696f 203d  1.0).    ratio =
+00008f50: 206a 6e70 2e65 7870 6d31 2830 2e35 202a   jnp.expm1(0.5 *
+00008f60: 206a 6e70 2e6c 6f67 3170 2873 6166 655f   jnp.log1p(safe_
+00008f70: 7371 7274 3170 6d31 5f61 7267 2929 202f  sqrt1pm1_arg)) /
+00008f80: 2064 656e 6f6d 696e 6174 6f72 0a20 2020   denominator.   
+00008f90: 2073 616d 706c 6564 203d 206d 6561 6e20   sampled = mean 
+00008fa0: 2a20 6a6e 702e 7768 6572 6528 7371 7274  * jnp.where(sqrt
+00008fb0: 3170 6d31 5f61 7267 203c 206e 702e 696e  1pm1_arg < np.in
+00008fc0: 662c 2072 6174 696f 2c20 312e 3029 2020  f, ratio, 1.0)  
+00008fd0: 2320 7820 6162 6f76 650a 2020 2020 7265  # x above.    re
+00008fe0: 7320 3d20 6a6e 702e 7768 6572 6528 7361  s = jnp.where(sa
+00008ff0: 6d70 6c65 645f 756e 6966 6f72 6d20 3c3d  mpled_uniform <=
+00009000: 206d 6561 6e20 2f20 286d 6561 6e20 2b20   mean / (mean + 
+00009010: 7361 6d70 6c65 6429 2c0a 2020 2020 2020  sampled),.      
+00009020: 2020 2020 2020 2020 2020 2020 2020 7361                sa
+00009030: 6d70 6c65 642c 0a20 2020 2020 2020 2020  mpled,.         
+00009040: 2020 2020 2020 2020 2020 206a 6e70 2e73             jnp.s
+00009050: 7175 6172 6528 6d65 616e 2920 2f20 7361  quare(mean) / sa
+00009060: 6d70 6c65 6429 0a20 2020 2072 6574 7572  mpled).    retur
+00009070: 6e20 5f72 6574 7572 6e28 7265 7329 0a0a  n _return(res)..
+00009080: 2020 6465 6620 7428 7365 6c66 2c20 6466    def t(self, df
+00009090: 2c20 7369 7a65 3d4e 6f6e 652c 206b 6579  , size=None, key
+000090a0: 3d4e 6f6e 6529 3a0a 2020 2020 6466 203d  =None):.    df =
+000090b0: 205f 6368 6563 6b5f 7079 5f73 6571 285f   _check_py_seq(_
+000090c0: 6173 5f6a 6178 5f61 7272 6179 2864 6629  as_jax_array(df)
+000090d0: 290a 2020 2020 6966 2073 697a 6520 6973  ).    if size is
+000090e0: 204e 6f6e 653a 0a20 2020 2020 2073 697a   None:.      siz
+000090f0: 6520 3d20 6e70 2e73 6861 7065 2864 6629  e = np.shape(df)
+00009100: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
+00009110: 2073 697a 6520 3d20 5f73 697a 6532 7368   size = _size2sh
+00009120: 6170 6528 7369 7a65 290a 2020 2020 2020  ape(size).      
+00009130: 5f63 6865 636b 5f73 6861 7065 2822 7422  _check_shape("t"
+00009140: 2c20 7369 7a65 2c20 6e70 2e73 6861 7065  , size, np.shape
+00009150: 2864 6629 290a 2020 2020 6966 206b 6579  (df)).    if key
+00009160: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00009170: 6b65 7973 203d 2073 656c 662e 7370 6c69  keys = self.spli
+00009180: 745f 6b65 7973 2832 290a 2020 2020 656c  t_keys(2).    el
+00009190: 7365 3a0a 2020 2020 2020 6b65 7973 203d  se:.      keys =
+000091a0: 206a 722e 7370 6c69 7428 5f66 6f72 6d61   jr.split(_forma
+000091b0: 6c69 7a65 5f6b 6579 286b 6579 292c 2032  lize_key(key), 2
+000091c0: 290a 2020 2020 6e20 3d20 6a72 2e6e 6f72  ).    n = jr.nor
+000091d0: 6d61 6c28 6b65 7973 5b30 5d2c 2073 697a  mal(keys[0], siz
+000091e0: 6529 0a20 2020 2074 776f 203d 205f 636f  e).    two = _co
+000091f0: 6e73 7428 6e2c 2032 290a 2020 2020 6861  nst(n, 2).    ha
+00009200: 6c66 5f64 6620 3d20 6c61 782e 6469 7628  lf_df = lax.div(
+00009210: 6466 2c20 7477 6f29 0a20 2020 2067 203d  df, two).    g =
+00009220: 206a 722e 6761 6d6d 6128 6b65 7973 5b31   jr.gamma(keys[1
+00009230: 5d2c 2068 616c 665f 6466 2c20 7369 7a65  ], half_df, size
+00009240: 290a 2020 2020 7220 3d20 6e20 2a20 6a6e  ).    r = n * jn
+00009250: 702e 7371 7274 2868 616c 665f 6466 202f  p.sqrt(half_df /
+00009260: 2067 290a 2020 2020 7265 7475 726e 205f   g).    return _
+00009270: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
+00009280: 206f 7274 686f 676f 6e61 6c28 7365 6c66   orthogonal(self
+00009290: 2c20 6e3a 2069 6e74 2c20 7369 7a65 3d4e  , n: int, size=N
+000092a0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+000092b0: 2020 2020 6b65 7920 3d20 7365 6c66 2e73      key = self.s
+000092c0: 706c 6974 5f6b 6579 2829 2069 6620 6b65  plit_key() if ke
+000092d0: 7920 6973 204e 6f6e 6520 656c 7365 205f  y is None else _
+000092e0: 666f 726d 616c 697a 655f 6b65 7928 6b65  formalize_key(ke
+000092f0: 7929 0a20 2020 2073 697a 6520 3d20 5f73  y).    size = _s
+00009300: 697a 6532 7368 6170 6528 7369 7a65 290a  ize2shape(size).
+00009310: 2020 2020 5f63 6865 636b 5f73 6861 7065      _check_shape
+00009320: 2822 6f72 7468 6f67 6f6e 616c 222c 2073  ("orthogonal", s
+00009330: 697a 6529 0a20 2020 206e 203d 2063 6f72  ize).    n = cor
+00009340: 652e 636f 6e63 7265 7465 5f6f 725f 6572  e.concrete_or_er
+00009350: 726f 7228 696e 6465 782c 206e 2c20 2254  ror(index, n, "T
+00009360: 6865 2065 7272 6f72 206f 6363 7572 7265  he error occurre
+00009370: 6420 696e 206a 6178 2e72 616e 646f 6d2e  d in jax.random.
+00009380: 6f72 7468 6f67 6f6e 616c 2829 2229 0a20  orthogonal()"). 
+00009390: 2020 207a 203d 206a 722e 6e6f 726d 616c     z = jr.normal
+000093a0: 286b 6579 2c20 7369 7a65 202b 2028 6e2c  (key, size + (n,
+000093b0: 206e 2929 0a20 2020 2071 2c20 7220 3d20   n)).    q, r = 
+000093c0: 6a6e 702e 6c69 6e61 6c67 2e71 7228 7a29  jnp.linalg.qr(z)
+000093d0: 0a20 2020 2064 203d 206a 6e70 2e64 6961  .    d = jnp.dia
+000093e0: 676f 6e61 6c28 722c 2030 2c20 2d32 2c20  gonal(r, 0, -2, 
+000093f0: 2d31 290a 2020 2020 7220 3d20 7120 2a20  -1).    r = q * 
+00009400: 6a6e 702e 6578 7061 6e64 5f64 696d 7328  jnp.expand_dims(
+00009410: 6420 2f20 6162 7328 6429 2c20 2d32 290a  d / abs(d), -2).
+00009420: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
+00009430: 726e 2872 290a 0a20 2064 6566 206e 6f6e  rn(r)..  def non
+00009440: 6365 6e74 7261 6c5f 6368 6973 7175 6172  central_chisquar
+00009450: 6528 7365 6c66 2c20 6466 2c20 6e6f 6e63  e(self, df, nonc
+00009460: 2c20 7369 7a65 3d4e 6f6e 652c 206b 6579  , size=None, key
+00009470: 3d4e 6f6e 6529 3a0a 2020 2020 6466 203d  =None):.    df =
+00009480: 205f 6368 6563 6b5f 7079 5f73 6571 285f   _check_py_seq(_
+00009490: 6173 5f6a 6178 5f61 7272 6179 2864 6629  as_jax_array(df)
+000094a0: 290a 2020 2020 6e6f 6e63 203d 205f 6368  ).    nonc = _ch
+000094b0: 6563 6b5f 7079 5f73 6571 285f 6173 5f6a  eck_py_seq(_as_j
+000094c0: 6178 5f61 7272 6179 286e 6f6e 6329 290a  ax_array(nonc)).
+000094d0: 2020 2020 6966 2073 697a 6520 6973 204e      if size is N
+000094e0: 6f6e 653a 0a20 2020 2020 2073 697a 6520  one:.      size 
+000094f0: 3d20 6c61 782e 6272 6f61 6463 6173 745f  = lax.broadcast_
+00009500: 7368 6170 6573 286a 6e70 2e73 6861 7065  shapes(jnp.shape
+00009510: 2864 6629 2c20 6a6e 702e 7368 6170 6528  (df), jnp.shape(
+00009520: 6e6f 6e63 2929 0a20 2020 2073 697a 6520  nonc)).    size 
+00009530: 3d20 5f73 697a 6532 7368 6170 6528 7369  = _size2shape(si
+00009540: 7a65 290a 2020 2020 6966 206b 6579 2069  ze).    if key i
+00009550: 7320 4e6f 6e65 3a0a 2020 2020 2020 6b65  s None:.      ke
+00009560: 7973 203d 2073 656c 662e 7370 6c69 745f  ys = self.split_
+00009570: 6b65 7973 2833 290a 2020 2020 656c 7365  keys(3).    else
+00009580: 3a0a 2020 2020 2020 6b65 7973 203d 206a  :.      keys = j
+00009590: 722e 7370 6c69 7428 5f66 6f72 6d61 6c69  r.split(_formali
+000095a0: 7a65 5f6b 6579 286b 6579 292c 2033 290a  ze_key(key), 3).
+000095b0: 2020 2020 6920 3d20 6a72 2e70 6f69 7373      i = jr.poiss
+000095c0: 6f6e 286b 6579 735b 305d 2c20 302e 3520  on(keys[0], 0.5 
+000095d0: 2a20 6e6f 6e63 2c20 7368 6170 653d 7369  * nonc, shape=si
+000095e0: 7a65 290a 2020 2020 6e20 3d20 6a72 2e6e  ze).    n = jr.n
+000095f0: 6f72 6d61 6c28 6b65 7973 5b31 5d2c 2073  ormal(keys[1], s
+00009600: 6861 7065 3d73 697a 6529 202b 206a 6e70  hape=size) + jnp
+00009610: 2e73 7172 7428 6e6f 6e63 290a 2020 2020  .sqrt(nonc).    
+00009620: 636f 6e64 203d 206a 6e70 2e67 7265 6174  cond = jnp.great
+00009630: 6572 2864 662c 2031 2e30 290a 2020 2020  er(df, 1.0).    
+00009640: 6466 3220 3d20 6a6e 702e 7768 6572 6528  df2 = jnp.where(
+00009650: 636f 6e64 2c20 6466 202d 2031 2e30 2c20  cond, df - 1.0, 
+00009660: 6466 202b 2032 2e30 202a 2069 290a 2020  df + 2.0 * i).  
+00009670: 2020 6368 6932 203d 2032 2e30 202a 206a    chi2 = 2.0 * j
+00009680: 722e 6761 6d6d 6128 6b65 7973 5b32 5d2c  r.gamma(keys[2],
+00009690: 2030 2e35 202a 2064 6632 2c20 7368 6170   0.5 * df2, shap
+000096a0: 653d 7369 7a65 290a 2020 2020 7220 3d20  e=size).    r = 
+000096b0: 6a6e 702e 7768 6572 6528 636f 6e64 2c20  jnp.where(cond, 
+000096c0: 6368 6932 202b 206e 202a 206e 2c20 6368  chi2 + n * n, ch
+000096d0: 6932 290a 2020 2020 7265 7475 726e 205f  i2).    return _
+000096e0: 7265 7475 726e 2872 290a 0a20 2064 6566  return(r)..  def
+000096f0: 206c 6f67 6761 6d6d 6128 7365 6c66 2c20   loggamma(self, 
+00009700: 612c 2073 697a 653d 4e6f 6e65 2c20 6b65  a, size=None, ke
+00009710: 793d 4e6f 6e65 293a 0a20 2020 206b 6579  y=None):.    key
+00009720: 203d 2073 656c 662e 7370 6c69 745f 6b65   = self.split_ke
+00009730: 7928 2920 6966 206b 6579 2069 7320 4e6f  y() if key is No
+00009740: 6e65 2065 6c73 6520 5f66 6f72 6d61 6c69  ne else _formali
+00009750: 7a65 5f6b 6579 286b 6579 290a 2020 2020  ze_key(key).    
+00009760: 6120 3d20 5f63 6865 636b 5f70 795f 7365  a = _check_py_se
+00009770: 7128 5f61 735f 6a61 785f 6172 7261 7928  q(_as_jax_array(
+00009780: 6129 290a 2020 2020 6966 2073 697a 6520  a)).    if size 
+00009790: 6973 204e 6f6e 653a 0a20 2020 2020 2073  is None:.      s
+000097a0: 697a 6520 3d20 6a6e 702e 7368 6170 6528  ize = jnp.shape(
+000097b0: 6129 0a20 2020 2072 203d 206a 722e 6c6f  a).    r = jr.lo
+000097c0: 6767 616d 6d61 286b 6579 2c20 612c 2073  ggamma(key, a, s
+000097d0: 6861 7065 3d5f 7369 7a65 3273 6861 7065  hape=_size2shape
+000097e0: 2873 697a 6529 290a 2020 2020 7265 7475  (size)).    retu
+000097f0: 726e 205f 7265 7475 726e 2872 290a 0a20  rn _return(r).. 
+00009800: 2064 6566 2063 6174 6567 6f72 6963 616c   def categorical
+00009810: 2873 656c 662c 206c 6f67 6974 732c 2061  (self, logits, a
+00009820: 7869 733a 2069 6e74 203d 202d 312c 2073  xis: int = -1, s
+00009830: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+00009840: 6e65 293a 0a20 2020 206b 6579 203d 2073  ne):.    key = s
+00009850: 656c 662e 7370 6c69 745f 6b65 7928 2920  elf.split_key() 
+00009860: 6966 206b 6579 2069 7320 4e6f 6e65 2065  if key is None e
+00009870: 6c73 6520 5f66 6f72 6d61 6c69 7a65 5f6b  lse _formalize_k
+00009880: 6579 286b 6579 290a 2020 2020 6c6f 6769  ey(key).    logi
+00009890: 7473 203d 205f 6368 6563 6b5f 7079 5f73  ts = _check_py_s
+000098a0: 6571 285f 6173 5f6a 6178 5f61 7272 6179  eq(_as_jax_array
+000098b0: 286c 6f67 6974 7329 290a 2020 2020 6966  (logits)).    if
+000098c0: 2073 697a 6520 6973 204e 6f6e 653a 0a20   size is None:. 
+000098d0: 2020 2020 2073 697a 6520 3d20 6c69 7374       size = list
+000098e0: 286a 6e70 2e73 6861 7065 286c 6f67 6974  (jnp.shape(logit
+000098f0: 7329 290a 2020 2020 2020 7369 7a65 2e70  s)).      size.p
+00009900: 6f70 2861 7869 7329 0a20 2020 2072 203d  op(axis).    r =
+00009910: 206a 722e 6361 7465 676f 7269 6361 6c28   jr.categorical(
+00009920: 6b65 792c 206c 6f67 6974 732c 2061 7869  key, logits, axi
+00009930: 733d 6178 6973 2c20 7368 6170 653d 5f73  s=axis, shape=_s
+00009940: 697a 6532 7368 6170 6528 7369 7a65 2929  ize2shape(size))
+00009950: 0a20 2020 2072 6574 7572 6e20 5f72 6574  .    return _ret
+00009960: 7572 6e28 7229 0a0a 2020 6465 6620 7a69  urn(r)..  def zi
+00009970: 7066 2873 656c 662c 2061 2c20 7369 7a65  pf(self, a, size
+00009980: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
+00009990: 3a0a 2020 2020 6120 3d20 5f63 6865 636b  :.    a = _check
+000099a0: 5f70 795f 7365 7128 5f61 735f 6a61 785f  _py_seq(_as_jax_
+000099b0: 6172 7261 7928 6129 290a 2020 2020 6966  array(a)).    if
+000099c0: 2073 697a 6520 6973 204e 6f6e 653a 0a20   size is None:. 
+000099d0: 2020 2020 2073 697a 6520 3d20 6a6e 702e       size = jnp.
+000099e0: 7368 6170 6528 6129 0a20 2020 2072 203d  shape(a).    r =
+000099f0: 2063 616c 6c28 6c61 6d62 6461 2078 3a20   call(lambda x: 
+00009a00: 6e70 2e72 616e 646f 6d2e 7a69 7066 2878  np.random.zipf(x
+00009a10: 2c20 7369 7a65 292c 0a20 2020 2020 2020  , size),.       
+00009a20: 2020 2020 2020 612c 0a20 2020 2020 2020        a,.       
+00009a30: 2020 2020 2020 7265 7375 6c74 5f73 6861        result_sha
+00009a40: 7065 3d6a 6178 2e53 6861 7065 4474 7970  pe=jax.ShapeDtyp
+00009a50: 6553 7472 7563 7428 7369 7a65 2c20 6a6e  eStruct(size, jn
+00009a60: 702e 696e 745f 2929 0a20 2020 2072 6574  p.int_)).    ret
+00009a70: 7572 6e20 5f72 6574 7572 6e28 7229 0a0a  urn _return(r)..
+00009a80: 2020 6465 6620 706f 7765 7228 7365 6c66    def power(self
+00009a90: 2c20 612c 2073 697a 653d 4e6f 6e65 2c20  , a, size=None, 
+00009aa0: 6b65 793d 4e6f 6e65 293a 0a20 2020 2061  key=None):.    a
+00009ab0: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+00009ac0: 285f 6173 5f6a 6178 5f61 7272 6179 2861  (_as_jax_array(a
+00009ad0: 2929 0a20 2020 2069 6620 7369 7a65 2069  )).    if size i
+00009ae0: 7320 4e6f 6e65 3a0a 2020 2020 2020 7369  s None:.      si
+00009af0: 7a65 203d 206a 6e70 2e73 6861 7065 2861  ze = jnp.shape(a
+00009b00: 290a 2020 2020 7369 7a65 203d 205f 7369  ).    size = _si
+00009b10: 7a65 3273 6861 7065 2873 697a 6529 0a20  ze2shape(size). 
+00009b20: 2020 2072 203d 2063 616c 6c28 6c61 6d62     r = call(lamb
+00009b30: 6461 2061 3a20 6e70 2e72 616e 646f 6d2e  da a: np.random.
+00009b40: 706f 7765 7228 613d 612c 2073 697a 653d  power(a=a, size=
+00009b50: 7369 7a65 292c 0a20 2020 2020 2020 2020  size),.         
+00009b60: 2020 2020 612c 2072 6573 756c 745f 7368      a, result_sh
+00009b70: 6170 653d 6a61 782e 5368 6170 6544 7479  ape=jax.ShapeDty
+00009b80: 7065 5374 7275 6374 2873 697a 652c 206a  peStruct(size, j
+00009b90: 6e70 2e66 6c6f 6174 5f29 290a 2020 2020  np.float_)).    
+00009ba0: 7265 7475 726e 205f 7265 7475 726e 2872  return _return(r
+00009bb0: 290a 0a20 2064 6566 2066 2873 656c 662c  )..  def f(self,
+00009bc0: 2064 666e 756d 2c20 6466 6465 6e2c 2073   dfnum, dfden, s
+00009bd0: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+00009be0: 6e65 293a 0a20 2020 2064 666e 756d 203d  ne):.    dfnum =
+00009bf0: 205f 6173 5f6a 6178 5f61 7272 6179 2864   _as_jax_array(d
+00009c00: 666e 756d 290a 2020 2020 6466 6465 6e20  fnum).    dfden 
+00009c10: 3d20 5f61 735f 6a61 785f 6172 7261 7928  = _as_jax_array(
+00009c20: 6466 6465 6e29 0a20 2020 2064 666e 756d  dfden).    dfnum
+00009c30: 203d 205f 6368 6563 6b5f 7079 5f73 6571   = _check_py_seq
+00009c40: 2864 666e 756d 290a 2020 2020 6466 6465  (dfnum).    dfde
+00009c50: 6e20 3d20 5f63 6865 636b 5f70 795f 7365  n = _check_py_se
+00009c60: 7128 6466 6465 6e29 0a20 2020 2069 6620  q(dfden).    if 
+00009c70: 7369 7a65 2069 7320 4e6f 6e65 3a0a 2020  size is None:.  
+00009c80: 2020 2020 7369 7a65 203d 206a 6e70 2e62      size = jnp.b
+00009c90: 726f 6164 6361 7374 5f73 6861 7065 7328  roadcast_shapes(
+00009ca0: 6a6e 702e 7368 6170 6528 6466 6e75 6d29  jnp.shape(dfnum)
+00009cb0: 2c20 6a6e 702e 7368 6170 6528 6466 6465  , jnp.shape(dfde
+00009cc0: 6e29 290a 2020 2020 7369 7a65 203d 205f  n)).    size = _
+00009cd0: 7369 7a65 3273 6861 7065 2873 697a 6529  size2shape(size)
+00009ce0: 0a20 2020 2064 203d 207b 2764 666e 756d  .    d = {'dfnum
+00009cf0: 273a 2064 666e 756d 2c20 2764 6664 656e  ': dfnum, 'dfden
+00009d00: 273a 2064 6664 656e 7d0a 2020 2020 7220  ': dfden}.    r 
+00009d10: 3d20 6361 6c6c 286c 616d 6264 6120 783a  = call(lambda x:
+00009d20: 206e 702e 7261 6e64 6f6d 2e66 2864 666e   np.random.f(dfn
+00009d30: 756d 3d78 5b27 6466 6e75 6d27 5d2c 0a20  um=x['dfnum'],. 
+00009d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009d60: 2020 6466 6465 6e3d 785b 2764 6664 656e    dfden=x['dfden
+00009d70: 275d 2c0a 2020 2020 2020 2020 2020 2020  '],.            
+00009d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009d90: 2020 2020 2020 2073 697a 653d 7369 7a65         size=size
+00009da0: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
+00009db0: 642c 0a20 2020 2020 2020 2020 2020 2020  d,.             
+00009dc0: 7265 7375 6c74 5f73 6861 7065 3d6a 6178  result_shape=jax
+00009dd0: 2e53 6861 7065 4474 7970 6553 7472 7563  .ShapeDtypeStruc
+00009de0: 7428 7369 7a65 2c20 6a6e 702e 666c 6f61  t(size, jnp.floa
+00009df0: 745f 2929 0a20 2020 2072 6574 7572 6e20  t_)).    return 
+00009e00: 5f72 6574 7572 6e28 7229 0a0a 2020 6465  _return(r)..  de
+00009e10: 6620 6879 7065 7267 656f 6d65 7472 6963  f hypergeometric
+00009e20: 2873 656c 662c 206e 676f 6f64 2c20 6e62  (self, ngood, nb
+00009e30: 6164 2c20 6e73 616d 706c 652c 2073 697a  ad, nsample, siz
+00009e40: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
+00009e50: 293a 0a20 2020 206e 676f 6f64 203d 205f  ):.    ngood = _
+00009e60: 6368 6563 6b5f 7079 5f73 6571 285f 6173  check_py_seq(_as
+00009e70: 5f6a 6178 5f61 7272 6179 286e 676f 6f64  _jax_array(ngood
+00009e80: 2929 0a20 2020 206e 6261 6420 3d20 5f63  )).    nbad = _c
+00009e90: 6865 636b 5f70 795f 7365 7128 5f61 735f  heck_py_seq(_as_
+00009ea0: 6a61 785f 6172 7261 7928 6e62 6164 2929  jax_array(nbad))
+00009eb0: 0a20 2020 206e 7361 6d70 6c65 203d 205f  .    nsample = _
+00009ec0: 6368 6563 6b5f 7079 5f73 6571 285f 6173  check_py_seq(_as
+00009ed0: 5f6a 6178 5f61 7272 6179 286e 7361 6d70  _jax_array(nsamp
+00009ee0: 6c65 2929 0a0a 2020 2020 6966 2073 697a  le))..    if siz
+00009ef0: 6520 6973 204e 6f6e 653a 0a20 2020 2020  e is None:.     
+00009f00: 2073 697a 6520 3d20 6c61 782e 6272 6f61   size = lax.broa
+00009f10: 6463 6173 745f 7368 6170 6573 286a 6e70  dcast_shapes(jnp
+00009f20: 2e73 6861 7065 286e 676f 6f64 292c 0a20  .shape(ngood),. 
+00009f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f50: 206a 6e70 2e73 6861 7065 286e 6261 6429   jnp.shape(nbad)
+00009f60: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00009f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f80: 2020 2020 6a6e 702e 7368 6170 6528 6e73      jnp.shape(ns
+00009f90: 616d 706c 6529 290a 2020 2020 7369 7a65  ample)).    size
+00009fa0: 203d 205f 7369 7a65 3273 6861 7065 2873   = _size2shape(s
+00009fb0: 697a 6529 0a20 2020 2064 203d 207b 276e  ize).    d = {'n
+00009fc0: 676f 6f64 273a 206e 676f 6f64 2c20 276e  good': ngood, 'n
+00009fd0: 6261 6427 3a20 6e62 6164 2c20 276e 7361  bad': nbad, 'nsa
+00009fe0: 6d70 6c65 273a 206e 7361 6d70 6c65 7d0a  mple': nsample}.
+00009ff0: 2020 2020 7220 3d20 6361 6c6c 286c 616d      r = call(lam
+0000a000: 6264 6120 783a 206e 702e 7261 6e64 6f6d  bda x: np.random
+0000a010: 2e68 7970 6572 6765 6f6d 6574 7269 6328  .hypergeometric(
+0000a020: 6e67 6f6f 643d 785b 276e 676f 6f64 275d  ngood=x['ngood']
+0000a030: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000a040: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a060: 2020 6e62 6164 3d78 5b27 6e62 6164 275d    nbad=x['nbad']
+0000a070: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000a080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a0a0: 2020 6e73 616d 706c 653d 785b 276e 7361    nsample=x['nsa
+0000a0b0: 6d70 6c65 275d 2c0a 2020 2020 2020 2020  mple'],.        
+0000a0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a0e0: 2020 2020 2020 2020 7369 7a65 3d73 697a          size=siz
+0000a0f0: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
+0000a100: 2064 2c20 7265 7375 6c74 5f73 6861 7065   d, result_shape
+0000a110: 3d6a 6178 2e53 6861 7065 4474 7970 6553  =jax.ShapeDtypeS
+0000a120: 7472 7563 7428 7369 7a65 2c20 6a6e 702e  truct(size, jnp.
+0000a130: 696e 745f 2929 0a20 2020 2072 6574 7572  int_)).    retur
+0000a140: 6e20 5f72 6574 7572 6e28 7229 0a0a 2020  n _return(r)..  
+0000a150: 6465 6620 6c6f 6773 6572 6965 7328 7365  def logseries(se
+0000a160: 6c66 2c20 702c 2073 697a 653d 4e6f 6e65  lf, p, size=None
+0000a170: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2020  , key=None):.   
+0000a180: 2070 203d 205f 6368 6563 6b5f 7079 5f73   p = _check_py_s
+0000a190: 6571 285f 6173 5f6a 6178 5f61 7272 6179  eq(_as_jax_array
+0000a1a0: 2870 2929 0a20 2020 2069 6620 7369 7a65  (p)).    if size
+0000a1b0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+0000a1c0: 7369 7a65 203d 206a 6e70 2e73 6861 7065  size = jnp.shape
+0000a1d0: 2870 290a 2020 2020 7369 7a65 203d 205f  (p).    size = _
+0000a1e0: 7369 7a65 3273 6861 7065 2873 697a 6529  size2shape(size)
+0000a1f0: 0a20 2020 2072 203d 2063 616c 6c28 6c61  .    r = call(la
+0000a200: 6d62 6461 2070 3a20 6e70 2e72 616e 646f  mbda p: np.rando
+0000a210: 6d2e 6c6f 6773 6572 6965 7328 703d 702c  m.logseries(p=p,
+0000a220: 2073 697a 653d 7369 7a65 292c 0a20 2020   size=size),.   
+0000a230: 2020 2020 2020 2020 2020 702c 2072 6573            p, res
+0000a240: 756c 745f 7368 6170 653d 6a61 782e 5368  ult_shape=jax.Sh
+0000a250: 6170 6544 7479 7065 5374 7275 6374 2873  apeDtypeStruct(s
+0000a260: 697a 652c 206a 6e70 2e69 6e74 5f29 290a  ize, jnp.int_)).
+0000a270: 2020 2020 7265 7475 726e 205f 7265 7475      return _retu
+0000a280: 726e 2872 290a 0a20 2064 6566 206e 6f6e  rn(r)..  def non
+0000a290: 6365 6e74 7261 6c5f 6628 7365 6c66 2c20  central_f(self, 
+0000a2a0: 6466 6e75 6d2c 2064 6664 656e 2c20 6e6f  dfnum, dfden, no
+0000a2b0: 6e63 2c20 7369 7a65 3d4e 6f6e 652c 206b  nc, size=None, k
+0000a2c0: 6579 3d4e 6f6e 6529 3a0a 2020 2020 6466  ey=None):.    df
+0000a2d0: 6e75 6d20 3d20 5f63 6865 636b 5f70 795f  num = _check_py_
+0000a2e0: 7365 7128 5f61 735f 6a61 785f 6172 7261  seq(_as_jax_arra
+0000a2f0: 7928 6466 6e75 6d29 290a 2020 2020 6466  y(dfnum)).    df
+0000a300: 6465 6e20 3d20 5f63 6865 636b 5f70 795f  den = _check_py_
+0000a310: 7365 7128 5f61 735f 6a61 785f 6172 7261  seq(_as_jax_arra
+0000a320: 7928 6466 6465 6e29 290a 2020 2020 6e6f  y(dfden)).    no
+0000a330: 6e63 203d 205f 6368 6563 6b5f 7079 5f73  nc = _check_py_s
+0000a340: 6571 285f 6173 5f6a 6178 5f61 7272 6179  eq(_as_jax_array
+0000a350: 286e 6f6e 6329 290a 2020 2020 6966 2073  (nonc)).    if s
+0000a360: 697a 6520 6973 204e 6f6e 653a 0a20 2020  ize is None:.   
+0000a370: 2020 2073 697a 6520 3d20 6c61 782e 6272     size = lax.br
+0000a380: 6f61 6463 6173 745f 7368 6170 6573 286a  oadcast_shapes(j
+0000a390: 6e70 2e73 6861 7065 2864 666e 756d 292c  np.shape(dfnum),
+0000a3a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a3c0: 2020 206a 6e70 2e73 6861 7065 2864 6664     jnp.shape(dfd
+0000a3d0: 656e 292c 0a20 2020 2020 2020 2020 2020  en),.           
+0000a3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a3f0: 2020 2020 2020 206a 6e70 2e73 6861 7065         jnp.shape
+0000a400: 286e 6f6e 6329 290a 2020 2020 7369 7a65  (nonc)).    size
+0000a410: 203d 205f 7369 7a65 3273 6861 7065 2873   = _size2shape(s
+0000a420: 697a 6529 0a20 2020 2064 203d 207b 2764  ize).    d = {'d
+0000a430: 666e 756d 273a 2064 666e 756d 2c20 2764  fnum': dfnum, 'd
+0000a440: 6664 656e 273a 2064 6664 656e 2c20 276e  fden': dfden, 'n
+0000a450: 6f6e 6327 3a20 6e6f 6e63 7d0a 2020 2020  onc': nonc}.    
+0000a460: 7220 3d20 6361 6c6c 286c 616d 6264 6120  r = call(lambda 
+0000a470: 783a 206e 702e 7261 6e64 6f6d 2e6e 6f6e  x: np.random.non
+0000a480: 6365 6e74 7261 6c5f 6628 6466 6e75 6d3d  central_f(dfnum=
+0000a490: 785b 2764 666e 756d 275d 2c0a 2020 2020  x['dfnum'],.    
+0000a4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a4c0: 2020 2020 2020 2020 2020 6466 6465 6e3d            dfden=
+0000a4d0: 785b 2764 6664 656e 275d 2c0a 2020 2020  x['dfden'],.    
+0000a4e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a500: 2020 2020 2020 2020 2020 6e6f 6e63 3d78            nonc=x
+0000a510: 5b27 6e6f 6e63 275d 2c0a 2020 2020 2020  ['nonc'],.      
+0000a520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a540: 2020 2020 2020 2020 7369 7a65 3d73 697a          size=siz
+0000a550: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
+0000a560: 2064 2c20 7265 7375 6c74 5f73 6861 7065   d, result_shape
+0000a570: 3d6a 6178 2e53 6861 7065 4474 7970 6553  =jax.ShapeDtypeS
+0000a580: 7472 7563 7428 7369 7a65 2c20 6a6e 702e  truct(size, jnp.
+0000a590: 666c 6f61 745f 2929 0a20 2020 2072 6574  float_)).    ret
+0000a5a0: 7572 6e20 5f72 6574 7572 6e28 7229 0a0a  urn _return(r)..
+0000a5b0: 2020 2320 5079 546f 7263 6820 636f 6d70    # PyTorch comp
+0000a5c0: 6174 6962 696c 6974 7920 230a 2020 2320  atibility #.  # 
+0000a5d0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+0000a5e0: 2d2d 2d2d 2d20 230a 0a20 2064 6566 2072  ----- #..  def r
+0000a5f0: 616e 645f 6c69 6b65 2873 656c 662c 2069  and_like(self, i
+0000a600: 6e70 7574 2c20 2a2c 2064 7479 7065 3d4e  nput, *, dtype=N
+0000a610: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+0000a620: 2020 2020 2222 2252 6574 7572 6e73 2061      """Returns a
+0000a630: 2074 656e 736f 7220 7769 7468 2074 6865   tensor with the
+0000a640: 2073 616d 6520 7369 7a65 2061 7320 696e   same size as in
+0000a650: 7075 7420 7468 6174 2069 7320 6669 6c6c  put that is fill
+0000a660: 6564 2077 6974 6820 7261 6e64 6f6d 0a20  ed with random. 
+0000a670: 2020 206e 756d 6265 7273 2066 726f 6d20     numbers from 
+0000a680: 6120 756e 6966 6f72 6d20 6469 7374 7269  a uniform distri
+0000a690: 6275 7469 6f6e 206f 6e20 7468 6520 696e  bution on the in
+0000a6a0: 7465 7276 616c 2060 605b 302c 2031 2960  terval ``[0, 1)`
+0000a6b0: 602e 0a0a 2020 2020 4172 6773 3a0a 2020  `...    Args:.  
+0000a6c0: 2020 2020 696e 7075 743a 2020 7468 6520      input:  the 
+0000a6d0: 6060 7369 7a65 6060 206f 6620 696e 7075  ``size`` of inpu
+0000a6e0: 7420 7769 6c6c 2064 6574 6572 6d69 6e65  t will determine
+0000a6f0: 2073 697a 6520 6f66 2074 6865 206f 7574   size of the out
+0000a700: 7075 7420 7465 6e73 6f72 2e0a 2020 2020  put tensor..    
+0000a710: 2020 6474 7970 653a 2020 7468 6520 6465    dtype:  the de
+0000a720: 7369 7265 6420 6461 7461 2074 7970 6520  sired data type 
+0000a730: 6f66 2072 6574 7572 6e65 6420 5465 6e73  of returned Tens
+0000a740: 6f72 2e20 4465 6661 756c 743a 2069 6620  or. Default: if 
+0000a750: 6060 4e6f 6e65 6060 2c20 6465 6661 756c  ``None``, defaul
+0000a760: 7473 2074 6f20 7468 6520 6474 7970 6520  ts to the dtype 
+0000a770: 6f66 2069 6e70 7574 2e0a 2020 2020 2020  of input..      
+0000a780: 6b65 793a 2074 6865 2073 6565 6420 6f72  key: the seed or
+0000a790: 206b 6579 2066 6f72 2074 6865 2072 616e   key for the ran
+0000a7a0: 646f 6d2e 0a0a 2020 2020 5265 7475 726e  dom...    Return
+0000a7b0: 733a 0a20 2020 2020 2054 6865 2072 616e  s:.      The ran
+0000a7c0: 646f 6d20 6461 7461 2e0a 2020 2020 2222  dom data..    ""
+0000a7d0: 220a 2020 2020 7265 7475 726e 2073 656c  ".    return sel
+0000a7e0: 662e 7261 6e64 6f6d 2873 6861 7065 2869  f.random(shape(i
+0000a7f0: 6e70 7574 292c 206b 6579 3d6b 6579 292e  nput), key=key).
+0000a800: 6173 7479 7065 2864 7479 7065 290a 0a20  astype(dtype).. 
+0000a810: 2064 6566 2072 616e 646e 5f6c 696b 6528   def randn_like(
+0000a820: 7365 6c66 2c20 696e 7075 742c 202a 2c20  self, input, *, 
+0000a830: 6474 7970 653d 4e6f 6e65 2c20 6b65 793d  dtype=None, key=
+0000a840: 4e6f 6e65 293a 0a20 2020 2022 2222 5265  None):.    """Re
+0000a850: 7475 726e 7320 6120 7465 6e73 6f72 2077  turns a tensor w
+0000a860: 6974 6820 7468 6520 7361 6d65 2073 697a  ith the same siz
+0000a870: 6520 6173 2060 6069 6e70 7574 6060 2074  e as ``input`` t
+0000a880: 6861 7420 6973 2066 696c 6c65 6420 7769  hat is filled wi
+0000a890: 7468 0a20 2020 2072 616e 646f 6d20 6e75  th.    random nu
+0000a8a0: 6d62 6572 7320 6672 6f6d 2061 206e 6f72  mbers from a nor
+0000a8b0: 6d61 6c20 6469 7374 7269 6275 7469 6f6e  mal distribution
+0000a8c0: 2077 6974 6820 6d65 616e 2030 2061 6e64   with mean 0 and
+0000a8d0: 2076 6172 6961 6e63 6520 312e 0a0a 2020   variance 1...  
+0000a8e0: 2020 4172 6773 3a0a 2020 2020 2020 696e    Args:.      in
+0000a8f0: 7075 743a 2020 7468 6520 6060 7369 7a65  put:  the ``size
+0000a900: 6060 206f 6620 696e 7075 7420 7769 6c6c  `` of input will
+0000a910: 2064 6574 6572 6d69 6e65 2073 697a 6520   determine size 
+0000a920: 6f66 2074 6865 206f 7574 7075 7420 7465  of the output te
+0000a930: 6e73 6f72 2e0a 2020 2020 2020 6474 7970  nsor..      dtyp
+0000a940: 653a 2020 7468 6520 6465 7369 7265 6420  e:  the desired 
+0000a950: 6461 7461 2074 7970 6520 6f66 2072 6574  data type of ret
+0000a960: 7572 6e65 6420 5465 6e73 6f72 2e20 4465  urned Tensor. De
+0000a970: 6661 756c 743a 2069 6620 6060 4e6f 6e65  fault: if ``None
+0000a980: 6060 2c20 6465 6661 756c 7473 2074 6f20  ``, defaults to 
+0000a990: 7468 6520 6474 7970 6520 6f66 2069 6e70  the dtype of inp
+0000a9a0: 7574 2e0a 2020 2020 2020 6b65 793a 2074  ut..      key: t
+0000a9b0: 6865 2073 6565 6420 6f72 206b 6579 2066  he seed or key f
+0000a9c0: 6f72 2074 6865 2072 616e 646f 6d2e 0a0a  or the random...
+0000a9d0: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
+0000a9e0: 2020 2054 6865 2072 616e 646f 6d20 6461     The random da
+0000a9f0: 7461 2e0a 2020 2020 2222 220a 2020 2020  ta..    """.    
+0000aa00: 7265 7475 726e 2073 656c 662e 7261 6e64  return self.rand
+0000aa10: 6e28 2a73 6861 7065 2869 6e70 7574 292c  n(*shape(input),
+0000aa20: 206b 6579 3d6b 6579 292e 6173 7479 7065   key=key).astype
+0000aa30: 2864 7479 7065 290a 0a20 2064 6566 2072  (dtype)..  def r
+0000aa40: 616e 6469 6e74 5f6c 696b 6528 7365 6c66  andint_like(self
+0000aa50: 2c20 696e 7075 742c 206c 6f77 3d30 2c20  , input, low=0, 
+0000aa60: 6869 6768 3d4e 6f6e 652c 202a 2c20 6474  high=None, *, dt
+0000aa70: 7970 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ype=None, key=No
+0000aa80: 6e65 293a 0a20 2020 2069 6620 6869 6768  ne):.    if high
+0000aa90: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+0000aaa0: 6869 6768 203d 206d 6178 2869 6e70 7574  high = max(input
+0000aab0: 290a 2020 2020 7265 7475 726e 2073 656c  ).    return sel
+0000aac0: 662e 7261 6e64 696e 7428 6c6f 772c 2068  f.randint(low, h
+0000aad0: 6967 683d 6869 6768 2c20 7369 7a65 3d73  igh=high, size=s
+0000aae0: 6861 7065 2869 6e70 7574 292c 2064 7479  hape(input), dty
+0000aaf0: 7065 3d64 7479 7065 2c20 6b65 793d 6b65  pe=dtype, key=ke
+0000ab00: 7929 0a0a 0a23 2061 6c69 6173 0a47 656e  y)...# alias.Gen
+0000ab10: 6572 6174 6f72 203d 2052 616e 646f 6d53  erator = RandomS
+0000ab20: 7461 7465 0a0a 2320 6465 6661 756c 7420  tate..# default 
+0000ab30: 7261 6e64 6f6d 2067 656e 6572 6174 6f72  random generator
+0000ab40: 0a5f 5f61 203d 2041 7272 6179 284e 6f6e  .__a = Array(Non
+0000ab50: 6529 0a5f 5f61 2e5f 7661 6c75 6520 3d20  e).__a._value = 
+0000ab60: 6e70 2e72 616e 646f 6d2e 7261 6e64 696e  np.random.randin
+0000ab70: 7428 302c 2031 3030 3030 2c20 7369 7a65  t(0, 10000, size
+0000ab80: 3d32 2c20 6474 7970 653d 6e70 2e75 696e  =2, dtype=np.uin
+0000ab90: 7433 3229 0a44 4546 4155 4c54 203d 2052  t32).DEFAULT = R
+0000aba0: 616e 646f 6d53 7461 7465 285f 5f61 290a  andomState(__a).
+0000abb0: 6465 6c20 5f5f 610a 0a0a 6465 6620 7370  del __a...def sp
+0000abc0: 6c69 745f 6b65 7928 293a 0a20 2072 6574  lit_key():.  ret
+0000abd0: 7572 6e20 4445 4641 554c 542e 7370 6c69  urn DEFAULT.spli
+0000abe0: 745f 6b65 7928 290a 0a0a 6465 6620 636c  t_key()...def cl
+0000abf0: 6f6e 655f 726e 6728 7365 6564 5f6f 725f  one_rng(seed_or_
+0000ac00: 6b65 793d 4e6f 6e65 2c20 636c 6f6e 653a  key=None, clone:
+0000ac10: 2062 6f6f 6c20 3d20 5472 7565 2920 2d3e   bool = True) ->
+0000ac20: 2052 616e 646f 6d53 7461 7465 3a0a 2020   RandomState:.  
+0000ac30: 6966 2073 6565 645f 6f72 5f6b 6579 2069  if seed_or_key i
+0000ac40: 7320 4e6f 6e65 3a0a 2020 2020 7265 7475  s None:.    retu
+0000ac50: 726e 2044 4546 4155 4c54 2e63 6c6f 6e65  rn DEFAULT.clone
+0000ac60: 2829 2069 6620 636c 6f6e 6520 656c 7365  () if clone else
+0000ac70: 2044 4546 4155 4c54 0a20 2065 6c73 653a   DEFAULT.  else:
+0000ac80: 0a20 2020 2072 6574 7572 6e20 5261 6e64  .    return Rand
+0000ac90: 6f6d 5374 6174 6528 7365 6564 5f6f 725f  omState(seed_or_
+0000aca0: 6b65 7929 0a0a 0a64 6566 2064 6566 6175  key)...def defau
+0000acb0: 6c74 5f72 6e67 2873 6565 645f 6f72 5f6b  lt_rng(seed_or_k
+0000acc0: 6579 3d4e 6f6e 652c 2063 6c6f 6e65 3d54  ey=None, clone=T
+0000acd0: 7275 6529 202d 3e20 5261 6e64 6f6d 5374  rue) -> RandomSt
+0000ace0: 6174 653a 0a20 2069 6620 7365 6564 5f6f  ate:.  if seed_o
+0000acf0: 725f 6b65 7920 6973 204e 6f6e 653a 0a20  r_key is None:. 
+0000ad00: 2020 2072 6574 7572 6e20 4445 4641 554c     return DEFAUL
+0000ad10: 542e 636c 6f6e 6528 2920 6966 2063 6c6f  T.clone() if clo
+0000ad20: 6e65 2065 6c73 6520 4445 4641 554c 540a  ne else DEFAULT.
+0000ad30: 2020 656c 7365 3a0a 2020 2020 7265 7475    else:.    retu
+0000ad40: 726e 2052 616e 646f 6d53 7461 7465 2873  rn RandomState(s
+0000ad50: 6565 645f 6f72 5f6b 6579 290a 0a0a 6465  eed_or_key)...de
+0000ad60: 6620 7365 6564 2873 6565 643a 2069 6e74  f seed(seed: int
+0000ad70: 203d 204e 6f6e 6529 3a0a 2020 2222 2253   = None):.  """S
+0000ad80: 6574 7320 6120 6e65 7720 7261 6e64 6f6d  ets a new random
+0000ad90: 2073 6565 642e 0a0a 2020 5061 7261 6d65   seed...  Parame
+0000ada0: 7465 7273 0a20 202d 2d2d 2d2d 2d2d 2d2d  ters.  ---------
+0000adb0: 2d0a 2020 7365 6564 3a20 696e 742c 206f  -.  seed: int, o
+0000adc0: 7074 696f 6e61 6c0a 2020 2020 5468 6520  ptional.    The 
+0000add0: 7261 6e64 6f6d 2073 6565 642e 0a20 2022  random seed..  "
+0000ade0: 2222 0a20 2077 6974 6820 6a61 782e 656e  "".  with jax.en
+0000adf0: 7375 7265 5f63 6f6d 7069 6c65 5f74 696d  sure_compile_tim
+0000ae00: 655f 6576 616c 2829 3a0a 2020 2020 6966  e_eval():.    if
+0000ae10: 2073 6565 6420 6973 204e 6f6e 653a 0a20   seed is None:. 
+0000ae20: 2020 2020 2073 6565 6420 3d20 6e70 2e72       seed = np.r
+0000ae30: 616e 646f 6d2e 7261 6e64 696e 7428 302c  andom.randint(0,
+0000ae40: 2031 3030 3030 3029 0a20 2020 206e 702e   100000).    np.
+0000ae50: 7261 6e64 6f6d 2e73 6565 6428 7365 6564  random.seed(seed
+0000ae60: 290a 2020 4445 4641 554c 542e 7365 6564  ).  DEFAULT.seed
+0000ae70: 2873 6565 6429 0a0a 0a64 6566 2072 616e  (seed)...def ran
+0000ae80: 6428 2a64 6e2c 206b 6579 3d4e 6f6e 6529  d(*dn, key=None)
+0000ae90: 3a0a 2020 7222 2222 5261 6e64 6f6d 2076  :.  r"""Random v
+0000aea0: 616c 7565 7320 696e 2061 2067 6976 656e  alues in a given
+0000aeb0: 2073 6861 7065 2e0a 0a20 202e 2e20 6e6f   shape...  .. no
+0000aec0: 7465 3a3a 0a20 2020 2020 2054 6869 7320  te::.      This 
+0000aed0: 6973 2061 2063 6f6e 7665 6e69 656e 6365  is a convenience
+0000aee0: 2066 756e 6374 696f 6e20 666f 7220 7573   function for us
+0000aef0: 6572 7320 706f 7274 696e 6720 636f 6465  ers porting code
+0000af00: 2066 726f 6d20 4d61 746c 6162 2c0a 2020   from Matlab,.  
+0000af10: 2020 2020 616e 6420 7772 6170 7320 6072      and wraps `r
+0000af20: 616e 646f 6d5f 7361 6d70 6c65 602e 2054  andom_sample`. T
+0000af30: 6861 7420 6675 6e63 7469 6f6e 2074 616b  hat function tak
+0000af40: 6573 2061 0a20 2020 2020 2074 7570 6c65  es a.      tuple
+0000af50: 2074 6f20 7370 6563 6966 7920 7468 6520   to specify the 
+0000af60: 7369 7a65 206f 6620 7468 6520 6f75 7470  size of the outp
+0000af70: 7574 2c20 7768 6963 6820 6973 2063 6f6e  ut, which is con
+0000af80: 7369 7374 656e 7420 7769 7468 0a20 2020  sistent with.   
+0000af90: 2020 206f 7468 6572 204e 756d 5079 2066     other NumPy f
+0000afa0: 756e 6374 696f 6e73 206c 696b 6520 606e  unctions like `n
+0000afb0: 756d 7079 2e7a 6572 6f73 6020 616e 6420  umpy.zeros` and 
+0000afc0: 606e 756d 7079 2e6f 6e65 7360 2e0a 0a20  `numpy.ones`... 
+0000afd0: 2043 7265 6174 6520 616e 2061 7272 6179   Create an array
+0000afe0: 206f 6620 7468 6520 6769 7665 6e20 7368   of the given sh
+0000aff0: 6170 6520 616e 6420 706f 7075 6c61 7465  ape and populate
+0000b000: 2069 7420 7769 7468 0a20 2072 616e 646f   it with.  rando
+0000b010: 6d20 7361 6d70 6c65 7320 6672 6f6d 2061  m samples from a
+0000b020: 2075 6e69 666f 726d 2064 6973 7472 6962   uniform distrib
+0000b030: 7574 696f 6e0a 2020 6f76 6572 2060 605b  ution.  over ``[
+0000b040: 302c 2031 2960 602e 0a0a 2020 5061 7261  0, 1)``...  Para
+0000b050: 6d65 7465 7273 0a20 202d 2d2d 2d2d 2d2d  meters.  -------
+0000b060: 2d2d 2d0a 2020 6430 2c20 6431 2c20 2e2e  ---.  d0, d1, ..
+0000b070: 2e2c 2064 6e20 3a20 696e 742c 206f 7074  ., dn : int, opt
+0000b080: 696f 6e61 6c0a 2020 2020 2020 5468 6520  ional.      The 
+0000b090: 6469 6d65 6e73 696f 6e73 206f 6620 7468  dimensions of th
+0000b0a0: 6520 7265 7475 726e 6564 2061 7272 6179  e returned array
+0000b0b0: 2c20 6d75 7374 2062 6520 6e6f 6e2d 6e65  , must be non-ne
+0000b0c0: 6761 7469 7665 2e0a 2020 2020 2020 4966  gative..      If
+0000b0d0: 206e 6f20 6172 6775 6d65 6e74 2069 7320   no argument is 
+0000b0e0: 6769 7665 6e20 6120 7369 6e67 6c65 2050  given a single P
+0000b0f0: 7974 686f 6e20 666c 6f61 7420 6973 2072  ython float is r
+0000b100: 6574 7572 6e65 642e 0a0a 2020 5265 7475  eturned...  Retu
+0000b110: 726e 730a 2020 2d2d 2d2d 2d2d 2d0a 2020  rns.  -------.  
+0000b120: 6f75 7420 3a20 6e64 6172 7261 792c 2073  out : ndarray, s
+0000b130: 6861 7065 2060 6028 6430 2c20 6431 2c20  hape ``(d0, d1, 
+0000b140: 2e2e 2e2c 2064 6e29 6060 0a20 2020 2020  ..., dn)``.     
+0000b150: 2052 616e 646f 6d20 7661 6c75 6573 2e0a   Random values..
+0000b160: 0a20 2053 6565 2041 6c73 6f0a 2020 2d2d  .  See Also.  --
+0000b170: 2d2d 2d2d 2d2d 0a20 2072 616e 646f 6d0a  ------.  random.
+0000b180: 0a20 2045 7861 6d70 6c65 730a 2020 2d2d  .  Examples.  --
+0000b190: 2d2d 2d2d 2d2d 0a20 203e 3e3e 2062 7261  ------.  >>> bra
+0000b1a0: 696e 7079 2e6d 6174 682e 7261 6e64 6f6d  inpy.math.random
+0000b1b0: 2e72 616e 6428 332c 3229 0a20 2061 7272  .rand(3,2).  arr
+0000b1c0: 6179 285b 5b20 302e 3134 3032 3234 3731  ay([[ 0.14022471
+0000b1d0: 2c20 2030 2e39 3633 3630 3631 385d 2c20  ,  0.96360618], 
+0000b1e0: 2023 7261 6e64 6f6d 0a20 2020 2020 2020   #random.       
+0000b1f0: 2020 5b20 302e 3337 3630 3130 3332 2c20    [ 0.37601032, 
+0000b200: 2030 2e32 3535 3238 3431 315d 2c20 2023   0.25528411],  #
+0000b210: 7261 6e64 6f6d 0a20 2020 2020 2020 2020  random.         
+0000b220: 5b20 302e 3439 3331 3330 3439 2c20 2030  [ 0.49313049,  0
+0000b230: 2e39 3439 3039 3837 385d 5d29 2023 7261  .94909878]]) #ra
+0000b240: 6e64 6f6d 0a20 2022 2222 0a20 2072 6574  ndom.  """.  ret
+0000b250: 7572 6e20 4445 4641 554c 542e 7261 6e64  urn DEFAULT.rand
+0000b260: 282a 646e 2c20 6b65 793d 6b65 7929 0a0a  (*dn, key=key)..
+0000b270: 0a64 6566 2072 616e 6469 6e74 286c 6f77  .def randint(low
+0000b280: 2c20 6869 6768 3d4e 6f6e 652c 2073 697a  , high=None, siz
+0000b290: 653d 4e6f 6e65 2c20 6474 7970 653d 6a6e  e=None, dtype=jn
+0000b2a0: 702e 696e 745f 2c20 6b65 793d 4e6f 6e65  p.int_, key=None
+0000b2b0: 293a 0a20 2072 2222 2252 6574 7572 6e20  ):.  r"""Return 
+0000b2c0: 7261 6e64 6f6d 2069 6e74 6567 6572 7320  random integers 
+0000b2d0: 6672 6f6d 2060 6c6f 7760 2028 696e 636c  from `low` (incl
+0000b2e0: 7573 6976 6529 2074 6f20 6068 6967 6860  usive) to `high`
+0000b2f0: 2028 6578 636c 7573 6976 6529 2e0a 0a20   (exclusive)... 
+0000b300: 2052 6574 7572 6e20 7261 6e64 6f6d 2069   Return random i
+0000b310: 6e74 6567 6572 7320 6672 6f6d 2074 6865  ntegers from the
+0000b320: 2022 6469 7363 7265 7465 2075 6e69 666f   "discrete unifo
+0000b330: 726d 2220 6469 7374 7269 6275 7469 6f6e  rm" distribution
+0000b340: 206f 660a 2020 7468 6520 7370 6563 6966   of.  the specif
+0000b350: 6965 6420 6474 7970 6520 696e 2074 6865  ied dtype in the
+0000b360: 2022 6861 6c66 2d6f 7065 6e22 2069 6e74   "half-open" int
+0000b370: 6572 7661 6c20 5b60 6c6f 7760 2c20 6068  erval [`low`, `h
+0000b380: 6967 6860 292e 2049 660a 2020 6068 6967  igh`). If.  `hig
+0000b390: 6860 2069 7320 4e6f 6e65 2028 7468 6520  h` is None (the 
+0000b3a0: 6465 6661 756c 7429 2c20 7468 656e 2072  default), then r
+0000b3b0: 6573 756c 7473 2061 7265 2066 726f 6d20  esults are from 
+0000b3c0: 5b30 2c20 606c 6f77 6029 2e0a 0a20 2050  [0, `low`)...  P
+0000b3d0: 6172 616d 6574 6572 730a 2020 2d2d 2d2d  arameters.  ----
+0000b3e0: 2d2d 2d2d 2d2d 0a20 206c 6f77 203a 2069  ------.  low : i
+0000b3f0: 6e74 206f 7220 6172 7261 792d 6c69 6b65  nt or array-like
+0000b400: 206f 6620 696e 7473 0a20 2020 2020 204c   of ints.      L
+0000b410: 6f77 6573 7420 2873 6967 6e65 6429 2069  owest (signed) i
+0000b420: 6e74 6567 6572 7320 746f 2062 6520 6472  ntegers to be dr
+0000b430: 6177 6e20 6672 6f6d 2074 6865 2064 6973  awn from the dis
+0000b440: 7472 6962 7574 696f 6e20 2875 6e6c 6573  tribution (unles
+0000b450: 730a 2020 2020 2020 6060 6869 6768 3d4e  s.      ``high=N
+0000b460: 6f6e 6560 602c 2069 6e20 7768 6963 6820  one``, in which 
+0000b470: 6361 7365 2074 6869 7320 7061 7261 6d65  case this parame
+0000b480: 7465 7220 6973 206f 6e65 2061 626f 7665  ter is one above
+0000b490: 2074 6865 0a20 2020 2020 202a 6869 6768   the.      *high
+0000b4a0: 6573 742a 2073 7563 6820 696e 7465 6765  est* such intege
+0000b4b0: 7229 2e0a 2020 6869 6768 203a 2069 6e74  r)..  high : int
+0000b4c0: 206f 7220 6172 7261 792d 6c69 6b65 206f   or array-like o
+0000b4d0: 6620 696e 7473 2c20 6f70 7469 6f6e 616c  f ints, optional
+0000b4e0: 0a20 2020 2020 2049 6620 7072 6f76 6964  .      If provid
+0000b4f0: 6564 2c20 6f6e 6520 6162 6f76 6520 7468  ed, one above th
+0000b500: 6520 6c61 7267 6573 7420 2873 6967 6e65  e largest (signe
+0000b510: 6429 2069 6e74 6567 6572 2074 6f20 6265  d) integer to be
+0000b520: 2064 7261 776e 0a20 2020 2020 2066 726f   drawn.      fro
+0000b530: 6d20 7468 6520 6469 7374 7269 6275 7469  m the distributi
+0000b540: 6f6e 2028 7365 6520 6162 6f76 6520 666f  on (see above fo
+0000b550: 7220 6265 6861 7669 6f72 2069 6620 6060  r behavior if ``
+0000b560: 6869 6768 3d4e 6f6e 6560 6029 2e0a 2020  high=None``)..  
+0000b570: 2020 2020 4966 2061 7272 6179 2d6c 696b      If array-lik
+0000b580: 652c 206d 7573 7420 636f 6e74 6169 6e20  e, must contain 
+0000b590: 696e 7465 6765 7220 7661 6c75 6573 0a20  integer values. 
+0000b5a0: 2073 697a 6520 3a20 696e 7420 6f72 2074   size : int or t
+0000b5b0: 7570 6c65 206f 6620 696e 7473 2c20 6f70  uple of ints, op
+0000b5c0: 7469 6f6e 616c 0a20 2020 2020 204f 7574  tional.      Out
+0000b5d0: 7075 7420 7368 6170 652e 2020 4966 2074  put shape.  If t
+0000b5e0: 6865 2067 6976 656e 2073 6861 7065 2069  he given shape i
+0000b5f0: 732c 2065 2e67 2e2c 2060 6028 6d2c 206e  s, e.g., ``(m, n
+0000b600: 2c20 6b29 6060 2c20 7468 656e 0a20 2020  , k)``, then.   
+0000b610: 2020 2060 606d 202a 206e 202a 206b 6060     ``m * n * k``
+0000b620: 2073 616d 706c 6573 2061 7265 2064 7261   samples are dra
+0000b630: 776e 2e20 2044 6566 6175 6c74 2069 7320  wn.  Default is 
+0000b640: 4e6f 6e65 2c20 696e 2077 6869 6368 2063  None, in which c
+0000b650: 6173 6520 610a 2020 2020 2020 7369 6e67  ase a.      sing
+0000b660: 6c65 2076 616c 7565 2069 7320 7265 7475  le value is retu
+0000b670: 726e 6564 2e0a 2020 6474 7970 6520 3a20  rned..  dtype : 
+0000b680: 6474 7970 652c 206f 7074 696f 6e61 6c0a  dtype, optional.
+0000b690: 2020 2020 2020 4465 7369 7265 6420 6474        Desired dt
+0000b6a0: 7970 6520 6f66 2074 6865 2072 6573 756c  ype of the resul
+0000b6b0: 742e 2042 7974 656f 7264 6572 206d 7573  t. Byteorder mus
+0000b6c0: 7420 6265 206e 6174 6976 652e 0a20 2020  t be native..   
+0000b6d0: 2020 2054 6865 2064 6566 6175 6c74 2076     The default v
+0000b6e0: 616c 7565 2069 7320 696e 742e 0a0a 2020  alue is int...  
+0000b6f0: 5265 7475 726e 730a 2020 2d2d 2d2d 2d2d  Returns.  ------
+0000b700: 2d0a 2020 6f75 7420 3a20 696e 7420 6f72  -.  out : int or
+0000b710: 206e 6461 7272 6179 206f 6620 696e 7473   ndarray of ints
+0000b720: 0a20 2020 2020 2060 7369 7a65 602d 7368  .      `size`-sh
+0000b730: 6170 6564 2061 7272 6179 206f 6620 7261  aped array of ra
+0000b740: 6e64 6f6d 2069 6e74 6567 6572 7320 6672  ndom integers fr
+0000b750: 6f6d 2074 6865 2061 7070 726f 7072 6961  om the appropria
+0000b760: 7465 0a20 2020 2020 2064 6973 7472 6962  te.      distrib
+0000b770: 7574 696f 6e2c 206f 7220 6120 7369 6e67  ution, or a sing
+0000b780: 6c65 2073 7563 6820 7261 6e64 6f6d 2069  le such random i
+0000b790: 6e74 2069 6620 6073 697a 6560 206e 6f74  nt if `size` not
+0000b7a0: 2070 726f 7669 6465 642e 0a0a 2020 5365   provided...  Se
+0000b7b0: 6520 416c 736f 0a20 202d 2d2d 2d2d 2d2d  e Also.  -------
+0000b7c0: 2d0a 2020 7261 6e64 6f6d 5f69 6e74 6567  -.  random_integ
+0000b7d0: 6572 7320 3a20 7369 6d69 6c61 7220 746f  ers : similar to
+0000b7e0: 2060 7261 6e64 696e 7460 2c20 6f6e 6c79   `randint`, only
+0000b7f0: 2066 6f72 2074 6865 2063 6c6f 7365 640a   for the closed.
+0000b800: 2020 2020 2020 696e 7465 7276 616c 205b        interval [
+0000b810: 606c 6f77 602c 2060 6869 6768 605d 2c20  `low`, `high`], 
+0000b820: 616e 6420 3120 6973 2074 6865 206c 6f77  and 1 is the low
+0000b830: 6573 7420 7661 6c75 6520 6966 2060 6869  est value if `hi
+0000b840: 6768 6020 6973 0a20 2020 2020 206f 6d69  gh` is.      omi
+0000b850: 7474 6564 2e0a 2020 4765 6e65 7261 746f  tted..  Generato
+0000b860: 722e 696e 7465 6765 7273 3a20 7768 6963  r.integers: whic
+0000b870: 6820 7368 6f75 6c64 2062 6520 7573 6564  h should be used
+0000b880: 2066 6f72 206e 6577 2063 6f64 652e 0a0a   for new code...
+0000b890: 2020 4578 616d 706c 6573 0a20 202d 2d2d    Examples.  ---
+0000b8a0: 2d2d 2d2d 2d0a 2020 3e3e 3e20 696d 706f  -----.  >>> impo
+0000b8b0: 7274 2062 7261 696e 7079 2e6d 6174 6820  rt brainpy.math 
+0000b8c0: 6173 2062 6d0a 2020 3e3e 3e20 626d 2e72  as bm.  >>> bm.r
+0000b8d0: 616e 646f 6d2e 7261 6e64 696e 7428 322c  andom.randint(2,
+0000b8e0: 2073 697a 653d 3130 290a 2020 6172 7261   size=10).  arra
+0000b8f0: 7928 5b31 2c20 302c 2030 2c20 302c 2031  y([1, 0, 0, 0, 1
+0000b900: 2c20 312c 2030 2c20 302c 2031 2c20 305d  , 1, 0, 0, 1, 0]
+0000b910: 2920 2320 7261 6e64 6f6d 0a20 203e 3e3e  ) # random.  >>>
+0000b920: 2062 6d2e 7261 6e64 6f6d 2e72 616e 6469   bm.random.randi
+0000b930: 6e74 2831 2c20 7369 7a65 3d31 3029 0a20  nt(1, size=10). 
+0000b940: 2061 7272 6179 285b 302c 2030 2c20 302c   array([0, 0, 0,
+0000b950: 2030 2c20 302c 2030 2c20 302c 2030 2c20   0, 0, 0, 0, 0, 
+0000b960: 302c 2030 5d29 0a0a 2020 4765 6e65 7261  0, 0])..  Genera
+0000b970: 7465 2061 2032 2078 2034 2061 7272 6179  te a 2 x 4 array
+0000b980: 206f 6620 696e 7473 2062 6574 7765 656e   of ints between
+0000b990: 2030 2061 6e64 2034 2c20 696e 636c 7573   0 and 4, inclus
+0000b9a0: 6976 653a 0a0a 2020 3e3e 3e20 626d 2e72  ive:..  >>> bm.r
+0000b9b0: 616e 646f 6d2e 7261 6e64 696e 7428 352c  andom.randint(5,
+0000b9c0: 2073 697a 653d 2832 2c20 3429 290a 2020   size=(2, 4)).  
+0000b9d0: 6172 7261 7928 5b5b 342c 2030 2c20 322c  array([[4, 0, 2,
+0000b9e0: 2031 5d2c 2023 2072 616e 646f 6d0a 2020   1], # random.  
+0000b9f0: 2020 2020 2020 205b 332c 2032 2c20 322c         [3, 2, 2,
+0000ba00: 2030 5d5d 290a 0a20 2047 656e 6572 6174   0]])..  Generat
+0000ba10: 6520 6120 3120 7820 3320 6172 7261 7920  e a 1 x 3 array 
+0000ba20: 7769 7468 2033 2064 6966 6665 7265 6e74  with 3 different
+0000ba30: 2075 7070 6572 2062 6f75 6e64 730a 0a20   upper bounds.. 
+0000ba40: 203e 3e3e 2062 6d2e 7261 6e64 6f6d 2e72   >>> bm.random.r
+0000ba50: 616e 6469 6e74 2831 2c20 5b33 2c20 352c  andint(1, [3, 5,
+0000ba60: 2031 305d 290a 2020 6172 7261 7928 5b32   10]).  array([2
+0000ba70: 2c20 322c 2039 5d29 2023 2072 616e 646f  , 2, 9]) # rando
+0000ba80: 6d0a 0a20 2047 656e 6572 6174 6520 6120  m..  Generate a 
+0000ba90: 3120 6279 2033 2061 7272 6179 2077 6974  1 by 3 array wit
+0000baa0: 6820 3320 6469 6666 6572 656e 7420 6c6f  h 3 different lo
+0000bab0: 7765 7220 626f 756e 6473 0a0a 2020 3e3e  wer bounds..  >>
+0000bac0: 3e20 626d 2e72 616e 646f 6d2e 7261 6e64  > bm.random.rand
+0000bad0: 696e 7428 5b31 2c20 352c 2037 5d2c 2031  int([1, 5, 7], 1
+0000bae0: 3029 0a20 2061 7272 6179 285b 392c 2038  0).  array([9, 8
+0000baf0: 2c20 375d 2920 2320 7261 6e64 6f6d 0a0a  , 7]) # random..
+0000bb00: 2020 4765 6e65 7261 7465 2061 2032 2062    Generate a 2 b
+0000bb10: 7920 3420 6172 7261 7920 7573 696e 6720  y 4 array using 
+0000bb20: 6272 6f61 6463 6173 7469 6e67 2077 6974  broadcasting wit
+0000bb30: 6820 6474 7970 6520 6f66 2075 696e 7438  h dtype of uint8
+0000bb40: 0a0a 2020 3e3e 3e20 626d 2e72 616e 646f  ..  >>> bm.rando
+0000bb50: 6d2e 7261 6e64 696e 7428 5b31 2c20 332c  m.randint([1, 3,
+0000bb60: 2035 2c20 375d 2c20 5b5b 3130 5d2c 205b   5, 7], [[10], [
+0000bb70: 3230 5d5d 2c20 6474 7970 653d 6e70 2e75  20]], dtype=np.u
+0000bb80: 696e 7438 290a 2020 6172 7261 7928 5b5b  int8).  array([[
+0000bb90: 2038 2c20 2036 2c20 2039 2c20 2037 5d2c   8,  6,  9,  7],
+0000bba0: 2023 2072 616e 646f 6d0a 2020 2020 2020   # random.      
+0000bbb0: 2020 205b 2031 2c20 3136 2c20 2039 2c20     [ 1, 16,  9, 
+0000bbc0: 3132 5d5d 2c20 6474 7970 653d 7569 6e74  12]], dtype=uint
+0000bbd0: 3829 0a20 2022 2222 0a0a 2020 7265 7475  8).  """..  retu
+0000bbe0: 726e 2044 4546 4155 4c54 2e72 616e 6469  rn DEFAULT.randi
+0000bbf0: 6e74 286c 6f77 2c20 6869 6768 3d68 6967  nt(low, high=hig
+0000bc00: 682c 2073 697a 653d 7369 7a65 2c20 6474  h, size=size, dt
+0000bc10: 7970 653d 6474 7970 652c 206b 6579 3d6b  ype=dtype, key=k
+0000bc20: 6579 290a 0a0a 6465 6620 7261 6e64 6f6d  ey)...def random
+0000bc30: 5f69 6e74 6567 6572 7328 6c6f 772c 2068  _integers(low, h
+0000bc40: 6967 683d 4e6f 6e65 2c20 7369 7a65 3d4e  igh=None, size=N
+0000bc50: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+0000bc60: 2020 7222 2222 0a20 2052 616e 646f 6d20    r""".  Random 
+0000bc70: 696e 7465 6765 7273 206f 6620 7479 7065  integers of type
+0000bc80: 2060 6e70 2e69 6e74 5f60 2062 6574 7765   `np.int_` betwe
+0000bc90: 656e 2060 6c6f 7760 2061 6e64 2060 6869  en `low` and `hi
+0000bca0: 6768 602c 2069 6e63 6c75 7369 7665 2e0a  gh`, inclusive..
+0000bcb0: 0a20 2052 6574 7572 6e20 7261 6e64 6f6d  .  Return random
+0000bcc0: 2069 6e74 6567 6572 7320 6f66 2074 7970   integers of typ
+0000bcd0: 6520 606e 702e 696e 745f 6020 6672 6f6d  e `np.int_` from
+0000bce0: 2074 6865 2022 6469 7363 7265 7465 2075   the "discrete u
+0000bcf0: 6e69 666f 726d 220a 2020 6469 7374 7269  niform".  distri
+0000bd00: 6275 7469 6f6e 2069 6e20 7468 6520 636c  bution in the cl
+0000bd10: 6f73 6564 2069 6e74 6572 7661 6c20 5b60  osed interval [`
+0000bd20: 6c6f 7760 2c20 6068 6967 6860 5d2e 2020  low`, `high`].  
+0000bd30: 4966 2060 6869 6768 6020 6973 0a20 204e  If `high` is.  N
+0000bd40: 6f6e 6520 2874 6865 2064 6566 6175 6c74  one (the default
+0000bd50: 292c 2074 6865 6e20 7265 7375 6c74 7320  ), then results 
+0000bd60: 6172 6520 6672 6f6d 205b 312c 2060 6c6f  are from [1, `lo
+0000bd70: 7760 5d2e 2054 6865 2060 6e70 2e69 6e74  w`]. The `np.int
+0000bd80: 5f60 0a20 2074 7970 6520 7472 616e 736c  _`.  type transl
+0000bd90: 6174 6573 2074 6f20 7468 6520 4320 6c6f  ates to the C lo
+0000bda0: 6e67 2069 6e74 6567 6572 2074 7970 6520  ng integer type 
+0000bdb0: 616e 6420 6974 7320 7072 6563 6973 696f  and its precisio
+0000bdc0: 6e0a 2020 6973 2070 6c61 7466 6f72 6d20  n.  is platform 
+0000bdd0: 6465 7065 6e64 656e 742e 0a0a 2020 5061  dependent...  Pa
+0000bde0: 7261 6d65 7465 7273 0a20 202d 2d2d 2d2d  rameters.  -----
+0000bdf0: 2d2d 2d2d 2d0a 2020 6c6f 7720 3a20 696e  -----.  low : in
+0000be00: 740a 2020 2020 2020 4c6f 7765 7374 2028  t.      Lowest (
+0000be10: 7369 676e 6564 2920 696e 7465 6765 7220  signed) integer 
+0000be20: 746f 2062 6520 6472 6177 6e20 6672 6f6d  to be drawn from
+0000be30: 2074 6865 2064 6973 7472 6962 7574 696f   the distributio
+0000be40: 6e20 2875 6e6c 6573 730a 2020 2020 2020  n (unless.      
+0000be50: 6060 6869 6768 3d4e 6f6e 6560 602c 2069  ``high=None``, i
+0000be60: 6e20 7768 6963 6820 6361 7365 2074 6869  n which case thi
+0000be70: 7320 7061 7261 6d65 7465 7220 6973 2074  s parameter is t
+0000be80: 6865 202a 6869 6768 6573 742a 2073 7563  he *highest* suc
+0000be90: 680a 2020 2020 2020 696e 7465 6765 7229  h.      integer)
+0000bea0: 2e0a 2020 6869 6768 203a 2069 6e74 2c20  ..  high : int, 
+0000beb0: 6f70 7469 6f6e 616c 0a20 2020 2020 2049  optional.      I
+0000bec0: 6620 7072 6f76 6964 6564 2c20 7468 6520  f provided, the 
+0000bed0: 6c61 7267 6573 7420 2873 6967 6e65 6429  largest (signed)
+0000bee0: 2069 6e74 6567 6572 2074 6f20 6265 2064   integer to be d
+0000bef0: 7261 776e 2066 726f 6d20 7468 650a 2020  rawn from the.  
+0000bf00: 2020 2020 6469 7374 7269 6275 7469 6f6e      distribution
+0000bf10: 2028 7365 6520 6162 6f76 6520 666f 7220   (see above for 
+0000bf20: 6265 6861 7669 6f72 2069 6620 6060 6869  behavior if ``hi
+0000bf30: 6768 3d4e 6f6e 6560 6029 2e0a 2020 7369  gh=None``)..  si
+0000bf40: 7a65 203a 2069 6e74 206f 7220 7475 706c  ze : int or tupl
+0000bf50: 6520 6f66 2069 6e74 732c 206f 7074 696f  e of ints, optio
+0000bf60: 6e61 6c0a 2020 2020 2020 4f75 7470 7574  nal.      Output
+0000bf70: 2073 6861 7065 2e20 2049 6620 7468 6520   shape.  If the 
+0000bf80: 6769 7665 6e20 7368 6170 6520 6973 2c20  given shape is, 
+0000bf90: 652e 672e 2c20 6060 286d 2c20 6e2c 206b  e.g., ``(m, n, k
+0000bfa0: 2960 602c 2074 6865 6e0a 2020 2020 2020  )``, then.      
+0000bfb0: 6060 6d20 2a20 6e20 2a20 6b60 6020 7361  ``m * n * k`` sa
+0000bfc0: 6d70 6c65 7320 6172 6520 6472 6177 6e2e  mples are drawn.
+0000bfd0: 2020 4465 6661 756c 7420 6973 204e 6f6e    Default is Non
+0000bfe0: 652c 2069 6e20 7768 6963 6820 6361 7365  e, in which case
+0000bff0: 2061 0a20 2020 2020 2073 696e 676c 6520   a.      single 
+0000c000: 7661 6c75 6520 6973 2072 6574 7572 6e65  value is returne
+0000c010: 642e 0a0a 2020 5265 7475 726e 730a 2020  d...  Returns.  
+0000c020: 2d2d 2d2d 2d2d 2d0a 2020 6f75 7420 3a20  -------.  out : 
+0000c030: 696e 7420 6f72 206e 6461 7272 6179 206f  int or ndarray o
+0000c040: 6620 696e 7473 0a20 2020 2020 2060 7369  f ints.      `si
+0000c050: 7a65 602d 7368 6170 6564 2061 7272 6179  ze`-shaped array
+0000c060: 206f 6620 7261 6e64 6f6d 2069 6e74 6567   of random integ
+0000c070: 6572 7320 6672 6f6d 2074 6865 2061 7070  ers from the app
+0000c080: 726f 7072 6961 7465 0a20 2020 2020 2064  ropriate.      d
+0000c090: 6973 7472 6962 7574 696f 6e2c 206f 7220  istribution, or 
+0000c0a0: 6120 7369 6e67 6c65 2073 7563 6820 7261  a single such ra
+0000c0b0: 6e64 6f6d 2069 6e74 2069 6620 6073 697a  ndom int if `siz
+0000c0c0: 6560 206e 6f74 2070 726f 7669 6465 642e  e` not provided.
+0000c0d0: 0a0a 2020 5365 6520 416c 736f 0a20 202d  ..  See Also.  -
+0000c0e0: 2d2d 2d2d 2d2d 2d0a 2020 7261 6e64 696e  -------.  randin
+0000c0f0: 7420 3a20 5369 6d69 6c61 7220 746f 2060  t : Similar to `
+0000c100: 7261 6e64 6f6d 5f69 6e74 6567 6572 7360  random_integers`
+0000c110: 2c20 6f6e 6c79 2066 6f72 2074 6865 2068  , only for the h
+0000c120: 616c 662d 6f70 656e 0a20 2020 2020 2069  alf-open.      i
+0000c130: 6e74 6572 7661 6c20 5b60 6c6f 7760 2c20  nterval [`low`, 
+0000c140: 6068 6967 6860 292c 2061 6e64 2030 2069  `high`), and 0 i
+0000c150: 7320 7468 6520 6c6f 7765 7374 2076 616c  s the lowest val
+0000c160: 7565 2069 6620 6068 6967 6860 2069 730a  ue if `high` is.
+0000c170: 2020 2020 2020 6f6d 6974 7465 642e 0a0a        omitted...
+0000c180: 2020 4e6f 7465 730a 2020 2d2d 2d2d 2d0a    Notes.  -----.
+0000c190: 2020 546f 2073 616d 706c 6520 6672 6f6d    To sample from
+0000c1a0: 204e 2065 7665 6e6c 7920 7370 6163 6564   N evenly spaced
+0000c1b0: 2066 6c6f 6174 696e 672d 706f 696e 7420   floating-point 
+0000c1c0: 6e75 6d62 6572 7320 6265 7477 6565 6e20  numbers between 
+0000c1d0: 6120 616e 6420 622c 0a20 2075 7365 3a3a  a and b,.  use::
+0000c1e0: 0a0a 2020 2020 6120 2b20 2862 202d 2061  ..    a + (b - a
+0000c1f0: 2920 2a20 2862 6d2e 7261 6e64 6f6d 2e72  ) * (bm.random.r
+0000c200: 616e 646f 6d5f 696e 7465 6765 7273 284e  andom_integers(N
+0000c210: 2920 2d20 3129 202f 2028 4e20 2d20 312e  ) - 1) / (N - 1.
+0000c220: 290a 0a20 2045 7861 6d70 6c65 730a 2020  )..  Examples.  
+0000c230: 2d2d 2d2d 2d2d 2d2d 0a20 203e 3e3e 2069  --------.  >>> i
+0000c240: 6d70 6f72 7420 6272 6169 6e70 792e 6d61  mport brainpy.ma
+0000c250: 7468 2061 7320 626d 0a20 203e 3e3e 2062  th as bm.  >>> b
+0000c260: 6d2e 7261 6e64 6f6d 2e72 616e 646f 6d5f  m.random.random_
+0000c270: 696e 7465 6765 7273 2835 290a 2020 3420  integers(5).  4 
+0000c280: 2320 7261 6e64 6f6d 0a20 203e 3e3e 2074  # random.  >>> t
+0000c290: 7970 6528 626d 2e72 616e 646f 6d2e 7261  ype(bm.random.ra
+0000c2a0: 6e64 6f6d 5f69 6e74 6567 6572 7328 3529  ndom_integers(5)
+0000c2b0: 290a 2020 3c63 6c61 7373 2027 6e75 6d70  ).  <class 'nump
+0000c2c0: 792e 696e 7436 3427 3e0a 2020 3e3e 3e20  y.int64'>.  >>> 
+0000c2d0: 626d 2e72 616e 646f 6d2e 7261 6e64 6f6d  bm.random.random
+0000c2e0: 5f69 6e74 6567 6572 7328 352c 2073 697a  _integers(5, siz
+0000c2f0: 653d 2833 2c32 2929 0a20 2061 7272 6179  e=(3,2)).  array
+0000c300: 285b 5b35 2c20 345d 2c20 2320 7261 6e64  ([[5, 4], # rand
+0000c310: 6f6d 0a20 2020 2020 2020 2020 5b33 2c20  om.         [3, 
+0000c320: 335d 2c0a 2020 2020 2020 2020 205b 342c  3],.         [4,
+0000c330: 2035 5d5d 290a 0a20 2043 686f 6f73 6520   5]])..  Choose 
+0000c340: 6669 7665 2072 616e 646f 6d20 6e75 6d62  five random numb
+0000c350: 6572 7320 6672 6f6d 2074 6865 2073 6574  ers from the set
+0000c360: 206f 6620 6669 7665 2065 7665 6e6c 792d   of five evenly-
+0000c370: 7370 6163 6564 0a20 206e 756d 6265 7273  spaced.  numbers
+0000c380: 2062 6574 7765 656e 2030 2061 6e64 2032   between 0 and 2
+0000c390: 2e35 2c20 696e 636c 7573 6976 6520 282a  .5, inclusive (*
+0000c3a0: 692e 652e 2a2c 2066 726f 6d20 7468 6520  i.e.*, from the 
+0000c3b0: 7365 740a 2020 3a6d 6174 683a 607b 302c  set.  :math:`{0,
+0000c3c0: 2035 2f38 2c20 3130 2f38 2c20 3135 2f38   5/8, 10/8, 15/8
+0000c3d0: 2c20 3230 2f38 7d60 293a 0a0a 2020 3e3e  , 20/8}`):..  >>
+0000c3e0: 3e20 322e 3520 2a20 2862 6d2e 7261 6e64  > 2.5 * (bm.rand
+0000c3f0: 6f6d 2e72 616e 646f 6d5f 696e 7465 6765  om.random_intege
+0000c400: 7273 2835 2c20 7369 7a65 3d28 352c 2929  rs(5, size=(5,))
+0000c410: 202d 2031 2920 2f20 342e 0a20 2061 7272   - 1) / 4..  arr
+0000c420: 6179 285b 2030 2e36 3235 2c20 2031 2e32  ay([ 0.625,  1.2
+0000c430: 3520 2c20 2030 2e36 3235 2c20 2030 2e36  5 ,  0.625,  0.6
+0000c440: 3235 2c20 2032 2e35 2020 5d29 2023 2072  25,  2.5  ]) # r
+0000c450: 616e 646f 6d0a 0a20 2052 6f6c 6c20 7477  andom..  Roll tw
+0000c460: 6f20 7369 7820 7369 6465 6420 6469 6365  o six sided dice
+0000c470: 2031 3030 3020 7469 6d65 7320 616e 6420   1000 times and 
+0000c480: 7375 6d20 7468 6520 7265 7375 6c74 733a  sum the results:
+0000c490: 0a0a 2020 3e3e 3e20 6431 203d 2062 6d2e  ..  >>> d1 = bm.
+0000c4a0: 7261 6e64 6f6d 2e72 616e 646f 6d5f 696e  random.random_in
+0000c4b0: 7465 6765 7273 2831 2c20 362c 2031 3030  tegers(1, 6, 100
+0000c4c0: 3029 0a20 203e 3e3e 2064 3220 3d20 626d  0).  >>> d2 = bm
+0000c4d0: 2e72 616e 646f 6d2e 7261 6e64 6f6d 5f69  .random.random_i
+0000c4e0: 6e74 6567 6572 7328 312c 2036 2c20 3130  ntegers(1, 6, 10
+0000c4f0: 3030 290a 2020 3e3e 3e20 6473 756d 7320  00).  >>> dsums 
+0000c500: 3d20 6431 202b 2064 320a 0a20 2044 6973  = d1 + d2..  Dis
+0000c510: 706c 6179 2072 6573 756c 7473 2061 7320  play results as 
+0000c520: 6120 6869 7374 6f67 7261 6d3a 0a0a 2020  a histogram:..  
+0000c530: 3e3e 3e20 696d 706f 7274 206d 6174 706c  >>> import matpl
+0000c540: 6f74 6c69 622e 7079 706c 6f74 2061 7320  otlib.pyplot as 
+0000c550: 706c 740a 2020 3e3e 3e20 636f 756e 742c  plt.  >>> count,
+0000c560: 2062 696e 732c 2069 676e 6f72 6564 203d   bins, ignored =
+0000c570: 2070 6c74 2e68 6973 7428 6473 756d 732c   plt.hist(dsums,
+0000c580: 2031 312c 2064 656e 7369 7479 3d54 7275   11, density=Tru
+0000c590: 6529 0a20 203e 3e3e 2070 6c74 2e73 686f  e).  >>> plt.sho
+0000c5a0: 7728 290a 2020 2222 220a 0a20 2072 6574  w().  """..  ret
+0000c5b0: 7572 6e20 4445 4641 554c 542e 7261 6e64  urn DEFAULT.rand
+0000c5c0: 6f6d 5f69 6e74 6567 6572 7328 6c6f 772c  om_integers(low,
+0000c5d0: 2068 6967 683d 6869 6768 2c20 7369 7a65   high=high, size
+0000c5e0: 3d73 697a 652c 206b 6579 3d6b 6579 290a  =size, key=key).
+0000c5f0: 0a0a 6465 6620 7261 6e64 6e28 2a64 6e2c  ..def randn(*dn,
+0000c600: 206b 6579 3d4e 6f6e 6529 3a0a 2020 7222   key=None):.  r"
+0000c610: 2222 0a20 2052 6574 7572 6e20 6120 7361  "".  Return a sa
+0000c620: 6d70 6c65 2028 6f72 2073 616d 706c 6573  mple (or samples
+0000c630: 2920 6672 6f6d 2074 6865 2022 7374 616e  ) from the "stan
+0000c640: 6461 7264 206e 6f72 6d61 6c22 2064 6973  dard normal" dis
+0000c650: 7472 6962 7574 696f 6e2e 0a0a 2020 2e2e  tribution...  ..
+0000c660: 206e 6f74 653a 3a0a 2020 2020 2020 5468   note::.      Th
+0000c670: 6973 2069 7320 6120 636f 6e76 656e 6965  is is a convenie
+0000c680: 6e63 6520 6675 6e63 7469 6f6e 2066 6f72  nce function for
+0000c690: 2075 7365 7273 2070 6f72 7469 6e67 2063   users porting c
+0000c6a0: 6f64 6520 6672 6f6d 204d 6174 6c61 622c  ode from Matlab,
+0000c6b0: 0a20 2020 2020 2061 6e64 2077 7261 7073  .      and wraps
+0000c6c0: 2060 7374 616e 6461 7264 5f6e 6f72 6d61   `standard_norma
+0000c6d0: 6c60 2e20 5468 6174 2066 756e 6374 696f  l`. That functio
+0000c6e0: 6e20 7461 6b65 7320 610a 2020 2020 2020  n takes a.      
+0000c6f0: 7475 706c 6520 746f 2073 7065 6369 6679  tuple to specify
+0000c700: 2074 6865 2073 697a 6520 6f66 2074 6865   the size of the
+0000c710: 206f 7574 7075 742c 2077 6869 6368 2069   output, which i
+0000c720: 7320 636f 6e73 6973 7465 6e74 2077 6974  s consistent wit
+0000c730: 680a 2020 2020 2020 6f74 6865 7220 4e75  h.      other Nu
+0000c740: 6d50 7920 6675 6e63 7469 6f6e 7320 6c69  mPy functions li
+0000c750: 6b65 2060 6e75 6d70 792e 7a65 726f 7360  ke `numpy.zeros`
+0000c760: 2061 6e64 2060 6e75 6d70 792e 6f6e 6573   and `numpy.ones
+0000c770: 602e 0a0a 2020 2e2e 206e 6f74 653a 3a0a  `...  .. note::.
+0000c780: 2020 2020 2020 4e65 7720 636f 6465 2073        New code s
+0000c790: 686f 756c 6420 7573 6520 7468 6520 6060  hould use the ``
+0000c7a0: 7374 616e 6461 7264 5f6e 6f72 6d61 6c60  standard_normal`
+0000c7b0: 6020 6d65 7468 6f64 206f 6620 6120 6060  ` method of a ``
+0000c7c0: 6465 6661 756c 745f 726e 6728 2960 600a  default_rng()``.
+0000c7d0: 2020 2020 2020 696e 7374 616e 6365 2069        instance i
+0000c7e0: 6e73 7465 6164 3b20 706c 6561 7365 2073  nstead; please s
+0000c7f0: 6565 2074 6865 203a 7265 663a 6072 616e  ee the :ref:`ran
+0000c800: 646f 6d2d 7175 6963 6b2d 7374 6172 7460  dom-quick-start`
+0000c810: 2e0a 0a20 2049 6620 706f 7369 7469 7665  ...  If positive
+0000c820: 2069 6e74 5f6c 696b 6520 6172 6775 6d65   int_like argume
+0000c830: 6e74 7320 6172 6520 7072 6f76 6964 6564  nts are provided
+0000c840: 2c20 6072 616e 646e 6020 6765 6e65 7261  , `randn` genera
+0000c850: 7465 7320 616e 2061 7272 6179 0a20 206f  tes an array.  o
+0000c860: 6620 7368 6170 6520 6060 2864 302c 2064  f shape ``(d0, d
+0000c870: 312c 202e 2e2e 2c20 646e 2960 602c 2066  1, ..., dn)``, f
+0000c880: 696c 6c65 640a 2020 7769 7468 2072 616e  illed.  with ran
+0000c890: 646f 6d20 666c 6f61 7473 2073 616d 706c  dom floats sampl
+0000c8a0: 6564 2066 726f 6d20 6120 756e 6976 6172  ed from a univar
+0000c8b0: 6961 7465 2022 6e6f 726d 616c 2220 2847  iate "normal" (G
+0000c8c0: 6175 7373 6961 6e29 0a20 2064 6973 7472  aussian).  distr
+0000c8d0: 6962 7574 696f 6e20 6f66 206d 6561 6e20  ibution of mean 
+0000c8e0: 3020 616e 6420 7661 7269 616e 6365 2031  0 and variance 1
+0000c8f0: 2e20 4120 7369 6e67 6c65 2066 6c6f 6174  . A single float
+0000c900: 2072 616e 646f 6d6c 7920 7361 6d70 6c65   randomly sample
+0000c910: 640a 2020 6672 6f6d 2074 6865 2064 6973  d.  from the dis
+0000c920: 7472 6962 7574 696f 6e20 6973 2072 6574  tribution is ret
+0000c930: 7572 6e65 6420 6966 206e 6f20 6172 6775  urned if no argu
+0000c940: 6d65 6e74 2069 7320 7072 6f76 6964 6564  ment is provided
+0000c950: 2e0a 0a20 2050 6172 616d 6574 6572 730a  ...  Parameters.
+0000c960: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2064    ----------.  d
+0000c970: 302c 2064 312c 202e 2e2e 2c20 646e 203a  0, d1, ..., dn :
+0000c980: 2069 6e74 2c20 6f70 7469 6f6e 616c 0a20   int, optional. 
+0000c990: 2020 2020 2054 6865 2064 696d 656e 7369       The dimensi
+0000c9a0: 6f6e 7320 6f66 2074 6865 2072 6574 7572  ons of the retur
+0000c9b0: 6e65 6420 6172 7261 792c 206d 7573 7420  ned array, must 
+0000c9c0: 6265 206e 6f6e 2d6e 6567 6174 6976 652e  be non-negative.
+0000c9d0: 0a20 2020 2020 2049 6620 6e6f 2061 7267  .      If no arg
+0000c9e0: 756d 656e 7420 6973 2067 6976 656e 2061  ument is given a
+0000c9f0: 2073 696e 676c 6520 5079 7468 6f6e 2066   single Python f
+0000ca00: 6c6f 6174 2069 7320 7265 7475 726e 6564  loat is returned
+0000ca10: 2e0a 0a20 2052 6574 7572 6e73 0a20 202d  ...  Returns.  -
+0000ca20: 2d2d 2d2d 2d2d 0a20 205a 203a 206e 6461  ------.  Z : nda
+0000ca30: 7272 6179 206f 7220 666c 6f61 740a 2020  rray or float.  
+0000ca40: 2020 2020 4120 6060 2864 302c 2064 312c      A ``(d0, d1,
+0000ca50: 202e 2e2e 2c20 646e 2960 602d 7368 6170   ..., dn)``-shap
+0000ca60: 6564 2061 7272 6179 206f 6620 666c 6f61  ed array of floa
+0000ca70: 7469 6e67 2d70 6f69 6e74 2073 616d 706c  ting-point sampl
+0000ca80: 6573 2066 726f 6d0a 2020 2020 2020 7468  es from.      th
+0000ca90: 6520 7374 616e 6461 7264 206e 6f72 6d61  e standard norma
+0000caa0: 6c20 6469 7374 7269 6275 7469 6f6e 2c20  l distribution, 
+0000cab0: 6f72 2061 2073 696e 676c 6520 7375 6368  or a single such
+0000cac0: 2066 6c6f 6174 2069 660a 2020 2020 2020   float if.      
+0000cad0: 6e6f 2070 6172 616d 6574 6572 7320 7765  no parameters we
+0000cae0: 7265 2073 7570 706c 6965 642e 0a0a 2020  re supplied...  
+0000caf0: 5365 6520 416c 736f 0a20 202d 2d2d 2d2d  See Also.  -----
+0000cb00: 2d2d 2d0a 2020 7374 616e 6461 7264 5f6e  ---.  standard_n
+0000cb10: 6f72 6d61 6c20 3a20 5369 6d69 6c61 722c  ormal : Similar,
+0000cb20: 2062 7574 2074 616b 6573 2061 2074 7570   but takes a tup
+0000cb30: 6c65 2061 7320 6974 7320 6172 6775 6d65  le as its argume
+0000cb40: 6e74 2e0a 2020 6e6f 726d 616c 203a 2041  nt..  normal : A
+0000cb50: 6c73 6f20 6163 6365 7074 7320 6d75 2061  lso accepts mu a
+0000cb60: 6e64 2073 6967 6d61 2061 7267 756d 656e  nd sigma argumen
+0000cb70: 7473 2e0a 2020 7261 6e64 6f6d 2e47 656e  ts..  random.Gen
+0000cb80: 6572 6174 6f72 2e73 7461 6e64 6172 645f  erator.standard_
+0000cb90: 6e6f 726d 616c 3a20 7768 6963 6820 7368  normal: which sh
+0000cba0: 6f75 6c64 2062 6520 7573 6564 2066 6f72  ould be used for
+0000cbb0: 206e 6577 2063 6f64 652e 0a0a 2020 4e6f   new code...  No
+0000cbc0: 7465 730a 2020 2d2d 2d2d 2d0a 2020 466f  tes.  -----.  Fo
+0000cbd0: 7220 7261 6e64 6f6d 2073 616d 706c 6573  r random samples
+0000cbe0: 2066 726f 6d20 3a6d 6174 683a 604e 285c   from :math:`N(\
+0000cbf0: 6d75 2c20 5c73 6967 6d61 5e32 2960 2c20  mu, \sigma^2)`, 
+0000cc00: 7573 653a 0a0a 2020 6060 7369 676d 6120  use:..  ``sigma 
+0000cc10: 2a20 626d 2e72 616e 646f 6d2e 7261 6e64  * bm.random.rand
+0000cc20: 6e28 2e2e 2e29 202b 206d 7560 600a 0a20  n(...) + mu``.. 
+0000cc30: 2045 7861 6d70 6c65 730a 2020 2d2d 2d2d   Examples.  ----
+0000cc40: 2d2d 2d2d 0a20 203e 3e3e 2069 6d70 6f72  ----.  >>> impor
+0000cc50: 7420 6272 6169 6e70 792e 6d61 7468 2061  t brainpy.math a
+0000cc60: 7320 626d 0a20 203e 3e3e 2062 6d2e 7261  s bm.  >>> bm.ra
+0000cc70: 6e64 6f6d 2e72 616e 646e 2829 0a20 2032  ndom.randn().  2
+0000cc80: 2e31 3932 3338 3735 3333 3535 3337 3331  .192387533553731
+0000cc90: 3520 2023 2072 616e 646f 6d0a 0a20 2054  5  # random..  T
+0000cca0: 776f 2d62 792d 666f 7572 2061 7272 6179  wo-by-four array
+0000ccb0: 206f 6620 7361 6d70 6c65 7320 6672 6f6d   of samples from
+0000ccc0: 204e 2833 2c20 362e 3235 293a 0a0a 2020   N(3, 6.25):..  
+0000ccd0: 3e3e 3e20 3320 2b20 322e 3520 2a20 626d  >>> 3 + 2.5 * bm
+0000cce0: 2e72 616e 646f 6d2e 7261 6e64 6e28 322c  .random.randn(2,
+0000ccf0: 2034 290a 2020 6172 7261 7928 5b5b 2d34   4).  array([[-4
+0000cd00: 2e34 3934 3031 3530 312c 2020 342e 3030  .49401501,  4.00
+0000cd10: 3935 3030 3334 2c20 2d31 2e38 3138 3134  950034, -1.81814
+0000cd20: 3836 372c 2020 372e 3239 3731 3836 3737  867,  7.29718677
+0000cd30: 5d2c 2020 2023 2072 616e 646f 6d0a 2020  ],   # random.  
+0000cd40: 2020 2020 2020 205b 2030 2e33 3939 3234         [ 0.39924
+0000cd50: 3830 342c 2020 342e 3638 3435 3633 3136  804,  4.68456316
+0000cd60: 2c20 2034 2e39 3933 3934 3532 392c 2020  ,  4.99394529,  
+0000cd70: 342e 3834 3035 3732 3534 5d5d 2920 2023  4.84057254]])  #
+0000cd80: 2072 616e 646f 6d0a 2020 2222 220a 0a20   random.  """.. 
+0000cd90: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
+0000cda0: 7261 6e64 6e28 2a64 6e2c 206b 6579 3d6b  randn(*dn, key=k
+0000cdb0: 6579 290a 0a0a 6465 6620 7261 6e64 6f6d  ey)...def random
+0000cdc0: 2873 697a 653d 4e6f 6e65 2c20 6b65 793d  (size=None, key=
+0000cdd0: 4e6f 6e65 293a 0a20 2022 2222 0a20 2052  None):.  """.  R
+0000cde0: 6574 7572 6e20 7261 6e64 6f6d 2066 6c6f  eturn random flo
+0000cdf0: 6174 7320 696e 2074 6865 2068 616c 662d  ats in the half-
+0000ce00: 6f70 656e 2069 6e74 6572 7661 6c20 5b30  open interval [0
+0000ce10: 2e30 2c20 312e 3029 2e20 416c 6961 7320  .0, 1.0). Alias 
+0000ce20: 666f 720a 2020 6072 616e 646f 6d5f 7361  for.  `random_sa
+0000ce30: 6d70 6c65 6020 746f 2065 6173 6520 666f  mple` to ease fo
+0000ce40: 7277 6172 642d 706f 7274 696e 6720 746f  rward-porting to
+0000ce50: 2074 6865 206e 6577 2072 616e 646f 6d20   the new random 
+0000ce60: 4150 492e 0a20 2022 2222 0a20 2072 6574  API..  """.  ret
+0000ce70: 7572 6e20 4445 4641 554c 542e 7261 6e64  urn DEFAULT.rand
+0000ce80: 6f6d 2873 697a 652c 206b 6579 3d6b 6579  om(size, key=key
+0000ce90: 290a 0a0a 6465 6620 7261 6e64 6f6d 5f73  )...def random_s
+0000cea0: 616d 706c 6528 7369 7a65 3d4e 6f6e 652c  ample(size=None,
+0000ceb0: 206b 6579 3d4e 6f6e 6529 3a0a 2020 7222   key=None):.  r"
+0000cec0: 2222 0a20 2052 6574 7572 6e20 7261 6e64  "".  Return rand
+0000ced0: 6f6d 2066 6c6f 6174 7320 696e 2074 6865  om floats in the
+0000cee0: 2068 616c 662d 6f70 656e 2069 6e74 6572   half-open inter
+0000cef0: 7661 6c20 5b30 2e30 2c20 312e 3029 2e0a  val [0.0, 1.0)..
+0000cf00: 0a20 2052 6573 756c 7473 2061 7265 2066  .  Results are f
+0000cf10: 726f 6d20 7468 6520 2263 6f6e 7469 6e75  rom the "continu
+0000cf20: 6f75 7320 756e 6966 6f72 6d22 2064 6973  ous uniform" dis
+0000cf30: 7472 6962 7574 696f 6e20 6f76 6572 2074  tribution over t
+0000cf40: 6865 0a20 2073 7461 7465 6420 696e 7465  he.  stated inte
+0000cf50: 7276 616c 2e20 2054 6f20 7361 6d70 6c65  rval.  To sample
+0000cf60: 203a 6d61 7468 3a60 556e 6966 5b61 2c20   :math:`Unif[a, 
+0000cf70: 6229 2c20 6220 3e20 6160 206d 756c 7469  b), b > a` multi
+0000cf80: 706c 790a 2020 7468 6520 6f75 7470 7574  ply.  the output
+0000cf90: 206f 6620 6072 616e 646f 6d5f 7361 6d70   of `random_samp
+0000cfa0: 6c65 6020 6279 2060 2862 2d61 2960 2061  le` by `(b-a)` a
+0000cfb0: 6e64 2061 6464 2060 6160 3a3a 0a0a 2020  nd add `a`::..  
+0000cfc0: 2020 2862 202d 2061 2920 2a20 7261 6e64    (b - a) * rand
+0000cfd0: 6f6d 5f73 616d 706c 6528 2920 2b20 610a  om_sample() + a.
+0000cfe0: 0a20 202e 2e20 6e6f 7465 3a3a 0a20 2020  .  .. note::.   
+0000cff0: 2020 204e 6577 2063 6f64 6520 7368 6f75     New code shou
+0000d000: 6c64 2075 7365 2074 6865 2060 6072 616e  ld use the ``ran
+0000d010: 646f 6d60 6020 6d65 7468 6f64 206f 6620  dom`` method of 
+0000d020: 6120 6060 6465 6661 756c 745f 726e 6728  a ``default_rng(
+0000d030: 2960 600a 2020 2020 2020 696e 7374 616e  )``.      instan
+0000d040: 6365 2069 6e73 7465 6164 3b20 706c 6561  ce instead; plea
+0000d050: 7365 2073 6565 2074 6865 203a 7265 663a  se see the :ref:
+0000d060: 6072 616e 646f 6d2d 7175 6963 6b2d 7374  `random-quick-st
+0000d070: 6172 7460 2e0a 0a20 2050 6172 616d 6574  art`...  Paramet
+0000d080: 6572 730a 2020 2d2d 2d2d 2d2d 2d2d 2d2d  ers.  ----------
+0000d090: 0a20 2073 697a 6520 3a20 696e 7420 6f72  .  size : int or
+0000d0a0: 2074 7570 6c65 206f 6620 696e 7473 2c20   tuple of ints, 
+0000d0b0: 6f70 7469 6f6e 616c 0a20 2020 2020 204f  optional.      O
+0000d0c0: 7574 7075 7420 7368 6170 652e 2020 4966  utput shape.  If
+0000d0d0: 2074 6865 2067 6976 656e 2073 6861 7065   the given shape
+0000d0e0: 2069 732c 2065 2e67 2e2c 2060 6028 6d2c   is, e.g., ``(m,
+0000d0f0: 206e 2c20 6b29 6060 2c20 7468 656e 0a20   n, k)``, then. 
+0000d100: 2020 2020 2060 606d 202a 206e 202a 206b       ``m * n * k
+0000d110: 6060 2073 616d 706c 6573 2061 7265 2064  `` samples are d
+0000d120: 7261 776e 2e20 2044 6566 6175 6c74 2069  rawn.  Default i
+0000d130: 7320 4e6f 6e65 2c20 696e 2077 6869 6368  s None, in which
+0000d140: 2063 6173 6520 610a 2020 2020 2020 7369   case a.      si
+0000d150: 6e67 6c65 2076 616c 7565 2069 7320 7265  ngle value is re
+0000d160: 7475 726e 6564 2e0a 0a20 2052 6574 7572  turned...  Retur
+0000d170: 6e73 0a20 202d 2d2d 2d2d 2d2d 0a20 206f  ns.  -------.  o
+0000d180: 7574 203a 2066 6c6f 6174 206f 7220 6e64  ut : float or nd
+0000d190: 6172 7261 7920 6f66 2066 6c6f 6174 730a  array of floats.
+0000d1a0: 2020 2020 2020 4172 7261 7920 6f66 2072        Array of r
+0000d1b0: 616e 646f 6d20 666c 6f61 7473 206f 6620  andom floats of 
+0000d1c0: 7368 6170 6520 6073 697a 6560 2028 756e  shape `size` (un
+0000d1d0: 6c65 7373 2060 6073 697a 653d 4e6f 6e65  less ``size=None
+0000d1e0: 6060 2c20 696e 2077 6869 6368 0a20 2020  ``, in which.   
+0000d1f0: 2020 2063 6173 6520 6120 7369 6e67 6c65     case a single
+0000d200: 2066 6c6f 6174 2069 7320 7265 7475 726e   float is return
+0000d210: 6564 292e 0a0a 2020 5365 6520 416c 736f  ed)...  See Also
+0000d220: 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020 4765  .  --------.  Ge
+0000d230: 6e65 7261 746f 722e 7261 6e64 6f6d 3a20  nerator.random: 
+0000d240: 7768 6963 6820 7368 6f75 6c64 2062 6520  which should be 
+0000d250: 7573 6564 2066 6f72 206e 6577 2063 6f64  used for new cod
+0000d260: 652e 0a0a 2020 4578 616d 706c 6573 0a20  e...  Examples. 
+0000d270: 202d 2d2d 2d2d 2d2d 2d0a 2020 3e3e 3e20   --------.  >>> 
+0000d280: 696d 706f 7274 2062 7261 696e 7079 2e6d  import brainpy.m
+0000d290: 6174 6820 6173 2062 6d0a 2020 3e3e 3e20  ath as bm.  >>> 
+0000d2a0: 626d 2e72 616e 646f 6d2e 7261 6e64 6f6d  bm.random.random
+0000d2b0: 5f73 616d 706c 6528 290a 2020 302e 3437  _sample().  0.47
+0000d2c0: 3130 3835 3437 3939 3533 3536 3039 3820  108547995356098 
+0000d2d0: 2320 7261 6e64 6f6d 0a20 203e 3e3e 2074  # random.  >>> t
+0000d2e0: 7970 6528 626d 2e72 616e 646f 6d2e 7261  ype(bm.random.ra
+0000d2f0: 6e64 6f6d 5f73 616d 706c 6528 2929 0a20  ndom_sample()). 
+0000d300: 203c 636c 6173 7320 2766 6c6f 6174 273e   <class 'float'>
+0000d310: 0a20 203e 3e3e 2062 6d2e 7261 6e64 6f6d  .  >>> bm.random
+0000d320: 2e72 616e 646f 6d5f 7361 6d70 6c65 2828  .random_sample((
+0000d330: 352c 2929 0a20 2061 7272 6179 285b 2030  5,)).  array([ 0
+0000d340: 2e33 3032 3230 3438 322c 2020 302e 3836  .30220482,  0.86
+0000d350: 3832 3034 3031 2c20 2030 2e31 3635 3435  820401,  0.16545
+0000d360: 3033 202c 2020 302e 3131 3635 3931 3439  03 ,  0.11659149
+0000d370: 2c20 2030 2e35 3433 3233 3432 385d 2920  ,  0.54323428]) 
+0000d380: 2320 7261 6e64 6f6d 0a0a 2020 5468 7265  # random..  Thre
+0000d390: 652d 6279 2d74 776f 2061 7272 6179 206f  e-by-two array o
+0000d3a0: 6620 7261 6e64 6f6d 206e 756d 6265 7273  f random numbers
+0000d3b0: 2066 726f 6d20 5b2d 352c 2030 293a 0a0a   from [-5, 0):..
+0000d3c0: 2020 3e3e 3e20 3520 2a20 626d 2e72 616e    >>> 5 * bm.ran
+0000d3d0: 646f 6d2e 7261 6e64 6f6d 5f73 616d 706c  dom.random_sampl
+0000d3e0: 6528 2833 2c20 3229 2920 2d20 350a 2020  e((3, 2)) - 5.  
+0000d3f0: 6172 7261 7928 5b5b 2d33 2e39 3931 3439  array([[-3.99149
+0000d400: 3938 392c 202d 302e 3532 3333 3839 3834  989, -0.52338984
+0000d410: 5d2c 2023 2072 616e 646f 6d0a 2020 2020  ], # random.    
+0000d420: 2020 2020 205b 2d32 2e39 3930 3931 3835       [-2.9909185
+0000d430: 382c 202d 302e 3739 3437 3935 3038 5d2c  8, -0.79479508],
+0000d440: 0a20 2020 2020 2020 2020 5b2d 312e 3233  .         [-1.23
+0000d450: 3230 3433 3435 2c20 2d31 2e37 3532 3234  204345, -1.75224
+0000d460: 3439 345d 5d29 0a20 2022 2222 0a20 2072  494]]).  """.  r
+0000d470: 6574 7572 6e20 4445 4641 554c 542e 7261  eturn DEFAULT.ra
+0000d480: 6e64 6f6d 5f73 616d 706c 6528 7369 7a65  ndom_sample(size
+0000d490: 2c20 6b65 793d 6b65 7929 0a0a 0a64 6566  , key=key)...def
+0000d4a0: 2072 616e 6628 7369 7a65 3d4e 6f6e 652c   ranf(size=None,
+0000d4b0: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2222   key=None):.  ""
+0000d4c0: 220a 2020 5468 6973 2069 7320 616e 2061  ".  This is an a
+0000d4d0: 6c69 6173 206f 6620 6072 616e 646f 6d5f  lias of `random_
+0000d4e0: 7361 6d70 6c65 602e 2053 6565 2060 7261  sample`. See `ra
+0000d4f0: 6e64 6f6d 5f73 616d 706c 6560 2020 666f  ndom_sample`  fo
+0000d500: 7220 7468 6520 636f 6d70 6c65 7465 0a20  r the complete. 
+0000d510: 2020 2020 2064 6f63 756d 656e 7461 7469       documentati
+0000d520: 6f6e 2e0a 2020 2222 220a 2020 7265 7475  on..  """.  retu
+0000d530: 726e 2044 4546 4155 4c54 2e72 616e 6628  rn DEFAULT.ranf(
+0000d540: 7369 7a65 2c20 6b65 793d 6b65 7929 0a0a  size, key=key)..
+0000d550: 0a64 6566 2073 616d 706c 6528 7369 7a65  .def sample(size
+0000d560: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
+0000d570: 3a0a 2020 2222 220a 2020 5468 6973 2069  :.  """.  This i
+0000d580: 7320 616e 2061 6c69 6173 206f 6620 6072  s an alias of `r
+0000d590: 616e 646f 6d5f 7361 6d70 6c65 602e 2053  andom_sample`. S
+0000d5a0: 6565 2060 7261 6e64 6f6d 5f73 616d 706c  ee `random_sampl
+0000d5b0: 6560 2020 666f 7220 7468 6520 636f 6d70  e`  for the comp
+0000d5c0: 6c65 7465 0a20 2020 2020 2064 6f63 756d  lete.      docum
+0000d5d0: 656e 7461 7469 6f6e 2e0a 2020 2222 220a  entation..  """.
+0000d5e0: 2020 7265 7475 726e 2044 4546 4155 4c54    return DEFAULT
+0000d5f0: 2e73 616d 706c 6528 7369 7a65 2c20 6b65  .sample(size, ke
+0000d600: 793d 6b65 7929 0a0a 0a64 6566 2063 686f  y=key)...def cho
+0000d610: 6963 6528 612c 2073 697a 653d 4e6f 6e65  ice(a, size=None
+0000d620: 2c20 7265 706c 6163 653d 5472 7565 2c20  , replace=True, 
+0000d630: 703d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  p=None, key=None
+0000d640: 293a 0a20 2072 2222 220a 2020 4765 6e65  ):.  r""".  Gene
+0000d650: 7261 7465 7320 6120 7261 6e64 6f6d 2073  rates a random s
+0000d660: 616d 706c 6520 6672 6f6d 2061 2067 6976  ample from a giv
+0000d670: 656e 2031 2d44 2061 7272 6179 0a0a 2020  en 1-D array..  
+0000d680: 5061 7261 6d65 7465 7273 0a20 202d 2d2d  Parameters.  ---
+0000d690: 2d2d 2d2d 2d2d 2d0a 2020 6120 3a20 312d  -------.  a : 1-
+0000d6a0: 4420 6172 7261 792d 6c69 6b65 206f 7220  D array-like or 
+0000d6b0: 696e 740a 2020 2020 2020 4966 2061 6e20  int.      If an 
+0000d6c0: 6e64 6172 7261 792c 2061 2072 616e 646f  ndarray, a rando
+0000d6d0: 6d20 7361 6d70 6c65 2069 7320 6765 6e65  m sample is gene
+0000d6e0: 7261 7465 6420 6672 6f6d 2069 7473 2065  rated from its e
+0000d6f0: 6c65 6d65 6e74 732e 0a20 2020 2020 2049  lements..      I
+0000d700: 6620 616e 2069 6e74 2c20 7468 6520 7261  f an int, the ra
+0000d710: 6e64 6f6d 2073 616d 706c 6520 6973 2067  ndom sample is g
+0000d720: 656e 6572 6174 6564 2061 7320 6966 2069  enerated as if i
+0000d730: 7420 7765 7265 2060 606e 702e 6172 616e  t were ``np.aran
+0000d740: 6765 2861 2960 600a 2020 7369 7a65 203a  ge(a)``.  size :
+0000d750: 2069 6e74 206f 7220 7475 706c 6520 6f66   int or tuple of
+0000d760: 2069 6e74 732c 206f 7074 696f 6e61 6c0a   ints, optional.
+0000d770: 2020 2020 2020 4f75 7470 7574 2073 6861        Output sha
+0000d780: 7065 2e20 2049 6620 7468 6520 6769 7665  pe.  If the give
+0000d790: 6e20 7368 6170 6520 6973 2c20 652e 672e  n shape is, e.g.
+0000d7a0: 2c20 6060 286d 2c20 6e2c 206b 2960 602c  , ``(m, n, k)``,
+0000d7b0: 2074 6865 6e0a 2020 2020 2020 6060 6d20   then.      ``m 
+0000d7c0: 2a20 6e20 2a20 6b60 6020 7361 6d70 6c65  * n * k`` sample
+0000d7d0: 7320 6172 6520 6472 6177 6e2e 2020 4465  s are drawn.  De
+0000d7e0: 6661 756c 7420 6973 204e 6f6e 652c 2069  fault is None, i
+0000d7f0: 6e20 7768 6963 6820 6361 7365 2061 0a20  n which case a. 
+0000d800: 2020 2020 2073 696e 676c 6520 7661 6c75       single valu
+0000d810: 6520 6973 2072 6574 7572 6e65 642e 0a20  e is returned.. 
+0000d820: 2072 6570 6c61 6365 203a 2062 6f6f 6c65   replace : boole
+0000d830: 616e 2c20 6f70 7469 6f6e 616c 0a20 2020  an, optional.   
+0000d840: 2020 2057 6865 7468 6572 2074 6865 2073     Whether the s
+0000d850: 616d 706c 6520 6973 2077 6974 6820 6f72  ample is with or
+0000d860: 2077 6974 686f 7574 2072 6570 6c61 6365   without replace
+0000d870: 6d65 6e74 2e20 4465 6661 756c 7420 6973  ment. Default is
+0000d880: 2054 7275 652c 0a20 2020 2020 206d 6561   True,.      mea
+0000d890: 6e69 6e67 2074 6861 7420 6120 7661 6c75  ning that a valu
+0000d8a0: 6520 6f66 2060 6061 6060 2063 616e 2062  e of ``a`` can b
+0000d8b0: 6520 7365 6c65 6374 6564 206d 756c 7469  e selected multi
+0000d8c0: 706c 6520 7469 6d65 732e 0a20 2070 203a  ple times..  p :
+0000d8d0: 2031 2d44 2061 7272 6179 2d6c 696b 652c   1-D array-like,
+0000d8e0: 206f 7074 696f 6e61 6c0a 2020 2020 2020   optional.      
+0000d8f0: 5468 6520 7072 6f62 6162 696c 6974 6965  The probabilitie
+0000d900: 7320 6173 736f 6369 6174 6564 2077 6974  s associated wit
+0000d910: 6820 6561 6368 2065 6e74 7279 2069 6e20  h each entry in 
+0000d920: 612e 0a20 2020 2020 2049 6620 6e6f 7420  a..      If not 
+0000d930: 6769 7665 6e2c 2074 6865 2073 616d 706c  given, the sampl
+0000d940: 6520 6173 7375 6d65 7320 6120 756e 6966  e assumes a unif
+0000d950: 6f72 6d20 6469 7374 7269 6275 7469 6f6e  orm distribution
+0000d960: 206f 7665 7220 616c 6c0a 2020 2020 2020   over all.      
+0000d970: 656e 7472 6965 7320 696e 2060 6061 6060  entries in ``a``
+0000d980: 2e0a 0a20 2052 6574 7572 6e73 0a20 202d  ...  Returns.  -
+0000d990: 2d2d 2d2d 2d2d 0a20 2073 616d 706c 6573  ------.  samples
+0000d9a0: 203a 2073 696e 676c 6520 6974 656d 206f   : single item o
+0000d9b0: 7220 6e64 6172 7261 790a 2020 2020 2020  r ndarray.      
+0000d9c0: 5468 6520 6765 6e65 7261 7465 6420 7261  The generated ra
+0000d9d0: 6e64 6f6d 2073 616d 706c 6573 0a0a 2020  ndom samples..  
+0000d9e0: 5261 6973 6573 0a20 202d 2d2d 2d2d 2d0a  Raises.  ------.
+0000d9f0: 2020 5661 6c75 6545 7272 6f72 0a20 2020    ValueError.   
+0000da00: 2020 2049 6620 6120 6973 2061 6e20 696e     If a is an in
+0000da10: 7420 616e 6420 6c65 7373 2074 6861 6e20  t and less than 
+0000da20: 7a65 726f 2c20 6966 2061 206f 7220 7020  zero, if a or p 
+0000da30: 6172 6520 6e6f 7420 312d 6469 6d65 6e73  are not 1-dimens
+0000da40: 696f 6e61 6c2c 0a20 2020 2020 2069 6620  ional,.      if 
+0000da50: 6120 6973 2061 6e20 6172 7261 792d 6c69  a is an array-li
+0000da60: 6b65 206f 6620 7369 7a65 2030 2c20 6966  ke of size 0, if
+0000da70: 2070 2069 7320 6e6f 7420 6120 7665 6374   p is not a vect
+0000da80: 6f72 206f 660a 2020 2020 2020 7072 6f62  or of.      prob
+0000da90: 6162 696c 6974 6965 732c 2069 6620 6120  abilities, if a 
+0000daa0: 616e 6420 7020 6861 7665 2064 6966 6665  and p have diffe
+0000dab0: 7265 6e74 206c 656e 6774 6873 2c20 6f72  rent lengths, or
+0000dac0: 2069 660a 2020 2020 2020 7265 706c 6163   if.      replac
+0000dad0: 653d 4661 6c73 6520 616e 6420 7468 6520  e=False and the 
+0000dae0: 7361 6d70 6c65 2073 697a 6520 6973 2067  sample size is g
+0000daf0: 7265 6174 6572 2074 6861 6e20 7468 6520  reater than the 
+0000db00: 706f 7075 6c61 7469 6f6e 0a20 2020 2020  population.     
+0000db10: 2073 697a 650a 0a20 2053 6565 2041 6c73   size..  See Als
+0000db20: 6f0a 2020 2d2d 2d2d 2d2d 2d2d 0a20 2072  o.  --------.  r
+0000db30: 616e 6469 6e74 2c20 7368 7566 666c 652c  andint, shuffle,
+0000db40: 2070 6572 6d75 7461 7469 6f6e 0a20 2047   permutation.  G
+0000db50: 656e 6572 6174 6f72 2e63 686f 6963 653a  enerator.choice:
+0000db60: 2077 6869 6368 2073 686f 756c 6420 6265   which should be
+0000db70: 2075 7365 6420 696e 206e 6577 2063 6f64   used in new cod
+0000db80: 650a 0a20 204e 6f74 6573 0a20 202d 2d2d  e..  Notes.  ---
+0000db90: 2d2d 0a20 2053 6574 7469 6e67 2075 7365  --.  Setting use
+0000dba0: 722d 7370 6563 6966 6965 6420 7072 6f62  r-specified prob
+0000dbb0: 6162 696c 6974 6965 7320 7468 726f 7567  abilities throug
+0000dbc0: 6820 6060 7060 6020 7573 6573 2061 206d  h ``p`` uses a m
+0000dbd0: 6f72 6520 6765 6e65 7261 6c20 6275 7420  ore general but 
+0000dbe0: 6c65 7373 0a20 2065 6666 6963 6965 6e74  less.  efficient
+0000dbf0: 2073 616d 706c 6572 2074 6861 6e20 7468   sampler than th
+0000dc00: 6520 6465 6661 756c 742e 2054 6865 2067  e default. The g
+0000dc10: 656e 6572 616c 2073 616d 706c 6572 2070  eneral sampler p
+0000dc20: 726f 6475 6365 7320 6120 6469 6666 6572  roduces a differ
+0000dc30: 656e 7420 7361 6d70 6c65 0a20 2074 6861  ent sample.  tha
+0000dc40: 6e20 7468 6520 6f70 7469 6d69 7a65 6420  n the optimized 
+0000dc50: 7361 6d70 6c65 7220 6576 656e 2069 6620  sampler even if 
+0000dc60: 6561 6368 2065 6c65 6d65 6e74 206f 6620  each element of 
+0000dc70: 6060 7060 6020 6973 2031 202f 206c 656e  ``p`` is 1 / len
+0000dc80: 2861 292e 0a0a 2020 5361 6d70 6c69 6e67  (a)...  Sampling
+0000dc90: 2072 616e 646f 6d20 726f 7773 2066 726f   random rows fro
+0000dca0: 6d20 6120 322d 4420 6172 7261 7920 6973  m a 2-D array is
+0000dcb0: 206e 6f74 2070 6f73 7369 626c 6520 7769   not possible wi
+0000dcc0: 7468 2074 6869 7320 6675 6e63 7469 6f6e  th this function
+0000dcd0: 2c0a 2020 6275 7420 6973 2070 6f73 7369  ,.  but is possi
+0000dce0: 626c 6520 7769 7468 2060 4765 6e65 7261  ble with `Genera
+0000dcf0: 746f 722e 6368 6f69 6365 6020 7468 726f  tor.choice` thro
+0000dd00: 7567 6820 6974 7320 6060 6178 6973 6060  ugh its ``axis``
+0000dd10: 206b 6579 776f 7264 2e0a 0a20 2045 7861   keyword...  Exa
+0000dd20: 6d70 6c65 730a 2020 2d2d 2d2d 2d2d 2d2d  mples.  --------
+0000dd30: 0a20 2047 656e 6572 6174 6520 6120 756e  .  Generate a un
+0000dd40: 6966 6f72 6d20 7261 6e64 6f6d 2073 616d  iform random sam
+0000dd50: 706c 6520 6672 6f6d 206e 702e 6172 616e  ple from np.aran
+0000dd60: 6765 2835 2920 6f66 2073 697a 6520 333a  ge(5) of size 3:
+0000dd70: 0a0a 2020 3e3e 3e20 696d 706f 7274 2062  ..  >>> import b
+0000dd80: 7261 696e 7079 2e6d 6174 6820 6173 2062  rainpy.math as b
+0000dd90: 6d0a 2020 3e3e 3e20 626d 2e72 616e 646f  m.  >>> bm.rando
+0000dda0: 6d2e 6368 6f69 6365 2835 2c20 3329 0a20  m.choice(5, 3). 
+0000ddb0: 2061 7272 6179 285b 302c 2033 2c20 345d   array([0, 3, 4]
+0000ddc0: 2920 2320 7261 6e64 6f6d 0a20 203e 3e3e  ) # random.  >>>
+0000ddd0: 2023 5468 6973 2069 7320 6571 7569 7661   #This is equiva
+0000dde0: 6c65 6e74 2074 6f20 6272 6169 6e70 792e  lent to brainpy.
+0000ddf0: 6d61 7468 2e72 616e 646f 6d2e 7261 6e64  math.random.rand
+0000de00: 696e 7428 302c 352c 3329 0a0a 2020 4765  int(0,5,3)..  Ge
+0000de10: 6e65 7261 7465 2061 206e 6f6e 2d75 6e69  nerate a non-uni
+0000de20: 666f 726d 2072 616e 646f 6d20 7361 6d70  form random samp
+0000de30: 6c65 2066 726f 6d20 6e70 2e61 7261 6e67  le from np.arang
+0000de40: 6528 3529 206f 6620 7369 7a65 2033 3a0a  e(5) of size 3:.
+0000de50: 0a20 203e 3e3e 2062 6d2e 7261 6e64 6f6d  .  >>> bm.random
+0000de60: 2e63 686f 6963 6528 352c 2033 2c20 703d  .choice(5, 3, p=
+0000de70: 5b30 2e31 2c20 302c 2030 2e33 2c20 302e  [0.1, 0, 0.3, 0.
+0000de80: 362c 2030 5d29 0a20 2061 7272 6179 285b  6, 0]).  array([
+0000de90: 332c 2033 2c20 305d 2920 2320 7261 6e64  3, 3, 0]) # rand
+0000dea0: 6f6d 0a0a 2020 4765 6e65 7261 7465 2061  om..  Generate a
+0000deb0: 2075 6e69 666f 726d 2072 616e 646f 6d20   uniform random 
+0000dec0: 7361 6d70 6c65 2066 726f 6d20 6e70 2e61  sample from np.a
+0000ded0: 7261 6e67 6528 3529 206f 6620 7369 7a65  range(5) of size
+0000dee0: 2033 2077 6974 686f 7574 0a20 2072 6570   3 without.  rep
+0000def0: 6c61 6365 6d65 6e74 3a0a 0a20 203e 3e3e  lacement:..  >>>
+0000df00: 2062 6d2e 7261 6e64 6f6d 2e63 686f 6963   bm.random.choic
+0000df10: 6528 352c 2033 2c20 7265 706c 6163 653d  e(5, 3, replace=
+0000df20: 4661 6c73 6529 0a20 2061 7272 6179 285b  False).  array([
+0000df30: 332c 312c 305d 2920 2320 7261 6e64 6f6d  3,1,0]) # random
+0000df40: 0a20 203e 3e3e 2023 5468 6973 2069 7320  .  >>> #This is 
+0000df50: 6571 7569 7661 6c65 6e74 2074 6f20 6272  equivalent to br
+0000df60: 6169 6e70 792e 6d61 7468 2e72 616e 646f  ainpy.math.rando
+0000df70: 6d2e 7065 726d 7574 6174 696f 6e28 6e70  m.permutation(np
+0000df80: 2e61 7261 6e67 6528 3529 295b 3a33 5d0a  .arange(5))[:3].
+0000df90: 0a20 2047 656e 6572 6174 6520 6120 6e6f  .  Generate a no
+0000dfa0: 6e2d 756e 6966 6f72 6d20 7261 6e64 6f6d  n-uniform random
+0000dfb0: 2073 616d 706c 6520 6672 6f6d 206e 702e   sample from np.
+0000dfc0: 6172 616e 6765 2835 2920 6f66 2073 697a  arange(5) of siz
+0000dfd0: 650a 2020 3320 7769 7468 6f75 7420 7265  e.  3 without re
+0000dfe0: 706c 6163 656d 656e 743a 0a0a 2020 3e3e  placement:..  >>
+0000dff0: 3e20 626d 2e72 616e 646f 6d2e 6368 6f69  > bm.random.choi
+0000e000: 6365 2835 2c20 332c 2072 6570 6c61 6365  ce(5, 3, replace
+0000e010: 3d46 616c 7365 2c20 703d 5b30 2e31 2c20  =False, p=[0.1, 
+0000e020: 302c 2030 2e33 2c20 302e 362c 2030 5d29  0, 0.3, 0.6, 0])
+0000e030: 0a20 2061 7272 6179 285b 322c 2033 2c20  .  array([2, 3, 
+0000e040: 305d 2920 2320 7261 6e64 6f6d 0a0a 2020  0]) # random..  
+0000e050: 416e 7920 6f66 2074 6865 2061 626f 7665  Any of the above
+0000e060: 2063 616e 2062 6520 7265 7065 6174 6564   can be repeated
+0000e070: 2077 6974 6820 616e 2061 7262 6974 7261   with an arbitra
+0000e080: 7279 2061 7272 6179 2d6c 696b 650a 2020  ry array-like.  
+0000e090: 696e 7374 6561 6420 6f66 206a 7573 7420  instead of just 
+0000e0a0: 696e 7465 6765 7273 2e20 466f 7220 696e  integers. For in
+0000e0b0: 7374 616e 6365 3a0a 0a20 203e 3e3e 2061  stance:..  >>> a
+0000e0c0: 615f 6d69 6c6e 655f 6172 7220 3d20 5b27  a_milne_arr = ['
+0000e0d0: 706f 6f68 272c 2027 7261 6262 6974 272c  pooh', 'rabbit',
+0000e0e0: 2027 7069 676c 6574 272c 2027 4368 7269   'piglet', 'Chri
+0000e0f0: 7374 6f70 6865 7227 5d0a 2020 3e3e 3e20  stopher'].  >>> 
+0000e100: 626d 2e72 616e 646f 6d2e 6368 6f69 6365  bm.random.choice
+0000e110: 2861 615f 6d69 6c6e 655f 6172 722c 2035  (aa_milne_arr, 5
+0000e120: 2c20 703d 5b30 2e35 2c20 302e 312c 2030  , p=[0.5, 0.1, 0
+0000e130: 2e31 2c20 302e 335d 290a 2020 6172 7261  .1, 0.3]).  arra
+0000e140: 7928 5b27 706f 6f68 272c 2027 706f 6f68  y(['pooh', 'pooh
+0000e150: 272c 2027 706f 6f68 272c 2027 4368 7269  ', 'pooh', 'Chri
+0000e160: 7374 6f70 6865 7227 2c20 2770 6967 6c65  stopher', 'pigle
+0000e170: 7427 5d2c 2023 2072 616e 646f 6d0a 2020  t'], # random.  
+0000e180: 2020 2020 2020 6474 7970 653d 273c 5531        dtype='<U1
+0000e190: 3127 290a 2020 2222 220a 2020 6120 3d20  1').  """.  a = 
+0000e1a0: 5f61 735f 6a61 785f 6172 7261 7928 6129  _as_jax_array(a)
+0000e1b0: 0a20 2072 6574 7572 6e20 4445 4641 554c  .  return DEFAUL
+0000e1c0: 542e 6368 6f69 6365 2861 3d61 2c20 7369  T.choice(a=a, si
+0000e1d0: 7a65 3d73 697a 652c 2072 6570 6c61 6365  ze=size, replace
+0000e1e0: 3d72 6570 6c61 6365 2c20 703d 702c 206b  =replace, p=p, k
+0000e1f0: 6579 3d6b 6579 290a 0a0a 6465 6620 7065  ey=key)...def pe
+0000e200: 726d 7574 6174 696f 6e28 782c 2061 7869  rmutation(x, axi
+0000e210: 733a 2069 6e74 203d 2030 2c20 696e 6465  s: int = 0, inde
+0000e220: 7065 6e64 656e 743a 2062 6f6f 6c20 3d20  pendent: bool = 
+0000e230: 4661 6c73 652c 206b 6579 3d4e 6f6e 6529  False, key=None)
+0000e240: 3a0a 2020 7222 2222 0a20 2052 616e 646f  :.  r""".  Rando
+0000e250: 6d6c 7920 7065 726d 7574 6520 6120 7365  mly permute a se
+0000e260: 7175 656e 6365 2c20 6f72 2072 6574 7572  quence, or retur
+0000e270: 6e20 6120 7065 726d 7574 6564 2072 616e  n a permuted ran
+0000e280: 6765 2e0a 0a20 2049 6620 6078 6020 6973  ge...  If `x` is
+0000e290: 2061 206d 756c 7469 2d64 696d 656e 7369   a multi-dimensi
+0000e2a0: 6f6e 616c 2061 7272 6179 2c20 6974 2069  onal array, it i
+0000e2b0: 7320 6f6e 6c79 2073 6875 6666 6c65 6420  s only shuffled 
+0000e2c0: 616c 6f6e 6720 6974 730a 2020 6669 7273  along its.  firs
+0000e2d0: 7420 696e 6465 782e 0a0a 2020 5061 7261  t index...  Para
+0000e2e0: 6d65 7465 7273 0a20 202d 2d2d 2d2d 2d2d  meters.  -------
+0000e2f0: 2d2d 2d0a 2020 7820 3a20 696e 7420 6f72  ---.  x : int or
+0000e300: 2061 7272 6179 5f6c 696b 650a 2020 2020   array_like.    
+0000e310: 2020 4966 2060 7860 2069 7320 616e 2069    If `x` is an i
+0000e320: 6e74 6567 6572 2c20 7261 6e64 6f6d 6c79  nteger, randomly
+0000e330: 2070 6572 6d75 7465 2060 606e 702e 6172   permute ``np.ar
+0000e340: 616e 6765 2878 2960 602e 0a20 2020 2020  ange(x)``..     
+0000e350: 2049 6620 6078 6020 6973 2061 6e20 6172   If `x` is an ar
+0000e360: 7261 792c 206d 616b 6520 6120 636f 7079  ray, make a copy
+0000e370: 2061 6e64 2073 6875 6666 6c65 2074 6865   and shuffle the
+0000e380: 2065 6c65 6d65 6e74 730a 2020 2020 2020   elements.      
+0000e390: 7261 6e64 6f6d 6c79 2e0a 0a20 2052 6574  randomly...  Ret
+0000e3a0: 7572 6e73 0a20 202d 2d2d 2d2d 2d2d 0a20  urns.  -------. 
+0000e3b0: 206f 7574 203a 206e 6461 7272 6179 0a20   out : ndarray. 
+0000e3c0: 2020 2020 2050 6572 6d75 7465 6420 7365       Permuted se
+0000e3d0: 7175 656e 6365 206f 7220 6172 7261 7920  quence or array 
+0000e3e0: 7261 6e67 652e 0a0a 2020 5365 6520 416c  range...  See Al
+0000e3f0: 736f 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020  so.  --------.  
+0000e400: 7261 6e64 6f6d 2e47 656e 6572 6174 6f72  random.Generator
+0000e410: 2e70 6572 6d75 7461 7469 6f6e 3a20 7768  .permutation: wh
+0000e420: 6963 6820 7368 6f75 6c64 2062 6520 7573  ich should be us
+0000e430: 6564 2066 6f72 206e 6577 2063 6f64 652e  ed for new code.
+0000e440: 0a0a 2020 4578 616d 706c 6573 0a20 202d  ..  Examples.  -
+0000e450: 2d2d 2d2d 2d2d 2d0a 2020 3e3e 3e20 696d  -------.  >>> im
+0000e460: 706f 7274 2062 7261 696e 7079 2e6d 6174  port brainpy.mat
+0000e470: 6820 6173 2062 6d0a 2020 3e3e 3e20 626d  h as bm.  >>> bm
+0000e480: 2e72 616e 646f 6d2e 7065 726d 7574 6174  .random.permutat
+0000e490: 696f 6e28 3130 290a 2020 6172 7261 7928  ion(10).  array(
+0000e4a0: 5b31 2c20 372c 2034 2c20 332c 2030 2c20  [1, 7, 4, 3, 0, 
+0000e4b0: 392c 2032 2c20 352c 2038 2c20 365d 2920  9, 2, 5, 8, 6]) 
+0000e4c0: 2320 7261 6e64 6f6d 0a0a 2020 3e3e 3e20  # random..  >>> 
+0000e4d0: 626d 2e72 616e 646f 6d2e 7065 726d 7574  bm.random.permut
+0000e4e0: 6174 696f 6e28 5b31 2c20 342c 2039 2c20  ation([1, 4, 9, 
+0000e4f0: 3132 2c20 3135 5d29 0a20 2061 7272 6179  12, 15]).  array
+0000e500: 285b 3135 2c20 2031 2c20 2039 2c20 2034  ([15,  1,  9,  4
+0000e510: 2c20 3132 5d29 2023 2072 616e 646f 6d0a  , 12]) # random.
+0000e520: 0a20 203e 3e3e 2061 7272 203d 206e 702e  .  >>> arr = np.
+0000e530: 6172 616e 6765 2839 292e 7265 7368 6170  arange(9).reshap
+0000e540: 6528 2833 2c20 3329 290a 2020 3e3e 3e20  e((3, 3)).  >>> 
+0000e550: 626d 2e72 616e 646f 6d2e 7065 726d 7574  bm.random.permut
+0000e560: 6174 696f 6e28 6172 7229 0a20 2061 7272  ation(arr).  arr
+0000e570: 6179 285b 5b36 2c20 372c 2038 5d2c 2023  ay([[6, 7, 8], #
+0000e580: 2072 616e 646f 6d0a 2020 2020 2020 2020   random.        
+0000e590: 205b 302c 2031 2c20 325d 2c0a 2020 2020   [0, 1, 2],.    
+0000e5a0: 2020 2020 205b 332c 2034 2c20 355d 5d29       [3, 4, 5]])
+0000e5b0: 0a20 2022 2222 0a20 2072 6574 7572 6e20  .  """.  return 
+0000e5c0: 4445 4641 554c 542e 7065 726d 7574 6174  DEFAULT.permutat
+0000e5d0: 696f 6e28 782c 2061 7869 733d 6178 6973  ion(x, axis=axis
+0000e5e0: 2c20 696e 6465 7065 6e64 656e 743d 696e  , independent=in
+0000e5f0: 6465 7065 6e64 656e 742c 206b 6579 3d6b  dependent, key=k
+0000e600: 6579 290a 0a0a 6465 6620 7368 7566 666c  ey)...def shuffl
+0000e610: 6528 782c 2061 7869 733d 302c 206b 6579  e(x, axis=0, key
+0000e620: 3d4e 6f6e 6529 3a0a 2020 7222 2222 0a20  =None):.  r""". 
+0000e630: 204d 6f64 6966 7920 6120 7365 7175 656e   Modify a sequen
+0000e640: 6365 2069 6e2d 706c 6163 6520 6279 2073  ce in-place by s
+0000e650: 6875 6666 6c69 6e67 2069 7473 2063 6f6e  huffling its con
+0000e660: 7465 6e74 732e 0a0a 2020 5468 6973 2066  tents...  This f
+0000e670: 756e 6374 696f 6e20 6f6e 6c79 2073 6875  unction only shu
+0000e680: 6666 6c65 7320 7468 6520 6172 7261 7920  ffles the array 
+0000e690: 616c 6f6e 6720 7468 6520 6669 7273 7420  along the first 
+0000e6a0: 6178 6973 206f 6620 610a 2020 6d75 6c74  axis of a.  mult
+0000e6b0: 692d 6469 6d65 6e73 696f 6e61 6c20 6172  i-dimensional ar
+0000e6c0: 7261 792e 2054 6865 206f 7264 6572 206f  ray. The order o
+0000e6d0: 6620 7375 622d 6172 7261 7973 2069 7320  f sub-arrays is 
+0000e6e0: 6368 616e 6765 6420 6275 740a 2020 7468  changed but.  th
+0000e6f0: 6569 7220 636f 6e74 656e 7473 2072 656d  eir contents rem
+0000e700: 6169 6e73 2074 6865 2073 616d 652e 0a0a  ains the same...
+0000e710: 2020 5061 7261 6d65 7465 7273 0a20 202d    Parameters.  -
+0000e720: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 7820 3a20  ---------.  x : 
+0000e730: 6e64 6172 7261 7920 6f72 204d 7574 6162  ndarray or Mutab
+0000e740: 6c65 5365 7175 656e 6365 0a20 2020 2020  leSequence.     
+0000e750: 2054 6865 2061 7272 6179 2c20 6c69 7374   The array, list
+0000e760: 206f 7220 6d75 7461 626c 6520 7365 7175   or mutable sequ
+0000e770: 656e 6365 2074 6f20 6265 2073 6875 6666  ence to be shuff
+0000e780: 6c65 642e 0a0a 2020 5265 7475 726e 730a  led...  Returns.
+0000e790: 2020 2d2d 2d2d 2d2d 2d0a 2020 4e6f 6e65    -------.  None
+0000e7a0: 0a0a 2020 5365 6520 416c 736f 0a20 202d  ..  See Also.  -
+0000e7b0: 2d2d 2d2d 2d2d 2d0a 2020 7261 6e64 6f6d  -------.  random
+0000e7c0: 2e47 656e 6572 6174 6f72 2e73 6875 6666  .Generator.shuff
+0000e7d0: 6c65 3a20 7768 6963 6820 7368 6f75 6c64  le: which should
+0000e7e0: 2062 6520 7573 6564 2066 6f72 206e 6577   be used for new
+0000e7f0: 2063 6f64 652e 0a0a 2020 4578 616d 706c   code...  Exampl
+0000e800: 6573 0a20 202d 2d2d 2d2d 2d2d 2d0a 2020  es.  --------.  
+0000e810: 3e3e 3e20 696d 706f 7274 2062 7261 696e  >>> import brain
+0000e820: 7079 2e6d 6174 6820 6173 2062 6d0a 2020  py.math as bm.  
+0000e830: 3e3e 3e20 6172 7220 3d20 6e70 2e61 7261  >>> arr = np.ara
+0000e840: 6e67 6528 3130 290a 2020 3e3e 3e20 626d  nge(10).  >>> bm
+0000e850: 2e72 616e 646f 6d2e 7368 7566 666c 6528  .random.shuffle(
+0000e860: 6172 7229 0a20 203e 3e3e 2061 7272 0a20  arr).  >>> arr. 
+0000e870: 205b 3120 3720 3520 3220 3920 3420 3320   [1 7 5 2 9 4 3 
+0000e880: 3620 3020 385d 2023 2072 616e 646f 6d0a  6 0 8] # random.
+0000e890: 0a20 204d 756c 7469 2d64 696d 656e 7369  .  Multi-dimensi
+0000e8a0: 6f6e 616c 2061 7272 6179 7320 6172 6520  onal arrays are 
+0000e8b0: 6f6e 6c79 2073 6875 6666 6c65 6420 616c  only shuffled al
+0000e8c0: 6f6e 6720 7468 6520 6669 7273 7420 6178  ong the first ax
+0000e8d0: 6973 3a0a 0a20 203e 3e3e 2061 7272 203d  is:..  >>> arr =
+0000e8e0: 206e 702e 6172 616e 6765 2839 292e 7265   np.arange(9).re
+0000e8f0: 7368 6170 6528 2833 2c20 3329 290a 2020  shape((3, 3)).  
+0000e900: 3e3e 3e20 626d 2e72 616e 646f 6d2e 7368  >>> bm.random.sh
+0000e910: 7566 666c 6528 6172 7229 0a20 203e 3e3e  uffle(arr).  >>>
+0000e920: 2061 7272 0a20 2061 7272 6179 285b 5b33   arr.  array([[3
+0000e930: 2c20 342c 2035 5d2c 2023 2072 616e 646f  , 4, 5], # rando
+0000e940: 6d0a 2020 2020 2020 2020 205b 362c 2037  m.         [6, 7
+0000e950: 2c20 385d 2c0a 2020 2020 2020 2020 205b  , 8],.         [
+0000e960: 302c 2031 2c20 325d 5d29 0a20 2022 2222  0, 1, 2]]).  """
+0000e970: 0a20 2044 4546 4155 4c54 2e73 6875 6666  .  DEFAULT.shuff
+0000e980: 6c65 2878 2c20 6178 6973 2c20 6b65 793d  le(x, axis, key=
+0000e990: 6b65 7929 0a0a 0a64 6566 2062 6574 6128  key)...def beta(
+0000e9a0: 612c 2062 2c20 7369 7a65 3d4e 6f6e 652c  a, b, size=None,
+0000e9b0: 206b 6579 3d4e 6f6e 6529 3a0a 2020 7222   key=None):.  r"
+0000e9c0: 2222 0a20 2044 7261 7720 7361 6d70 6c65  "".  Draw sample
+0000e9d0: 7320 6672 6f6d 2061 2042 6574 6120 6469  s from a Beta di
+0000e9e0: 7374 7269 6275 7469 6f6e 2e0a 0a20 2054  stribution...  T
+0000e9f0: 6865 2042 6574 6120 6469 7374 7269 6275  he Beta distribu
+0000ea00: 7469 6f6e 2069 7320 6120 7370 6563 6961  tion is a specia
+0000ea10: 6c20 6361 7365 206f 6620 7468 6520 4469  l case of the Di
+0000ea20: 7269 6368 6c65 7420 6469 7374 7269 6275  richlet distribu
+0000ea30: 7469 6f6e 2c0a 2020 616e 6420 6973 2072  tion,.  and is r
+0000ea40: 656c 6174 6564 2074 6f20 7468 6520 4761  elated to the Ga
+0000ea50: 6d6d 6120 6469 7374 7269 6275 7469 6f6e  mma distribution
+0000ea60: 2e20 2049 7420 6861 7320 7468 6520 7072  .  It has the pr
+0000ea70: 6f62 6162 696c 6974 790a 2020 6469 7374  obability.  dist
+0000ea80: 7269 6275 7469 6f6e 2066 756e 6374 696f  ribution functio
+0000ea90: 6e0a 0a20 202e 2e20 6d61 7468 3a3a 2066  n..  .. math:: f
+0000eaa0: 2878 3b20 612c 6229 203d 205c 6672 6163  (x; a,b) = \frac
+0000eab0: 7b31 7d7b 4228 5c61 6c70 6861 2c20 5c62  {1}{B(\alpha, \b
+0000eac0: 6574 6129 7d20 785e 7b5c 616c 7068 6120  eta)} x^{\alpha 
+0000ead0: 2d20 317d 0a20 2020 2020 2020 2020 2020  - 1}.           
+0000eae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eaf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eb00: 2020 2020 2020 2020 2831 202d 2078 295e          (1 - x)^
+0000eb10: 7b5c 6265 7461 202d 2031 7d2c 0a0a 2020  {\beta - 1},..  
+0000eb20: 7768 6572 6520 7468 6520 6e6f 726d 616c  where the normal
+0000eb30: 697a 6174 696f 6e2c 2042 2c20 6973 2074  ization, B, is t
+0000eb40: 6865 2062 6574 6120 6675 6e63 7469 6f6e  he beta function
+0000eb50: 2c0a 0a20 202e 2e20 6d61 7468 3a3a 2042  ,..  .. math:: B
+0000eb60: 285c 616c 7068 612c 205c 6265 7461 2920  (\alpha, \beta) 
+0000eb70: 3d20 5c69 6e74 5f30 5e31 2074 5e7b 5c61  = \int_0^1 t^{\a
+0000eb80: 6c70 6861 202d 2031 7d0a 2020 2020 2020  lpha - 1}.      
+0000eb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eba0: 2020 2020 2020 2020 2028 3120 2d20 7429           (1 - t)
+0000ebb0: 5e7b 5c62 6574 6120 2d20 317d 2064 742e  ^{\beta - 1} dt.
+0000ebc0: 0a0a 2020 4974 2069 7320 6f66 7465 6e20  ..  It is often 
+0000ebd0: 7365 656e 2069 6e20 4261 7965 7369 616e  seen in Bayesian
+0000ebe0: 2069 6e66 6572 656e 6365 2061 6e64 206f   inference and o
+0000ebf0: 7264 6572 2073 7461 7469 7374 6963 732e  rder statistics.
+0000ec00: 0a0a 2020 5061 7261 6d65 7465 7273 0a20  ..  Parameters. 
+0000ec10: 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020 6120   ----------.  a 
+0000ec20: 3a20 666c 6f61 7420 6f72 2061 7272 6179  : float or array
+0000ec30: 5f6c 696b 6520 6f66 2066 6c6f 6174 730a  _like of floats.
+0000ec40: 2020 2020 2020 416c 7068 612c 2070 6f73        Alpha, pos
+0000ec50: 6974 6976 6520 283e 3029 2e0a 2020 6220  itive (>0)..  b 
+0000ec60: 3a20 666c 6f61 7420 6f72 2061 7272 6179  : float or array
+0000ec70: 5f6c 696b 6520 6f66 2066 6c6f 6174 730a  _like of floats.
+0000ec80: 2020 2020 2020 4265 7461 2c20 706f 7369        Beta, posi
+0000ec90: 7469 7665 2028 3e30 292e 0a20 2073 697a  tive (>0)..  siz
+0000eca0: 6520 3a20 696e 7420 6f72 2074 7570 6c65  e : int or tuple
+0000ecb0: 206f 6620 696e 7473 2c20 6f70 7469 6f6e   of ints, option
+0000ecc0: 616c 0a20 2020 2020 204f 7574 7075 7420  al.      Output 
+0000ecd0: 7368 6170 652e 2020 4966 2074 6865 2067  shape.  If the g
+0000ece0: 6976 656e 2073 6861 7065 2069 732c 2065  iven shape is, e
+0000ecf0: 2e67 2e2c 2060 6028 6d2c 206e 2c20 6b29  .g., ``(m, n, k)
+0000ed00: 6060 2c20 7468 656e 0a20 2020 2020 2060  ``, then.      `
+0000ed10: 606d 202a 206e 202a 206b 6060 2073 616d  `m * n * k`` sam
+0000ed20: 706c 6573 2061 7265 2064 7261 776e 2e20  ples are drawn. 
+0000ed30: 2049 6620 7369 7a65 2069 7320 6060 4e6f   If size is ``No
+0000ed40: 6e65 6060 2028 6465 6661 756c 7429 2c0a  ne`` (default),.
+0000ed50: 2020 2020 2020 6120 7369 6e67 6c65 2076        a single v
+0000ed60: 616c 7565 2069 7320 7265 7475 726e 6564  alue is returned
+0000ed70: 2069 6620 6060 6160 6020 616e 6420 6060   if ``a`` and ``
+0000ed80: 6260 6020 6172 6520 626f 7468 2073 6361  b`` are both sca
+0000ed90: 6c61 7273 2e0a 2020 2020 2020 4f74 6865  lars..      Othe
+0000eda0: 7277 6973 652c 2060 606e 702e 6272 6f61  rwise, ``np.broa
+0000edb0: 6463 6173 7428 612c 2062 292e 7369 7a65  dcast(a, b).size
+0000edc0: 6060 2073 616d 706c 6573 2061 7265 2064  `` samples are d
+0000edd0: 7261 776e 2e0a 0a20 2052 6574 7572 6e73  rawn...  Returns
+0000ede0: 0a20 202d 2d2d 2d2d 2d2d 0a20 206f 7574  .  -------.  out
+0000edf0: 203a 206e 6461 7272 6179 206f 7220 7363   : ndarray or sc
+0000ee00: 616c 6172 0a20 2020 2020 2044 7261 776e  alar.      Drawn
+0000ee10: 2073 616d 706c 6573 2066 726f 6d20 7468   samples from th
+0000ee20: 6520 7061 7261 6d65 7465 7269 7a65 6420  e parameterized 
+0000ee30: 6265 7461 2064 6973 7472 6962 7574 696f  beta distributio
+0000ee40: 6e2e 0a0a 2020 5365 6520 416c 736f 0a20  n...  See Also. 
+0000ee50: 202d 2d2d 2d2d 2d2d 2d0a 2020 7261 6e64   --------.  rand
+0000ee60: 6f6d 2e47 656e 6572 6174 6f72 2e62 6574  om.Generator.bet
+0000ee70: 613a 2077 6869 6368 2073 686f 756c 6420  a: which should 
+0000ee80: 6265 2075 7365 6420 666f 7220 6e65 7720  be used for new 
+0000ee90: 636f 6465 2e0a 2020 2222 220a 2020 7265  code..  """.  re
+0000eea0: 7475 726e 2044 4546 4155 4c54 2e62 6574  turn DEFAULT.bet
+0000eeb0: 6128 612c 2062 2c20 7369 7a65 3d73 697a  a(a, b, size=siz
+0000eec0: 652c 206b 6579 3d6b 6579 290a 0a0a 2320  e, key=key)...# 
+0000eed0: 4077 7261 7073 286e 702e 7261 6e64 6f6d  @wraps(np.random
+0000eee0: 2e65 7870 6f6e 656e 7469 616c 290a 6465  .exponential).de
+0000eef0: 6620 6578 706f 6e65 6e74 6961 6c28 7363  f exponential(sc
+0000ef00: 616c 653d 4e6f 6e65 2c20 7369 7a65 3d4e  ale=None, size=N
+0000ef10: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+0000ef20: 2020 7265 7475 726e 2044 4546 4155 4c54    return DEFAULT
+0000ef30: 2e65 7870 6f6e 656e 7469 616c 2873 6361  .exponential(sca
+0000ef40: 6c65 2c20 7369 7a65 2c20 6b65 793d 6b65  le, size, key=ke
+0000ef50: 7929 0a0a 0a23 2040 7772 6170 7328 6e70  y)...# @wraps(np
+0000ef60: 2e72 616e 646f 6d2e 6761 6d6d 6129 0a64  .random.gamma).d
+0000ef70: 6566 2067 616d 6d61 2873 6861 7065 2c20  ef gamma(shape, 
+0000ef80: 7363 616c 653d 4e6f 6e65 2c20 7369 7a65  scale=None, size
+0000ef90: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
+0000efa0: 3a0a 2020 7265 7475 726e 2044 4546 4155  :.  return DEFAU
+0000efb0: 4c54 2e67 616d 6d61 2873 6861 7065 2c20  LT.gamma(shape, 
+0000efc0: 7363 616c 652c 2073 697a 653d 7369 7a65  scale, size=size
+0000efd0: 2c20 6b65 793d 6b65 7929 0a0a 0a23 2040  , key=key)...# @
+0000efe0: 7772 6170 7328 6e70 2e72 616e 646f 6d2e  wraps(np.random.
+0000eff0: 6775 6d62 656c 290a 6465 6620 6775 6d62  gumbel).def gumb
+0000f000: 656c 286c 6f63 3d4e 6f6e 652c 2073 6361  el(loc=None, sca
+0000f010: 6c65 3d4e 6f6e 652c 2073 697a 653d 4e6f  le=None, size=No
+0000f020: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
+0000f030: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
+0000f040: 6775 6d62 656c 286c 6f63 2c20 7363 616c  gumbel(loc, scal
+0000f050: 652c 2073 697a 653d 7369 7a65 2c20 6b65  e, size=size, ke
+0000f060: 793d 6b65 7929 0a0a 0a23 2040 7772 6170  y=key)...# @wrap
+0000f070: 7328 6e70 2e72 616e 646f 6d2e 6c61 706c  s(np.random.lapl
+0000f080: 6163 6529 0a64 6566 206c 6170 6c61 6365  ace).def laplace
+0000f090: 286c 6f63 3d4e 6f6e 652c 2073 6361 6c65  (loc=None, scale
+0000f0a0: 3d4e 6f6e 652c 2073 697a 653d 4e6f 6e65  =None, size=None
+0000f0b0: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2072  , key=None):.  r
+0000f0c0: 6574 7572 6e20 4445 4641 554c 542e 6c61  eturn DEFAULT.la
+0000f0d0: 706c 6163 6528 6c6f 632c 2073 6361 6c65  place(loc, scale
+0000f0e0: 2c20 7369 7a65 2c20 6b65 793d 6b65 7929  , size, key=key)
+0000f0f0: 0a0a 0a23 2040 7772 6170 7328 6e70 2e72  ...# @wraps(np.r
+0000f100: 616e 646f 6d2e 6c6f 6769 7374 6963 290a  andom.logistic).
+0000f110: 6465 6620 6c6f 6769 7374 6963 286c 6f63  def logistic(loc
+0000f120: 3d4e 6f6e 652c 2073 6361 6c65 3d4e 6f6e  =None, scale=Non
+0000f130: 652c 2073 697a 653d 4e6f 6e65 2c20 6b65  e, size=None, ke
+0000f140: 793d 4e6f 6e65 293a 0a20 2072 6574 7572  y=None):.  retur
+0000f150: 6e20 4445 4641 554c 542e 6c6f 6769 7374  n DEFAULT.logist
+0000f160: 6963 286c 6f63 2c20 7363 616c 652c 2073  ic(loc, scale, s
+0000f170: 697a 652c 206b 6579 3d6b 6579 290a 0a0a  ize, key=key)...
+0000f180: 2320 4077 7261 7073 286e 702e 7261 6e64  # @wraps(np.rand
+0000f190: 6f6d 2e6e 6f72 6d61 6c29 0a64 6566 206e  om.normal).def n
+0000f1a0: 6f72 6d61 6c28 6c6f 633d 4e6f 6e65 2c20  ormal(loc=None, 
+0000f1b0: 7363 616c 653d 4e6f 6e65 2c20 7369 7a65  scale=None, size
+0000f1c0: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
+0000f1d0: 3a0a 2020 7265 7475 726e 2044 4546 4155  :.  return DEFAU
+0000f1e0: 4c54 2e6e 6f72 6d61 6c28 6c6f 632c 2073  LT.normal(loc, s
+0000f1f0: 6361 6c65 2c20 7369 7a65 2c20 6b65 793d  cale, size, key=
+0000f200: 6b65 7929 0a0a 0a23 2040 7772 6170 7328  key)...# @wraps(
+0000f210: 6e70 2e72 616e 646f 6d2e 7061 7265 746f  np.random.pareto
+0000f220: 290a 6465 6620 7061 7265 746f 2861 2c20  ).def pareto(a, 
+0000f230: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
+0000f240: 6f6e 6529 3a0a 2020 7265 7475 726e 2044  one):.  return D
+0000f250: 4546 4155 4c54 2e70 6172 6574 6f28 612c  EFAULT.pareto(a,
+0000f260: 2073 697a 652c 206b 6579 3d6b 6579 290a   size, key=key).
+0000f270: 0a0a 2320 4077 7261 7073 286e 702e 7261  ..# @wraps(np.ra
+0000f280: 6e64 6f6d 2e70 6f69 7373 6f6e 290a 6465  ndom.poisson).de
+0000f290: 6620 706f 6973 736f 6e28 6c61 6d3d 312e  f poisson(lam=1.
+0000f2a0: 302c 2073 697a 653d 4e6f 6e65 2c20 6b65  0, size=None, ke
+0000f2b0: 793d 4e6f 6e65 293a 0a20 2072 6574 7572  y=None):.  retur
+0000f2c0: 6e20 4445 4641 554c 542e 706f 6973 736f  n DEFAULT.poisso
+0000f2d0: 6e28 6c61 6d2c 2073 697a 652c 206b 6579  n(lam, size, key
+0000f2e0: 3d6b 6579 290a 0a0a 2320 4077 7261 7073  =key)...# @wraps
+0000f2f0: 286e 702e 7261 6e64 6f6d 2e73 7461 6e64  (np.random.stand
+0000f300: 6172 645f 6361 7563 6879 290a 6465 6620  ard_cauchy).def 
+0000f310: 7374 616e 6461 7264 5f63 6175 6368 7928  standard_cauchy(
+0000f320: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
+0000f330: 6f6e 6529 3a0a 2020 7265 7475 726e 2044  one):.  return D
+0000f340: 4546 4155 4c54 2e73 7461 6e64 6172 645f  EFAULT.standard_
+0000f350: 6361 7563 6879 2873 697a 652c 206b 6579  cauchy(size, key
+0000f360: 3d6b 6579 290a 0a0a 2320 4077 7261 7073  =key)...# @wraps
+0000f370: 286e 702e 7261 6e64 6f6d 2e73 7461 6e64  (np.random.stand
+0000f380: 6172 645f 6578 706f 6e65 6e74 6961 6c29  ard_exponential)
+0000f390: 0a64 6566 2073 7461 6e64 6172 645f 6578  .def standard_ex
+0000f3a0: 706f 6e65 6e74 6961 6c28 7369 7a65 3d4e  ponential(size=N
+0000f3b0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+0000f3c0: 2020 7265 7475 726e 2044 4546 4155 4c54    return DEFAULT
+0000f3d0: 2e73 7461 6e64 6172 645f 6578 706f 6e65  .standard_expone
+0000f3e0: 6e74 6961 6c28 7369 7a65 2c20 6b65 793d  ntial(size, key=
+0000f3f0: 6b65 7929 0a0a 0a23 2040 7772 6170 7328  key)...# @wraps(
+0000f400: 6e70 2e72 616e 646f 6d2e 7374 616e 6461  np.random.standa
+0000f410: 7264 5f67 616d 6d61 290a 6465 6620 7374  rd_gamma).def st
+0000f420: 616e 6461 7264 5f67 616d 6d61 2873 6861  andard_gamma(sha
+0000f430: 7065 2c20 7369 7a65 3d4e 6f6e 652c 206b  pe, size=None, k
+0000f440: 6579 3d4e 6f6e 6529 3a0a 2020 7265 7475  ey=None):.  retu
+0000f450: 726e 2044 4546 4155 4c54 2e73 7461 6e64  rn DEFAULT.stand
+0000f460: 6172 645f 6761 6d6d 6128 7368 6170 652c  ard_gamma(shape,
+0000f470: 2073 697a 652c 206b 6579 3d6b 6579 290a   size, key=key).
+0000f480: 0a0a 2320 4077 7261 7073 286e 702e 7261  ..# @wraps(np.ra
+0000f490: 6e64 6f6d 2e73 7461 6e64 6172 645f 6e6f  ndom.standard_no
+0000f4a0: 726d 616c 290a 6465 6620 7374 616e 6461  rmal).def standa
+0000f4b0: 7264 5f6e 6f72 6d61 6c28 7369 7a65 3d4e  rd_normal(size=N
+0000f4c0: 6f6e 652c 206b 6579 3d4e 6f6e 6529 3a0a  one, key=None):.
+0000f4d0: 2020 7265 7475 726e 2044 4546 4155 4c54    return DEFAULT
+0000f4e0: 2e73 7461 6e64 6172 645f 6e6f 726d 616c  .standard_normal
+0000f4f0: 2873 697a 652c 206b 6579 3d6b 6579 290a  (size, key=key).
+0000f500: 0a0a 2320 4077 7261 7073 286e 702e 7261  ..# @wraps(np.ra
+0000f510: 6e64 6f6d 2e73 7461 6e64 6172 645f 7429  ndom.standard_t)
+0000f520: 0a64 6566 2073 7461 6e64 6172 645f 7428  .def standard_t(
+0000f530: 6466 2c20 7369 7a65 3d4e 6f6e 652c 206b  df, size=None, k
+0000f540: 6579 3d4e 6f6e 6529 3a0a 2020 7265 7475  ey=None):.  retu
+0000f550: 726e 2044 4546 4155 4c54 2e73 7461 6e64  rn DEFAULT.stand
+0000f560: 6172 645f 7428 6466 2c20 7369 7a65 2c20  ard_t(df, size, 
+0000f570: 6b65 793d 6b65 7929 0a0a 0a23 2040 7772  key=key)...# @wr
+0000f580: 6170 7328 6e70 2e72 616e 646f 6d2e 756e  aps(np.random.un
+0000f590: 6966 6f72 6d29 0a64 6566 2075 6e69 666f  iform).def unifo
+0000f5a0: 726d 286c 6f77 3d30 2e30 2c20 6869 6768  rm(low=0.0, high
+0000f5b0: 3d31 2e30 2c20 7369 7a65 3d4e 6f6e 652c  =1.0, size=None,
+0000f5c0: 206b 6579 3d4e 6f6e 6529 3a0a 2020 7265   key=None):.  re
+0000f5d0: 7475 726e 2044 4546 4155 4c54 2e75 6e69  turn DEFAULT.uni
+0000f5e0: 666f 726d 286c 6f77 2c20 6869 6768 2c20  form(low, high, 
+0000f5f0: 7369 7a65 2c20 6b65 793d 6b65 7929 0a0a  size, key=key)..
+0000f600: 0a64 6566 2074 7275 6e63 6174 6564 5f6e  .def truncated_n
+0000f610: 6f72 6d61 6c28 6c6f 7765 722c 2075 7070  ormal(lower, upp
+0000f620: 6572 2c20 7369 7a65 3d4e 6f6e 652c 2073  er, size=None, s
+0000f630: 6361 6c65 3d4e 6f6e 652c 206b 6579 3d4e  cale=None, key=N
+0000f640: 6f6e 6529 3a0a 2020 2222 2253 616d 706c  one):.  """Sampl
+0000f650: 6520 7472 756e 6361 7465 6420 7374 616e  e truncated stan
+0000f660: 6461 7264 206e 6f72 6d61 6c20 7261 6e64  dard normal rand
+0000f670: 6f6d 2076 616c 7565 7320 7769 7468 2067  om values with g
+0000f680: 6976 656e 2073 6861 7065 2061 6e64 2064  iven shape and d
+0000f690: 7479 7065 2e0a 0a20 2050 6172 616d 6574  type...  Paramet
+0000f6a0: 6572 730a 2020 2d2d 2d2d 2d2d 2d2d 2d2d  ers.  ----------
+0000f6b0: 0a20 206c 6f77 6572 203a 2066 6c6f 6174  .  lower : float
+0000f6c0: 2c20 6e64 6172 7261 790a 2020 2020 4120  , ndarray.    A 
+0000f6d0: 666c 6f61 7420 6f72 2061 7272 6179 206f  float or array o
+0000f6e0: 6620 666c 6f61 7473 2072 6570 7265 7365  f floats represe
+0000f6f0: 6e74 696e 6720 7468 6520 6c6f 7765 7220  nting the lower 
+0000f700: 626f 756e 6420 666f 720a 2020 2020 7472  bound for.    tr
+0000f710: 756e 6361 7469 6f6e 2e20 4d75 7374 2062  uncation. Must b
+0000f720: 6520 6272 6f61 6463 6173 742d 636f 6d70  e broadcast-comp
+0000f730: 6174 6962 6c65 2077 6974 6820 6060 7570  atible with ``up
+0000f740: 7065 7260 602e 0a20 2075 7070 6572 203a  per``..  upper :
+0000f750: 2066 6c6f 6174 2c20 6e64 6172 7261 790a   float, ndarray.
+0000f760: 2020 2020 4120 666c 6f61 7420 6f72 2061      A float or a
+0000f770: 7272 6179 206f 6620 666c 6f61 7473 2072  rray of floats r
+0000f780: 6570 7265 7365 6e74 696e 6720 7468 6520  epresenting the 
+0000f790: 2075 7070 6572 2062 6f75 6e64 2066 6f72   upper bound for
+0000f7a0: 0a20 2020 2074 7275 6e63 6174 696f 6e2e  .    truncation.
+0000f7b0: 204d 7573 7420 6265 2062 726f 6164 6361   Must be broadca
+0000f7c0: 7374 2d63 6f6d 7061 7469 626c 6520 7769  st-compatible wi
+0000f7d0: 7468 2060 606c 6f77 6572 6060 2e0a 2020  th ``lower``..  
+0000f7e0: 7369 7a65 203a 206f 7074 696f 6e61 6c2c  size : optional,
+0000f7f0: 206c 6973 7420 6f66 2069 6e74 2c20 7475   list of int, tu
+0000f800: 706c 6520 6f66 2069 6e74 0a20 2020 2041  ple of int.    A
+0000f810: 2074 7570 6c65 206f 6620 6e6f 6e6e 6567   tuple of nonneg
+0000f820: 6174 6976 6520 696e 7465 6765 7273 2073  ative integers s
+0000f830: 7065 6369 6679 696e 6720 7468 6520 7265  pecifying the re
+0000f840: 7375 6c74 0a20 2020 2073 6861 7065 2e20  sult.    shape. 
+0000f850: 4d75 7374 2062 6520 6272 6f61 6463 6173  Must be broadcas
+0000f860: 742d 636f 6d70 6174 6962 6c65 2077 6974  t-compatible wit
+0000f870: 6820 6060 6c6f 7765 7260 6020 616e 6420  h ``lower`` and 
+0000f880: 6060 7570 7065 7260 602e 2054 6865 0a20  ``upper``. The. 
+0000f890: 2020 2064 6566 6175 6c74 2028 4e6f 6e65     default (None
+0000f8a0: 2920 7072 6f64 7563 6573 2061 2072 6573  ) produces a res
+0000f8b0: 756c 7420 7368 6170 6520 6279 2062 726f  ult shape by bro
+0000f8c0: 6164 6361 7374 696e 6720 6060 6c6f 7765  adcasting ``lowe
+0000f8d0: 7260 6020 616e 640a 2020 2020 6060 7570  r`` and.    ``up
+0000f8e0: 7065 7260 602e 0a20 2073 6361 6c65 203a  per``..  scale :
+0000f8f0: 2066 6c6f 6174 2c20 6e64 6172 7261 790a   float, ndarray.
+0000f900: 2020 2020 5374 616e 6461 7264 2064 6576      Standard dev
+0000f910: 6961 7469 6f6e 2028 7370 7265 6164 206f  iation (spread o
+0000f920: 7220 2277 6964 7468 2229 206f 6620 7468  r "width") of th
+0000f930: 6520 6469 7374 7269 6275 7469 6f6e 2e20  e distribution. 
+0000f940: 4d75 7374 2062 650a 2020 2020 6e6f 6e2d  Must be.    non-
+0000f950: 6e65 6761 7469 7665 2e0a 0a20 2052 6574  negative...  Ret
+0000f960: 7572 6e73 0a20 202d 2d2d 2d2d 2d2d 0a20  urns.  -------. 
+0000f970: 206f 7574 203a 2041 7272 6179 0a20 2020   out : Array.   
+0000f980: 2041 2072 616e 646f 6d20 6172 7261 7920   A random array 
+0000f990: 7769 7468 2074 6865 2073 7065 6369 6669  with the specifi
+0000f9a0: 6564 2064 7479 7065 2061 6e64 2073 6861  ed dtype and sha
+0000f9b0: 7065 2067 6976 656e 2062 7920 6060 7368  pe given by ``sh
+0000f9c0: 6170 6560 6020 6966 0a20 2020 2060 6073  ape`` if.    ``s
+0000f9d0: 6861 7065 6060 2069 7320 6e6f 7420 4e6f  hape`` is not No
+0000f9e0: 6e65 2c20 6f72 2065 6c73 6520 6279 2062  ne, or else by b
+0000f9f0: 726f 6164 6361 7374 696e 6720 6060 6c6f  roadcasting ``lo
+0000fa00: 7765 7260 6020 616e 6420 6060 7570 7065  wer`` and ``uppe
+0000fa10: 7260 602e 0a20 2020 2052 6574 7572 6e73  r``..    Returns
+0000fa20: 2076 616c 7565 7320 696e 2074 6865 206f   values in the o
+0000fa30: 7065 6e20 696e 7465 7276 616c 2060 6028  pen interval ``(
+0000fa40: 6c6f 7765 722c 2075 7070 6572 2960 602e  lower, upper)``.
+0000fa50: 0a20 2022 2222 0a20 2072 6574 7572 6e20  .  """.  return 
+0000fa60: 4445 4641 554c 542e 7472 756e 6361 7465  DEFAULT.truncate
+0000fa70: 645f 6e6f 726d 616c 286c 6f77 6572 2c20  d_normal(lower, 
+0000fa80: 7570 7065 722c 2073 697a 652c 2073 6361  upper, size, sca
+0000fa90: 6c65 2c20 6b65 793d 6b65 7929 0a0a 0a64  le, key=key)...d
+0000faa0: 6566 2062 6572 6e6f 756c 6c69 2870 3d30  ef bernoulli(p=0
+0000fab0: 2e35 2c20 7369 7a65 3d4e 6f6e 652c 206b  .5, size=None, k
+0000fac0: 6579 3d4e 6f6e 6529 3a0a 2020 2222 2253  ey=None):.  """S
+0000fad0: 616d 706c 6520 4265 726e 6f75 6c6c 6920  ample Bernoulli 
+0000fae0: 7261 6e64 6f6d 2076 616c 7565 7320 7769  random values wi
+0000faf0: 7468 2067 6976 656e 2073 6861 7065 2061  th given shape a
+0000fb00: 6e64 206d 6561 6e2e 0a0a 2020 5061 7261  nd mean...  Para
+0000fb10: 6d65 7465 7273 0a20 202d 2d2d 2d2d 2d2d  meters.  -------
+0000fb20: 2d2d 2d0a 2020 703a 2066 6c6f 6174 2c20  ---.  p: float, 
+0000fb30: 6172 7261 795f 6c69 6b65 2c20 6f70 7469  array_like, opti
+0000fb40: 6f6e 616c 0a20 2020 2041 2066 6c6f 6174  onal.    A float
+0000fb50: 206f 7220 6172 7261 7920 6f66 2066 6c6f   or array of flo
+0000fb60: 6174 7320 666f 7220 7468 6520 6d65 616e  ats for the mean
+0000fb70: 206f 6620 7468 6520 7261 6e64 6f6d 0a20   of the random. 
+0000fb80: 2020 2076 6172 6961 626c 6573 2e20 4d75     variables. Mu
+0000fb90: 7374 2062 6520 6272 6f61 6463 6173 742d  st be broadcast-
+0000fba0: 636f 6d70 6174 6962 6c65 2077 6974 6820  compatible with 
+0000fbb0: 6060 7368 6170 6560 6020 616e 6420 7468  ``shape`` and th
+0000fbc0: 6520 7661 6c75 6573 0a20 2020 2073 686f  e values.    sho
+0000fbd0: 756c 6420 6265 2077 6974 6869 6e20 5b30  uld be within [0
+0000fbe0: 2c20 315d 2e20 4465 6661 756c 7420 302e  , 1]. Default 0.
+0000fbf0: 352e 0a20 2073 697a 653a 206f 7074 696f  5..  size: optio
+0000fc00: 6e61 6c2c 2074 7570 6c65 206f 6620 696e  nal, tuple of in
+0000fc10: 742c 2069 6e74 0a20 2020 2041 2074 7570  t, int.    A tup
+0000fc20: 6c65 206f 6620 6e6f 6e6e 6567 6174 6976  le of nonnegativ
+0000fc30: 6520 696e 7465 6765 7273 2072 6570 7265  e integers repre
+0000fc40: 7365 6e74 696e 6720 7468 6520 7265 7375  senting the resu
+0000fc50: 6c74 0a20 2020 2073 6861 7065 2e20 4d75  lt.    shape. Mu
+0000fc60: 7374 2062 6520 6272 6f61 6463 6173 742d  st be broadcast-
+0000fc70: 636f 6d70 6174 6962 6c65 2077 6974 6820  compatible with 
+0000fc80: 6060 702e 7368 6170 6560 602e 2054 6865  ``p.shape``. The
+0000fc90: 2064 6566 6175 6c74 2028 4e6f 6e65 290a   default (None).
+0000fca0: 2020 2020 7072 6f64 7563 6573 2061 2072      produces a r
+0000fcb0: 6573 756c 7420 7368 6170 6520 6571 7561  esult shape equa
+0000fcc0: 6c20 746f 2060 6070 2e73 6861 7065 6060  l to ``p.shape``
+0000fcd0: 2e0a 0a20 2052 6574 7572 6e73 0a20 202d  ...  Returns.  -
+0000fce0: 2d2d 2d2d 2d2d 0a20 206f 7574 3a20 6172  ------.  out: ar
+0000fcf0: 7261 795f 6c69 6b65 0a20 2020 2041 2072  ray_like.    A r
+0000fd00: 616e 646f 6d20 6172 7261 7920 7769 7468  andom array with
+0000fd10: 2062 6f6f 6c65 616e 2064 7479 7065 2061   boolean dtype a
+0000fd20: 6e64 2073 6861 7065 2067 6976 656e 2062  nd shape given b
+0000fd30: 7920 6060 7368 6170 6560 6020 6966 2060  y ``shape`` if `
+0000fd40: 6073 6861 7065 6060 0a20 2020 2069 7320  `shape``.    is 
+0000fd50: 6e6f 7420 4e6f 6e65 2c20 6f72 2065 6c73  not None, or els
+0000fd60: 6520 6060 702e 7368 6170 6560 602e 0a20  e ``p.shape``.. 
+0000fd70: 2022 2222 0a20 2072 6574 7572 6e20 4445   """.  return DE
+0000fd80: 4641 554c 542e 6265 726e 6f75 6c6c 6928  FAULT.bernoulli(
+0000fd90: 702c 2073 697a 652c 206b 6579 3d6b 6579  p, size, key=key
+0000fda0: 290a 0a0a 2320 4077 7261 7073 286e 702e  )...# @wraps(np.
+0000fdb0: 7261 6e64 6f6d 2e6c 6f67 6e6f 726d 616c  random.lognormal
+0000fdc0: 290a 6465 6620 6c6f 676e 6f72 6d61 6c28  ).def lognormal(
+0000fdd0: 6d65 616e 3d4e 6f6e 652c 2073 6967 6d61  mean=None, sigma
+0000fde0: 3d4e 6f6e 652c 2073 697a 653d 4e6f 6e65  =None, size=None
+0000fdf0: 2c20 6b65 793d 4e6f 6e65 293a 0a20 2072  , key=None):.  r
+0000fe00: 6574 7572 6e20 4445 4641 554c 542e 6c6f  eturn DEFAULT.lo
+0000fe10: 676e 6f72 6d61 6c28 6d65 616e 2c20 7369  gnormal(mean, si
+0000fe20: 676d 612c 2073 697a 652c 206b 6579 3d6b  gma, size, key=k
+0000fe30: 6579 290a 0a0a 2320 4077 7261 7073 286e  ey)...# @wraps(n
+0000fe40: 702e 7261 6e64 6f6d 2e62 696e 6f6d 6961  p.random.binomia
+0000fe50: 6c29 0a64 6566 2062 696e 6f6d 6961 6c28  l).def binomial(
+0000fe60: 6e2c 2070 2c20 7369 7a65 3d4e 6f6e 652c  n, p, size=None,
+0000fe70: 206b 6579 3d4e 6f6e 6529 3a0a 2020 7265   key=None):.  re
+0000fe80: 7475 726e 2044 4546 4155 4c54 2e62 696e  turn DEFAULT.bin
+0000fe90: 6f6d 6961 6c28 6e2c 2070 2c20 7369 7a65  omial(n, p, size
+0000fea0: 2c20 6b65 793d 6b65 7929 0a0a 0a23 2040  , key=key)...# @
+0000feb0: 7772 6170 7328 6e70 2e72 616e 646f 6d2e  wraps(np.random.
+0000fec0: 6368 6973 7175 6172 6529 0a64 6566 2063  chisquare).def c
+0000fed0: 6869 7371 7561 7265 2864 662c 2073 697a  hisquare(df, siz
+0000fee0: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
+0000fef0: 293a 0a20 2072 6574 7572 6e20 4445 4641  ):.  return DEFA
+0000ff00: 554c 542e 6368 6973 7175 6172 6528 6466  ULT.chisquare(df
+0000ff10: 2c20 7369 7a65 2c20 6b65 793d 6b65 7929  , size, key=key)
+0000ff20: 0a0a 0a23 2040 7772 6170 7328 6e70 2e72  ...# @wraps(np.r
+0000ff30: 616e 646f 6d2e 6469 7269 6368 6c65 7429  andom.dirichlet)
+0000ff40: 0a64 6566 2064 6972 6963 686c 6574 2861  .def dirichlet(a
+0000ff50: 6c70 6861 2c20 7369 7a65 3d4e 6f6e 652c  lpha, size=None,
+0000ff60: 206b 6579 3d4e 6f6e 6529 3a0a 2020 7265   key=None):.  re
+0000ff70: 7475 726e 2044 4546 4155 4c54 2e64 6972  turn DEFAULT.dir
+0000ff80: 6963 686c 6574 2861 6c70 6861 2c20 7369  ichlet(alpha, si
+0000ff90: 7a65 2c20 6b65 793d 6b65 7929 0a0a 0a23  ze, key=key)...#
+0000ffa0: 2040 7772 6170 7328 6e70 2e72 616e 646f   @wraps(np.rando
+0000ffb0: 6d2e 6765 6f6d 6574 7269 6329 0a64 6566  m.geometric).def
+0000ffc0: 2067 656f 6d65 7472 6963 2870 2c20 7369   geometric(p, si
+0000ffd0: 7a65 3d4e 6f6e 652c 206b 6579 3d4e 6f6e  ze=None, key=Non
+0000ffe0: 6529 3a0a 2020 7265 7475 726e 2044 4546  e):.  return DEF
+0000fff0: 4155 4c54 2e67 656f 6d65 7472 6963 2870  AULT.geometric(p
+00010000: 2c20 7369 7a65 2c20 6b65 793d 6b65 7929  , size, key=key)
+00010010: 0a0a 0a23 2040 7772 6170 7328 6e70 2e72  ...# @wraps(np.r
+00010020: 616e 646f 6d2e 6629 0a64 6566 2066 2864  andom.f).def f(d
+00010030: 666e 756d 2c20 6466 6465 6e2c 2073 697a  fnum, dfden, siz
+00010040: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
+00010050: 293a 0a20 2072 6574 7572 6e20 4445 4641  ):.  return DEFA
+00010060: 554c 542e 6628 6466 6e75 6d2c 2064 6664  ULT.f(dfnum, dfd
+00010070: 656e 2c20 7369 7a65 2c20 6b65 793d 6b65  en, size, key=ke
+00010080: 7929 0a0a 0a23 2040 7772 6170 7328 6e70  y)...# @wraps(np
+00010090: 2e72 616e 646f 6d2e 6879 7065 7267 656f  .random.hypergeo
+000100a0: 6d65 7472 6963 290a 6465 6620 6879 7065  metric).def hype
+000100b0: 7267 656f 6d65 7472 6963 286e 676f 6f64  rgeometric(ngood
+000100c0: 2c20 6e62 6164 2c20 6e73 616d 706c 652c  , nbad, nsample,
+000100d0: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
+000100e0: 4e6f 6e65 293a 0a20 2072 6574 7572 6e20  None):.  return 
+000100f0: 4445 4641 554c 542e 6879 7065 7267 656f  DEFAULT.hypergeo
+00010100: 6d65 7472 6963 286e 676f 6f64 2c20 6e62  metric(ngood, nb
+00010110: 6164 2c20 6e73 616d 706c 652c 2073 697a  ad, nsample, siz
+00010120: 652c 206b 6579 3d6b 6579 290a 0a0a 2320  e, key=key)...# 
+00010130: 4077 7261 7073 286e 702e 7261 6e64 6f6d  @wraps(np.random
+00010140: 2e6c 6f67 7365 7269 6573 290a 6465 6620  .logseries).def 
+00010150: 6c6f 6773 6572 6965 7328 702c 2073 697a  logseries(p, siz
+00010160: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
+00010170: 293a 0a20 2072 6574 7572 6e20 4445 4641  ):.  return DEFA
+00010180: 554c 542e 6c6f 6773 6572 6965 7328 702c  ULT.logseries(p,
+00010190: 2073 697a 652c 206b 6579 3d6b 6579 290a   size, key=key).
+000101a0: 0a0a 2320 4077 7261 7073 286e 702e 7261  ..# @wraps(np.ra
+000101b0: 6e64 6f6d 2e6d 756c 7469 6e6f 6d69 616c  ndom.multinomial
+000101c0: 290a 6465 6620 6d75 6c74 696e 6f6d 6961  ).def multinomia
+000101d0: 6c28 6e2c 2070 7661 6c73 2c20 7369 7a65  l(n, pvals, size
+000101e0: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
+000101f0: 3a0a 2020 7265 7475 726e 2044 4546 4155  :.  return DEFAU
+00010200: 4c54 2e6d 756c 7469 6e6f 6d69 616c 286e  LT.multinomial(n
+00010210: 2c20 7076 616c 732c 2073 697a 652c 206b  , pvals, size, k
+00010220: 6579 3d6b 6579 290a 0a0a 2320 4077 7261  ey=key)...# @wra
+00010230: 7073 286e 702e 7261 6e64 6f6d 2e6d 756c  ps(np.random.mul
+00010240: 7469 7661 7269 6174 655f 6e6f 726d 616c  tivariate_normal
+00010250: 290a 6465 6620 6d75 6c74 6976 6172 6961  ).def multivaria
+00010260: 7465 5f6e 6f72 6d61 6c28 6d65 616e 2c20  te_normal(mean, 
+00010270: 636f 762c 2073 697a 653d 4e6f 6e65 2c20  cov, size=None, 
+00010280: 6d65 7468 6f64 3a20 7374 7220 3d20 2763  method: str = 'c
+00010290: 686f 6c65 736b 7927 2c20 6b65 793d 4e6f  holesky', key=No
+000102a0: 6e65 293a 0a20 2072 6574 7572 6e20 4445  ne):.  return DE
+000102b0: 4641 554c 542e 6d75 6c74 6976 6172 6961  FAULT.multivaria
+000102c0: 7465 5f6e 6f72 6d61 6c28 6d65 616e 2c20  te_normal(mean, 
+000102d0: 636f 762c 2073 697a 652c 206d 6574 686f  cov, size, metho
+000102e0: 642c 206b 6579 3d6b 6579 290a 0a0a 2320  d, key=key)...# 
+000102f0: 4077 7261 7073 286e 702e 7261 6e64 6f6d  @wraps(np.random
+00010300: 2e6e 6567 6174 6976 655f 6269 6e6f 6d69  .negative_binomi
+00010310: 616c 290a 6465 6620 6e65 6761 7469 7665  al).def negative
+00010320: 5f62 696e 6f6d 6961 6c28 6e2c 2070 2c20  _binomial(n, p, 
+00010330: 7369 7a65 3d4e 6f6e 652c 206b 6579 3d4e  size=None, key=N
+00010340: 6f6e 6529 3a0a 2020 7265 7475 726e 2044  one):.  return D
+00010350: 4546 4155 4c54 2e6e 6567 6174 6976 655f  EFAULT.negative_
+00010360: 6269 6e6f 6d69 616c 286e 2c20 702c 2073  binomial(n, p, s
+00010370: 697a 652c 206b 6579 3d6b 6579 290a 0a0a  ize, key=key)...
+00010380: 2320 4077 7261 7073 286e 702e 7261 6e64  # @wraps(np.rand
+00010390: 6f6d 2e6e 6f6e 6365 6e74 7261 6c5f 6368  om.noncentral_ch
+000103a0: 6973 7175 6172 6529 0a64 6566 206e 6f6e  isquare).def non
+000103b0: 6365 6e74 7261 6c5f 6368 6973 7175 6172  central_chisquar
+000103c0: 6528 6466 2c20 6e6f 6e63 2c20 7369 7a65  e(df, nonc, size
+000103d0: 3d4e 6f6e 652c 206b 6579 3d4e 6f6e 6529  =None, key=None)
+000103e0: 3a0a 2020 7265 7475 726e 2044 4546 4155  :.  return DEFAU
+000103f0: 4c54 2e6e 6f6e 6365 6e74 7261 6c5f 6368  LT.noncentral_ch
+00010400: 6973 7175 6172 6528 6466 2c20 6e6f 6e63  isquare(df, nonc
+00010410: 2c20 7369 7a65 2c20 6b65 793d 6b65 7929  , size, key=key)
+00010420: 0a0a 0a23 2040 7772 6170 7328 6e70 2e72  ...# @wraps(np.r
+00010430: 616e 646f 6d2e 6e6f 6e63 656e 7472 616c  andom.noncentral
+00010440: 5f66 290a 6465 6620 6e6f 6e63 656e 7472  _f).def noncentr
+00010450: 616c 5f66 2864 666e 756d 2c20 6466 6465  al_f(dfnum, dfde
+00010460: 6e2c 206e 6f6e 632c 2073 697a 653d 4e6f  n, nonc, size=No
+00010470: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
+00010480: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
+00010490: 6e6f 6e63 656e 7472 616c 5f66 2864 666e  noncentral_f(dfn
+000104a0: 756d 2c20 6466 6465 6e2c 206e 6f6e 632c  um, dfden, nonc,
+000104b0: 2073 697a 652c 206b 6579 3d6b 6579 290a   size, key=key).
+000104c0: 0a0a 2320 4077 7261 7073 286e 702e 7261  ..# @wraps(np.ra
+000104d0: 6e64 6f6d 2e70 6f77 6572 290a 6465 6620  ndom.power).def 
+000104e0: 706f 7765 7228 612c 2073 697a 653d 4e6f  power(a, size=No
+000104f0: 6e65 2c20 6b65 793d 4e6f 6e65 293a 0a20  ne, key=None):. 
+00010500: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
+00010510: 706f 7765 7228 612c 2073 697a 652c 206b  power(a, size, k
+00010520: 6579 3d6b 6579 290a 0a0a 2320 4077 7261  ey=key)...# @wra
+00010530: 7073 286e 702e 7261 6e64 6f6d 2e72 6179  ps(np.random.ray
+00010540: 6c65 6967 6829 0a64 6566 2072 6179 6c65  leigh).def rayle
+00010550: 6967 6828 7363 616c 653d 312e 302c 2073  igh(scale=1.0, s
+00010560: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+00010570: 6e65 293a 0a20 2072 6574 7572 6e20 4445  ne):.  return DE
+00010580: 4641 554c 542e 7261 796c 6569 6768 2873  FAULT.rayleigh(s
+00010590: 6361 6c65 2c20 7369 7a65 2c20 6b65 793d  cale, size, key=
+000105a0: 6b65 7929 0a0a 0a23 2040 7772 6170 7328  key)...# @wraps(
+000105b0: 6e70 2e72 616e 646f 6d2e 7472 6961 6e67  np.random.triang
+000105c0: 756c 6172 290a 6465 6620 7472 6961 6e67  ular).def triang
+000105d0: 756c 6172 2873 697a 653d 4e6f 6e65 2c20  ular(size=None, 
+000105e0: 6b65 793d 4e6f 6e65 293a 0a20 2072 6574  key=None):.  ret
+000105f0: 7572 6e20 4445 4641 554c 542e 7472 6961  urn DEFAULT.tria
+00010600: 6e67 756c 6172 2873 697a 652c 206b 6579  ngular(size, key
+00010610: 3d6b 6579 290a 0a0a 2320 4077 7261 7073  =key)...# @wraps
+00010620: 286e 702e 7261 6e64 6f6d 2e76 6f6e 6d69  (np.random.vonmi
+00010630: 7365 7329 0a64 6566 2076 6f6e 6d69 7365  ses).def vonmise
+00010640: 7328 6d75 2c20 6b61 7070 612c 2073 697a  s(mu, kappa, siz
+00010650: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
+00010660: 293a 0a20 2072 6574 7572 6e20 4445 4641  ):.  return DEFA
+00010670: 554c 542e 766f 6e6d 6973 6573 286d 752c  ULT.vonmises(mu,
+00010680: 206b 6170 7061 2c20 7369 7a65 2c20 6b65   kappa, size, ke
+00010690: 793d 6b65 7929 0a0a 0a23 2040 7772 6170  y=key)...# @wrap
+000106a0: 7328 6e70 2e72 616e 646f 6d2e 7761 6c64  s(np.random.wald
+000106b0: 290a 6465 6620 7761 6c64 286d 6561 6e2c  ).def wald(mean,
+000106c0: 2073 6361 6c65 2c20 7369 7a65 3d4e 6f6e   scale, size=Non
+000106d0: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
+000106e0: 7265 7475 726e 2044 4546 4155 4c54 2e77  return DEFAULT.w
+000106f0: 616c 6428 6d65 616e 2c20 7363 616c 652c  ald(mean, scale,
+00010700: 2073 697a 652c 206b 6579 3d6b 6579 290a   size, key=key).
+00010710: 0a0a 6465 6620 7765 6962 756c 6c28 612c  ..def weibull(a,
+00010720: 2073 697a 653d 4e6f 6e65 2c20 6b65 793d   size=None, key=
+00010730: 4e6f 6e65 293a 0a20 2072 2222 220a 2020  None):.  r""".  
+00010740: 4472 6177 2073 616d 706c 6573 2066 726f  Draw samples fro
+00010750: 6d20 6120 5765 6962 756c 6c20 6469 7374  m a Weibull dist
+00010760: 7269 6275 7469 6f6e 2e0a 2020 2020 0a20  ribution..    . 
+00010770: 2044 7261 7720 7361 6d70 6c65 7320 6672   Draw samples fr
+00010780: 6f6d 2061 2031 2d70 6172 616d 6574 6572  om a 1-parameter
+00010790: 2057 6569 6275 6c6c 2064 6973 7472 6962   Weibull distrib
+000107a0: 7574 696f 6e20 7769 7468 2074 6865 2067  ution with the g
+000107b0: 6976 656e 0a20 2073 6861 7065 2070 6172  iven.  shape par
+000107c0: 616d 6574 6572 2060 6160 2e0a 0a20 202e  ameter `a`...  .
+000107d0: 2e20 6d61 7468 3a3a 2058 203d 2028 2d6c  . math:: X = (-l
+000107e0: 6e28 5529 295e 7b31 2f61 7d0a 0a20 2048  n(U))^{1/a}..  H
+000107f0: 6572 652c 2055 2069 7320 6472 6177 6e20  ere, U is drawn 
+00010800: 6672 6f6d 2074 6865 2075 6e69 666f 726d  from the uniform
+00010810: 2064 6973 7472 6962 7574 696f 6e20 6f76   distribution ov
+00010820: 6572 2028 302c 315d 2e0a 0a20 2054 6865  er (0,1]...  The
+00010830: 206d 6f72 6520 636f 6d6d 6f6e 2032 2d70   more common 2-p
+00010840: 6172 616d 6574 6572 2057 6569 6275 6c6c  arameter Weibull
+00010850: 2c20 696e 636c 7564 696e 6720 6120 7363  , including a sc
+00010860: 616c 6520 7061 7261 6d65 7465 720a 2020  ale parameter.  
+00010870: 3a6d 6174 683a 605c 6c61 6d62 6461 6020  :math:`\lambda` 
+00010880: 6973 206a 7573 7420 3a6d 6174 683a 6058  is just :math:`X
+00010890: 203d 205c 6c61 6d62 6461 282d 6c6e 2855   = \lambda(-ln(U
+000108a0: 2929 5e7b 312f 617d 602e 0a0a 2020 2e2e  ))^{1/a}`...  ..
+000108b0: 206e 6f74 653a 3a0a 2020 2020 2020 4e65   note::.      Ne
+000108c0: 7720 636f 6465 2073 686f 756c 6420 7573  w code should us
+000108d0: 6520 7468 6520 6060 7765 6962 756c 6c60  e the ``weibull`
+000108e0: 6020 6d65 7468 6f64 206f 6620 6120 6060  ` method of a ``
+000108f0: 6465 6661 756c 745f 726e 6728 2960 600a  default_rng()``.
+00010900: 2020 2020 2020 696e 7374 616e 6365 2069        instance i
+00010910: 6e73 7465 6164 3b20 706c 6561 7365 2073  nstead; please s
+00010920: 6565 2074 6865 203a 7265 663a 6072 616e  ee the :ref:`ran
+00010930: 646f 6d2d 7175 6963 6b2d 7374 6172 7460  dom-quick-start`
+00010940: 2e0a 0a20 2050 6172 616d 6574 6572 730a  ...  Parameters.
+00010950: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2061    ----------.  a
+00010960: 203a 2066 6c6f 6174 206f 7220 6172 7261   : float or arra
+00010970: 795f 6c69 6b65 206f 6620 666c 6f61 7473  y_like of floats
+00010980: 0a20 2020 2020 2053 6861 7065 2070 6172  .      Shape par
+00010990: 616d 6574 6572 206f 6620 7468 6520 6469  ameter of the di
+000109a0: 7374 7269 6275 7469 6f6e 2e20 204d 7573  stribution.  Mus
+000109b0: 7420 6265 206e 6f6e 6e65 6761 7469 7665  t be nonnegative
+000109c0: 2e0a 2020 7369 7a65 203a 2069 6e74 206f  ..  size : int o
+000109d0: 7220 7475 706c 6520 6f66 2069 6e74 732c  r tuple of ints,
+000109e0: 206f 7074 696f 6e61 6c0a 2020 2020 2020   optional.      
+000109f0: 4f75 7470 7574 2073 6861 7065 2e20 2049  Output shape.  I
+00010a00: 6620 7468 6520 6769 7665 6e20 7368 6170  f the given shap
+00010a10: 6520 6973 2c20 652e 672e 2c20 6060 286d  e is, e.g., ``(m
+00010a20: 2c20 6e2c 206b 2960 602c 2074 6865 6e0a  , n, k)``, then.
+00010a30: 2020 2020 2020 6060 6d20 2a20 6e20 2a20        ``m * n * 
+00010a40: 6b60 6020 7361 6d70 6c65 7320 6172 6520  k`` samples are 
+00010a50: 6472 6177 6e2e 2020 4966 2073 697a 6520  drawn.  If size 
+00010a60: 6973 2060 604e 6f6e 6560 6020 2864 6566  is ``None`` (def
+00010a70: 6175 6c74 292c 0a20 2020 2020 2061 2073  ault),.      a s
+00010a80: 696e 676c 6520 7661 6c75 6520 6973 2072  ingle value is r
+00010a90: 6574 7572 6e65 6420 6966 2060 6061 6060  eturned if ``a``
+00010aa0: 2069 7320 6120 7363 616c 6172 2e20 204f   is a scalar.  O
+00010ab0: 7468 6572 7769 7365 2c0a 2020 2020 2020  therwise,.      
+00010ac0: 6060 6e70 2e61 7272 6179 2861 292e 7369  ``np.array(a).si
+00010ad0: 7a65 6060 2073 616d 706c 6573 2061 7265  ze`` samples are
+00010ae0: 2064 7261 776e 2e0a 0a20 2052 6574 7572   drawn...  Retur
+00010af0: 6e73 0a20 202d 2d2d 2d2d 2d2d 0a20 206f  ns.  -------.  o
+00010b00: 7574 203a 206e 6461 7272 6179 206f 7220  ut : ndarray or 
+00010b10: 7363 616c 6172 0a20 2020 2020 2044 7261  scalar.      Dra
+00010b20: 776e 2073 616d 706c 6573 2066 726f 6d20  wn samples from 
+00010b30: 7468 6520 7061 7261 6d65 7465 7269 7a65  the parameterize
+00010b40: 6420 5765 6962 756c 6c20 6469 7374 7269  d Weibull distri
+00010b50: 6275 7469 6f6e 2e0a 0a20 2053 6565 2041  bution...  See A
+00010b60: 6c73 6f0a 2020 2d2d 2d2d 2d2d 2d2d 0a20  lso.  --------. 
+00010b70: 2073 6369 7079 2e73 7461 7473 2e77 6569   scipy.stats.wei
+00010b80: 6275 6c6c 5f6d 6178 0a20 2073 6369 7079  bull_max.  scipy
+00010b90: 2e73 7461 7473 2e77 6569 6275 6c6c 5f6d  .stats.weibull_m
+00010ba0: 696e 0a20 2073 6369 7079 2e73 7461 7473  in.  scipy.stats
+00010bb0: 2e67 656e 6578 7472 656d 650a 2020 6775  .genextreme.  gu
+00010bc0: 6d62 656c 0a20 2072 616e 646f 6d2e 4765  mbel.  random.Ge
+00010bd0: 6e65 7261 746f 722e 7765 6962 756c 6c3a  nerator.weibull:
+00010be0: 2077 6869 6368 2073 686f 756c 6420 6265   which should be
+00010bf0: 2075 7365 6420 666f 7220 6e65 7720 636f   used for new co
+00010c00: 6465 2e0a 0a20 204e 6f74 6573 0a20 202d  de...  Notes.  -
+00010c10: 2d2d 2d2d 0a20 2054 6865 2057 6569 6275  ----.  The Weibu
+00010c20: 6c6c 2028 6f72 2054 7970 6520 4949 4920  ll (or Type III 
+00010c30: 6173 796d 7074 6f74 6963 2065 7874 7265  asymptotic extre
+00010c40: 6d65 2076 616c 7565 2064 6973 7472 6962  me value distrib
+00010c50: 7574 696f 6e0a 2020 666f 7220 736d 616c  ution.  for smal
+00010c60: 6c65 7374 2076 616c 7565 732c 2053 4556  lest values, SEV
+00010c70: 2054 7970 6520 4949 492c 206f 7220 526f   Type III, or Ro
+00010c80: 7369 6e2d 5261 6d6d 6c65 720a 2020 6469  sin-Rammler.  di
+00010c90: 7374 7269 6275 7469 6f6e 2920 6973 206f  stribution) is o
+00010ca0: 6e65 206f 6620 6120 636c 6173 7320 6f66  ne of a class of
+00010cb0: 2047 656e 6572 616c 697a 6564 2045 7874   Generalized Ext
+00010cc0: 7265 6d65 2056 616c 7565 0a20 2028 4745  reme Value.  (GE
+00010cd0: 5629 2064 6973 7472 6962 7574 696f 6e73  V) distributions
+00010ce0: 2075 7365 6420 696e 206d 6f64 656c 696e   used in modelin
+00010cf0: 6720 6578 7472 656d 6520 7661 6c75 6520  g extreme value 
+00010d00: 7072 6f62 6c65 6d73 2e0a 2020 5468 6973  problems..  This
+00010d10: 2063 6c61 7373 2069 6e63 6c75 6465 7320   class includes 
+00010d20: 7468 6520 4775 6d62 656c 2061 6e64 2046  the Gumbel and F
+00010d30: 7265 6368 6574 2064 6973 7472 6962 7574  rechet distribut
+00010d40: 696f 6e73 2e0a 0a20 2054 6865 2070 726f  ions...  The pro
+00010d50: 6261 6269 6c69 7479 2064 656e 7369 7479  bability density
+00010d60: 2066 6f72 2074 6865 2057 6569 6275 6c6c   for the Weibull
+00010d70: 2064 6973 7472 6962 7574 696f 6e20 6973   distribution is
+00010d80: 0a0a 2020 2e2e 206d 6174 683a 3a20 7028  ..  .. math:: p(
+00010d90: 7829 203d 205c 6672 6163 7b61 7d0a 2020  x) = \frac{a}.  
+00010da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010db0: 207b 5c6c 616d 6264 617d 285c 6672 6163   {\lambda}(\frac
+00010dc0: 7b78 7d7b 5c6c 616d 6264 617d 295e 7b61  {x}{\lambda})^{a
+00010dd0: 2d31 7d65 5e7b 2d28 782f 5c6c 616d 6264  -1}e^{-(x/\lambd
+00010de0: 6129 5e61 7d2c 0a0a 2020 7768 6572 6520  a)^a},..  where 
+00010df0: 3a6d 6174 683a 6061 6020 6973 2074 6865  :math:`a` is the
+00010e00: 2073 6861 7065 2061 6e64 203a 6d61 7468   shape and :math
+00010e10: 3a60 5c6c 616d 6264 6160 2074 6865 2073  :`\lambda` the s
+00010e20: 6361 6c65 2e0a 0a20 2054 6865 2066 756e  cale...  The fun
+00010e30: 6374 696f 6e20 6861 7320 6974 7320 7065  ction has its pe
+00010e40: 616b 2028 7468 6520 6d6f 6465 2920 6174  ak (the mode) at
+00010e50: 0a20 203a 6d61 7468 3a60 5c6c 616d 6264  .  :math:`\lambd
+00010e60: 6128 5c66 7261 637b 612d 317d 7b61 7d29  a(\frac{a-1}{a})
+00010e70: 5e7b 312f 617d 602e 0a0a 2020 5768 656e  ^{1/a}`...  When
+00010e80: 2060 6061 203d 2031 6060 2c20 7468 6520   ``a = 1``, the 
+00010e90: 5765 6962 756c 6c20 6469 7374 7269 6275  Weibull distribu
+00010ea0: 7469 6f6e 2072 6564 7563 6573 2074 6f20  tion reduces to 
+00010eb0: 7468 6520 6578 706f 6e65 6e74 6961 6c0a  the exponential.
+00010ec0: 2020 6469 7374 7269 6275 7469 6f6e 2e0a    distribution..
+00010ed0: 0a20 2052 6566 6572 656e 6365 730a 2020  .  References.  
+00010ee0: 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 202e 2e20  ----------.  .. 
+00010ef0: 5b31 5d20 5761 6c6f 6464 6920 5765 6962  [1] Waloddi Weib
+00010f00: 756c 6c2c 2052 6f79 616c 2054 6563 686e  ull, Royal Techn
+00010f10: 6963 616c 2055 6e69 7665 7273 6974 792c  ical University,
+00010f20: 2053 746f 636b 686f 6c6d 2c0a 2020 2020   Stockholm,.    
+00010f30: 2020 2020 2031 3933 3920 2241 2053 7461       1939 "A Sta
+00010f40: 7469 7374 6963 616c 2054 6865 6f72 7920  tistical Theory 
+00010f50: 4f66 2054 6865 2053 7472 656e 6774 6820  Of The Strength 
+00010f60: 4f66 204d 6174 6572 6961 6c73 222c 0a20  Of Materials",. 
+00010f70: 2020 2020 2020 2020 496e 6765 6e69 6f72          Ingenior
+00010f80: 7376 6574 656e 736b 6170 7361 6b61 6465  svetenskapsakade
+00010f90: 6d69 656e 7320 4861 6e64 6c69 6e67 6172  miens Handlingar
+00010fa0: 204e 7220 3135 312c 2031 3933 392c 0a20   Nr 151, 1939,. 
+00010fb0: 2020 2020 2020 2020 4765 6e65 7261 6c73          Generals
+00010fc0: 7461 6265 6e73 204c 6974 6f67 7261 6669  tabens Litografi
+00010fd0: 736b 6120 416e 7374 616c 7473 2046 6f72  ska Anstalts For
+00010fe0: 6c61 672c 2053 746f 636b 686f 6c6d 2e0a  lag, Stockholm..
+00010ff0: 2020 2e2e 205b 325d 2057 616c 6f64 6469    .. [2] Waloddi
+00011000: 2057 6569 6275 6c6c 2c20 2241 2053 7461   Weibull, "A Sta
+00011010: 7469 7374 6963 616c 2044 6973 7472 6962  tistical Distrib
+00011020: 7574 696f 6e20 4675 6e63 7469 6f6e 206f  ution Function o
+00011030: 660a 2020 2020 2020 2020 2057 6964 6520  f.         Wide 
+00011040: 4170 706c 6963 6162 696c 6974 7922 2c20  Applicability", 
+00011050: 4a6f 7572 6e61 6c20 4f66 2041 7070 6c69  Journal Of Appli
+00011060: 6564 204d 6563 6861 6e69 6373 2041 534d  ed Mechanics ASM
+00011070: 4520 5061 7065 720a 2020 2020 2020 2020  E Paper.        
+00011080: 2031 3935 312e 0a20 202e 2e20 5b33 5d20   1951..  .. [3] 
+00011090: 5769 6b69 7065 6469 612c 2022 5765 6962  Wikipedia, "Weib
+000110a0: 756c 6c20 6469 7374 7269 6275 7469 6f6e  ull distribution
+000110b0: 222c 0a20 2020 2020 2020 2020 6874 7470  ",.         http
+000110c0: 733a 2f2f 656e 2e77 696b 6970 6564 6961  s://en.wikipedia
+000110d0: 2e6f 7267 2f77 696b 692f 5765 6962 756c  .org/wiki/Weibul
+000110e0: 6c5f 6469 7374 7269 6275 7469 6f6e 0a0a  l_distribution..
+000110f0: 2020 4578 616d 706c 6573 0a20 202d 2d2d    Examples.  ---
+00011100: 2d2d 2d2d 2d0a 2020 4472 6177 2073 616d  -----.  Draw sam
+00011110: 706c 6573 2066 726f 6d20 7468 6520 6469  ples from the di
+00011120: 7374 7269 6275 7469 6f6e 3a0a 0a20 203e  stribution:..  >
+00011130: 3e3e 2061 203d 2035 2e20 2320 7368 6170  >> a = 5. # shap
+00011140: 650a 2020 3e3e 3e20 7320 3d20 6272 6169  e.  >>> s = brai
+00011150: 6e70 792e 6d61 7468 2e72 616e 646f 6d2e  npy.math.random.
+00011160: 7765 6962 756c 6c28 612c 2031 3030 3029  weibull(a, 1000)
+00011170: 0a0a 2020 4469 7370 6c61 7920 7468 6520  ..  Display the 
+00011180: 6869 7374 6f67 7261 6d20 6f66 2074 6865  histogram of the
+00011190: 2073 616d 706c 6573 2c20 616c 6f6e 6720   samples, along 
+000111a0: 7769 7468 0a20 2074 6865 2070 726f 6261  with.  the proba
+000111b0: 6269 6c69 7479 2064 656e 7369 7479 2066  bility density f
+000111c0: 756e 6374 696f 6e3a 0a0a 2020 3e3e 3e20  unction:..  >>> 
+000111d0: 696d 706f 7274 206d 6174 706c 6f74 6c69  import matplotli
+000111e0: 622e 7079 706c 6f74 2061 7320 706c 740a  b.pyplot as plt.
+000111f0: 2020 3e3e 3e20 7820 3d20 6e70 2e61 7261    >>> x = np.ara
+00011200: 6e67 6528 312c 3130 302e 292f 3530 2e0a  nge(1,100.)/50..
+00011210: 2020 3e3e 3e20 6465 6620 7765 6962 2878    >>> def weib(x
+00011220: 2c6e 2c61 293a 0a20 202e 2e2e 2020 2020  ,n,a):.  ...    
+00011230: 2072 6574 7572 6e20 2861 202f 206e 2920   return (a / n) 
+00011240: 2a20 2878 202f 206e 292a 2a28 6120 2d20  * (x / n)**(a - 
+00011250: 3129 202a 206e 702e 6578 7028 2d28 7820  1) * np.exp(-(x 
+00011260: 2f20 6e29 2a2a 6129 0a0a 2020 3e3e 3e20  / n)**a)..  >>> 
+00011270: 636f 756e 742c 2062 696e 732c 2069 676e  count, bins, ign
+00011280: 6f72 6564 203d 2070 6c74 2e68 6973 7428  ored = plt.hist(
+00011290: 6272 6169 6e70 792e 6d61 7468 2e72 616e  brainpy.math.ran
+000112a0: 646f 6d2e 7765 6962 756c 6c28 352e 2c31  dom.weibull(5.,1
+000112b0: 3030 3029 290a 2020 3e3e 3e20 7820 3d20  000)).  >>> x = 
+000112c0: 6e70 2e61 7261 6e67 6528 312c 3130 302e  np.arange(1,100.
+000112d0: 292f 3530 2e0a 2020 3e3e 3e20 7363 616c  )/50..  >>> scal
+000112e0: 6520 3d20 636f 756e 742e 6d61 7828 292f  e = count.max()/
+000112f0: 7765 6962 2878 2c20 312e 2c20 352e 292e  weib(x, 1., 5.).
+00011300: 6d61 7828 290a 2020 3e3e 3e20 706c 742e  max().  >>> plt.
+00011310: 706c 6f74 2878 2c20 7765 6962 2878 2c20  plot(x, weib(x, 
+00011320: 312e 2c20 352e 292a 7363 616c 6529 0a20  1., 5.)*scale). 
+00011330: 203e 3e3e 2070 6c74 2e73 686f 7728 290a   >>> plt.show().
+00011340: 0a20 2022 2222 0a20 2072 6574 7572 6e20  .  """.  return 
+00011350: 4445 4641 554c 542e 7765 6962 756c 6c28  DEFAULT.weibull(
+00011360: 612c 2073 697a 652c 206b 6579 3d6b 6579  a, size, key=key
+00011370: 290a 0a0a 6465 6620 7765 6962 756c 6c5f  )...def weibull_
+00011380: 6d69 6e28 612c 2073 6361 6c65 3d4e 6f6e  min(a, scale=Non
+00011390: 652c 2073 697a 653d 4e6f 6e65 2c20 6b65  e, size=None, ke
+000113a0: 793d 4e6f 6e65 293a 0a20 2022 2222 5361  y=None):.  """Sa
+000113b0: 6d70 6c65 2066 726f 6d20 6120 5765 6962  mple from a Weib
+000113c0: 756c 6c20 6469 7374 7269 6275 7469 6f6e  ull distribution
+000113d0: 2e0a 0a20 2054 6865 2073 6369 7079 2063  ...  The scipy c
+000113e0: 6f75 6e74 6572 7061 7274 2069 7320 6073  ounterpart is `s
+000113f0: 6369 7079 2e73 7461 7473 2e77 6569 6275  cipy.stats.weibu
+00011400: 6c6c 5f6d 696e 602e 0a0a 2020 4172 6773  ll_min`...  Args
+00011410: 3a0a 2020 2020 7363 616c 653a 2054 6865  :.    scale: The
+00011420: 2073 6361 6c65 2070 6172 616d 6574 6572   scale parameter
+00011430: 206f 6620 7468 6520 6469 7374 7269 6275   of the distribu
+00011440: 7469 6f6e 2e0a 2020 2020 636f 6e63 656e  tion..    concen
+00011450: 7472 6174 696f 6e3a 2054 6865 2063 6f6e  tration: The con
+00011460: 6365 6e74 7261 7469 6f6e 2070 6172 616d  centration param
+00011470: 6574 6572 206f 6620 7468 6520 6469 7374  eter of the dist
+00011480: 7269 6275 7469 6f6e 2e0a 2020 2020 7368  ribution..    sh
+00011490: 6170 653a 2054 6865 2073 6861 7065 2061  ape: The shape a
+000114a0: 6464 6564 2074 6f20 7468 6520 7061 7261  dded to the para
+000114b0: 6d65 7465 7273 206c 6f63 2061 6e64 2073  meters loc and s
+000114c0: 6361 6c65 2062 726f 6164 6361 7374 6162  cale broadcastab
+000114d0: 6c65 2073 6861 7065 2e0a 2020 2020 6474  le shape..    dt
+000114e0: 7970 653a 2054 6865 2074 7970 6520 7573  ype: The type us
+000114f0: 6564 2066 6f72 2073 616d 706c 6573 2e0a  ed for samples..
+00011500: 2020 2020 6b65 793a 2061 2050 524e 4720      key: a PRNG 
+00011510: 6b65 7920 6f72 2061 2073 6565 642e 0a0a  key or a seed...
+00011520: 2020 5265 7475 726e 733a 0a20 2020 2041    Returns:.    A
+00011530: 206a 6e70 2e61 7272 6179 206f 6620 7361   jnp.array of sa
+00011540: 6d70 6c65 732e 0a0a 2020 2222 220a 2020  mples...  """.  
+00011550: 7265 7475 726e 2044 4546 4155 4c54 2e77  return DEFAULT.w
+00011560: 6569 6275 6c6c 5f6d 696e 2861 2c20 7363  eibull_min(a, sc
+00011570: 616c 652c 2073 697a 652c 206b 6579 3d6b  ale, size, key=k
+00011580: 6579 290a 0a0a 6465 6620 7a69 7066 2861  ey)...def zipf(a
+00011590: 2c20 7369 7a65 3d4e 6f6e 652c 206b 6579  , size=None, key
+000115a0: 3d4e 6f6e 6529 3a0a 2020 7222 2222 0a20  =None):.  r""". 
+000115b0: 2044 7261 7720 7361 6d70 6c65 7320 6672   Draw samples fr
+000115c0: 6f6d 2061 205a 6970 6620 6469 7374 7269  om a Zipf distri
+000115d0: 6275 7469 6f6e 2e0a 0a20 2053 616d 706c  bution...  Sampl
+000115e0: 6573 2061 7265 2064 7261 776e 2066 726f  es are drawn fro
+000115f0: 6d20 6120 5a69 7066 2064 6973 7472 6962  m a Zipf distrib
+00011600: 7574 696f 6e20 7769 7468 2073 7065 6369  ution with speci
+00011610: 6669 6564 2070 6172 616d 6574 6572 0a20  fied parameter. 
+00011620: 2060 6160 203e 2031 2e0a 0a20 2054 6865   `a` > 1...  The
+00011630: 205a 6970 6620 6469 7374 7269 6275 7469   Zipf distributi
+00011640: 6f6e 2028 616c 736f 206b 6e6f 776e 2061  on (also known a
+00011650: 7320 7468 6520 7a65 7461 2064 6973 7472  s the zeta distr
+00011660: 6962 7574 696f 6e29 2069 7320 610a 2020  ibution) is a.  
+00011670: 6469 7363 7265 7465 2070 726f 6261 6269  discrete probabi
+00011680: 6c69 7479 2064 6973 7472 6962 7574 696f  lity distributio
+00011690: 6e20 7468 6174 2073 6174 6973 6669 6573  n that satisfies
+000116a0: 205a 6970 6627 7320 6c61 773a 2074 6865   Zipf's law: the
+000116b0: 0a20 2066 7265 7175 656e 6379 206f 6620  .  frequency of 
+000116c0: 616e 2069 7465 6d20 6973 2069 6e76 6572  an item is inver
+000116d0: 7365 6c79 2070 726f 706f 7274 696f 6e61  sely proportiona
+000116e0: 6c20 746f 2069 7473 2072 616e 6b20 696e  l to its rank in
+000116f0: 2061 0a20 2066 7265 7175 656e 6379 2074   a.  frequency t
+00011700: 6162 6c65 2e0a 0a20 202e 2e20 6e6f 7465  able...  .. note
+00011710: 3a3a 0a20 2020 2020 204e 6577 2063 6f64  ::.      New cod
+00011720: 6520 7368 6f75 6c64 2075 7365 2074 6865  e should use the
+00011730: 2060 607a 6970 6660 6020 6d65 7468 6f64   ``zipf`` method
+00011740: 206f 6620 6120 6060 6465 6661 756c 745f   of a ``default_
+00011750: 726e 6728 2960 600a 2020 2020 2020 696e  rng()``.      in
+00011760: 7374 616e 6365 2069 6e73 7465 6164 3b20  stance instead; 
+00011770: 706c 6561 7365 2073 6565 2074 6865 203a  please see the :
+00011780: 7265 663a 6072 616e 646f 6d2d 7175 6963  ref:`random-quic
+00011790: 6b2d 7374 6172 7460 2e0a 0a20 2050 6172  k-start`...  Par
+000117a0: 616d 6574 6572 730a 2020 2d2d 2d2d 2d2d  ameters.  ------
+000117b0: 2d2d 2d2d 0a20 2061 203a 2066 6c6f 6174  ----.  a : float
+000117c0: 206f 7220 6172 7261 795f 6c69 6b65 206f   or array_like o
+000117d0: 6620 666c 6f61 7473 0a20 2020 2020 2044  f floats.      D
+000117e0: 6973 7472 6962 7574 696f 6e20 7061 7261  istribution para
+000117f0: 6d65 7465 722e 204d 7573 7420 6265 2067  meter. Must be g
+00011800: 7265 6174 6572 2074 6861 6e20 312e 0a20  reater than 1.. 
+00011810: 2073 697a 6520 3a20 696e 7420 6f72 2074   size : int or t
+00011820: 7570 6c65 206f 6620 696e 7473 2c20 6f70  uple of ints, op
+00011830: 7469 6f6e 616c 0a20 2020 2020 204f 7574  tional.      Out
+00011840: 7075 7420 7368 6170 652e 2020 4966 2074  put shape.  If t
+00011850: 6865 2067 6976 656e 2073 6861 7065 2069  he given shape i
+00011860: 732c 2065 2e67 2e2c 2060 6028 6d2c 206e  s, e.g., ``(m, n
+00011870: 2c20 6b29 6060 2c20 7468 656e 0a20 2020  , k)``, then.   
+00011880: 2020 2060 606d 202a 206e 202a 206b 6060     ``m * n * k``
+00011890: 2073 616d 706c 6573 2061 7265 2064 7261   samples are dra
+000118a0: 776e 2e20 2049 6620 7369 7a65 2069 7320  wn.  If size is 
+000118b0: 6060 4e6f 6e65 6060 2028 6465 6661 756c  ``None`` (defaul
+000118c0: 7429 2c0a 2020 2020 2020 6120 7369 6e67  t),.      a sing
+000118d0: 6c65 2076 616c 7565 2069 7320 7265 7475  le value is retu
+000118e0: 726e 6564 2069 6620 6060 6160 6020 6973  rned if ``a`` is
+000118f0: 2061 2073 6361 6c61 722e 204f 7468 6572   a scalar. Other
+00011900: 7769 7365 2c0a 2020 2020 2020 6060 6e70  wise,.      ``np
+00011910: 2e61 7272 6179 2861 292e 7369 7a65 6060  .array(a).size``
+00011920: 2073 616d 706c 6573 2061 7265 2064 7261   samples are dra
+00011930: 776e 2e0a 0a20 2052 6574 7572 6e73 0a20  wn...  Returns. 
+00011940: 202d 2d2d 2d2d 2d2d 0a20 206f 7574 203a   -------.  out :
+00011950: 206e 6461 7272 6179 206f 7220 7363 616c   ndarray or scal
+00011960: 6172 0a20 2020 2020 2044 7261 776e 2073  ar.      Drawn s
+00011970: 616d 706c 6573 2066 726f 6d20 7468 6520  amples from the 
+00011980: 7061 7261 6d65 7465 7269 7a65 6420 5a69  parameterized Zi
+00011990: 7066 2064 6973 7472 6962 7574 696f 6e2e  pf distribution.
+000119a0: 0a0a 2020 5365 6520 416c 736f 0a20 202d  ..  See Also.  -
+000119b0: 2d2d 2d2d 2d2d 2d0a 2020 7363 6970 792e  -------.  scipy.
+000119c0: 7374 6174 732e 7a69 7066 203a 2070 726f  stats.zipf : pro
+000119d0: 6261 6269 6c69 7479 2064 656e 7369 7479  bability density
+000119e0: 2066 756e 6374 696f 6e2c 2064 6973 7472   function, distr
+000119f0: 6962 7574 696f 6e2c 206f 720a 2020 2020  ibution, or.    
+00011a00: 2020 6375 6d75 6c61 7469 7665 2064 656e    cumulative den
+00011a10: 7369 7479 2066 756e 6374 696f 6e2c 2065  sity function, e
+00011a20: 7463 2e0a 2020 7261 6e64 6f6d 2e47 656e  tc..  random.Gen
+00011a30: 6572 6174 6f72 2e7a 6970 663a 2077 6869  erator.zipf: whi
+00011a40: 6368 2073 686f 756c 6420 6265 2075 7365  ch should be use
+00011a50: 6420 666f 7220 6e65 7720 636f 6465 2e0a  d for new code..
+00011a60: 0a20 204e 6f74 6573 0a20 202d 2d2d 2d2d  .  Notes.  -----
+00011a70: 0a20 2054 6865 2070 726f 6261 6269 6c69  .  The probabili
+00011a80: 7479 2064 656e 7369 7479 2066 6f72 2074  ty density for t
+00011a90: 6865 205a 6970 6620 6469 7374 7269 6275  he Zipf distribu
+00011aa0: 7469 6f6e 2069 730a 0a20 202e 2e20 6d61  tion is..  .. ma
+00011ab0: 7468 3a3a 2070 286b 2920 3d20 5c66 7261  th:: p(k) = \fra
+00011ac0: 637b 6b5e 7b2d 617d 7d7b 5c7a 6574 6128  c{k^{-a}}{\zeta(
+00011ad0: 6129 7d2c 0a0a 2020 666f 7220 696e 7465  a)},..  for inte
+00011ae0: 6765 7273 203a 6d61 7468 3a60 6b20 5c67  gers :math:`k \g
+00011af0: 6571 2031 602c 2077 6865 7265 203a 6d61  eq 1`, where :ma
+00011b00: 7468 3a60 5c7a 6574 6160 2069 7320 7468  th:`\zeta` is th
+00011b10: 6520 5269 656d 616e 6e20 5a65 7461 0a20  e Riemann Zeta. 
+00011b20: 2066 756e 6374 696f 6e2e 0a0a 2020 4974   function...  It
+00011b30: 2069 7320 6e61 6d65 6420 666f 7220 7468   is named for th
+00011b40: 6520 416d 6572 6963 616e 206c 696e 6775  e American lingu
+00011b50: 6973 7420 4765 6f72 6765 204b 696e 6773  ist George Kings
+00011b60: 6c65 7920 5a69 7066 2c20 7768 6f20 6e6f  ley Zipf, who no
+00011b70: 7465 640a 2020 7468 6174 2074 6865 2066  ted.  that the f
+00011b80: 7265 7175 656e 6379 206f 6620 616e 7920  requency of any 
+00011b90: 776f 7264 2069 6e20 6120 7361 6d70 6c65  word in a sample
+00011ba0: 206f 6620 6120 6c61 6e67 7561 6765 2069   of a language i
+00011bb0: 7320 696e 7665 7273 656c 790a 2020 7072  s inversely.  pr
+00011bc0: 6f70 6f72 7469 6f6e 616c 2074 6f20 6974  oportional to it
+00011bd0: 7320 7261 6e6b 2069 6e20 7468 6520 6672  s rank in the fr
+00011be0: 6571 7565 6e63 7920 7461 626c 652e 0a0a  equency table...
+00011bf0: 2020 5265 6665 7265 6e63 6573 0a20 202d    References.  -
+00011c00: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2e2e 205b  ---------.  .. [
+00011c10: 315d 205a 6970 662c 2047 2e20 4b2e 2c20  1] Zipf, G. K., 
+00011c20: 2253 656c 6563 7465 6420 5374 7564 6965  "Selected Studie
+00011c30: 7320 6f66 2074 6865 2050 7269 6e63 6970  s of the Princip
+00011c40: 6c65 206f 6620 5265 6c61 7469 7665 0a20  le of Relative. 
+00011c50: 2020 2020 2020 2020 4672 6571 7565 6e63          Frequenc
+00011c60: 7920 696e 204c 616e 6775 6167 652c 2220  y in Language," 
+00011c70: 4361 6d62 7269 6467 652c 204d 413a 2048  Cambridge, MA: H
+00011c80: 6172 7661 7264 2055 6e69 762e 2050 7265  arvard Univ. Pre
+00011c90: 7373 2c0a 2020 2020 2020 2020 2031 3933  ss,.         193
+00011ca0: 322e 0a0a 2020 4578 616d 706c 6573 0a20  2...  Examples. 
+00011cb0: 202d 2d2d 2d2d 2d2d 2d0a 2020 4472 6177   --------.  Draw
+00011cc0: 2073 616d 706c 6573 2066 726f 6d20 7468   samples from th
+00011cd0: 6520 6469 7374 7269 6275 7469 6f6e 3a0a  e distribution:.
+00011ce0: 0a20 203e 3e3e 2061 203d 2034 2e30 0a20  .  >>> a = 4.0. 
+00011cf0: 203e 3e3e 206e 203d 2032 3030 3030 0a20   >>> n = 20000. 
+00011d00: 203e 3e3e 2073 203d 2062 7261 696e 7079   >>> s = brainpy
+00011d10: 2e6d 6174 682e 7261 6e64 6f6d 2e7a 6970  .math.random.zip
+00011d20: 6628 612c 206e 290a 0a20 2044 6973 706c  f(a, n)..  Displ
+00011d30: 6179 2074 6865 2068 6973 746f 6772 616d  ay the histogram
+00011d40: 206f 6620 7468 6520 7361 6d70 6c65 732c   of the samples,
+00011d50: 2061 6c6f 6e67 2077 6974 680a 2020 7468   along with.  th
+00011d60: 6520 6578 7065 6374 6564 2068 6973 746f  e expected histo
+00011d70: 6772 616d 2062 6173 6564 206f 6e20 7468  gram based on th
+00011d80: 6520 7072 6f62 6162 696c 6974 790a 2020  e probability.  
+00011d90: 6465 6e73 6974 7920 6675 6e63 7469 6f6e  density function
+00011da0: 3a0a 0a20 203e 3e3e 2069 6d70 6f72 7420  :..  >>> import 
+00011db0: 6d61 7470 6c6f 746c 6962 2e70 7970 6c6f  matplotlib.pyplo
+00011dc0: 7420 6173 2070 6c74 0a20 203e 3e3e 2066  t as plt.  >>> f
+00011dd0: 726f 6d20 7363 6970 792e 7370 6563 6961  rom scipy.specia
+00011de0: 6c20 696d 706f 7274 207a 6574 6120 2023  l import zeta  #
+00011df0: 2064 6f63 7465 7374 3a20 2b53 4b49 500a   doctest: +SKIP.
+00011e00: 0a20 2060 6269 6e63 6f75 6e74 6020 7072  .  `bincount` pr
+00011e10: 6f76 6964 6573 2061 2066 6173 7420 6869  ovides a fast hi
+00011e20: 7374 6f67 7261 6d20 666f 7220 736d 616c  stogram for smal
+00011e30: 6c20 696e 7465 6765 7273 2e0a 0a20 203e  l integers...  >
+00011e40: 3e3e 2063 6f75 6e74 203d 206e 702e 6269  >> count = np.bi
+00011e50: 6e63 6f75 6e74 2873 290a 2020 3e3e 3e20  ncount(s).  >>> 
+00011e60: 6b20 3d20 6e70 2e61 7261 6e67 6528 312c  k = np.arange(1,
+00011e70: 2073 2e6d 6178 2829 202b 2031 290a 0a20   s.max() + 1).. 
+00011e80: 203e 3e3e 2070 6c74 2e62 6172 286b 2c20   >>> plt.bar(k, 
+00011e90: 636f 756e 745b 313a 5d2c 2061 6c70 6861  count[1:], alpha
+00011ea0: 3d30 2e35 2c20 6c61 6265 6c3d 2773 616d  =0.5, label='sam
+00011eb0: 706c 6520 636f 756e 7427 290a 2020 3e3e  ple count').  >>
+00011ec0: 3e20 706c 742e 706c 6f74 286b 2c20 6e2a  > plt.plot(k, n*
+00011ed0: 286b 2a2a 2d61 292f 7a65 7461 2861 292c  (k**-a)/zeta(a),
+00011ee0: 2027 6b2e 2d27 2c20 616c 7068 613d 302e   'k.-', alpha=0.
+00011ef0: 352c 0a20 202e 2e2e 2020 2020 2020 2020  5,.  ...        
+00011f00: 2020 6c61 6265 6c3d 2765 7870 6563 7465    label='expecte
+00011f10: 6420 636f 756e 7427 2920 2020 2320 646f  d count')   # do
+00011f20: 6374 6573 743a 202b 534b 4950 0a20 203e  ctest: +SKIP.  >
+00011f30: 3e3e 2070 6c74 2e73 656d 696c 6f67 7928  >> plt.semilogy(
+00011f40: 290a 2020 3e3e 3e20 706c 742e 6772 6964  ).  >>> plt.grid
+00011f50: 2861 6c70 6861 3d30 2e34 290a 2020 3e3e  (alpha=0.4).  >>
+00011f60: 3e20 706c 742e 6c65 6765 6e64 2829 0a20  > plt.legend(). 
+00011f70: 203e 3e3e 2070 6c74 2e74 6974 6c65 2866   >>> plt.title(f
+00011f80: 275a 6970 6620 7361 6d70 6c65 2c20 613d  'Zipf sample, a=
+00011f90: 7b61 7d2c 2073 697a 653d 7b6e 7d27 290a  {a}, size={n}').
+00011fa0: 2020 3e3e 3e20 706c 742e 7368 6f77 2829    >>> plt.show()
+00011fb0: 0a20 2022 2222 0a20 2072 6574 7572 6e20  .  """.  return 
+00011fc0: 4445 4641 554c 542e 7a69 7066 2861 2c20  DEFAULT.zipf(a, 
+00011fd0: 7369 7a65 2c20 6b65 793d 6b65 7929 0a0a  size, key=key)..
+00011fe0: 0a64 6566 206d 6178 7765 6c6c 2873 697a  .def maxwell(siz
+00011ff0: 653d 4e6f 6e65 2c20 6b65 793d 4e6f 6e65  e=None, key=None
+00012000: 293a 0a20 2022 2222 5361 6d70 6c65 2066  ):.  """Sample f
+00012010: 726f 6d20 6120 6f6e 6520 7369 6465 6420  rom a one sided 
+00012020: 4d61 7877 656c 6c20 6469 7374 7269 6275  Maxwell distribu
+00012030: 7469 6f6e 2e0a 0a20 2054 6865 2073 6369  tion...  The sci
+00012040: 7079 2063 6f75 6e74 6572 7061 7274 2069  py counterpart i
+00012050: 7320 6073 6369 7079 2e73 7461 7473 2e6d  s `scipy.stats.m
+00012060: 6178 7765 6c6c 602e 0a0a 2020 4172 6773  axwell`...  Args
+00012070: 3a0a 2020 2020 6b65 793a 2061 2050 524e  :.    key: a PRN
+00012080: 4720 6b65 792e 0a20 2020 2073 697a 653a  G key..    size:
+00012090: 2054 6865 2073 6861 7065 206f 6620 7468   The shape of th
+000120a0: 6520 7265 7475 726e 6564 2073 616d 706c  e returned sampl
+000120b0: 6573 2e0a 2020 2020 6474 7970 653a 2054  es..    dtype: T
+000120c0: 6865 2074 7970 6520 7573 6564 2066 6f72  he type used for
+000120d0: 2073 616d 706c 6573 2e0a 0a20 2052 6574   samples...  Ret
+000120e0: 7572 6e73 3a0a 2020 2020 4120 6a6e 702e  urns:.    A jnp.
+000120f0: 6172 7261 7920 6f66 2073 616d 706c 6573  array of samples
+00012100: 2c20 6f66 2073 6861 7065 2060 7368 6170  , of shape `shap
+00012110: 6560 2e0a 0a20 2022 2222 0a20 2072 6574  e`...  """.  ret
+00012120: 7572 6e20 4445 4641 554c 542e 6d61 7877  urn DEFAULT.maxw
+00012130: 656c 6c28 7369 7a65 2c20 6b65 793d 6b65  ell(size, key=ke
+00012140: 7929 0a0a 0a64 6566 2074 2864 662c 2073  y)...def t(df, s
+00012150: 697a 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ize=None, key=No
+00012160: 6e65 293a 0a20 2022 2222 5361 6d70 6c65  ne):.  """Sample
+00012170: 2053 7475 6465 6e74 e280 9973 2074 2072   Student...s t r
+00012180: 616e 646f 6d20 7661 6c75 6573 2e0a 0a20  andom values... 
+00012190: 2050 6172 616d 6574 6572 730a 2020 2d2d   Parameters.  --
+000121a0: 2d2d 2d2d 2d2d 2d2d 0a20 2064 663a 2066  --------.  df: f
+000121b0: 6c6f 6174 2c20 6172 7261 795f 6c69 6b65  loat, array_like
+000121c0: 0a20 2020 2041 2066 6c6f 6174 206f 7220  .    A float or 
+000121d0: 6172 7261 7920 6f66 2066 6c6f 6174 7320  array of floats 
+000121e0: 6272 6f61 6463 6173 742d 636f 6d70 6174  broadcast-compat
+000121f0: 6962 6c65 2077 6974 6820 7368 6170 6520  ible with shape 
+00012200: 7265 7072 6573 656e 7469 6e67 2074 6865  representing the
+00012210: 2070 6172 616d 6574 6572 206f 6620 7468   parameter of th
+00012220: 6520 6469 7374 7269 6275 7469 6f6e 2e0a  e distribution..
+00012230: 2020 7369 7a65 3a20 6f70 7469 6f6e 616c    size: optional
+00012240: 2c20 696e 742c 2074 7570 6c65 206f 6620  , int, tuple of 
+00012250: 696e 740a 2020 2020 4120 7475 706c 6520  int.    A tuple 
+00012260: 6f66 206e 6f6e 2d6e 6567 6174 6976 6520  of non-negative 
+00012270: 696e 7465 6765 7273 2073 7065 6369 6679  integers specify
+00012280: 696e 6720 7468 6520 7265 7375 6c74 2073  ing the result s
+00012290: 6861 7065 2e0a 2020 2020 4d75 7374 2062  hape..    Must b
+000122a0: 6520 6272 6f61 6463 6173 742d 636f 6d70  e broadcast-comp
+000122b0: 6174 6962 6c65 2077 6974 6820 6064 6660  atible with `df`
+000122c0: 2e20 5468 6520 6465 6661 756c 7420 284e  . The default (N
+000122d0: 6f6e 6529 2070 726f 6475 6365 7320 6120  one) produces a 
+000122e0: 7265 7375 6c74 2073 6861 7065 2065 7175  result shape equ
+000122f0: 616c 2074 6f20 6064 662e 7368 6170 6560  al to `df.shape`
+00012300: 2e0a 0a20 2052 6574 7572 6e73 0a20 202d  ...  Returns.  -
+00012310: 2d2d 2d2d 2d2d 0a20 206f 7574 3a20 6172  ------.  out: ar
+00012320: 7261 795f 6c69 6b65 0a20 2020 2054 6865  ray_like.    The
+00012330: 2073 616d 706c 6564 2076 616c 7565 2e0a   sampled value..
+00012340: 2020 2222 220a 2020 7265 7475 726e 2044    """.  return D
+00012350: 4546 4155 4c54 2e74 2864 662c 2073 697a  EFAULT.t(df, siz
+00012360: 652c 206b 6579 3d6b 6579 290a 0a0a 6465  e, key=key)...de
+00012370: 6620 6f72 7468 6f67 6f6e 616c 286e 3a20  f orthogonal(n: 
+00012380: 696e 742c 2073 697a 653d 4e6f 6e65 2c20  int, size=None, 
+00012390: 6b65 793d 4e6f 6e65 293a 0a20 2022 2222  key=None):.  """
+000123a0: 5361 6d70 6c65 2075 6e69 666f 726d 6c79  Sample uniformly
+000123b0: 2066 726f 6d20 7468 6520 6f72 7468 6f67   from the orthog
+000123c0: 6f6e 616c 2067 726f 7570 2060 4f28 6e29  onal group `O(n)
+000123d0: 602e 0a0a 2020 5061 7261 6d65 7465 7273  `...  Parameters
+000123e0: 0a20 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  .  ----------.  
+000123f0: 6e3a 2069 6e74 0a20 2020 2020 416e 2069  n: int.     An i
+00012400: 6e74 6567 6572 2069 6e64 6963 6174 696e  nteger indicatin
+00012410: 6720 7468 6520 7265 7375 6c74 696e 6720  g the resulting 
+00012420: 6469 6d65 6e73 696f 6e2e 0a20 2073 697a  dimension..  siz
+00012430: 653a 206f 7074 696f 6e61 6c2c 2069 6e74  e: optional, int
+00012440: 2c20 7475 706c 6520 6f66 2069 6e74 0a20  , tuple of int. 
+00012450: 2020 2054 6865 2062 6174 6368 2064 696d     The batch dim
+00012460: 656e 7369 6f6e 7320 6f66 2074 6865 2072  ensions of the r
+00012470: 6573 756c 742e 0a0a 2020 5265 7475 726e  esult...  Return
+00012480: 730a 2020 2d2d 2d2d 2d2d 2d0a 2020 6f75  s.  -------.  ou
+00012490: 743a 2041 7272 6179 0a20 2020 2054 6865  t: Array.    The
+000124a0: 2073 616d 706c 6564 2072 6573 756c 7473   sampled results
+000124b0: 2e0a 2020 2222 220a 2020 7265 7475 726e  ..  """.  return
+000124c0: 2044 4546 4155 4c54 2e6f 7274 686f 676f   DEFAULT.orthogo
+000124d0: 6e61 6c28 6e2c 2073 697a 652c 206b 6579  nal(n, size, key
+000124e0: 3d6b 6579 290a 0a0a 6465 6620 6c6f 6767  =key)...def logg
+000124f0: 616d 6d61 2861 2c20 7369 7a65 3d4e 6f6e  amma(a, size=Non
+00012500: 652c 206b 6579 3d4e 6f6e 6529 3a0a 2020  e, key=None):.  
+00012510: 2222 2253 616d 706c 6520 6c6f 672d 6761  """Sample log-ga
+00012520: 6d6d 6120 7261 6e64 6f6d 2076 616c 7565  mma random value
+00012530: 732e 0a0a 2020 5061 7261 6d65 7465 7273  s...  Parameters
+00012540: 0a20 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  .  ----------.  
+00012550: 613a 2066 6c6f 6174 2c20 6172 7261 795f  a: float, array_
+00012560: 6c69 6b65 0a20 2020 2041 2066 6c6f 6174  like.    A float
+00012570: 206f 7220 6172 7261 7920 6f66 2066 6c6f   or array of flo
+00012580: 6174 7320 6272 6f61 6463 6173 742d 636f  ats broadcast-co
+00012590: 6d70 6174 6962 6c65 2077 6974 6820 7368  mpatible with sh
+000125a0: 6170 6520 7265 7072 6573 656e 7469 6e67  ape representing
+000125b0: 2074 6865 2070 6172 616d 6574 6572 206f   the parameter o
+000125c0: 6620 7468 6520 6469 7374 7269 6275 7469  f the distributi
+000125d0: 6f6e 2e0a 2020 7369 7a65 3a20 6f70 7469  on..  size: opti
+000125e0: 6f6e 616c 2c20 696e 742c 2074 7570 6c65  onal, int, tuple
+000125f0: 206f 6620 696e 740a 2020 2020 4120 7475   of int.    A tu
+00012600: 706c 6520 6f66 206e 6f6e 6e65 6761 7469  ple of nonnegati
+00012610: 7665 2069 6e74 6567 6572 7320 7370 6563  ve integers spec
+00012620: 6966 7969 6e67 2074 6865 2072 6573 756c  ifying the resul
+00012630: 7420 7368 6170 652e 0a20 2020 204d 7573  t shape..    Mus
+00012640: 7420 6265 2062 726f 6164 6361 7374 2d63  t be broadcast-c
+00012650: 6f6d 7061 7469 626c 6520 7769 7468 2060  ompatible with `
+00012660: 6160 2e20 5468 6520 6465 6661 756c 7420  a`. The default 
+00012670: 284e 6f6e 6529 2070 726f 6475 6365 7320  (None) produces 
+00012680: 6120 7265 7375 6c74 2073 6861 7065 2065  a result shape e
+00012690: 7175 616c 2074 6f20 6061 2e73 6861 7065  qual to `a.shape
+000126a0: 602e 0a0a 2020 5265 7475 726e 730a 2020  `...  Returns.  
+000126b0: 2d2d 2d2d 2d2d 2d0a 2020 6f75 743a 2061  -------.  out: a
+000126c0: 7272 6179 5f6c 696b 650a 2020 2020 5468  rray_like.    Th
+000126d0: 6520 7361 6d70 6c65 6420 7265 7375 6c74  e sampled result
+000126e0: 732e 0a20 2022 2222 0a20 2072 6574 7572  s..  """.  retur
+000126f0: 6e20 4445 4641 554c 542e 6c6f 6767 616d  n DEFAULT.loggam
+00012700: 6d61 2861 2c20 7369 7a65 290a 0a0a 6465  ma(a, size)...de
+00012710: 6620 6361 7465 676f 7269 6361 6c28 6c6f  f categorical(lo
+00012720: 6769 7473 2c20 6178 6973 3a20 696e 7420  gits, axis: int 
+00012730: 3d20 2d31 2c20 7369 7a65 3d4e 6f6e 652c  = -1, size=None,
+00012740: 206b 6579 3d4e 6f6e 6529 3a0a 2020 2222   key=None):.  ""
+00012750: 2253 616d 706c 6520 7261 6e64 6f6d 2076  "Sample random v
+00012760: 616c 7565 7320 6672 6f6d 2063 6174 6567  alues from categ
+00012770: 6f72 6963 616c 2064 6973 7472 6962 7574  orical distribut
+00012780: 696f 6e73 2e0a 0a20 2041 7267 733a 0a20  ions...  Args:. 
+00012790: 2020 206c 6f67 6974 733a 2055 6e6e 6f72     logits: Unnor
+000127a0: 6d61 6c69 7a65 6420 6c6f 6720 7072 6f62  malized log prob
+000127b0: 6162 696c 6974 6965 7320 6f66 2074 6865  abilities of the
+000127c0: 2063 6174 6567 6f72 6963 616c 2064 6973   categorical dis
+000127d0: 7472 6962 7574 696f 6e28 7329 2074 6f20  tribution(s) to 
+000127e0: 7361 6d70 6c65 2066 726f 6d2c 0a20 2020  sample from,.   
+000127f0: 2020 2073 6f20 7468 6174 2060 736f 6674     so that `soft
+00012800: 6d61 7828 6c6f 6769 7473 2c20 6178 6973  max(logits, axis
+00012810: 2960 2067 6976 6573 2074 6865 2063 6f72  )` gives the cor
+00012820: 7265 7370 6f6e 6469 6e67 2070 726f 6261  responding proba
+00012830: 6269 6c69 7469 6573 2e0a 2020 2020 6178  bilities..    ax
+00012840: 6973 3a20 4178 6973 2061 6c6f 6e67 2077  is: Axis along w
+00012850: 6869 6368 206c 6f67 6974 7320 6265 6c6f  hich logits belo
+00012860: 6e67 2074 6f20 7468 6520 7361 6d65 2063  ng to the same c
+00012870: 6174 6567 6f72 6963 616c 2064 6973 7472  ategorical distr
+00012880: 6962 7574 696f 6e2e 0a20 2020 2073 6861  ibution..    sha
+00012890: 7065 3a20 4f70 7469 6f6e 616c 2c20 6120  pe: Optional, a 
+000128a0: 7475 706c 6520 6f66 206e 6f6e 6e65 6761  tuple of nonnega
+000128b0: 7469 7665 2069 6e74 6567 6572 7320 7265  tive integers re
+000128c0: 7072 6573 656e 7469 6e67 2074 6865 2072  presenting the r
+000128d0: 6573 756c 7420 7368 6170 652e 0a20 2020  esult shape..   
+000128e0: 2020 204d 7573 7420 6265 2062 726f 6164     Must be broad
+000128f0: 6361 7374 2d63 6f6d 7061 7469 626c 6520  cast-compatible 
+00012900: 7769 7468 2060 606e 702e 6465 6c65 7465  with ``np.delete
+00012910: 286c 6f67 6974 732e 7368 6170 652c 2061  (logits.shape, a
+00012920: 7869 7329 6060 2e0a 2020 2020 2020 5468  xis)``..      Th
+00012930: 6520 6465 6661 756c 7420 284e 6f6e 6529  e default (None)
+00012940: 2070 726f 6475 6365 7320 6120 7265 7375   produces a resu
+00012950: 6c74 2073 6861 7065 2065 7175 616c 2074  lt shape equal t
+00012960: 6f20 6060 6e70 2e64 656c 6574 6528 6c6f  o ``np.delete(lo
+00012970: 6769 7473 2e73 6861 7065 2c20 6178 6973  gits.shape, axis
+00012980: 2960 602e 0a20 2020 206b 6579 3a20 6120  )``..    key: a 
+00012990: 5052 4e47 206b 6579 2075 7365 6420 6173  PRNG key used as
+000129a0: 2074 6865 2072 616e 646f 6d20 6b65 792e   the random key.
+000129b0: 0a0a 2020 5265 7475 726e 733a 0a20 2020  ..  Returns:.   
+000129c0: 2041 2072 616e 646f 6d20 6172 7261 7920   A random array 
+000129d0: 7769 7468 2069 6e74 2064 7479 7065 2061  with int dtype a
+000129e0: 6e64 2073 6861 7065 2067 6976 656e 2062  nd shape given b
+000129f0: 7920 6060 7368 6170 6560 6020 6966 2060  y ``shape`` if `
+00012a00: 6073 6861 7065 6060 0a20 2020 2069 7320  `shape``.    is 
+00012a10: 6e6f 7420 4e6f 6e65 2c20 6f72 2065 6c73  not None, or els
+00012a20: 6520 6060 6e70 2e64 656c 6574 6528 6c6f  e ``np.delete(lo
+00012a30: 6769 7473 2e73 6861 7065 2c20 6178 6973  gits.shape, axis
+00012a40: 2960 602e 0a20 2022 2222 0a20 2072 6574  )``..  """.  ret
+00012a50: 7572 6e20 4445 4641 554c 542e 6361 7465  urn DEFAULT.cate
+00012a60: 676f 7269 6361 6c28 6c6f 6769 7473 2c20  gorical(logits, 
+00012a70: 6178 6973 2c20 7369 7a65 2c20 6b65 793d  axis, size, key=
+00012a80: 6b65 7929 0a0a 0a64 6566 2072 616e 645f  key)...def rand_
+00012a90: 6c69 6b65 2869 6e70 7574 2c20 2a2c 2064  like(input, *, d
+00012aa0: 7479 7065 3d4e 6f6e 652c 206b 6579 3d4e  type=None, key=N
+00012ab0: 6f6e 6529 3a0a 2020 2222 2253 696d 696c  one):.  """Simil
+00012ac0: 6172 2074 6f20 6060 7261 6e64 5f6c 696b  ar to ``rand_lik
+00012ad0: 6560 6020 696e 2074 6f72 6368 2e20 0a20  e`` in torch. . 
+00012ae0: 200a 2020 5265 7475 726e 7320 6120 7465   .  Returns a te
+00012af0: 6e73 6f72 2077 6974 6820 7468 6520 7361  nsor with the sa
+00012b00: 6d65 2073 697a 6520 6173 2069 6e70 7574  me size as input
+00012b10: 2074 6861 7420 6973 2066 696c 6c65 6420   that is filled 
+00012b20: 7769 7468 2072 616e 646f 6d0a 2020 6e75  with random.  nu
+00012b30: 6d62 6572 7320 6672 6f6d 2061 2075 6e69  mbers from a uni
+00012b40: 666f 726d 2064 6973 7472 6962 7574 696f  form distributio
+00012b50: 6e20 6f6e 2074 6865 2069 6e74 6572 7661  n on the interva
+00012b60: 6c20 6060 5b30 2c20 3129 6060 2e0a 0a20  l ``[0, 1)``... 
+00012b70: 2041 7267 733a 0a20 2020 2069 6e70 7574   Args:.    input
+00012b80: 3a20 2074 6865 2060 6073 697a 6560 6020  :  the ``size`` 
+00012b90: 6f66 2069 6e70 7574 2077 696c 6c20 6465  of input will de
+00012ba0: 7465 726d 696e 6520 7369 7a65 206f 6620  termine size of 
+00012bb0: 7468 6520 6f75 7470 7574 2074 656e 736f  the output tenso
+00012bc0: 722e 0a20 2020 2064 7479 7065 3a20 2074  r..    dtype:  t
+00012bd0: 6865 2064 6573 6972 6564 2064 6174 6120  he desired data 
+00012be0: 7479 7065 206f 6620 7265 7475 726e 6564  type of returned
+00012bf0: 2054 656e 736f 722e 2044 6566 6175 6c74   Tensor. Default
+00012c00: 3a20 6966 2060 604e 6f6e 6560 602c 2064  : if ``None``, d
+00012c10: 6566 6175 6c74 7320 746f 2074 6865 2064  efaults to the d
+00012c20: 7479 7065 206f 6620 696e 7075 742e 0a20  type of input.. 
+00012c30: 2020 206b 6579 3a20 7468 6520 7365 6564     key: the seed
+00012c40: 206f 7220 6b65 7920 666f 7220 7468 6520   or key for the 
+00012c50: 7261 6e64 6f6d 2e0a 0a20 2052 6574 7572  random...  Retur
+00012c60: 6e73 3a0a 2020 2020 5468 6520 7261 6e64  ns:.    The rand
+00012c70: 6f6d 2064 6174 612e 0a20 2022 2222 0a20  om data..  """. 
+00012c80: 2072 6574 7572 6e20 4445 4641 554c 542e   return DEFAULT.
+00012c90: 7261 6e64 5f6c 696b 6528 696e 7075 742c  rand_like(input,
+00012ca0: 2064 7479 7065 3d64 7479 7065 2c20 6b65   dtype=dtype, ke
+00012cb0: 793d 6b65 7929 0a0a 0a64 6566 2072 616e  y=key)...def ran
+00012cc0: 646e 5f6c 696b 6528 696e 7075 742c 202a  dn_like(input, *
+00012cd0: 2c20 6474 7970 653d 4e6f 6e65 2c20 6b65  , dtype=None, ke
+00012ce0: 793d 4e6f 6e65 293a 0a20 2022 2222 5369  y=None):.  """Si
+00012cf0: 6d69 6c61 7220 746f 2060 6072 616e 646e  milar to ``randn
+00012d00: 5f6c 696b 6560 6020 696e 2074 6f72 6368  _like`` in torch
+00012d10: 2e20 0a20 200a 2020 5265 7475 726e 7320  . .  .  Returns 
+00012d20: 6120 7465 6e73 6f72 2077 6974 6820 7468  a tensor with th
+00012d30: 6520 7361 6d65 2073 697a 6520 6173 2060  e same size as `
+00012d40: 6069 6e70 7574 6060 2074 6861 7420 6973  `input`` that is
+00012d50: 2066 696c 6c65 6420 7769 7468 0a20 2072   filled with.  r
+00012d60: 616e 646f 6d20 6e75 6d62 6572 7320 6672  andom numbers fr
+00012d70: 6f6d 2061 206e 6f72 6d61 6c20 6469 7374  om a normal dist
+00012d80: 7269 6275 7469 6f6e 2077 6974 6820 6d65  ribution with me
+00012d90: 616e 2030 2061 6e64 2076 6172 6961 6e63  an 0 and varianc
+00012da0: 6520 312e 0a0a 2020 4172 6773 3a0a 2020  e 1...  Args:.  
+00012db0: 2020 696e 7075 743a 2020 7468 6520 6060    input:  the ``
+00012dc0: 7369 7a65 6060 206f 6620 696e 7075 7420  size`` of input 
+00012dd0: 7769 6c6c 2064 6574 6572 6d69 6e65 2073  will determine s
+00012de0: 697a 6520 6f66 2074 6865 206f 7574 7075  ize of the outpu
+00012df0: 7420 7465 6e73 6f72 2e0a 2020 2020 6474  t tensor..    dt
+00012e00: 7970 653a 2020 7468 6520 6465 7369 7265  ype:  the desire
+00012e10: 6420 6461 7461 2074 7970 6520 6f66 2072  d data type of r
+00012e20: 6574 7572 6e65 6420 5465 6e73 6f72 2e20  eturned Tensor. 
+00012e30: 4465 6661 756c 743a 2069 6620 6060 4e6f  Default: if ``No
+00012e40: 6e65 6060 2c20 6465 6661 756c 7473 2074  ne``, defaults t
+00012e50: 6f20 7468 6520 6474 7970 6520 6f66 2069  o the dtype of i
+00012e60: 6e70 7574 2e0a 2020 2020 6b65 793a 2074  nput..    key: t
+00012e70: 6865 2073 6565 6420 6f72 206b 6579 2066  he seed or key f
+00012e80: 6f72 2074 6865 2072 616e 646f 6d2e 0a0a  or the random...
+00012e90: 2020 5265 7475 726e 733a 0a20 2020 2054    Returns:.    T
+00012ea0: 6865 2072 616e 646f 6d20 6461 7461 2e0a  he random data..
+00012eb0: 2020 2222 220a 2020 7265 7475 726e 2044    """.  return D
+00012ec0: 4546 4155 4c54 2e72 616e 646e 5f6c 696b  EFAULT.randn_lik
+00012ed0: 6528 696e 7075 742c 2064 7479 7065 3d64  e(input, dtype=d
+00012ee0: 7479 7065 2c20 6b65 793d 6b65 7929 0a0a  type, key=key)..
+00012ef0: 0a64 6566 2072 616e 6469 6e74 5f6c 696b  .def randint_lik
+00012f00: 6528 696e 7075 742c 206c 6f77 3d30 2c20  e(input, low=0, 
+00012f10: 6869 6768 3d4e 6f6e 652c 202a 2c20 6474  high=None, *, dt
+00012f20: 7970 653d 4e6f 6e65 2c20 6b65 793d 4e6f  ype=None, key=No
+00012f30: 6e65 293a 0a20 2022 2222 5369 6d69 6c61  ne):.  """Simila
+00012f40: 7220 746f 2060 6072 616e 6469 6e74 5f6c  r to ``randint_l
+00012f50: 696b 6560 6020 696e 2074 6f72 6368 2e20  ike`` in torch. 
+00012f60: 0a20 200a 2020 5265 7475 726e 7320 6120  .  .  Returns a 
+00012f70: 7465 6e73 6f72 2077 6974 6820 7468 6520  tensor with the 
+00012f80: 7361 6d65 2073 6861 7065 2061 7320 5465  same shape as Te
+00012f90: 6e73 6f72 2060 6069 6e70 7574 6060 2066  nsor ``input`` f
+00012fa0: 696c 6c65 6420 7769 7468 0a20 2072 616e  illed with.  ran
+00012fb0: 646f 6d20 696e 7465 6765 7273 2067 656e  dom integers gen
+00012fc0: 6572 6174 6564 2075 6e69 666f 726d 6c79  erated uniformly
+00012fd0: 2062 6574 7765 656e 2060 606c 6f77 6060   between ``low``
+00012fe0: 2028 696e 636c 7573 6976 6529 2061 6e64   (inclusive) and
+00012ff0: 2060 6068 6967 6860 6020 2865 7863 6c75   ``high`` (exclu
+00013000: 7369 7665 292e 0a0a 2020 4172 6773 3a0a  sive)...  Args:.
+00013010: 2020 2020 696e 7075 743a 2020 7468 6520      input:  the 
+00013020: 6060 7369 7a65 6060 206f 6620 696e 7075  ``size`` of inpu
+00013030: 7420 7769 6c6c 2064 6574 6572 6d69 6e65  t will determine
+00013040: 2073 697a 6520 6f66 2074 6865 206f 7574   size of the out
+00013050: 7075 7420 7465 6e73 6f72 2e0a 2020 2020  put tensor..    
+00013060: 6c6f 773a 204c 6f77 6573 7420 696e 7465  low: Lowest inte
+00013070: 6765 7220 746f 2062 6520 6472 6177 6e20  ger to be drawn 
+00013080: 6672 6f6d 2074 6865 2064 6973 7472 6962  from the distrib
+00013090: 7574 696f 6e2e 2044 6566 6175 6c74 3a20  ution. Default: 
+000130a0: 302e 0a20 2020 2068 6967 683a 204f 6e65  0..    high: One
+000130b0: 2061 626f 7665 2074 6865 2068 6967 6865   above the highe
+000130c0: 7374 2069 6e74 6567 6572 2074 6f20 6265  st integer to be
+000130d0: 2064 7261 776e 2066 726f 6d20 7468 6520   drawn from the 
+000130e0: 6469 7374 7269 6275 7469 6f6e 2e0a 2020  distribution..  
+000130f0: 2020 6474 7970 653a 2074 6865 2064 6573    dtype: the des
+00013100: 6972 6564 2064 6174 6120 7479 7065 206f  ired data type o
+00013110: 6620 7265 7475 726e 6564 2054 656e 736f  f returned Tenso
+00013120: 722e 2044 6566 6175 6c74 3a20 6966 2060  r. Default: if `
+00013130: 604e 6f6e 6560 602c 2064 6566 6175 6c74  `None``, default
+00013140: 7320 746f 2074 6865 2064 7479 7065 206f  s to the dtype o
+00013150: 6620 696e 7075 742e 0a20 2020 206b 6579  f input..    key
+00013160: 3a20 7468 6520 7365 6564 206f 7220 6b65  : the seed or ke
+00013170: 7920 666f 7220 7468 6520 7261 6e64 6f6d  y for the random
+00013180: 2e0a 0a20 2052 6574 7572 6e73 3a0a 2020  ...  Returns:.  
+00013190: 2020 5468 6520 7261 6e64 6f6d 2064 6174    The random dat
+000131a0: 612e 0a20 2022 2222 0a20 2072 6574 7572  a..  """.  retur
+000131b0: 6e20 4445 4641 554c 542e 7261 6e64 696e  n DEFAULT.randin
+000131c0: 745f 6c69 6b65 2869 6e70 7574 3d69 6e70  t_like(input=inp
+000131d0: 7574 2c20 6c6f 773d 6c6f 772c 2068 6967  ut, low=low, hig
+000131e0: 683d 6869 6768 2c20 6474 7970 653d 6474  h=high, dtype=dt
+000131f0: 7970 652c 206b 6579 3d6b 6579 290a 0a0a  ype, key=key)...
+00013200: 666f 7220 5f5f 6b20 696e 2064 6972 2852  for __k in dir(R
+00013210: 616e 646f 6d53 7461 7465 293a 0a20 205f  andomState):.  _
+00013220: 5f74 203d 2067 6574 6174 7472 2852 616e  _t = getattr(Ran
+00013230: 646f 6d53 7461 7465 2c20 5f5f 6b29 0a20  domState, __k). 
+00013240: 2069 6620 6e6f 7420 5f5f 6b2e 7374 6172   if not __k.star
+00013250: 7473 7769 7468 2827 5f5f 2729 2061 6e64  tswith('__') and
+00013260: 2063 616c 6c61 626c 6528 5f5f 7429 2061   callable(__t) a
+00013270: 6e64 2028 6e6f 7420 5f5f 742e 5f5f 646f  nd (not __t.__do
+00013280: 635f 5f29 3a0a 2020 2020 5f5f 7220 3d20  c__):.    __r = 
+00013290: 676c 6f62 616c 7328 292e 6765 7428 5f5f  globals().get(__
+000132a0: 6b2c 204e 6f6e 6529 0a20 2020 2069 6620  k, None).    if 
+000132b0: 5f5f 7220 6973 206e 6f74 204e 6f6e 6520  __r is not None 
+000132c0: 616e 6420 6361 6c6c 6162 6c65 285f 5f72  and callable(__r
+000132d0: 293a 0a20 2020 2020 205f 5f74 2e5f 5f64  ):.      __t.__d
+000132e0: 6f63 5f5f 203d 205f 5f72 2e5f 5f64 6f63  oc__ = __r.__doc
+000132f0: 5f5f 0a                                  __.
```

## brainpy/_src/math/remove_vmap.py

```diff
@@ -1,13 +1,12 @@
 # -*- coding: utf-8 -*-
 
 
 import jax.numpy as jnp
-from jax.abstract_arrays import ShapedArray
-from jax.core import Primitive
+from jax.core import Primitive, ShapedArray
 from jax.interpreters import batching, mlir, xla
 from .ndarray import Array
 
 __all__ = [
   'remove_vmap'
 ]
```

## brainpy/_src/math/jitconn/_event_matvec.py

```diff
@@ -6,14 +6,15 @@
 import jax
 import numpy as np
 from jax import numpy as jnp, dtypes
 from jax.core import ShapedArray, Primitive
 from jax.interpreters import xla, ad
 from jax.lib import xla_client
 
+from brainpy._src.math.ndarray import _get_dtype
 from brainpy._src.math.interoperability import as_jax
 from brainpy._src.math.jitconn._matvec import (mv_prob_homo_p,
                                                mv_prob_uniform_p,
                                                mv_prob_normal_p,
                                                mv_prob_homo,
                                                mv_prob_uniform,
                                                mv_prob_normal)
@@ -128,14 +129,19 @@
 
 event_mv_prob_normal.__doc__ = mv_prob_normal.__doc__
 
 
 def _event_matvec_prob_homo_abstract(
     events, weight, clen, seed, *, shape, transpose, outdim_parallel
 ):
+  assert _get_dtype(events) in [jnp.bool_, jnp.float32, jnp.float64]
+  assert _get_dtype(weight) in [jnp.float32, jnp.float64], '"weight" must be float valued.'
+  assert _get_dtype(clen) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+  assert _get_dtype(seed) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+
   if events.ndim != 1:
     raise ValueError('events should be a 1D vector.')
   if len(shape) != 2:
     raise ValueError('shape should be a length-2 tuple.')
   if seed.ndim != 1:
     raise ValueError('seed must be a 1D scalar.')
   if clen.ndim != 1:
@@ -313,14 +319,23 @@
 ad.primitive_transposes[event_mv_prob_homo_p] = _event_matvec_prob_homo_transpose
 register_general_batching(event_mv_prob_homo_p)
 
 
 def _event_matvec_prob_uniform_abstract(
     events, w_low, w_high, clen, seed, *, shape, transpose, outdim_parallel
 ):
+  assert _get_dtype(events) in [jnp.bool_, jnp.float32, jnp.float64]
+  _w_low_dtype = _get_dtype(w_low)
+  _w_high_dtype = _get_dtype(w_low)
+  assert _w_low_dtype == _w_high_dtype, '"w_low" and "w_high" must be same typed.'
+  assert _w_low_dtype in [jnp.float32, jnp.float64], '"w_low" must be float valued.'
+  assert _w_high_dtype in [jnp.float32, jnp.float64], '"w_high" must be float valued.'
+  assert _get_dtype(clen) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+  assert _get_dtype(seed) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+
   if events.ndim != 1:
     raise ValueError('events should be a 1D vector.')
   if len(shape) != 2:
     raise ValueError('shape should be a length-2 tuple.')
   if w_low.ndim != 1:
     raise ValueError('w_low must be a 1D scalar.')
   if w_high.ndim != 1:
@@ -489,14 +504,23 @@
 ad.primitive_jvps[event_mv_prob_uniform_p] = _event_matvec_prob_uniform_jvp
 ad.primitive_transposes[event_mv_prob_uniform_p] = _event_matvec_prob_uniform_transpose
 
 
 def _event_matvec_prob_normal_abstract(
     events, w_mu, w_sigma, clen, seed, *, shape, transpose, outdim_parallel
 ):
+  assert _get_dtype(events) in [jnp.bool_, jnp.float32, jnp.float64]
+  _w_mu_dtype = _get_dtype(w_mu)
+  _w_sigma_dtype = _get_dtype(w_sigma)
+  assert _w_mu_dtype == _w_sigma_dtype, '"w_mu" and "w_sigma" must be same typed.'
+  assert _w_mu_dtype in [jnp.float32, jnp.float64], '"w_mu" must be float valued.'
+  assert _w_sigma_dtype in [jnp.float32, jnp.float64], '"w_sigma" must be float valued.'
+  assert _get_dtype(clen) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+  assert _get_dtype(seed) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+
   if w_mu.ndim != 1:
     raise ValueError('w_mu should be a 1D scalar.')
   if w_sigma.ndim != 1:
     raise ValueError('w_sigma should be a 1D scalar.')
   if clen.ndim != 1:
     raise ValueError('clen should be a 1D scalar.')
   if events.ndim != 1:
```

## brainpy/_src/math/jitconn/_matvec.py

```diff
@@ -9,15 +9,15 @@
 import numpy as np
 from jax import numpy as jnp, dtypes
 from jax.core import ShapedArray, Primitive
 from jax.interpreters import xla, ad
 from jax.lib import xla_client
 
 from brainpy._src.math.interoperability import as_jax
-from brainpy._src.math.ndarray import Array
+from brainpy._src.math.ndarray import Array, _get_dtype
 from brainpy._src.math.op_registers import register_general_batching
 from brainpy.errors import GPUOperatorNotFound, MathError
 
 try:
   from brainpylib import gpu_ops
 except ImportError:
   gpu_ops = None
@@ -264,14 +264,19 @@
                                transpose=transpose,
                                outdim_parallel=outdim_parallel)[0]
 
 
 def _matvec_prob_homo_abstract(
     vector, weight, clen, seed, *, shape, transpose, outdim_parallel
 ):
+  assert _get_dtype(vector) in [jnp.float32, jnp.float64]
+  assert _get_dtype(weight) in [jnp.float32, jnp.float64], '"weight" must be float valued.'
+  assert _get_dtype(clen) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+  assert _get_dtype(seed) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+
   if vector.ndim != 1:
     raise ValueError('vector should be a 1D vector.')
   if len(shape) != 2:
     raise ValueError('shape should be a length-2 tuple.')
   if seed.ndim != 1:
     raise ValueError('seed must be a 1D scalar.')
   if clen.ndim != 1:
@@ -447,14 +452,23 @@
 ad.primitive_jvps[mv_prob_homo_p] = _matvec_prob_homo_jvp
 ad.primitive_transposes[mv_prob_homo_p] = _matvec_prob_homo_transpose
 
 
 def _matvec_prob_uniform_abstract(
     vector, w_low, w_high, clen, seed, *, shape, transpose, outdim_parallel
 ):
+  assert _get_dtype(vector) in [jnp.float32, jnp.float64]
+  _w_low_dtype = _get_dtype(w_low)
+  _w_high_dtype = _get_dtype(w_low)
+  assert _w_low_dtype == _w_high_dtype, '"w_low" and "w_high" must be same typed.'
+  assert _w_low_dtype in [jnp.float32, jnp.float64], '"w_low" must be float valued.'
+  assert _w_high_dtype in [jnp.float32, jnp.float64], '"w_high" must be float valued.'
+  assert _get_dtype(clen) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+  assert _get_dtype(seed) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+
   if vector.ndim != 1:
     raise ValueError('vector should be a 1D vector.')
   if len(shape) != 2:
     raise ValueError('shape should be a length-2 tuple.')
   if w_low.ndim != 1:
     raise ValueError('w_low must be a 1D scalar.')
   if w_high.ndim != 1:
@@ -619,14 +633,23 @@
 ad.primitive_jvps[mv_prob_uniform_p] = _matvec_prob_uniform_jvp
 ad.primitive_transposes[mv_prob_uniform_p] = _matvec_prob_uniform_transpose
 
 
 def _matvec_prob_normal_abstract(
     vector, w_mu, w_sigma, clen, seed, *, shape, transpose, outdim_parallel
 ):
+  assert _get_dtype(vector) in [jnp.float32, jnp.float64]
+  _w_mu_dtype = _get_dtype(w_mu)
+  _w_sigma_dtype = _get_dtype(w_sigma)
+  assert _w_mu_dtype == _w_sigma_dtype, '"w_mu" and "w_sigma" must be same typed.'
+  assert _w_mu_dtype in [jnp.float32, jnp.float64], '"w_mu" must be float valued.'
+  assert _w_sigma_dtype in [jnp.float32, jnp.float64], '"w_sigma" must be float valued.'
+  assert _get_dtype(clen) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+  assert _get_dtype(seed) in [jnp.int32, jnp.int64, jnp.uint32, jnp.uint64]
+
   if w_mu.ndim != 1:
     raise ValueError('w_mu should be a 1D scalar.')
   if w_sigma.ndim != 1:
     raise ValueError('w_sigma should be a 1D scalar.')
   if clen.ndim != 1:
     raise ValueError('clen should be a 1D scalar.')
   if vector.ndim != 1:
```

## brainpy/_src/math/object_transform/_tools.py

```diff
@@ -2,15 +2,15 @@
 from functools import wraps
 from typing import Sequence
 
 import jax
 
 from brainpy._src.math.object_transform.naming import (cache_stack,
                                                        get_stack_cache)
-from brainpy._src.math.object_transform.variables import VariableStack
+from brainpy._src.math.object_transform.variables import VariableStack, current_transform_number
 
 
 class Empty(object):
   pass
 
 
 empty = Empty()
@@ -72,26 +72,57 @@
 def abstract(x):
   if callable(x):
     return x
   else:
     return jax.api_util.shaped_abstractify(x)
 
 
-def evaluate_dyn_vars(f,
-                      *args,
-                      static_argnums: Sequence[int] = (),
-                      static_argnames: Sequence[str] = (),
-                      **kwargs):
+def evaluate_dyn_vars(
+    f,
+    *args,
+    static_argnums: Sequence[int] = (),
+    static_argnames: Sequence[str] = (),
+    use_eval_shape: bool = True,
+    **kwargs
+):
+  # arguments
+  if len(static_argnums) or len(static_argnames):
+    f2, args, kwargs = _partial_fun(f, args, kwargs,
+                                    static_argnums=static_argnums,
+                                    static_argnames=static_argnames)
+  else:
+    f2, args, kwargs = f, args, kwargs
+  # stack
+  with VariableStack() as stack:
+    if use_eval_shape:
+      rets = jax.eval_shape(f2, *args, **kwargs)
+    else:
+      rets = f2(*args, **kwargs)
+  return stack, rets
+
+
+def evaluate_dyn_vars_with_cache(
+    f,
+    *args,
+    static_argnums: Sequence[int] = (),
+    static_argnames: Sequence[str] = (),
+    with_return: bool = False,
+    **kwargs
+):
   # TODO: better way for cache mechanism
   stack = get_stack_cache(f)
-  if stack is None:
+  if stack is None or with_return:
     if len(static_argnums) or len(static_argnames):
       f2, args, kwargs = _partial_fun(f, args, kwargs, static_argnums=static_argnums, static_argnames=static_argnames)
     else:
       f2, args, kwargs = f, args, kwargs
+
     with jax.ensure_compile_time_eval():
       with VariableStack() as stack:
-        _ = jax.eval_shape(f2, *args, **kwargs)
+        rets = jax.eval_shape(f2, *args, **kwargs)
       cache_stack(f, stack)  # cache
       del args, kwargs, f2
+    if with_return:
+      return stack, rets
+    else:
+      return stack
   return stack
-
```

## brainpy/_src/math/object_transform/autograd.py

```diff
@@ -6,26 +6,39 @@
 
 import jax
 import numpy as np
 from jax import linear_util, dtypes, vmap, numpy as jnp, core
 from jax._src.api import (_vjp, _jvp)
 from jax.api_util import argnums_partial
 from jax.interpreters import xla
-from jax.tree_util import (tree_flatten, tree_unflatten,
-                           tree_map, tree_transpose,
-                           tree_structure)
+from jax.tree_util import (
+  tree_flatten, tree_unflatten,
+  tree_map, tree_transpose,
+  tree_structure
+)
 from jax.util import safe_map
 
 from brainpy import tools, check
 from brainpy._src.math.ndarray import Array
-from .variables import Variable
-from .base import BrainPyObject, ObjectTransform
-from ._tools import (dynvar_deprecation,
-                     node_deprecation,
-                     evaluate_dyn_vars)
+from ._tools import (
+  dynvar_deprecation,
+  node_deprecation,
+  get_stack_cache,
+  cache_stack,
+)
+from .base import (
+  BrainPyObject,
+  ObjectTransform
+)
+from .variables import (
+  Variable,
+  VariableStack,
+  current_transform_number,
+  new_transform,
+)
 
 __all__ = [
   'grad',  # gradient of scalar function
   'vector_grad',  # gradient of vector/matrix/...
   'jacobian', 'jacrev', 'jacfwd',  # gradient of jacobian
   'hessian',  # gradient of hessian
 ]
@@ -81,25 +94,40 @@
     self._return_value = return_value
     self._has_aux = has_aux
 
     # target
     self.target = target
 
     # transform
+    self._eval_dyn_vars = False
     self._grad_transform = transform
-    self._dyn_vars = None
+    self._dyn_vars = VariableStack()
     self._transform = None
     self._grad_setting = dict() if transform_setting is None else transform_setting
+    if self._has_aux:
+      self._transform = self._grad_transform(
+        self._f_grad_with_aux_to_transform,
+        argnums=self._argnums,
+        has_aux=True,
+        **self._grad_setting
+      )
+    else:
+      self._transform = self._grad_transform(
+        self._f_grad_without_aux_to_transform,
+        argnums=self._argnums,
+        has_aux=True,
+        **self._grad_setting
+      )
 
   def _f_grad_with_aux_to_transform(self,
                                     grad_values: tuple,
                                     dyn_values: dict,
                                     *args,
                                     **kwargs):
-    for k in self._dyn_vars.keys():
+    for k in dyn_values.keys():
       self._dyn_vars[k]._value = dyn_values[k]
     for v, d in zip(self._grad_vars, grad_values):
       v._value = d
     # Users should return the auxiliary data like::
     # >>> # 1. example of return one data
     # >>> return scalar_loss, data
     # >>> # 2. example of return multiple data
@@ -111,61 +139,38 @@
     return output0, (outputs, [v.value for v in self._grad_vars], self._dyn_vars.dict_data())
 
   def _f_grad_without_aux_to_transform(self,
                                        grad_values: tuple,
                                        dyn_values: dict,
                                        *args,
                                        **kwargs):
-    for k in self._dyn_vars.keys():
+    for k in dyn_values.keys():
       self._dyn_vars[k]._value = dyn_values[k]
     for v, d in zip(self._grad_vars, grad_values):
       v._value = d
     # Users should return the scalar value like this::
     # >>> return scalar_loss
     output = self.target(*args, **kwargs)
     output0 = tree_map(lambda a: (a.value if isinstance(a, Array) else a), output)
     return output0, (output, [v.value for v in self._grad_vars], self._dyn_vars.dict_data())
 
   def __repr__(self):
     name = self.__class__.__name__
     f = tools.repr_object(self.target)
     f = tools.repr_context(f, " " * (len(name) + 6))
-    format_ref = (f'{name}(target={f}, \n' +
+    format_ref = (f'{name}({self.name}, target={f}, \n' +
                   f'{" " * len(name)} num_of_grad_vars={len(self._grad_vars)}, \n'
                   f'{" " * len(name)} num_of_dyn_vars={len(self._dyn_vars)})')
     return format_ref
 
-  def __call__(self, *args, **kwargs):
-    if self._transform is None:
-      self._dyn_vars = evaluate_dyn_vars(self.target, *args, **kwargs)
-      self._dyn_vars.remove_var_by_id(*[id(v) for v in self._grad_vars])
-      if self._has_aux:
-        self._transform = self._grad_transform(
-          self._f_grad_with_aux_to_transform,
-          argnums=self._argnums,
-          has_aux=True,
-          **self._grad_setting
-        )
-      else:
-        self._transform = self._grad_transform(
-          self._f_grad_without_aux_to_transform,
-          argnums=self._argnums,
-          has_aux=True,
-          **self._grad_setting
-        )
-
-    grads, (outputs, new_grad_vs, new_dyn_vs) = self._transform(
-      [v.value for v in self._grad_vars],  # gradient variables
-      self._dyn_vars.dict_data(),  # dynamical variables
-      *args,
-      **kwargs
-    )
+  def _return(self, rets):
+    grads, (outputs, new_grad_vs, new_dyn_vs) = rets
     for v, d in zip(self._grad_vars, new_grad_vs):
       v._value = d
-    for k in self._dyn_vars.keys():
+    for k in new_dyn_vs.keys():
       self._dyn_vars[k]._value = new_dyn_vs[k]
 
     # check returned grads
     if len(self._grad_vars) > 0:
       if self._nonvar_argnums is None:
         grads = self._grad_tree.unflatten(grads)
       else:
@@ -183,14 +188,62 @@
     else:
       # check aux
       if self._has_aux:
         return grads, outputs[1]
       else:
         return grads
 
+  def __call__(self, *args, **kwargs):
+    if jax.config.jax_disable_jit:  # disable JIT
+      rets = self._transform(
+        [v.value for v in self._grad_vars],  # variables for gradients
+        self._dyn_vars.dict_data(),  # dynamical variables
+        *args,
+        **kwargs
+      )
+      return self._return(rets)
+
+    elif not self._eval_dyn_vars:  # evaluate dynamical variables
+      stack = get_stack_cache(self.target)
+      if stack is None:
+        with new_transform(self):
+          with VariableStack() as stack:
+            if current_transform_number() > 1:
+              rets = self._transform(
+                [v.value for v in self._grad_vars],  # variables for gradients
+                {},  # dynamical variables
+                *args,
+                **kwargs
+              )
+            else:
+              rets = jax.eval_shape(
+                self._transform,
+                [v.value for v in self._grad_vars],  # variables for gradients
+                {},  # dynamical variables
+                *args,
+                **kwargs
+              )
+          cache_stack(self.target, stack)
+
+      self._dyn_vars = stack
+      self._dyn_vars.remove_var_by_id(*[id(v) for v in self._grad_vars])
+      self._eval_dyn_vars = True
+
+      # if not the outermost transformation
+      if current_transform_number():
+        return self._return(rets)
+
+    rets = self._transform(
+      [v.value for v in self._grad_vars],  # variables for gradients
+      self._dyn_vars.dict_data(),  # dynamical variables
+      *args,
+      **kwargs
+    )
+    return self._return(rets)
+
 
 def _make_grad(
     func: Callable,
     grad_vars: Optional[Union[Variable, Sequence[Variable], Dict[str, Variable]]] = None,
     argnums: Optional[Union[int, Sequence[int]]] = None,
     holomorphic: Optional[bool] = False,
     allow_int: Optional[bool] = False,
@@ -214,27 +267,27 @@
                            has_aux=False if has_aux is None else has_aux,
                            transform_setting=dict(holomorphic=holomorphic,
                                                   allow_int=allow_int,
                                                   reduce_axes=reduce_axes))
 
 
 def grad(
-    func: Callable = None,
+    func: Optional[Callable] = None,
     grad_vars: Optional[Union[Variable, Sequence[Variable], Dict[str, Variable]]] = None,
     argnums: Optional[Union[int, Sequence[int]]] = None,
     holomorphic: Optional[bool] = False,
     allow_int: Optional[bool] = False,
     reduce_axes: Optional[Sequence[str]] = (),
     has_aux: Optional[bool] = None,
     return_value: Optional[bool] = False,
 
     # deprecated
     dyn_vars: Optional[Union[Variable, Sequence[Variable], Dict[str, Variable]]] = None,
     child_objs: Optional[Union[BrainPyObject, Sequence[BrainPyObject], Dict[str, BrainPyObject]]] = None,
-) -> GradientTransform:
+) -> Union[Callable, GradientTransform]:
   """Automatic gradient computation for functions or class objects.
 
   This gradient function only support scalar return. It creates a function
   which evaluates the gradient of ``func``.
 
   It's worthy to note that the returns are different for different argument settings (where ``arg_grads`` refers
   to the gradients of "argnums", and ``var_grads`` refers to the gradients of "grad_vars").
@@ -715,37 +768,37 @@
     f = linear_util.wrap_init(func, kwargs)
     f_partial, dyn_args = argnums_partial(f, argnums, args, require_static_args_hashable=False)
     if has_aux:
       y, vjp_fn, aux = _vjp(f_partial, *dyn_args, has_aux=True)
     else:
       y, vjp_fn = _vjp(f_partial, *dyn_args, has_aux=False)
     leaves, tree = tree_flatten(y)
-    tangents = tree_unflatten(tree, [jnp.ones_like(l) for l in leaves])
+    tangents = tree_unflatten(tree, [jnp.ones(l.shape, dtype=l.dtype) for l in leaves])
     grads = vjp_fn(tangents)
     if isinstance(argnums, int):
       grads = grads[0]
     if has_aux:
       return (grads, y, aux) if return_value else (grads, aux)
     else:
       return (grads, y) if return_value else grads
 
   return grad_fun
 
 
 def vector_grad(
-    func: Callable,
+    func: Optional[Callable] = None,
     grad_vars: Optional[Union[Variable, Sequence[Variable], Dict[str, Variable]]] = None,
     argnums: Optional[Union[int, Sequence[int]]] = None,
     return_value: bool = False,
     has_aux: Optional[bool] = None,
 
     # deprecated
     dyn_vars: Optional[Union[Variable, Sequence[Variable], Dict[str, Variable]]] = None,
     child_objs: Optional[Union[BrainPyObject, Sequence[BrainPyObject], Dict[str, BrainPyObject]]] = None,
-) -> ObjectTransform:
+) -> Union[Callable, ObjectTransform]:
   """Take vector-valued gradients for function ``func``.
 
   Same as `brainpy.math.grad <./brainpy.math.autograd.grad.html>`_,
   `brainpy.math.jacrev <./brainpy.math.autograd.jacrev.html>`_ and
   `brainpy.math.jacfwd <./brainpy.math.autograd.jacfwd.html>`_,
   the returns in this function are different for different argument settings.
 
@@ -798,22 +851,32 @@
   -------
   func : GradientTransform
     The vector gradient function.
   """
   child_objs = check.is_all_objs(child_objs, out_as='dict')
   dyn_vars = check.is_all_vars(dyn_vars, out_as='dict')
 
-  return GradientTransform(target=func,
-                           transform=_vector_grad,
-                           grad_vars=grad_vars,
-                           dyn_vars=dyn_vars,
-                           child_objs=child_objs,
-                           argnums=argnums,
-                           return_value=return_value,
-                           has_aux=False if has_aux is None else has_aux)
+  if func is None:
+    return lambda f: GradientTransform(target=f,
+                                       transform=_vector_grad,
+                                       grad_vars=grad_vars,
+                                       dyn_vars=dyn_vars,
+                                       child_objs=child_objs,
+                                       argnums=argnums,
+                                       return_value=return_value,
+                                       has_aux=False if has_aux is None else has_aux)
+  else:
+    return GradientTransform(target=func,
+                             transform=_vector_grad,
+                             grad_vars=grad_vars,
+                             dyn_vars=dyn_vars,
+                             child_objs=child_objs,
+                             argnums=argnums,
+                             return_value=return_value,
+                             has_aux=False if has_aux is None else has_aux)
 
 
 def _check_callable(fun):
   # In Python 3.10+, the only thing stopping us from supporting staticmethods
   # is that we can't take weak references to them, which the C++ JIT requires.
   if isinstance(fun, staticmethod):
     raise TypeError(f"staticmethod arguments are not supported, got {fun}")
```

## brainpy/_src/math/object_transform/base.py

```diff
@@ -23,15 +23,15 @@
                                                           VarList, VarDict)
 
 StateLoadResult = namedtuple('StateLoadResult', ['missing_keys', 'unexpected_keys'])
 
 __all__ = [
   'BrainPyObject', 'Base', 'FunAsObject', 'ObjectTransform',
 
-  'NodeDict', 'NodeList',
+  'NodeDict', 'node_dict', 'NodeList', 'node_list',
 ]
 
 
 class BrainPyObject(object):
   """The BrainPyObject class for the whole BrainPy ecosystem.
 
   The subclass of BrainPyObject includes but not limited to:
@@ -95,16 +95,19 @@
     # which cannot be accessed by self.xxx
     self.implicit_vars: ArrayCollector = ArrayCollector()
 
     # Used to wrap the implicit children nodes
     # which cannot be accessed by self.xxx
     self.implicit_nodes: Collector = Collector()
 
+  def setattr(self, key: str, value: Any) -> None:
+    super().__setattr__(key, value)
+
   def __setattr__(self, key: str, value: Any) -> None:
-    """Overwrite `__setattr__` method for change Variable values.
+    """Overwrite `__setattr__` method for changing :py:class:`~.Variable` values.
 
     .. versionadded:: 2.3.1
 
     Parameters
     ----------
     key: str
       The attribute.
@@ -390,23 +393,23 @@
         return get_unique_name(type_=self.__class__.__name__)
       else:
         return get_unique_name(type_=type_)
     else:
       check_name_uniqueness(name=name, obj=self)
       return name
 
-  def __save_state__(self) -> dict:
+  def __save_state__(self) -> Dict[str, Variable]:
     return self.vars(include_self=True, level=0).unique().dict()
 
-  def __load_state__(self, state_dict: dict) -> Optional[Tuple[Sequence[str], Sequence[str]]]:
+  def __load_state__(self, state_dict: Dict) -> Optional[Tuple[Sequence[str], Sequence[str]]]:
     variables = self.vars(include_self=True, level=0).unique()
     keys1 = set(state_dict.keys())
     keys2 = set(variables.keys())
     for key in keys2.intersection(keys1):
-      variables[key].value = state_dict[key]
+      variables[key].value = jax.numpy.asarray(state_dict[key])
     unexpected_keys = list(keys1 - keys2)
     missing_keys = list(keys2 - keys1)
     return unexpected_keys, missing_keys
 
   def state_dict(self) -> dict:
     """Returns a dictionary containing a whole state of the module.
 
@@ -443,23 +446,25 @@
     if compatible == 'v1':
       variables = self.vars().unique()
       keys1 = set(state_dict.keys())
       keys2 = set(variables.keys())
       unexpected_keys = list(keys1 - keys2)
       missing_keys = list(keys2 - keys1)
       for key in keys2.intersection(keys1):
-        variables[key].value = state_dict[key]
+        variables[key].value = jax.numpy.asarray(state_dict[key])
     elif compatible == 'v2':
       nodes = self.nodes()
       missing_keys = []
       unexpected_keys = []
       for name, node in nodes.items():
-        missing, unexpected = node.__load_state__(state_dict[name])
-        missing_keys.extend([f'{name}.{key}' for key in missing])
-        unexpected_keys.extend([f'{name}.{key}' for key in unexpected])
+        r = node.__load_state__(state_dict[name])
+        if r is not None:
+          missing, unexpected = r
+          missing_keys.extend([f'{name}.{key}' for key in missing])
+          unexpected_keys.extend([f'{name}.{key}' for key in unexpected])
     else:
       raise ValueError(f'Unknown compatible version: {compatible}')
     if warn:
       if len(unexpected_keys):
         warnings.warn(f'Unexpected keys in state_dict: {unexpected_keys}', UserWarning)
       if len(missing_keys):
         warnings.warn(f'Missing keys in state_dict: {missing_keys}', UserWarning)
@@ -651,14 +656,16 @@
 
   def extend(self, iterable) -> 'NodeList':
     for element in iterable:
       self.append(element)
     return self
 
 
+node_list = NodeList
+
 
 class NodeDict(dict):
   """A dictionary of :py:class:`~.BrainPyObject`, which is compatible with
   :py:func:`.vars()` operation in a :py:class:`~.BrainPyObject`.
   """
 
   def _check_elem(self, elem):
@@ -682,7 +689,10 @@
       self[k] = v
     return self
 
   def __setitem__(self, key, value) -> 'VarDict':
     super().__setitem__(key, self._check_elem(value))
     return self
 
+
+node_dict = NodeDict
+
```

## brainpy/_src/math/object_transform/controls.py

```diff
@@ -1,30 +1,42 @@
 # -*- coding: utf-8 -*-
-
-
+import functools
 from typing import Union, Sequence, Any, Dict, Callable, Optional
+import numbers
 
 import jax
 import jax.numpy as jnp
-from jax import lax
 from jax.errors import UnexpectedTracerError
 from jax.tree_util import tree_flatten, tree_unflatten
+from tqdm.auto import tqdm
+from jax.experimental.host_callback import id_tap
 
 from brainpy import errors, tools
 from brainpy._src.math.interoperability import as_jax
 from brainpy._src.math.ndarray import (Array, )
-from ._tools import (evaluate_dyn_vars,
-                     dynvar_deprecation,
-                     node_deprecation,
-                     abstract)
+from ._tools import (
+  evaluate_dyn_vars,
+  evaluate_dyn_vars_with_cache,
+  dynvar_deprecation,
+  node_deprecation,
+  abstract
+)
 from .base import BrainPyObject, ObjectTransform
-from .naming import (get_unique_name,
-                     get_stack_cache,
-                     cache_stack)
-from .variables import (Variable, VariableStack)
+from .naming import (
+  get_unique_name,
+  get_stack_cache,
+  cache_stack
+)
+from .variables import (
+  Variable,
+  VariableStack,
+  new_transform,
+  current_transform_number,
+  transform_stack,
+)
 
 __all__ = [
   'make_loop',
   'make_while',
   'make_cond',
 
   'cond',
@@ -198,28 +210,28 @@
                                             has_return=has_return)
 
   # functions
   if has_return:
     def call(xs=None, length=None):
       init_values = [v.value for v in dyn_vars]
       try:
-        dyn_values, (out_values, results) = lax.scan(
+        dyn_values, (out_values, results) = jax.lax.scan(
           f=fun2scan, init=init_values, xs=xs, length=length
         )
       except UnexpectedTracerError as e:
         for v, d in zip(dyn_vars, init_values): v._value = d
         raise errors.JaxTracerError(variables=dyn_vars) from e
       for v, d in zip(dyn_vars, dyn_values): v._value = d
       return tree_unflatten(tree, out_values), results
 
   else:
     def call(xs):
       init_values = [v.value for v in dyn_vars]
       try:
-        dyn_values, out_values = lax.scan(f=fun2scan, init=init_values, xs=xs)
+        dyn_values, out_values = jax.lax.scan(f=fun2scan, init=init_values, xs=xs)
       except UnexpectedTracerError as e:
         for v, d in zip(dyn_vars, init_values): v._value = d
         raise errors.JaxTracerError(variables=dyn_vars) from e
       except Exception as e:
         for v, d in zip(dyn_vars, init_values): v._value = d
         raise e
       for v, d in zip(dyn_vars, dyn_values): v._value = d
@@ -293,17 +305,17 @@
     return as_jax(cond_fun(static_values))
 
   name = get_unique_name('_brainpy_object_oriented_make_while_')
 
   def call(x=None):
     dyn_init = [v.value for v in dyn_vars]
     try:
-      dyn_values, _ = lax.while_loop(cond_fun=_cond_fun,
-                                     body_fun=_body_fun,
-                                     init_val=(dyn_init, x))
+      dyn_values, _ = jax.lax.while_loop(cond_fun=_cond_fun,
+                                         body_fun=_body_fun,
+                                         init_val=(dyn_init, x))
     except UnexpectedTracerError as e:
       for v, d in zip(dyn_vars, dyn_init): v._value = d
       raise errors.JaxTracerError(variables=dyn_vars) from e
     except Exception as e:
       for v, d in zip(dyn_vars, dyn_init): v._value = d
       raise e
     for v, d in zip(dyn_vars, dyn_values): v._value = d
@@ -388,60 +400,81 @@
       res = false_fun(static_vals)
       dyn_vals = [v.value for v in dyn_vars]
       return dyn_vals, res
 
     def call(pred, x=None):
       old_values = [v.value for v in dyn_vars]
       try:
-        dyn_values, res = lax.cond(pred, _true_fun, _false_fun, (old_values, x))
+        dyn_values, res = jax.lax.cond(pred, _true_fun, _false_fun, (old_values, x))
       except UnexpectedTracerError as e:
         for v, d in zip(dyn_vars, old_values): v._value = d
         raise errors.JaxTracerError(variables=dyn_vars) from e
       except Exception as e:
         for v, d in zip(dyn_vars, old_values): v._value = d
         raise e
       for v, d in zip(dyn_vars, dyn_values): v._value = d
       return res
 
   else:
     def call(pred, x=None):
-      res = lax.cond(pred, true_fun, false_fun, x)
+      res = jax.lax.cond(pred, true_fun, false_fun, x)
       return res
 
   return ControlObject(call, dyn_vars, repr_fun={'true_fun': true_fun, 'false_fun': false_fun})
 
 
 def _check_f(f):
   if callable(f):
     return f
   else:
-    return (lambda _: f)
+    return (lambda *args, **kwargs: f)
 
 
 def _check_sequence(a):
   return isinstance(a, (list, tuple))
 
 
+def _cond_transform_fun(fun, dyn_vars):
+  @functools.wraps(fun)
+  def new_fun(dyn_vals, *static_vals):
+    for k, v in dyn_vars.items():
+      v._value = dyn_vals[k]
+    r = fun(*static_vals)
+    return {k: v.value for k, v in dyn_vars.items()}, r
+
+  return new_fun
+
+
+def _get_cond_transform(dyn_vars, pred, true_fun, false_fun):
+  _true_fun = _cond_transform_fun(true_fun, dyn_vars)
+  _false_fun = _cond_transform_fun(false_fun, dyn_vars)
+
+  def call_fun(operands):
+    return jax.lax.cond(pred, _true_fun, _false_fun, dyn_vars.dict_data(), *operands)
+
+  return call_fun
+
+
 def cond(
     pred: bool,
-    true_fun: Union[Callable, jnp.ndarray, Array, float, int, bool],
-    false_fun: Union[Callable, jnp.ndarray, Array, float, int, bool],
-    operands: Any,
+    true_fun: Union[Callable, jnp.ndarray, Array, numbers.Number],
+    false_fun: Union[Callable, jnp.ndarray, Array, numbers.Number],
+    operands: Any = (),
 
     # deprecated
     dyn_vars: Union[Variable, Sequence[Variable], Dict[str, Variable]] = None,
     child_objs: Optional[Union[BrainPyObject, Sequence[BrainPyObject], Dict[str, BrainPyObject]]] = None,
 ):
   """Simple conditional statement (if-else) with instance of :py:class:`~.Variable`.
 
   >>> import brainpy.math as bm
   >>> a = bm.Variable(bm.zeros(2))
   >>> b = bm.Variable(bm.ones(2))
-  >>> def true_f(_):  a.value += 1
-  >>> def false_f(_): b.value -= 1
+  >>> def true_f():  a.value += 1
+  >>> def false_f(): b.value -= 1
   >>>
   >>> bm.cond(True, true_f, false_f)
   >>> a, b
   Variable([1., 1.], dtype=float32), Variable([1., 1.], dtype=float32)
   >>>
   >>> bm.cond(False, true_f, false_f)
   >>> a, b
@@ -456,20 +489,27 @@
     This function must receive one arguement for ``operands``.
   false_fun: callable, ArrayType, float, int, bool
     Function to be applied if ``pred`` is False.
     This function must receive one arguement for ``operands``.
   operands: Any
     Operands (A) input to branching function depending on ``pred``. The type
     can be a scalar, array, or any pytree (nested Python tuple/list/dict) thereof.
+
   dyn_vars: optional, Variable, sequence of Variable, dict
     The dynamically changed variables.
+
+    .. deprecated:: 2.4.0
+       No longer need to provide ``dyn_vars``. This function is capable of automatically
+       collecting the dynamical variables used in the target ``func``.
   child_objs: optional, dict, sequence of BrainPyObject, BrainPyObject
     The children objects used in the target function.
 
-    .. versionadded:: 2.3.1
+    .. deprecated:: 2.4.0
+       No longer need to provide ``dyn_vars``. This function is capable of automatically
+       collecting the dynamical variables used in the target ``func``.
 
   Returns
   -------
   res: Any
     The conditional results.
   """
 
@@ -481,42 +521,62 @@
   if not isinstance(operands, (tuple, list)):
     operands = (operands,)
 
   # dyn vars
   dynvar_deprecation(dyn_vars)
   node_deprecation(child_objs)
 
+  dyn_vars = get_stack_cache((true_fun, false_fun))
+  _transform = _get_cond_transform(VariableStack() if dyn_vars is None else dyn_vars,
+                                   pred,
+                                   true_fun,
+                                   false_fun)
   if jax.config.jax_disable_jit:
-    dyn_vars = VariableStack()
+    dyn_values, res = _transform(operands)
+
+  else:
+    if dyn_vars is None:
+      with new_transform('cond'):
+        dyn_vars, rets = evaluate_dyn_vars(
+          _transform,
+          operands,
+          use_eval_shape=current_transform_number() <= 1
+        )
+        cache_stack((true_fun, false_fun), dyn_vars)
+      if current_transform_number() > 0:
+        return rets[1]
+    dyn_values, res = _get_cond_transform(dyn_vars, pred, true_fun, false_fun)(operands)
+  for k in dyn_values.keys():
+    dyn_vars[k]._value = dyn_values[k]
+  return res
+
 
+def _if_else_return1(conditions, branches, operands):
+  for i, pred in enumerate(conditions):
+    if pred:
+      return branches[i](*operands)
   else:
-    dyn_vars = evaluate_dyn_vars(true_fun, *operands)
-    dyn_vars += evaluate_dyn_vars(false_fun, *operands)
+    return branches[-1](*operands)
 
-  # TODO: cache mechanism?
-  if len(dyn_vars) > 0:
-    def _true_fun(dyn_vals, *static_vals):
-      for k, v in dyn_vars.items():
-        v._value = dyn_vals[k]
-      r = true_fun(*static_vals)
-      return {k: v.value for k, v in dyn_vars.items()}, r
-
-    def _false_fun(dyn_vals, *static_vals):
-      for k, v in dyn_vars.items():
-        v._value = dyn_vals[k]
-      r = false_fun(*static_vals)
-      return {k: v.value for k, v in dyn_vars.items()}, r
 
-    old_values = {k: v.value for k, v in dyn_vars.items()}
-    dyn_values, res = lax.cond(pred, _true_fun, _false_fun, old_values, *operands)
-    for k, v in dyn_vars.items():
-      v._value = dyn_values[k]
+def _if_else_return2(conditions, branches):
+  for i, pred in enumerate(conditions):
+    if pred:
+      return branches[i]
   else:
-    res = lax.cond(pred, true_fun, false_fun, *operands)
-  return res
+    return branches[-1]
+
+
+def all_equal(iterator):
+  iterator = iter(iterator)
+  try:
+    first = next(iterator)
+  except StopIteration:
+    return True
+  return all(first == x for x in iterator)
 
 
 def ifelse(
     conditions: Union[bool, Sequence[bool]],
     branches: Sequence[Any],
     operands: Any = None,
     show_code: bool = False,
@@ -554,22 +614,28 @@
   branches: Any
     The branches, at least has two elements. Elements can be functions,
     arrays, or numbers. The number of ``branches`` and ``conditions`` has
     the relationship of `len(branches) == len(conditions) + 1`.
     Each branch should receive one arguement for ``operands``.
   operands: optional, Any
     The operands for each branch.
-  dyn_vars: Variable, sequence of Variable, dict
-    The dynamically changed variables.
   show_code: bool
     Whether show the formatted code.
+  dyn_vars: Variable, sequence of Variable, dict
+    The dynamically changed variables.
+
+    .. deprecated:: 2.4.0
+       No longer need to provide ``dyn_vars``. This function is capable of automatically
+       collecting the dynamical variables used in the target ``func``.
   child_objs: optional, dict, sequence of BrainPyObject, BrainPyObject
     The children objects used in the target function.
 
-    .. versionadded:: 2.3.1
+    .. deprecated:: 2.4.0
+       No longer need to provide ``dyn_vars``. This function is capable of automatically
+       collecting the dynamical variables used in the target ``func``.
 
   Returns
   -------
   res: Any
     The results of the control flow.
   """
   # checking
@@ -582,60 +648,124 @@
     raise ValueError(f'"branches" must be a tuple/list. '
                      f'But we got {type(branches)}.')
   branches = [_check_f(b) for b in branches]
   if len(branches) != len(conditions) + 1:
     raise ValueError(f'The numbers of branches and conditions do not match. '
                      f'Got len(conditions)={len(conditions)} and len(branches)={len(branches)}. '
                      f'We expect len(conditions) + 1 == len(branches). ')
+  if operands is None:
+    operands = tuple()
+  if not isinstance(operands, (tuple, list)):
+    operands = (operands,)
 
   dynvar_deprecation(dyn_vars)
   node_deprecation(child_objs)
 
   # format new codes
   if len(conditions) == 1:
     return cond(conditions[0],
                 branches[0],
                 branches[1],
                 operands)
   else:
+    if jax.config.jax_disable_jit:
+      return _if_else_return1(conditions, branches, operands)
+
+    else:
+      dyn_vars = get_stack_cache(tuple(branches))
+      if dyn_vars is None:
+        with new_transform('ifelse'):
+          with VariableStack() as dyn_vars:
+            if current_transform_number() > 1:
+              rets = [branch(*operands) for branch in branches]
+            else:
+              rets = [jax.eval_shape(branch, *operands) for branch in branches]
+            trees = [jax.tree_util.tree_structure(ret) for ret in rets]
+            if not all_equal(trees):
+              msg = 'All returns in branches should have the same tree structure. But we got:\n'
+              for tree in trees:
+                msg += f'- {tree}\n'
+              raise TypeError(msg)
+          cache_stack(tuple(branches), dyn_vars)
+        if current_transform_number():
+          return _if_else_return2(conditions, rets)
+
+      branches = [_cond_transform_fun(fun, dyn_vars) for fun in branches]
+
     code_scope = {'conditions': conditions, 'branches': branches}
-    codes = ['def f(operands):',
+    codes = ['def f(dyn_vals, *operands):',
              f'  f0 = branches[{len(conditions)}]']
     num_cond = len(conditions) - 1
-    code_scope['_cond'] = cond
+    code_scope['_cond'] = jax.lax.cond
     for i in range(len(conditions) - 1):
-      codes.append(f'  f{i + 1} = lambda r: _cond(conditions[{num_cond - i}], branches[{num_cond - i}], f{i}, r)')
-    codes.append(f'  return _cond(conditions[0], branches[0], f{len(conditions) - 1}, operands)')
+      codes.append(f'  f{i + 1} = lambda *r: _cond(conditions[{num_cond - i}], branches[{num_cond - i}], f{i}, *r)')
+    codes.append(f'  return _cond(conditions[0], branches[0], f{len(conditions) - 1}, dyn_vals, *operands)')
     codes = '\n'.join(codes)
-    if show_code: print(codes)
+    if show_code:
+      print(codes)
     exec(compile(codes.strip(), '', 'exec'), code_scope)
     f = code_scope['f']
-    r = f(operands)
-    return r
+    dyn_values, res = f(dyn_vars.dict_data(), *operands)
+    for k in dyn_values.keys():
+      dyn_vars[k]._value = dyn_values[k]
+    return res
 
 
 def _loop_abstractify(x):
   x = abstract(x)
   return jax.core.mapped_aval(x.shape[0], 0, x)
 
 
+def _get_for_loop_transform(
+    body_fun,
+    dyn_vars,
+    bar: tqdm,
+    progress_bar: bool,
+    remat: bool,
+    reverse: bool,
+    unroll: int
+):
+  def fun2scan(carry, x):
+    for k in dyn_vars.keys():
+      dyn_vars[k]._value = carry[k]
+    results = body_fun(*x)
+    if progress_bar:
+      id_tap(lambda *arg: bar.update(), ())
+    return dyn_vars.dict_data(), results
+
+  if remat:
+    fun2scan = jax.checkpoint(fun2scan)
+
+  def call(operands):
+    return jax.lax.scan(f=fun2scan,
+                        init=dyn_vars.dict_data(),
+                        xs=operands,
+                        reverse=reverse,
+                        unroll=unroll)
+
+  return call
+
+
 def for_loop(
     body_fun: Callable,
     operands: Any,
     reverse: bool = False,
     unroll: int = 1,
     remat: bool = False,
-    jit: bool = True,
+    jit: Optional[bool] = None,
+    progress_bar: bool = False,
 
     # deprecated
     dyn_vars: Union[Variable, Sequence[Variable], Dict[str, Variable]] = None,
     child_objs: Optional[Union[BrainPyObject, Sequence[BrainPyObject], Dict[str, BrainPyObject]]] = None,
 ):
   """``for-loop`` control flow with :py:class:`~.Variable`.
 
+  .. versionadded:: 2.1.11
+
   .. versionchanged:: 2.3.0
      ``dyn_vars`` has been changed into a default argument.
      Please change your call from ``for_loop(fun, dyn_vars, operands)``
      to ``for_loop(fun, operands, dyn_vars)``.
 
   Simply speaking, all dynamically changed variables used in the body function should
   be labeld in ``dyn_vars`` argument. All returns in body function will be gathered
@@ -668,16 +798,14 @@
   >>> a_hist = bm.for_loop(body, operands=(bm.arange(1, 5), bm.arange(2, 6)))
   >>> a_hist
   [[11.]
    [13.]
    [16.]
    [20.]]
 
-  .. versionadded:: 2.1.11
-
   Parameters
   ----------
   body_fun: callable
     A Python function to be scanned. This function accepts one argument and returns one output.
     The argument denotes a slice of ``operands`` along its leading axis, and that
     output represents a slice of the return value.
   operands: Any
@@ -695,15 +823,18 @@
     Optional boolean specifying whether to run the scan iteration
     forward (the default) or in reverse, equivalent to reversing the leading
     axes of the arrays in both ``xs`` and in ``ys``.
   unroll: int
     Optional positive int specifying, in the underlying operation of the
     scan primitive, how many scan iterations to unroll within a single
     iteration of a loop.
+  progress_bar: bool
+    Whether we use the progress bar to report the running progress.
 
+    .. versionadded:: 2.4.2
   dyn_vars: Variable, sequence of Variable, dict
     The instances of :py:class:`~.Variable`.
 
     .. deprecated:: 2.4.0
        No longer need to provide ``dyn_vars``. This function is capable of automatically
        collecting the dynamical variables used in the target ``func``.
   child_objs: optional, dict, sequence of BrainPyObject, BrainPyObject
@@ -723,51 +854,82 @@
 
   dynvar_deprecation(dyn_vars)
   node_deprecation(child_objs)
 
   if not isinstance(operands, (list, tuple)):
     operands = (operands,)
 
-  dyn_vars = get_stack_cache(body_fun)
-  if not jit:
-    if dyn_vars is None:
-      dyn_vars = VariableStack()
+  num_total = min([op.shape[0] for op in jax.tree_util.tree_flatten(operands)[0]])
+  bar = None
+  if progress_bar:
+    bar = tqdm(total=num_total)
 
-  else:
-    # TODO: better cache mechanism?
+  if jit is None:  # jax disable jit
+    jit = not jax.config.jax_disable_jit
+  dyn_vars = get_stack_cache(body_fun)
+  if jit:
     if dyn_vars is None:
-      with jax.ensure_compile_time_eval():
-        op_vals = jax.tree_util.tree_map(_loop_abstractify, operands)
+      # TODO: better cache mechanism?
+      with new_transform('for_loop'):
         with VariableStack() as dyn_vars:
-          _ = jax.eval_shape(body_fun, *op_vals)
-        cache_stack(body_fun, dyn_vars)  # cache
-        del op_vals
-
-  # functions
-  def fun2scan(carry, x):
-    for k in dyn_vars.keys():
-      dyn_vars[k]._value = carry[k]
-    results = body_fun(*x)
-    return dyn_vars.dict_data(), results
-
-  if remat:
-    fun2scan = jax.checkpoint(fun2scan)
+          transform = _get_for_loop_transform(body_fun, VariableStack(), bar,
+                                              progress_bar, remat, reverse, unroll)
+          if current_transform_number() > 1:
+            rets = transform(operands)
+          else:
+            rets = jax.eval_shape(transform, operands)
+      cache_stack(body_fun, dyn_vars)  # cache
+      if current_transform_number():
+        return rets[1]
+      del rets
+  else:
+    dyn_vars = VariableStack()
 
   # TODO: cache mechanism?
-  with jax.disable_jit(not jit):
-    dyn_vals, out_vals = lax.scan(f=fun2scan,
-                                  init=dyn_vars.dict_data(),
-                                  xs=operands,
-                                  reverse=reverse,
-                                  unroll=unroll)
+  transform = _get_for_loop_transform(body_fun, dyn_vars, bar, progress_bar, remat, reverse, unroll)
+  if jit:
+    dyn_vals, out_vals = transform(operands)
+  else:
+    with jax.disable_jit():
+      dyn_vals, out_vals = transform(operands)
   for key in dyn_vars.keys():
     dyn_vars[key]._value = dyn_vals[key]
+  if progress_bar:
+    bar.close()
   return out_vals
 
 
+def _get_while_transform(cond_fun, body_fun, dyn_vars):
+  def _body_fun(op):
+    dyn_vals, old_vals = op
+    for k, v in dyn_vars.items():
+      v._value = dyn_vals[k]
+    new_vals = body_fun(*old_vals)
+    if new_vals is None:
+      new_vals = old_vals
+    if not isinstance(new_vals, tuple):
+      new_vals = (new_vals,)
+    if isinstance(new_vals, list):
+      new_vals = tuple(new_vals)
+    return dyn_vars.dict_data(), new_vals
+
+  def _cond_fun(op):
+    dyn_vals, old_vals = op
+    for k, v in dyn_vars.items():
+      v._value = dyn_vals[k]
+    with jax.ensure_compile_time_eval():
+      r = cond_fun(*old_vals)
+    return r if isinstance(r, Array) else r
+
+  # TODO: cache mechanism?
+  return lambda operands: jax.lax.while_loop(cond_fun=_cond_fun,
+                                             body_fun=_body_fun,
+                                             init_val=(dyn_vars.dict_data(), operands))
+
+
 def while_loop(
     body_fun: Callable,
     cond_fun: Callable,
     operands: Any,
 
     # deprecated
     dyn_vars: Union[Variable, Sequence[Variable], Dict[str, Variable]] = None,
@@ -821,16 +983,14 @@
 
     .. deprecated:: 2.4.0
        No longer need to provide ``dyn_vars``. This function is capable of automatically
        collecting the dynamical variables used in the target ``func``.
   child_objs: optional, dict, sequence of BrainPyObject, BrainPyObject
     The children objects used in the target function.
 
-    .. versionadded:: 2.3.1
-
     .. deprecated:: 2.4.0
        No longer need to provide ``child_objs``. This function is capable of automatically
        collecting the children objects used in the target ``func``.
 
 
   """
   dynvar_deprecation(dyn_vars)
@@ -839,35 +999,23 @@
   if not isinstance(operands, (list, tuple)):
     operands = (operands,)
 
   if jax.config.jax_disable_jit:
     dyn_vars = VariableStack()
 
   else:
-    dyn_vars = evaluate_dyn_vars(body_fun, *operands)
-    dyn_vars += evaluate_dyn_vars(cond_fun, *operands)
+    dyn_vars = get_stack_cache(body_fun)
 
-  def _body_fun(op):
-    dyn_vals, old_vals = op
-    for k, v in dyn_vars.items():
-      v._value = dyn_vals[k]
-    new_vals = body_fun(*old_vals)
-    if new_vals is None:
-      new_vals = tuple()
-    if not isinstance(new_vals, tuple):
-      new_vals = (new_vals,)
-    return dyn_vars.dict_data(), new_vals
-
-  def _cond_fun(op):
-    dyn_vals, old_vals = op
-    for k, v in dyn_vars.items():
-      v._value = dyn_vals[k]
-    r = cond_fun(*old_vals)
-    return r if isinstance(r, Array) else r
+    if dyn_vars is None:
+      with new_transform('while_loop'):
+        dyn_vars, rets = evaluate_dyn_vars(
+          _get_while_transform(cond_fun, body_fun, VariableStack()),
+          operands
+        )
+        cache_stack(body_fun, dyn_vars)
+      if current_transform_number():
+        return rets[1]
 
-  # TODO: cache mechanism?
-  dyn_values, out = lax.while_loop(cond_fun=_cond_fun,
-                                   body_fun=_body_fun,
-                                   init_val=(dyn_vars.dict_data(), operands))
+  dyn_values, out = _get_while_transform(cond_fun, body_fun, dyn_vars)(operands)
   for k, v in dyn_vars.items():
     v._value = dyn_values[k]
   return out
```

## brainpy/_src/math/object_transform/jit.py

```diff
@@ -7,26 +7,47 @@
 
 """
 
 from functools import partial, wraps
 from typing import Callable, Union, Optional, Sequence, Dict, Any, Iterable
 
 import jax
+from jax._src.sharding_impls import UnspecifiedValue, UNSPECIFIED
+from jax.sharding import Sharding
 
 from brainpy import tools, check
-from ._tools import dynvar_deprecation, node_deprecation, evaluate_dyn_vars, _partial_fun
+from ._tools import (dynvar_deprecation,
+                     node_deprecation,
+                     evaluate_dyn_vars_with_cache,
+                     evaluate_dyn_vars,
+                     _partial_fun)
 from .base import BrainPyObject, ObjectTransform
 from .naming import get_stack_cache, cache_stack
-from .variables import Variable, VariableStack
+from .variables import (Variable,
+                        VariableStack,
+                        outermost_transform,
+                        transform_stack,
+                        current_transform_number,
+                        new_transform)
 
 __all__ = [
   'jit',
 ]
 
 
+def _get_sharding(a):
+  pass
+
+
+def _get_sharding_of_dyn_vars(dyn_vars: dict):
+  leaves, tree = jax.tree_util.tree_flatten(dyn_vars)
+
+
+
+
 def _seq_of_int(static_argnums):
   if static_argnums is None:
     static_argnums = ()
   elif isinstance(static_argnums, int):
     static_argnums = (static_argnums,)
   elif isinstance(static_argnums, (tuple, list)):
     pass
@@ -58,21 +79,20 @@
       donate_argnums: Union[int, Iterable[int]] = (),
       device: Optional[Any] = None,
       inline: bool = False,
       keep_unused: bool = False,
       abstracted_axes: Optional[Any] = None,
       name: Optional[str] = None,
       backend: Optional[str] = None,
+      in_shardings: Union[Sharding, UnspecifiedValue] = UNSPECIFIED,
+      out_shardings: Union[Sharding, UnspecifiedValue] = UNSPECIFIED,
 
       # deprecated
       dyn_vars: Dict[str, Variable] = None,
       child_objs: Dict[str, BrainPyObject] = None,
-
-      # others
-      **kwargs
   ):
     super().__init__(name=name)
 
     # variables and nodes
     if dyn_vars is not None:
       self.register_implicit_vars(dyn_vars)
     if child_objs is not None:
@@ -88,59 +108,79 @@
     self._static_argnums = _seq_of_int(static_argnums)
     self._static_argnames = _seq_of_str(static_argnames)
     self._donate_argnums = donate_argnums
     self._device = device
     self._inline = inline
     self._keep_unused = keep_unused
     self._abstracted_axes = abstracted_axes
-    self._kwargs = kwargs
+    self._in_shardings = in_shardings
+    self._out_shardings = out_shardings
+    # if isinstance(in_shardings, UnspecifiedValue):
+    #   pass
+    # else:
+    #   self._in_shardings = (UNSPECIFIED, in_shardings)
+    # if isinstance(out_shardings, UnspecifiedValue):
+    #   pass
+    # else:
+    #   self._out_shardings = (AUTO, out_shardings)
 
     # transformation function
     self._transform = None
     self._dyn_vars = None
 
   def _transform_function(self, variable_data: Dict, *args, **kwargs):
     for key, v in self._dyn_vars.items():
       v._value = variable_data[key]
     out = self.fun(*args, **kwargs)
     changes = self._dyn_vars.dict_data()
-    return out, changes
+    return changes, out
 
   def __call__(self, *args, **kwargs):
-    if jax.config.jax_disable_jit:
+    if jax.config.jax_disable_jit:  # support to disable JIT for debugging
       return self.fun(*args, **kwargs)
 
-    if self._transform is None:
-      self._dyn_vars = evaluate_dyn_vars(self.fun,
-                                         *args,
-                                         static_argnums=self._static_argnums,
-                                         static_argnames=self._static_argnames,
-                                         **kwargs)
-      self._transform = jax.jit(
-        self._transform_function,
-        static_argnums=jax.tree_util.tree_map(lambda a: a + 1, self._static_argnums),
-        static_argnames=self._static_argnames,
-        donate_argnums=self._donate_argnums,
-        device=self._device,
-        inline=self._inline,
-        keep_unused=self._keep_unused,
-        abstracted_axes=self._abstracted_axes,
-        backend=self._backend,
-        **self._kwargs
-      )
-    out, changes = self._transform(self._dyn_vars.dict_data(), *args, **kwargs)
+    if self._transform is None:  # initialize the transformation
+      with new_transform(self):
+        self._dyn_vars, rets = evaluate_dyn_vars(
+          self.fun,
+          *args,
+          static_argnums=self._static_argnums,
+          static_argnames=self._static_argnames,
+          use_eval_shape=current_transform_number() <= 1,
+          **kwargs
+        )
+        self._transform = jax.jit(
+          self._transform_function,
+          static_argnums=jax.tree_util.tree_map(lambda a: a + 1, self._static_argnums),
+          static_argnames=self._static_argnames,
+          donate_argnums=self._donate_argnums,
+          device=self._device,
+          inline=self._inline,
+          keep_unused=self._keep_unused,
+          abstracted_axes=self._abstracted_axes,
+          backend=self._backend,
+          in_shardings=self._in_shardings,
+          out_shardings=self._out_shardings,
+        )
+
+      # if not the outermost transformation
+      if current_transform_number():
+        return rets
+
+    # call the transformed function
+    changes, out = self._transform(self._dyn_vars.dict_data(), *args, **kwargs)
     for key, v in self._dyn_vars.items():
       v._value = changes[key]
     return out
 
   def __repr__(self):
     name = self.__class__.__name__
     f = tools.repr_object(self.fun)
     f = tools.repr_context(f, " " * (len(name) + 6))
-    format_ref = (f'{name}(target={f}, \n' +
+    format_ref = (f'{name}(name={self.name}, target={f}, \n' +
                   f'{" " * len(name)} num_of_vars={len(self.vars().unique())})')
     return format_ref
 
 
 _jit_par = '''
   func : BrainPyObject, function, callable
     The instance of Base or a function.
@@ -196,15 +236,14 @@
     donate_argnums: Union[int, Sequence[int]] = (),
     device: Optional[Any] = None,
     inline: bool = False,
     keep_unused: bool = False,
     backend: Optional[str] = None,
     abstracted_axes: Optional[Any] = None,
 
-
     # deprecated
     dyn_vars: Optional[Union[Variable, Sequence[Variable], Dict[str, Variable]]] = None,
     child_objs: Optional[Union[BrainPyObject, Sequence[BrainPyObject], Dict[str, BrainPyObject]]] = None,
 
     # others
     **kwargs,
 ) -> JITTransform:
@@ -247,16 +286,14 @@
 
     .. deprecated:: 2.4.0
        No longer need to provide ``dyn_vars``. This function is capable of automatically
        collecting the dynamical variables used in the target ``func``.
   child_objs: optional, dict, sequence of BrainPyObject, BrainPyObject
     The children objects used in the target function.
 
-    .. versionadded:: 2.3.1
-
     .. deprecated:: 2.4.0
        No longer need to provide ``child_objs``. This function is capable of automatically
        collecting the children objects used in the target ``func``.
 
   Returns
   -------
   func : JITTransform
@@ -418,15 +455,14 @@
       v._value = changes[key]
     return out
 
   return call_fun
 
 
 def _make_transform(fun, stack):
-
   @wraps(fun)
   def _transform_function(variable_data: dict, *args, **kwargs):
     for key, v in stack.items():
       v._value = variable_data[key]
     out = fun(*args, **kwargs)
     changes = stack.dict_data()
     return out, changes
```

## brainpy/_src/math/object_transform/variables.py

```diff
@@ -1,105 +1,155 @@
-from typing import Optional, Any, List
+from typing import Optional, Any, List, Callable, Sequence
 
+from contextlib import contextmanager
 import jax
 import numpy as np
 from jax import numpy as jnp
 from jax.dtypes import canonicalize_dtype
 from jax.tree_util import register_pytree_node_class
 
+from brainpy._src.math.sharding import BATCH_AXIS
 from brainpy._src.math.ndarray import Array
 from brainpy.errors import MathError
 
 __all__ = [
   'Variable',
   'TrainVar',
   'Parameter',
   'VariableView',
 
-  'VarList',
-  'VarDict',
+  'VarList', 'var_list',
+  'VarDict', 'var_dict',
 ]
 
 
 class VariableStack(dict):
+  """Variable stack, for collecting all :py:class:`~.Variable` used in the program.
+
+  :py:class:`~.VariableStack` supports all features of python dict.
+  """
+
   def __init__(self, *args, **kwargs):
     super().__init__(*args, **kwargs)
     self._values = dict()
 
   def add(self, var: 'Variable'):
-    assert isinstance(var, Variable)
+    """Add a new :py:class:`~.Variable`."""
+    assert isinstance(var, Variable), f'must be instance of {Variable}'
     id_ = id(var)
     if id_ not in self:
       self[id_] = var
       self._values[id_] = var._value
 
-  def recollect_values(self):
+  def collect_values(self):
     """Collect the value of each variable once again."""
     for id_, var in self.items():
       self._values[id_] = var._value
 
-  def reassign_values(self):
-    """Assign the old value for each variable."""
+  def assign_org_values(self):
+    """Assign the original value for each variable."""
     for id_, var in self.items():
       if id_ in self._values:
         var._value = self._values[id_]
 
   def instance_of(self, cls: type) -> 'VariableStack':
+    """Collect all variables which are instances of the given class type."""
     new_dict = type(self)()
     for id_, elem in self.items():
       if isinstance(elem, cls):
         new_dict[id_] = elem
     return new_dict
 
   def not_instance_of(self, cls: type) -> 'VariableStack':
+    """Collect all variables which are not instance of the given class type."""
     new_dict = type(self)()
     for id_, elem in self.items():
       if not isinstance(elem, cls):
         new_dict[id_] = elem
     return new_dict
 
   def dict_data(self) -> dict:
+    """Get all data in the collected variables with a python dict structure."""
     new_dict = dict()
     for id_, elem in tuple(self.items()):
       new_dict[id_] = elem.value if isinstance(elem, Array) else elem
     return new_dict
 
   def list_data(self) -> list:
+    """Get all data in the collected variables with a python list structure."""
     new_list = list()
     for elem in tuple(self.values()):
       new_list.append(elem.value if isinstance(elem, Array) else elem)
     return new_list
 
   def remove_var_by_id(self, *ids, error_when_absent=False):
-    for id_ in ids:
-      if error_when_absent:
+    """Remove variables in the stack by the given ids."""
+    if error_when_absent:
+      for id_ in ids:
         self.pop(id_)
-      else:
+    else:
+      for id_ in ids:
         self.pop(id_, None)
 
   def __enter__(self) -> 'VariableStack':
-    self.recollect_values()  # recollect the original value of each variable
+    self.collect_values()  # recollect the original value of each variable
     var_stack_list.append(self)
     return self
 
   def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
     var_stack_list.pop()
-    self.reassign_values()  # reassign the original value for each variable
+    self.assign_org_values()  # reassign the original value for each variable
     self._values.clear()
 
   def __add__(self, other: dict):
     new_dict = VariableStack(self)
     new_dict.update(other)
     new_dict._values.update(self._values)
     if isinstance(other, VariableStack):
       new_dict._values.update(other._values)
     return new_dict
 
 
 var_stack_list: List[VariableStack] = []
+transform_stack: List[Callable] = []
+
+
+@contextmanager
+def new_transform(transform: Any):
+  transform_stack.append(transform)
+  try:
+    yield
+  finally:
+    transform_stack.pop()
+
+
+def outermost_stack():
+  if len(var_stack_list):
+    return var_stack_list[0]
+  else:
+    return None
+
+
+def outermost_transform():
+  if len(transform_stack):
+    return transform_stack[0]
+  else:
+    return None
+
+
+def current_transform_number():
+  return len(transform_stack)
+
+
+def _stack_add_read(var: 'Variable'):
+  pass
+
+
+def _stack_add_write(var: 'Variable'):
+  pass
 
 
 @register_pytree_node_class
 class Variable(Array):
   """The pointer to specify the dynamical variable.
 
   Initializing an instance of ``Variable`` by two ways:
@@ -119,22 +169,23 @@
     The value or the size of the value.
   dtype:
     The type of the data.
   batch_axis: optional, int
     The batch axis.
   """
 
-  __slots__ = ('_value', '_batch_axis', '_ready_to_trace')
+  __slots__ = ('_value', '_batch_axis', '_ready_to_trace', 'axis_names')
 
   def __init__(
       self,
       value_or_size: Any,
       dtype: type = None,
       batch_axis: int = None,
       *,
+      axis_names: Optional[Sequence[str]] = None,
       _ready_to_trace: bool = True
   ):
     if isinstance(value_or_size, int):
       value = jnp.zeros(value_or_size, dtype=dtype)
     elif isinstance(value_or_size, (tuple, list)) and all([isinstance(s, int) for s in value_or_size]):
       value = jnp.zeros(value_or_size, dtype=dtype)
     else:
@@ -155,14 +206,29 @@
     if batch_axis is not None:
       if batch_axis >= np.ndim(self._value):
         raise MathError(f'This variables has {np.ndim(self._value)} dimension, '
                         f'but the batch axis is set to be {batch_axis}.')
 
     # ready to trace the variable
     self._ready_to_trace = _ready_to_trace and len(var_stack_list) == 0
+    if axis_names is not None:
+      if len(axis_names) + 1 == self.ndim:
+        axis_names = list(axis_names)
+        axis_names.insert(self.batch_axis, BATCH_AXIS)
+      assert len(axis_names) == self.ndim
+      axis_names = tuple(axis_names)
+    self.axis_names = axis_names
+
+  @property
+  def size_without_batch(self):
+    if self.batch_axis is None:
+      return self.size
+    else:
+      sizes = self.size
+      return sizes[:self.batch_size] + sizes[self.batch_axis + 1:]
 
   @property
   def batch_axis(self) -> Optional[int]:
     return self._batch_axis
 
   @batch_axis.setter
   def batch_axis(self, val):
@@ -209,14 +275,20 @@
       for stack in var_stack_list:
         stack.add(self)
 
   @classmethod
   def tree_unflatten(cls, aux_data, flat_contents):
     return cls(*flat_contents, _ready_to_trace=False)
 
+  def clone(self) -> 'Variable':
+    """Clone the variable. """
+    r = type(self)(jnp.copy(self.value), batch_axis=self.batch_axis)
+    r._ready_to_trace = self._ready_to_trace
+    return r
+
 
 def _get_dtype(v):
   if hasattr(v, 'dtype'):
     dtype = v.dtype
   else:
     dtype = canonicalize_dtype(type(v))
   return dtype
@@ -233,42 +305,46 @@
 
   def __init__(
       self,
       value_or_size: Any,
       dtype: type = None,
       batch_axis: int = None,
       *,
+      axis_names: Optional[Sequence[str]] = None,
       _ready_to_trace: bool = True
   ):
     super(TrainVar, self).__init__(
       value_or_size,
       dtype=dtype,
       batch_axis=batch_axis,
-      _ready_to_trace=_ready_to_trace
+      _ready_to_trace=_ready_to_trace,
+      axis_names=axis_names,
     )
 
 
 @register_pytree_node_class
 class Parameter(Variable):
   """The pointer to specify the parameter.
   """
 
   def __init__(
       self,
       value_or_size: Any,
       dtype: type = None,
       batch_axis: int = None,
       *,
+      axis_names: Optional[Sequence[str]] = None,
       _ready_to_trace: bool = True
   ):
     super(Parameter, self).__init__(
       value_or_size,
       dtype=dtype,
       batch_axis=batch_axis,
-      _ready_to_trace=_ready_to_trace
+      _ready_to_trace=_ready_to_trace,
+      axis_names=axis_names,
     )
 
 
 class VariableView(Variable):
   """A view of a Variable instance.
 
   This class is used to create a subset view of ``brainpy.math.Variable``.
@@ -344,17 +420,21 @@
       raise MathError(error)
     if v.dtype != self._value.dtype:
       raise MathError(f"The dtype of the original data is {self._value.dtype}, "
                       f"while we got {v.dtype}.")
     self._value[self.index] = v.value if isinstance(v, Array) else v
 
 
+@register_pytree_node_class
 class VarList(list):
   """A sequence of :py:class:`~.Variable`, which is compatible with
   :py:func:`.vars()` operation in a :py:class:`~.BrainPyObject`.
+
+  Actually, :py:class:`~.VarList` is a python list.
+
   """
 
   def __init__(self, seq=()):
     super().__init__()
     self.extend(seq)
 
   def append(self, element) -> 'VarList':
@@ -371,19 +451,32 @@
   def __setitem__(self, key, value) -> 'VarList':
     if isinstance(key, int):
       self[key].value = value
     else:
       super().__setitem__(key, value)
     return self
 
+  def tree_flatten(self):
+    return tuple(self), None
+
+  @classmethod
+  def tree_unflatten(cls, aux_data, children):
+    return cls(children)
 
+
+var_list = VarList
+
+
+@register_pytree_node_class
 class VarDict(dict):
   """A dictionary of :py:class:`~.Variable`, which is compatible with
   :py:func:`.vars()` operation in a :py:class:`~.BrainPyObject`.
 
+  Actually, :py:class:`~.VarDict` is a python dict.
+
   """
 
   def _check_elem(self, elem):
     if not isinstance(elem, Variable):
       raise TypeError(f'Element should be {Variable.__name__}, but got {type(elem)}.')
     return elem
 
@@ -406,7 +499,16 @@
   def __setitem__(self, key, value) -> 'VarDict':
     if key in self:
       self[key].value = value
     else:
       super().__setitem__(key, self._check_elem(value))
     return self
 
+  def tree_flatten(self):
+    return tuple(self.values()), tuple(self.keys())
+
+  @classmethod
+  def tree_unflatten(cls, keys, values):
+    return cls(jax.util.safe_zip(keys, values))
+
+
+var_dict = VarDict
```

## brainpy/_src/math/op_registers/numba_approach/__init__.py

```diff
@@ -105,15 +105,14 @@
                     args, is_leaf=lambda a: isinstance(a, Array))
     kwargs = tree_map(lambda a: a.value if isinstance(a, Array) else a,
                       kwargs, is_leaf=lambda a: isinstance(a, Array))
     res = self.op.bind(*args, **kwargs)
     return res
 
 
-
 def register_op_with_numba(
     op_name: str,
     cpu_func: Callable,
     out_shapes: Union[Callable, ShapedArray, Sequence[ShapedArray]],
     gpu_func_translation: Callable = None,
     batching_translation: Callable = None,
     jvp_translation: Callable = None,
```

## brainpy/_src/math/sparse/__init__.py

```diff
@@ -1,7 +1,9 @@
 
 from ._coo_mv import *
 from ._csr_mv import *
 from ._utils import *
 from ._bsr_mv import *
 from ._bsr_mm import *
+from ._jax_prim import *
+
```

## brainpy/_src/math/sparse/_bsr_mm.py

```diff
@@ -312,56 +312,55 @@
       ke = ki + block_size_k
       bi = B_indices[i, 1]
       C_tmp += np.matmul(B_data[bi], A_data[:, ks: ke].T)
     res_val[ns: ne] = C_tmp
   return res_val
 
 
-def _bcsrmm_abstract(
+def _bcsrmm_cutlass_abstract(
     A_data, B_data, B_indices, B_ptr, *, m, k, n, block_size_k, block_size_n
 ):
+  assert block_size_k == 32, 'cutlass based block-sparse mm only support block size (32, 32)'
+  assert block_size_n == 32, 'cutlass based block-sparse mm only support block size (32, 32)'
   assert B_indices.shape[0] * block_size_n == B_data.shape[0]
   assert block_size_k == B_data.shape[1]
   assert A_data.shape[0] == m
   assert A_data.shape[1] == k
   assert A_data.dtype == B_data.dtype
   assert n // block_size_n + 1 == B_ptr.shape[0]
   return [ShapedArray(dtype=A_data.dtype, shape=(n, m))]
 
 
-def _bcsrmm_cpu_translation(
+def _bcsrmm_cutlass_cpu_translation(
     c, A_data, B_data, B_indices, B_ptr, *,
     m, k, n, block_size_k, block_size_n
 ):
   inputs = (A_data, B_ptr, B_indices, B_data)
   description = dict(m=m,
                      n=n,
                      k=k,
                      block_size_k=block_size_k,
                      block_size_n=block_size_n)
   name, inputs, in_layouts, out_layouts = compile_cpu_signature_with_numba(
     c,
     _bcsrmm_cutlass_imp2,
-    abs_eval_fn=_bcsrmm_abstract,
+    abs_eval_fn=_bcsrmm_cutlass_abstract,
     multiple_results=True,
     inputs=inputs,
     description=description
   )
   return xla_client.ops.CustomCallWithLayout(
     c, name,
     operands=inputs,
     operand_shapes_with_layout=in_layouts,
     shape_with_layout=out_layouts,
   )
 
 
-def _bcsrmm_gpu_translation(
-    c, A_data, B_data, B_indices, B_ptr, *,
-    m, k, n, block_size_k, block_size_n
-):
+def _bcsrmm_cutlass_gpu_translation(c, A_data, B_data, B_indices, B_ptr, *, m, k, n, block_size_k, block_size_n):
   if gpu_ops is None:
     raise GPUOperatorNotFound(_bcsrmm_cutlass_p.name)
 
   matrix_info = c.get_shape(A_data)
   dtype = matrix_info.element_type()
 
   opaque = gpu_ops.build_blocksparse_format_descriptor(m,
@@ -383,39 +382,39 @@
     shape_with_layout=xla_client.Shape.tuple_shape(
       (xla_client.Shape.array_shape(dtype, (n, m), (1, 0)),)
     ),
     opaque=opaque
   )
 
 
-def _bcsrmm_jvp_dense_a(dense_a_dot, A_data, B_ptr, B_indices, B_data, *, m, n, k, block_size_k,
-                        block_size_n):
+def _bcsrmm_cutlass_jvp_dense_a(dense_a_dot, A_data, B_ptr, B_indices, B_data, *, m, n, k, block_size_k,
+                                block_size_n):
   return bcsrmm(dense_a_dot, B_ptr, B_indices, B_data, m=m, n=n, k=k, block_size_k=block_size_k,
                 block_size_n=block_size_n)
 
 
-def _bcsrmm_jvp_data_b(data_b_dot, A_data, B_ptr, B_indices, B_data, *, m, n, k, block_size_k,
-                       block_size_n):
+def _bcsrmm_cutlass_jvp_data_b(data_b_dot, A_data, B_ptr, B_indices, B_data, *, m, n, k, block_size_k,
+                               block_size_n):
   return bcsrmm(A_data, B_ptr, B_indices, data_b_dot, m=m, n=n, k=k, block_size_k=block_size_k,
                 block_size_n=block_size_n)
 
 
-def _bcsrmm_jvp_transpose():
+def _bcsrmm_cutlass_jvp_transpose():
   # TODO: implement
   pass
 
 
 _bcsrmm_cutlass_p = Primitive('bcsrmm_cutlass_pim')
 _bcsrmm_cutlass_p.multiple_results = True
-_bcsrmm_cutlass_p.def_abstract_eval(_bcsrmm_abstract)
+_bcsrmm_cutlass_p.def_abstract_eval(_bcsrmm_cutlass_abstract)
 _bcsrmm_cutlass_p.def_impl(partial(xla.apply_primitive, _bcsrmm_cutlass_p))
-xla.backend_specific_translations['cpu'][_bcsrmm_cutlass_p] = _bcsrmm_cpu_translation
-xla.backend_specific_translations['gpu'][_bcsrmm_cutlass_p] = _bcsrmm_gpu_translation
-ad.primitive_jvps[_bcsrmm_cutlass_p] = _bcsrmm_jvp_transpose
-ad.primitive_transposes[_bcsrmm_cutlass_p] = _bcsrmm_jvp_transpose
+xla.backend_specific_translations['cpu'][_bcsrmm_cutlass_p] = _bcsrmm_cutlass_cpu_translation
+xla.backend_specific_translations['gpu'][_bcsrmm_cutlass_p] = _bcsrmm_cutlass_gpu_translation
+ad.primitive_jvps[_bcsrmm_cutlass_p] = _bcsrmm_cutlass_jvp_transpose
+ad.primitive_transposes[_bcsrmm_cutlass_p] = _bcsrmm_cutlass_jvp_transpose
 register_general_batching(bcsrmm)
 
 
 def _blocksparse_matmat_back_abstract(
     A_data, B_data, blocks, *, m, n, k, transpose, block_size_k, block_size_n, blocks_len
 ):
   shape = (n, k)
```

## brainpy/_src/math/surrogate/__init__.py

```diff
@@ -1,5 +1,6 @@
 # -*- coding: utf-8 -*-
 
 
+from .base import *
 from ._one_input import *
 from ._two_inputs import *
```

## brainpy/_src/math/surrogate/_one_input.py

```diff
@@ -3,14 +3,16 @@
 
 from typing import Union
 
 import jax
 import jax.numpy as jnp
 import jax.scipy as sci
 
+from .base import Surrogate
+
 from brainpy._src.math.interoperability import as_jax
 from brainpy._src.math.ndarray import Array
 from ._utils import vjp_custom
 
 __all__ = [
   'sigmoid',
   'piecewise_quadratic',
@@ -29,22 +31,25 @@
   'gaussian_grad',
   'inv_square_grad',
   'multi_gaussian_grad',
   'slayer_grad',
 ]
 
 
-class Sigmoid:
+class Sigmoid(Surrogate):
   def __init__(self, alpha=4., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return sigmoid(x, alpha=self.alpha, origin=self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=4., origin=False), dict(origin=[True, False]))
 def sigmoid(
     x: Union[jax.Array, Array],
     alpha: float = None,
     origin: bool = None,
 ):
@@ -108,22 +113,25 @@
     sgax = sci.special.expit(x * alpha)
     dx = as_jax(dz) * (1. - sgax) * sgax * alpha
     return dx, None
 
   return z, grad
 
 
-class PiecewiseQuadratic:
+class PiecewiseQuadratic(Surrogate):
   def __init__(self, alpha=1., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return piecewise_quadratic(x, alpha=self.alpha, origin=self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=1., origin=False), dict(origin=[True, False]))
 def piecewise_quadratic(
     x: Union[jax.Array, Array],
     alpha: float,
     origin: bool
 ):
@@ -207,22 +215,25 @@
   def grad(dz):
     dx = jnp.where(jnp.abs(x) > 1 / alpha, 0., dz * (-(alpha * x) ** 2 + alpha))
     return dx, None
 
   return z, grad
 
 
-class PiecewiseExp:
+class PiecewiseExp(Surrogate):
   def __init__(self, alpha=1., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return piecewise_exp(x, alpha=self.alpha, origin=self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=1., origin=False), dict(origin=[True, False]))
 def piecewise_exp(
     x: Union[jax.Array, Array],
     alpha: float,
     origin: bool
 ):
@@ -292,22 +303,25 @@
   def grad(dz):
     dx = (alpha / 2) * jnp.exp(-alpha * jnp.abs(x))
     return dx * as_jax(dz), None
 
   return z, grad
 
 
-class SoftSign:
+class SoftSign(Surrogate):
   def __init__(self, alpha=1., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return soft_sign(x, alpha=self.alpha, origin=self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=1., origin=False), dict(origin=[True, False]))
 def soft_sign(
     x: Union[jax.Array, Array],
     alpha: float,
     origin: bool
 ):
@@ -372,22 +386,25 @@
   def grad(dz):
     dx = alpha * 0.5 / (1 + jnp.abs(alpha * x)) ** 2
     return dx * as_jax(dz), None
 
   return z, grad
 
 
-class Arctan:
+class Arctan(Surrogate):
   def __init__(self, alpha=1., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return arctan(x, alpha=self.alpha, origin=self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=1., origin=False), dict(origin=[True, False]))
 def arctan(
     x: Union[jax.Array, Array],
     alpha: float,
     origin: bool
 ):
@@ -451,22 +468,25 @@
   def grad(dz):
     dx = alpha * 0.5 / (1 + (jnp.pi / 2 * alpha * x) ** 2)
     return dx * as_jax(dz), None
 
   return z, grad
 
 
-class NonzeroSignLog:
+class NonzeroSignLog(Surrogate):
   def __init__(self, alpha=1., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return nonzero_sign_log(x, alpha=self.alpha, origin=self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=1., origin=False), statics={'origin': [True, False]})
 def nonzero_sign_log(
     x: Union[jax.Array, Array],
     alpha: float,
     origin: bool
 ):
@@ -543,22 +563,25 @@
   def grad(dz):
     dx = as_jax(dz) / (1 / alpha + jnp.abs(x))
     return dx, None
 
   return z, grad
 
 
-class ERF:
+class ERF(Surrogate):
   def __init__(self, alpha=1., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return erf(x, alpha=self.alpha, origin=self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=1., origin=False), statics={'origin': [True, False]})
 def erf(
     x: Union[jax.Array, Array],
     alpha: float,
     origin: bool
 ):
@@ -632,23 +655,26 @@
   def grad(dz):
     dx = (alpha / jnp.sqrt(jnp.pi)) * jnp.exp(-jnp.power(alpha, 2) * x * x)
     return dx * as_jax(dz), None
 
   return z, grad
 
 
-class PiecewiseLeakyRelu:
+class PiecewiseLeakyRelu(Surrogate):
   def __init__(self, c=0.01, w=1., origin=False):
     self.c = c
     self.w = w
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return piecewise_leaky_relu(x, c=self.c, w=self.w, origin=self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(c={self.c}, w={self.w})'
+
 
 @vjp_custom(['x'], dict(c=0.01, w=1., origin=False), statics={'origin': [True, False]})
 def piecewise_leaky_relu(
     x: Union[jax.Array, Array],
     c: float,
     w: float,
     origin: bool
@@ -740,23 +766,26 @@
   def grad(dz):
     dx = jnp.where(jnp.abs(x) > w, c, 1 / w)
     return dx * as_jax(dz), None, None
 
   return z, grad
 
 
-class SquarewaveFourierSeries:
+class SquarewaveFourierSeries(Surrogate):
   def __init__(self, n=2, t_period=8., origin=False):
     self.n = n
     self.t_period = t_period
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return squarewave_fourier_series(x, self.n, self.t_period, self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(n={self.n}, t_period={self.t_period})'
+
 
 @vjp_custom(['x'], dict(n=2, t_period=8., origin=False), statics={'origin': [True, False]})
 def squarewave_fourier_series(
     x: Union[jax.Array, Array],
     n: int,
     t_period: float,
     origin: bool
@@ -829,24 +858,27 @@
       dx += jnp.cos((2 * i - 1.) * w * x)
     dx *= 4. / t_period
     return dx * as_jax(dz), None, None
 
   return z, grad
 
 
-class S2NN:
+class S2NN(Surrogate):
   def __init__(self, alpha=4., beta=1., epsilon=1e-8, origin=False):
     self.alpha = alpha
     self.beta = beta
     self.epsilon = epsilon
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array], ):
     return s2nn(x, self.alpha, self.beta, self.epsilon, self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha}, beta={self.beta}, epsilon={self.epsilon})'
+
 
 @vjp_custom(['x'],
             defaults=dict(alpha=4., beta=1., epsilon=1e-8, origin=False),
             statics={'origin': [True, False]})
 def s2nn(
     x: Union[jax.Array, Array],
     alpha: float,
@@ -932,22 +964,25 @@
     sg = sci.special.expit(alpha * x)
     dx = jnp.where(x < 0., alpha * sg * (1. - sg), beta / (x + 1.))
     return dx * as_jax(dz), None, None, None
 
   return z, grad
 
 
-class QPseudoSpike:
+class QPseudoSpike(Surrogate):
   def __init__(self, alpha=2., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return q_pseudo_spike(x, self.alpha, self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'],
             dict(alpha=2., origin=False),
             statics={'origin': [True, False]})
 def q_pseudo_spike(
     x: Union[jax.Array, Array],
     alpha: float,
@@ -1022,23 +1057,26 @@
   def grad(dz):
     dx = jnp.power(1 + 2 / (alpha + 1) * jnp.abs(x), -alpha)
     return dx * as_jax(dz), None
 
   return z, grad
 
 
-class LeakyRelu:
+class LeakyRelu(Surrogate):
   def __init__(self, alpha=0.1, beta=1., origin=False):
     self.alpha = alpha
     self.beta = beta
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return leaky_relu(x, self.alpha, self.beta, self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha}, beta={self.beta})'
+
 
 @vjp_custom(['x'],
             dict(alpha=0.1, beta=1., origin=False),
             statics={'origin': [True, False]})
 def leaky_relu(
     x: Union[jax.Array, Array],
     alpha: float,
@@ -1113,22 +1151,25 @@
   def grad(dz):
     dx = jnp.where(x < 0., alpha, beta)
     return dx * as_jax(dz), None, None
 
   return z, grad
 
 
-class LogTailedRelu:
+class LogTailedRelu(Surrogate):
   def __init__(self, alpha=0., origin=False):
     self.alpha = alpha
     self.origin = origin
 
   def __call__(self, x: Union[jax.Array, Array]):
     return log_tailed_relu(x, self.alpha, self.origin)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'],
             dict(alpha=0., origin=False),
             statics={'origin': [True, False]})
 def log_tailed_relu(
     x: Union[jax.Array, Array],
     alpha: float,
@@ -1214,22 +1255,25 @@
                              1.,
                              alpha))
     return dx * as_jax(dz), None
 
   return z, grad
 
 
-class ReluGrad:
+class ReluGrad(Surrogate):
   def __init__(self, alpha=0.3, width=1.):
     self.alpha = alpha
     self.width = width
 
   def __call__(self, x: Union[jax.Array, Array]):
     return relu_grad(x, self.alpha, self.width)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha}, width={self.width})'
+
 
 @vjp_custom(['x'], dict(alpha=0.3, width=1.))
 def relu_grad(
     x: Union[jax.Array, Array],
     alpha: float,
     width: float,
 ):
@@ -1288,22 +1332,25 @@
   def grad(dz):
     dx = jnp.maximum(alpha * width - jnp.abs(x) * alpha, 0)
     return dx * as_jax(dz), None, None
 
   return z, grad
 
 
-class GaussianGrad:
+class GaussianGrad(Surrogate):
   def __init__(self, sigma=0.5, alpha=0.5):
     self.sigma = sigma
     self.alpha = alpha
 
   def __call__(self, x: Union[jax.Array, Array]):
     return gaussian_grad(x, self.sigma, self.alpha)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha}, sigma={self.sigma})'
+
 
 @vjp_custom(['x'], dict(sigma=0.5, alpha=0.5))
 def gaussian_grad(
     x: Union[jax.Array, Array],
     sigma: float,
     alpha: float,
 ):
@@ -1361,24 +1408,27 @@
   def grad(dz):
     dx = jnp.exp(-(x ** 2) / 2 * jnp.power(sigma, 2)) / (jnp.sqrt(2 * jnp.pi) * sigma)
     return alpha * dx * as_jax(dz), None, None
 
   return z, grad
 
 
-class MultiGaussianGrad:
+class MultiGaussianGrad(Surrogate):
   def __init__(self, h=0.15, s=6.0, sigma=0.5, scale=0.5):
     self.h = h
     self.s = s
     self.sigma = sigma
     self.scale = scale
 
   def __call__(self, x: Union[jax.Array, Array]):
     return multi_gaussian_grad(x, self.h, self.s, self.sigma, self.scale)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(h={self.h}, s={self.s}, sigma={self.sigma}, scale={self.scale})'
+
 
 @vjp_custom(['x'], dict(h=0.15, s=6.0, sigma=0.5, scale=0.5))
 def multi_gaussian_grad(
     x: Union[jax.Array, Array],
     h: float,
     s: float,
     sigma: float,
@@ -1448,21 +1498,24 @@
     g3 = jnp.exp(-(x + sigma) ** 2 / (2 * jnp.power(s * sigma, 2))) / (jnp.sqrt(2 * jnp.pi) * s * sigma)
     dx = g1 * (1. + h) - g2 * h - g3 * h
     return scale * dx * as_jax(dz), None, None, None, None
 
   return z, grad
 
 
-class InvSquareGrad:
+class InvSquareGrad(Surrogate):
   def __init__(self, alpha=100.):
     self.alpha = alpha
 
   def __call__(self, x: Union[jax.Array, Array]):
     return inv_square_grad(x, self.alpha)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=100.))
 def inv_square_grad(
     x: Union[jax.Array, Array],
     alpha: float
 ):
   r"""Spike function with the inverse-square surrogate gradient.
@@ -1513,21 +1566,24 @@
   def grad(dz):
     dx = as_jax(dz) / (alpha * jnp.abs(x) + 1.0) ** 2
     return dx, None
 
   return z, grad
 
 
-class SlayerGrad:
+class SlayerGrad(Surrogate):
   def __init__(self, alpha=1.):
     self.alpha = alpha
 
   def __call__(self, x: Union[jax.Array, Array]):
     return slayer_grad(x, self.alpha)
 
+  def __repr__(self):
+    return f'{self.__class__.__name__}(alpha={self.alpha})'
+
 
 @vjp_custom(['x'], dict(alpha=1.))
 def slayer_grad(
     x: Union[jax.Array, Array],
     alpha: float
 ):
   r"""Spike function with the slayer surrogate gradient function.
```

## brainpy/_src/tools/__init__.py

```diff
@@ -2,7 +2,8 @@
 
 from .codes import *
 from .others import *
 from .dicts import *
 from .others import *
 from .package import *
 from .math_util import *
+from .install import *
```

## brainpy/_src/tools/codes.py

```diff
@@ -4,14 +4,15 @@
 import re
 from types import LambdaType
 
 BrainPyObject = None
 
 
 __all__ = [
+  'repr_dict',
   'repr_object',
   'repr_context',
   'copy_doc',
   'code_lines_to_func',
 
   # tools for code string
   'get_identifiers',
@@ -23,14 +24,19 @@
   'is_lambda_function',
   'get_main_code',
   'get_func_source',
   'change_func_name',
 ]
 
 
+def repr_dict(dict_obj: dict):
+  ret = [f'{k}={v}' for k, v in dict_obj.items()]
+  return ', '.join(ret)
+
+
 def repr_object(x):
   global BrainPyObject
   if BrainPyObject is None:
     from brainpy.math import BrainPyObject
   if isinstance(x, BrainPyObject):
     return repr(x)
   elif callable(x):
```

## brainpy/_src/tools/others.py

```diff
@@ -17,15 +17,15 @@
   'to_size',
   'size2num',
   'timeout',
   'init_progress_bar',
 ]
 
 
-def one_of(default: Any, *choices, names: Sequence[str] =None):
+def one_of(default: Any, *choices, names: Sequence[str] = None):
   names = [f'arg{i}' for i in range(len(choices))] if names is None else names
   res = default
   has_chosen = False
   for c in choices:
     if c is not None:
       if has_chosen:
         raise ValueError(f'Provide one of {names}, but we got {list(zip(choices, names))}')
@@ -86,15 +86,15 @@
     raise ValueError(f'Do not support type {type(size)}: {size}')
 
 
 def to_size(x) -> Optional[Tuple[int]]:
   if isinstance(x, (tuple, list)):
     return tuple(x)
   if isinstance(x, (int, np.integer)):
-    return (x, )
+    return (x,)
   if x is None:
     return x
   raise ValueError(f'Cannot make a size for {x}')
 
 
 def timeout(s):
   """Add a timeout parameter to a function and return it.
@@ -179,7 +179,8 @@
     )
 
   def _progress_bar(iter_num):
     _update_progress_bar(iter_num)
     close_tqdm(iter_num)
 
   return _progress_bar
+
```

## brainpy/_src/train/__init__.py

```diff
@@ -18,12 +18,8 @@
 - reservoir computing networks,
 - artificial recurrent neural networks,
 - spiking neural networks,
 - and others.
 """
 
 
-from .base import *
-from .back_propagation import *
-from .online import *
-from .offline import *
```

## brainpy/_src/train/base.py

```diff
@@ -1,14 +1,14 @@
 # -*- coding: utf-8 -*-
 
 from typing import Dict, Sequence, Any, Union, Optional
 
 import brainpy.math as bm
 from brainpy._src.dynsys import DynamicalSystem
-from brainpy._src.dyn.runners import DSRunner
+from brainpy._src.runners import DSRunner
 from brainpy._src.running import constants as c
 from brainpy.errors import NoLongerSupportError
 from brainpy.types import ArrayType, Output
 
 __all__ = [
   'DSTrainer',
 ]
```

## brainpy/math/__init__.py

```diff
@@ -1,10 +1,9 @@
 # -*- coding: utf-8 -*-
 
-
 # data structure
 from .ndarray import *
 from .delayvars import *
 from .interoperability import *
 from .datatypes import *
 from .compat_numpy import *
 from .compat_tensorflow import *
@@ -30,14 +29,16 @@
 
 # high-level numpy operations
 from . import fft
 from . import linalg
 from . import random
 
 # others
+from . import sharding
+
 import jax.numpy as jnp
 from jax import config
 
 mode = NonBatchingMode()
 '''Default computation mode.'''
 
 dt = 0.1
@@ -53,14 +54,62 @@
 '''Default float data type.'''
 
 complex_ = jnp.complex128 if config.read('jax_enable_x64') else jnp.complex64
 '''Default complex data type.'''
 
 del jnp, config
 
-
 from brainpy._src.math.surrogate._compt import (
   spike_with_sigmoid_grad as spike_with_sigmoid_grad,
   spike_with_linear_grad as spike_with_linear_grad,
   spike_with_gaussian_grad as spike_with_gaussian_grad,
   spike_with_mg_grad as spike_with_mg_grad,
 )
+
+from brainpy._src.deprecations import deprecation_getattr
+__deprecations = {
+  "sparse_matmul": ("brainpy.math.sparse_matmul is deprecated. Use brainpy.math.sparse.seg_matmul instead.",
+                    sparse.seg_matmul),
+  'csr_matvec': ("brainpy.math.csr_matvec is deprecated. Use brainpy.math.sparse.csrmv instead.",
+                 sparse.csrmv),
+  'event_matvec_prob_conn_homo_weight': ("brainpy.math.event_matvec_prob_conn_homo_weight is deprecated. "
+                                         "Use brainpy.math.jitconn.event_mv_prob_homo instead.",
+                                         jitconn.event_mv_prob_homo),
+  'event_matvec_prob_conn_uniform_weight': ("brainpy.math.event_matvec_prob_conn_uniform_weight is deprecated. "
+                                            "Use brainpy.math.jitconn.event_mv_prob_uniform instead.",
+                                            jitconn.event_mv_prob_uniform),
+  'event_matvec_prob_conn_normal_weight': ("brainpy.math.event_matvec_prob_conn_normal_weight is deprecated. "
+                                           "Use brainpy.math.jitconn.event_mv_prob_normal instead.",
+                                           jitconn.event_mv_prob_normal),
+  'matvec_prob_conn_homo_weight': ("brainpy.math.matvec_prob_conn_homo_weight is deprecated. "
+                                   "Use brainpy.math.jitconn.mv_prob_homo instead.",
+                                   jitconn.mv_prob_homo),
+  'matvec_prob_conn_uniform_weight': ("brainpy.math.matvec_prob_conn_uniform_weight is deprecated. "
+                                      "Use brainpy.math.jitconn.mv_prob_uniform instead.",
+                                      jitconn.mv_prob_uniform),
+  'matvec_prob_conn_normal_weight': ("brainpy.math.matvec_prob_conn_normal_weight is deprecated. "
+                                     "Use brainpy.math.jitconn.mv_prob_normal instead.",
+                                     jitconn.mv_prob_normal),
+  'cusparse_csr_matvec': ("brainpy.math.cusparse_csr_matvec is deprecated. "
+                          "Use brainpy.math.sparse.csrmv instead.",
+                          sparse.csrmv),
+  'cusparse_coo_matvec': ("brainpy.math.cusparse_coo_matvec is deprecated. "
+                          "Use brainpy.math.sparse.coomv instead.",
+                          sparse.coomv),
+  'coo_to_csr': ("brainpy.math.coo_to_csr is deprecated. "
+                 "Use brainpy.math.sparse.coo_to_csr instead.",
+                 sparse.coo_to_csr),
+  'csr_to_coo': ("brainpy.math.csr_to_coo is deprecated. "
+                 "Use brainpy.math.sparse.csr_to_coo instead.",
+                 sparse.csr_to_coo),
+  'csr_to_dense': ("brainpy.math.csr_to_dense is deprecated. "
+                   "Use brainpy.math.sparse.csr_to_dense instead.",
+                   sparse.csr_to_dense),
+  'event_csr_matvec': ("brainpy.math.event_csr_matvec is deprecated. "
+                       "Use brainpy.math.event.csr_to_dense instead.",
+                       event.csrmv),
+  'event_info': ("brainpy.math.event_info is deprecated. "
+                 "Use brainpy.math.event.info instead.",
+                 event.info),
+}
+__getattr__ = deprecation_getattr(__name__, __deprecations)
+del deprecation_getattr
```

## brainpy/math/activations.py

```diff
@@ -1,28 +1,39 @@
 # -*- coding: utf-8 -*-
 
 from brainpy._src.math.activations import (
   celu as celu,
   elu as elu,
   gelu as gelu,
   glu as glu,
+  prelu as prelu,
+  silu as silu,
+  selu as selu,
+  relu as relu,
+  relu6 as relu6,
+  rrelu as rrelu,
+  hard_silu as hard_silu,
+  leaky_relu as leaky_relu,
+
   hard_tanh as hard_tanh,
   hard_sigmoid as hard_sigmoid,
-  hard_silu as hard_silu,
+  tanh_shrink as tanh_shrink,
   hard_swish as hard_swish,
-  leaky_relu as leaky_relu,
+  hard_shrink as hard_shrink,
+
+  soft_sign as soft_sign,
+  soft_shrink as soft_shrink,
+  softmax as softmax,
+  softmin as softmin,
+  softplus as softplus,
+
+  swish as swish,
+  mish as mish,
+
   log_sigmoid as log_sigmoid,
   log_softmax as log_softmax,
   one_hot as one_hot,
   normalize as normalize,
-  relu as relu,
-  relu6 as relu6,
   sigmoid as sigmoid,
-  soft_sign as soft_sign,
-  softmax as softmax,
-  softplus as softplus,
-  silu as silu,
-  swish as swish,
-  selu as selu,
   identity as identity,
 )
 from .compat_numpy import tanh
```

## brainpy/math/object_base.py

```diff
@@ -1,16 +1,20 @@
 # -*- coding: utf-8 -*-
 
 from brainpy._src.math.object_transform.base import (BrainPyObject as BrainPyObject,
                                                      FunAsObject as FunAsObject)
 from brainpy._src.math.object_transform.function import (Partial as Partial)
 from brainpy._src.math.object_transform.base import (NodeList as NodeList,
-                                                     NodeDict as NodeDict,)
+                                                     NodeDict as NodeDict,
+                                                     node_dict as node_dict,
+                                                     node_list as node_list, )
 from brainpy._src.math.object_transform.variables import (Variable as Variable,
                                                           Parameter as Parameter,
                                                           TrainVar as TrainVar,
                                                           VariableView as VariableView,
                                                           VarList as VarList,
-                                                          VarDict as VarDict,)
+                                                          VarDict as VarDict,
+                                                          var_list as var_list,
+                                                          var_dict as var_dict, )
```

## brainpy/math/sparse.py

```diff
@@ -1,9 +1,11 @@
 from brainpy._src.math.sparse import (
-  csrmv as csrmv,
-  coomv as coomv,
+  csrmv,
+  coomv,
+
+  seg_matmul,
 
   csr_to_dense as csr_to_dense,
   csr_to_coo as csr_to_coo,
   coo_to_csr as coo_to_csr,
 )
```

## brainpy/math/surrogate.py

```diff
@@ -1,13 +1,18 @@
 # -*- coding: utf-8 -*-
 
 
 # from brainpy._src.math.surrogate._utils import (
 #   vjp_custom as vjp_custom
 # )
+
+from brainpy._src.math.surrogate.base import (
+  Surrogate
+)
+
 from brainpy._src.math.surrogate._one_input import (
   Sigmoid,
   sigmoid as sigmoid,
 
   PiecewiseQuadratic,
   piecewise_quadratic as piecewise_quadratic,
```

## brainpy/synapses/dynamics.py

```diff
@@ -1,25 +1,25 @@
 # -*- coding: utf-8 -*-
 
-from brainpy._src.dyn.synapses.abstract_models import (
+from brainpy._src.synapses.abstract_models import (
   Delta as Delta,
   Exponential as Exponential,
   DualExponential as DualExponential,
   Alpha as Alpha,
   NMDA as NMDA,
   PoissonInput as PoissonInput,
 )
-from brainpy._src.dyn.synapses.biological_models import (
+from brainpy._src.synapses.biological_models import (
   AMPA as AMPA,
   GABAa as GABAa,
   BioNMDA as BioNMDA,
 )
-from brainpy._src.dyn.synapses.delay_couplings import (
+from brainpy._src.synapses.delay_couplings import (
   DelayCoupling as DelayCoupling,
   DiffusiveCoupling as DiffusiveCoupling,
   AdditiveCoupling as AdditiveCoupling,
 )
-from brainpy._src.dyn.synapses.gap_junction import (
+from brainpy._src.synapses.gap_junction import (
   GapJunction as GapJunction,
 )
```

## brainpy/synapses/synouts.py

```diff
@@ -1,10 +1,10 @@
 # -*- coding: utf-8 -*-
 
-from brainpy._src.dyn.synouts.conductances import (
+from brainpy._src.synouts.conductances import (
   COBA as COBA,
   CUBA as CUBA,
 )
-from brainpy._src.dyn.synouts.ions import (
+from brainpy._src.synouts.ions import (
   MgBlock as MgBlock,
 )
```

## brainpy/synapses/synplast.py

```diff
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 
-from brainpy._src.dyn.synplast.short_term_plasticity import (
+from brainpy._src.synplast.short_term_plasticity import (
   STD as STD,
   STP as STP,
 )
```

## Comparing `brainpy/_src/dyn/runners.py` & `brainpy/_src/runners.py`

 * *Files 0% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 from brainpy._src.dynsys import DynamicalSystem
 from brainpy._src.context import share
 from brainpy._src.running.runner import Runner
 from brainpy.check import serialize_kwargs
 from brainpy.errors import RunningError
 from brainpy.types import ArrayType, Output, Monitor
 
+
 __all__ = [
   'DSRunner',
 ]
 
 SUPPORTED_INPUT_OPS = ['-', '+', '*', '/', '=']
 SUPPORTED_INPUT_TYPE = ['fix', 'iter', 'func']
```

## Comparing `brainpy/_src/dyn/transform.py` & `brainpy/_src/transform.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/dyn/neurons/biological_models.py` & `brainpy/_src/neurons/biological_models.py`

 * *Files 0% similar despite different names*

```diff
@@ -798,26 +798,28 @@
     dVdt = (- I_leak - I_Ca - I_AHP - I_C + I_gj + self.Id / p) / self.Cm
     return dVdt
 
   @property
   def derivative(self):
     return JointEq([self.dVs, self.dVd, self.dCa, self.dh, self.dn, self.ds, self.dc, self.dq])
 
-  def update(self, tdi, x=None):
+  def update(self, x=None):
     assert x is None
+    t = share.load('t')
+    dt = share.load('dt')
     Vs, Vd, Ca, h, n, s, c, q = self.integral(Vs=self.Vs.value,
                                               Vd=self.Vd.value,
                                               Ca=self.Ca.value,
                                               h=self.h.value,
                                               n=self.n.value,
                                               s=self.s.value,
                                               c=self.c.value,
                                               q=self.q.value,
-                                              t=tdi['t'],
-                                              dt=tdi['dt'])
+                                              t=t,
+                                              dt=dt)
     self.Vs.value = Vs
     self.Vd.value = Vd
     self.Ca.value = Ca
     self.h.value = h
     self.n.value = n
     self.s.value = s
     self.c.value = c
```

## Comparing `brainpy/_src/dyn/neurons/compat.py` & `brainpy/_src/neurons/compat.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/dyn/neurons/fractional_models.py` & `brainpy/_src/neurons/fractional_models.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/dyn/neurons/input_groups.py` & `brainpy/_src/neurons/input_groups.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 # -*- coding: utf-8 -*-
 
 from typing import Union, Sequence
 
+import jax
 import jax.numpy as jnp
 from brainpy._src.context import share
 import brainpy.math as bm
 from brainpy._src.dynsys import NeuGroupNS
 from brainpy._src.initialize import Initializer, parameter, variable_
 from brainpy.types import Shape, ArrayType
 
@@ -143,15 +144,15 @@
 
   def reset_state(self, batch_size=None):
     self.i = bm.Variable(bm.asarray(0))
     self.spike = variable_(lambda s: jnp.zeros(s, dtype=bool), self.varshape, batch_size)
 
   def update(self):
     self.spike.value = bm.zeros_like(self.spike)
-    bm.while_loop(self._cond_fun, self._body_fun, share.load('t'))
+    bm.while_loop(self._body_fun, self._cond_fun, share.load('t'))
     return self.spike.value
 
   # functions
   def _cond_fun(self, t):
     i = self.i.value
     return bm.logical_and(i < self.num_times, t >= self.times[i])
 
@@ -184,22 +185,17 @@
 
     # parameters
     self.keep_size = keep_size
     self.seed = seed
     self.freqs = parameter(freqs, self.num, allow_none=False)
 
     # variables
-    self.rng = bm.random.default_rng(seed)
     self.reset_state(self.mode)
 
   def update(self):
-    spikes = self.rng.rand_like(self.spike) <= (self.freqs * share.dt / 1000.)
+    spikes = bm.random.rand_like(self.spike) <= (self.freqs * share.dt / 1000.)
     self.spike.value = spikes
     return spikes
 
-  def reset(self, batch_size=None):
-    self.rng.value = bm.random.default_rng(self.seed)
-    self.reset_state(batch_size)
-
   def reset_state(self, batch_size=None):
     self.spike = variable_(lambda s: jnp.zeros(s, dtype=bool), self.varshape, batch_size)
```

## Comparing `brainpy/_src/dyn/neurons/noise_groups.py` & `brainpy/_src/neurons/noise_groups.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 # -*- coding: utf-8 -*-
 
 from typing import Union, Callable
 
 import jax.numpy as jnp
 from brainpy._src.context import share
 from brainpy import math as bm, initialize as init
-from brainpy._src.dynsys import NeuGroupNS as NeuGroup
+from brainpy._src.dynsys import NeuGroupNS
 from brainpy._src.initialize import Initializer
 from brainpy._src.integrators.sde.generic import sdeint
 from brainpy.types import ArrayType, Shape
 
 __all__ = [
   'OUProcess',
 ]
 
 
-class OUProcess(NeuGroup):
+class OUProcess(NeuGroupNS):
   r"""The OrnsteinUhlenbeck process.
 
   The OrnsteinUhlenbeck process :math:`x_{t}` is defined by the following
   stochastic differential equation:
 
   .. math::
```

## Comparing `brainpy/_src/dyn/neurons/reduced_models.py` & `brainpy/_src/neurons/reduced_models.py`

 * *Files 1% similar despite different names*

```diff
@@ -582,14 +582,15 @@
       V_T: Union[float, ArrayType, Initializer, Callable] = -59.9,
       delta_T: Union[float, ArrayType, Initializer, Callable] = 3.48,
       R: Union[float, ArrayType, Initializer, Callable] = 1.,
       tau: Union[float, ArrayType, Initializer, Callable] = 10.,
       tau_ref: Union[float, ArrayType, Initializer, Callable] = None,
       V_initializer: Union[Initializer, Callable, ArrayType] = ZeroInit(),
       noise: Union[float, ArrayType, Initializer, Callable] = None,
+      spike_fun: Callable = bm.surrogate.inv_square_grad,
       keep_size: bool = False,
       input_var: bool = True,
       ref_var: bool = False,
       mode: bm.Mode = None,
       method: str = 'exp_auto',
       name: str = None
   ):
@@ -612,14 +613,17 @@
     self.noise = init_noise(noise, self.varshape)
     self.input_var = input_var
     self.ref_var = ref_var
 
     # initializers
     self._V_initializer = is_initializer(V_initializer)
 
+    # training setting
+    self.spike_fun = is_callable(spike_fun, 'spike_fun')
+
     # variables
     self.reset_state(self.mode)
 
     # integral
     if self.noise is None:
       self.integral = odeint(method=method, f=self.derivative)
     else:
@@ -646,26 +650,46 @@
     dt = share.load('dt')
     if self.input_var:
       if x is not None:
         self.input += x
       x = self.input.value
     else:
       x = 0. if x is None else x
+
     V = self.integral(self.V.value, t, x, dt)
+
     if self.tau_ref is not None:
       refractory = (t - self.t_last_spike) <= self.tau_ref
+      if isinstance(self.mode, bm.TrainingMode):
+        refractory = stop_gradient(refractory)
       V = bm.where(refractory, self.V.value, V)
-      spike = self.V_th <= V
-      V = bm.where(spike, self.V_reset, V)
-      self.t_last_spike.value = bm.where(spike, t, self.t_last_spike)
-      if self.ref_var:
-        self.refractory.value = bm.logical_or(refractory, spike)
+
+      if isinstance(self.mode, bm.TrainingMode):
+        spike = self.spike_fun(V - self.V_th)
+        spike_no_grad = stop_gradient(spike)
+        V += (self.V_reset - V) * spike_no_grad
+        spike_ = spike_no_grad > 0.
+        self.t_last_spike.value = stop_gradient(bm.where(spike_, t, self.t_last_spike.value))
+        if self.ref_var:
+        # will be used in other place, like Delta Synapse, so stop its gradient
+          self.refractory.value = stop_gradient(bm.logical_or(refractory, spike_).value)
+      else:
+        spike = self.V_th <= V
+        V = bm.where(spike, self.V_reset, V)
+        self.t_last_spike.value = bm.where(spike, t, self.t_last_spike)
+        if self.ref_var:
+          self.refractory.value = bm.logical_or(refractory, spike)
     else:
-      spike = self.V_th <= V
-      V = bm.where(spike, self.V_reset, V)
+      if isinstance(self.mode, bm.TrainingMode):
+        spike = self.spike_fun(V - self.V_th)
+        spike_no_grad = stop_gradient(spike)
+        V += (self.V_reset - V) * spike_no_grad
+      else:
+        spike = self.V_th <= V
+        V = bm.where(spike, self.V_reset, V)
     self.V.value = V
     self.spike.value = spike
     return spike
 
   def clear_input(self):
     if self.input_var:
       self.input[:] = 0.
@@ -759,14 +783,15 @@
       tau: Union[float, ArrayType, Initializer, Callable] = 10.,
       tau_w: Union[float, ArrayType, Initializer, Callable] = 30.,
       tau_ref: Optional[Union[float, ArrayType, Initializer, Callable]] = None,
       R: Union[float, ArrayType, Initializer, Callable] = 1.,
       V_initializer: Union[Initializer, Callable, ArrayType] = ZeroInit(),
       w_initializer: Union[Initializer, Callable, ArrayType] = ZeroInit(),
       noise: Optional[Union[float, ArrayType, Initializer, Callable]] = None,
+      spike_fun: Callable = bm.surrogate.inv_square_grad,
       method: str = 'exp_auto',
       keep_size: bool = False,
       input_var: bool = True,
       mode: bm.Mode = None,
       name: Optional[str] = None
   ):
     super(AdExIF, self).__init__(size=size,
@@ -785,14 +810,15 @@
     self.R = parameter(R, self.varshape, allow_none=False)
     self.tau = parameter(tau, self.varshape, allow_none=False)
     self.tau_w = parameter(tau_w, self.varshape, allow_none=False)
     self.tau_ref = parameter(tau_ref, self.varshape, allow_none=True)
     self.delta_T = parameter(delta_T, self.varshape, allow_none=False)
     self.noise = init_noise(noise, self.varshape, num_vars=2)
     self.input_var = input_var
+    self.spike_fun = is_callable(spike_fun, 'spike_fun')
 
     # initializers
     self._V_initializer = is_initializer(V_initializer)
     self._w_initializer = is_initializer(w_initializer)
 
     # variables
     self.reset_state(self.mode)
@@ -832,25 +858,41 @@
     dt = share.load('dt')
     if self.input_var:
       if x is not None:
         self.input += x
       x = self.input.value
     else:
       x = 0. if x is None else x
+
     V, w = self.integral(self.V.value, self.w.value, t, x, dt)
+
     if self.tau_ref is not None:
       refractory = (t - self.t_last_spike) <= self.tau_ref
+      if isinstance(self.mode, bm.TrainingMode):
+        refractory = stop_gradient(refractory)
       V = bm.where(refractory, self.V.value, V)
-    spike = V >= self.V_th
-    self.V.value = bm.where(spike, self.V_reset, V)
-    self.w.value = bm.where(spike, w + self.b, w)
-    self.spike.value = spike
-    if self.tau_ref is not None:
-      self.refractory.value = bm.logical_or(refractory, spike)
-      self.t_last_spike.value = bm.where(spike, t, self.t_last_spike.value)
+
+    if isinstance(self.mode, bm.TrainingMode):
+      spike = self.spike_fun(V - self.V_th)
+      spike_no_grad = stop_gradient(spike)
+      V += (self.V_reset - V) * spike_no_grad
+      w += self.b * spike_no_grad
+      spike_ = spike_no_grad > 0.
+      if self.tau_ref is not None:
+        self.refractory.value = stop_gradient(bm.logical_or(refractory, spike_).value)
+        self.t_last_spike.value = stop_gradient(bm.where(spike_, t, self.t_last_spike.value))
+    else:
+      spike = V >= self.V_th
+      self.V.value = bm.where(spike, self.V_reset, V)
+      self.w.value = bm.where(spike, w + self.b, w)
+      self.spike.value = spike
+      if self.tau_ref is not None:
+        self.refractory.value = bm.logical_or(refractory, spike)
+        self.t_last_spike.value = bm.where(spike, t, self.t_last_spike.value)
+
     return spike
 
   def clear_input(self):
     if self.input_var:
       self.input[:] = 0.
 
 
@@ -930,14 +972,15 @@
       V_c: Union[float, ArrayType, Initializer, Callable] = -50.0,
       c: Union[float, ArrayType, Initializer, Callable] = .07,
       R: Union[float, ArrayType, Initializer, Callable] = 1.,
       tau: Union[float, ArrayType, Initializer, Callable] = 10.,
       tau_ref: Union[float, ArrayType, Initializer, Callable] = None,
       V_initializer: Union[Initializer, Callable, ArrayType] = ZeroInit(),
       noise: Union[float, ArrayType, Initializer, Callable] = None,
+      spike_fun: Callable = bm.surrogate.inv_square_grad,
       keep_size: bool = False,
       input_var: bool = True,
       mode: bm.Mode = None,
       method: str = 'exp_auto',
       name: str = None
   ):
     # initialization
@@ -954,14 +997,15 @@
     self.V_c = parameter(V_c, self.varshape, allow_none=False)
     self.c = parameter(c, self.varshape, allow_none=False)
     self.R = parameter(R, self.varshape, allow_none=False)
     self.tau = parameter(tau, self.varshape, allow_none=False)
     self.tau_ref = parameter(tau_ref, self.varshape, allow_none=True)
     self.noise = init_noise(noise, self.varshape, num_vars=1)
     self.input_var = input_var
+    self.spike_fun = is_callable(spike_fun, 'spike_fun')
 
     # initializers
     self._V_initializer = is_initializer(V_initializer)
 
     # variables
     self.reset_state(self.mode)
 
@@ -990,26 +1034,44 @@
     dt = share.load('dt')
     if self.input_var:
       if x is not None:
         self.input += x
       x = self.input.value
     else:
       x = 0. if x is None else x
+
     V = self.integral(self.V.value, t, x, dt)
+
     if self.tau_ref is not None:
       refractory = (t - self.t_last_spike) <= self.tau_ref
+      if isinstance(self.mode, bm.TrainingMode):
+        refractory = stop_gradient(refractory)
       V = bm.where(refractory, self.V.value, V)
-      spike = self.V_th <= V
-      t_last_spike = bm.where(spike, t, self.t_last_spike.value)
-      V = bm.where(spike, self.V_reset, V)
-      self.refractory.value = bm.logical_or(refractory, spike)
-      self.t_last_spike.value = t_last_spike
+
+      if isinstance(self.mode, bm.TrainingMode):
+        spike = self.spike_fun(V - self.V_th)
+        spike_no_grad = stop_gradient(spike)
+        V += (self.V_reset - V) * spike_no_grad
+        spike_ = spike_no_grad > 0.
+        self.refractory.value = stop_gradient(bm.logical_or(refractory, spike_).value)
+        self.t_last_spike.value = stop_gradient(bm.where(spike_, t, self.t_last_spike.value))
+      else:
+        spike = self.V_th <= V
+        t_last_spike = bm.where(spike, t, self.t_last_spike.value)
+        V = bm.where(spike, self.V_reset, V)
+        self.refractory.value = bm.logical_or(refractory, spike)
+        self.t_last_spike.value = t_last_spike
     else:
-      spike = self.V_th <= V
-      V = bm.where(spike, self.V_reset, V)
+      if isinstance(self.mode, bm.TrainingMode):
+        spike = self.spike_fun(V - self.V_th)
+        spike_no_grad = stop_gradient(spike)
+        V += (self.V_reset - V) * spike_no_grad
+      else:
+        spike = self.V_th <= V
+        V = bm.where(spike, self.V_reset, V)
     self.V.value = V
     self.spike.value = spike
 
   def clear_input(self):
     if self.input_var:
       self.input[:] = 0.
 
@@ -1102,14 +1164,15 @@
       b: Union[float, ArrayType, Initializer, Callable] = .1,
       c: Union[float, ArrayType, Initializer, Callable] = .07,
       tau: Union[float, ArrayType, Initializer, Callable] = 10.,
       tau_w: Union[float, ArrayType, Initializer, Callable] = 10.,
       V_initializer: Union[Initializer, Callable, ArrayType] = ZeroInit(),
       w_initializer: Union[Initializer, Callable, ArrayType] = ZeroInit(),
       noise: Union[float, ArrayType, Initializer, Callable] = None,
+      spike_fun: Callable = bm.surrogate.inv_square_grad,
       method: str = 'exp_auto',
       keep_size: bool = False,
       input_var: bool = True,
       mode: bm.Mode = None,
       name: str = None
   ):
     super(AdQuaIF, self).__init__(size=size,
@@ -1126,14 +1189,15 @@
     self.c = parameter(c, self.varshape, allow_none=False)
     self.a = parameter(a, self.varshape, allow_none=False)
     self.b = parameter(b, self.varshape, allow_none=False)
     self.tau = parameter(tau, self.varshape, allow_none=False)
     self.tau_w = parameter(tau_w, self.varshape, allow_none=False)
     self.noise = init_noise(noise, self.varshape, num_vars=2)
     self.input_var = input_var
+    self.spike_fun = is_callable(spike_fun, 'spike_fun')
 
     # initializers
     self._V_initializer = is_initializer(V_initializer)
     self._w_initializer = is_initializer(w_initializer)
 
     # variables
     self.reset_state(self.mode)
@@ -1169,18 +1233,26 @@
     dt = share.load('dt')
     if self.input_var:
       if x is not None:
         self.input += x
       x = self.input.value
     else:
       x = 0. if x is None else x
+
     V, w = self.integral(self.V.value, self.w.value, t, x, dt)
-    spike = self.V_th <= V
-    self.V.value = bm.where(spike, self.V_reset, V)
-    self.w.value = bm.where(spike, w + self.b, w)
+
+    if isinstance(self.mode, bm.TrainingMode):
+      spike = self.spike_fun(V - self.V_th)
+      spike_no_grad = stop_gradient(spike)
+      V += (self.V_reset - V) * spike_no_grad
+      w += self.b * spike_no_grad
+    else:
+      spike = self.V_th <= V
+      self.V.value = bm.where(spike, self.V_reset, V)
+      self.w.value = bm.where(spike, w + self.b, w)
     self.spike.value = spike
     return spike
 
   def clear_input(self):
     if self.input_var:
       self.input[:] = 0.
```

## Comparing `brainpy/_src/dyn/rates/populations.py` & `brainpy/_src/rates/populations.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 # -*- coding: utf-8 -*-
 
 from typing import Union, Callable
+import jax
 
 from brainpy import math as bm
 from brainpy._src.context import share
 from brainpy._src.dynsys import NeuGroupNS
-from brainpy._src.dyn.neurons.noise_groups import OUProcess
+from brainpy._src.neurons.noise_groups import OUProcess
 from brainpy._src.initialize import (Initializer,
                                      Uniform,
                                      parameter,
                                      variable,
                                      variable_,
                                      ZeroInit)
 from brainpy._src.integrators.joint_eq import JointEq
 from brainpy._src.integrators.ode.generic import odeint
 from brainpy.check import is_initializer
 from brainpy.types import Shape, ArrayType
 
 __all__ = [
-  'RateModel',
   'FHN',
   'FeedbackFHN',
   'QIF',
   'StuartLandauOscillator',
   'WilsonCowanModel',
   'ThresholdLinearModel',
 ]
@@ -166,34 +166,34 @@
 
   def dx(self, x, t, y, x_ext):
     return - self.alpha * x ** 3 + self.beta * x ** 2 + self.gamma * x - y + x_ext
 
   def dy(self, y, t, x, y_ext=0.):
     return (x - self.delta - self.epsilon * y) / self.tau + y_ext
 
-  def update(self, x1=None, x2=None):
+  def update(self, inp_x=None, inp_y=None):
     t = share.load('t')
     dt = share.load('dt')
 
     # input
     if self.input_var:
-      if x1 is not None:
-        self.input += x1
+      if inp_x is not None:
+        self.input += inp_x
       if self.x_ou is not None:
         self.input += self.x_ou()
-      if x2 is not None:
-        self.input_y += x2
+      if inp_y is not None:
+        self.input_y += inp_y
       if self.y_ou is not None:
         self.input_y += self.y_ou()
       input_x = self.input.value
       input_y = self.input_y.value
     else:
-      input_x = x1 if (x1 is not None) else 0.
+      input_x = inp_x if (inp_x is not None) else 0.
       if self.x_ou is not None: input_x += self.x_ou()
-      input_y = x2 if (x2 is not None) else 0.
+      input_y = inp_y if (inp_y is not None) else 0.
       if self.y_ou is not None: input_y += self.y_ou()
 
     # integral
     x, y = self.integral(self.x.value, self.y.value, t, x_ext=input_x, y_ext=input_y, dt=dt)
     self.x.value = x
     self.y.value = y
     return x
@@ -346,15 +346,15 @@
                             self.y_ou_sigma,
                             self.y_ou_tau,
                             method=method)
 
     # integral
     self.integral = odeint(method=method,
                            f=JointEq([self.dx, self.dy]),
-                           state_delays={'V': self.x_delay})
+                           state_delays={'x': self.x_delay})
 
   def reset_state(self, batch_size=None):
     self.x.value = variable(self._x_initializer, batch_size, self.varshape)
     self.y.value = variable(self._y_initializer, batch_size, self.varshape)
     self.x_delay.reset(self.x, self.delay)
     if self.input_var:
       self.input = variable(bm.zeros, batch_size, self.varshape)
@@ -366,34 +366,34 @@
 
   def dx(self, x, t, y, x_ext):
     return x - x * x * x / 3 - y + x_ext + self.mu * (self.x_delay(t - self.delay) - self.v0)
 
   def dy(self, y, t, x, y_ext):
     return (x + self.a - self.b * y + y_ext) / self.tau
 
-  def update(self, x1=None, x2=None):
+  def update(self, inp_x=None, inp_y=None):
     t = share.load('t')
     dt = share.load('dt')
 
     # input
     if self.input_var:
-      if x1 is not None:
-        self.input += x1
+      if inp_x is not None:
+        self.input += inp_x
       if self.x_ou is not None:
         self.input += self.x_ou()
-      if x2 is not None:
-        self.input_y += x2
+      if inp_y is not None:
+        self.input_y += inp_y
       if self.y_ou is not None:
         self.input_y += self.y_ou()
       input_x = self.input.value
       input_y = self.input_y.value
     else:
-      input_x = x1 if (x1 is not None) else 0.
+      input_x = inp_x if (inp_x is not None) else 0.
       if self.x_ou is not None: input_x += self.x_ou()
-      input_y = x2 if (x2 is not None) else 0.
+      input_y = inp_y if (inp_y is not None) else 0.
       if self.y_ou is not None: input_y += self.y_ou()
 
     x, y = self.integral(self.x.value, self.y.value, t, x_ext=input_x, y_ext=input_y, dt=dt)
     self.x.value = x
     self.y.value = y
     return x
 
@@ -566,34 +566,34 @@
   def dy(self, y, t, x, y_ext):
     return (self.delta / (bm.pi * self.tau) + 2. * x * y + y_ext) / self.tau
 
   def dx(self, x, t, y, x_ext):
     return (x ** 2 + self.eta + x_ext + self.J * y * self.tau -
             (bm.pi * y * self.tau) ** 2) / self.tau
 
-  def update(self, x1=None, x2=None):
+  def update(self, inp_x=None, inp_y=None):
     t = share.load('t')
     dt = share.load('dt')
 
     # input
     if self.input_var:
-      if x1 is not None:
-        self.input += x1
+      if inp_x is not None:
+        self.input += inp_x
       if self.x_ou is not None:
         self.input += self.x_ou()
-      if x2 is not None:
-        self.input_y += x2
+      if inp_y is not None:
+        self.input_y += inp_y
       if self.y_ou is not None:
         self.input_y += self.y_ou()
       input_x = self.input.value
       input_y = self.input_y.value
     else:
-      input_x = x1 if (x1 is not None) else 0.
+      input_x = inp_x if (inp_x is not None) else 0.
       if self.x_ou is not None: input_x += self.x_ou()
-      input_y = x2 if (x2 is not None) else 0.
+      input_y = inp_y if (inp_y is not None) else 0.
       if self.y_ou is not None: input_y += self.y_ou()
 
     x, y = self.integral(self.x, self.y, t=t, x_ext=input_x, y_ext=input_y, dt=dt)
     self.x.value = x
     self.y.value = y
     return x
 
@@ -718,34 +718,34 @@
 
   def dx(self, x, t, y, x_ext, a, w):
     return (a - x * x - y * y) * x - w * y + x_ext
 
   def dy(self, y, t, x, y_ext, a, w):
     return (a - x * x - y * y) * y - w * y + y_ext
 
-  def update(self, x1=None, x2=None):
+  def update(self, inp_x=None, inp_y=None):
     t = share.load('t')
     dt = share.load('dt')
 
     # input
     if self.input_var:
-      if x1 is not None:
-        self.input += x1
+      if inp_x is not None:
+        self.input += inp_x
       if self.x_ou is not None:
         self.input += self.x_ou()
-      if x2 is not None:
-        self.input_y += x2
+      if inp_y is not None:
+        self.input_y += inp_y
       if self.y_ou is not None:
         self.input_y += self.y_ou()
       input_x = self.input.value
       input_y = self.input_y.value
     else:
-      input_x = x1 if (x1 is not None) else 0.
+      input_x = inp_x if (inp_x is not None) else 0.
       if self.x_ou is not None: input_x += self.x_ou()
-      input_y = x2 if (x2 is not None) else 0.
+      input_y = inp_y if (inp_y is not None) else 0.
       if self.y_ou is not None: input_y += self.y_ou()
 
     x, y = self.integral(self.x,
                          self.y,
                          t=t,
                          x_ext=input_x,
                          y_ext=input_y,
@@ -901,34 +901,34 @@
     xx = self.wEE * x - self.wIE * y + x_ext
     return (-x + (1 - self.r * x) * self.F(xx, self.E_a, self.E_theta)) / self.E_tau
 
   def dy(self, y, t, x, y_ext):
     xx = self.wEI * x - self.wII * y + y_ext
     return (-y + (1 - self.r * y) * self.F(xx, self.I_a, self.I_theta)) / self.I_tau
 
-  def update(self, x1=None, x2=None):
+  def update(self, inp_x=None, inp_y=None):
     t = share.load('t')
     dt = share.load('dt')
 
     # input
     if self.input_var:
-      if x1 is not None:
-        self.input += x1
+      if inp_x is not None:
+        self.input += inp_x
       if self.x_ou is not None:
         self.input += self.x_ou()
-      if x2 is not None:
-        self.input_y += x2
+      if inp_y is not None:
+        self.input_y += inp_y
       if self.y_ou is not None:
         self.input_y += self.y_ou()
       input_x = self.input.value
       input_y = self.input_y.value
     else:
-      input_x = x1 if (x1 is not None) else 0.
+      input_x = inp_x if (inp_x is not None) else 0.
       if self.x_ou is not None: input_x += self.x_ou()
-      input_y = x2 if (x2 is not None) else 0.
+      input_y = inp_y if (inp_y is not None) else 0.
       if self.y_ou is not None: input_y += self.y_ou()
 
     x, y = self.integral(self.x, self.y, t, x_ext=input_x, y_ext=input_y, dt=dt)
     self.x.value = x
     self.y.value = y
     return x
 
@@ -1022,52 +1022,55 @@
 
     # variables
     self.e = variable(e_initializer, self.mode, self.varshape)  # Firing rate of excitatory population
     self.i = variable(i_initializer, self.mode, self.varshape)  # Firing rate of inhibitory population
     if self.input_var:
        self.Ie = variable(bm.zeros, self.mode, self.varshape)  # Input of excitaory population
        self.Ii = variable(bm.zeros, self.mode, self.varshape)  # Input of inhibitory population
-    if bm.any(self.noise_e != 0) or bm.any(self.noise_i != 0):
-      self.rng = bm.random.default_rng(seed)
 
   def reset(self, batch_size=None):
-    self.rng.seed(self.seed)
     self.reset_state(batch_size)
 
   def reset_state(self, batch_size=None):
     self.e.value = variable(self._e_initializer, batch_size, self.varshape)
     self.i.value = variable(self._i_initializer, batch_size, self.varshape)
     if self.input_var:
       self.Ie.value = variable(bm.zeros, batch_size, self.varshape)
       self.Ii.value = variable(bm.zeros, batch_size, self.varshape)
 
-  def update(self, x1=None, x2=None):
+  def update(self, inp_e=None, inp_i=None):
     dt = share.load('dt')
 
     # input
     if self.input_var:
-      if x1 is not None:
-        self.Ie += x1
-      if x2 is not None:
-        self.Ii += x2
+      if inp_e is not None:
+        self.Ie += inp_e
+      if inp_i is not None:
+        self.Ii += inp_i
       input_e = self.Ie.value
       input_i = self.Ii.value
     else:
-      input_e = x1 if (x1 is not None) else 0.
-      input_i = x2 if (x2 is not None) else 0.
+      input_e = inp_e if (inp_e is not None) else 0.
+      input_i = inp_i if (inp_i is not None) else 0.
 
     de = -self.e + self.beta_e * bm.maximum(input_e, 0.)
-    if bm.any(self.noise_e != 0.):
-      de += self.rng.randn(self.varshape) * self.noise_e
+    with jax.ensure_compile_time_eval():
+      has_noise = bm.any(self.noise_e != 0.)
+
+    if has_noise:
+      de += bm.random.randn(self.varshape) * self.noise_e
     de = de / self.tau_e
     self.e.value = bm.maximum(self.e + de * dt, 0.)
 
     di = -self.i + self.beta_i * bm.maximum(input_i, 0.)
-    if bm.any(self.noise_i != 0.):
-      di += self.rng.randn(self.varshape) * self.noise_i
+    with jax.ensure_compile_time_eval():
+      has_noise = bm.any(self.noise_i != 0.)
+
+    if has_noise:
+      di += bm.random.randn(self.varshape) * self.noise_i
     di = di / self.tau_i
     self.i.value = bm.maximum(self.i + di * dt, 0.)
     return self.e.value
 
   def clear_input(self):
     if self.input_var:
       self.Ie.value = bm.zeros_like(self.Ie)
```

## Comparing `brainpy/_src/dyn/synapses/abstract_models.py` & `brainpy/_src/synapses/abstract_models.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 from typing import Union, Dict, Callable, Optional
 
 from jax import vmap
 from jax.lax import stop_gradient
 
 import brainpy.math as bm
 from brainpy._src.connect import TwoEndConnector, All2All, One2One
-from brainpy._src.dyn.synouts import CUBA, MgBlock
+from brainpy._src.synouts import CUBA, MgBlock
 from brainpy._src.dynsys import NeuGroup, SynOut, SynSTP, TwoEndConn, SynConn
 from brainpy._src.initialize import Initializer, variable_
 from brainpy._src.integrators import odeint, JointEq
 from brainpy.check import is_integer, is_float, is_subclass
 from brainpy.types import ArrayType
 
 __all__ = [
@@ -148,15 +148,15 @@
     elif isinstance(self.conn, One2One):
       syn_value = bm.asarray(pre_spike, dtype=bm.float_)
       if self.stp is not None:
         syn_value = self.stp(syn_value)
       post_vs = self._syn2post_with_one2one(syn_value, self.g_max)
     else:
       if self.comp_method == 'sparse':
-        f = lambda s: bm.event_csr_matvec(
+        f = lambda s: bm.event.csrmv(
           self.g_max, self.conn_mask[0], self.conn_mask[1], s,
           shape=(self.pre.num, self.post.num), transpose=True
         )
         if isinstance(self.mode, bm.BatchingMode): f = vmap(f)
         post_vs = f(pre_spike)
         # if not isinstance(self.stp, _NullSynSTP):
         #   raise NotImplementedError()
@@ -339,15 +339,15 @@
       post_vs = self._syn2post_with_all2all(syn_value, self.g_max)
     elif isinstance(self.conn, One2One):
       syn_value = bm.asarray(pre_spike, dtype=bm.float_)
       if self.stp is not None: syn_value = self.stp(syn_value)
       post_vs = self._syn2post_with_one2one(syn_value, self.g_max)
     else:
       if self.comp_method == 'sparse':
-        f = lambda s: bm.event_csr_matvec(
+        f = lambda s: bm.event.csrmv(
           self.g_max, self.conn_mask[0], self.conn_mask[1], s,
           shape=(self.pre.num, self.post.num),
           transpose=True
         )
         if isinstance(self.mode, bm.BatchingMode): f = vmap(f)
         post_vs = f(pre_spike)
         # if not isinstance(self.stp, _NullSynSTP):
@@ -544,15 +544,15 @@
     if self.stp is not None: syn_value = self.stp(syn_value)
     if isinstance(self.conn, All2All):
       post_vs = self._syn2post_with_all2all(syn_value, self.g_max)
     elif isinstance(self.conn, One2One):
       post_vs = self._syn2post_with_one2one(syn_value, self.g_max)
     else:
       if self.comp_method == 'sparse':
-        f = lambda s: bm.cusparse_csr_matvec(
+        f = lambda s: bm.sparse.csrmv(
           self.g_max, self.conn_mask[0], self.conn_mask[1], s,
           shape=(self.pre.num, self.post.num),
           transpose=True
         )
         if isinstance(self.mode, bm.BatchingMode): f = vmap(f)
         post_vs = f(syn_value)
       else:
@@ -889,15 +889,15 @@
     if self.stp is not None: syn_value = self.stp(syn_value)
     if isinstance(self.conn, All2All):
       post_vs = self._syn2post_with_all2all(syn_value, self.g_max)
     elif isinstance(self.conn, One2One):
       post_vs = self._syn2post_with_one2one(syn_value, self.g_max)
     else:
       if self.comp_method == 'sparse':
-        f = lambda s: bm.event_csr_matvec(
+        f = lambda s: bm.event.csrmv(
           self.g_max, self.conn_mask[0], self.conn_mask[1], s,
           shape=(self.pre.num, self.post.num),
           transpose=True
         )
         if isinstance(self.mode, bm.BatchingMode): f = vmap(f)
         post_vs = f(syn_value)
       else:
@@ -956,36 +956,34 @@
 
     # parameters
     self.target_var = target_var
     self.num_input = num_input
     self.freq = freq
     self.weight = weight
     self.seed = seed
-    self.rng = bm.random.default_rng(seed)
 
   def update(self, tdi):
     p = self.freq * tdi.dt / 1e3
     a = self.num_input * p
     b = self.num_input * (1 - p)
     if isinstance(tdi.dt, (int, float)):  # dt is not in tracing
       if (a > 5) and (b > 5):
-        inp = self.rng.normal(a, b * p, self.target_var.shape)
+        inp = bm.random.normal(a, b * p, self.target_var.shape)
       else:
-        inp = self.rng.binomial(self.num_input, p, self.target_var.shape)
+        inp = bm.random.binomial(self.num_input, p, self.target_var.shape)
 
     else:  # dt is in tracing
       inp = bm.cond((a > 5) * (b > 5),
-                    lambda _: self.rng.normal(a, b * p, self.target_var.shape),
-                    lambda _: self.rng.binomial(self.num_input, p, self.target_var.shape),
+                    lambda _: bm.random.normal(a, b * p, self.target_var.shape),
+                    lambda _: bm.random.binomial(self.num_input, p, self.target_var.shape),
                     None)
     self.target_var += inp * self.weight
 
   def __repr__(self):
     names = self.__class__.__name__
     return f'{names}(name={self.name}, num_input={self.num_input}, freq={self.freq}, weight={self.weight})'
 
   def reset_state(self, batch_size=None):
     pass
 
   def reset(self, batch_size=None):
-    self.rng.seed(self.seed)
     self.reset_state(batch_size)
```

## Comparing `brainpy/_src/dyn/synapses/biological_models.py` & `brainpy/_src/synapses/biological_models.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 from typing import Union, Dict, Callable, Optional
 
 from jax import vmap
 from jax.lax import stop_gradient
 
 import brainpy.math as bm
 from brainpy._src.dynsys import NeuGroup, TwoEndConn, SynSTP, SynOut
-from brainpy._src.dyn.synouts import COBA, MgBlock
+from brainpy._src.synouts import COBA, MgBlock
 from brainpy._src.initialize import Initializer, variable
 from brainpy._src.integrators import odeint, JointEq
 from brainpy._src.connect import TwoEndConnector, All2All, One2One
 from brainpy.types import ArrayType
 
 __all__ = [
   'AMPA',
@@ -225,15 +225,15 @@
     if self.stp is not None: syn_value = self.stp(syn_value)
     if isinstance(self.conn, All2All):
       post_vs = self._syn2post_with_all2all(syn_value, self.g_max)
     elif isinstance(self.conn, One2One):
       post_vs = self._syn2post_with_one2one(syn_value, self.g_max)
     else:
       if self.comp_method == 'sparse':
-        f = lambda s: bm.cusparse_csr_matvec(
+        f = lambda s: bm.sparse.csrmv(
           self.g_max, self.conn_mask[0], self.conn_mask[1], s,
           shape=(self.pre.num, self.post.num),
           transpose=True
         )
         if isinstance(self.mode, bm.BatchingMode):
           f = vmap(f)
         post_vs = f(syn_value)
@@ -569,15 +569,15 @@
     if self.stp is not None: syn_value = self.stp(syn_value)
     if isinstance(self.conn, All2All):
       post_vs = self._syn2post_with_all2all(syn_value, self.g_max)
     elif isinstance(self.conn, One2One):
       post_vs = self._syn2post_with_one2one(syn_value, self.g_max)
     else:
       if self.comp_method == 'sparse':
-        f = lambda s: bm.cusparse_csr_matvec(
+        f = lambda s: bm.sparse.csrmv(
           self.g_max,self.conn_mask[0], self.conn_mask[1], s,
           shape=(self.pre.num, self.post.num),
           transpose=True
         )
         if isinstance(self.mode, bm.BatchingMode): f = vmap(f)
         post_vs = f(syn_value)
       else:
```

## Comparing `brainpy/_src/dyn/synapses/compat.py` & `brainpy/_src/synapses/compat.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 import warnings
 from typing import Union, Dict, Callable, Optional
 
 import brainpy._src.math as bm
 from brainpy._src.connect import TwoEndConnector
 from brainpy._src.dynsys import NeuGroup, SynSTP
-from brainpy._src.dyn.synouts import COBA, CUBA, MgBlock
+from brainpy._src.synouts import COBA, CUBA, MgBlock
 from brainpy._src.initialize import Initializer
 from brainpy.types import ArrayType
 from .abstract_models import Delta, Exponential, DualExponential, NMDA as NewNMDA
 
 __all__ = [
   'DeltaSynapse',
   'ExpCUBA',
```

## Comparing `brainpy/_src/dyn/synapses/delay_couplings.py` & `brainpy/_src/synapses/delay_couplings.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 from typing import Optional, Union, Sequence, Tuple, Callable
 
 import jax.numpy as jnp
 from jax import vmap
 
 import brainpy.math as bm
 from brainpy._src.dynsys import SynConn
-from brainpy._src.dyn.neurons.input_groups import InputGroup, OutputGroup
+from brainpy._src.neurons.input_groups import InputGroup, OutputGroup
 from brainpy._src.initialize import Initializer
 from brainpy.check import is_sequence
 from brainpy.types import ArrayType
 
 __all__ = [
   'DelayCoupling',
   'DiffusiveCoupling',
```

## Comparing `brainpy/_src/dyn/synapses/gap_junction.py` & `brainpy/_src/synapses/gap_junction.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/dyn/synapses/learning_rules.py` & `brainpy/_src/synapses/learning_rules.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/dyn/synapses_v2/abstract_synapses.py` & `brainpy/_src/synapses_v2/abstract_synapses.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 from typing import Union, Dict, Callable, Optional
 
 from jax import vmap
 
 import brainpy.math as bm
 from brainpy._src.connect import TwoEndConnector, All2All, One2One
 from brainpy._src.context import share
-from brainpy._src.dyn.synapses_v2.base import SynConnNS, SynOutNS, SynSTPNS
+from brainpy._src.synapses_v2.base import SynConnNS, SynOutNS, SynSTPNS
 from brainpy._src.initialize import Initializer, variable_
 from brainpy._src.integrators import odeint, JointEq
 from brainpy.check import is_float
 from brainpy.types import ArrayType
 
 
 class Exponential(SynConnNS):
@@ -116,29 +116,30 @@
     if isinstance(self.conn, All2All):
       post_vs = self._syn2post_with_all2all(syn_value, self.g_max, self.conn.include_self)
     elif isinstance(self.conn, One2One):
       post_vs = self._syn2post_with_one2one(syn_value, self.g_max)
     else:
       if self.comp_method == 'sparse':
         if self.stp is None:
-          f = lambda s: bm.event_csr_matvec(self.g_max,
-                                                      self.conn_mask[0],
-                                                      self.conn_mask[1],
-                                                      s,
-                                                      shape=(self.pre_num, self.post_num),
-                                                      transpose=True)
+          f = lambda s: bm.event.csrmv(self.g_max,
+                                       self.conn_mask[0],
+                                       self.conn_mask[1],
+                                       s,
+                                       shape=(self.pre_num, self.post_num),
+                                       transpose=True)
           if isinstance(self.mode, bm.BatchingMode):
             f = vmap(f)
         else:
-          f = lambda s: bm.cusparse_csr_matvec(self.g_max,
-                                                          self.conn_mask[0],
-                                                          self.conn_mask[1],
-                                                          s,
-                                                          shape=(self.pre_num, self.post_num),
-                                                          transpose=True)
+          f = lambda s: bm.sparse.csrmv(self.g_max,
+                                        self.conn_mask[0],
+                                        self.conn_mask[1],
+                                        s,
+                                        shape=(self.pre_num, self.post_num),
+                                        transpose=True,
+                                        method='cusparse')
           if isinstance(self.mode, bm.BatchingMode):
             f = vmap(f)
         post_vs = f(pre_spike)
       else:
         post_vs = self._syn2post_with_dense(syn_value, self.g_max, self.conn_mask)
 
     # updates
@@ -271,21 +272,22 @@
 
     if isinstance(self.conn, All2All):
       post_vs = self._syn2post_with_all2all(syn_value, self.g_max, self.conn.include_self)
     elif isinstance(self.conn, One2One):
       post_vs = self._syn2post_with_one2one(syn_value, self.g_max)
     else:
       if self.comp_method == 'sparse':
-        f = lambda s: bm.cusparse_csr_matvec(
+        f = lambda s: bm.sparse.csrmv(
           self.g_max,
           self.conn_mask[0],
           self.conn_mask[1],
           s,
           shape=(self.conn.pre_num, self.conn.post_num),
-          transpose=True
+          transpose=True,
+          method='cusparse'
         )
         if isinstance(self.mode, bm.BatchingMode):
           f = vmap(f)
         post_vs = f(syn_value)
       else:
         post_vs = self._syn2post_with_dense(syn_value, self.g_max, self.conn_mask)
 
@@ -392,8 +394,7 @@
                      tau_decay=tau_decay,
                      tau_rise=tau_decay,
                      method=method,
                      out=out,
                      stp=stp,
                      name=name,
                      mode=mode)
-
```

## Comparing `brainpy/_src/dyn/synapses_v2/base.py` & `brainpy/_src/synapses_v2/base.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/dyn/synapses_v2/others.py` & `brainpy/_src/synapses_v2/others.py`

 * *Files 15% similar despite different names*

```diff
@@ -48,38 +48,36 @@
 
     # parameters
     self.target_shape = target_shape
     self.num_input = num_input
     self.freq = freq
     self.weight = weight
     self.seed = seed
-    self.rng = bm.random.default_rng(seed)
 
   def update(self):
     p = self.freq * share.dt / 1e3
     a = self.num_input * p
     b = self.num_input * (1 - p)
     if isinstance(share.dt, (int, float)):  # dt is not in tracing
       if (a > 5) and (b > 5):
-        inp = self.rng.normal(a, b * p, self.target_shape)
+        inp = bm.random.normal(a, b * p, self.target_shape)
       else:
-        inp = self.rng.binomial(self.num_input, p, self.target_shape)
+        inp = bm.random.binomial(self.num_input, p, self.target_shape)
 
     else:  # dt is in tracing
       inp = bm.cond((a > 5) * (b > 5),
-                    lambda _: self.rng.normal(a, b * p, self.target_shape),
-                    lambda _: self.rng.binomial(self.num_input, p, self.target_shape),
+                    lambda _: bm.random.normal(a, b * p, self.target_shape),
+                    lambda _: bm.random.binomial(self.num_input, p, self.target_shape),
                     None)
     return inp * self.weight
 
   def __repr__(self):
     names = self.__class__.__name__
     return f'{names}(shape={self.target_shape}, num_input={self.num_input}, freq={self.freq}, weight={self.weight})'
 
   def reset_state(self, batch_size=None):
     pass
 
   def reset(self, batch_size=None):
-    self.rng.seed(self.seed)
     self.reset_state(batch_size)
```

## Comparing `brainpy/_src/dyn/synapses_v2/syn_outs.py` & `brainpy/_src/synapses_v2/syn_outs.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # -*- coding: utf-8 -*-
 
 from typing import Union
 
-from brainpy._src.dyn.synapses_v2.base import SynOutNS
+from brainpy._src.synapses_v2.base import SynOutNS
 from brainpy.math import exp
 from brainpy.types import ArrayType
 
 __all__ = [
   'COBA',
   'CUBA',
   'MgBlock',
```

## Comparing `brainpy/_src/dyn/synapses_v2/syn_plasticity.py` & `brainpy/_src/synapses_v2/syn_plasticity.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 from typing import Union
 
 import jax.numpy as jnp
 
 from brainpy._src.context import share
 from brainpy import math as bm, tools
-from brainpy._src.dyn.synapses_v2.base import SynSTPNS
+from brainpy._src.synapses_v2.base import SynSTPNS
 from brainpy._src.initialize import variable_, OneInit, parameter
 from brainpy._src.integrators import odeint, JointEq
 from brainpy.types import ArrayType, Shape
 
 __all__ = [
   'STD',
   'STP',
```

## Comparing `brainpy/_src/dyn/synouts/conductances.py` & `brainpy/_src/synouts/conductances.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/dyn/synouts/ions.py` & `brainpy/_src/synouts/ions.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/dyn/synplast/short_term_plasticity.py` & `brainpy/_src/synplast/short_term_plasticity.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/layers/conv.py` & `brainpy/_src/dnn/conv.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 # -*- coding: utf-8 -*-
 
 from typing import Union, Tuple, Optional, Sequence, Callable
 
 from jax import lax
 
 from brainpy import math as bm, tools, check
-from brainpy._src.dynsys import not_pass_shared
 from brainpy._src.initialize import Initializer, XavierNormal, ZeroInit, parameter
 from brainpy.types import ArrayType
 from .base import Layer
 
 __all__ = [
   'Conv1d', 'Conv2d', 'Conv3d',
   'Conv1D', 'Conv2D', 'Conv3D',
@@ -521,15 +520,14 @@
       self.w = bm.TrainVar(self.w)
       if self.b is not None:
         self.b = bm.TrainVar(self.b)
 
   def _check_input_dim(self, x):
     raise NotImplementedError
 
-  @not_pass_shared
   def update(self, x):
     self._check_input_dim(x)
 
     w = self.w.value
     if self.mask is not None:
       try:
         lax.broadcast_shapes(self.w.shape, self.mask.shape)
```

## Comparing `brainpy/_src/layers/dropout.py` & `brainpy/_src/dnn/dropout.py`

 * *Files 17% similar despite different names*

```diff
@@ -15,43 +15,38 @@
 
   In training, to compensate for the fraction of input values dropped (`rate`),
   all surviving values are multiplied by `1 / (1 - rate)`.
 
   This layer is active only during training (`mode=brainpy.modes.training`). In other
   circumstances it is a no-op.
 
-  Parameters
-  ----------
-  prob : float
-    Probability to keep element of the tensor.
-  seed : optional, int
-    The random sampling seed.
-  mode: Mode
-    The computation mode of the object.
-  name : str, optional
-    The name of the dynamic system.
-
-  References
-  ----------
   .. [1] Srivastava, Nitish, et al. "Dropout: a simple way to prevent
          neural networks from overfitting." The journal of machine learning
          research 15.1 (2014): 1929-1958.
+
+  Args:
+    prob: Probability to keep element of the tensor.
+    mode: Mode. The computation mode of the object.
+    name: str. The name of the dynamic system.
+
   """
 
   def __init__(
       self,
       prob: float,
-      seed: int = None,
       mode: bm.Mode = None,
       name: str = None
   ):
+    """
+
+
+    """
     super(Dropout, self).__init__(mode=mode, name=name)
     self.prob = check.is_float(prob, min_bound=0., max_bound=1.)
-    self.rng = bm.random.default_rng(seed)
 
   def update(self, x):
     if share.load('fit'):
-      keep_mask = self.rng.bernoulli(self.prob, x.shape)
+      keep_mask = bm.random.bernoulli(self.prob, x.shape)
       return bm.where(keep_mask, x / self.prob, 0.)
     else:
       return x
```

## Comparing `brainpy/_src/layers/function.py` & `brainpy/_src/dnn/function.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/layers/interoperation_flax.py` & `brainpy/_src/dnn/interoperation_flax.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/layers/normalization.py` & `brainpy/_src/dnn/normalization.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/layers/nvar.py` & `brainpy/_src/dnn/nvar.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 
 from itertools import combinations_with_replacement
-from typing import Union, Sequence, List
+from typing import Union, Sequence, List, Optional
 
 import jax.numpy as jnp
 import numpy as np
 
 import brainpy.math as bm
 from brainpy import check
 from .base import Layer
@@ -59,21 +59,21 @@
          reservoir computing. Nat Commun 12, 5564 (2021).
          https://doi.org/10.1038/s41467-021-25801-2
 
   """
 
   def __init__(
       self,
-      num_in,
+      num_in: int,
       delay: int,
-      order: Union[int, Sequence[int]] = None,
+      order: Optional[Union[int, Sequence[int]]] = None,
       stride: int = 1,
       constant: bool = False,
-      mode: bm.Mode = None,
-      name: str = None,
+      mode: Optional[bm.Mode] = None,
+      name: Optional[str] = None,
   ):
     super(NVAR, self).__init__(mode=mode, name=name)
     check.is_subclass(self.mode, (bm.BatchingMode, bm.NonBatchingMode), self.__class__.__name__)
 
     # parameters
     order = tuple() if order is None else order
     if not isinstance(order, (tuple, list)):
```

## Comparing `brainpy/_src/layers/pooling.py` & `brainpy/_src/dnn/pooling.py`

 * *Files identical despite different names*

## Comparing `brainpy/_src/layers/reservoir.py` & `brainpy/_src/dnn/reservoir.py`

 * *Files 2% similar despite different names*

```diff
@@ -123,15 +123,14 @@
     assert num_out > 0, f'Must be a positive integer, but we got {num_out}'
     self.leaky_rate = leaky_rate
     check.is_float(leaky_rate, 'leaky_rate', 0., 1.)
     self.activation = getattr(bm, activation) if isinstance(activation, str) else activation
     check.is_callable(self.activation, allow_none=False)
     self.activation_type = activation_type
     check.is_string(activation_type, 'activation_type', ['internal', 'external'])
-    self.rng = bm.random.default_rng(seed)
     check.is_float(spectral_radius, 'spectral_radius', allow_none=True)
     self.spectral_radius = spectral_radius
 
     # initializations
     check.is_initializer(Win_initializer, 'ff_initializer', allow_none=False)
     check.is_initializer(Wrec_initializer, 'rec_initializer', allow_none=False)
     check.is_initializer(b_initializer, 'bias_initializer', allow_none=True)
@@ -156,27 +155,27 @@
     check.is_string(noise_type, 'noise_type', ['normal', 'uniform'])
 
     # initialize feedforward weights
     weight_shape = (input_shape[-1], self.num_unit)
     self.Wff_shape = weight_shape
     self.Win = parameter(self._Win_initializer, weight_shape)
     if self.ff_connectivity < 1.:
-      conn_mat = self.rng.random(weight_shape) > self.ff_connectivity
+      conn_mat = bm.random.random(weight_shape) > self.ff_connectivity
       self.Win[conn_mat] = 0.
     if self.comp_type == 'sparse' and self.ff_connectivity < 1.:
       self.ff_pres, self.ff_posts = jnp.where(jnp.logical_not(bm.as_jax(conn_mat)))
       self.Win = self.Win[self.ff_pres, self.ff_posts]
     if isinstance(self.mode, bm.TrainingMode):
       self.Win = bm.TrainVar(self.Win)
 
     # initialize recurrent weights
     recurrent_shape = (self.num_unit, self.num_unit)
     self.Wrec = parameter(self._Wrec_initializer, recurrent_shape)
     if self.rec_connectivity < 1.:
-      conn_mat = self.rng.random(recurrent_shape) > self.rec_connectivity
+      conn_mat = bm.random.random(recurrent_shape) > self.rec_connectivity
       self.Wrec[conn_mat] = 0.
     if self.spectral_radius is not None:
       current_sr = max(abs(jnp.linalg.eig(bm.as_jax(self.Wrec))[0]))
       self.Wrec *= self.spectral_radius / current_sr
     if self.comp_type == 'sparse' and self.rec_connectivity < 1.:
       self.rec_pres, self.rec_posts = jnp.where(jnp.logical_not(bm.as_jax(conn_mat)))
       self.Wrec = self.Wrec[self.rec_pres, self.rec_posts]
@@ -192,33 +191,33 @@
     self.state.value = variable(jnp.zeros, batch_size, self.output_shape)
 
   def update(self, x):
     """Feedforward output."""
     # inputs
     x = bm.as_jax(x)
     if self.noise_ff > 0:
-      x += self.noise_ff * self.rng.uniform(-1, 1, x.shape)
+      x += self.noise_ff * bm.random.uniform(-1, 1, x.shape)
     if self.comp_type == 'sparse' and self.ff_connectivity < 1.:
       sparse = {'data': self.Win,
                 'index': (self.ff_pres, self.ff_posts),
                 'shape': self.Wff_shape}
-      hidden = bm.sparse_matmul(x, sparse)
+      hidden = bm.sparse.seg_matmul(x, sparse)
     else:
       hidden = x @ self.Win
     # recurrent
     if self.comp_type == 'sparse' and self.rec_connectivity < 1.:
       sparse = {'data': self.Wrec,
                 'index': (self.rec_pres, self.rec_posts),
                 'shape': (self.num_unit, self.num_unit)}
-      hidden += bm.sparse_matmul(self.state, sparse)
+      hidden += bm.sparse.seg_matmul(self.state, sparse)
     else:
       hidden += self.state @ self.Wrec
     if self.activation_type == 'internal':
       hidden = self.activation(hidden)
     if self.noise_rec > 0.:
-      hidden += self.noise_rec * self.rng.uniform(-1, -1, self.state.shape)
+      hidden += self.noise_rec * bm.random.uniform(-1, -1, self.state.shape)
     # new state/output
     state = (1 - self.leaky_rate) * self.state + self.leaky_rate * hidden
     if self.activation_type == 'external':
       state = self.activation(state)
     self.state.value = state
     return state
```

## Comparing `brainpy/_src/layers/rnncells.py` & `brainpy/_src/dnn/rnncells.py`

 * *Files identical despite different names*

## Comparing `brainpy-2.4.1.dist-info/LICENSE` & `brainpy-2.4.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `brainpy-2.4.1.dist-info/METADATA` & `brainpy-2.4.2.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 Metadata-Version: 2.1
 Name: brainpy
-Version: 2.4.1
+Version: 2.4.2
 Summary: BrainPy: Brain Dynamics Programming in Python
 Home-page: https://github.com/brainpy/BrainPy
 Author: BrainPy Team
 Author-email: chao.brain@qq.com
 License: GPL-3.0 license
 Project-URL: Bug Tracker, https://github.com/brainpy/BrainPy/issues
 Project-URL: Documentation, https://brainpy.readthedocs.io/
 Project-URL: Source Code, https://github.com/brainpy/BrainPy
 Keywords: computational neuroscience,brain-inspired computation,dynamical systems,differential equations,brain modeling,brain dynamics modeling,brain dynamics programming
 Platform: UNKNOWN
 Classifier: Natural Language :: English
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Intended Audience :: Science/Research
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Software Development :: Libraries
-Requires-Python: >=3.7
+Requires-Python: >=3.8
 Description-Content-Type: text/markdown
 License-File: LICENSE
-Requires-Dist: jax (>=0.3.0)
+Requires-Dist: jax (>=0.4.1)
 Requires-Dist: msgpack
 Requires-Dist: numpy (>=1.15)
 Requires-Dist: tqdm
 
 <p align="center">
   	<img alt="Header image of BrainPy - brain dynamics programming in Python." src="https://github.com/brainpy/BrainPy/blob/master/images/logo.png" width=80%>
 </p> 
@@ -41,17 +40,15 @@
 
 
 <p align="center">
 	<a href="https://pypi.org/project/brainpy/"><img alt="Supported Python Version" src="https://img.shields.io/pypi/pyversions/brainpy"></a>
 	<a href="https://github.com/brainpy/BrainPy"><img alt="LICENSE" src="https://anaconda.org/brainpy/brainpy/badges/license.svg"></a>
   	<a href="https://brainpy.readthedocs.io/en/latest/?badge=latest"><img alt="Documentation" src="https://readthedocs.org/projects/brainpy/badge/?version=latest"></a>
   	<a href="https://badge.fury.io/py/brainpy"><img alt="PyPI version" src="https://badge.fury.io/py/brainpy.svg"></a>
-    <a href="https://github.com/brainpy/BrainPy"><img alt="Linux CI" src="https://github.com/brainpy/BrainPy/actions/workflows/Linux_CI.yml/badge.svg"></a>
-    <a href="https://github.com/brainpy/BrainPy"><img alt="Windows CI" src="https://github.com/brainpy/BrainPy/actions/workflows/Windows_CI.yml/badge.svg"></a>
-    <a href="https://github.com/brainpy/BrainPy"><img alt="MacOS CI" src="https://github.com/brainpy/BrainPy/actions/workflows/MacOS_CI.yml/badge.svg"></a>
+    <a href="https://github.com/brainpy/BrainPy"><img alt="Continuous Integration" src="https://github.com/brainpy/BrainPy/actions/workflows/CI.yml/badge.svg"></a>
 </p>
 
 
 
 
 BrainPy is a flexible, efficient, and extensible framework for computational neuroscience and brain-inspired computation based on the Just-In-Time (JIT) compilation (built on top of [JAX](https://github.com/google/jax), [Numba](https://github.com/numba/numba), and other JIT compilers). It provides an integrative ecosystem for brain dynamics programming, including brain dynamics **building**, **simulation**, **training**, **analysis**, etc.
```

### html2text {}

```diff
@@ -1,31 +1,31 @@
-Metadata-Version: 2.1 Name: brainpy Version: 2.4.1 Summary: BrainPy: Brain
+Metadata-Version: 2.1 Name: brainpy Version: 2.4.2 Summary: BrainPy: Brain
 Dynamics Programming in Python Home-page: https://github.com/brainpy/BrainPy
 Author: BrainPy Team Author-email: chao.brain@qq.com License: GPL-3.0 license
 Project-URL: Bug Tracker, https://github.com/brainpy/BrainPy/issues Project-
 URL: Documentation, https://brainpy.readthedocs.io/ Project-URL: Source Code,
 https://github.com/brainpy/BrainPy Keywords: computational neuroscience,brain-
 inspired computation,dynamical systems,differential equations,brain
 modeling,brain dynamics modeling,brain dynamics programming Platform: UNKNOWN
 Classifier: Natural Language :: English Classifier: Operating System :: OS
 Independent Classifier: Programming Language :: Python Classifier: Programming
-Language :: Python :: 3 Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8 Classifier: Programming
-Language :: Python :: 3.9 Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11 Classifier: Intended
-Audience :: Science/Research Classifier: License :: OSI Approved :: Apache
-Software License Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
-Classifier: Topic :: Scientific/Engineering :: Mathematics Classifier: Topic ::
-Scientific/Engineering :: Artificial Intelligence Classifier: Topic :: Software
-Development :: Libraries Requires-Python: >=3.7 Description-Content-Type: text/
-markdown License-File: LICENSE Requires-Dist: jax (>=0.3.0) Requires-Dist:
-msgpack Requires-Dist: numpy (>=1.15) Requires-Dist: tqdm
+Language :: Python :: 3 Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9 Classifier: Programming
+Language :: Python :: 3.10 Classifier: Programming Language :: Python :: 3.11
+Classifier: Intended Audience :: Science/Research Classifier: License :: OSI
+Approved :: Apache Software License Classifier: Topic :: Scientific/Engineering
+:: Bio-Informatics Classifier: Topic :: Scientific/Engineering :: Mathematics
+Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
+Classifier: Topic :: Software Development :: Libraries Requires-Python: >=3.8
+Description-Content-Type: text/markdown License-File: LICENSE Requires-Dist:
+jax (>=0.4.1) Requires-Dist: msgpack Requires-Dist: numpy (>=1.15) Requires-
+Dist: tqdm
        [Header image of BrainPy - brain dynamics programming in Python.]
-[Supported_Python_Version] [LICENSE] [Documentation] [PyPI_version] [Linux_CI]
-                            [Windows_CI] [MacOS_CI]
+[Supported_Python_Version] [LICENSE] [Documentation] [PyPI_version] [Continuous
+                                 Integration]
 BrainPy is a flexible, efficient, and extensible framework for computational
 neuroscience and brain-inspired computation based on the Just-In-Time (JIT)
 compilation (built on top of [JAX](https://github.com/google/jax), [Numba]
 (https://github.com/numba/numba), and other JIT compilers). It provides an
 integrative ecosystem for brain dynamics programming, including brain dynamics
 **building**, **simulation**, **training**, **analysis**, etc. - **Website
 (documentation and APIs)**: https://brainpy.readthedocs.io/en/latest -
```

## Comparing `brainpy-2.4.1.dist-info/RECORD` & `brainpy-2.4.2.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,289 +1,308 @@
-brainpy/__init__.py,sha256=2q2Swmr9eI32d6f1xzd2nXIqZ8yktIxHYKtRhGg1ZBo,10037
+brainpy/__init__.py,sha256=tsETtMpJicaRLBe361OUWPU1aRBSA9NatfulLqZH_l4,10155
 brainpy/analysis.py,sha256=1F9j_gVbbZeE4vbtnWm3aZQnsiRFQH5jawh8idpUI54,661
 brainpy/channels.py,sha256=_IghoZjZTtLWzb8eT6iCBY2zjZOLuRuo8FuQ51DAJgs,1308
-brainpy/check.py,sha256=E1quhDXU2npIgMgtF0Rj36wL-yIPzCCqG3svWhjSFWA,18712
-brainpy/checkpoints.py,sha256=QPhbn5QQC2a7lXiqQ3GQD70l0c_6-QRvP9TtXkSR21s,245
-brainpy/connect.py,sha256=xlZkOkM01D0DbtjbqNl5sCpbUQEpFT0cHeCcbfXTdXA,1243
+brainpy/check.py,sha256=MEGRzRe8yuFuQ3bLukAnUK1jkai0iqgxQpuWhPrdZ-U,19357
+brainpy/checkpoints.py,sha256=HVQLY0VkJ8K0dkOeVSmrZr6gmfTz7turFNRkkwnfwac,407
+brainpy/connect.py,sha256=attHF6pF-uf63E95mp2IyixIXDdy1mufGEbtUiFuGIs,1275
+brainpy/dnn.py,sha256=BuSWGifJqHB3YJBjdpQZS_358GqNdOLaGMorgEvT6LQ,2690
 brainpy/encoding.py,sha256=UAr-ouj1z3kktUUZUL79YL1TxkCI6cL0LhE4DiEAW2Q,324
-brainpy/errors.py,sha256=9xG8gfM6ClgQLUUIVyT2v-wv3guAAQqIGaHYVbspyOY,8551
-brainpy/experimental.py,sha256=Mln_QBtd3fD0ONY8p-nhXvk0sw5a5nGMEbH_eaajHzw,350
+brainpy/errors.py,sha256=te_PNK5GduoEDpX0QLnqaMNFMU0RDG-kxkfVEwWAUVY,7520
+brainpy/experimental.py,sha256=Q8rOmhQecwVNKdo2CKaIb0GvRcsB3zat3-qX7NOUAxU,334
 brainpy/initialize.py,sha256=Vh-Oao7TunLnXLNLlhTJlAfVKWQ-2tLMNThBCj_g68E,1123
 brainpy/inputs.py,sha256=EieFIsSPhoYdC8w8RSFgDPHO8gpphZZqS1z3JOP58Q0,335
-brainpy/layers.py,sha256=7Fj8ZJ1CdOk24PKJc7WkSL6Whg_LRikTwXGqmzPSVYU,1944
-brainpy/losses.py,sha256=XKVUmkogSaZ5YXHob3zxu_nd2dWezWb3KzGlgMsZF0c,963
+brainpy/layers.py,sha256=UZhDVzO0tSqGfHFNHZ9ntLI0qUeH8HX2WQ24aj03R9U,20
+brainpy/losses.py,sha256=buIh5f-o0QI1_H-MYaayuEOcW1cTrQno5QINY8yfX7I,1086
 brainpy/measure.py,sha256=bAKe5XqcfP50j2H96ZcTIJmVvNHwBGxGQppoEsQK_gI,487
-brainpy/neurons.py,sha256=SYkdRcazcLyT9qgGIQ9QEihaDJV8N52s9dmvrtsU9rw,1033
+brainpy/mixin.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+brainpy/neurons.py,sha256=_XzpTdSdBz7lYaHNJp9r0wdYbyAHW7QERZCeUWmeTVc,1013
 brainpy/optim.py,sha256=ShG_NXD334Ns_wqh0L7e-sINzTEoPW7hLI1B-j8Clhs,1013
-brainpy/rates.py,sha256=viLA85gOdh_Ytq0DOr_PtcZJ6c66uoWYYCcY0IXvAcI,303
+brainpy/rates.py,sha256=lfddb1qSEoacvLH9MPosTE6rzuJMo_1c5x46tLzpkmw,299
 brainpy/running.py,sha256=ZGjJH40qBJjNzo9WWuyd9CrMf1vNFd27cN9qwPoDnnw,466
 brainpy/testing.py,sha256=4unb3IJCji-0CO5PaZsP_9727UnKlbOEoJmTthCPFK8,51
-brainpy/tools.py,sha256=3b1mi6rjbVibPNpjiuJJa1LovCZrYRKW_0ELGUgcepU,951
-brainpy/types.py,sha256=R1V1eV0tSa8_0WDGkgEqg1ld7YVkSkbT6K2Z1aFGEsM,241
-brainpy/_src/__init__.py,sha256=iwhKnzeBJLKxpRVjvzwiRE63_zNpIBfaKLITauVph-0,24
-brainpy/_src/checking.py,sha256=XZcjpTOyjAVt2QEQVNWU4VVpUPS9hpi1mlIqHR03_Cw,924
-brainpy/_src/context.py,sha256=VNTJMOaBJwfzhUjPm7DPOuGhvHoPE2XCm6QF2XqDGO8,2622
-brainpy/_src/delay.py,sha256=A511SnGNDqhcEONOjTBJicb9AorjrihuQeuSK0Zy_lk,9982
-brainpy/_src/dynsys.py,sha256=G0YHBGI5Pi6w4E4_tPrHzzeji21ArgWOwd79-VpmXco,48588
-brainpy/_src/modes.py,sha256=MdT2qLBIjFsFpwxEqKcGNYp4tYdYmHvzc56oHBRzFcQ,119
-brainpy/_src/test_check.py,sha256=VyysbnG4CDSxE8cyogvnLD1HrLtIFtj0MQhq_hTGDIM,1359
-brainpy/_src/types.py,sha256=YmZTriSbfJdQLLmq_y5VhRMFwfR7GVmaPq96wPHHbZw,976
+brainpy/tools.py,sha256=E-8tyzS5mxZ4GLxSkwREsj8D_FHAgrzddViiVAWsJnE,1046
+brainpy/types.py,sha256=ivDEcU3XoFeMVrCsHH5f_NmvtGqh59lMpi2kRbjmt98,265
+brainpy/_src/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+brainpy/_src/_delay.py,sha256=vo1GQWsI6M-T5ti6KpTzQAqjoKsQZ7RwgAKwHnVj1QU,9945
+brainpy/_src/checking.py,sha256=idG-wjzyB8kW9NJh1qqtQmSFTwfePVC28juRW__QioA,2457
+brainpy/_src/context.py,sha256=aCzixPHjFGgbkBuaMsUYfoF7OEVjw2PAekIrFeukv8Y,2631
+brainpy/_src/delay.py,sha256=xC5UM65wP2kwPAnstywQ8kWtgci0vNVXds-wI1WbS9A,22860
+brainpy/_src/deprecations.py,sha256=X79H4rN7yQxtdRMXFN7DYqOdBVrqny-Dfs3sxXW8QLE,1500
+brainpy/_src/dynsys.py,sha256=rh3xEotti_r0udflOyVnCGNnJbNqlBGfGA4isL9crRk,49179
+brainpy/_src/mixin.py,sha256=CUttHHGMbW5H1qD4y7IFTrfgmrkmE29JOTlbj72lodI,2328
+brainpy/_src/modes.py,sha256=9UNgQyOgp0h8Ky7z394ZyF0XM6xQXeMqiD4erEe4Svg,1101
+brainpy/_src/runners.py,sha256=lvm5sNACiQWlwWRf0eIMPAlDWovc1fMjSWd2whnOaOI,24973
+brainpy/_src/transform.py,sha256=61dEagNWUuvcL18JVd2JslBaWbvKuRX78RIW4d8rjE4,10267
+brainpy/_src/types.py,sha256=39V_8jqDeFq_gEGFtz3eKh7VdzGDiKnE1lmpiu8HWLc,1065
 brainpy/_src/analysis/__init__.py,sha256=LvgnPFbrO99KqhQncgovd8qRSagRYjudppkyW3jjydk,846
 brainpy/_src/analysis/base.py,sha256=Elojhf3EVObjW0BHhXSivgrKO86lgYPDg-strF-Xefg,156
 brainpy/_src/analysis/constants.py,sha256=vh_jBcUaqVgsJWe8GxyJKMNOKa30F5ijPjj5BMjs2z0,1721
 brainpy/_src/analysis/plotstyle.py,sha256=3QPU2ZIHgEQtrXlr4-pKLy2NS4KXr8CiH9TLBGXblmY,3924
 brainpy/_src/analysis/stability.py,sha256=h6dY4j-zNI0r2nil5yHyVqkHErZcL6BYEtPUJ6s1yj0,5651
 brainpy/_src/analysis/highdim/__init__.py,sha256=VEjW7stN-EyTUIfh2bwZzMKip9N6TOrLtBtp7K5serA,52
-brainpy/_src/analysis/highdim/slow_points.py,sha256=a6-Bp9Y_V5xe4rWpXUmeG5Awh6Hp8q0ChMcpAX5fVVg,30951
+brainpy/_src/analysis/highdim/slow_points.py,sha256=Y-GfBaIdr-xdrTRacuEb_euMEp9Smt2NdCBTCBM3Tp4,30947
 brainpy/_src/analysis/lowdim/__init__.py,sha256=LmcgMjhR2WDLRlcGHiiVpYAKEDlHs-NF-XOT7B9Vi9M,93
 brainpy/_src/analysis/lowdim/lowdim_analyzer.py,sha256=D59pQNA_FwJ4D0eV-zJdQPIvhciw3TiYuJzAUMlUJK8,44743
 brainpy/_src/analysis/lowdim/lowdim_bifurcation.py,sha256=_YwjI6mq1I4d1RUKDiAGvBKLur_7VadSE6UMfdvlSdw,25000
 brainpy/_src/analysis/lowdim/lowdim_phase_plane.py,sha256=SUXjCKl-MyK1ugLDvprB-0dNLFWf596WfmN0NK8hZCw,20273
 brainpy/_src/analysis/utils/__init__.py,sha256=hsynCeksFHyhL0AMX3-IvPhcnVD0jjXAFO3G7K1UckM,199
 brainpy/_src/analysis/utils/function.py,sha256=bjVGfcoygD8HIrDLLpCcL1ii2i20rv9a-G6jVRodlJM,2840
 brainpy/_src/analysis/utils/measurement.py,sha256=w_CMQq7y0CDq_xzaxsC7yEIFKVSrNLF6CA1cQedUlc4,3054
-brainpy/_src/analysis/utils/model.py,sha256=k7G5HtqiF1G3gG0uPcXxoX84vjjXNnB1fVjiRjYmH-A,5302
+brainpy/_src/analysis/utils/model.py,sha256=kBjkcCtLXFapYj8meQWMeI_TFK-47t0G1zxvF3yiP30,5298
 brainpy/_src/analysis/utils/optimization.py,sha256=FuDKkx3pmoXZpoGRd22nsb0XoQBkHvaCq7xJRwFNDHw,19554
 brainpy/_src/analysis/utils/others.py,sha256=f64tjVHTrxnFQi6uN8RL4-sCuCzHpjn1GnvD3YbbEws,5822
 brainpy/_src/analysis/utils/outputs.py,sha256=7IsgRNIouanEpTUWRf9YnN-NSd3TzfT6vuXr_mE_0Vw,158
 brainpy/_src/analysis/utils/visualization.py,sha256=ZBUO4Lv_LpNzAVot8Jp7vyBQrA7U5wRCUV5cLdPHwQY,967
-brainpy/_src/base/__init__.py,sha256=-kWNcNsRCdUeOJjbY61hNxhfhC63i9YjJV2A_I6nnMg,175
-brainpy/_src/base/base.py,sha256=iwhKnzeBJLKxpRVjvzwiRE63_zNpIBfaKLITauVph-0,24
+brainpy/_src/base/__init__.py,sha256=iAq3ty-mtEtr0_3B14Y4CDYJSMDTce5enUDFIt7Hx3Q,169
 brainpy/_src/base/collector.py,sha256=iwhKnzeBJLKxpRVjvzwiRE63_zNpIBfaKLITauVph-0,24
 brainpy/_src/base/function.py,sha256=O9CT1B2F-cVB8elT0EoCJbgkcffjvlmqteqavs4giDg,25
-brainpy/_src/base/io.py,sha256=LRPHp8IUd7wp7-iQJB6Kd7uxqyI8sonpzBf2EJpdarM,502
+brainpy/_src/base/io.py,sha256=u2EUWzj6zJIdO9F-RrAb4YsRJEjl15Hp0lEYYGq3ssI,1029
 brainpy/_src/base/naming.py,sha256=N_HOta7wY7D5JQirksRw48AB43LjMtNP1E85OR8ULJk,305
 brainpy/_src/checkpoints/__init__.py,sha256=iwhKnzeBJLKxpRVjvzwiRE63_zNpIBfaKLITauVph-0,24
 brainpy/_src/checkpoints/io.py,sha256=gQZbjzKM6o41bYjeAhf7uFTQwNG_HVZ9MTEzGTxR__I,12240
-brainpy/_src/checkpoints/serialization.py,sha256=yKxoTJhoGTe9OpioYFcj_IetQHn5Hx7Hxcw6WjCTnis,57388
+brainpy/_src/checkpoints/serialization.py,sha256=AxDYWrB6CT1pzOIFLANsxw2T-bgr3ltaFgnyv1qdbMQ,57361
 brainpy/_src/connect/__init__.py,sha256=BQDEgFkQ2WZPnLRUlc5OfDKHDhEgvMYdoBGtIXZUfKI,268
-brainpy/_src/connect/base.py,sha256=dR7zxftU48fBInhGMNKln81qzCjFW7bm-1k0vo0HV4Q,24303
+brainpy/_src/connect/base.py,sha256=erc5Lu2oyoPssUXrAnDumqM31zf8QTYCJI24EvalvhI,24714
 brainpy/_src/connect/custom_conn.py,sha256=a7C9F0nD8I_I5IGu5FId1KCueqJNJk1nAfXXjYa-hmQ,4210
-brainpy/_src/connect/random_conn.py,sha256=RwHQCiqWJbMq1foSAnL15A1IaDD77rJDScjLUUA7vzE,39143
+brainpy/_src/connect/random_conn.py,sha256=MHWm-swGqfWsF1HmXvTznvYo4sdXxMS77pZlII26HhA,40725
 brainpy/_src/connect/regular_conn.py,sha256=x1EV_1KwKPTiAyy7geODNmhogRUNvCg_8Pptcp5yqho,9173
-brainpy/_src/dyn/__init__.py,sha256=DDQ3pUZcaWsX_kVSl80d0vZ--8D3kuB5IfJPxdfcxbE,338
-brainpy/_src/dyn/_utils.py,sha256=dGm-K409kpoHuWoKUg8CkZZukvfoecIA9zR-i7263-Q,636
-brainpy/_src/dyn/runners.py,sha256=92Qb7zwtltJwst5r1kAbrbmlb4bZouV2BuNJ7meiLDE,24972
-brainpy/_src/dyn/transform.py,sha256=61dEagNWUuvcL18JVd2JslBaWbvKuRX78RIW4d8rjE4,10267
+brainpy/_src/dnn/__init__.py,sha256=9DokGkdhI5OnbcT5Js6jmoLRy4vLYVsB7qNiJ04KiIg,295
+brainpy/_src/dnn/activations.py,sha256=RygZ8dg1epkOdbkNyXyr7LFBrvaKDZACrVxVZbW66WQ,32514
+brainpy/_src/dnn/base.py,sha256=wChhfWI61jOh2LqrJZx7l6Bi5jnMSbHLEitaP-bpg6g,197
+brainpy/_src/dnn/conv.py,sha256=eQ7QGCd-3UBHgm60s4AfPuwCx-Zd22SvFsqHRd0jdTM,29730
+brainpy/_src/dnn/dropout.py,sha256=7ldgz5QtOMmII7E1F3QNfSn3n9nm3s4i9qec1idndNs,1302
+brainpy/_src/dnn/function.py,sha256=LYnB_9fq8zB4KylZGN1TxjDkSd_QkBu1JtKD_tDVtGA,1803
+brainpy/_src/dnn/interoperation_flax.py,sha256=AVG8MZFEKSYfbYa5eDnmtcDwwfJ5AHSeZeAaeXOMQpY,4106
+brainpy/_src/dnn/linear.py,sha256=Wi9ToB_30DdQBbB2qbPlppAyKuD8AhqOpzWIM5BIB1Y,35318
+brainpy/_src/dnn/normalization.py,sha256=g3JN8i-nt9NcSrcdLeJhM9EBpyjDlbhumlyj_p3qBfA,25687
+brainpy/_src/dnn/nvar.py,sha256=5x3nQtI_WtsrgasSgXesHsT0-3oW51u7uk6h-7mzV-w,6732
+brainpy/_src/dnn/pooling.py,sha256=iF6SaiTor5EMyTavSRX4QqSba_o0-VdRk-Y24yLmEZ8,34199
+brainpy/_src/dnn/reservoir.py,sha256=XvvksZG2ue2VfVKSSlT7daWcuxsZ78-CtyMg1ue5aHA,8875
+brainpy/_src/dnn/rnncells.py,sha256=jDuSIOvLhGztwkvE2LG31f4WgB5FaFjE7DDtFHxMd0Y,27026
+brainpy/_src/dyn/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+brainpy/_src/dyn/_docs.py,sha256=LwrXyrccdd2S0SWdaQ4Ou4Fb0Z4qkzWJDITfjHtz-lk,1382
+brainpy/_src/dyn/base.py,sha256=W187iqJhxuOk2tkEaM8WkNe5y55p3YsgKVXVVQPptho,4882
+brainpy/_src/dyn/projections.py,sha256=ucOH7j9OxRBdtLaJ4q1DH2GdMRgEdubilLB8hEffm00,5485
 brainpy/_src/dyn/channels/Ca.py,sha256=DMKpsH3cY2C4gfFV_TAq9EP2rW28-CnWdu4JLP9bIg8,40139
-brainpy/_src/dyn/channels/IH.py,sha256=Tf0D3V49EgFk9b3jBSb2ZxgX55knFNbfWACZ183tLVQ,9130
-brainpy/_src/dyn/channels/K.py,sha256=HHqKG8-7h7bvcd3tGeMj2Or4D4LS9Jxj6Wo8trY7n-o,35637
+brainpy/_src/dyn/channels/IH.py,sha256=XZGkK64wIhyPQLFsVlVadJ7aNEq7C83Ykyq7bqHjljE,9190
+brainpy/_src/dyn/channels/K.py,sha256=1HI-Fb3H4kQmEccknvTVw8CWNyez3Z174bKFJfd0Zqw,35645
 brainpy/_src/dyn/channels/KCa.py,sha256=2kNF5cUHQBJNj-wEISxe0_Bisqvv4BWNAh_Dt_Id-M4,4491
 brainpy/_src/dyn/channels/Na.py,sha256=doSFKYMaXKiUFtz0vierNF2UT3FbJOwqP8cZNTxQajU,11936
 brainpy/_src/dyn/channels/__init__.py,sha256=PDPYmDDQCato2ZvBOXj0ueUSgkiW13hm4GNdQJn0kOI,423
 brainpy/_src/dyn/channels/base.py,sha256=ISv1CWBJyJaZajNdn0aIfDxCFicIYtxW423EhD1oR_I,4039
 brainpy/_src/dyn/channels/leaky.py,sha256=3r92utKkj67P6pNIgWQ5Uo-06mx0If-F3TwFLbF8HX4,2102
-brainpy/_src/dyn/networks/__init__.py,sha256=iwhKnzeBJLKxpRVjvzwiRE63_zNpIBfaKLITauVph-0,24
-brainpy/_src/dyn/networks/cann.py,sha256=ZmITc-6kzBLx3Zx-cAio0Lk5KH7epci088_jSsy5XlU,250
-brainpy/_src/dyn/neurons/__init__.py,sha256=xlEq2G7WQWqMnTz7zLmRbCUPAXDl5xELJGpvEscFMQk,177
-brainpy/_src/dyn/neurons/biological_models.py,sha256=hBejVn4A5JUYSfpZIMB860viyJ-JWD8rDQv6tDHHHEo,48741
-brainpy/_src/dyn/neurons/compat.py,sha256=YTPVRatOoivZ7C6YL4FAUf83WflrGYSX0GNyxrCzioA,595
-brainpy/_src/dyn/neurons/fractional_models.py,sha256=h88lQn1cA59HV_FIcDTyLDnwphuX_dHFBbmcEL28OEI,13124
-brainpy/_src/dyn/neurons/input_groups.py,sha256=Pokaypfd3Afnt-6EfjQodzs80lCQGkssMvxF05OucNQ,5632
-brainpy/_src/dyn/neurons/noise_groups.py,sha256=zap3NnfkCQbUMZTKJwjJ86SrmBLzCeF0oireYgStCQc,2311
-brainpy/_src/dyn/neurons/reduced_models.py,sha256=qxw50y6bess8v0bysdw229vC3O2uoiB4Y9wtqaf0YGs,89191
-brainpy/_src/dyn/rates/__init__.py,sha256=biF71W-hlm9xRYQpbOWuA3jpDZ3WWGXoaOG7emElYSc,52
-brainpy/_src/dyn/rates/populations.py,sha256=ztjlYl4lekFchiRIdQ90g1ksOR5bGPqwnQ97e4j98hk,41039
-brainpy/_src/dyn/synapses/__init__.py,sha256=vnhuo80o4KyGjetcCrEb8nVbOhe-MXnO5wOHUT9VYI8,223
-brainpy/_src/dyn/synapses/abstract_models.py,sha256=YxvFfZjCa-UtE9V5QZ5tzyfqmOw3_JxBpMQw8UY5D2w,36074
-brainpy/_src/dyn/synapses/biological_models.py,sha256=u-uxH3QPE4BxjHhCIbuhYTJj9CGfk9HfZWXAfKblt8U,21863
-brainpy/_src/dyn/synapses/compat.py,sha256=WJ3QSekvWlEtt0mGBJHJBIKwk_J_qOsL_eB5NWIv6yA,10250
-brainpy/_src/dyn/synapses/delay_couplings.py,sha256=rV3xcWZJBhLvpFjjmFzLFsN3U83z1X4ysypGb4oa0EQ,11137
-brainpy/_src/dyn/synapses/gap_junction.py,sha256=57pUw6xEYfgpzWEWsbU0Cyl2C8lX2IDhYOrPwkE_zrA,2023
-brainpy/_src/dyn/synapses/learning_rules.py,sha256=jecO7rWpXLbVuYX_x20Pj6aW7MViV30GQZvwEaVVCCU,9212
-brainpy/_src/dyn/synapses_v2/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-brainpy/_src/dyn/synapses_v2/abstract_synapses.py,sha256=idvVcql1FE-kuN_XT6Ax3MmTO82kGJl7mGHMUSFf7gs,13658
-brainpy/_src/dyn/synapses_v2/base.py,sha256=zMd6CT-JEbL0uSMjCRbBQRG7M6TLYbH4hXJcrIsHcmE,4649
-brainpy/_src/dyn/synapses_v2/others.py,sha256=EAYioTpnGAMkVPstVDw0sIl9FMFdltvMTOxTFJVr7gA,2621
-brainpy/_src/dyn/synapses_v2/syn_outs.py,sha256=gojMJjSc4zJYrvwwDzefB7fzcNTBqSoIfJ8mxK7QcVs,2652
-brainpy/_src/dyn/synapses_v2/syn_plasticity.py,sha256=gfmR_uAwomvatO5NRkDpU4onwuKD5TR1QygVop7fLNw,4726
-brainpy/_src/dyn/synouts/__init__.py,sha256=0Z2hJcdyS_8FsPlHxP0oGhLj_tCS7FF5xt-rImFiIew,73
-brainpy/_src/dyn/synouts/conductances.py,sha256=-C5BQx6zuAnKIQEvRenfnL3_Gq1Eouygk5254i5LLf0,2634
-brainpy/_src/dyn/synouts/ions.py,sha256=3hNPl7hYq_rdLV4fUis6vzFfTeMwxORgex7oO5PBMyA,3279
-brainpy/_src/dyn/synplast/__init__.py,sha256=2So17UaLExSNKtLczYtfCo53b3agOcLjz2UCCPtB0S4,62
-brainpy/_src/dyn/synplast/long_term_plasticity.py,sha256=iwhKnzeBJLKxpRVjvzwiRE63_zNpIBfaKLITauVph-0,24
-brainpy/_src/dyn/synplast/short_term_plasticity.py,sha256=f8jEVTYsXkuLEiJaaoxdMx4TH_-uwouLS5bcQ38q2Qc,5168
+brainpy/_src/dyn/neurons/__init__.py,sha256=PFZ1iNJNJVQT7yuYmJaVEzZ5hOYw8VB2sRPiee1Un8Y,21
+brainpy/_src/dyn/neurons/hh.py,sha256=CWGSpq1-rbnw8VVZKJsd348vh0ubCm2U_ZR_BDISrHc,44733
+brainpy/_src/dyn/neurons/input.py,sha256=2hNeVLNfqfb9FZ6lhXatyVX3Xg2WbyIEEBlvQWaKvP8,5860
+brainpy/_src/dyn/neurons/lif.py,sha256=DPDBJJDYH9JXJNmBaxM3rOfrYIa6NyixDkQ1TJYy4Fo,84993
+brainpy/_src/dyn/others/__init__.py,sha256=A2MAv0P_hAjdLhI1sMCq3f261BPtquh4CvF55SC-Vig,28
+brainpy/_src/dyn/others/common.py,sha256=BAuUt6ZsQGp_wHYaUtdw-ujnEyjYAkNKYu9gwFObZeM,4141
+brainpy/_src/dyn/synapses/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+brainpy/_src/dyn/synapses/dynamics.py,sha256=R0P5a6ul1kyQWkKkAlV3Bjql530RrkZQUyUZUm7Oa64,28351
+brainpy/_src/dyn/synapses/outputs.py,sha256=tFx0AM4qL1G5_n4XTgqXorGwkEODory1SzvuV7FAbhU,3147
 brainpy/_src/encoding/__init__.py,sha256=Y4USQ3gijv8QEyE8Kcnq7hIsY3xQiS2lr3I85OCakiE,114
 brainpy/_src/encoding/base.py,sha256=2-q2O9HyMG-f1Y-t-BImU-u-1x_ySKsD50BCqrzzcDE,364
 brainpy/_src/encoding/stateful_encoding.py,sha256=lOu0_fEwyLID5NASynahFbWOrfKjswyw-N-IUt0-cBU,4769
-brainpy/_src/encoding/stateless_encoding.py,sha256=vuOdVUeJdeMA6qUer_dzgLUSHhMiW4_Kt7AlrYiDmJk,2249
+brainpy/_src/encoding/stateless_encoding.py,sha256=ZJWrKFGXP9TLA69efojTsmRtYaEUXsLP5D49KXHvRsg,2156
 brainpy/_src/initialize/__init__.py,sha256=BZnTMuwfTddVqmvLbwjczRYLPC_CN8yJZtu__wnZmZA,154
 brainpy/_src/initialize/base.py,sha256=xseZjikf7TWq6BL5C_WybpGHm1G9yQW-MCCvlfG0AQs,614
-brainpy/_src/initialize/decay_inits.py,sha256=OHY57x3qz30Ubx1D-Y87CQLDrJvW5VM8-o9-LQbx198,11571
-brainpy/_src/initialize/generic.py,sha256=nWzJuDhnTZpOQ-a5k81L1za8qSzX_CERKFxHBCoA28s,9310
+brainpy/_src/initialize/decay_inits.py,sha256=NDpSLBHM5IsPQ9rCPQqQX72cJtgaUdpU52OJ16gFo7s,13428
+brainpy/_src/initialize/generic.py,sha256=MByLpy7wKxWHQUi6xW4yXUxTK9Aq69bkkaEAs5zO_jg,10608
 brainpy/_src/initialize/others.py,sha256=4kD5tjDCC5ZhLah9b4Kkkfar7T4-F6F9YpvZ0MPdy2M,554
 brainpy/_src/initialize/random_inits.py,sha256=d9tHTwEaSiaVaThn36exKXq4cia-XqKv4K1vFQqaeb8,13534
 brainpy/_src/initialize/regular_inits.py,sha256=fXh7J2Rr0IfNA_MfbxbRlyCXylp0lDwpRgQSqIu062c,2266
 brainpy/_src/inputs/__init__.py,sha256=x-dZso4oLYPaO37Ajz3RgyexdM0MrkpE32xGIBHAMv8,173
-brainpy/_src/inputs/currents.py,sha256=MV_SOEWqA9yf0MWseBV7CRaYoFGrQ0Z84DfIZxMarLA,11406
+brainpy/_src/inputs/currents.py,sha256=ZDHZmMRuWLsYpgeKuuvGScZ_U0CIXU7jgFR4pUNBY0A,11432
 brainpy/_src/integrators/__init__.py,sha256=lPnfiLZ8kqEMgmy6vpreYmHSz5SvUBAqYfzwuFDuTJg,1189
 brainpy/_src/integrators/base.py,sha256=0TpLuvfkCwKBGnwttn5Ud3hkfEI26qHrVJgiMlo-RGU,4154
 brainpy/_src/integrators/constants.py,sha256=HnKOsxGXHYUILHgDSjaYgi-lOWrKFh-MnbypNdIt_UI,2946
 brainpy/_src/integrators/joint_eq.py,sha256=CCUtWv14nyimOc4NeSQAUXSZ_ldkPI6ZHLVzBS6tfIc,8158
 brainpy/_src/integrators/runner.py,sha256=IaTFJxtdZUZ92HVDbQq8AogmAhpDiEWnNscrptoDuTM,11802
 brainpy/_src/integrators/utils.py,sha256=JgwnAOGEwqrpa8XkZo30mZmOVbHib3Pp7_PSiLZyqwc,4455
-brainpy/_src/integrators/fde/Caputo.py,sha256=oW6_jWiFRNp4ZEnjWR3xFyVDODcYJ1K7qnAMY94VZpE,15058
+brainpy/_src/integrators/fde/Caputo.py,sha256=pN-pvFQ_IsFuRXHlz8EhitRkMx4JtnG6bV07al1RuWA,15040
 brainpy/_src/integrators/fde/GL.py,sha256=gzQBLjas2xihwgovuBSNNxLo1WXVennkVJnjzDVAuEM,7233
 brainpy/_src/integrators/fde/__init__.py,sha256=i3NIsv-0zacq2SILhbLoDykdnX1OIHnz7uVazFLv95I,110
 brainpy/_src/integrators/fde/base.py,sha256=YJLBNm7uIEA2GKf2vvLkT0z9uUYulMoISKdfOlXV0uw,2771
 brainpy/_src/integrators/fde/generic.py,sha256=zFfKmvOIyS8_CnWDKceRYK-FsHhfO_Jf-jGb2Nph6wY,2706
 brainpy/_src/integrators/ode/__init__.py,sha256=aX9ioVcUyyzTe55DJxjZMx54znbGjKpvt7y1KNJQRko,220
 brainpy/_src/integrators/ode/adaptive_rk.py,sha256=MHGcrraQG43A886TZcFD05eGFlTe6JKxURyrFmr1_5A,17892
 brainpy/_src/integrators/ode/base.py,sha256=YraM5qO9m5hsWvzmFbQ5p0pWpIaC2KsfZ4ddBD_8DZk,4845
 brainpy/_src/integrators/ode/common.py,sha256=shreGp53Qg8i602ZDQa0qurMWpAbOP7djSLsc1UZBqw,1493
 brainpy/_src/integrators/ode/explicit_rk.py,sha256=zNBYecP9JydLWxip49J-SQpP98sYHOi8OQzZVVEDsJk,25974
-brainpy/_src/integrators/ode/exponential.py,sha256=VXb1Y7wZhcSr7r__YCyhiZS8kv_yNKsKcM8JIWbAiJw,13764
+brainpy/_src/integrators/ode/exponential.py,sha256=GXC4oNsIJQxammb4UP3VSAW6HSQpEZekzZfw_ljg-tk,13756
 brainpy/_src/integrators/ode/generic.py,sha256=WnSD2LFE-Yj7nWOCN0DoY7ySG47Xc2fzR-8aMSuoVxw,4139
 brainpy/_src/integrators/pde/__init__.py,sha256=iwhKnzeBJLKxpRVjvzwiRE63_zNpIBfaKLITauVph-0,24
 brainpy/_src/integrators/pde/base.py,sha256=8lHCODxLITFBRTs1vHRNc2QpoS8VefHH3_izeyeltI4,98
 brainpy/_src/integrators/sde/__init__.py,sha256=s76hX5fgaP-zZXSf_Q03052NYzU_xkC9AUVgIreZXQA,184
-brainpy/_src/integrators/sde/base.py,sha256=-7cFMKWE5S-XPWBFWEKyGWuXna24ds8Fqn9QIrwyZBQ,3310
+brainpy/_src/integrators/sde/base.py,sha256=eFIiRCj3ictHhE7fBZWxUN3cIQIgcHJldPH8Rgl5l-s,3321
 brainpy/_src/integrators/sde/generic.py,sha256=LyBzeLCgrDLBnbiXtIAd6y_S6rVcjdgTUspXKUNdC5Q,3877
 brainpy/_src/integrators/sde/normal.py,sha256=8JweJYKdjtQetySpjqKVyljhnCPj5S_fPQ0DbGYd-dA,24171
 brainpy/_src/integrators/sde/srk_scalar.py,sha256=_ZVx_lCOXp2ofh78lskyoljnj0NTr3jPJZdcTPJu8pw,17060
 brainpy/_src/integrators/sde/srk_strong.py,sha256=E60wXEcMLcC_Vx0t4tpRwCs4lFnVpmLWtKiFVa8nAlQ,17016
-brainpy/_src/layers/__init__.py,sha256=FQIcKFYxan6dVDzzkXzW92N7ezomIMNVXFjrAsCXntQ,268
-brainpy/_src/layers/base.py,sha256=wChhfWI61jOh2LqrJZx7l6Bi5jnMSbHLEitaP-bpg6g,197
-brainpy/_src/layers/conv.py,sha256=GuIObH59HMxw5pj_4AmKF92fakldsWFANSvFTGK53ow,29797
-brainpy/_src/layers/dropout.py,sha256=MRfJFQM3lt89HSPK_SUsZ8pfZjU_pa1_vrkhEwHEkao,1468
-brainpy/_src/layers/function.py,sha256=LYnB_9fq8zB4KylZGN1TxjDkSd_QkBu1JtKD_tDVtGA,1803
-brainpy/_src/layers/interoperation_flax.py,sha256=AVG8MZFEKSYfbYa5eDnmtcDwwfJ5AHSeZeAaeXOMQpY,4106
-brainpy/_src/layers/linear.py,sha256=xXKYrGXd_2wP2MvHWPzeF1cBLjQUVoRrCIkYHBunmKM,7105
-brainpy/_src/layers/normalization.py,sha256=g3JN8i-nt9NcSrcdLeJhM9EBpyjDlbhumlyj_p3qBfA,25687
-brainpy/_src/layers/nvar.py,sha256=xqISZ1hdmhDFRqXQE_RahlzIKxIrhEjFjW17gZ5O1Q4,6687
-brainpy/_src/layers/pooling.py,sha256=iF6SaiTor5EMyTavSRX4QqSba_o0-VdRk-Y24yLmEZ8,34199
-brainpy/_src/layers/reservoir.py,sha256=JSfZ6z4am8ddTgiZzin-CMXf6i-wgbjyuFuduDeApWs,8906
-brainpy/_src/layers/rnncells.py,sha256=jDuSIOvLhGztwkvE2LG31f4WgB5FaFjE7DDtFHxMd0Y,27026
-brainpy/_src/layers/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-brainpy/_src/layers/tests/test_conv.py,sha256=9RzuElnm-r7hawVYR-nK1sdWnP69qccxUm-M-5DDcuI,4756
-brainpy/_src/layers/tests/test_pooling.py,sha256=kFEFVh3HrFrWMgfVgf2IMn7KNCOUIiAfe8pJakXjflA,5073
-brainpy/_src/losses/__init__.py,sha256=5c_OONbxlULz96DM8cXTgh0whPa1Kn83mWCktG7zqlE,276
-brainpy/_src/losses/comparison.py,sha256=--5PjPC1JILaQXauHoYijk7nv-kk7VH3ev6GdGUFcaQ,22010
-brainpy/_src/losses/regularization.py,sha256=xNWfCxMMuewW6_aqkqeFOXuph5CeSnlpo_cj9e4kdLY,2370
+brainpy/_src/losses/__init__.py,sha256=4gEwa78LS0Pr8711Kvw5mb2W2ovZQOV2ZDW__NpWCyg,274
+brainpy/_src/losses/base.py,sha256=s-9GiRz5PEZFhM1VQ9IbOR8sR1qpiidEYKsdmdxbb80,445
+brainpy/_src/losses/comparison.py,sha256=A2bdIEDKtRLTFn2G3F0CrJ_h6TtF17b5Mb6e_4UHGaE,40982
+brainpy/_src/losses/regularization.py,sha256=PR6eHqO-dXszHk9Qj9JWWPtRf9bN76pbj03Eo0xktro,2368
 brainpy/_src/losses/utils.py,sha256=36MfIfCZV2-zD19CPANwbwfl0hak7rpHl2bz_n3qUG8,792
-brainpy/_src/lsbnn/__init__.py,sha256=Brb_CL1oNOVQIhtZMcoIZ2LKz9aeGYSS_Ngsb9ohW_M,63
-brainpy/_src/lsbnn/neurons_abstract.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 brainpy/_src/math/__init__.py,sha256=O9Qw0ErmR0TYIhI4XTMeOwmtUD5R8e2TRmr-rrkRSWE,1488
 brainpy/_src/math/_utils.py,sha256=uCb4a4MqgWuWb2Q90XQm1fOd2Gpy_zZr1_M4Cp73Bp0,1792
-brainpy/_src/math/activations.py,sha256=tfA1BMeaL4cs4senPRt450U-UylFOBQlCbzVuxLjrRM,13411
+brainpy/_src/math/activations.py,sha256=pXldmiFbEqcxqTRpVaDFw0JbXmJmeba3YlspVGcAX20,18933
 brainpy/_src/math/compat_numpy.py,sha256=Iju_t16qGFigmvuCVU5azq8rx0_1o86Pd6S0h3ZDdkI,29884
 brainpy/_src/math/compat_pytorch.py,sha256=dGE5YU6UapyxwJFSehGACH7SF4R9oUZGuJKUUg3nL2U,6488
 brainpy/_src/math/compat_tensorflow.py,sha256=86I2H11zpRoyCrVSkNLpATnshdx9juVhg0VXBrqInpE,17887
 brainpy/_src/math/datatypes.py,sha256=AgZZmDKVEqTpVTM85i6HPT9GUf_YPs_ymi4p7tuR_S4,911
-brainpy/_src/math/delayvars.py,sha256=Imaei474tT8_fqGOM_yAVx5VXJZ182yRauXymTtKo_0,15918
+brainpy/_src/math/delayvars.py,sha256=wdMdEZcLVA4Okcnr2rpY1d8Q9LeaVAthBxJb-3vchpU,15861
 brainpy/_src/math/environment.py,sha256=4ChAaPrKAFeJ67bV5rGVtOdrivxkEAGu_fe7eOUkqgI,16825
 brainpy/_src/math/fft.py,sha256=NO5RqLkdor_8JXXB5cK7yQFEAVgoatk7q6T7KCvLp8k,1498
 brainpy/_src/math/index_tricks.py,sha256=tNZ63fVlO9M4hwRbztHiWwwdZ6V3dVchKoaPYC5Wb6U,8866
 brainpy/_src/math/interoperability.py,sha256=n1bWyu-QGfg9t2q6mMVitimbG-LU3TPogbigLWcdQGc,2523
 brainpy/_src/math/linalg.py,sha256=Q9Be3i9CNE8W8bK-4hKDAsz--O2zgw-U_xF0R6rGrg0,1792
 brainpy/_src/math/modes.py,sha256=KHKtSDgbzis6ebIcl_HGnjC2y_y19U5ofaWreTk5nsM,2319
-brainpy/_src/math/ndarray.py,sha256=pEvZYMhs5-EqMyXqJjy66D3RISNew42KyHXnVyxFHgo,45121
+brainpy/_src/math/ndarray.py,sha256=VeHHjZWAT6ZH9STmurKMP1RwUNKWHxYgf3pfg0YNjLA,47277
 brainpy/_src/math/others.py,sha256=QoseJ2WRoOcVw0iCQP0OfZmEj8XK_JfOLy_7Vdz8bH4,2255
 brainpy/_src/math/pre_syn_post.py,sha256=ZuJSaDwq1yZqzsYCe86xs76SKnGbcMdOwhMcmL3wh1A,15894
-brainpy/_src/math/random.py,sha256=-_M0aHXxq2xNjFCv_RYjjFX3vIih6ajVf4aDc5349lw,78615
-brainpy/_src/math/remove_vmap.py,sha256=vlzDJgkMMXdAsBk3m-qeZLvZHH87WoNwgQEFmXakTvw,2119
+brainpy/_src/math/random.py,sha256=RHzY5wtIvRfd6_MKuzxgcMVraLhSBkdH0gbwq9NJYWw,78579
+brainpy/_src/math/remove_vmap.py,sha256=qqSlj6NcKp-7iXpQc5Pp-NTEnad6cLdwl_y-JZ5aZ_U,2088
+brainpy/_src/math/sharding.py,sha256=wTn7K_BALSn_PlZy0wL_Q5xr1LXDhSyZaXqgWs7qzac,3578
 brainpy/_src/math/event/__init__.py,sha256=YhAfSQkrc_0oUXQuLbhIDI2UQ43Bl_cliT_rps545MM,61
 brainpy/_src/math/event/_csr_matvec.py,sha256=dxkjj1xMjerZIMqifDSeFy55bMSAQ4kcp4BaiyNyqEk,17787
 brainpy/_src/math/event/_info_collection.py,sha256=O1kVj-CVZbXV9QTdrLd3BNFN3PnRW5wcoRqNxdNzkTw,5062
 brainpy/_src/math/jitconn/__init__.py,sha256=qFqNeEACHCxuaidBSePVvuOWUE8A0K6LRlb0XjZo7VY,53
-brainpy/_src/math/jitconn/_event_matvec.py,sha256=CBfNPzammsXfJ9whlgKJevJO4e8eUtYbxG5gQdP_zSw,24908
-brainpy/_src/math/jitconn/_matvec.py,sha256=sbgMseZySV9YKIobr5IDRgmiFszmNLlycGFfjaFpQ64,27403
+brainpy/_src/math/jitconn/_event_matvec.py,sha256=C9z0ZeOKoQ8030Q4NgQKdsF-s7iLzFCtUMWlynCJc_U,26368
+brainpy/_src/math/jitconn/_matvec.py,sha256=M4uz7uXPNiT92I0xZHA9PnGC98P1dWdeRyQh_S8I5RU,28793
 brainpy/_src/math/object_transform/__init__.py,sha256=iV3d2uYiGe0r2aVIxqmvIJwrTcqpC0pXysISGyr23yo,914
-brainpy/_src/math/object_transform/_tools.py,sha256=qGx6Hnv3MwnFsecDhfD2pN3dhpKuKvRi0yQJ5N7nPoc,2869
+brainpy/_src/math/object_transform/_tools.py,sha256=So_GDh8Rc0hjGjY6XBQkw4wzDgBIkTgMXO-AMSFO-4E,3615
 brainpy/_src/math/object_transform/_utils.py,sha256=VMIQvLnpFkWoNdsDVigSnpgceNoDqcEEk_MMzkOwe3M,758
-brainpy/_src/math/object_transform/autograd.py,sha256=ifzXiN-UhHwg0MSEqVnvzKVsfnM0UYchn4tuvjGawBw,38682
-brainpy/_src/math/object_transform/base.py,sha256=Hrfu1vFDUgtxydFiUoOrt6yTAvRfuF4PlyEGFIhRvm8,22499
+brainpy/_src/math/object_transform/autograd.py,sha256=AL-e-xA-LyFs_ec7MZJD8URiaQNTKrDdNrOAXiaRwqM,40562
+brainpy/_src/math/object_transform/base.py,sha256=9ixSzP1YTqaQlLf0dMAMdlSaWpSvUS5cq_LRehABxHQ,22773
 brainpy/_src/math/object_transform/collectors.py,sha256=Zl4bm-naLRzh7HbMyA9sjZxR3u6VHFqRFvWmdDcGEC0,5931
-brainpy/_src/math/object_transform/controls.py,sha256=Es26v17dWIbSE99nsdNdEKxh23kL706-e_PJJ1-OW_o,27560
+brainpy/_src/math/object_transform/controls.py,sha256=9EXRRQZ9g6gZuS2FJBufYY90RQvacbAPsX4IhXNiO_o,32211
 brainpy/_src/math/object_transform/function.py,sha256=LqUH4_8LvbppNrYsNP1dzLXL-Tc9U3uNXrFzPXpIjhQ,2999
-brainpy/_src/math/object_transform/jit.py,sha256=3QTzOuk9IrQq_puL7dWkyuBIVDrvdudqm7tRvArcRvU,15077
+brainpy/_src/math/object_transform/jit.py,sha256=-HTPesOK2yO-hK9HFW-X-ybegMk-ZyGmad3VZ4j6T9Q,16336
 brainpy/_src/math/object_transform/naming.py,sha256=hA9pSorEw5EHYGRPZdEH51qA7v1A6ZPySwFG6YWLyb4,1637
 brainpy/_src/math/object_transform/parallels.py,sha256=t84hKHGPB0l4ddV79tvaJvIi42Bex0_qaCu21CuSCFo,17774
-brainpy/_src/math/object_transform/variables.py,sha256=FYmI0wUS09QLKR1maE377TjPCH2DJN1EFK3bazyV6zw,11821
+brainpy/_src/math/object_transform/variables.py,sha256=q4F43xMXuMWIgqSao83QznzPePcO1Fv-SYSPtuYHRBM,14573
 brainpy/_src/math/op_registers/__init__.py,sha256=asxTRD0C_nTVXs65_cn60KxMUnb6gUWZ2ATlRQZ4jRk,204
 brainpy/_src/math/op_registers/utils.py,sha256=ijkEdSi214KVyNmV2uqYMOeENNfCTHTUbkujRe0jong,1051
-brainpy/_src/math/op_registers/numba_approach/__init__.py,sha256=b3ibl-7c8nj38Vd0mjnlked9-lHD6idF4hPuKoTteBk,7130
+brainpy/_src/math/op_registers/numba_approach/__init__.py,sha256=EjD9sDhkG0Lt9rxag274Cy4B3ZjepjfmyQ3uHWIim9s,7129
 brainpy/_src/math/op_registers/numba_approach/cpu_translation.py,sha256=rwNWiUZVq8zBkg2YjzYD6mw0oPnK6e4fQ9JGL-61qpU,5129
-brainpy/_src/math/op_registers/numba_approach/test_ei_net.py,sha256=AYdZ_tSRzuHw5Wbu1AHvTroloUsLgoGbUgpkm9mNm9M,2587
-brainpy/_src/math/sparse/__init__.py,sha256=lluRRRoQJvABgXVaqbIKmxPn3wN7kHNIo6FZ_JGT2P0,116
-brainpy/_src/math/sparse/_bsr_mm.py,sha256=pLWrF2bz1Qi5HflfTCDyFy2zQAA7WEu2F73mvQucqN8,14286
+brainpy/_src/math/sparse/__init__.py,sha256=9IQnulrX6Gj9qgC3sC_KpbGZ5DuJhu2ErKXBVAXIupo,142
+brainpy/_src/math/sparse/_bsr_mm.py,sha256=GElnwanLgw-okA6MzZ1kNoiHAW4TwJ7mOXLVByFjojI,14576
 brainpy/_src/math/sparse/_bsr_mv.py,sha256=M78yp1cDzBSvXX4VsJYukd-HizhQOSvxSn8rL-ZUCYI,8134
 brainpy/_src/math/sparse/_coo_mv.py,sha256=AKbaubeBe3AAPaw15tyYx1L4hFl6-t6oLR4qLLtT6RM,7127
 brainpy/_src/math/sparse/_csr_mv.py,sha256=UsJ01nwfyRGVhLtHw0iQTykiq-hch1414NkbWhwiGfk,16697
+brainpy/_src/math/sparse/_jax_prim.py,sha256=Tmy0fV8AapBIOtIqDirjz1Zjs1Kpy6gP9S2RZ12waK4,4439
 brainpy/_src/math/sparse/_utils.py,sha256=0vh382nVZbf3A5ji_9SkgmxbctDJ6RTpG0TA1SbKFgo,5021
-brainpy/_src/math/surrogate/__init__.py,sha256=gDTtgNzpoCErgS4J7VKuIufiuPwOWvNtDHl2GVsdhkk,79
+brainpy/_src/math/surrogate/__init__.py,sha256=9qMFRG17XcBmn6hS1JRlRCHyQOS8kB5pv5VIdSTe_hU,99
 brainpy/_src/math/surrogate/_compt.py,sha256=4PuAhWPW_fGLvEixK6gNQh0ahr_hAIupGMixv6k6ujU,7216
-brainpy/_src/math/surrogate/_one_input.py,sha256=wsdhFk0AeDgFcudXj6TAZ2tprAFZTpOar6eBXbSKgMY,40736
+brainpy/_src/math/surrogate/_one_input.py,sha256=Yig2uVAx_z24jqjxtYeZpOBn0vn-71UgbgotsUsK6I8,42623
 brainpy/_src/math/surrogate/_two_inputs.py,sha256=lWyvtFUYk3FYq53zKGdW0gIYK88u26dWPUOJFz1tG_Q,1492
 brainpy/_src/math/surrogate/_utils.py,sha256=CVhDyaqzK6ddXQNyz0YYaS-T1b8U4KOMXqveles0X68,3665
+brainpy/_src/math/surrogate/base.py,sha256=cyAd-G3Fge59G-iHCUHZH9AU22PLoJDbqeXkrTVDQhY,243
 brainpy/_src/measure/__init__.py,sha256=eOAgeUH97IPxsvg1_q8SjY-ZdD8nui3h2uiGS_F-8E0,287
 brainpy/_src/measure/correlation.py,sha256=oOwNSQO6ChaaTuzLd0erD8tU6g_DjdaexknDl2O29jw,10102
 brainpy/_src/measure/firings.py,sha256=ki5MhHL0vVeMYi9Yrms3BWOlZzZ9cL-NA3nvED5YB-E,1770
 brainpy/_src/measure/lfp.py,sha256=gYsAqzHcP4V9K43-d4EioFrI39iWcebKSyiv9ONx5ZQ,3896
+brainpy/_src/neurons/__init__.py,sha256=xlEq2G7WQWqMnTz7zLmRbCUPAXDl5xELJGpvEscFMQk,177
+brainpy/_src/neurons/biological_models.py,sha256=cg9cclDGIyaj6wfAJhZn8ApGx3MAXKf004MF3n_IZ0k,48772
+brainpy/_src/neurons/compat.py,sha256=YTPVRatOoivZ7C6YL4FAUf83WflrGYSX0GNyxrCzioA,595
+brainpy/_src/neurons/fractional_models.py,sha256=h88lQn1cA59HV_FIcDTyLDnwphuX_dHFBbmcEL28OEI,13124
+brainpy/_src/neurons/input_groups.py,sha256=XjMAaSEdIRATYo1Ccrd8rKpnG9iyo0m_6WyGwwCnLWc,5477
+brainpy/_src/neurons/noise_groups.py,sha256=pixoBdjbrpyRLlkiloxB0adWBU8Y3V8ebTUk826js-w,2301
+brainpy/_src/neurons/reduced_models.py,sha256=KdG5smdfafrPfG4bhHWMOsEb0xg-iLNH5u5Sn9EZ3Jw,92062
 brainpy/_src/optimizers/__init__.py,sha256=ToxZhvkgFhL9St3jQESUSY57RsPQc_5rYFDjWSzWTsY,75
 brainpy/_src/optimizers/optimizer.py,sha256=_47vxjzn34oSa603oz8jeR_ops-l7gVbNPZUhakH6X0,41331
 brainpy/_src/optimizers/scheduler.py,sha256=e_W27P4M-ZPDEW1930d3C1BK2N4szpdjL4w4N2NjTBY,13240
+brainpy/_src/rates/__init__.py,sha256=biF71W-hlm9xRYQpbOWuA3jpDZ3WWGXoaOG7emElYSc,52
+brainpy/_src/rates/populations.py,sha256=9Lj6d8Lz9oFOGKolEu8P6iMSeDASF7SyUw3XaJ-JEeA,41216
 brainpy/_src/running/__init__.py,sha256=4EORFDW-JNEpvzsyNuBsj9Sa5Ie61TeUAY4JiRM57DY,525
 brainpy/_src/running/constants.py,sha256=ekB6jpM51xZnWCscVM1hLPw86WQtoQYnBBHpRs6SII8,269
 brainpy/_src/running/jax_multiprocessing.py,sha256=rmd_voTmREb4etkOODkPAdNcfkxKOk3-YsIHrT7V1Ao,4913
 brainpy/_src/running/native_multiprocessing.py,sha256=uJgl6qX1TTGOwT-OEiGuGRuRqjM3xSpu81AxJ1Qj8Ec,2976
 brainpy/_src/running/pathos_multiprocessing.py,sha256=sSnqtbzszxIHBamt5tcUTjK2yiYiO_3GoCT1QsXLdiM,6995
 brainpy/_src/running/runner.py,sha256=mIQNxKLXgDhmJgXSe964KK4X82YWBdIPMBljocfk0LA,9779
+brainpy/_src/synapses/__init__.py,sha256=vnhuo80o4KyGjetcCrEb8nVbOhe-MXnO5wOHUT9VYI8,223
+brainpy/_src/synapses/abstract_models.py,sha256=mjIHPUqF4ALwBNsKrvk2AoQfxmXXWWAEVCAq67Dj0IY,35980
+brainpy/_src/synapses/biological_models.py,sha256=HWvU_6IE2mef-0G1XF512MesDq5zDFX73OPZmvJyCfQ,21845
+brainpy/_src/synapses/compat.py,sha256=XLesmxZTtAdA26g7xgrNHMJEsb9XsfXZNvlD-HOiAXg,10246
+brainpy/_src/synapses/delay_couplings.py,sha256=SCpXVQ0QNC_HF5YacN4iJF1RCxx5ee8vaJxQQGxs9XM,11133
+brainpy/_src/synapses/gap_junction.py,sha256=57pUw6xEYfgpzWEWsbU0Cyl2C8lX2IDhYOrPwkE_zrA,2023
+brainpy/_src/synapses/learning_rules.py,sha256=jecO7rWpXLbVuYX_x20Pj6aW7MViV30GQZvwEaVVCCU,9212
+brainpy/_src/synapses_v2/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+brainpy/_src/synapses_v2/abstract_synapses.py,sha256=k4mTi2Wj3yxNGieTdfH2u62F7pexMKgSsn1pnhvF1ak,13557
+brainpy/_src/synapses_v2/base.py,sha256=zMd6CT-JEbL0uSMjCRbBQRG7M6TLYbH4hXJcrIsHcmE,4649
+brainpy/_src/synapses_v2/others.py,sha256=4560N_0GET9g3Hxe5zOVlc9ssyRBm-K_qDc0beyBlwI,2553
+brainpy/_src/synapses_v2/syn_outs.py,sha256=oAyhBD12RXthnaCOXeTy7i9nEuYygIiVfi_ozyRXh0o,2648
+brainpy/_src/synapses_v2/syn_plasticity.py,sha256=TfvsoTeEHQhk7Mn1OZAqFclKicThaAwARW6DCgxd8Ks,4722
+brainpy/_src/synouts/__init__.py,sha256=0Z2hJcdyS_8FsPlHxP0oGhLj_tCS7FF5xt-rImFiIew,73
+brainpy/_src/synouts/conductances.py,sha256=-C5BQx6zuAnKIQEvRenfnL3_Gq1Eouygk5254i5LLf0,2634
+brainpy/_src/synouts/ions.py,sha256=3hNPl7hYq_rdLV4fUis6vzFfTeMwxORgex7oO5PBMyA,3279
+brainpy/_src/synplast/__init__.py,sha256=2So17UaLExSNKtLczYtfCo53b3agOcLjz2UCCPtB0S4,62
+brainpy/_src/synplast/long_term_plasticity.py,sha256=iwhKnzeBJLKxpRVjvzwiRE63_zNpIBfaKLITauVph-0,24
+brainpy/_src/synplast/short_term_plasticity.py,sha256=f8jEVTYsXkuLEiJaaoxdMx4TH_-uwouLS5bcQ38q2Qc,5168
 brainpy/_src/testing/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 brainpy/_src/testing/base.py,sha256=FswvOzYoom9RYaL34v3YRynynAkUTnwJ_ACo_HBXI2A,422
-brainpy/_src/tools/__init__.py,sha256=FoDJFbb3uo9xhvKaJcHVCUhOJgzZoc98pPXbLllDDBI,159
-brainpy/_src/tools/codes.py,sha256=s6veW1UF2vSTbS5dNFXbmxKPNx7Sm5-eKnRqy548O2c,7326
+brainpy/_src/tools/__init__.py,sha256=GnNGRLjUzYTbXcyMz_Y2VGybU-Gk-JpFOrbWQNGPOw4,182
+brainpy/_src/tools/codes.py,sha256=hT4Zvb3nO8Osx7GRSl_Pyfmi7eRFSvRXhewkXYHXAXk,7448
 brainpy/_src/tools/dicts.py,sha256=ctYh-jTVfsL2PSZ6Bg2g5pdj_etzHw5fq1hPLnT-7XQ,5882
+brainpy/_src/tools/install.py,sha256=n6UbYADGwjkz4J1Y4ZCzrX66JQ2IYLu_Z3S2ceTHS2M,1015
 brainpy/_src/tools/math_util.py,sha256=afNqi1UZQmP9KXmSkaOLlwVDNDLxvWMY3dgYdUKn7w8,223
-brainpy/_src/tools/others.py,sha256=KqCRiNJzUyhmqP8YH69eKJySklDXS3UKNZkvCxbxj7o,4424
+brainpy/_src/tools/others.py,sha256=nQr93gHerHu_0DuVQ15RuPsrGxO5uP-uCx3GrQudbzE,4425
 brainpy/_src/tools/package.py,sha256=xYqde4JYnIYokzLRjiw0CFWhxg-CdFz1bYMK3UT-RKA,1407
-brainpy/_src/train/__init__.py,sha256=LWAw8kdeEh4lPWRJ5CzgP0EgSkiQeQTUjXKbXHB0xk0,659
+brainpy/_src/train/__init__.py,sha256=IOuQfImvK1BfNx4pbGq-lyeNCCqTxbgHJEppVsQXQMU,562
 brainpy/_src/train/_utils.py,sha256=OY_jjyPdga4m0OU1ZKYPQRo0_7NOcw_fU3TndkW7EbI,1970
 brainpy/_src/train/back_propagation.py,sha256=ggkfkBtjPLMlZOIuypsc8tRHlpBvywA_KfnYgX0o64Q,24067
-brainpy/_src/train/base.py,sha256=gCdzIZC7AxSP5t1_sE8lkn-f4CeUqZ_gYZKTpCXUlQ8,2978
+brainpy/_src/train/base.py,sha256=uP-mKZqQQEciJ9Rfc5-QeabHmxubYH_Vw73P3d3fgtg,2974
 brainpy/_src/train/offline.py,sha256=ne9VTdP4X1EG2Q72R_OLdC2k73rgg8O6OApd-CYFmDg,10034
 brainpy/_src/train/online.py,sha256=-nkKGDH4OPf6HzJXslvv0sDde7VIGl6gkZkvjWGFQ1s,10356
 brainpy/_src/visualization/__init__.py,sha256=9jcWciqRU4d1BH4bCjuUc7u9qx_E1gyAFJFx-yDxK20,77
 brainpy/_src/visualization/base.py,sha256=A8mBH_IYD5XJYgLI8DthEjTTx-Cl6ARvNsW5w5sYohw,3544
 brainpy/_src/visualization/figures.py,sha256=_Pq10YOBDzwdYwqG2qN5B4wTW6-z_f_ti_7cxUP_BMU,841
 brainpy/_src/visualization/plots.py,sha256=FwbsaeCWijBYYylvqu0HmwOcSgX9R_7ZM22HjSbaOoM,14603
 brainpy/_src/visualization/styles.py,sha256=MkrX9e8c3bsowczpbnlVq_jhX4BjajtV2lRcvQ7mQkw,1026
 brainpy/algorithms/__init__.py,sha256=NwSgRAiSJcAHBdeuqVG98t6S6phGd6gl5cLCUSKZQPY,90
 brainpy/algorithms/offline.py,sha256=lCKCjtLlXt2CiIwMeaoowq7nAOhKHHoBg79GNoKp1Do,17344
 brainpy/algorithms/online.py,sha256=P-r3xm9xef5jnx8mw_kCz4hZ3T-rexXPMM1pHZ-ryaA,6284
 brainpy/algorithms/utils.py,sha256=-CZfyZ_7mupjU6vjRNQIwOpc4bJjsQ62xDBAhz1Dz-o,2656
+brainpy/dyn/__init__.py,sha256=3CBoNpEuBLzok0d08jEAUCsuWAR62QhpyhFsVgE4hew,121
+brainpy/dyn/channels.py,sha256=kOSx2RsHuSzDwYyDfZHolv9Og_np8ZdbLFSxrmSNId8,820
+brainpy/dyn/neurons.py,sha256=OAienl0f38_0KpfRzLa5pLPenBeXNIiJz03CQV-DfIY,737
+brainpy/dyn/others.py,sha256=ODny_ynBCK2-GWK_tSyNHWmBlBVy4ZJaRxPZBNERXGU,69
+brainpy/dyn/projections.py,sha256=qLtFL1p2JAPlJk3bIppK5qtjYp-sl3M7uGNRquArQGI,81
+brainpy/dyn/synapses.py,sha256=8_9wmEsORQ3x842Roem_0GahUu56fhHZqv63u6Bt-yM,271
 brainpy/integrators/__init__.py,sha256=Cvh3lH346n1pgnra6SkLc92uBnFp-y7QXVew5TgL5lE,128
 brainpy/integrators/fde.py,sha256=l7AexMW_0mS8D6Euovn04Vs5aCFddB6QnT8QwwurTvQ,576
 brainpy/integrators/ode.py,sha256=NI80C2t_v8Fq6rTMBxtqW78Rxm5eiuR-Dho_p0wYFpI,1061
 brainpy/integrators/sde.py,sha256=6kYyp0FDyDWvVwTeqdWPZk6RK_ktXeku5c5SqaILv9M,679
-brainpy/math/__init__.py,sha256=8mtUyDR0FNpkaFKigqhssMvR4fpWi6sqAGrxMdgtasQ,1518
-brainpy/math/activations.py,sha256=FGamOBARpRhm5DABaKAS71PVW07Bak_3Y9gM1EWHGLU,612
+brainpy/math/__init__.py,sha256=6w3Ruoe82py-NVRsIJMjer_EQwYiyoCbfxXZSmBK-3w,4768
+brainpy/math/activations.py,sha256=T85gbICpXPrLsGzY7OJY-6Bblve7Pm-Eg_we4rxOkbg,780
 brainpy/math/compat_numpy.py,sha256=F830tznz3RM758Ay3ytCAWIB4JD2I7acBjiPNhqPE80,8074
 brainpy/math/compat_pytorch.py,sha256=KxWezO2uRPzXmZVmPo--qm_DQys2hpE9fq87HqOr3mI,469
 brainpy/math/compat_tensorflow.py,sha256=UzsRTjxcA2BzsuQ5IlERHIVivi8FcTvP3RY34tXArdg,932
 brainpy/math/datatypes.py,sha256=dVThvS9GyrDwNi9Cv01lpA6gb8b-BNxDAVzNGgHDDSI,498
 brainpy/math/delayvars.py,sha256=3_MY0HYjYKaZjt9JVxrQOKp51ZnodG8U8E1LK1Y4nRs,255
 brainpy/math/environment.py,sha256=J3v2zZmBnbImTRakYZl4hjDIASjAx3pCFa8J9NTkeQ0,943
 brainpy/math/event.py,sha256=LHfeNw-sY0pA0pZBBxj_Ya5cwwyk2B7zZfsvfz5fRlY,75
 brainpy/math/fft.py,sha256=eZ0gTY081T7T4DfMrtWNCWRMglTjcgWKvg6EQ-_E5YE,402
 brainpy/math/interoperability.py,sha256=p9Zeotud2lkJ_h-8hpuA_fUcoyVJkAlkQuD5ZIzjDf0,217
 brainpy/math/jitconn.py,sha256=5p8QBrizfDtCZIFY1hs7Txja42Urjdux2gLJVgq5tSU,292
 brainpy/math/linalg.py,sha256=uV_S2R2W7N8__aKdSa7jaNJBioT56VKo8xOcdf5QLW4,470
 brainpy/math/modes.py,sha256=y1Iqpj7KJ9CvUbd080NHpCYoO4k8lOTLqxkr4sN6XzU,292
 brainpy/math/ndarray.py,sha256=Polh3tVZfHdHEt78tLJ25h2fDhvdU0tqW6NCnaa3saA,150
-brainpy/math/object_base.py,sha256=SGMa9vJA3-xcr3Gff1uGEqPGh4tcuVVmK9BY5RLpcHM,909
+brainpy/math/object_base.py,sha256=9L6wJRXSM97bh5mRGDlPapbrvsEPf8JcmXmPJx6u5po,1225
 brainpy/math/object_transform.py,sha256=srXOv7hVHhyshaUuLSdrX3sWBu7WKb6OJuwHb6g7Pfw,651
 brainpy/math/op_register.py,sha256=-CTPZo8Sv_CzfHxHBnJm233535IEbLfLEDo_pzbs3J0,127
 brainpy/math/others.py,sha256=Q5WaFgg2u8e3iuhXSaQq__OFvca-ZOy-BeLrwHasgfI,257
 brainpy/math/pre_syn_post.py,sha256=0-vfY89KIadAF5XZyN5dznjaUzPpl8XX6myFICxipGc,331
 brainpy/math/random.py,sha256=DevtUfAjobWASIsOgEq1JUBtwHino5r6okFIH_rjtM0,1770
-brainpy/math/sparse.py,sha256=xnHRqxdrqrK6B_Ht70NMdS40dtE1t23Sb3_ubmhGe8E,167
-brainpy/math/surrogate.py,sha256=YCDkiQGOCijbr0LUVqncMuknUMIPwWln3llOmMc37ng,1186
+brainpy/math/sharding.py,sha256=AOdBWKmfUMLZyisUZkINW6XXK4pefBqyOUHy66E_ltk,213
+brainpy/math/sparse.py,sha256=DGmy2wFfrCu3tgGsDxJFLlR-iAJTPM3_hI4Ei1JP-Tg,164
+brainpy/math/surrogate.py,sha256=bX-XigJ3R4Ctv3yhcErJqUt70mtDEGRBDU_xJQsm3WA,1249
 brainpy/synapses/__init__.py,sha256=OsHo0CQjonQzN2C2w1ls1PyXZiksaA22u6iyljV947I,73
-brainpy/synapses/dynamics.py,sha256=rNS9-iVD9OVFtHu2qy1LAMa0tcmgUbTrDMLyJNHELhA,612
-brainpy/synapses/synouts.py,sha256=xwEH6cOzC9NuWPvogFI7DewmPmW7MGw6A33laQELtpk,180
-brainpy/synapses/synplast.py,sha256=yYoUV58coEBONG5nJqyfWL8eIt32kbeQgEFkbiDW6r8,117
-brainpy-2.4.1.dist-info/LICENSE,sha256=awdTB1OZyMqrS8QDj8fyUDxz40eWjrqByUqj7MApebM,35100
-brainpy-2.4.1.dist-info/METADATA,sha256=wA57IBGFGVzWHKyn_iyBZzwe5W-HbsZI-vdivhmTuXM,4489
-brainpy-2.4.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-brainpy-2.4.1.dist-info/top_level.txt,sha256=5oi55xrJaqccrIi7VVShKhvGx0MjnDl0efebGKr5Omc,8
-brainpy-2.4.1.dist-info/RECORD,,
+brainpy/synapses/dynamics.py,sha256=ADPR4uUwlgqsh6NWbmtNdh1b6cHt06LS4ibektdF4HA,596
+brainpy/synapses/synouts.py,sha256=2DFTM0LFTfX7NVslwiwd8ffP4---8fVmKQzpaYh51WM,172
+brainpy/synapses/synplast.py,sha256=98xl_N491M6BXkPISLojPnLzi-VhoVazeNBl9YVu8lo,113
+brainpy-2.4.2.dist-info/LICENSE,sha256=awdTB1OZyMqrS8QDj8fyUDxz40eWjrqByUqj7MApebM,35100
+brainpy-2.4.2.dist-info/METADATA,sha256=ybFz7mzupd7OyEeUNIiwejEbiCF2agrzuVNaeZ88AWo,4131
+brainpy-2.4.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+brainpy-2.4.2.dist-info/top_level.txt,sha256=5oi55xrJaqccrIi7VVShKhvGx0MjnDl0efebGKr5Omc,8
+brainpy-2.4.2.dist-info/RECORD,,
```


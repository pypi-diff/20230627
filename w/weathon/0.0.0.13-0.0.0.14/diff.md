# Comparing `tmp/weathon-0.0.0.13.tar.gz` & `tmp/weathon-0.0.0.14.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/weathon-0.0.0.13.tar", last modified: Wed Jun 14 11:15:47 2023, max compression
+gzip compressed data, was "dist/weathon-0.0.0.14.tar", last modified: Mon Jun 26 05:56:17 2023, max compression
```

## Comparing `weathon-0.0.0.13.tar` & `weathon-0.0.0.14.tar`

### file list

```diff
@@ -1,2815 +1,2839 @@
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/
--rw-r--r--   0 runner    (1001) docker     (122)       53 2023-06-14 11:15:46.000000 weathon-0.0.0.13/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (122)      859 2023-06-14 11:15:47.000000 weathon-0.0.0.13/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (122)       72 2023-06-14 11:15:46.000000 weathon-0.0.0.13/README.md
--rw-r--r--   0 runner    (1001) docker     (122)       38 2023-06-14 11:15:47.000000 weathon-0.0.0.13/setup.cfg
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/
--rw-r--r--   0 runner    (1001) docker     (122)      423 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/configs/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/configs/examples/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/configs/examples/configuration.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/
--rw-r--r--   0 runner    (1001) docker     (122)     3655 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/cli/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/cli/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/cli/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      829 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/cli/cli.py
--rw-r--r--   0 runner    (1001) docker     (122)     1230 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/cli/download.py
--rw-r--r--   0 runner    (1001) docker     (122)     6240 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/cli/modelcard.py
--rw-r--r--   0 runner    (1001) docker     (122)     4369 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/cli/pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/cli/plugins.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/exporters/
--rw-r--r--   0 runner    (1001) docker     (122)     1255 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/exporters/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      507 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2272 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/audio/ans_dfsmn_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     2667 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      732 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/exporters/cv/
--rw-r--r--   0 runner    (1001) docker     (122)      869 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2593 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/cv/cartoon_translation_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     3619 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/cv/face_detection_scrfd_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     1245 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/cv/object_detection_damoyolo_exporter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/exporters/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7341 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/nlp/csanmt_for_translation_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4579 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/nlp/model_for_token_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     3409 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/nlp/sbert_for_sequence_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     2316 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/nlp/sbert_for_zero_shot_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4809 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/tf_model_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)    15145 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/exporters/torch_model_exporter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/fileio/
--rw-r--r--   0 runner    (1001) docker     (122)      122 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/fileio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/fileio/file.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/fileio/format/
--rw-r--r--   0 runner    (1001) docker     (122)      143 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/fileio/format/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      454 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/fileio/format/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1050 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/fileio/format/json.py
--rw-r--r--   0 runner    (1001) docker     (122)    13853 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/fileio/format/jsonplus.py
--rw-r--r--   0 runner    (1001) docker     (122)      669 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/fileio/format/yaml.py
--rw-r--r--   0 runner    (1001) docker     (122)     4254 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/fileio/io.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/hub/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    40951 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/api.py
--rw-r--r--   0 runner    (1001) docker     (122)     3649 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/check_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1395 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/constants.py
--rw-r--r--   0 runner    (1001) docker     (122)    11358 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/deploy.py
--rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/errors.py
--rw-r--r--   0 runner    (1001) docker     (122)    10249 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/file_download.py
--rw-r--r--   0 runner    (1001) docker     (122)     8958 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/git.py
--rw-r--r--   0 runner    (1001) docker     (122)     5386 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/push_to_hub.py
--rw-r--r--   0 runner    (1001) docker     (122)    12489 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/repository.py
--rw-r--r--   0 runner    (1001) docker     (122)     6535 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/snapshot_download.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/hub/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9916 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/utils/caching.py
--rw-r--r--   0 runner    (1001) docker     (122)     2978 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/hub/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    54353 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metainfo.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/metrics/
--rw-r--r--   0 runner    (1001) docker     (122)     3978 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/accuracy_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     7530 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/action_detection_evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     1925 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/audio_noise_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1454 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1726 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/bleu_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/metrics/ciderD/
--rwxr-xr-x   0 runner    (1001) docker     (122)       21 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/ciderD/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1926 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/ciderD/ciderD.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8931 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/ciderD/ciderD_scorer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8664 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/image_color_enhance_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    13387 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/image_colorization_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    10011 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/image_denoise_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/image_inpainting_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    13318 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/image_instance_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1739 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/image_portrait_enhancement_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2536 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/image_quality_assessment_degradation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1632 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/image_quality_assessment_mos_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2231 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/inbatch_recall_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/loss_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3002 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/map_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2032 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/movie_scene_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/ned_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2310 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/ocr_recognition_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2082 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/ppl_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1163 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/prediction_saving_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     4453 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/referring_video_object_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3112 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/sequence_classification_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3233 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/text_generation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/text_ranking_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5765 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/token_classification_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5703 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/translation_evaluation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5435 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/video_frame_interpolation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     8655 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/video_stabilization_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3092 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/video_summarization_metric.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7030 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/matlab_functions.py
--rw-r--r--   0 runner    (1001) docker     (122)     4771 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/metric_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     8932 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/niqe.py
--rw-r--r--   0 runner    (1001) docker     (122)     1710 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/video_super_resolution_metric.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/
--rw-r--r--   0 runner    (1001) docker     (122)      519 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1434 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/activations.py
--rw-r--r--   0 runner    (1001) docker     (122)     2700 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/affine_transform.py
--rw-r--r--   0 runner    (1001) docker     (122)     5630 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/deep_fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1322 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/layer_base.py
--rw-r--r--   0 runner    (1001) docker     (122)    14384 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/uni_deep_fsmn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14438 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/network/loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     9382 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/network/modulation_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)    15396 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/aec/network/se_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/
--rw-r--r--   0 runner    (1001) docker     (122)      515 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6475 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/complex_nn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3688 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/conv_stft.py
--rw-r--r--   0 runner    (1001) docker     (122)     2513 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/denoise_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/frcrn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1468 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/activations.py
--rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/affine_transform.py
--rw-r--r--   0 runner    (1001) docker     (122)      661 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/layer_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     5284 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/uni_deep_fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1038 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/se_module_complex.py
--rw-r--r--   0 runner    (1001) docker     (122)     9833 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/ans/unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/asr/
--rw-r--r--   0 runner    (1001) docker     (122)      585 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/asr/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/asr/generic_automatic_speech_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/asr/wenet_automatic_speech_recognition.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/itn/
--rw-r--r--   0 runner    (1001) docker     (122)      557 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/itn/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1462 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/itn/generic_inverse_text_processing.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/
--rw-r--r--   0 runner    (1001) docker     (122)      735 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14349 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     7462 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/fsmn_sele_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)     7861 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/fsmn_sele_v3.py
--rw-r--r--   0 runner    (1001) docker     (122)     3521 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2608 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/model_def.py
--rw-r--r--   0 runner    (1001) docker     (122)      908 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/generic_key_word_spotting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/nearfield/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/nearfield/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3300 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/nearfield/cmvn.py
--rw-r--r--   0 runner    (1001) docker     (122)    17496 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/nearfield/fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     6079 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/kws/nearfield/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/punc/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/punc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1466 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/punc/generic_punctuation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/separation/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/separation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2240 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/separation/layer_norm.py
--rw-r--r--   0 runner    (1001) docker     (122)    13963 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/separation/mossformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9142 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/separation/mossformer_block.py
--rw-r--r--   0 runner    (1001) docker     (122)     9004 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/separation/mossformer_conv_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/
--rw-r--r--   0 runner    (1001) docker     (122)     6905 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/DTDNN.py
--rw-r--r--   0 runner    (1001) docker     (122)     8425 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/DTDNN_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    11515 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/ERes2Net.py
--rw-r--r--   0 runner    (1001) docker     (122)      498 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14531 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/ecapa_tdnn.py
--rw-r--r--   0 runner    (1001) docker     (122)      904 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/fusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/generic_speaker_verification.py
--rw-r--r--   0 runner    (1001) docker     (122)     3630 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/pooling_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    16895 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/rdino.py
--rw-r--r--   0 runner    (1001) docker     (122)    11975 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/sv/speaker_change_locator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/audio/tts/
--rw-r--r--   0 runner    (1001) docker     (122)      474 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/tts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11845 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/tts/sambert_hifi.py
--rw-r--r--   0 runner    (1001) docker     (122)    26390 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/audio/tts/voice.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/base/
--rw-r--r--   0 runner    (1001) docker     (122)      303 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/base/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/base/base_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6994 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/base/base_model.py
--rw-r--r--   0 runner    (1001) docker     (122)      605 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/base/base_torch_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     5679 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/base/base_torch_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3647 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1812 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      490 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3806 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/
--rw-r--r--   0 runner    (1001) docker     (122)      113 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/roi_head/
--rw-r--r--   0 runner    (1001) docker     (122)      211 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/roi_head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6414 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/
--rw-r--r--   0 runner    (1001) docker     (122)      145 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6729 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      493 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7307 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_detection/action_detection_onnx.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_detection/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_detection/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9364 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_detection/modules/action_detection_pytorch.py
--rw-r--r--   0 runner    (1001) docker     (122)    12132 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_detection/modules/resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      709 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4304 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/models.py
--rw-r--r--   0 runner    (1001) docker     (122)    10276 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/s3dg.py
--rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/tada_convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    45442 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/temporal_patch_shift_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/animal_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      558 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/animal_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14141 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/animal_recognition/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     3955 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/animal_recognition/splat.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/bad_image_detecting/
--rw-r--r--   0 runner    (1001) docker     (122)      496 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/bad_image_detecting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2589 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/bad_image_detecting/bad_image_detecting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_2d_keypoints/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_2d_keypoints/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12660 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_2d_keypoints/hrnet_basic_modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     8773 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_2d_keypoints/hrnet_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_2d_keypoints/w48.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/
--rw-r--r--   0 runner    (1001) docker     (122)      601 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/cannonical_pose/
--rw-r--r--   0 runner    (1001) docker     (122)       51 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/cannonical_pose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8957 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py
--rw-r--r--   0 runner    (1001) docker     (122)     8196 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/
--rw-r--r--   0 runner    (1001) docker     (122)       98 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11552 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    12870 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/block.py
--rw-r--r--   0 runner    (1001) docker     (122)     8080 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/directed_graph.py
--rw-r--r--   0 runner    (1001) docker     (122)     2516 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/hdformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7719 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/skeleton.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/
--rw-r--r--   0 runner    (1001) docker     (122)     1216 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/LK/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/LK/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/LK/lk.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      713 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/face_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5158 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/face_landmark.py
--rw-r--r--   0 runner    (1001) docker     (122)     4563 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/facer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9075 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/model_tf.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/mtcnn_pytorch/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/mtcnn_pytorch/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/mtcnn_pytorch/src/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/mtcnn_pytorch/src/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6072 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     8519 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py
--rw-r--r--   0 runner    (1001) docker     (122)     4404 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/network.py
--rw-r--r--   0 runner    (1001) docker     (122)     5265 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cartoon/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/
--rw-r--r--   0 runner    (1001) docker     (122)      647 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3876 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/c3d.py
--rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/resnet2p1d.py
--rw-r--r--   0 runner    (1001) docker     (122)     8949 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/resnet3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      414 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13516 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/annotator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4960 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/api.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      504 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    10152 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py
--rw-r--r--   0 runner    (1001) docker     (122)     2746 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5829 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py
--rw-r--r--   0 runner    (1001) docker     (122)     8045 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    15438 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/vit.py
--rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/mlsd/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/mlsd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9896 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py
--rw-r--r--   0 runner    (1001) docker     (122)    25158 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/mlsd/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12595 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/body.py
--rw-r--r--   0 runner    (1001) docker     (122)     3894 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/hand.py
--rw-r--r--   0 runner    (1001) docker     (122)     9024 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     8031 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/controlnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/crowd_counting/
--rw-r--r--   0 runner    (1001) docker     (122)      491 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/crowd_counting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1100 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/crowd_counting/cc_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    22875 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/crowd_counting/hrnet_aspp_relu.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_attribute_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      490 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_attribute_recognition/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_attribute_recognition/fair_face/
--rw-r--r--   0 runner    (1001) docker     (122)      115 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_attribute_recognition/fair_face/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2559 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      930 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/detectors.py
--rw-r--r--   0 runner    (1001) docker     (122)     4675 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/mogface.py
--rw-r--r--   0 runner    (1001) docker     (122)     5578 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/mogprednet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6264 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/resnet.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7072 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/
--rw-r--r--   0 runner    (1001) docker     (122)       97 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7061 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5415 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/first_stage.py
--rw-r--r--   0 runner    (1001) docker     (122)     5232 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/get_nets.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/LK/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/LK/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/LK/lk.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3578 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/face_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5129 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/face_landmark.py
--rw-r--r--   0 runner    (1001) docker     (122)     4210 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/facer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4832 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/models/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4766 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/models/net.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4590 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/models/retinaface.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/
--rw-r--r--   0 runner    (1001) docker     (122)      174 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      955 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/damofd_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/
--rwxr-xr-x   0 runner    (1001) docker     (122)      192 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/
--rw-r--r--   0 runner    (1001) docker     (122)      325 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2945 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/
--rwxr-xr-x   0 runner    (1001) docker     (122)      292 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      276 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/
--rwxr-xr-x   0 runner    (1001) docker     (122)      471 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11707 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py
--rw-r--r--   0 runner    (1001) docker     (122)     4169 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py
--rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    30670 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5543 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)      289 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/
--rwxr-xr-x   0 runner    (1001) docker     (122)      361 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4202 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     3590 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py
--rw-r--r--   0 runner    (1001) docker     (122)    16146 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/
--rwxr-xr-x   0 runner    (1001) docker     (122)      270 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    46999 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/
--rwxr-xr-x   0 runner    (1001) docker     (122)      295 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11062 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6092 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py
--rw-r--r--   0 runner    (1001) docker     (122)     6395 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5970 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py
--rw-r--r--   0 runner    (1001) docker     (122)     3451 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/scrfd_detect.py
--rw-r--r--   0 runner    (1001) docker     (122)      960 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/tinymog_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/
--rw-r--r--   0 runner    (1001) docker     (122)       90 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1477 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4126 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2058 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      571 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     3719 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py
--rw-r--r--   0 runner    (1001) docker     (122)     2845 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4621 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py
--rw-r--r--   0 runner    (1001) docker     (122)     1497 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/efficient/
--rw-r--r--   0 runner    (1001) docker     (122)      327 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/efficient/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15911 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/efficient/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    20077 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/efficient/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2007 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/emotion_infer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/emotion_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/face_alignment/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/face_alignment/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2844 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/face_alignment/face.py
--rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/face_alignment/face_align.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      475 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_generation/op/
--rwxr-xr-x   0 runner    (1001) docker     (122)       89 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_generation/op/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6497 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_generation/op/conv2d_gradfix.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3104 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_generation/op/fused_act.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5922 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_generation/op/upfirdn2d.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    19998 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_generation/stylegan2.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4109 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/det_infer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12584 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/ghost_pan.py
--rw-r--r--   0 runner    (1001) docker     (122)    16846 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/nanodet_plus_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1833 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/one_stage_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5791 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/shufflenetv2.py
--rw-r--r--   0 runner    (1001) docker     (122)     8874 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1572 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/align_face.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/
--rwxr-xr-x   0 runner    (1001) docker     (122)      473 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/
--rwxr-xr-x   0 runner    (1001) docker     (122)     1080 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1977 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     7572 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8551 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/model_irse.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4744 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/model_resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     7186 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/rts_backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    31337 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/bfm.py
--rw-r--r--   0 runner    (1001) docker     (122)     1428 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/de_retouching_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2583 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/nets/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/nets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6561 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5124 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    30403 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facerecon_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    13171 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)    21235 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     8821 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/nv_diffrast.py
--rw-r--r--   0 runner    (1001) docker     (122)      277 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/opt.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/pix2pix/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/pix2pix/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    31957 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/pix2pix/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     5908 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py
--rw-r--r--   0 runner    (1001) docker     (122)      779 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    13410 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/renderer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    31247 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      484 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/fer/
--rw-r--r--   0 runner    (1001) docker     (122)      121 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/fer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     3277 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/fer/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/fer/vgg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_landmark_confidence/
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_landmark_confidence/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_landmark_confidence/flc/
--rw-r--r--   0 runner    (1001) docker     (122)      115 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_landmark_confidence/flc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py
--rw-r--r--   0 runner    (1001) docker     (122)     4932 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/hand_static/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/hand_static/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2480 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/hand_static/hand_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    10891 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/hand_static/networks.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/
--rw-r--r--   0 runner    (1001) docker     (122)     5936 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/Reconstruction.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/
--rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/Embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     4542 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/PixToMesh.py
--rw-r--r--   0 runner    (1001) docker     (122)    11301 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/Res_backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     2418 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/Surface_head.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2716 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/detectors.py
--rw-r--r--   0 runner    (1001) docker     (122)     1982 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/geometry.py
--rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/human_segmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)    11865 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     6105 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_binary_quant_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      573 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_binary_quant_classification/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2859 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_binary_quant_classification/binary_quant_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    19111 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_binary_quant_classification/bnext.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/
--rw-r--r--   0 runner    (1001) docker     (122)      500 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3920 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/image_body_reshaping.py
--rw-r--r--   0 runner    (1001) docker     (122)     6541 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    13616 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/person_info.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/pose_estimator/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/pose_estimator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12027 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/pose_estimator/body.py
--rw-r--r--   0 runner    (1001) docker     (122)     5673 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/pose_estimator/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/pose_estimator/util.py
--rw-r--r--   0 runner    (1001) docker     (122)    15760 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/slim_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      598 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      107 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    20295 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/backbones/beit_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)    17261 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/backbones/nextvit.py
--rw-r--r--   0 runner    (1001) docker     (122)     2185 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/mmcls_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1554 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/resnet50_cc.py
--rw-r--r--   0 runner    (1001) docker     (122)     5255 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_classification/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/
--rw-r--r--   0 runner    (1001) docker     (122)      704 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/adaint/
--rw-r--r--   0 runner    (1001) docker     (122)       44 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/adaint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14338 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/adaint/adaint.py
--rw-r--r--   0 runner    (1001) docker     (122)     3753 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/csrnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/deeplpf/
--rw-r--r--   0 runner    (1001) docker     (122)       66 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/deeplpf/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2575 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py
--rw-r--r--   0 runner    (1001) docker     (122)    31764 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/deeplpf/deeplpfnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     2821 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/image_color_enhance.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/
--rw-r--r--   0 runner    (1001) docker     (122)      640 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/
--rw-r--r--   0 runner    (1001) docker     (122)      122 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9385 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/ddcolor.py
--rw-r--r--   0 runner    (1001) docker     (122)     6437 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py
--rw-r--r--   0 runner    (1001) docker     (122)     9576 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/loss.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6857 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     7796 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/transformer_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6465 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6510 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/vgg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/unet/
--rw-r--r--   0 runner    (1001) docker     (122)      129 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/unet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10574 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/unet/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    10647 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/unet/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_debanding/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_debanding/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_debanding/rrdb/
--rw-r--r--   0 runner    (1001) docker     (122)       53 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_debanding/rrdb/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3005 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_debanding/rrdb/rrdb_image_debanding.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_deblur/
--rw-r--r--   0 runner    (1001) docker     (122)      510 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_deblur/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4241 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_deblur/nafnet_for_image_deblur.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4329 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/evaluation/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/evaluation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12474 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py
--rw-r--r--   0 runner    (1001) docker     (122)     3141 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/evaluation/evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/
--rw-r--r--   0 runner    (1001) docker     (122)      448 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6827 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/calibration_layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7064 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/defrcn.py
--rw-r--r--   0 runner    (1001) docker     (122)    10779 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/fast_rcnn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1220 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/gdl.py
--rw-r--r--   0 runner    (1001) docker     (122)     1732 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     4770 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/roi_heads.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    23599 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/coco_register.py
--rw-r--r--   0 runner    (1001) docker     (122)     4803 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     3595 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py
--rw-r--r--   0 runner    (1001) docker     (122)      583 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/register_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     2617 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/requirements_check.py
--rw-r--r--   0 runner    (1001) docker     (122)    11013 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/voc_register.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/
--rw-r--r--   0 runner    (1001) docker     (122)      514 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/nafnet/
--rw-r--r--   0 runner    (1001) docker     (122)     6664 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/nafnet/NAFNet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/nafnet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1627 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/nafnet/arch_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     2475 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/nafnet_for_image_denoise.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6757 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/newcrf_depth.py
--rw-r--r--   0 runner    (1001) docker     (122)    18233 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/newcrf_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    10106 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/newcrf_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    26006 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    13560 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/uper_crf_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1600 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/newcrfs_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2606 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1485 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/bts_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2819 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     2506 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8545 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/
--rw-r--r--   0 runner    (1001) docker     (122)      999 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2022 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/image_driving_percetion_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7475 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3124 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/gan_wrap.py
--rw-r--r--   0 runner    (1001) docker     (122)    21432 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/op/
--rw-r--r--   0 runner    (1001) docker     (122)      242 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/op/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6497 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py
--rw-r--r--   0 runner    (1001) docker     (122)     3094 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/op/fused_act.py
--rw-r--r--   0 runner    (1001) docker     (122)     5912 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/op/upfirdn2d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facelib/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facelib/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10514 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facelib/align_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     5955 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facelib/matlab_cp2tform.py
--rw-r--r--   0 runner    (1001) docker     (122)     9077 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/image_face_fusion.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3045 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/aad_layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8555 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/aei_flow_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     9366 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/bfm.py
--rw-r--r--   0 runner    (1001) docker     (122)    12449 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/dense_motion.py
--rw-r--r--   0 runner    (1001) docker     (122)    20604 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/facerecon_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7433 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/model_irse.py
--rw-r--r--   0 runner    (1001) docker     (122)     7790 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/ops.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/
--rw-r--r--   0 runner    (1001) docker     (122)      575 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      525 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11736 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/backbone/deeplab_resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp/
--rw-r--r--   0 runner    (1001) docker     (122)      640 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8257 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp/m2fp_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8361 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp/m2fp_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    15097 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5633 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/parsing_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      475 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2690 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7605 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/default.py
--rw-r--r--   0 runner    (1001) docker     (122)     1253 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/ade20k/
--rw-r--r--   0 runner    (1001) docker     (122)       81 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/ade20k/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12202 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/ade20k/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     5348 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/ade20k/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     7509 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/adversarial.py
--rw-r--r--   0 runner    (1001) docker     (122)     1564 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/feature_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)    19052 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/ffc.py
--rw-r--r--   0 runner    (1001) docker     (122)    11842 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/inception.py
--rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/perceptual.py
--rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/pix2pixhd.py
--rw-r--r--   0 runner    (1001) docker     (122)    13350 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/refinement.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      664 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3826 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/backbones/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)    27174 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/backbones/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9305 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      101 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3992 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/datasets/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/fastinst/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/fastinst/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14867 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6266 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8692 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/fastinst_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/
--rw-r--r--   0 runner    (1001) docker     (122)      600 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10072 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/dino_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    15407 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    18188 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     7274 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py
--rw-r--r--   0 runner    (1001) docker     (122)     2720 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     6712 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1429 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    11454 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino_swin.py
--rw-r--r--   0 runner    (1001) docker     (122)     1549 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7886 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/postprocess_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/
--rw-r--r--   0 runner    (1001) docker     (122)      553 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/config/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/config/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6991 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/config/default.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/
--rw-r--r--   0 runner    (1001) docker     (122)      171 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      588 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7244 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3784 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/
--rw-r--r--   0 runner    (1001) docker     (122)      239 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     3012 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     2994 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     9677 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10531 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)     3048 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)     2132 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     2735 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/quadtree_attention_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      344 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_matching/utils/misc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      521 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/cas_mvsnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/casmvs_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    18175 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9861 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/depth_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     9404 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/general_eval_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    21735 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/module.py
--rw-r--r--   0 runner    (1001) docker     (122)     3367 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_paintbyexample/
--rw-r--r--   0 runner    (1001) docker     (122)      507 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_paintbyexample/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_paintbyexample/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_panoptic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      513 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_panoptic_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1694 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_panoptic_segmentation/panseg_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8563 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/align_faces.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/eqface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/eqface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1836 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/eqface/fqa.py
--rw-r--r--   0 runner    (1001) docker     (122)     4710 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/eqface/model_resnet.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    22869 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/gpen.py
--rw-r--r--   0 runner    (1001) docker     (122)     7114 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/image_portrait_enhancement.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/losses/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/losses/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4336 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/losses/helpers.py
--rw-r--r--   0 runner    (1001) docker     (122)     3286 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/losses/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)     3155 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/losses/model_irse.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7313 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/models/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4845 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/models/net.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4676 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/
--rw-r--r--   0 runner    (1001) docker     (122)      533 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10076 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     3319 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5206 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_degradation/
--rw-r--r--   0 runner    (1001) docker     (122)      584 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_degradation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5064 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_degradation/degradation_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4654 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2600 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/image_quality_assessment_man.py
--rw-r--r--   0 runner    (1001) docker     (122)     5163 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/maniqa.py
--rw-r--r--   0 runner    (1001) docker     (122)    23230 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/swin.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      272 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16222 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/backbones/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     1060 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/heads/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/heads/simple_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2651 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_reid_person/
--rw-r--r--   0 runner    (1001) docker     (122)      467 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_reid_person/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5444 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_reid_person/pass_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    14108 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_reid_person/transreid_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/
--rw-r--r--   0 runner    (1001) docker     (122)      527 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/demoire_models/
--rw-r--r--   0 runner    (1001) docker     (122)       69 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/demoire_models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10243 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/demoire_models/nets.py
--rw-r--r--   0 runner    (1001) docker     (122)     2640 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/image_restoration_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      712 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7896 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py
--rw-r--r--   0 runner    (1001) docker     (122)     5155 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py
--rw-r--r--   0 runner    (1001) docker     (122)     2273 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3208 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/pan_merge/
--rw-r--r--   0 runner    (1001) docker     (122)      111 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/pan_merge/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1516 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2122 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/semantic_seg_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/
--rw-r--r--   0 runner    (1001) docker     (122)      303 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/
--rw-r--r--   0 runner    (1001) docker     (122)      290 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      249 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17484 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/
--rw-r--r--   0 runner    (1001) docker     (122)      196 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18241 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py
--rw-r--r--   0 runner    (1001) docker     (122)     6379 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      251 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    26514 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/
--rw-r--r--   0 runner    (1001) docker     (122)      253 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12370 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py
--rw-r--r--   0 runner    (1001) docker     (122)    11715 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      368 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      398 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     1938 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py
--rw-r--r--   0 runner    (1001) docker     (122)     1788 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/
--rw-r--r--   0 runner    (1001) docker     (122)      650 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9312 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/
--rw-r--r--   0 runner    (1001) docker     (122)     3740 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/BlockModules.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21275 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/hrnet_backnone.py
--rw-r--r--   0 runner    (1001) docker     (122)    18023 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py
--rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    11210 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/skychange.py
--rw-r--r--   0 runner    (1001) docker     (122)     7874 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/skychange_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      120 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/data/
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/data/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    10476 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/models/
--rw-r--r--   0 runner    (1001) docker     (122)      603 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/models/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/models/clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/ops/
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/ops/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24469 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/ops/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/ops/losses.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/data/
--rw-r--r--   0 runner    (1001) docker     (122)      127 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/data/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    10527 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/model_translation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/models/
--rw-r--r--   0 runner    (1001) docker     (122)      161 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/models/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/models/clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/
--rw-r--r--   0 runner    (1001) docker     (122)      384 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21828 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/apps.py
--rw-r--r--   0 runner    (1001) docker     (122)    36549 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/degradation.py
--rw-r--r--   0 runner    (1001) docker     (122)    24615 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/metrics.py
--rw-r--r--   0 runner    (1001) docker     (122)     6736 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/random_color.py
--rw-r--r--   0 runner    (1001) docker     (122)     2745 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/random_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     3777 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/svd.py
--rw-r--r--   0 runner    (1001) docker     (122)     6728 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      486 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      136 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4099 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py
--rw-r--r--   0 runner    (1001) docker     (122)     6931 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/misc/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/misc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/misc/fourier.py
--rw-r--r--   0 runner    (1001) docker     (122)     3251 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/misc/panostretch.py
--rw-r--r--   0 runner    (1001) docker     (122)    14887 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/misc/post_proc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/modality/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/modality/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5518 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/modality/layout.py
--rw-r--r--   0 runner    (1001) docker     (122)     3406 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/panovit.py
--rw-r--r--   0 runner    (1001) docker     (122)     4808 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1834 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/panovit.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/
--rwxr-xr-x   0 runner    (1001) docker     (122)      542 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6441 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/summarizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/
--rwxr-xr-x   0 runner    (1001) docker     (122)      508 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1900 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/layers.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7275 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/models.py
--rwxr-xr-x   0 runner    (1001) docker     (122)      826 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/modules.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2690 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/sub_layers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      639 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2151 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/cfg_sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)    26783 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    13594 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/mdm.py
--rw-r--r--   0 runner    (1001) docker     (122)     5412 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/respace.py
--rw-r--r--   0 runner    (1001) docker     (122)     3914 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/rotation2xyz.py
--rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/smpl.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      615 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/get_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     8465 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      181 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      798 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4291 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/save_op.py
--rw-r--r--   0 runner    (1001) docker     (122)    10325 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/shot_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     5057 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/trn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/
--rw-r--r--   0 runner    (1001) docker     (122)      602 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/dataloader/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/dataloader/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18782 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    20567 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/dataloader/read_write_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7297 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/nerf_preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     7876 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/nerf_recon_acc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13317 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/network/nerf.py
--rw-r--r--   0 runner    (1001) docker     (122)     1509 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/network/segmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)     5720 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/network/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      606 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3432 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/
--rw-r--r--   0 runner    (1001) docker     (122)      321 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      211 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21306 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/backbones/vit.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/dense_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      278 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/dense_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2220 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    11529 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      213 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9021 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/necks/fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      426 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      375 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8542 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      239 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17739 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      306 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21926 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/utils/checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/
--rw-r--r--   0 runner    (1001) docker     (122)      467 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2657 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/depe_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/
--rw-r--r--   0 runner    (1001) docker     (122)      605 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/
--rw-r--r--   0 runner    (1001) docker     (122)      299 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6670 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/
--rw-r--r--   0 runner    (1001) docker     (122)      282 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4476 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/
--rw-r--r--   0 runner    (1001) docker     (122)      276 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1064 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
--rw-r--r--   0 runner    (1001) docker     (122)     2041 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      294 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3095 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/
--rw-r--r--   0 runner    (1001) docker     (122)      522 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7936 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py
--rw-r--r--   0 runner    (1001) docker     (122)     8689 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      255 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12874 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      282 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7442 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    59197 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/
--rw-r--r--   0 runner    (1001) docker     (122)      255 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9533 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      256 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9032 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      562 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18126 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5175 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)    11047 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/result_vis.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      473 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2870 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18335 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/modules/dbnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     8217 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/modules/seg_detector_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     2647 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7972 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      477 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6164 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)      517 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/convnextvit.py
--rw-r--r--   0 runner    (1001) docker     (122)     3451 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/crnn.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/timm_tinyc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/vitstr.py
--rw-r--r--   0 runner    (1001) docker     (122)     3603 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/open_vocabulary_detection_vild/
--rw-r--r--   0 runner    (1001) docker     (122)      501 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/open_vocabulary_detection_vild/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14225 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/open_vocabulary_detection_vild/vild.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      511 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)      102 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5077 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/equi.py
--rw-r--r--   0 runner    (1001) docker     (122)     7500 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/layers.py
--rw-r--r--   0 runner    (1001) docker     (122)     7839 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/mobilenet.py
--rw-r--r--   0 runner    (1001) docker     (122)    14421 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9175 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/unifuse.py
--rw-r--r--   0 runner    (1001) docker     (122)     3962 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/unifuse_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/pedestrian_attribute_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/pedestrian_attribute_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3468 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/pedestrian_attribute_recognition/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      495 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16147 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/common.py
--rw-r--r--   0 runner    (1001) docker     (122)    11898 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1797 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/rcp_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/
--rw-r--r--   0 runner    (1001) docker     (122)      548 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    20974 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/item_detection.py
--rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/item_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     4340 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/item_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      528 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7978 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_segmentation/net.py
--rw-r--r--   0 runner    (1001) docker     (122)     2194 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/product_segmentation/seg_infer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      514 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      318 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8504 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     9206 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/criterion.py
--rw-r--r--   0 runner    (1001) docker     (122)     7299 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/matcher.py
--rw-r--r--   0 runner    (1001) docker     (122)     7935 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/mttr.py
--rw-r--r--   0 runner    (1001) docker     (122)    16610 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2091 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py
--rw-r--r--   0 runner    (1001) docker     (122)     5629 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/postprocessing.py
--rw-r--r--   0 runner    (1001) docker     (122)     5180 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)    27941 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/swin_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/robust_image_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      501 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/robust_image_classification/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/robust_image_classification/easyrobust_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      497 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/
--rw-r--r--   0 runner    (1001) docker     (122)      213 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)     6558 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/backbone/Res2Net_v1b.py
--rw-r--r--   0 runner    (1001) docker     (122)      256 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6525 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     3047 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/senet.py
--rw-r--r--   0 runner    (1001) docker     (122)    12007 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/u2net.py
--rw-r--r--   0 runner    (1001) docker     (122)     3524 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2704 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/salient_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2203 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     4385 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/head_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)    32989 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/models.py
--rw-r--r--   0 runner    (1001) docker     (122)     9319 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/neck_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     5632 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/shop_seg_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4095 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/shop_seg_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6699 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/detection_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/detection_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/detection_model/detection_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     2532 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/detection_model/detection_unet_in.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/inpainting_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/inpainting_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5759 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/inpainting_model/gconv.py
--rw-r--r--   0 runner    (1001) docker     (122)     3233 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/inpainting_model/inpainting_unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10898 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3911 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/net.py
--rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/network.py
--rw-r--r--   0 runner    (1001) docker     (122)     5003 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/predict_single.py
--rw-r--r--   0 runner    (1001) docker     (122)     1035 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/prior_box.py
--rw-r--r--   0 runner    (1001) docker     (122)     2110 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3890 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/unet_deploy.py
--rw-r--r--   0 runner    (1001) docker     (122)     9917 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1169 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/weights_init.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/
--rw-r--r--   0 runner    (1001) docker     (122)      526 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/data/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2094 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/data/data_augment.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/
--rw-r--r--   0 runner    (1001) docker     (122)      165 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      274 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/base_exp.py
--rw-r--r--   0 runner    (1001) docker     (122)      392 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/build.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/default/
--rw-r--r--   0 runner    (1001) docker     (122)      137 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/default/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/default/streamyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)     1845 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/yolox_base.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/
--rw-r--r--   0 runner    (1001) docker     (122)      238 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/darknet.py
--rw-r--r--   0 runner    (1001) docker     (122)    10911 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/dfp_pafpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     6156 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/network_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     1314 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/streamyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)     5669 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/tal_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/realtime_video_detector.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      270 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3681 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/utils/boxes.py
--rw-r--r--   0 runner    (1001) docker     (122)      209 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/utils/format.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      555 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7652 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/arch_util.py
--rw-r--r--   0 runner    (1001) docker     (122)    10508 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/ecb.py
--rw-r--r--   0 runner    (1001) docker     (122)     3525 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/ecbsr_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/rrdbnet_arch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      462 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15842 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/lineless_table_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     3360 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/model_lore.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12614 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/modules/lore_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)    15090 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/modules/lore_processor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)      777 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7587 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     4143 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6145 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    18951 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_vit.py
--rw-r--r--   0 runner    (1001) docker     (122)    16418 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5165 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/simple_tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/
--rw-r--r--   0 runner    (1001) docker     (122)      594 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    43681 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/basic_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/global_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/master_net.py
--rw-r--r--   0 runner    (1001) docker     (122)      766 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/model_zoo.py
--rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/plain_net_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     7405 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/super_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)    14983 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/super_res_idwexkx.py
--rw-r--r--   0 runner    (1001) docker     (122)     8709 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/super_res_k1kxk1.py
--rw-r--r--   0 runner    (1001) docker     (122)     6923 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/super_res_kxkx.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      699 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/apis/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/apis/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2067 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/apis/detector_evaluater.py
--rw-r--r--   0 runner    (1001) docker     (122)     4000 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/apis/detector_inference.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3460 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     8123 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     2345 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py
--rw-r--r--   0 runner    (1001) docker     (122)     5911 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     2842 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/
--rw-r--r--   0 runner    (1001) docker     (122)      148 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      621 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3701 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9356 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py
--rw-r--r--   0 runner    (1001) docker     (122)     7465 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14261 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/base_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    10559 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    13101 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/ops.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    18626 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py
--rw-r--r--   0 runner    (1001) docker     (122)     7526 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py
--rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/weight_init.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/heads/
--rw-r--r--   0 runner    (1001) docker     (122)      409 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12602 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py
--rw-r--r--   0 runner    (1001) docker     (122)    19162 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/losses/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/losses/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5588 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)    12284 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      421 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7347 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py
--rw-r--r--   0 runner    (1001) docker     (122)    24842 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3499 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/detectors/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2809 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/detectors/detector.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/structures/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/structures/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9197 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/structures/bounding_box.py
--rw-r--r--   0 runner    (1001) docker     (122)     2627 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/structures/boxlist_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)     2774 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/structures/image_list.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      189 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11594 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/utils/boxes.py
--rw-r--r--   0 runner    (1001) docker     (122)     5838 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/utils/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1164 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/utils/scheduler.py
--rw-r--r--   0 runner    (1001) docker     (122)     6400 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/detector.py
--rw-r--r--   0 runner    (1001) docker     (122)      627 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/tinynas_damoyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)      643 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/tinynas_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/
--rw-r--r--   0 runner    (1001) docker     (122)     2896 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/UNet_for_video_deinterlace.py
--rw-r--r--   0 runner    (1001) docker     (122)      494 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      773 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/deinterlace_arch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3159 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/archs.py
--rw-r--r--   0 runner    (1001) docker     (122)     1441 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/deep_fourier_upsampling.py
--rw-r--r--   0 runner    (1001) docker     (122)     2972 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/enh.py
--rw-r--r--   0 runner    (1001) docker     (122)     3572 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/fre.py
--rw-r--r--   0 runner    (1001) docker     (122)     3716 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/configs/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/configs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12753 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/configs/default_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     6731 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/dro_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5494 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/camera.py
--rw-r--r--   0 runner    (1001) docker     (122)     2285 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/camera_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3737 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/pose.py
--rw-r--r--   0 runner    (1001) docker     (122)     3685 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/pose_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5277 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/model_checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     2356 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    10098 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/model_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     7204 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/sfm_model_mf.py
--rw-r--r--   0 runner    (1001) docker     (122)     4387 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/sup_model_mf.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/depth_pose/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/depth_pose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10532 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8902 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     1607 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/layers.py
--rw-r--r--   0 runner    (1001) docker     (122)     1915 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/optim/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/optim/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15781 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/optim/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     8039 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/optim/update.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6815 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/augmentations.py
--rw-r--r--   0 runner    (1001) docker     (122)    10248 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/config.py
--rw-r--r--   0 runner    (1001) docker     (122)    15068 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/depth.py
--rw-r--r--   0 runner    (1001) docker     (122)     1153 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/horovod.py
--rw-r--r--   0 runner    (1001) docker     (122)    10965 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     9407 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/image_gt.py
--rw-r--r--   0 runner    (1001) docker     (122)     6499 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/load.py
--rw-r--r--   0 runner    (1001) docker     (122)     2726 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1348 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/types.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/
--rw-r--r--   0 runner    (1001) docker     (122)     1894 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/VFINet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)     3334 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py
--rw-r--r--   0 runner    (1001) docker     (122)      458 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3212 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/corr.py
--rw-r--r--   0 runner    (1001) docker     (122)     9228 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5346 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/update.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/
--rw-r--r--   0 runner    (1001) docker     (122)    13745 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py
--rw-r--r--   0 runner    (1001) docker     (122)     4049 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/UNet.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3823 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/flow_reversal.py
--rw-r--r--   0 runner    (1001) docker     (122)    16050 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)    36415 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/transformer_layers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3314 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/utils/scene_change_detection.py
--rw-r--r--   0 runner    (1001) docker     (122)     2907 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/utils/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/
--rw-r--r--   0 runner    (1001) docker     (122)      558 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1324 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10465 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     2662 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/deep_guided_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     5506 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/effv2.py
--rw-r--r--   0 runner    (1001) docker     (122)     2904 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/lraspp.py
--rw-r--r--   0 runner    (1001) docker     (122)     2234 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/matting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      524 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11056 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_inpainting/inpainting.py
--rw-r--r--   0 runner    (1001) docker     (122)    13727 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_inpainting/inpainting_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      582 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18236 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    21551 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    16955 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    20983 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4136 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_updator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/neck/
--rw-r--r--   0 runner    (1001) docker     (122)      525 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/neck/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11733 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/track/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/track/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    26843 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/track/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    10771 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py
--rw-r--r--   0 runner    (1001) docker     (122)     4163 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    18059 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/video_knet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/
--rw-r--r--   0 runner    (1001) docker     (122)      541 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2970 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     2420 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/decode.py
--rw-r--r--   0 runner    (1001) docker     (122)     1890 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4921 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/yolo.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/tracker/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/tracker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1084 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/tracker/basetrack.py
--rw-r--r--   0 runner    (1001) docker     (122)     3117 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/tracker/matching.py
--rw-r--r--   0 runner    (1001) docker     (122)    14995 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/tracker/multitracker.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2230 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     9570 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/kalman_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     7296 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2888 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/visualization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      497 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      818 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/aggregate.py
--rw-r--r--   0 runner    (1001) docker     (122)     3582 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/cbam.py
--rw-r--r--   0 runner    (1001) docker     (122)     1979 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/eval_network.py
--rw-r--r--   0 runner    (1001) docker     (122)     3980 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/inference_core.py
--rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/inference_memory_bank.py
--rw-r--r--   0 runner    (1001) docker     (122)     7037 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/mod_resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)      974 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    15309 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     5593 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/network.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      477 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10040 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)    26628 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/
--rw-r--r--   0 runner    (1001) docker     (122)      515 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8349 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/kernel_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    20677 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    28653 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4081 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/kernel_updator.py
--rw-r--r--   0 runner    (1001) docker     (122)     6696 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     8627 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     5885 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/track_heads.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/neck/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/neck/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6255 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/neck/fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/track/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/track/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8508 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py
--rw-r--r--   0 runner    (1001) docker     (122)    17155 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/video_k_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5440 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/visualizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/config/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/config/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1024 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/config/ostrack.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/attn.py
--rw-r--r--   0 runner    (1001) docker     (122)     5004 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/attn_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     4805 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1234 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/patch_embed.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3380 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     3393 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/ostrack.py
--rw-r--r--   0 runner    (1001) docker     (122)      653 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12278 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/procontext/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/procontext/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3497 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/procontext/procontext.py
--rw-r--r--   0 runner    (1001) docker     (122)      943 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/procontext/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4473 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/procontext/vit_ce.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/tracker/
--rw-r--r--   0 runner    (1001) docker     (122)      114 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/tracker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5507 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/tracker/ostrack.py
--rw-r--r--   0 runner    (1001) docker     (122)     7123 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/tracker/procontext.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/utils/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/
--rw-r--r--   0 runner    (1001) docker     (122)    14702 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/DUT_raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     4715 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/MotionPro.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3290 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/corr.py
--rw-r--r--   0 runner    (1001) docker     (122)     9214 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5275 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     5526 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/update.py
--rw-r--r--   0 runner    (1001) docker     (122)     3922 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/Smoother.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1447 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     7292 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/rf_det_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/rf_det_so.py
--rw-r--r--   0 runner    (1001) docker     (122)     3452 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUTRAFTStabilizer.py
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/
--rw-r--r--   0 runner    (1001) docker     (122)     4684 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/IterativeSmooth.py
--rw-r--r--   0 runner    (1001) docker     (122)    14212 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/MedianFilter.py
--rw-r--r--   0 runner    (1001) docker     (122)    22544 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/ProjectionUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2893 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/RAFTUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2817 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/WarpUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14474 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/image_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4977 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/math_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/
--rw-r--r--   0 runner    (1001) docker     (122)      487 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/exp/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/exp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7097 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/longshortnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5774 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py
--rw-r--r--   0 runner    (1001) docker     (122)     4848 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py
--rw-r--r--   0 runner    (1001) docker     (122)     9990 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/longshort.py
--rw-r--r--   0 runner    (1001) docker     (122)     3905 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4959 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/base_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/kts/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/kts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1221 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/kts/cpd_auto.py
--rw-r--r--   0 runner    (1001) docker     (122)     3238 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/kts/cpd_nonlin.py
--rw-r--r--   0 runner    (1001) docker     (122)    13098 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/pgl_sum.py
--rw-r--r--   0 runner    (1001) docker     (122)     8812 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/summarizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      689 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14118 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/basicvsr_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     4727 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/msrresnet_lite_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3636 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py
--rw-r--r--   0 runner    (1001) docker     (122)     3637 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/real_basicvsr_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/vidt/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vidt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    40074 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vidt/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    25588 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vidt/deformable_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7436 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vidt/fpn_fusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    16697 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vidt/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     3651 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vidt/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/virual_tryon/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/virual_tryon/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17690 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/virual_tryon/sdafnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16102 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)      797 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1786 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     9340 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/petl.py
--rw-r--r--   0 runner    (1001) docker     (122)     5021 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/timm_helpers.py
--rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/timm_vision_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5040 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/timm_weight_init.py
--rw-r--r--   0 runner    (1001) docker     (122)     5614 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/vision_efficient_tuning.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5749 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    28089 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6494 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6192 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/vim.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/
--rw-r--r--   0 runner    (1001) docker     (122)      919 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12238 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5188 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/basic_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    13520 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5299 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/model_se.py
--rw-r--r--   0 runner    (1001) docker     (122)     5177 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/tokenization_clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)     2182 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       97 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14496 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/bert_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3898 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/configuration_bert.py
--rw-r--r--   0 runner    (1001) docker     (122)    22351 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    20998 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/modeling_bert.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip_interrogator/
--rw-r--r--   0 runner    (1001) docker     (122)       37 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip_interrogator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24293 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/clip_interrogator/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      140 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    26652 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    14427 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    39910 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/structbert.py
--rw-r--r--   0 runner    (1001) docker     (122)    11507 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11834 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/unet_generator.py
--rw-r--r--   0 runner    (1001) docker     (122)     8566 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/unet_upsampler_1024.py
--rw-r--r--   0 runner    (1001) docker     (122)    12361 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/unet_upsampler_256.py
--rw-r--r--   0 runner    (1001) docker     (122)    44602 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/dpm_solver_pytorch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/efficient_diffusion_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/efficient_diffusion_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10302 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/gemm/
--rw-r--r--   0 runner    (1001) docker     (122)      139 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/gemm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21694 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/gemm/gemm_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     3718 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/gemm/gemm_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/gemm/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      548 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    36265 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/respace.py
--rw-r--r--   0 runner    (1001) docker     (122)     1365 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/script.py
--rw-r--r--   0 runner    (1001) docker     (122)    36898 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/
--rw-r--r--   0 runner    (1001) docker     (122)     1444 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)   101942 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     8651 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     3268 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)    10331 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/
--rw-r--r--   0 runner    (1001) docker     (122)      141 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/dataloaders/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/dataloaders/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3789 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/dataloaders/rawvideo_util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/
--rw-r--r--   0 runner    (1001) docker     (122)      162 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9790 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     1442 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/dynamic_inverted_softmax.py
--rw-r--r--   0 runner    (1001) docker     (122)    21257 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/modeling.py
--rw-r--r--   0 runner    (1001) docker     (122)    18790 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/module_clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     3577 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/module_cross.py
--rw-r--r--   0 runner    (1001) docker     (122)     5581 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/tokenization_clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     4116 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/until_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/
--rw-r--r--   0 runner    (1001) docker     (122)      739 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16605 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/clip/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     6030 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/configuration_mplug.py
--rwxr-xr-x   0 runner    (1001) docker     (122)   120753 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/modeling_mplug.py
--rw-r--r--   0 runner    (1001) docker     (122)    34049 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/mvit.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    21332 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/predictor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5536 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_for_all_tasks.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_owl/
--rw-r--r--   0 runner    (1001) docker     (122)      835 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_owl/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10293 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_owl/configuration_mplug_owl.py
--rw-r--r--   0 runner    (1001) docker     (122)    64194 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_owl/modeling_mplug_owl.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      150 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10208 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)    11503 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    28436 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    13487 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/prior.py
--rw-r--r--   0 runner    (1001) docker     (122)     6898 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)    16675 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/upsampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     6565 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/xglm.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)      306 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/adaptor/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/adaptor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18720 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/configuration_mmspeech.py
--rw-r--r--   0 runner    (1001) docker     (122)    16552 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/configuration_ofa.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1785 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/incremental_decoding_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    21049 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/multihead_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     5658 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/ngram_repeat_block.py
--rw-r--r--   0 runner    (1001) docker     (122)    43439 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/search.py
--rw-r--r--   0 runner    (1001) docker     (122)    41976 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/sequence_generator.py
--rw-r--r--   0 runner    (1001) docker     (122)    16690 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/token_generation_constraints.py
--rw-r--r--   0 runner    (1001) docker     (122)     4883 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    44296 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/modeling_mmspeech.py
--rw-r--r--   0 runner    (1001) docker     (122)   100933 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/modeling_ofa.py
--rw-r--r--   0 runner    (1001) docker     (122)    13226 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)    15028 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/tokenization_ofa.py
--rw-r--r--   0 runner    (1001) docker     (122)     8004 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/tokenization_ofa_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/utils/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      676 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/utils/constant.py
--rw-r--r--   0 runner    (1001) docker     (122)     1877 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     8435 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/vit.py
--rw-r--r--   0 runner    (1001) docker     (122)    24779 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa_for_all_tasks.py
--rw-r--r--   0 runner    (1001) docker     (122)    12983 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa_for_text_to_image_synthesis_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/rleg/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/rleg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4865 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/rleg/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3410 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/rleg/rleg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/
--rw-r--r--   0 runner    (1001) docker     (122)      678 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9838 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)    11896 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     6165 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    22584 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4885 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     1597 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/team/
--rw-r--r--   0 runner    (1001) docker     (122)      140 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/team/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5181 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/team/team_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    11502 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/team/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18477 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     9264 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     9504 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    38498 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/unet_sd.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11339 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/conv_fpn_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    16687 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    47348 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/modeling_layout_roberta.py
--rw-r--r--   0 runner    (1001) docker     (122)    20956 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/processing.py
--rw-r--r--   0 runner    (1001) docker     (122)     4680 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)     7333 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/transformer_local.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/T5/
--rw-r--r--   0 runner    (1001) docker     (122)      599 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/T5/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    67374 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/T5/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7541 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/T5/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    21467 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/T5/text2text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     6368 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bart/
--rw-r--r--   0 runner    (1001) docker     (122)      112 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bart/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3058 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bart/text_error_correction.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/
--rw-r--r--   0 runner    (1001) docker     (122)     1519 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    40458 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7308 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4113 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/document_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)      512 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     6074 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/sentence_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     7153 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/siamese_uie.py
--rw-r--r--   0 runner    (1001) docker     (122)     1478 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     1138 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)     2140 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/token_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     6904 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bert/word_alignment.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bloom/
--rw-r--r--   0 runner    (1001) docker     (122)      472 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bloom/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      505 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/bloom/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/canmt/
--rw-r--r--   0 runner    (1001) docker     (122)      102 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/canmt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    52235 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/canmt/canmt_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2940 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/canmt/canmt_translation.py
--rw-r--r--   0 runner    (1001) docker     (122)    35688 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/canmt/sequence_generator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/
--rwxr-xr-x   0 runner    (1001) docker     (122)      730 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    35473 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/codegeex.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3995 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/codegeex_for_code_generation.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4008 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/codegeex_for_code_translation.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     9997 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/inference.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6111 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/csanmt/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/csanmt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    61868 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/csanmt/translation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/
--rw-r--r--   0 runner    (1001) docker     (122)     1771 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    47998 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6771 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10364 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)    21421 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)    10698 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/tokenization_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/dgds/
--rw-r--r--   0 runner    (1001) docker     (122)      939 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/dgds/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7092 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/dgds/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     1656 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/dgds/document_grounded_dialog_generate.py
--rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/dgds/document_grounded_dialog_rerank.py
--rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/dgds/document_grounded_dialog_retrieval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/fid_T5/
--rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/fid_T5/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8108 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/fid_T5/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/
--rw-r--r--   0 runner    (1001) docker     (122)     1181 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    45082 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5045 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     6709 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/generation/
--rw-r--r--   0 runner    (1001) docker     (122)       87 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/generation/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    10112 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/generation/strategies.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5152 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/initialize.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/kernels/
--rw-r--r--   0 runner    (1001) docker     (122)     3263 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/kernels/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/quantization/
--rw-r--r--   0 runner    (1001) docker     (122)     2635 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/quantization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/quantization/functional.py
--rw-r--r--   0 runner    (1001) docker     (122)     4510 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/quantization/layers.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    13504 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt2/
--rw-r--r--   0 runner    (1001) docker     (122)      470 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      498 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt2/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/
--rw-r--r--   0 runner    (1001) docker     (122)      852 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15811 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     8971 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    51600 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/distributed_gpt3.py
--rw-r--r--   0 runner    (1001) docker     (122)     2847 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2586 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/
--rw-r--r--   0 runner    (1001) docker     (122)      874 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13129 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5198 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/checkpointing.py
--rw-r--r--   0 runner    (1001) docker     (122)     4930 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    49316 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/distributed_gpt_moe.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/experts.py
--rw-r--r--   0 runner    (1001) docker     (122)     3504 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2553 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/mappings.py
--rw-r--r--   0 runner    (1001) docker     (122)    23756 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/sharded_moe.py
--rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2717 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2277 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_neo/
--rw-r--r--   0 runner    (1001) docker     (122)      474 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_neo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      518 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/gpt_neo/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/
--rw-r--r--   0 runner    (1001) docker     (122)      661 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    25248 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/crf_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6947 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/fill_mask_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     5145 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/infromation_extraction_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2056 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/text_classification_head.py
--rw-r--r--   0 runner    (1001) docker     (122)      964 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/text_generation_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2029 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/text_ranking_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2596 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/token_classification_head.py
--rw-r--r--   0 runner    (1001) docker     (122)      948 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/heads/torch_pretrain_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/hf_transformers/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/hf_transformers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4897 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/hf_transformers/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/llama/
--rw-r--r--   0 runner    (1001) docker     (122)      866 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/llama/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    29197 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/llama/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     4695 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/llama/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    11349 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/llama/convert_llama_weights_to_hf.py
--rw-r--r--   0 runner    (1001) docker     (122)     7212 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/llama/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)    10333 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/llama/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/llama/tokenization_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/lstm/
--rw-r--r--   0 runner    (1001) docker     (122)      610 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/lstm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1312 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/lstm/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     2187 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/lstm/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/megatron_bert/
--rw-r--r--   0 runner    (1001) docker     (122)      688 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/megatron_bert/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    39864 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/megatron_bert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6599 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/megatron_bert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    12452 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/megatron_bert/fill_mask.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/
--rw-r--r--   0 runner    (1001) docker     (122)      572 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    28115 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/arguments.py
--rw-r--r--   0 runner    (1001) docker     (122)    28162 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/blocklm_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    17995 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/configure_data.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/
--rw-r--r--   0 runner    (1001) docker     (122)    13656 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    20350 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/corpora.py
--rw-r--r--   0 runner    (1001) docker     (122)    45765 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/datasets.py
--rw-r--r--   0 runner    (1001) docker     (122)     3342 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/extraction.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8459 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     9797 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/lazy_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     7221 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/samplers.py
--rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/sp_tokenizer.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    53304 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)    14551 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/tokenization_gpt2.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    15773 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/wordpiece.py
--rw-r--r--   0 runner    (1001) docker     (122)    21669 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/generation_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    16247 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/mglm_for_text_summarization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/
--rwxr-xr-x   0 runner    (1001) docker     (122)      984 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5443 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/distributed.py
--rw-r--r--   0 runner    (1001) docker     (122)     9967 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/downstream.py
--rw-r--r--   0 runner    (1001) docker     (122)    70249 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/modeling_bert.py
--rw-r--r--   0 runner    (1001) docker     (122)     8743 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/modeling_glm.py
--rw-r--r--   0 runner    (1001) docker     (122)     2531 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/prompt.py
--rw-r--r--   0 runner    (1001) docker     (122)    48886 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/process_grid.py
--rw-r--r--   0 runner    (1001) docker     (122)      203 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/run_test.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/test/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/test/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      950 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/test/test_block.py
--rw-r--r--   0 runner    (1001) docker     (122)      704 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/test/test_rel_shift.py
--rw-r--r--   0 runner    (1001) docker     (122)    17815 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/train_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    19029 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/mglm/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/
--rw-r--r--   0 runner    (1001) docker     (122)     1268 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5532 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    29453 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/dureader_eval.py
--rw-r--r--   0 runner    (1001) docker     (122)    55450 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/peer/
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/peer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    55780 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/peer/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    11716 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/peer/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     6166 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/peer/sas_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/peer/text_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug/
--rwxr-xr-x   0 runner    (1001) docker     (122)     3321 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug/AnnealingLR.py
--rw-r--r--   0 runner    (1001) docker     (122)      660 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    41209 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    11797 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10983 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug/distributed_plug.py
--rw-r--r--   0 runner    (1001) docker     (122)     8427 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug/generator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/
--rw-r--r--   0 runner    (1001) docker     (122)     1359 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7671 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/adv_utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    47486 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7956 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10881 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/text_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/ponet/
--rw-r--r--   0 runner    (1001) docker     (122)     1490 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/ponet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    37918 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/ponet/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6366 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/ponet/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4176 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/ponet/document_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)    11011 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/ponet/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     7147 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/ponet/tokenization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)      987 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1208 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     3832 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/dialog_intent_prediction.py
--rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/dialog_modeling.py
--rw-r--r--   0 runner    (1001) docker     (122)    16648 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/dialog_state_tracking.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/model/
--rw-r--r--   0 runner    (1001) docker     (122)      421 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10281 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/model/gen_unified_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10757 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/model/generator.py
--rw-r--r--   0 runner    (1001) docker     (122)     7505 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/model/intent_unified_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/model/model_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/model/tokenization_space.py
--rw-r--r--   0 runner    (1001) docker     (122)    11941 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/model/unified_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2398 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/embedder.py
--rw-r--r--   0 runner    (1001) docker     (122)      956 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/feedforward.py
--rw-r--r--   0 runner    (1001) docker     (122)     1721 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/functions.py
--rw-r--r--   0 runner    (1001) docker     (122)     3397 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/multihead_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     1922 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/transformer_block.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    44438 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5194 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    30117 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/table_question_answering.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/space_T_en/text_to_sql.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/
--rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7673 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/adv_utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    40848 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7686 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    27203 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/faq_question_answering.py
--rw-r--r--   0 runner    (1001) docker     (122)    12581 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)    11862 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)    11074 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/structbert/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/
--rw-r--r--   0 runner    (1001) docker     (122)     1453 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5323 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/feature_extraction.py
--rw-r--r--   0 runner    (1001) docker     (122)     2698 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)      766 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/information_extraction.py
--rw-r--r--   0 runner    (1001) docker     (122)    28991 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/task_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1912 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     8678 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2092 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)     5116 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/task_models/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/unite/
--rw-r--r--   0 runner    (1001) docker     (122)      626 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/unite/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      409 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/unite/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    18320 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/unite/translation_evaluation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/use/
--rw-r--r--   0 runner    (1001) docker     (122)      545 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/use/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5133 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/use/transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5795 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/use/user_satisfaction_estimation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/veco/
--rw-r--r--   0 runner    (1001) docker     (122)     1479 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/veco/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4031 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/veco/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     1192 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/veco/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4278 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/veco/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     6643 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/veco/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     4129 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/veco/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/nlp/xlm_roberta/
--rw-r--r--   0 runner    (1001) docker     (122)     1156 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/xlm_roberta/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    42932 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/xlm_roberta/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7697 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/nlp/xlm_roberta/configuration.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/science/
--rw-r--r--   0 runner    (1001) docker     (122)      491 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/
--rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24057 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/
--rw-r--r--   0 runner    (1001) docker     (122)      634 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    49139 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/data_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    19691 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/msa_pairing.py
--rw-r--r--   0 runner    (1001) docker     (122)     8941 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/process.py
--rw-r--r--   0 runner    (1001) docker     (122)    14792 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/process_multimer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11422 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/protein.py
--rw-r--r--   0 runner    (1001) docker     (122)    42023 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/residue_constants.py
--rw-r--r--   0 runner    (1001) docker     (122)     4628 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/data/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    19250 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/
--rw-r--r--   0 runner    (1001) docker     (122)      187 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17066 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/alphafold.py
--rw-r--r--   0 runner    (1001) docker     (122)    12323 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/attentions.py
--rw-r--r--   0 runner    (1001) docker     (122)     5403 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/auxillary_heads.py
--rw-r--r--   0 runner    (1001) docker     (122)    10676 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     5814 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/confidence.py
--rw-r--r--   0 runner    (1001) docker     (122)     8771 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/embedders.py
--rw-r--r--   0 runner    (1001) docker     (122)    11078 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/evoformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6820 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/featurization.py
--rw-r--r--   0 runner    (1001) docker     (122)    18025 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/frame.py
--rw-r--r--   0 runner    (1001) docker     (122)    18476 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/structure_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     9771 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/template.py
--rw-r--r--   0 runner    (1001) docker     (122)     5623 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/triangle_multiplication.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/
--rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17940 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/mmcif.py
--rw-r--r--   0 runner    (1001) docker     (122)     3128 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/msa_identifiers.py
--rw-r--r--   0 runner    (1001) docker     (122)    23503 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/parsers.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    45468 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/templates.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/
--rw-r--r--   0 runner    (1001) docker     (122)      639 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6218 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/hhblits.py
--rw-r--r--   0 runner    (1001) docker     (122)     3991 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/hhsearch.py
--rw-r--r--   0 runner    (1001) docker     (122)     5098 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/hmmbuild.py
--rw-r--r--   0 runner    (1001) docker     (122)     5013 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/hmmsearch.py
--rw-r--r--   0 runner    (1001) docker     (122)     8662 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/jackhmmer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3752 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/kalign.py
--rw-r--r--   0 runner    (1001) docker     (122)     1255 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/
--rw-r--r--   0 runner    (1001) docker     (122)       84 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/audio/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      346 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/audio/asr_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/auth/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/auth/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1326 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/auth/auth_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/context/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/context/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3369 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/context/dataset_context_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/data_files/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/data_files/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5110 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/data_files/data_files_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/data_loader/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/data_loader/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12704 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/data_loader/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     5767 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/data_loader/data_loader_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/
--rw-r--r--   0 runner    (1001) docker     (122)      111 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/
--rw-r--r--   0 runner    (1001) docker     (122)     4111 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      730 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1737 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     8512 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     7723 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    11689 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/
--rw-r--r--   0 runner    (1001) docker     (122)      541 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1264 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      791 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/
--rw-r--r--   0 runner    (1001) docker     (122)      134 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4708 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py
--rw-r--r--   0 runner    (1001) docker     (122)      945 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      177 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3815 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py
--rw-r--r--   0 runner    (1001) docker     (122)    16180 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/
--rw-r--r--   0 runner    (1001) docker     (122)      934 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11572 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/
--rw-r--r--   0 runner    (1001) docker     (122)      312 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2622 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py
--rw-r--r--   0 runner    (1001) docker     (122)     4858 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     1469 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/
--rw-r--r--   0 runner    (1001) docker     (122)      196 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1086 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py
--rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/easycv_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     2141 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_colorization/
--rw-r--r--   0 runner    (1001) docker     (122)      539 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py
--rw-r--r--   0 runner    (1001) docker     (122)    12152 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    12574 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/
--rw-r--r--   0 runner    (1001) docker     (122)      577 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1629 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/
--rw-r--r--   0 runner    (1001) docker     (122)      615 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1487 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/
--rw-r--r--   0 runner    (1001) docker     (122)      583 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     4849 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     6225 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      559 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6171 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     4013 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      161 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1589 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     5437 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/
--rw-r--r--   0 runner    (1001) docker     (122)       40 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7547 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     3416 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/
--rw-r--r--   0 runner    (1001) docker     (122)      309 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3172 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py
--rw-r--r--   0 runner    (1001) docker     (122)      971 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     5818 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py
--rw-r--r--   0 runner    (1001) docker     (122)     2000 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py
--rw-r--r--   0 runner    (1001) docker     (122)      707 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py
--rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     2393 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2017 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      599 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16767 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     8725 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/
--rw-r--r--   0 runner    (1001) docker     (122)      545 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1475 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1984 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2684 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     5114 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1635 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2664 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/veco_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/
--rw-r--r--   0 runner    (1001) docker     (122)      573 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1390 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_stabilization/
--rw-r--r--   0 runner    (1001) docker     (122)      543 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      809 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2624 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      553 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2370 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    10687 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/download/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/download/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16684 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/download/dataset_builder.py
--rw-r--r--   0 runner    (1001) docker     (122)      609 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/download/download_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     2487 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/download/download_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/meta/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/meta/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1772 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/meta/data_meta_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     8634 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/meta/data_meta_manager.py
--rw-r--r--   0 runner    (1001) docker     (122)    36466 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/ms_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/task_datasets/
--rw-r--r--   0 runner    (1001) docker     (122)     1072 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/task_datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      408 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/task_datasets/gopro_image_deblurring_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      401 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/task_datasets/reds_image_deblurring_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/task_datasets/sidd_image_denoising.py
--rw-r--r--   0 runner    (1001) docker     (122)      410 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/task_datasets/torch_base_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/task_datasets/video_summarization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/msdatasets/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7610 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/utils/dataset_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/utils/delete_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/utils/maxcompute_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6124 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/utils/oss_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2496 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/msdatasets/utils/upload_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/ops/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/ops/ailut/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/ops/ailut/Ailut/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/ailut/Ailut/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/ops/ailut/Ailut/csrc/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/ailut/Ailut/csrc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      105 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/ailut/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4314 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/ailut/pyinterfaces.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/
--rw-r--r--   0 runner    (1001) docker     (122)      106 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/functions/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/functions/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2925 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/functions/quadtree_attention.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13956 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/modules/quadtree_attention.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/src/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/src/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/outputs/
--rw-r--r--   0 runner    (1001) docker     (122)      132 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/outputs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      908 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/outputs/cv_outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    19855 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/outputs/nlp_outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    51098 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/outputs/outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    11135 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipeline_inputs.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/
--rw-r--r--   0 runner    (1001) docker     (122)      150 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7481 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/ans_dfsmn_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5016 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/ans_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    23877 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/asr_inference_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/asr_wenet_inference_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4357 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/inverse_text_processing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3830 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/kws_farfield_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7276 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/kws_kwsbp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5555 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/linear_aec_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8056 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/lm_infer_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6469 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/punctuation_processing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2560 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/separation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4042 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_change_locating_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11089 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_diarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4078 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_verification_eres2net_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4118 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_verification_light_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    10499 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_verification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_verification_rdino_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/text_to_speech_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11925 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/timestamp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9684 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/audio/voice_activity_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    22849 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7279 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/
--rw-r--r--   0 runner    (1001) docker     (122)    16252 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2545 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/action_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4852 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/action_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4024 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/animal_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2576 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/arc_face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2614 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/bad_image_detecting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/body_2d_keypoints_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    14219 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/body_3d_keypoints_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4740 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/card_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5307 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/cmdssl_video_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2528 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/content_check_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5055 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/controllable_image_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5942 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/crowd_counting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5136 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ddcolor_image_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ddpm_semantic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_attribute_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3980 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1531 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_emotion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_human_hand_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2894 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_image_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3312 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_liveness_ir_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3573 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_liveness_xc_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7748 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_processing_base_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3872 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_quality_assessment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3528 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_recognition_onnx_fm_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3493 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_recognition_onnx_ir_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2878 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_recognition_ood_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    19630 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/face_reconstruction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2400 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/facial_expression_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2681 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/facial_landmark_confidence_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4442 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/fast_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4030 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/general_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1360 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/hand_static_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2982 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/hicossl_video_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/human_reconstruction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1399 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_body_reshaping_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2919 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_bts_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5251 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_cartoon_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5857 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3296 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_color_enhance_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4441 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2648 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_debanding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4624 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_deblur_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3517 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_defrcn_fewshot_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4160 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_denoise_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1943 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1854 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4134 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_driving_perception_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2317 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_face_fusion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4866 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_human_parsing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5854 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_inpainting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4673 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_inpainting_sdv2_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3903 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5929 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_matching_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_matting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2796 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_mvs_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2770 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_open_vocabulary_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6113 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_paintbyexample_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8567 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_portrait_enhancement_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3549 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_quality_assessment_degradation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2835 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_quality_assessment_man_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2801 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_quality_assessment_mos_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2026 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_reid_person_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1702 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_restoration_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1644 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_salient_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3207 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_semantic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2237 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_skychange_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2839 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_structured_model_probing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4615 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_style_transfer_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3138 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9718 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_to_image_generate_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    12737 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/image_to_image_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1883 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/indoor_layout_estimation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     9872 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/language_guided_video_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4570 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/license_plate_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4182 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/lineless_table_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/live_category_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2757 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/mask_face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2787 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/maskdino_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3670 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/mobile_image_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1857 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/mog_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4844 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/motion_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2628 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/movie_scene_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1953 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/mtcnn_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3328 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/nerf_recon_acc_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6018 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/object_detection_3d_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11033 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2500 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_recognition_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/
--rw-r--r--   0 runner    (1001) docker     (122)      966 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      720 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_convnext_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    19821 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_dla34.py
--rw-r--r--   0 runner    (1001) docker     (122)     8768 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_resnet18_half.py
--rw-r--r--   0 runner    (1001) docker     (122)     5286 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py
--rw-r--r--   0 runner    (1001) docker     (122)    15421 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_vlpt.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ocr_modules/
--rw-r--r--   0 runner    (1001) docker     (122)      550 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ocr_modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ocr_modules/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1560 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ocr_modules/vitstr.py
--rw-r--r--   0 runner    (1001) docker     (122)    38278 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    19004 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/resnet18_v1.py
--rw-r--r--   0 runner    (1001) docker     (122)    11371 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/resnet_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    11168 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/table_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     7971 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3029 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/panorama_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9781 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/pedestrian_attribute_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4199 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1457 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/product_retrieval_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1451 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/product_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2020 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/realtime_video_object_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9239 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/referring_video_object_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/retina_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1760 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/shop_segmentation_pipleline.py
--rw-r--r--   0 runner    (1001) docker     (122)    12129 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/skin_retouching_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4446 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/table_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4899 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/tbs_detection_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/tbs_detection_utils/
--rw-r--r--   0 runner    (1001) docker     (122)       10 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/tbs_detection_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15542 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/tbs_detection_utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1841 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/text_driven_segmentation_pipleline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3246 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/tinynas_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3244 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/tinynas_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1888 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/ulfd_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    13776 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_category_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6097 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7757 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_deinterlace_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1565 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    24271 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_frame_interpolation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3635 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_human_matting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1719 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_inpainting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9652 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3294 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_multi_object_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4724 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_object_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4683 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_panoptic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3436 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_single_object_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4647 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_stabilization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4289 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7078 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/video_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7564 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/vidt_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5240 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/virtual_try_on_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3986 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/vision_efficient_tuning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/vision_middleware_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4762 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/vop_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5787 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/cv/vop_retrieval_se_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)     3071 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2366 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/asr_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/
--rw-r--r--   0 runner    (1001) docker     (122)      636 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2013 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      718 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11691 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2880 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/disco_guided_diffusion_pipeline/
--rw-r--r--   0 runner    (1001) docker     (122)      585 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15631 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    18987 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2311 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/document_vl_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2931 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1093 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9352 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/gridvlp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3219 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/image_captioning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1612 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/image_text_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7869 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/mgeo_ranking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3325 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/multimodal_dialogue_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/ocr_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8561 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1848 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/sudoku_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/text2sql_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/text_to_image_synthesis_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3556 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/text_to_video_synthesis_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2150 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/video_captioning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1329 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/video_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/visual_entailment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1781 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/visual_grounding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2396 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/visual_question_answering_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     6798 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6939 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/automatic_post_editing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3696 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/canmt_translation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2202 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/codegeex_code_generation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2885 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/codegeex_code_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2251 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/conversational_text_to_sql_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2577 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/dialog_intent_prediction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2308 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/dialog_modeling_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7663 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/dialog_state_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2218 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/distributed_gpt3_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1851 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/distributed_gpt_moe_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4425 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/distributed_plug_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2754 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/document_grounded_dialog_generate_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    25997 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5480 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9623 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/document_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6259 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/extractive_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3348 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/faq_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2437 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/fasttext_text_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3258 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/feature_extraction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    10171 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/fid_dialogue_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4655 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/fill_mask_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)      999 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/glm130b_text_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2383 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/information_extraction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6363 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/interactive_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9928 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/language_identification_pipline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1776 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/mglm_text_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2955 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/named_entity_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3184 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/sentence_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    14334 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/siamese_uie_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    16315 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/table_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6787 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/text_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3490 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/text_error_correction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7735 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/text_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2877 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/text_ranking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6399 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/token_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/translation_evaluation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5586 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2339 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/translation_quality_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4613 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/user_satisfaction_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2713 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/word_alignment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4523 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/word_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5875 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/nlp/zero_shot_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2816 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/pipeline_template.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/pipelines/science/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/science/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/science/protein_structure_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3492 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/pipelines/util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/
--rw-r--r--   0 runner    (1001) docker     (122)     5792 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10063 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/asr.py
--rw-r--r--   0 runner    (1001) docker     (122)     8680 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/audio.py
--rw-r--r--   0 runner    (1001) docker     (122)    15312 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      812 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/common.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1896 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7446 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/action_detection_mapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     1126 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/bad_image_detecting_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7789 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/controllable_image_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)    20909 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/cv2_transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    12826 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/image_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1250 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/image_quality_assessment_man.py
--rw-r--r--   0 runner    (1001) docker     (122)     2113 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/image_quality_assessment_mos.py
--rw-r--r--   0 runner    (1001) docker     (122)     2790 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/image_restoration_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2625 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/mmcls_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3050 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/timer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3606 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     1501 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/video_stabilization.py
--rw-r--r--   0 runner    (1001) docker     (122)     8579 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/cv/video_super_resolution.py
--rw-r--r--   0 runner    (1001) docker     (122)    13406 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     4884 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/kws.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10809 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/movie_scene_segmentation/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    30147 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/multi_modal.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     5966 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      762 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/bert_seq_cls_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3929 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/canmt_translation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/dialog_classification_use_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4102 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4391 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4086 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    11004 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/document_segmentation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     6844 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/faq_question_answering_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/feature_extraction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    12086 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/fill_mask_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     8199 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/mgeo_ranking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1168 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/mglm_summarization_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/relation_extraction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4023 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/sentence_embedding_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1424 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/siamese_uie_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)     1219 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1908 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/args.py
--rw-r--r--   0 runner    (1001) docker     (122)     1555 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/batch.py
--rw-r--r--   0 runner    (1001) docker     (122)     3629 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     2701 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/dialog_modeling_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5457 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    56779 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/dst_processors.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/fields/
--rw-r--r--   0 runner    (1001) docker     (122)      592 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    33884 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/fields/gen_field.py
--rw-r--r--   0 runner    (1001) docker     (122)    42465 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/fields/intent_field.py
--rw-r--r--   0 runner    (1001) docker     (122)     1147 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/lazy_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1935 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     1610 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     2084 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/tensorlistdataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    24803 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/
--rw-r--r--   0 runner    (1001) docker     (122)      654 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/fields/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4936 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/fields/database.py
--rw-r--r--   0 runner    (1001) docker     (122)    15867 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/fields/schema_link.py
--rw-r--r--   0 runner    (1001) docker     (122)     4888 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/fields/struct.py
--rw-r--r--   0 runner    (1001) docker     (122)     4175 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)      846 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4902 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/
--rw-r--r--   0 runner    (1001) docker     (122)      818 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21521 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/common_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12500 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/parse.py
--rw-r--r--   0 runner    (1001) docker     (122)     1380 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2111 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/process_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_clean.py
--rw-r--r--   0 runner    (1001) docker     (122)     2298 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_error_correction.py
--rw-r--r--   0 runner    (1001) docker     (122)    13896 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_generation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3834 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_ranking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    19475 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/token_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1640 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/token_classification_thai_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1238 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/token_classification_viet_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4482 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/transformers_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7304 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/translation_evaluation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3622 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4962 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/word_alignment_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2584 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/nlp/zero_shot_classification_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)      762 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4839 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/asr.py
--rw-r--r--   0 runner    (1001) docker     (122)    11909 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4172 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/image_captioning.py
--rw-r--r--   0 runner    (1001) docker     (122)     6461 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/image_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     5740 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/ocr_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     4603 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/sudoku.py
--rw-r--r--   0 runner    (1001) docker     (122)     5210 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/summarization.py
--rw-r--r--   0 runner    (1001) docker     (122)    16449 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/text2sql.py
--rw-r--r--   0 runner    (1001) docker     (122)     5368 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     2164 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/text_to_image_synthesis.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3221 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/audio_helper.py
--rw-r--r--   0 runner    (1001) docker     (122)     8936 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/bridge_content_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6809 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/collate.py
--rw-r--r--   0 runner    (1001) docker     (122)      660 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/constant.py
--rw-r--r--   0 runner    (1001) docker     (122)     3421 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/get_tables.py
--rw-r--r--   0 runner    (1001) docker     (122)     1302 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/random_help.py
--rw-r--r--   0 runner    (1001) docker     (122)     5459 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/text2phone.py
--rw-r--r--   0 runner    (1001) docker     (122)    19116 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/vision_helper.py
--rw-r--r--   0 runner    (1001) docker     (122)     7664 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/visual_entailment.py
--rw-r--r--   0 runner    (1001) docker     (122)     8484 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/visual_grounding.py
--rw-r--r--   0 runner    (1001) docker     (122)     6796 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/ofa/visual_question_answering.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/preprocessors/science/
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/science/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21698 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/science/uni_fold.py
--rw-r--r--   0 runner    (1001) docker     (122)     2101 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/tts.py
--rw-r--r--   0 runner    (1001) docker     (122)    13168 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/preprocessors/video.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/tools/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/tools/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      772 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/tools/eval.py
--rw-r--r--   0 runner    (1001) docker     (122)     5362 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/tools/speech_tts_autolabel.py
--rw-r--r--   0 runner    (1001) docker     (122)      607 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/tools/train.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/
--rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      826 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1873 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/ans_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6969 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/asr_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12816 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_farfield_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    22065 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_nearfield_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/
--rw-r--r--   0 runner    (1001) docker     (122)     1768 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    22114 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/batch_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    11499 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/det_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     7022 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2854 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/runtime_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    21962 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/separation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10858 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/audio/tts_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1808 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     5553 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cli_argument_parser.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1974 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7494 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/action_detection_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      668 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/card_detection_scrfd_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10044 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/cartoon_translation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6737 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/face_detection_scrfd_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20323 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/image_classifition_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11655 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/image_defrcn_fewshot_detection_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    22965 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/image_detection_damoyolo_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4405 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/image_inpainting_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      816 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/image_instance_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5520 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/image_portrait_enhancement_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      680 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/movie_scene_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20149 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/nerf_recon_acc_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    16911 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/ocr_detection_db_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/ocr_recognition_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/referring_video_object_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4602 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/cv/vision_efficient_tuning_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2594 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/default_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/
--rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      296 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/checkpoint/
--rw-r--r--   0 runner    (1001) docker     (122)      116 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/checkpoint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18438 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/checkpoint/checkpoint_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)    10797 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/checkpoint/checkpoint_processor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5541 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/checkpoint/load_checkpoint_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)      764 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/clip_clamp_logit_scale_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/compression/
--rw-r--r--   0 runner    (1001) docker     (122)      610 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/compression/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4812 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/compression/sparsity_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6915 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/compression/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/distributed/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/distributed/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1458 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/distributed/ddp_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     8200 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/distributed/deepspeed_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6905 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/distributed/megatron_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     4398 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/early_stop_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     3825 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/evaluation_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/hook.py
--rw-r--r--   0 runner    (1001) docker     (122)      731 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/iter_timer_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/logger/
--rw-r--r--   0 runner    (1001) docker     (122)      718 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/logger/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4498 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/logger/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4507 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/logger/tensorboard_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     7443 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/logger/text_logger_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6402 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/lr_scheduler_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/
--rw-r--r--   0 runner    (1001) docker     (122)      743 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3139 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/apex_optimizer_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     3786 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     3729 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/torch_optimizer_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/hooks/priority.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/
--rw-r--r--   0 runner    (1001) docker     (122)      699 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2040 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/warmup/
--rw-r--r--   0 runner    (1001) docker     (122)      614 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/warmup/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2547 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/warmup/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     2934 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/warmup/warmup.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)      682 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       89 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9702 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/clip/clip_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4388 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/clip/clip_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/efficient_diffusion_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/efficient_diffusion_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2874 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8086 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/mgeo_ranking_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/mplug/
--rw-r--r--   0 runner    (1001) docker     (122)       91 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/mplug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1642 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/mplug/mplug_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)       87 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/ofa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10186 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/ofa/ofa_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17647 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/ofa/ofa_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/team/
--rw-r--r--   0 runner    (1001) docker     (122)       95 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/team/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5429 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/team/team_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2443 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/multi_modal/team/team_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     1332 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14266 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/csanmt_translation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9999 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/document_grounded_dialog_generate_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    24284 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/document_grounded_dialog_rerank_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/document_grounded_dialog_retrieval_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12769 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/faq_question_answering_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3064 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/gpt3_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2097 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/gpt_moe_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8171 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/plug_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/sentence_embedding_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8378 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/sequence_classification_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17110 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/siamese_uie_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5324 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/dialog_intent_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4229 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/dialog_modeling_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    36354 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/eval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/metrics/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/metrics/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2447 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/metrics/metrics_tracker.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/trainer/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/trainer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    30567 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/trainer/gen_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    29570 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/space/trainer/intent_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20453 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/table_question_answering_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      991 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/text_generation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7514 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/text_ranking_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    15326 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp/translation_evaluation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7129 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/nlp_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/optimizer/
--rw-r--r--   0 runner    (1001) docker     (122)      223 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/optimizer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1753 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/optimizer/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     7081 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/optimizer/child_tuning_adamw_optimizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/parallel/
--rw-r--r--   0 runner    (1001) docker     (122)       80 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/parallel/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      681 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/parallel/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)      754 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/parallel/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    59078 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17574 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/training_args.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/trainers/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11090 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/utils/inference.py
--rw-r--r--   0 runner    (1001) docker     (122)     1294 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/trainers/utils/log_buffer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/tuners/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/tuners/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    38904 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/tuners/control_sd_lora.py
--rw-r--r--   0 runner    (1001) docker     (122)    24058 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/tuners/lora.py
--rw-r--r--   0 runner    (1001) docker     (122)     8840 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/tuners/sd_lora.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    28920 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/ast_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/utils/audio/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11795 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/audio/audio_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2428 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/audio/tts_exceptions.py
--rw-r--r--   0 runner    (1001) docker     (122)    26430 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     2573 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/chinese_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    27433 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     1027 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/config_ds.py
--rw-r--r--   0 runner    (1001) docker     (122)    18753 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/constant.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/utils/cv/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    23195 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/cv/image_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/utils/cv/motion_utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/cv/motion_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/cv/motion_utils/motion_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     3847 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/cv/motion_utils/plot_script.py
--rw-r--r--   0 runner    (1001) docker     (122)     4290 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/cv/motion_utils/rotation_conversions.py
--rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/data_collators.py
--rw-r--r--   0 runner    (1001) docker     (122)     1279 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3744 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/device.py
--rw-r--r--   0 runner    (1001) docker     (122)     6339 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/error.py
--rw-r--r--   0 runner    (1001) docker     (122)     1128 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5939 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/hub.py
--rw-r--r--   0 runner    (1001) docker     (122)    15823 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/import_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    25538 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/input_output.py
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/json_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/logger.py
--rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/megatron_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2335 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5099 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/model_tag.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)      499 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4424 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/distributed.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4526 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/load_checkpoint.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1909 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/args.py
--rw-r--r--   0 runner    (1001) docker     (122)    11818 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/clean_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1439 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/criterions.py
--rw-r--r--   0 runner    (1001) docker     (122)    11252 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/db_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)     6174 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/ontology.py
--rw-r--r--   0 runner    (1001) docker     (122)      197 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/scores.py
--rw-r--r--   0 runner    (1001) docker     (122)     6356 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1054 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space/utils_dst.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      859 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/space_T_en/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2554 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/nlp/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    39508 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/plugins.py
--rw-r--r--   0 runner    (1001) docker     (122)     7833 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/registry.py
--rw-r--r--   0 runner    (1001) docker     (122)    30195 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/regress_test_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6127 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/service_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2500 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/task_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1593 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/tensor_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12532 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/test_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/timer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10966 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/torch_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      597 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/trie.py
--rw-r--r--   0 runner    (1001) docker     (122)     1696 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/type_assert.py
--rw-r--r--   0 runner    (1001) docker     (122)      296 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/typing.py
--rw-r--r--   0 runner    (1001) docker     (122)      783 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/dl/utils/url_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon/utils/
--rw-r--r--   0 runner    (1001) docker     (122)     3615 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4790 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/attack.py
--rw-r--r--   0 runner    (1001) docker     (122)     2373 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/char_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12460 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/conlleval.py
--rw-r--r--   0 runner    (1001) docker     (122)     2055 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/constants.py
--rw-r--r--   0 runner    (1001) docker     (122)     1249 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5286 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/dictionary.py
--rw-r--r--   0 runner    (1001) docker     (122)     3814 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/ema.py
--rw-r--r--   0 runner    (1001) docker     (122)     2379 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/email_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      668 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/encrypt_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      674 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/environment_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    11031 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4488 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/gpu_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1283 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/ip_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      627 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/json_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    21438 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/keyword_extract.py
--rw-r--r--   0 runner    (1001) docker     (122)     6569 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/label_studio_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4481 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/loss_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12341 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/midi_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5159 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/minjoin.py
--rw-r--r--   0 runner    (1001) docker     (122)      661 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/model_ensemble.py
--rw-r--r--   0 runner    (1001) docker     (122)     4831 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/music.py
--rw-r--r--   0 runner    (1001) docker     (122)    21209 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/ner_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      885 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/nextpow2.py
--rw-r--r--   0 runner    (1001) docker     (122)     5183 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/noise_reduction.py
--rw-r--r--   0 runner    (1001) docker     (122)     6305 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/note_plotter.py
--rw-r--r--   0 runner    (1001) docker     (122)    11716 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/number_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2746 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/onset_frames_split.py
--rw-r--r--   0 runner    (1001) docker     (122)     6713 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/optimizer_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1266 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/pdf_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2366 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/prune.py
--rw-r--r--   0 runner    (1001) docker     (122)     2434 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     9394 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/schedule_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      584 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/semantic_scholar.py
--rw-r--r--   0 runner    (1001) docker     (122)     1663 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/sound_plot_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2994 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/sound_recorder.py
--rw-r--r--   0 runner    (1001) docker     (122)     3194 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/states_machine.py
--rw-r--r--   0 runner    (1001) docker     (122)     3678 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/string_converter.py
--rw-r--r--   0 runner    (1001) docker     (122)    25723 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/string_similarity.py
--rw-r--r--   0 runner    (1001) docker     (122)    18063 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/string_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    10283 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/text_cluster.py
--rw-r--r--   0 runner    (1001) docker     (122)     1334 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/textrank.py
--rw-r--r--   0 runner    (1001) docker     (122)     8217 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/transformer_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6909 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/union_find.py
--rw-r--r--   0 runner    (1001) docker     (122)      532 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/wav_note.py
--rw-r--r--   0 runner    (1001) docker     (122)      653 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/wav_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    10737 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/word_discover.py
--rw-r--r--   0 runner    (1001) docker     (122)    41028 2023-06-14 11:15:16.000000 weathon-0.0.0.13/weathon/utils/word_finder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-14 11:15:47.000000 weathon-0.0.0.13/weathon.egg-info/
--rw-r--r--   0 runner    (1001) docker     (122)      859 2023-06-14 11:15:46.000000 weathon-0.0.0.13/weathon.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (122)   132857 2023-06-14 11:15:46.000000 weathon-0.0.0.13/weathon.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (122)        1 2023-06-14 11:15:46.000000 weathon-0.0.0.13/weathon.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (122)       53 2023-06-14 11:15:46.000000 weathon-0.0.0.13/weathon.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (122)        1 2023-06-14 11:15:46.000000 weathon-0.0.0.13/weathon.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (122)      248 2023-06-14 11:15:46.000000 weathon-0.0.0.13/weathon.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (122)        8 2023-06-14 11:15:46.000000 weathon-0.0.0.13/weathon.egg-info/top_level.txt
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/
+-rw-r--r--   0 runner    (1001) docker     (122)       53 2023-06-26 05:56:16.000000 weathon-0.0.0.14/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (122)      859 2023-06-26 05:56:17.000000 weathon-0.0.0.14/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (122)       72 2023-06-26 05:56:16.000000 weathon-0.0.0.14/README.md
+-rw-r--r--   0 runner    (1001) docker     (122)       38 2023-06-26 05:56:17.000000 weathon-0.0.0.14/setup.cfg
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/
+-rw-r--r--   0 runner    (1001) docker     (122)     3737 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/base/
+-rw-r--r--   0 runner    (1001) docker     (122)      772 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      353 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/cli.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1326 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/data_downloader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1561 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21080 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6399 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2497 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/lr_scheduler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1410 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13257 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1873 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/modeloutput.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22788 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9376 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    76917 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/base/trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)     3818 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      677 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1680 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/asr_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8509 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/kws_farfield_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7617 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/kws_nearfield_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11686 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/kws_nearfield_processor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/bad_image_detecting/
+-rw-r--r--   0 runner    (1001) docker     (122)      488 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/bad_image_detecting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1264 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/
+-rw-r--r--   0 runner    (1001) docker     (122)       84 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4705 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/build.py
+-rw-r--r--   0 runner    (1001) docker     (122)      936 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/collate_batch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      127 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3812 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/datasets/coco.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16174 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/datasets/mosaic_wrapper.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/evaluation/
+-rw-r--r--   0 runner    (1001) docker     (122)      934 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/evaluation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/evaluation/coco/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/evaluation/coco/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11563 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/evaluation/coco/coco_eval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/samplers/
+-rw-r--r--   0 runner    (1001) docker     (122)      312 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/samplers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2484 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/samplers/distributed.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4736 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1348 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/transforms/
+-rw-r--r--   0 runner    (1001) docker     (122)      196 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/transforms/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1028 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/transforms/build.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2388 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/transforms/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1465 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/easycv_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2031 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/gopro_image_deblurring_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_colorization/
+-rw-r--r--   0 runner    (1001) docker     (122)      486 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_colorization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2135 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_colorization/image_colorization_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      476 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_inpainting/aug.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12289 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_inpainting/image_inpainting_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12560 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_instance_segmentation_coco_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_portrait_enhancement/
+-rw-r--r--   0 runner    (1001) docker     (122)      524 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_portrait_enhancement/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_portrait_enhancement/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1568 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assessment_degradation/
+-rw-r--r--   0 runner    (1001) docker     (122)      562 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assessment_degradation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1418 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assmessment_mos/
+-rw-r--r--   0 runner    (1001) docker     (122)      530 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assmessment_mos/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1126 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4833 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/language_guided_video_summarization_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5943 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/mgeo_ranking_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      506 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6130 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4013 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/movie_scene_segmentation/sampler.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      111 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1589 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/augmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5437 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/image_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/measures/
+-rw-r--r--   0 runner    (1001) docker     (122)       40 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/measures/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7547 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/measures/iou_evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3416 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/measures/quad_measurer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/
+-rw-r--r--   0 runner    (1001) docker     (122)      309 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3172 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/augment_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)      971 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/data_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5818 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/make_border_map.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2000 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/make_icdar_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/make_seg_detection_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)      707 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/normalize_image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/random_crop_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2197 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_recognition_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1781 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/reds_image_deblurring_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/referring_video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      546 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/referring_video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16747 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8722 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/referring_video_object_segmentation/transformers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/sidd_image_denoising/
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/sidd_image_denoising/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1475 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/sidd_image_denoising/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1923 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2684 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/sidd_image_denoising/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4840 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/text_ranking_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2609 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/veco_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_frame_interpolation/
+-rw-r--r--   0 runner    (1001) docker     (122)      520 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_frame_interpolation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1390 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_frame_interpolation/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1584 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_stabilization/
+-rw-r--r--   0 runner    (1001) docker     (122)      490 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_stabilization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      748 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_stabilization/video_stabilization_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2581 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_summarization_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      500 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2309 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/custom_datasets/video_super_resolution/video_super_resolution_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/cv/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/cv/ocr_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/cv/ocr_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2990 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/cv/ocr_detection/datasets.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/nlp/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/datasets/nlp/text_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)       89 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/nlp/text_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1637 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/datasets/nlp/text_classification/datasets.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/errors/
+-rw-r--r--   0 runner    (1001) docker     (122)       73 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/errors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6288 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/errors/error.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4018 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/errors/hub_error.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/exporters/
+-rw-r--r--   0 runner    (1001) docker     (122)      807 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/exporters/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      453 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2149 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/audio/ans_dfsmn_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/exporters/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)      815 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/cv/cartoon_translation_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3539 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/cv/face_detection_scrfd_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1072 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/cv/object_detection_damoyolo_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/exporters/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     1028 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7325 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/nlp/csanmt_for_translation_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4458 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/nlp/model_for_token_classification_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3483 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/nlp/sbert_for_sequence_classification_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2552 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/exporters/nlp/sbert_for_zero_shot_classification_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/hooks/
+-rw-r--r--   0 runner    (1001) docker     (122)     2011 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/hooks/checkpoint/
+-rw-r--r--   0 runner    (1001) docker     (122)      116 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/checkpoint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18338 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/checkpoint/checkpoint_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10623 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/checkpoint/checkpoint_processor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5445 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/checkpoint/load_checkpoint_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)      747 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/clip_clamp_logit_scale_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/hooks/compression/
+-rw-r--r--   0 runner    (1001) docker     (122)      557 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/compression/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5022 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/compression/sparsity_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6861 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/compression/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/hooks/distributed/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/distributed/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1340 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/distributed/ddp_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8010 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/distributed/deepspeed_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6617 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/distributed/megatron_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4421 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/early_stop_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3811 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/evaluation_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)      682 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/iter_timer_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/hooks/logger/
+-rw-r--r--   0 runner    (1001) docker     (122)      606 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/logger/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4390 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/logger/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4438 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/logger/tensorboard_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7385 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/logger/text_logger_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6279 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/lr_scheduler_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/hooks/optimizer/
+-rw-r--r--   0 runner    (1001) docker     (122)      690 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/optimizer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3074 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/optimizer/apex_optimizer_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3694 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/optimizer/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3538 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/hooks/optimizer/torch_optimizer_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/inference/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/inference/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10944 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/inference/inference.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/lrscheduler/
+-rw-r--r--   0 runner    (1001) docker     (122)      520 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/lrscheduler/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2880 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/lrscheduler/warmup.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/metrics/
+-rw-r--r--   0 runner    (1001) docker     (122)     3727 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2548 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/accuracy_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7479 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/action_detection_evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1920 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/audio_noise_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1813 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/bleu_metric.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/metrics/ciderD/
+-rwxr-xr-x   0 runner    (1001) docker     (122)       21 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/ciderD/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1926 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/ciderD/ciderD.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8931 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/ciderD/ciderD_scorer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8999 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/image_color_enhance_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13213 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/image_colorization_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9717 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/image_denoise_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7645 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/image_inpainting_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13353 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/image_instance_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1817 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/image_portrait_enhancement_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2527 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/image_quality_assessment_degradation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1596 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/image_quality_assessment_mos_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2220 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/inbatch_recall_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1248 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/loss_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3054 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/map_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2042 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/movie_scene_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3255 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/ned_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2507 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/ocr_recognition_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2138 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/ppl_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)      960 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/prediction_saving_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4496 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/referring_video_object_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3132 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/sequence_classification_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3212 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/text_generation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3373 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/text_ranking_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5834 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/token_classification_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5705 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/translation_evaluation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5458 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/video_frame_interpolation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8836 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/video_stabilization_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3223 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/video_summarization_metric.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7030 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/matlab_functions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4771 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/metric_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8908 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/niqe.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1685 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/video_super_resolution_metric.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      177 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)       42 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/aec/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/aec/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1383 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/layers/activations.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2649 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/layers/affine_transform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5579 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/layers/deep_fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1271 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/layers/layer_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14333 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/layers/uni_deep_fsmn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/aec/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14387 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/network/loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9331 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/network/modulation_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15333 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/aec/network/se_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/ans/
+-rw-r--r--   0 runner    (1001) docker     (122)      462 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/complex_nn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3638 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/conv_stft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2484 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/denoise_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10139 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/frcrn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/ans/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1414 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/layers/activations.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2357 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/layers/affine_transform.py
+-rw-r--r--   0 runner    (1001) docker     (122)      610 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/layers/layer_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5227 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/layers/uni_deep_fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)      988 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/se_module_complex.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9783 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/ans/unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/asr/
+-rw-r--r--   0 runner    (1001) docker     (122)      532 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/asr/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1832 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/asr/generic_automatic_speech_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1149 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/asr/wenet_automatic_speech_recognition.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/itn/
+-rw-r--r--   0 runner    (1001) docker     (122)      504 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/itn/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1513 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/itn/generic_inverse_text_processing.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/kws/
+-rw-r--r--   0 runner    (1001) docker     (122)      682 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/kws/farfield/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/farfield/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14298 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/farfield/fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7411 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/farfield/fsmn_sele_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7810 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/farfield/fsmn_sele_v3.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3457 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/farfield/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2557 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/farfield/model_def.py
+-rw-r--r--   0 runner    (1001) docker     (122)      976 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/generic_key_word_spotting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/kws/nearfield/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/nearfield/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3300 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/nearfield/cmvn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17496 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/nearfield/fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5955 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/kws/nearfield/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/punc/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/punc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1533 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/punc/generic_punctuation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/separation/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/separation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2240 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/separation/layer_norm.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14024 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/separation/mossformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9088 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/separation/mossformer_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8953 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/separation/mossformer_conv_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/sv/
+-rw-r--r--   0 runner    (1001) docker     (122)     6972 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/DTDNN.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8375 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/DTDNN_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11468 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/ERes2Net.py
+-rw-r--r--   0 runner    (1001) docker     (122)      445 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14602 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/ecapa_tdnn.py
+-rw-r--r--   0 runner    (1001) docker     (122)      854 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/fusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1415 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/generic_speaker_verification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3580 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/pooling_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16959 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/rdino.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12048 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/sv/speaker_change_locator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/audio/tts/
+-rw-r--r--   0 runner    (1001) docker     (122)      421 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/tts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11722 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/tts/sambert_hifi.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26330 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/audio/tts/voice.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1761 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      437 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3875 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/
+-rw-r--r--   0 runner    (1001) docker     (122)       63 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/roi_head/
+-rw-r--r--   0 runner    (1001) docker     (122)      161 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/roi_head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6414 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/
+-rw-r--r--   0 runner    (1001) docker     (122)       95 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6729 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/action_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      440 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7325 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_detection/action_detection_onnx.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/action_detection/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_detection/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9303 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_detection/modules/action_detection_pytorch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12081 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_detection/modules/resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/action_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      656 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4304 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_recognition/models.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10276 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_recognition/s3dg.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_recognition/tada_convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45437 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/action_recognition/temporal_patch_shift_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/animal_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      505 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/animal_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14141 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/animal_recognition/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3955 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/animal_recognition/splat.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/bad_image_detecting/
+-rw-r--r--   0 runner    (1001) docker     (122)      443 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/bad_image_detecting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2505 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/bad_image_detecting/bad_image_detecting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/body_2d_keypoints/
+-rw-r--r--   0 runner    (1001) docker     (122)      449 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_2d_keypoints/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12660 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_2d_keypoints/hrnet_basic_modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8737 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_2d_keypoints/hrnet_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_2d_keypoints/w48.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/
+-rw-r--r--   0 runner    (1001) docker     (122)      548 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/cannonical_pose/
+-rw-r--r--   0 runner    (1001) docker     (122)       51 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/cannonical_pose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8874 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8196 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/
+-rw-r--r--   0 runner    (1001) docker     (122)       48 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11543 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12870 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8030 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/directed_graph.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2463 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/hdformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7624 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/skeleton.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/
+-rw-r--r--   0 runner    (1001) docker     (122)     1163 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/LK/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/LK/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3485 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/LK/lk.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      713 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/face_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5158 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/face_landmark.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4563 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/facer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9075 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2117 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/model_tf.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/mtcnn_pytorch/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/mtcnn_pytorch/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/mtcnn_pytorch/src/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/mtcnn_pytorch/src/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6072 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8519 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4404 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5214 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cartoon/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/
+-rw-r--r--   0 runner    (1001) docker     (122)      644 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3876 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/c3d.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/resnet2p1d.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8949 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/resnet3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      411 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13516 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/annotator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4960 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/api.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      504 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10152 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2746 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5829 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8045 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15438 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/mlsd/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/mlsd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9896 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25158 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/mlsd/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12595 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/body.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3894 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/hand.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9024 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8031 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8544 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/controlnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/crowd_counting/
+-rw-r--r--   0 runner    (1001) docker     (122)      438 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/crowd_counting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1002 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/crowd_counting/cc_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22872 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/crowd_counting/hrnet_aspp_relu.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_attribute_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      437 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_attribute_recognition/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_attribute_recognition/fair_face/
+-rw-r--r--   0 runner    (1001) docker     (122)       65 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_attribute_recognition/fair_face/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2559 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      877 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3021 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/detectors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4675 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/mogface.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5578 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/mogprednet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6264 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/resnet.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7072 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/
+-rw-r--r--   0 runner    (1001) docker     (122)       47 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7061 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5414 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/first_stage.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5232 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/get_nets.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/LK/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/LK/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/LK/lk.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3578 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/face_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5129 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/face_landmark.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4210 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/facer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)       43 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4836 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/models/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4766 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/models/net.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4590 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/models/retinaface.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/
+-rw-r--r--   0 runner    (1001) docker     (122)      124 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      898 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/damofd_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      192 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/
+-rw-r--r--   0 runner    (1001) docker     (122)      325 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2945 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      292 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      276 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      471 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11707 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4169 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    30670 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5543 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      289 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      361 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4149 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3590 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16146 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      270 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    46999 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      295 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11062 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6092 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6395 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5970 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3393 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3257 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/scrfd_detect.py
+-rw-r--r--   0 runner    (1001) docker     (122)      729 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/tinymog_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/
+-rw-r--r--   0 runner    (1001) docker     (122)       40 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1477 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4126 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2058 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      571 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3719 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2845 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4621 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1497 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/
+-rw-r--r--   0 runner    (1001) docker     (122)      537 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/efficient/
+-rw-r--r--   0 runner    (1001) docker     (122)      327 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/efficient/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15911 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/efficient/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20077 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/efficient/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2004 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/emotion_infer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3111 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/emotion_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/face_alignment/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/face_alignment/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2844 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/face_alignment/face.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_emotion/face_alignment/face_align.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      422 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_generation/op/
+-rwxr-xr-x   0 runner    (1001) docker     (122)       89 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_generation/op/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6497 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_generation/op/conv2d_gradfix.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3104 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_generation/op/fused_act.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5922 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_generation/op/upfirdn2d.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    19998 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_generation/stylegan2.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      541 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4105 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/det_infer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12584 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/ghost_pan.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16846 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/nanodet_plus_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1833 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/one_stage_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5791 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/shufflenetv2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8874 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1572 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/align_face.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      470 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1080 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1977 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7572 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8551 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/model_irse.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4744 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/model_resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7125 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/rts_backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31337 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/bfm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1378 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/de_retouching_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2533 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/nets/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/nets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6511 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5074 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30347 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facerecon_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13121 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21235 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8821 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/nv_diffrast.py
+-rw-r--r--   0 runner    (1001) docker     (122)      227 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/opt.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/pix2pix/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/pix2pix/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31957 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/pix2pix/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5908 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)      729 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    13410 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/renderer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4883 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31197 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/face_reconstruction/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      431 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/fer/
+-rw-r--r--   0 runner    (1001) docker     (122)       71 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/fer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3277 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/fer/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1315 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/fer/vgg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/facial_landmark_confidence/
+-rw-r--r--   0 runner    (1001) docker     (122)      425 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_landmark_confidence/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/facial_landmark_confidence/flc/
+-rw-r--r--   0 runner    (1001) docker     (122)       65 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_landmark_confidence/flc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3147 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4882 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/hand_static/
+-rw-r--r--   0 runner    (1001) docker     (122)      499 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/hand_static/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2372 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/hand_static/hand_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10891 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/hand_static/networks.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/
+-rw-r--r--   0 runner    (1001) docker     (122)     5868 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/Reconstruction.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/
+-rw-r--r--   0 runner    (1001) docker     (122)     1015 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/Embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4492 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/PixToMesh.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11251 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/Res_backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2368 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/Surface_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2716 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/detectors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1982 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/geometry.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/human_segmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11865 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6105 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/human_reconstruction/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_binary_quant_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      570 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_binary_quant_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2760 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_binary_quant_classification/binary_quant_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19111 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_binary_quant_classification/bnext.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/
+-rw-r--r--   0 runner    (1001) docker     (122)      447 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3829 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/image_body_reshaping.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6491 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13566 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/person_info.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/pose_estimator/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/pose_estimator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12027 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/pose_estimator/body.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5673 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/pose_estimator/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/pose_estimator/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15709 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/slim_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      545 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)       57 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20295 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/backbones/beit_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17261 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/backbones/nextvit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2070 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/mmcls_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1447 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/resnet50_cc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5205 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_classification/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/
+-rw-r--r--   0 runner    (1001) docker     (122)      651 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/adaint/
+-rw-r--r--   0 runner    (1001) docker     (122)       44 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/adaint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14273 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/adaint/adaint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3753 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/csrnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/deeplpf/
+-rw-r--r--   0 runner    (1001) docker     (122)       66 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/deeplpf/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2522 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31764 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/deeplpf/deeplpfnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2768 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_color_enhance/image_color_enhance.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/
+-rw-r--r--   0 runner    (1001) docker     (122)      587 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/
+-rw-r--r--   0 runner    (1001) docker     (122)       72 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9334 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/ddcolor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6384 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9576 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/loss.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6857 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7796 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/transformer_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6465 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6510 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/vgg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/unet/
+-rw-r--r--   0 runner    (1001) docker     (122)       79 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/unet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10574 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/unet/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10647 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_colorization/unet/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_debanding/
+-rw-r--r--   0 runner    (1001) docker     (122)      430 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_debanding/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_debanding/rrdb/
+-rw-r--r--   0 runner    (1001) docker     (122)       53 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_debanding/rrdb/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2949 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_debanding/rrdb/rrdb_image_debanding.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_deblur/
+-rw-r--r--   0 runner    (1001) docker     (122)      457 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_deblur/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4186 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_deblur/nafnet_for_image_deblur.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/
+-rw-r--r--   0 runner    (1001) docker     (122)      439 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4275 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/evaluation/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/evaluation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12474 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3141 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/evaluation/evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      395 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6824 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/calibration_layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7064 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/defrcn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10779 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/fast_rcnn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1220 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/gdl.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1681 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4770 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/roi_heads.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23599 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/coco_register.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4807 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3595 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py
+-rw-r--r--   0 runner    (1001) docker     (122)      532 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/register_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2563 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/requirements_check.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11013 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/voc_register.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_denoise/
+-rw-r--r--   0 runner    (1001) docker     (122)      461 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_denoise/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_denoise/nafnet/
+-rw-r--r--   0 runner    (1001) docker     (122)     6664 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_denoise/nafnet/NAFNet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_denoise/nafnet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1627 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_denoise/nafnet/arch_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2423 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_denoise/nafnet_for_image_denoise.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6707 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/newcrf_depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18183 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/newcrf_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10056 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/newcrf_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26006 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13510 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/uper_crf_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1524 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/newcrfs_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/
+-rw-r--r--   0 runner    (1001) docker     (122)      483 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1435 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/bts_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2819 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2506 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8545 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_driving_perception/
+-rw-r--r--   0 runner    (1001) docker     (122)      996 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_driving_perception/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_driving_perception/image_driving_percetion_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4285 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_driving_perception/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7475 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_driving_perception/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      435 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3074 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/gan_wrap.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21432 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/op/
+-rw-r--r--   0 runner    (1001) docker     (122)      242 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/op/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6497 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3094 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/op/fused_act.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5912 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/op/upfirdn2d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facelib/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facelib/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10514 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facelib/align_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5955 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facelib/matlab_cp2tform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9021 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/image_face_fusion.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2995 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/aad_layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8505 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/aei_flow_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9366 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/bfm.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12449 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/dense_motion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20604 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/facerecon_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7433 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/model_irse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7740 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/ops.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/
+-rw-r--r--   0 runner    (1001) docker     (122)      522 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      472 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11733 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/backbone/deeplab_resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp/
+-rw-r--r--   0 runner    (1001) docker     (122)      587 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8248 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp/m2fp_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8352 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp/m2fp_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15090 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5633 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_human_parsing/parsing_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      422 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2687 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7602 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/default.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1199 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/ade20k/
+-rw-r--r--   0 runner    (1001) docker     (122)       31 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/ade20k/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12202 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/ade20k/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5348 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/ade20k/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7509 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/adversarial.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1564 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/feature_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19052 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/ffc.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11839 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/inception.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/perceptual.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/pix2pixhd.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13350 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_inpainting/refinement.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)     1012 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      611 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3820 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/backbones/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27174 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/backbones/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9297 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)       51 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3939 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/datasets/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/fastinst/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/fastinst/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14814 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6213 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8685 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/fastinst_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/
+-rw-r--r--   0 runner    (1001) docker     (122)      547 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10072 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/dino_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15407 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18188 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7223 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2720 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6712 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1379 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11446 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino_swin.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1499 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7883 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/postprocess_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/
+-rw-r--r--   0 runner    (1001) docker     (122)      500 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/config/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6991 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/config/default.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/
+-rw-r--r--   0 runner    (1001) docker     (122)      171 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      588 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7244 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3784 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/
+-rw-r--r--   0 runner    (1001) docker     (122)      239 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3012 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2946 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9677 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10531 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3048 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2132 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2625 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/quadtree_attention_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      344 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_matching/utils/misc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      468 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8496 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/cas_mvsnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6199 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/casmvs_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18175 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9861 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/depth_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9354 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/general_eval_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21735 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3367 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_paintbyexample/
+-rw-r--r--   0 runner    (1001) docker     (122)      454 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_paintbyexample/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1456 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_paintbyexample/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_panoptic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      460 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_panoptic_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1643 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_panoptic_segmentation/panseg_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/
+-rw-r--r--   0 runner    (1001) docker     (122)      485 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8560 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/align_faces.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/eqface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/eqface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1786 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/eqface/fqa.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4710 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/eqface/model_resnet.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    22866 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/gpen.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7065 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/image_portrait_enhancement.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/losses/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/losses/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4336 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/losses/helpers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3286 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/losses/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3155 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/losses/model_irse.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7313 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/models/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4845 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/models/net.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4676 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_probing_model/
+-rw-r--r--   0 runner    (1001) docker     (122)      530 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_probing_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10076 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_probing_model/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3170 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_probing_model/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5206 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_probing_model/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_degradation/
+-rw-r--r--   0 runner    (1001) docker     (122)      531 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_degradation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5064 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_degradation/degradation_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4562 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_man/
+-rw-r--r--   0 runner    (1001) docker     (122)      491 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_man/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2545 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_man/image_quality_assessment_man.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5163 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_man/maniqa.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23230 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_man/swin.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/
+-rw-r--r--   0 runner    (1001) docker     (122)      491 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      272 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16222 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/backbones/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1060 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      529 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/heads/simple_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2596 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_reid_person/
+-rw-r--r--   0 runner    (1001) docker     (122)      414 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_reid_person/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5447 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_reid_person/pass_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14108 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_reid_person/transreid_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_restoration/
+-rw-r--r--   0 runner    (1001) docker     (122)      474 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_restoration/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_restoration/demoire_models/
+-rw-r--r--   0 runner    (1001) docker     (122)       69 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_restoration/demoire_models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10243 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_restoration/demoire_models/nets.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2593 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_restoration/image_restoration_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      659 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7896 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4607 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5104 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2273 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3157 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/pan_merge/
+-rw-r--r--   0 runner    (1001) docker     (122)       61 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/pan_merge/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1516 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2072 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/semantic_seg_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/
+-rw-r--r--   0 runner    (1001) docker     (122)      303 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      290 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      249 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17484 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/
+-rw-r--r--   0 runner    (1001) docker     (122)      196 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18241 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6379 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      251 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26514 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/
+-rw-r--r--   0 runner    (1001) docker     (122)      253 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12370 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11715 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      368 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      398 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1938 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1788 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/
+-rw-r--r--   0 runner    (1001) docker     (122)      647 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9231 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/
+-rw-r--r--   0 runner    (1001) docker     (122)     3740 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/BlockModules.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21275 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/hrnet_backnone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18023 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11160 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/skychange.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7786 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_skychange/skychange_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      120 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      558 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/data/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10476 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      600 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/models/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/models/clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/ops/
+-rw-r--r--   0 runner    (1001) docker     (122)      558 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/ops/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24469 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/ops/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/ops/losses.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/
+-rw-r--r--   0 runner    (1001) docker     (122)      533 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      127 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/data/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10527 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/model_translation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      161 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/models/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/models/clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/
+-rw-r--r--   0 runner    (1001) docker     (122)      384 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21828 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/apps.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/degradation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24615 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/metrics.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6736 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/random_color.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2745 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/random_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3777 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/svd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6728 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      432 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)       86 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4048 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6880 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/misc/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/misc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2460 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/misc/fourier.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3200 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/misc/panostretch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14837 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/misc/post_proc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/modality/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/modality/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5467 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/modality/layout.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3355 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/panovit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4757 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1777 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/panovit.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      489 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6217 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/summarizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      455 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1900 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/layers.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7275 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/models.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)      826 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/modules.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2690 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/sub_layers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      586 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2151 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/cfg_sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26783 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13594 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/mdm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5412 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/respace.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3911 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/rotation2xyz.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/smpl.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      562 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/get_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8465 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      131 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      798 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4291 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/save_op.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10325 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/shot_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5057 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/trn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/
+-rw-r--r--   0 runner    (1001) docker     (122)      549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/dataloader/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/dataloader/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18732 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20567 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/dataloader/read_write_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7184 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/nerf_preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7803 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/nerf_recon_acc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13317 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/network/nerf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1459 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/network/segmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5720 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/network/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      553 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3385 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/
+-rw-r--r--   0 runner    (1001) docker     (122)      321 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      211 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21306 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/backbones/vit.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/dense_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      278 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/dense_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2220 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11529 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      213 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9021 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/necks/fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      426 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      375 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8542 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      239 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17739 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      306 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21926 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/utils/checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/
+-rw-r--r--   0 runner    (1001) docker     (122)      414 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2604 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/depe_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/
+-rw-r--r--   0 runner    (1001) docker     (122)      605 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/
+-rw-r--r--   0 runner    (1001) docker     (122)      299 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6667 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/
+-rw-r--r--   0 runner    (1001) docker     (122)      282 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4473 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/
+-rw-r--r--   0 runner    (1001) docker     (122)      276 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1064 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2041 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      294 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3095 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/
+-rw-r--r--   0 runner    (1001) docker     (122)      522 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7936 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8689 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      255 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12874 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      282 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7442 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    59194 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/
+-rw-r--r--   0 runner    (1001) docker     (122)      255 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9533 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      256 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9032 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      562 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18126 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5175 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11047 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/result_vis.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      420 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2785 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18335 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/modules/dbnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8217 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/modules/seg_detector_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2591 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7922 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      424 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6085 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)      467 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/convnextvit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3451 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/crnn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/timm_tinyc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/vitstr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3617 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/ocr_recognition/preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/open_vocabulary_detection_vild/
+-rw-r--r--   0 runner    (1001) docker     (122)      448 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/open_vocabulary_detection_vild/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14079 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/open_vocabulary_detection_vild/vild.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      458 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)       52 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5027 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/equi.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7450 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7789 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/mobilenet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14371 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9125 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/unifuse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3912 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3244 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/unifuse_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/pedestrian_attribute_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      435 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/pedestrian_attribute_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3437 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/pedestrian_attribute_recognition/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      442 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16097 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11898 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1740 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/rcp_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18568 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/
+-rw-r--r--   0 runner    (1001) docker     (122)      545 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20974 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/item_detection.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/item_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4324 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/item_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/product_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      525 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/product_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7978 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/product_segmentation/net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2190 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/product_segmentation/seg_infer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      461 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      268 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8504 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9206 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/criterion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7299 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/matcher.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7935 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/mttr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16610 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2091 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5629 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/postprocessing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5180 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27941 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/swin_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/robust_image_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      448 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/robust_image_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2854 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/robust_image_classification/easyrobust_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      444 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      213 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)     6558 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/backbone/Res2Net_v1b.py
+-rw-r--r--   0 runner    (1001) docker     (122)      256 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6475 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2997 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/senet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12007 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/u2net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3524 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/models/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2657 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/salient_detection/salient_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      411 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2203 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4385 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/head_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    32989 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/models.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9319 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/neck_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5632 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/shop_seg_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3901 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/shop_seg_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6699 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/shop_segmentation/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/detection_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/detection_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1730 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/detection_model/detection_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2482 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/detection_model/detection_unet_in.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/inpainting_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/inpainting_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5709 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/inpainting_model/gconv.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3180 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/inpainting_model/inpainting_unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10898 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3911 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5003 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/predict_single.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1035 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/prior_box.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2110 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3840 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/unet_deploy.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9867 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1119 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/skin_retouching/weights_init.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/
+-rw-r--r--   0 runner    (1001) docker     (122)      473 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/data/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2094 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/data/data_augment.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/
+-rw-r--r--   0 runner    (1001) docker     (122)      165 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      274 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/base_exp.py
+-rw-r--r--   0 runner    (1001) docker     (122)      392 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/build.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/default/
+-rw-r--r--   0 runner    (1001) docker     (122)      137 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/default/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/default/streamyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1845 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/yolox_base.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      238 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/darknet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10911 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/dfp_pafpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6156 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/network_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1314 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/streamyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5669 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/tal_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4237 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/realtime_video_detector.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      270 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3681 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/utils/boxes.py
+-rw-r--r--   0 runner    (1001) docker     (122)      159 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/stream_yolo/utils/format.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      502 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7652 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/super_resolution/arch_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10508 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/super_resolution/ecb.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3473 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/super_resolution/ecbsr_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/super_resolution/rrdbnet_arch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/table_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      409 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/table_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15842 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/table_recognition/lineless_table_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3312 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/table_recognition/model_lore.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon/models/cv/table_recognition/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/table_recognition/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12614 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/table_recognition/modules/lore_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15090 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/table_recognition/modules/lore_processor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5488 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)      777 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7587 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4079 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6145 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18951 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16418 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5165 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/simple_tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/
+-rw-r--r--   0 runner    (1001) docker     (122)      541 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    43631 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/basic_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2124 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/global_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2852 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/master_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)      716 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/model_zoo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2842 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/plain_net_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7355 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/super_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14933 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/super_res_idwexkx.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8659 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/super_res_k1kxk1.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6873 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/super_res_kxkx.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      646 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/apis/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/apis/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2007 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/apis/detector_evaluater.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3938 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/apis/detector_inference.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3460 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8123 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2345 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5911 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2842 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/
+-rw-r--r--   0 runner    (1001) docker     (122)       98 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      570 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3647 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9306 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7415 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14211 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/base_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10509 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13050 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/ops.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    18572 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7476 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2521 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      561 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/weight_init.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      358 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19093 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/losses/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/losses/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5537 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12281 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      370 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7296 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24789 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3445 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/detectors/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2740 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/detectors/detector.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/structures/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/structures/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9197 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/structures/bounding_box.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2627 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/structures/boxlist_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2774 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/structures/image_list.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      189 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11540 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/utils/boxes.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5838 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/utils/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1114 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/utils/scheduler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6340 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)      578 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/tinynas_damoyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)      595 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/tinynas_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)      976 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/tinynas_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/
+-rw-r--r--   0 runner    (1001) docker     (122)     2841 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/UNet_for_video_deinterlace.py
+-rw-r--r--   0 runner    (1001) docker     (122)      441 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      717 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/deinterlace_arch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3109 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/archs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1441 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/deep_fourier_upsampling.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2916 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/enh.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3516 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/fre.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3666 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      430 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/configs/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/configs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12753 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/configs/default_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6662 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/dro_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5435 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/camera.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2235 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/camera_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3684 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/pose.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3632 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/pose_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5277 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/model_checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2353 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10092 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/model_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7192 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/sfm_model_mf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4378 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/sup_model_mf.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/depth_pose/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/depth_pose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10517 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8902 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1607 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1915 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/optim/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/optim/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15781 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/optim/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8039 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/optim/update.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6812 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/augmentations.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10236 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15062 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1153 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/horovod.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10962 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9404 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/image_gt.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6490 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/load.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2723 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1348 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/types.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/
+-rw-r--r--   0 runner    (1001) docker     (122)     1835 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/VFINet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3276 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py
+-rw-r--r--   0 runner    (1001) docker     (122)      405 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3209 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/corr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9228 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5334 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/update.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/
+-rw-r--r--   0 runner    (1001) docker     (122)    13742 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4049 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/UNet.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3823 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/flow_reversal.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16041 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36415 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/transformer_layers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3264 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/utils/scene_change_detection.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2907 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/utils/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/
+-rw-r--r--   0 runner    (1001) docker     (122)      555 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1131 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10465 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2662 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/deep_guided_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5506 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/effv2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2904 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/lraspp.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2234 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/matting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      521 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11056 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_inpainting/inpainting.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13720 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_inpainting/inpainting_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      529 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18236 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21551 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16955 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20983 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4136 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_updator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/neck/
+-rw-r--r--   0 runner    (1001) docker     (122)      472 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/neck/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11733 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/track/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/track/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26843 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/track/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10771 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4163 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17498 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/video_knet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/
+-rw-r--r--   0 runner    (1001) docker     (122)      488 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2970 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2417 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/decode.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1887 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4919 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/yolo.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/tracker/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/tracker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1084 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/tracker/basetrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3111 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/tracker/matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14974 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/tracker/multitracker.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2230 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9570 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/kalman_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7296 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2888 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/visualization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      494 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      818 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/aggregate.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3582 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/cbam.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1973 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/eval_network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3974 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/inference_core.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/inference_memory_bank.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7037 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/mod_resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)      919 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15306 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5590 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/network.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      424 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10040 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26628 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/
+-rw-r--r--   0 runner    (1001) docker     (122)      462 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8349 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/kernel_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20677 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28653 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4081 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/kernel_updator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6696 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8627 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5885 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/track_heads.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/neck/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/neck/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6255 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/neck/fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/track/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/track/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8508 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17029 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/video_k_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5440 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/visualizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/config/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1024 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/config/ostrack.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/attn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5004 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/attn_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4805 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1234 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/patch_embed.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3377 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3390 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/ostrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)      653 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12272 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/procontext/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/procontext/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3494 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/procontext/procontext.py
+-rw-r--r--   0 runner    (1001) docker     (122)      943 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/procontext/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4461 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/procontext/vit_ce.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/tracker/
+-rw-r--r--   0 runner    (1001) docker     (122)       64 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/tracker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5498 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/tracker/ostrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7117 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/tracker/procontext.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8488 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/utils/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/
+-rw-r--r--   0 runner    (1001) docker     (122)    14690 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/DUT_raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4709 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/MotionPro.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3287 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/corr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9214 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5272 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5526 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/update.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3919 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/Smoother.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1447 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7289 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/rf_det_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7975 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/rf_det_so.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3441 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUTRAFTStabilizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      439 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)     4684 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/IterativeSmooth.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14209 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/MedianFilter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22544 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/ProjectionUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2893 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/RAFTUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2817 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/WarpUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14471 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/image_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4977 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/math_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/
+-rw-r--r--   0 runner    (1001) docker     (122)      434 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/exp/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/exp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2482 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7041 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/longshortnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5768 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4842 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9987 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/longshort.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3899 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/
+-rw-r--r--   0 runner    (1001) docker     (122)      483 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4959 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/base_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/kts/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/kts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1221 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/kts/cpd_auto.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3238 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/kts/cpd_nonlin.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13098 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/pgl_sum.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8803 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_summarization/summarizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/video_super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      636 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14115 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_super_resolution/basicvsr_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4727 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_super_resolution/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4646 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_super_resolution/msrresnet_lite_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3578 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3634 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/video_super_resolution/real_basicvsr_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/vidt/
+-rw-r--r--   0 runner    (1001) docker     (122)      411 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vidt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    40074 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vidt/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25588 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vidt/deformable_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7436 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vidt/fpn_fusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16697 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vidt/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3650 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vidt/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/virual_tryon/
+-rw-r--r--   0 runner    (1001) docker     (122)      411 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/virual_tryon/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17698 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/virual_tryon/sdafnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)      449 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16102 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)      797 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1785 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9340 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/petl.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5021 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/timm_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/timm_vision_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5040 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/timm_weight_init.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5609 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/vision_efficient_tuning.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/vision_middleware/
+-rw-r--r--   0 runner    (1001) docker     (122)      439 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_middleware/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5749 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_middleware/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28089 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_middleware/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6490 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_middleware/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6192 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vision_middleware/vim.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/cv/vop_retrieval/
+-rw-r--r--   0 runner    (1001) docker     (122)      866 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vop_retrieval/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12235 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vop_retrieval/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5188 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vop_retrieval/basic_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13523 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vop_retrieval/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5214 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vop_retrieval/model_se.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5177 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/cv/vop_retrieval/tokenization_clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)     2129 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14496 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip/bert_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3898 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip/configuration_bert.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22332 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20998 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip/modeling_bert.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip_interrogator/
+-rw-r--r--   0 runner    (1001) docker     (122)       37 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip_interrogator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24283 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/clip_interrogator/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      140 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26649 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14402 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    39910 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/structbert.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11507 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11834 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/unet_generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8566 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/unet_upsampler_1024.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12361 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/diffusion/unet_upsampler_256.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44602 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/dpm_solver_pytorch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/efficient_diffusion_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)      487 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/efficient_diffusion_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10291 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/gemm/
+-rw-r--r--   0 runner    (1001) docker     (122)      139 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/gemm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21691 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/gemm/gemm_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3576 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/gemm/gemm_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/gemm/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      495 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36265 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/respace.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1362 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/script.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36898 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/mgeo/
+-rw-r--r--   0 runner    (1001) docker     (122)     1441 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mgeo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)   101683 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mgeo/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8591 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mgeo/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3177 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mgeo/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10271 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mgeo/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/
+-rw-r--r--   0 runner    (1001) docker     (122)      141 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/dataloaders/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/dataloaders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3786 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/dataloaders/rawvideo_util.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      162 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9770 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1442 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/dynamic_inverted_softmax.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21245 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/modeling.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18790 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/module_clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3577 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/module_cross.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5581 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/tokenization_clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4116 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/until_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/
+-rw-r--r--   0 runner    (1001) docker     (122)      739 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       35 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16605 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/clip/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6028 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/configuration_mplug.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)   120738 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/modeling_mplug.py
+-rw-r--r--   0 runner    (1001) docker     (122)    34049 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/mvit.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    21332 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug/predictor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5475 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug_for_all_tasks.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug_owl/
+-rw-r--r--   0 runner    (1001) docker     (122)      835 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug_owl/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10291 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug_owl/configuration_mplug_owl.py
+-rw-r--r--   0 runner    (1001) docker     (122)    63654 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/mplug_owl/modeling_mplug_owl.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      150 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10208 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11503 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28433 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13457 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/prior.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6898 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16675 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/upsampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6565 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/xglm.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)      255 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/adaptor/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/adaptor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18720 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/configuration_mmspeech.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16552 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/configuration_ofa.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1785 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/incremental_decoding_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21049 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/multihead_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5658 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/ngram_repeat_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)    43439 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/search.py
+-rw-r--r--   0 runner    (1001) docker     (122)    41970 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/sequence_generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16690 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/token_generation_constraints.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4883 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44296 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/modeling_mmspeech.py
+-rw-r--r--   0 runner    (1001) docker     (122)   100933 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/modeling_ofa.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13226 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15026 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/tokenization_ofa.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8002 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/tokenization_ofa_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      621 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/utils/constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1827 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8435 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa/vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24721 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa_for_all_tasks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12914 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/ofa_for_text_to_image_synthesis_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/rleg/
+-rw-r--r--   0 runner    (1001) docker     (122)      535 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/rleg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4862 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/rleg/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3397 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/rleg/rleg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/soonet/
+-rw-r--r--   0 runner    (1001) docker     (122)      625 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/soonet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9838 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/soonet/blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11896 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/soonet/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6168 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/soonet/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22584 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/soonet/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4885 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/soonet/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1597 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/soonet/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/team/
+-rw-r--r--   0 runner    (1001) docker     (122)      140 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/team/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5075 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/team/team_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11502 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/team/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/
+-rw-r--r--   0 runner    (1001) docker     (122)      485 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18477 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9264 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9495 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38498 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/unet_sd.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/
+-rw-r--r--   0 runner    (1001) docker     (122)       42 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11282 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/conv_fpn_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16512 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    47348 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/modeling_layout_roberta.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20903 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/processing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4629 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7333 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/multi_modal/vldoc/transformer_local.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     5549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/T5/
+-rw-r--r--   0 runner    (1001) docker     (122)      545 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/T5/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    67175 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/T5/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7488 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/T5/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21421 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/T5/text2text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bart/
+-rw-r--r--   0 runner    (1001) docker     (122)       62 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bart/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3016 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bart/text_error_correction.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/
+-rw-r--r--   0 runner    (1001) docker     (122)     1466 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    40425 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7255 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4073 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/document_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)      457 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6020 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/sentence_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7048 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/siamese_uie.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1413 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1083 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2085 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/token_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6867 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bert/word_alignment.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bloom/
+-rw-r--r--   0 runner    (1001) docker     (122)      419 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bloom/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      457 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/bloom/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/canmt/
+-rw-r--r--   0 runner    (1001) docker     (122)       51 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/canmt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    52235 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/canmt/canmt_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2806 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/canmt/canmt_translation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    35688 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/canmt/sequence_generator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      727 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    35473 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/codegeex.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4000 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/codegeex_for_code_generation.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3950 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/codegeex_for_code_translation.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     9997 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/inference.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6111 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/csanmt/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/csanmt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    61912 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/csanmt/translation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/
+-rw-r--r--   0 runner    (1001) docker     (122)     1768 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    47942 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6768 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10330 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21421 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10695 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/tokenization_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/
+-rw-r--r--   0 runner    (1001) docker     (122)      886 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7089 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1836 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/document_grounded_dialog_generate.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1216 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/document_grounded_dialog_rerank.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2203 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/document_grounded_dialog_retrieval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/fid_T5/
+-rw-r--r--   0 runner    (1001) docker     (122)     1079 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/fid_T5/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8326 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/fid_T5/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/
+-rw-r--r--   0 runner    (1001) docker     (122)     1178 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45082 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5045 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6786 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/
+-rw-r--r--   0 runner    (1001) docker     (122)      537 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/generation/
+-rw-r--r--   0 runner    (1001) docker     (122)       87 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/generation/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    10112 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/generation/strategies.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5152 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/initialize.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/kernels/
+-rw-r--r--   0 runner    (1001) docker     (122)     3263 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/kernels/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/quantization/
+-rw-r--r--   0 runner    (1001) docker     (122)     2635 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/quantization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/quantization/functional.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4510 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/quantization/layers.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    13746 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt2/
+-rw-r--r--   0 runner    (1001) docker     (122)      417 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      450 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt2/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/
+-rw-r--r--   0 runner    (1001) docker     (122)      799 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15922 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8971 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    51600 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/distributed_gpt3.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2819 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2586 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/
+-rw-r--r--   0 runner    (1001) docker     (122)      821 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13127 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5198 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/checkpointing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4930 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    49319 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/distributed_gpt_moe.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/experts.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3504 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2553 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/mappings.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23756 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/sharded_moe.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2686 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2277 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_neo/
+-rw-r--r--   0 runner    (1001) docker     (122)      421 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_neo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      465 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_neo/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/hf_transformers/
+-rw-r--r--   0 runner    (1001) docker     (122)      435 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/hf_transformers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4715 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/hf_transformers/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/llama/
+-rw-r--r--   0 runner    (1001) docker     (122)      813 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/llama/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    29152 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/llama/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4645 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/llama/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11299 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/llama/convert_llama_weights_to_hf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7164 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/llama/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10280 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/llama/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4667 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/llama/tokenization_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/lstm/
+-rw-r--r--   0 runner    (1001) docker     (122)      557 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/lstm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1273 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/lstm/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2133 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/lstm/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/
+-rw-r--r--   0 runner    (1001) docker     (122)      635 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    39816 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6546 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12392 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/fill_mask.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/
+-rw-r--r--   0 runner    (1001) docker     (122)      569 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    28115 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/arguments.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28162 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/blocklm_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17995 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/configure_data.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)    13656 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    20308 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/corpora.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45724 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/datasets.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3342 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/extraction.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8459 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9797 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/lazy_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7221 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/samplers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/sp_tokenizer.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    53304 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14551 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/tokenization_gpt2.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    15773 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/wordpiece.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21669 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/generation_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16146 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/mglm_for_text_summarization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      984 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5443 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/distributed.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9967 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/downstream.py
+-rw-r--r--   0 runner    (1001) docker     (122)    70249 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/modeling_bert.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8740 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/modeling_glm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2531 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/prompt.py
+-rw-r--r--   0 runner    (1001) docker     (122)    48886 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/process_grid.py
+-rw-r--r--   0 runner    (1001) docker     (122)      203 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/run_test.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13467 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10871 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/eval_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/language_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/language_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10032 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/language_model/dataset.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1900 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/language_model/detokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9960 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/language_model/finetune.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/seq2seq/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/seq2seq/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28186 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/seq2seq/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22654 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/seq2seq/evaluate.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5822 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/seq2seq/finetune.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/superglue/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/superglue/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    55015 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/superglue/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3279 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/superglue/evaluate.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5072 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/superglue/finetune.py
+-rw-r--r--   0 runner    (1001) docker     (122)    56975 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/superglue/pvp.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/test/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/test/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      950 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/test/test_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)      704 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/test/test_rel_shift.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17815 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/train_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19029 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/
+-rw-r--r--   0 runner    (1001) docker     (122)     1265 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5526 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    29453 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/dureader_eval.py
+-rw-r--r--   0 runner    (1001) docker     (122)    55432 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/peer/
+-rw-r--r--   0 runner    (1001) docker     (122)     1191 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/peer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    55762 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/peer/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11713 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/peer/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6166 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/peer/sas_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4936 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/peer/text_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug/
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3321 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug/AnnealingLR.py
+-rw-r--r--   0 runner    (1001) docker     (122)      607 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    41203 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11791 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10917 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug/distributed_plug.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8377 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug/generator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/
+-rw-r--r--   0 runner    (1001) docker     (122)     1356 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7668 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/adv_utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    47482 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7953 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10874 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/text_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/
+-rw-r--r--   0 runner    (1001) docker     (122)     1487 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    37917 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6363 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4136 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/document_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11015 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7142 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/tokenization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/
+-rw-r--r--   0 runner    (1001) docker     (122)      934 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1211 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3728 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/dialog_intent_prediction.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4274 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/dialog_modeling.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16545 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/dialog_state_tracking.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/
+-rw-r--r--   0 runner    (1001) docker     (122)      371 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10230 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/gen_unified_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10706 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7451 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/intent_unified_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2934 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/model_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1186 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/tokenization_space.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11875 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/unified_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2347 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/embedder.py
+-rw-r--r--   0 runner    (1001) docker     (122)      905 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/feedforward.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1670 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/functions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3346 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/multihead_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1871 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/transformer_block.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_cn/
+-rw-r--r--   0 runner    (1001) docker     (122)      476 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_cn/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44430 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_cn/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5194 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_cn/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30089 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_cn/table_question_answering.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)      439 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3648 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_en/text_to_sql.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/
+-rw-r--r--   0 runner    (1001) docker     (122)     1671 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7670 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/adv_utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    40614 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7571 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27152 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/faq_question_answering.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12578 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11915 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11045 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/unite/
+-rw-r--r--   0 runner    (1001) docker     (122)      572 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/unite/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      360 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/unite/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18097 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/unite/translation_evaluation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/use/
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/use/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5082 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/use/transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5753 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/use/user_satisfaction_estimation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/veco/
+-rw-r--r--   0 runner    (1001) docker     (122)     1476 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/veco/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4030 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/veco/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/veco/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4296 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/veco/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6623 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/veco/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4153 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/veco/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/xlm_roberta/
+-rw-r--r--   0 runner    (1001) docker     (122)     1153 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/xlm_roberta/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42850 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/xlm_roberta/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7644 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/backbone/xlm_roberta/configuration.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      608 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25121 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/crf_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7114 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/fill_mask_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5299 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/infromation_extraction_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2218 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/text_classification_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1032 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/text_generation_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2166 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/text_ranking_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2687 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/token_classification_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1021 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/heads/torch_pretrain_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/
+-rw-r--r--   0 runner    (1001) docker     (122)     1400 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5163 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/feature_extraction.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2647 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)      715 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/information_extraction.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28842 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/task_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1926 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8654 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2045 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5037 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/nlp/task_models/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      438 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/science/unifold/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24057 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      634 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    49130 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/data_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19691 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/msa_pairing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8938 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/process.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14789 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/process_multimer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11419 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/protein.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42023 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/residue_constants.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4628 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/data/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19250 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2304 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)      187 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17066 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/alphafold.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12323 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/attentions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5403 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/auxillary_heads.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10676 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5814 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/confidence.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8771 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/embedders.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11078 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/evoformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6817 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/featurization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18025 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/frame.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18473 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/structure_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9771 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/template.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5623 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/modules/triangle_multiplication.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17940 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/mmcif.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3128 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/msa_identifiers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23503 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/parsers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11635 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45459 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/templates.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/
+-rw-r--r--   0 runner    (1001) docker     (122)      639 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6218 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/hhblits.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3988 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/hhsearch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5098 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/hmmbuild.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5010 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/hmmsearch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8662 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/jackhmmer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3752 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/kalign.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1255 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2889 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/models/science/unifold/msa/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/optimizer/
+-rw-r--r--   0 runner    (1001) docker     (122)       91 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/optimizer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7118 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/optimizer/child_tuning_adamw_optimizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/
+-rw-r--r--   0 runner    (1001) docker     (122)       42 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)     1514 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7471 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/ans_dfsmn_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4952 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/ans_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23640 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/asr_inference_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3117 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/asr_wenet_inference_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4284 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/inverse_text_processing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3819 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/kws_farfield_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7185 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/kws_kwsbp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5513 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/linear_aec_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8032 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/lm_infer_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6344 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/punctuation_processing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2522 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/separation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4034 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/speaker_change_locating_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10879 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/speaker_diarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4060 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/speaker_verification_eres2net_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4105 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/speaker_verification_light_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10373 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/speaker_verification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4054 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/speaker_verification_rdino_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1734 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/text_to_speech_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11868 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/timestamp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9608 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/audio/voice_activity_detection_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)    16199 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2473 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/action_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4789 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/action_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4007 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/animal_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2320 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/arc_face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2535 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/bad_image_detecting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9426 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/body_2d_keypoints_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14090 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/body_3d_keypoints_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4668 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/card_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5298 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/cmdssl_video_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2312 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/content_check_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4854 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/controllable_image_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5876 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/crowd_counting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5011 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ddcolor_image_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1901 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ddpm_semantic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2426 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_attribute_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3761 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1495 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_emotion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1612 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_human_hand_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2751 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_image_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3012 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_liveness_ir_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3498 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_liveness_xc_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7679 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_processing_base_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3477 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_quality_assessment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3136 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_recognition_onnx_fm_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3101 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_recognition_onnx_ir_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2540 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_recognition_ood_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2426 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/face_reconstruction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2328 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/facial_expression_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2609 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/facial_landmark_confidence_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4370 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/fast_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4014 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/general_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1324 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/hand_static_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2920 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/hicossl_video_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4303 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/human_reconstruction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1336 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_body_reshaping_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2845 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_bts_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5184 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_cartoon_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5785 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3219 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_color_enhance_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4375 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2568 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_debanding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4550 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_deblur_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3450 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_defrcn_fewshot_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4091 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_denoise_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1852 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1793 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4065 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_driving_perception_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2220 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_face_fusion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4800 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_human_parsing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5772 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_inpainting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4546 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_inpainting_sdv2_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3841 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5858 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_matching_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2541 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_matting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2733 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_mvs_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2704 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_open_vocabulary_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5865 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_paintbyexample_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8383 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_portrait_enhancement_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3407 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_quality_assessment_degradation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2598 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_quality_assessment_man_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2564 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_quality_assessment_mos_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1967 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_reid_person_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1638 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_restoration_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1583 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_salient_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3117 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_semantic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2168 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_skychange_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2716 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_structured_model_probing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4548 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_style_transfer_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3072 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_to_image_generate_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12661 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/image_to_image_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1803 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/indoor_layout_estimation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     9800 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/language_guided_video_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4434 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/license_plate_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4107 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/lineless_table_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5270 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/live_category_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2685 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/mask_face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2724 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/maskdino_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3590 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/mobile_image_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1791 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/mog_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4778 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/motion_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2568 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/movie_scene_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1887 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/mtcnn_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3261 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/nerf_recon_acc_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5923 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/object_detection_3d_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10832 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2449 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_recognition_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      913 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      670 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_convnext_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19821 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_dla34.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8768 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_resnet18_half.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5286 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15421 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_vlpt.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ocr_modules/
+-rw-r--r--   0 runner    (1001) docker     (122)      497 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ocr_modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ocr_modules/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1560 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ocr_modules/vitstr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38278 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19004 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/resnet18_v1.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11371 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/resnet_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11168 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/table_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7921 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2955 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/panorama_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9624 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/pedestrian_attribute_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4133 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1287 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/product_retrieval_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1435 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/product_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1951 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/realtime_video_object_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9178 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/referring_video_object_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1890 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/retina_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1700 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/shop_segmentation_pipleline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12037 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/skin_retouching_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4306 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/table_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4791 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/tbs_detection_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/cv/tbs_detection_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       10 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/tbs_detection_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15539 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/tbs_detection_utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1781 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/text_driven_segmentation_pipleline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3179 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/tinynas_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3179 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/tinynas_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1787 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/ulfd_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13766 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_category_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6031 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7728 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_deinterlace_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1505 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23997 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_frame_interpolation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3516 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_human_matting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1706 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_inpainting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9518 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3225 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_multi_object_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_object_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4574 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_panoptic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3367 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_single_object_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4465 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_stabilization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4274 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7052 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/video_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7551 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/vidt_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5170 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/virtual_try_on_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3938 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/vision_efficient_tuning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2168 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/vision_middleware_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4696 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/vop_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5682 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/cv/vop_retrieval_se_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)     3018 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2300 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/asr_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/
+-rw-r--r--   0 runner    (1001) docker     (122)      583 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1950 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      665 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11684 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2873 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/disco_guided_diffusion_pipeline/
+-rw-r--r--   0 runner    (1001) docker     (122)      532 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15613 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18987 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2168 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/document_vl_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2915 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1079 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9149 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/gridvlp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3117 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/image_captioning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/image_text_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7803 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/mgeo_ranking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1584 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3234 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/multimodal_dialogue_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1714 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/ocr_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8549 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1782 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/sudoku_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1052 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1723 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/text2sql_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1976 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/text_to_image_synthesis_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3472 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/text_to_video_synthesis_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2084 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/video_captioning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1268 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1845 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/video_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1714 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/visual_entailment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1715 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/visual_grounding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2324 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/multi_modal/visual_question_answering_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     6745 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6708 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/automatic_post_editing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3624 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/canmt_translation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2188 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/codegeex_code_generation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2869 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/codegeex_code_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2133 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/conversational_text_to_sql_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2471 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/dialog_intent_prediction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2235 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/dialog_modeling_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7557 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/dialog_state_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2154 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/distributed_gpt3_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1787 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/distributed_gpt_moe_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4361 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/distributed_plug_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2678 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/document_grounded_dialog_generate_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25966 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5404 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9554 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/document_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6186 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/extractive_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3278 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/faq_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2347 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/fasttext_text_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3065 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/feature_extraction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10017 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/fid_dialogue_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4579 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/fill_mask_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)      986 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/glm130b_text_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2320 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/information_extraction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6288 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/interactive_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9797 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/language_identification_pipline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1751 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/mglm_text_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2895 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/named_entity_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3118 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/sentence_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14262 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/siamese_uie_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2507 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16234 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/table_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6706 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/text_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3414 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/text_error_correction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7657 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/text_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2811 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/text_ranking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6330 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/token_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4171 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/translation_evaluation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5517 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2275 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/translation_quality_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4540 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/user_satisfaction_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2612 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/word_alignment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4217 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/word_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5806 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/nlp/zero_shot_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4267 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2765 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/pipeline_template.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/pipelines/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      485 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/science/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8102 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/pipelines/science/protein_structure_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/
+-rw-r--r--   0 runner    (1001) docker     (122)     5595 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9995 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/asr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8614 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/audio.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1843 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7395 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/action_detection_mapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)      997 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/bad_image_detecting_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7562 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/controllable_image_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20909 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/cv2_transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12761 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/image_classification_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1180 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/image_quality_assessment_man.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2042 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/image_quality_assessment_mos.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2723 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/image_restoration_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2558 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/mmcls_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3050 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/timer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3606 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1498 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/video_stabilization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8579 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/cv/video_super_resolution.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13463 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4836 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/kws.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      430 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10809 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/movie_scene_segmentation/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    29816 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/multi_modal.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     5913 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      684 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/bert_seq_cls_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3868 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/canmt_translation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2514 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/dialog_classification_use_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4049 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4291 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4033 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10946 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/document_segmentation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6786 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/faq_question_answering_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3272 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/feature_extraction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12055 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/fill_mask_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8090 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/mgeo_ranking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1143 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/mglm_summarization_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1741 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/relation_extraction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3991 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/sentence_embedding_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1265 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/siamese_uie_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)     1166 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1858 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/args.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1504 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/batch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3566 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2634 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2722 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/dialog_modeling_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5264 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    56779 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/dst_processors.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)      539 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    33816 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/fields/gen_field.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42400 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/fields/intent_field.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1097 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/lazy_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1881 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1559 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2084 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/tensorlistdataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24752 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/
+-rw-r--r--   0 runner    (1001) docker     (122)      601 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4886 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/fields/database.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15817 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/fields/schema_link.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4837 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/fields/struct.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4106 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)      793 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4830 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)      765 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21518 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/common_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12449 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/parse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1329 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2111 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/process_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/text_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      102 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/text_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9034 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/text_classification/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1645 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/text_clean.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2233 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/text_error_correction.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13842 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/text_generation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3776 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/text_ranking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19438 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/token_classification_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1581 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/token_classification_thai_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1106 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/token_classification_viet_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7143 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/translation_evaluation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4805 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/word_alignment_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2552 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/nlp/zero_shot_classification_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)      712 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4782 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/asr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11847 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4119 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/image_captioning.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6405 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/image_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5687 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/ocr_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4550 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/sudoku.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5157 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/summarization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16395 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/text2sql.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5315 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2111 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/text_to_image_synthesis.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3170 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/audio_helper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8936 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/bridge_content_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6758 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/collate.py
+-rw-r--r--   0 runner    (1001) docker     (122)      607 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3370 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/get_tables.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1251 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/random_help.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5405 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/text2phone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19116 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/utils/vision_helper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7608 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/visual_entailment.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8428 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/visual_grounding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6740 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/ofa/visual_question_answering.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/preprocessors/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      425 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/science/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21666 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/science/uni_fold.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1970 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/tts.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13188 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/preprocessors/video.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/registry/
+-rw-r--r--   0 runner    (1001) docker     (122)      756 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      687 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      635 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)      260 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1992 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/lr_scheduler.py
+-rw-r--r--   0 runner    (1001) docker     (122)      857 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3483 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1485 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/optimizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      629 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/parallel.py
+-rw-r--r--   0 runner    (1001) docker     (122)      627 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)      659 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6962 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/registry.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1716 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/registry/trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      553 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/train.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/
+-rw-r--r--   0 runner    (1001) docker     (122)     1746 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      773 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1810 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/ans_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6696 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/asr_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12685 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_farfield_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21862 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_nearfield_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)     1715 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22111 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_utils/batch_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11496 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_utils/det_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7019 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_utils/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4503 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_utils/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2851 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/kws_utils/runtime_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21877 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/separation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10600 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/audio/tts_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5553 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cli_argument_parser.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1921 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7409 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/action_detection_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      617 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/card_detection_scrfd_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9962 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/cartoon_translation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6653 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/face_detection_scrfd_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19790 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/image_classifition_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11598 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/image_defrcn_fewshot_detection_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22773 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/image_detection_damoyolo_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4187 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/image_inpainting_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      753 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/image_instance_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5341 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/image_portrait_enhancement_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      617 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/movie_scene_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20038 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/nerf_recon_acc_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16788 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/ocr_detection_db_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2755 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/ocr_recognition_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2107 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/referring_video_object_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4453 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/cv/vision_efficient_tuning_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)      629 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       38 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9478 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/clip/clip_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4409 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/clip/clip_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/efficient_diffusion_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/efficient_diffusion_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2790 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7975 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/mgeo_ranking_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/mplug/
+-rw-r--r--   0 runner    (1001) docker     (122)       40 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/mplug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1590 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/mplug/mplug_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/ofa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10002 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/ofa/ofa_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17647 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/ofa/ofa_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/team/
+-rw-r--r--   0 runner    (1001) docker     (122)       44 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/team/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5334 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/team/team_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2390 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/multi_modal/team/team_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     1279 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14121 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/csanmt_translation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9895 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/document_grounded_dialog_generate_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24232 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/document_grounded_dialog_rerank_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8070 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/document_grounded_dialog_retrieval_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12546 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/faq_question_answering_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2993 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/gpt3_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2040 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/gpt_moe_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8174 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/plug_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3863 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/sentence_embedding_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8314 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/sequence_classification_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16888 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/siamese_uie_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5281 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/dialog_intent_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4189 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/dialog_modeling_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36348 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/eval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/metrics/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/metrics/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2396 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/metrics/metrics_tracker.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/trainer/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/trainer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30505 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/trainer/gen_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    29511 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/space/trainer/intent_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20142 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/table_question_answering_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/nlp/text_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/text_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2486 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/text_classification/trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      841 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/text_generation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7428 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/text_ranking_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14570 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/nlp/translation_evaluation_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/trainers/parallel/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/parallel/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      712 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/parallel/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17525 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/trainers/training_args.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/tuners/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/tuners/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38904 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/tuners/control_sd_lora.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24008 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/tuners/lora.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8840 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/tuners/sd_lora.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    29176 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ast_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11696 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/audio/audio_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2378 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/audio/tts_exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26426 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2522 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/chinese_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/cli/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cli/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      780 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cli/cli.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1167 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cli/download.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6135 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cli/modelcard.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4313 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cli/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3247 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cli/plugins.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/config/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1275 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/config/auth_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25429 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/config/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1002 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/config/config_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1723 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/config/data_meta_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3294 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/config/dataset_context_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2506 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/config/default_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)      558 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/config/download_config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/constants/
+-rw-r--r--   0 runner    (1001) docker     (122)      342 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1450 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/constants.py
+-rw-r--r--   0 runner    (1001) docker     (122)      967 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/dataset_constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1657 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/hook_priority.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18770 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/hub_constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)    60137 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/metainfo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2786 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/metric_constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)    49162 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/output_constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10468 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/pipeline_inputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1905 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/constants/registry_constant.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23159 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cv/image_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/cv/motion_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cv/motion_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cv/motion_utils/motion_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3847 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cv/motion_utils/plot_script.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4290 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/cv/motion_utils/rotation_conversions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3103 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/data_collators.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1223 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/data_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/dataset/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10956 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45709 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16413 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/dataset_downloader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7557 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/dataset_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/dataset/manager/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/manager/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      978 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/manager/data_delete_manager.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4977 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/manager/data_files_manager.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5699 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/manager/data_loader_manager.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8511 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/manager/data_meta_manager.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2440 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/manager/data_upload_manager.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/manager/download_manager.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5489 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/maxcompute_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5982 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/dataset/oss_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3689 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/device.py
+-rw-r--r--   0 runner    (1001) docker     (122)      736 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/exporter_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/fileio/
+-rw-r--r--   0 runner    (1001) docker     (122)       71 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9871 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/caching.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10190 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/file.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1074 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/file_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/fileio/format/
+-rw-r--r--   0 runner    (1001) docker     (122)       92 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/format/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      404 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/format/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1000 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/format/json.py
+-rw-r--r--   0 runner    (1001) docker     (122)      996 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/format/json_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13853 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/format/jsonplus.py
+-rw-r--r--   0 runner    (1001) docker     (122)      619 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/format/yaml.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4203 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/fileio/io.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/hub/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/hub/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    41487 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/hub/api.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3607 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/hub/check_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11384 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/hub/deploy.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8931 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/hub/git.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5342 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/hub/push_to_hub.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12370 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/hub/repository.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23283 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/hub/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15725 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/import_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25344 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/input_output.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/logger/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/logger/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1196 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/logger/log_buffer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2648 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/logger/logger.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7559 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/megatron_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2335 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5037 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/model_tag.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)      446 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4424 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/distributed.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4526 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/load_checkpoint.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1858 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/args.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11767 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/clean_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1388 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/criterions.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11201 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/db_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6123 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/ontology.py
+-rw-r--r--   0 runner    (1001) docker     (122)      146 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/scores.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6302 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1022 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space/utils_dst.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/nlp/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      826 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/space_T_en/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2475 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/nlp/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/ops/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/ops/ailut/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/ops/ailut/Ailut/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/ailut/Ailut/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/ops/ailut/Ailut/csrc/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/ailut/Ailut/csrc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      105 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/ailut/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4314 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/ailut/pyinterfaces.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/
+-rw-r--r--   0 runner    (1001) docker     (122)       55 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/functions/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/functions/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2874 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/functions/quadtree_attention.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13876 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/modules/quadtree_attention.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/src/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/src/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/output/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/output/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      806 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/output/cv_outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19841 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/output/nlp_outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)      777 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/output/outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6636 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/pipeline_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    39453 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/plugins.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/preprocessor/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/preprocessor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3263 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/preprocessor/preprocessor_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4184 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/preprocessor/transformers_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6158 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/service_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2473 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/task_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1543 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/tensor_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/test_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/test_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30138 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/test_utils/regress_test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12479 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/test_utils/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/timer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/tools/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/tools/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      675 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/tools/eval.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5351 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/tools/speech_tts_autolabel.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10913 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/torch_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      288 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/transforms/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/transforms/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6939 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/transforms/common.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/transforms/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/transforms/cv/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils/transforms/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/transforms/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      546 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/trie.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1645 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/type_assert.py
+-rw-r--r--   0 runner    (1001) docker     (122)      354 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/typing.py
+-rw-r--r--   0 runner    (1001) docker     (122)      729 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils/url_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:17.000000 weathon-0.0.0.14/weathon/utils_/
+-rw-r--r--   0 runner    (1001) docker     (122)     2702 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4790 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/attack.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2373 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/char_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12460 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/conlleval.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2055 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/constants.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1249 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5286 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/dictionary.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3814 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/ema.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2379 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/email_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      668 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/encrypt_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      674 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/environment_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11031 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4488 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/gpu_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1283 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/ip_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      627 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/json_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21438 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/keyword_extract.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6569 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/label_studio_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4481 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/loss_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12341 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/midi_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5159 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/minjoin.py
+-rw-r--r--   0 runner    (1001) docker     (122)      661 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/model_ensemble.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4831 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/music.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21209 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/ner_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      885 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/nextpow2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5183 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/noise_reduction.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6305 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/note_plotter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11716 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/number_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2746 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/onset_frames_split.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6713 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/optimizer_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1266 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/pdf_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2366 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/prune.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2434 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9394 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/schedule_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      584 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/semantic_scholar.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1663 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/sound_plot_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3001 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/sound_recorder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3194 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/states_machine.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3678 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/string_converter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25723 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/string_similarity.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18063 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/string_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10283 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/text_cluster.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1334 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/textrank.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8217 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/transformer_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6909 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/union_find.py
+-rw-r--r--   0 runner    (1001) docker     (122)      532 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/wav_note.py
+-rw-r--r--   0 runner    (1001) docker     (122)      653 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/wav_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10737 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/word_discover.py
+-rw-r--r--   0 runner    (1001) docker     (122)    41028 2023-06-26 05:55:38.000000 weathon-0.0.0.14/weathon/utils_/word_finder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (122)      859 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (122)   127760 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (122)        1 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (122)       53 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (122)        1 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (122)      504 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (122)        8 2023-06-26 05:56:16.000000 weathon-0.0.0.14/weathon.egg-info/top_level.txt
```

### Comparing `weathon-0.0.0.13/PKG-INFO` & `weathon-0.0.0.14/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: weathon
-Version: 0.0.0.13
+Version: 0.0.0.14
 Summary: weathon: a personal Weapon Depot for python, so called weathon.
 Home-page: https://github.com/LiZhen0628
 Author: LiZhen
 Author-email: 16621660628@163.com
 License: UNKNOWN
 Description: # weathon_package
         a personal Weapon Depot for python, so called weathon.
```

### Comparing `weathon-0.0.0.13/weathon/dl/cli/modelcard.py` & `weathon-0.0.0.14/weathon/utils/cli/modelcard.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import shutil
 import tempfile
 from argparse import ArgumentParser
 from string import Template
 
-from modelscope.cli.base import CLICommand
-from modelscope.hub.api import HubApi
-from modelscope.hub.snapshot_download import snapshot_download
-from modelscope.hub.utils.utils import get_endpoint
-from modelscope.utils.logger import get_logger
+from weathon.base.cli import CLICommand
+from weathon.utils.hub.api import HubApi
+from weathon.utils.constants.constants import END_POINT
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 curren_path = os.path.dirname(os.path.abspath(__file__))
 template_path = os.path.join(curren_path, 'template')
 
 
@@ -29,15 +27,15 @@
     def __init__(self, args):
         self.args = args
         self.api = HubApi()
         self.api.login(args.access_token)
         self.model_id = os.path.join(
             self.args.group_id, self.args.model_id
         ) if '/' not in self.args.model_id else self.args.model_id
-        self.url = os.path.join(get_endpoint(), self.model_id)
+        self.url = os.path.join(END_POINT, self.model_id)
 
     @staticmethod
     def define_args(parsers: ArgumentParser):
         """ define args for create or upload modelcard command.
         """
         parser = parsers.add_parser(ModelCardCMD.name)
         parser.add_argument(
@@ -100,15 +98,15 @@
             '--version_info',
             type=str,
             default=None,
             help='the info of uploaded model')
         parser.set_defaults(func=subparser_func)
 
     def create_model(self):
-        from modelscope.hub.constants import Licenses, ModelVisibility
+        from weathon.utils.constants.constants import Licenses, ModelVisibility
         visibilities = [
             getattr(ModelVisibility, attr) for attr in dir(ModelVisibility)
             if not attr.startswith('__')
         ]
         if self.args.visibility not in visibilities:
             raise ValueError('The access_token must in %s!' % visibilities)
         licenses = [
@@ -129,15 +127,15 @@
             )
         self.pprint()
 
     def get_model_url(self):
         return self.api.get_model_url(self.model_id)
 
     def push_model(self, tpl_dir='readme.tpl'):
-        from modelscope.hub.repository import Repository
+        from weathon.utils.hub.repository import Repository
         if self.args.version_tag and self.args.version_info:
             clone_dir = tempfile.TemporaryDirectory().name
             repo = Repository(clone_dir, clone_from=self.model_id)
             repo.tag_and_push(self.args.version_tag, self.args.version_info)
             shutil.rmtree(clone_dir)
         else:
             cfg_file = os.path.join(self.args.model_dir, 'README.md')
```

### Comparing `weathon-0.0.0.13/weathon/dl/cli/pipeline.py` & `weathon-0.0.0.14/weathon/utils/cli/pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from argparse import ArgumentParser
 from string import Template
 
-from modelscope.cli.base import CLICommand
-from modelscope.utils.logger import get_logger
+from weathon.base.cli import CLICommand
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 curren_path = os.path.dirname(os.path.abspath(__file__))
 template_path = os.path.join(curren_path, 'template')
```

### Comparing `weathon-0.0.0.13/weathon/dl/cli/plugins.py` & `weathon-0.0.0.14/weathon/utils/cli/plugins.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from argparse import ArgumentParser
 
-from modelscope.cli.base import CLICommand
-from modelscope.utils.plugins import PluginsManager
+from weathon.base.cli import CLICommand
+from weathon.utils.plugins import PluginsManager
 
 plugins_manager = PluginsManager()
 
 
 def subparser_func(args):
     """ Function which will be called for a specific sub parser.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/audio/ans_dfsmn_exporter.py` & `weathon-0.0.0.14/weathon/exporters/audio/ans_dfsmn_exporter.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
 import torch
 
-from modelscope.exporters.builder import EXPORTERS
-from modelscope.exporters.torch_model_exporter import TorchModelExporter
-from modelscope.metainfo import Models
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import TorchModelExporter
+from weathon.registry import EXPORTERS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
 
 INPUT_NAME = 'input'
 OUTPUT_NAME = 'output'
 
 
-@EXPORTERS.register_module(
-    Tasks.acoustic_noise_suppression, module_name=Models.speech_dfsmn_ans)
+@EXPORTERS.register_module(Tasks.acoustic_noise_suppression, module_name=Models.speech_dfsmn_ans)
 class ANSDFSMNExporter(TorchModelExporter):
 
     def export_onnx(self, output_dir: str, opset=9, **kwargs):
         """Export the model as onnx format files.
 
         Args:
             output_dir: The output dir.
@@ -25,16 +23,15 @@
             kwargs:
                 device: The device used to forward.
         Returns:
             A dict containing the model key - model file path pairs.
         """
         model = self.model if 'model' not in kwargs else kwargs.pop('model')
         device_name = 'cpu' if 'device' not in kwargs else kwargs.pop('device')
-        model_bin_file = os.path.join(model.model_dir,
-                                      ModelFile.TORCH_MODEL_BIN_FILE)
+        model_bin_file = os.path.join(model.model_dir, ModelFile.TORCH_MODEL_BIN_FILE)
         if os.path.exists(model_bin_file):
             checkpoint = torch.load(model_bin_file, map_location='cpu')
             model.load_state_dict(checkpoint)
         onnx_file = os.path.join(output_dir, ModelFile.ONNX_MODEL_FILE)
 
         with torch.no_grad():
             model.eval()
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/cv/__init__.py` & `weathon-0.0.0.14/weathon/exporters/cv/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,12 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .cartoon_translation_exporter import CartoonTranslationExporter
     from .object_detection_damoyolo_exporter import ObjectDetectionDamoyoloExporter
     from .face_detection_scrfd_exporter import FaceDetectionSCRFDExporter
 else:
     _import_structure = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/cv/cartoon_translation_exporter.py` & `weathon-0.0.0.14/weathon/exporters/cv/cartoon_translation_exporter.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 import os
 from typing import Any, Dict
 
 import tensorflow as tf
 from packaging import version
 
-from modelscope.exporters.builder import EXPORTERS
-from modelscope.exporters.tf_model_exporter import TfModelExporter
-from modelscope.models.cv.cartoon import CartoonModel
-from modelscope.utils.logger import get_logger
+from weathon.base import TfModelExporter
+from weathon.models.cv.cartoon import CartoonModel
+from weathon.registry import EXPORTERS
+from weathon.utils.logger import get_logger
 
 logger = get_logger(__name__)
 
 if version.parse(tf.__version__) < version.parse('2'):
     pass
 else:
     logger.info(
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/cv/face_detection_scrfd_exporter.py` & `weathon-0.0.0.14/weathon/exporters/cv/face_detection_scrfd_exporter.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from functools import partial
 from typing import Mapping
 
 import numpy as np
 import onnx
 import torch
 
-from modelscope.exporters.builder import EXPORTERS
-from modelscope.exporters.torch_model_exporter import TorchModelExporter
-from modelscope.metainfo import Models
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import TorchModelExporter
+from weathon.registry import EXPORTERS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
 
 
 def convert_ndarray_to_list(input_dict):
     for key, value in input_dict.items():
         if isinstance(value, np.ndarray):
             input_dict[key] = value.tolist()
         elif isinstance(value, dict):
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/cv/object_detection_damoyolo_exporter.py` & `weathon-0.0.0.14/weathon/exporters/cv/object_detection_damoyolo_exporter.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,24 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from functools import partial
-from typing import Mapping
 
-import numpy as np
-import onnx
 import torch
 
-from modelscope.exporters.builder import EXPORTERS
-from modelscope.exporters.torch_model_exporter import TorchModelExporter
-from modelscope.metainfo import Models
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import TorchModelExporter
+from weathon.registry import EXPORTERS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
 
 
-@EXPORTERS.register_module(
-    Tasks.image_object_detection, module_name=Models.tinynas_damoyolo)
+@EXPORTERS.register_module(Tasks.image_object_detection, module_name=Models.tinynas_damoyolo)
 class ObjectDetectionDamoyoloExporter(TorchModelExporter):
 
     def export_onnx(self,
                     output_dir: str,
                     opset=11,
                     input_shape=(1, 3, 640, 640)):
         onnx_file = os.path.join(output_dir, ModelFile.ONNX_MODEL_FILE)
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/nlp/__init__.py` & `weathon-0.0.0.14/weathon/exporters/nlp/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,12 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .csanmt_for_translation_exporter import CsanmtForTranslationExporter
     from .model_for_token_classification_exporter import ModelForSequenceClassificationExporter
     from .sbert_for_sequence_classification_exporter import \
         SbertForSequenceClassificationExporter
     from .sbert_for_zero_shot_classification_exporter import \
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/nlp/csanmt_for_translation_exporter.py` & `weathon-0.0.0.14/weathon/exporters/nlp/csanmt_for_translation_exporter.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,20 +2,20 @@
 from typing import Any, Dict
 
 import tensorflow as tf
 from tensorflow.python.framework import ops
 from tensorflow.python.saved_model import tag_constants
 from tensorflow.python.tools import freeze_graph
 
-from modelscope.exporters.builder import EXPORTERS
-from modelscope.exporters.tf_model_exporter import TfModelExporter
-from modelscope.metainfo import Models
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.test_utils import compare_arguments_nested
+from weathon.base.exporter import TfModelExporter
+from weathon.registry import EXPORTERS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.logger import get_logger
+from weathon.utils.test_utils.test_utils import compare_arguments_nested
 
 logger = get_logger(__name__)
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
 
 tf.logging.set_verbosity(tf.logging.INFO)
@@ -24,15 +24,15 @@
 @EXPORTERS.register_module(Tasks.translation, module_name=Models.translation)
 class CsanmtForTranslationExporter(TfModelExporter):
 
     def __init__(self, model=None):
         tf.disable_eager_execution()
         super().__init__(model)
 
-        from modelscope.pipelines.nlp.translation_pipeline import TranslationPipeline
+        from weathon.pipelines.nlp.translation_pipeline import TranslationPipeline
         self.pipeline = TranslationPipeline(self.model)
 
     def generate_dummy_inputs(self, **kwargs) -> Dict[str, Any]:
         return_dict = self.pipeline.preprocess(
             "Alibaba Group's mission is to let the world have no difficult business"
         )
         return {'input_wids': return_dict['input_ids']}
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/nlp/model_for_token_classification_exporter.py` & `weathon-0.0.0.14/weathon/exporters/nlp/model_for_token_classification_exporter.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,27 +1,25 @@
 from collections import OrderedDict
 from typing import Any, Dict, Mapping
 
 import torch
-from torch import nn
-
-from modelscope.exporters.builder import EXPORTERS
-from modelscope.exporters.torch_model_exporter import TorchModelExporter
-from modelscope.metainfo import Models
-from modelscope.outputs import ModelOutputBase
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.regress_test_utils import (compare_arguments_nested,
-                                                 numpify_tensor_nested)
 
+from weathon.base import BasePreprocessor, BaseModelOutput
+from weathon.base.exporter import TorchModelExporter
+from weathon.registry import EXPORTERS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.logger import get_logger
+from weathon.utils.test_utils.regress_test_utils import numpify_tensor_nested
+from weathon.utils.test_utils.test_utils import compare_arguments_nested
 
+logger = get_logger()
 @EXPORTERS.register_module(Tasks.transformer_crf, module_name=Models.tcrf)
 @EXPORTERS.register_module(Tasks.token_classification, module_name=Models.tcrf)
-@EXPORTERS.register_module(
-    Tasks.named_entity_recognition, module_name=Models.tcrf)
+@EXPORTERS.register_module(Tasks.named_entity_recognition, module_name=Models.tcrf)
 @EXPORTERS.register_module(Tasks.part_of_speech, module_name=Models.tcrf)
 @EXPORTERS.register_module(Tasks.word_segmentation, module_name=Models.tcrf)
 class ModelForSequenceClassificationExporter(TorchModelExporter):
 
     def generate_dummy_inputs(self, **kwargs) -> Dict[str, Any]:
         """Generate dummy inputs for model exportation to onnx or other formats by tracing.
 
@@ -31,20 +29,17 @@
                 shape = (8, 128) batch_size=1, sequence_length=128, which will cover the config of the preprocessor.
             pair(bool, `optional`): Whether to generate sentence pairs or single sentences.
 
         Returns:
             Dummy inputs.
         """
 
-        assert hasattr(
-            self.model, 'model_dir'
-        ), 'model_dir attribute is required to build the preprocessor'
+        assert hasattr(self.model, 'model_dir'), 'model_dir attribute is required to build the preprocessor'
 
-        preprocessor = Preprocessor.from_pretrained(
-            self.model.model_dir, return_text=False)
+        preprocessor = BasePreprocessor.from_pretrained(self.model.model_dir, return_text=False)
         return preprocessor('2023')
 
     @property
     def inputs(self) -> Mapping[str, Mapping[int, str]]:
         dynamic_axis = {0: 'batch', 1: 'sequence'}
         return OrderedDict([
             ('input_ids', dynamic_axis),
@@ -78,17 +73,16 @@
         onnx_model = onnx.load(output)
         onnx.checker.check_model(onnx_model)
         ort_session = ort.InferenceSession(output)
         with torch.no_grad():
             model.eval()
             outputs_origin = model.forward(
                 *self._decide_input_format(model, dummy_inputs))
-        if isinstance(outputs_origin, (Mapping, ModelOutputBase)):
-            outputs_origin = list(
-                numpify_tensor_nested(outputs_origin).values())
+        if isinstance(outputs_origin, (Mapping, BaseModelOutput)):
+            outputs_origin = list(numpify_tensor_nested(outputs_origin).values())
         elif isinstance(outputs_origin, (tuple, list)):
             outputs_origin = list(numpify_tensor_nested(outputs_origin))
 
         outputs_origin = [outputs_origin[0]
                           ]  # keep `predictions`, drop other outputs
 
         np_dummy_inputs = numpify_tensor_nested(dummy_inputs)
@@ -102,11 +96,9 @@
             outputs = list(outputs)
 
         tols = {}
         if rtol is not None:
             tols['rtol'] = rtol
         if atol is not None:
             tols['atol'] = atol
-        if not compare_arguments_nested('Onnx model output match failed',
-                                        outputs, outputs_origin, **tols):
-            raise RuntimeError(
-                'export onnx failed because of validation error.')
+        if not compare_arguments_nested('Onnx model output match failed', outputs, outputs_origin, **tols):
+            raise RuntimeError('export onnx failed because of validation error.')
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/nlp/sbert_for_sequence_classification_exporter.py` & `weathon-0.0.0.14/weathon/exporters/nlp/sbert_for_sequence_classification_exporter.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,30 +1,26 @@
 from collections import OrderedDict
 from typing import Any, Dict, Mapping, Tuple
 
 from torch.utils.data.dataloader import default_collate
 
-from modelscope.exporters.builder import EXPORTERS
-from modelscope.exporters.torch_model_exporter import TorchModelExporter
-from modelscope.metainfo import Models
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import ModeKeys, Tasks
+from weathon.base import BasePreprocessor
+from weathon.base.exporter import TorchModelExporter
+from weathon.registry import EXPORTERS
+from weathon.utils.constants import Tasks, ModeKeys
+from weathon.utils.constants.metainfo import Models
 
 
 @EXPORTERS.register_module(Tasks.text_classification, module_name=Models.bert)
-@EXPORTERS.register_module(
-    Tasks.text_classification, module_name=Models.structbert)
+@EXPORTERS.register_module(Tasks.text_classification, module_name=Models.structbert)
 @EXPORTERS.register_module(Tasks.sentence_similarity, module_name=Models.bert)
-@EXPORTERS.register_module(
-    Tasks.sentiment_classification, module_name=Models.bert)
+@EXPORTERS.register_module(Tasks.sentiment_classification, module_name=Models.bert)
 @EXPORTERS.register_module(Tasks.nli, module_name=Models.bert)
-@EXPORTERS.register_module(
-    Tasks.sentence_similarity, module_name=Models.structbert)
-@EXPORTERS.register_module(
-    Tasks.sentiment_classification, module_name=Models.structbert)
+@EXPORTERS.register_module(Tasks.sentence_similarity, module_name=Models.structbert)
+@EXPORTERS.register_module(Tasks.sentiment_classification, module_name=Models.structbert)
 @EXPORTERS.register_module(Tasks.nli, module_name=Models.structbert)
 class SbertForSequenceClassificationExporter(TorchModelExporter):
 
     def generate_dummy_inputs(self,
                               shape: Tuple = None,
                               pair: bool = False,
                               **kwargs) -> Dict[str, Any]:
@@ -48,19 +44,18 @@
         if shape is not None:
             if len(shape) == 1:
                 batch_size = shape[0]
             elif len(shape) == 2:
                 batch_size, max_length = shape
                 sequence_length = {'sequence_length': max_length}
 
-        preprocessor = Preprocessor.from_pretrained(
-            self.model.model_dir,
-            preprocessor_mode=ModeKeys.TRAIN,
-            task=Tasks.text_classification,
-            **sequence_length)
+        preprocessor = BasePreprocessor.from_pretrained(self.model.model_dir,
+                                                        preprocessor_mode=ModeKeys.TRAIN,
+                                                        task=Tasks.text_classification,
+                                                        **sequence_length)
         if pair:
             first_sequence = preprocessor.nlp_tokenizer.tokenizer.unk_token
             second_sequence = preprocessor.nlp_tokenizer.tokenizer.unk_token
         else:
             first_sequence = preprocessor.nlp_tokenizer.tokenizer.unk_token
             second_sequence = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/nlp/sbert_for_zero_shot_classification_exporter.py` & `weathon-0.0.0.14/weathon/exporters/nlp/sbert_for_zero_shot_classification_exporter.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,21 +1,26 @@
 from collections import OrderedDict
 from typing import Any, Dict, Mapping
 
-from modelscope.exporters.builder import EXPORTERS
-from modelscope.exporters.torch_model_exporter import TorchModelExporter
-from modelscope.metainfo import Models
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import Tasks
+from weathon.base import BasePreprocessor
+from weathon.base.exporter import TorchModelExporter
+from weathon.registry import EXPORTERS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+
+
+# from weathon.exporters.builder import EXPORTERS
+# from weathon.exporters.torch_model_exporter import TorchModelExporter
+# from weathon.utils.constants.metainfo import Models
+# from weathon.preprocessors import Preprocessor
+# from weathon.utils.constants import Tasks
 
 
-@EXPORTERS.register_module(
-    Tasks.zero_shot_classification, module_name=Models.bert)
-@EXPORTERS.register_module(
-    Tasks.zero_shot_classification, module_name=Models.structbert)
+@EXPORTERS.register_module(Tasks.zero_shot_classification, module_name=Models.bert)
+@EXPORTERS.register_module(Tasks.zero_shot_classification, module_name=Models.structbert)
 class SbertForZeroShotClassificationExporter(TorchModelExporter):
 
     def generate_dummy_inputs(self,
                               candidate_labels,
                               hypothesis_template,
                               max_length=128,
                               pair: bool = False,
@@ -33,15 +38,15 @@
         Returns:
             Dummy inputs.
         """
 
         assert hasattr(
             self.model, 'model_dir'
         ), 'model_dir attribute is required to build the preprocessor'
-        preprocessor = Preprocessor.from_pretrained(
+        preprocessor = BasePreprocessor.from_pretrained(
             self.model.model_dir, max_length=max_length)
         return preprocessor(
             preprocessor.nlp_tokenizer.tokenizer.unk_token,
             candidate_labels=candidate_labels,
             hypothesis_template=hypothesis_template)
 
     @property
```

### Comparing `weathon-0.0.0.13/weathon/dl/exporters/torch_model_exporter.py` & `weathon-0.0.0.14/weathon/base/exporter.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,30 +1,95 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from contextlib import contextmanager
+from abc import ABC, abstractmethod
 from itertools import chain
-from typing import Any, Dict, Mapping
+from typing import Union, Dict, Any, Mapping,Callable
 
 import torch
 from torch import nn
+
+from weathon.registry import build_exporter
+from weathon.utils.config.config import Config, ConfigDict
+from weathon.utils.constants import ModelFile
+from weathon.utils.exporter_utils import replace_call
+from weathon.utils.logger import get_logger
+from weathon.utils.test_utils.regress_test_utils import numpify_tensor_nested
+from weathon.utils.test_utils.test_utils import compare_arguments_nested
 from torch.onnx import export as onnx_export
+from .model import BaseModel
+from .modeloutput import BaseModelOutput
+from .pipeline import collate_fn
+
+logger = get_logger(__name__)
+
 
-from modelscope.models import TorchModel
-from modelscope.outputs import ModelOutputBase
-from modelscope.pipelines.base import collate_fn
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
-from modelscope.utils.regress_test_utils import (compare_arguments_nested,
-                                                 numpify_tensor_nested)
-from .base import Exporter
 
-logger = get_logger()
 
+class BaseExporter(ABC):
+    """Exporter base class to output model to onnx, torch_script, graphdef, etc.
+    """
+
+    def __init__(self, model=None):
+        self.model = model
+
+    @classmethod
+    def from_model(cls, model: Union[BaseModel, str], **kwargs):
+        """Build the Exporter instance.
+
+        Args:
+            model: A Model instance or a model id or a model dir, the configuration.json file besides to which
+            will be used to create the exporter instance.
+            kwargs: Extra kwargs used to create the Exporter instance.
+
+        Returns:
+            The Exporter instance
+        """
+        if isinstance(model, str):
+            model = BaseModel.from_pretrained(model)
 
-class TorchModelExporter(Exporter):
+        assert hasattr(model, 'model_dir')
+        model_dir = model.model_dir
+        cfg = Config.from_file(os.path.join(model_dir, ModelFile.CONFIGURATION))
+        task_name = cfg.task
+        if hasattr(model, 'group_key'):
+            task_name = model.group_key
+        model_cfg = cfg.model
+        if hasattr(model_cfg, 'model_type') and not hasattr(model_cfg, 'type'):
+            model_cfg.type = model_cfg.model_type
+        export_cfg = ConfigDict({'type': model_cfg.type})
+        if hasattr(cfg, 'export'):
+            export_cfg.update(cfg.export)
+        export_cfg['model'] = model
+        try:
+            exporter = build_exporter(export_cfg, task_name, kwargs)
+        except KeyError as e:
+            raise KeyError(
+                f'The exporting of model \'{model_cfg.type}\' with task: \'{task_name}\' '
+                f'is not supported currently.') from e
+        return exporter
+
+    @abstractmethod
+    def export_onnx(self, output_dir: str, opset=13, **kwargs):
+        """Export the model as onnx format files.
+
+        In some cases,  several files may be generated,
+        So please return a dict which contains the generated name with the file path.
+
+        Args:
+            opset: The version of the ONNX operator set to use.
+            output_dir: The output dir.
+            kwargs: In this default implementation,
+                kwargs will be carried to generate_dummy_inputs as extra arguments (like input shape).
+
+        Returns:
+            A dict contains the model name with the model file path.
+        """
+        pass
+
+
+class TorchModelExporter(BaseExporter):
     """The torch base class of exporter.
 
     This class provides the default implementations for exporting onnx and torch script.
     Each specific model may implement its own exporter by overriding the export_onnx/export_torch_script,
     and to provide implementations for generate_dummy_inputs/inputs/outputs methods.
     """
 
@@ -171,50 +236,42 @@
             atol: The atol used to regress the outputs.
             kwargs:
                 dummy_inputs: A dummy inputs which will replace the calling of self.generate_dummy_inputs().
                 inputs: An inputs structure which will replace the calling of self.inputs.
                 outputs: An outputs structure which will replace the calling of self.outputs.
         """
 
-        dummy_inputs = self.generate_dummy_inputs(
-            **kwargs) if 'dummy_inputs' not in kwargs else kwargs.pop(
-                'dummy_inputs')
-        inputs = self.inputs if 'inputs' not in kwargs else kwargs.pop(
-            'inputs')
-        outputs = self.outputs if 'outputs' not in kwargs else kwargs.pop(
-            'outputs')
+        dummy_inputs = self.generate_dummy_inputs(**kwargs) if 'dummy_inputs' not in kwargs else kwargs.pop('dummy_inputs')
+        inputs = self.inputs if 'inputs' not in kwargs else kwargs.pop('inputs')
+        outputs = self.outputs if 'outputs' not in kwargs else kwargs.pop('outputs')
         if dummy_inputs is None or inputs is None or outputs is None:
-            raise NotImplementedError(
-                'Model property dummy_inputs,inputs,outputs must be set.')
+            raise NotImplementedError('Model property dummy_inputs,inputs,outputs must be set.')
 
         with torch.no_grad():
             model.eval()
             device = torch.device(device)
             model.to(device)
             dummy_inputs = collate_fn(dummy_inputs, device)
 
             if isinstance(dummy_inputs, Mapping):
                 dummy_inputs = dict(dummy_inputs)
             onnx_outputs = list(outputs.keys())
 
             with replace_call():
-                onnx_export(
-                    model,
-                    (dummy_inputs, ),
-                    f=output,
-                    input_names=list(inputs.keys()),
-                    output_names=onnx_outputs,
-                    dynamic_axes={
-                        name: axes
-                        for name, axes in chain(inputs.items(),
-                                                outputs.items())
-                    },
-                    do_constant_folding=True,
-                    opset_version=opset,
-                )
+                onnx_export(model, (dummy_inputs,), f=output,
+                            input_names=list(inputs.keys()),
+                            output_names=onnx_outputs,
+                            dynamic_axes={
+                                name: axes
+                                for name, axes in chain(inputs.items(),
+                                                        outputs.items())
+                            },
+                            do_constant_folding=True,
+                            opset_version=opset,
+                            )
 
         if validation:
             self._validate_onnx_model(dummy_inputs, model, output,
                                       onnx_outputs, rtol, atol)
 
     def _validate_onnx_model(self,
                              dummy_inputs,
@@ -223,28 +280,24 @@
                              onnx_outputs,
                              rtol: float = None,
                              atol: float = None):
         try:
             import onnx
             import onnxruntime as ort
         except ImportError:
-            logger.warning(
-                'Cannot validate the exported onnx file, because '
-                'the installation of onnx or onnxruntime cannot be found')
+            logger.warning('Cannot validate the exported onnx file, because the installation of onnx or onnxruntime cannot be found')
             return
         onnx_model = onnx.load(output)
         onnx.checker.check_model(onnx_model)
         ort_session = ort.InferenceSession(output)
         with torch.no_grad():
             model.eval()
-            outputs_origin = model.forward(
-                *self._decide_input_format(model, dummy_inputs))
-        if isinstance(outputs_origin, (Mapping, ModelOutputBase)):
-            outputs_origin = list(
-                numpify_tensor_nested(outputs_origin).values())
+            outputs_origin = model.forward(*self._decide_input_format(model, dummy_inputs))
+        if isinstance(outputs_origin, (Mapping, BaseModelOutput)):
+            outputs_origin = list(numpify_tensor_nested(outputs_origin).values())
         elif isinstance(outputs_origin, (tuple, list)):
             outputs_origin = list(numpify_tensor_nested(outputs_origin))
 
         outputs = ort_session.run(
             onnx_outputs,
             numpify_tensor_nested(dummy_inputs),
         )
@@ -290,16 +343,15 @@
         """
 
         model.eval()
         dummy_param = 'dummy_inputs' not in kwargs
         dummy_inputs = self.generate_dummy_inputs(
             **kwargs) if dummy_param else kwargs.pop('dummy_inputs')
         if dummy_inputs is None:
-            raise NotImplementedError(
-                'Model property dummy_inputs must be set.')
+            raise NotImplementedError('Model property dummy_inputs must be set.')
         dummy_inputs = collate_fn(dummy_inputs, device)
         if isinstance(dummy_inputs, Mapping):
             dummy_inputs_filter = []
             for _input in self._decide_input_format(model, dummy_inputs):
                 if _input is not None:
                     dummy_inputs_filter.append(_input)
                 else:
@@ -345,20 +397,120 @@
         if not compare_arguments_nested(
                 'Torch script model output match failed', outputs,
                 outputs_origin, **tols):
             raise RuntimeError(
                 'export torch script failed because of validation error.')
 
 
-@contextmanager
-def replace_call():
-    """This function is used to recover the original call method.
-
-    The Model class of modelscope overrides the call method. When exporting to onnx or torchscript, torch will
-    prepare the parameters as the prototype of forward method, and trace the call method, this causes
-    problems. Here we recover the call method to the default implementation of torch.nn.Module, and change it
-    back after the tracing was done.
-    """
-    TorchModel.call_origin, TorchModel.__call__ = TorchModel.__call__, TorchModel._call_impl
-    yield
-    TorchModel.__call__ = TorchModel.call_origin
-    del TorchModel.call_origin
+class TfModelExporter(BaseExporter):
+
+    def generate_dummy_inputs(self, **kwargs) -> Dict[str, Any]:
+        """Generate dummy inputs for model exportation to onnx or other formats by tracing.
+
+        Returns:
+            Dummy inputs that matches the specific model input, the matched preprocessor can be used here.
+        """
+        return None
+
+    def export_onnx(self, output_dir: str, opset=13, **kwargs):
+        model = self.model if 'model' not in kwargs else kwargs.pop('model')
+        onnx_file = os.path.join(output_dir, ModelFile.ONNX_MODEL_FILE)
+        self._tf2_export_onnx(model, onnx_file, opset=opset, **kwargs)
+        return {'model': onnx_file}
+
+    def export_saved_model(self, output_dir: str, **kwargs):
+        raise NotImplementedError()
+
+    def export_frozen_graph_def(self, output_dir: str, **kwargs):
+        raise NotImplementedError()
+
+    def _tf2_export_onnx(self,
+                         model,
+                         output: str,
+                         opset: int = 13,
+                         validation: bool = True,
+                         rtol: float = None,
+                         atol: float = None,
+                         call_func: Callable = None,
+                         **kwargs):
+        logger.info(
+            'Important: This exporting function only supports models of tf2.0 or above.'
+        )
+        import onnx
+        import tf2onnx
+        dummy_inputs = self.generate_dummy_inputs(
+            **kwargs) if 'dummy_inputs' not in kwargs else kwargs.pop(
+            'dummy_inputs')
+        if dummy_inputs is None:
+            raise NotImplementedError('Model property dummy_inputs,inputs,outputs must be set.')
+
+        input_signature = [
+            tf.TensorSpec.from_tensor(tensor, name=key)
+            for key, tensor in dummy_inputs.items()
+        ]
+        onnx_model, _ = tf2onnx.convert.from_keras(
+            model, input_signature, opset=opset)
+        onnx.save(onnx_model, output)
+
+        if validation:
+            self._validate_model(dummy_inputs, model, output, rtol, atol,
+                                 call_func)
+
+    def _validate_model(
+            self,
+            dummy_inputs,
+            model,
+            output,
+            rtol: float = None,
+            atol: float = None,
+            call_func: Callable = None,
+    ):
+        try:
+            import onnx
+            import onnxruntime as ort
+        except ImportError:
+            logger.warn(
+                'Cannot validate the exported onnx file, because '
+                'the installation of onnx or onnxruntime cannot be found')
+            return
+
+        def tensor_nested_numpify(tensors):
+            if isinstance(tensors, (list, tuple)):
+                return type(tensors)(tensor_nested_numpify(t) for t in tensors)
+            if isinstance(tensors, Mapping):
+                # return dict
+                return {
+                    k: tensor_nested_numpify(t)
+                    for k, t in tensors.items()
+                }
+            if isinstance(tensors, tf.Tensor):
+                t = tensors.cpu()
+                return t.numpy()
+            return tensors
+
+        onnx_model = onnx.load(output)
+        onnx.checker.check_model(onnx_model, full_check=True)
+        ort_session = ort.InferenceSession(output)
+        outputs_origin = call_func(
+            dummy_inputs) if call_func is not None else model(dummy_inputs)
+        if isinstance(outputs_origin, (Mapping, BaseModelOutput)):
+            outputs_origin = list(
+                tensor_nested_numpify(outputs_origin).values())
+        elif isinstance(outputs_origin, (tuple, list)):
+            outputs_origin = list(tensor_nested_numpify(outputs_origin))
+        outputs = ort_session.run(
+            None,
+            tensor_nested_numpify(dummy_inputs),
+        )
+        outputs = tensor_nested_numpify(outputs)
+        if isinstance(outputs, dict):
+            outputs = list(outputs.values())
+        elif isinstance(outputs, tuple):
+            outputs = list(outputs)
+
+        tols = {}
+        if rtol is not None:
+            tols['rtol'] = rtol
+        if atol is not None:
+            tols['atol'] = atol
+        if not compare_arguments_nested('Onnx model output match failed',outputs, outputs_origin, **tols):
+            raise RuntimeError('export onnx failed because of validation error.')
```

### Comparing `weathon-0.0.0.13/weathon/dl/fileio/file.py` & `weathon-0.0.0.14/weathon/utils/fileio/file.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import contextlib
 import os
 import tempfile
 from abc import ABCMeta, abstractmethod
 from pathlib import Path
 from typing import Generator, Union
```

### Comparing `weathon-0.0.0.13/weathon/dl/fileio/format/json.py` & `weathon-0.0.0.14/weathon/utils/fileio/format/json.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 
 from . import jsonplus
 from .base import FormatHandler
 
 
 def set_default(obj):
```

### Comparing `weathon-0.0.0.13/weathon/dl/fileio/format/jsonplus.py` & `weathon-0.0.0.14/weathon/utils/fileio/format/jsonplus.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/fileio/format/yaml.py` & `weathon-0.0.0.14/weathon/utils/fileio/format/yaml.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import yaml
 
 try:
     from yaml import CDumper as Dumper
     from yaml import CLoader as Loader
 except ImportError:
     from yaml import Loader, Dumper  # type: ignore
```

### Comparing `weathon-0.0.0.13/weathon/dl/fileio/io.py` & `weathon-0.0.0.14/weathon/utils/fileio/io.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 # Copyright (c) OpenMMLab. All rights reserved.
 from io import BytesIO, StringIO
 from pathlib import Path
 
 from .file import File
 from .format import JsonHandler, YamlHandler
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/api.py` & `weathon-0.0.0.14/weathon/utils/hub/api.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # yapf: disable
 
 import datetime
 import functools
 import os
 import pickle
 import platform
@@ -16,58 +15,54 @@
 from os.path import expanduser
 from typing import Dict, List, Optional, Tuple, Union
 
 import requests
 from requests import Session
 from requests.adapters import HTTPAdapter, Retry
 
-from modelscope.hub.constants import (API_HTTP_CLIENT_TIMEOUT,
-                                      API_RESPONSE_FIELD_DATA,
-                                      API_RESPONSE_FIELD_EMAIL,
-                                      API_RESPONSE_FIELD_GIT_ACCESS_TOKEN,
-                                      API_RESPONSE_FIELD_MESSAGE,
-                                      API_RESPONSE_FIELD_USERNAME,
-                                      DEFAULT_CREDENTIALS_PATH,
-                                      MODELSCOPE_CLOUD_ENVIRONMENT,
-                                      MODELSCOPE_CLOUD_USERNAME,
-                                      ONE_YEAR_SECONDS,
-                                      REQUESTS_API_HTTP_METHOD, Licenses,
-                                      ModelVisibility)
-from modelscope.hub.errors import (InvalidParameter, NotExistError,
-                                   NotLoginException, NoValidRevisionError,
-                                   RequestError, datahub_raise_on_error,
-                                   handle_http_post_error,
-                                   handle_http_response, is_ok,
-                                   raise_for_http_status, raise_on_error)
-from modelscope.hub.git import GitCommandWrapper
-from modelscope.hub.repository import Repository
-from modelscope.utils.constant import (DEFAULT_DATASET_REVISION,
-                                       DEFAULT_MODEL_REVISION,
-                                       DEFAULT_REPOSITORY_REVISION,
-                                       MASTER_MODEL_BRANCH, DatasetFormations,
-                                       DatasetMetaFormats,
-                                       DatasetVisibilityMap, DownloadChannel,
-                                       ModelFile, VirgoDatasetConfig)
-from modelscope.utils.logger import get_logger
-from .utils.utils import (get_endpoint, get_release_datetime,
-                          model_id_to_group_owner_name)
+from weathon.utils.constants import DEFAULT_MODEL_REVISION, DEFAULT_REPOSITORY_REVISION, ModelFile, MASTER_MODEL_BRANCH, \
+    DatasetMetaFormats, DatasetFormations, DEFAULT_DATASET_REVISION, VirgoDatasetConfig, DatasetVisibilityMap, \
+    DownloadChannel
+from weathon.utils.constants.constants import (API_HTTP_CLIENT_TIMEOUT,
+                                               API_RESPONSE_FIELD_DATA,
+                                               API_RESPONSE_FIELD_EMAIL,
+                                               API_RESPONSE_FIELD_GIT_ACCESS_TOKEN,
+                                               API_RESPONSE_FIELD_MESSAGE,
+                                               API_RESPONSE_FIELD_USERNAME,
+                                               DEFAULT_CREDENTIALS_PATH,
+                                               MODELSCOPE_CLOUD_ENVIRONMENT,
+                                               MODELSCOPE_CLOUD_USERNAME,
+                                               ONE_YEAR_SECONDS,END_POINT,
+                                               REQUESTS_API_HTTP_METHOD, Licenses,
+                                               MODEL_ID_SEPARATOR, 
+                                               DEFAULT_MODELSCOPE_GROUP,
+                                               ModelVisibility)
+from weathon.errors.hub_error import (InvalidParameter, NotExistError,
+                                      NotLoginException, NoValidRevisionError,
+                                      RequestError, datahub_raise_on_error,
+                                      handle_http_post_error,
+                                      handle_http_response, is_ok,
+                                      raise_for_http_status, raise_on_error)
+from weathon.utils.hub.git import GitCommandWrapper
+from weathon.utils.hub.repository import Repository
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class HubApi:
     """Model hub api interface.
     """
     def __init__(self, endpoint: Optional[str] = None):
         """The ModelScope HubApi
 
         Args:
             endpoint (str, optional): The modelscope server http|https address. Defaults to None.
         """
-        self.endpoint = endpoint if endpoint is not None else get_endpoint()
+        self.endpoint = endpoint if endpoint is not None else END_POINT
         self.headers = {'user-agent': ModelScopeConfig.get_user_agent()}
         self.session = Session()
         retry = Retry(
             total=2,
             read=2,
             connect=2,
             backoff_factor=1,
@@ -163,19 +158,19 @@
             'OriginalModelId': original_model_id,
             'TrainId': os.environ.get('MODELSCOPE_TRAIN_ID', ''),
         }
         r = self.session.post(
             path, json=body, cookies=cookies, headers=self.headers)
         handle_http_post_error(r, path, body)
         raise_on_error(r.json())
-        model_repo_url = f'{get_endpoint()}/{model_id}'
+        model_repo_url = f'{END_POINT}/{model_id}'
         return model_repo_url
 
     def delete_model(self, model_id: str):
-        """Delete model_id from ModelScope.
+        """Delete model_id from weathon.
 
         Args:
             model_id (str): The model id.
 
         Raises:
             ValueError: If not login.
 
@@ -938,22 +933,42 @@
         env = 'custom'
         if MODELSCOPE_CLOUD_ENVIRONMENT in os.environ:
             env = os.environ[MODELSCOPE_CLOUD_ENVIRONMENT]
         user_name = 'unknown'
         if MODELSCOPE_CLOUD_USERNAME in os.environ:
             user_name = os.environ[MODELSCOPE_CLOUD_USERNAME]
 
-        from modelscope import __version__
-        ua = 'modelscope/%s; python/%s; session_id/%s; platform/%s; processor/%s; env/%s; user/%s' % (
+        from weathon import __version__
+        ua = 'weathon/%s; python/%s; session_id/%s; platform/%s; processor/%s; env/%s; user/%s' % (
             __version__,
             platform.python_version(),
             ModelScopeConfig.get_user_session_id(),
             platform.platform(),
             platform.processor(),
             env,
             user_name,
         )
         if isinstance(user_agent, dict):
             ua += '; ' + '; '.join(f'{k}/{v}' for k, v in user_agent.items())
         elif isinstance(user_agent, str):
             ua += '; ' + user_agent
         return ua
+
+def get_release_datetime():
+    if MODELSCOPE_SDK_DEBUG in os.environ:
+        rt = int(round(datetime.now().timestamp()))
+    else:
+        from weathon import version
+        rt = int(
+            round(
+                datetime.strptime(version.__release_datetime__,
+                                  '%Y-%m-%d %H:%M:%S').timestamp()))
+    return rt
+
+def model_id_to_group_owner_name(model_id):
+    if MODEL_ID_SEPARATOR in model_id:
+        group_or_owner = model_id.split(MODEL_ID_SEPARATOR)[0]
+        name = model_id.split(MODEL_ID_SEPARATOR)[1]
+    else:
+        group_or_owner = DEFAULT_MODELSCOPE_GROUP
+        name = model_id
+    return group_or_owner, name
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/check_model.py` & `weathon-0.0.0.14/weathon/utils/hub/check_model.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Dict, Optional, Union
 from urllib.parse import urlparse
 
-from modelscope.hub.api import HubApi, ModelScopeConfig
-from modelscope.hub.constants import FILE_HASH
-from modelscope.hub.git import GitCommandWrapper
-from modelscope.hub.utils.caching import ModelFileSystemCache
-from modelscope.hub.utils.utils import compute_hash
-from modelscope.utils.logger import get_logger
+from weathon.utils.hub.api import HubApi, ModelScopeConfig
+from weathon.utils.constants.constants import FILE_HASH
+from weathon.utils.fileio.caching import ModelFileSystemCache
+from weathon.utils.hub.git import GitCommandWrapper
+from weathon.utils.hub.utils import compute_hash
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def check_local_model_is_latest(
     model_root_path: str,
     user_agent: Optional[Union[Dict, str]] = None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/constants.py` & `weathon-0.0.0.14/weathon/utils/constants/constants.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
+import os
 from pathlib import Path
 
 MODELSCOPE_URL_SCHEME = 'http://'
 DEFAULT_MODELSCOPE_DOMAIN = 'www.modelscope.cn'
 DEFAULT_MODELSCOPE_DATA_ENDPOINT = MODELSCOPE_URL_SCHEME + DEFAULT_MODELSCOPE_DOMAIN
 
 DEFAULT_MODELSCOPE_GROUP = 'damo'
@@ -24,14 +23,17 @@
 MODELSCOPE_CLOUD_ENVIRONMENT = 'MODELSCOPE_ENVIRONMENT'
 MODELSCOPE_CLOUD_USERNAME = 'MODELSCOPE_USERNAME'
 MODELSCOPE_SDK_DEBUG = 'MODELSCOPE_SDK_DEBUG'
 ONE_YEAR_SECONDS = 24 * 365 * 60 * 60
 MODEL_META_FILE_NAME = '.mdl'
 MODEL_META_MODEL_ID = 'id'
 
+END_POINT = MODELSCOPE_URL_SCHEME + os.getenv('MODELSCOPE_DOMAIN', DEFAULT_MODELSCOPE_DOMAIN)
+
+
 
 class Licenses(object):
     APACHE_V2 = 'Apache License 2.0'
     GPL_V2 = 'GPL-2.0'
     GPL_V3 = 'GPL-3.0'
     LGPL_V2_1 = 'LGPL-2.1'
     LGPL_V3 = 'LGPL-3.0'
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/deploy.py` & `weathon-0.0.0.14/weathon/utils/hub/deploy.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,22 +3,22 @@
 from http import HTTPStatus
 from typing import Optional
 
 import json
 import requests
 from attrs import asdict, define, field, validators
 
-from modelscope.hub.api import ModelScopeConfig
-from modelscope.hub.constants import (API_RESPONSE_FIELD_DATA,
-                                      API_RESPONSE_FIELD_MESSAGE)
-from modelscope.hub.errors import (NotLoginException, NotSupportError,
-                                   RequestError, handle_http_response, is_ok,
-                                   raise_for_http_status)
-from modelscope.hub.utils.utils import get_endpoint
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.constants import (API_RESPONSE_FIELD_DATA,
+                                               API_RESPONSE_FIELD_MESSAGE)
+from weathon.errors.hub_error import (NotLoginException, NotSupportError,
+                                      RequestError, handle_http_response, is_ok,
+                                      raise_for_http_status)
+from weathon.utils.hub.api import ModelScopeConfig
+from weathon.utils.constants.constants import END_POINT
+from weathon.utils.logger import get_logger
 
 # yapf: enable
 
 logger = get_logger()
 
 
 class Accelerator(object):
@@ -185,15 +185,15 @@
 
 
 class ServiceDeployer(object):
     """Facilitate model deployment on to supported service provider(s).
     """
 
     def __init__(self, endpoint=None):
-        self.endpoint = endpoint if endpoint is not None else get_endpoint()
+        self.endpoint = endpoint if endpoint is not None else END_POINT
         self.headers = {'user-agent': ModelScopeConfig.get_user_agent()}
         self.cookies = ModelScopeConfig.get_cookies()
         if self.cookies is None:
             raise NotLoginException(
                 'Token does not exist, please login with HubApi first.')
 
     # deploy_model
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/errors.py` & `weathon-0.0.0.14/weathon/errors/hub_error.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from http import HTTPStatus
 
 import requests
 from requests.exceptions import HTTPError
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class NotSupportError(Exception):
     pass
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/file_download.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/ofa/ofa_trainer.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,259 +1,227 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import copy
+import math
 import os
+import shutil
 import tempfile
 from functools import partial
-from http.cookiejar import CookieJar
-from pathlib import Path
-from typing import Dict, Optional, Union
-
-import requests
-from requests.adapters import Retry
-from tqdm import tqdm
-
-from modelscope.hub.api import HubApi, ModelScopeConfig
-from modelscope.hub.constants import (API_FILE_DOWNLOAD_CHUNK_SIZE,
-                                      API_FILE_DOWNLOAD_RETRY_TIMES,
-                                      API_FILE_DOWNLOAD_TIMEOUT, FILE_HASH)
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION
-from modelscope.utils.logger import get_logger
-from .errors import FileDownloadError, NotExistError
-from .utils.caching import ModelFileSystemCache
-from .utils.utils import (file_integrity_validation, get_cache_dir,
-                          get_endpoint, model_id_to_group_owner_name)
-
-logger = get_logger()
-
-
-def model_file_download(
-    model_id: str,
-    file_path: str,
-    revision: Optional[str] = DEFAULT_MODEL_REVISION,
-    cache_dir: Optional[str] = None,
-    user_agent: Union[Dict, str, None] = None,
-    local_files_only: Optional[bool] = False,
-    cookies: Optional[CookieJar] = None,
-) -> Optional[str]:  # pragma: no cover
-    """Download from a given URL and cache it if it's not already present in the local cache.
-
-    Given a URL, this function looks for the corresponding file in the local
-    cache. If it's not there, download it. Then return the path to the cached
-    file.
+from shutil import ignore_patterns
+from typing import Callable, Dict, Optional, Tuple, Union
+
+import json
+import torch
+from torch import distributed as dist
+from torch import nn
+from torch.utils.data import Dataset
+
+from weathon.registry import TRAINERS, build_optimizer
+from weathon.utils.constants import DEFAULT_MODEL_REVISION, Invoke, ModelFile, ConfigKeys, ModeKeys
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.hub.file_download import model_file_download
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, TorchModel, EpochBasedTrainer
+from weathon.base import BasePreprocessor
+from weathon.preprocessors.multi_modal import OfaPreprocessor
+from weathon.preprocessors.ofa.utils.collate import collate_fn
+from weathon.trainers.parallel.utils import is_parallel
+from weathon.utils.config.config import Config
+from .ofa_trainer_utils import (AdjustLabelSmoothedCrossEntropyCriterion,
+                                get_schedule, recursive_overwrite)
+
+
+@TRAINERS.register_module(module_name=Trainers.ofa)
+class OFATrainer(EpochBasedTrainer):
+    r"""
+    OFA trainer for MaaS.
 
     Args:
-        model_id (str): The model to whom the file to be downloaded belongs.
-        file_path(str): Path of the file to be downloaded, relative to the root of model repo.
-        revision(str, optional): revision of the model file to be downloaded.
-            Can be any of a branch, tag or commit hash.
-        cache_dir (str, Path, optional): Path to the folder where cached files are stored.
-        user_agent (dict, str, optional): The user-agent info in the form of a dictionary or a string.
-        local_files_only (bool, optional):  If `True`, avoid downloading the file and return the path to the
-            local cached file if it exists. if `False`, download the file anyway even it exists.
-        cookies (CookieJar, optional): The cookie of download request.
-
-    Returns:
-        string: string of local file or if networking is off, last version of
-        file cached on disk.
-
-    Raises:
-        NotExistError: The file is not exist.
-        ValueError: The request parameter error.
-
-    Note:
-        Raises the following errors:
-
-            - [`EnvironmentError`](https://docs.python.org/3/library/exceptions.html#EnvironmentError)
-            if `use_auth_token=True` and the token cannot be found.
-            - [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError)
-            if ETag cannot be determined.
-            - [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)
-            if some parameter value is invalid
+        model (`str`): A model dir or a model id to be loaded
+        cfg_file (`str`, **optional**, default to `None`):
+            A config dir
+        cfg_modify_fn (`Callable`, **optional**, default to `None`):
+            A function which can rebuild the config file.
+        arg_parse_fn (`Callable`, **optional**, default to `None`):
+            Same as ``parse_fn`` in :obj:`Config.to_args`.
+        data_collator (`Callable`, **optional**, default to `None`):
+            The function to use to form a batch from a list of elements
+            of `train_dataset` or `eval_dataset`.
+        train_dataset (:obj:`MsDataset` or :obj:`Dataset`, **optional**, default to `None`):
+            Dataset for training.
+        eval_dataset (:obj:`MsDataset` or :obj:`Dataset`, **optional**, default to `None`):
+            Dataset for evaluation.
+        preprocessor (:obj:`Preprocessor`, **optional**, default to `None`):
+            The optional preprocessor.
+            NOTE: If the preprocessor has been called before the dataset fed into this trainer by user's custom code,
+            this parameter should be None, meanwhile remove the 'preprocessor' key from the cfg_file.
+            Else the preprocessor will be instantiated from the cfg_file or assigned from this parameter and
+            this preprocessing action will be executed every time the dataset's __getitem__ is called.
+        model_revision (`str`, **optional**, default to `None`):
+            The revision used when the model_name_or_path is
+                a model id of the remote hub. default `None`.
+        seed (`int`, **optional**, default to `42`):
+            The optional random seed for torch, cuda, numpy and random.
     """
-    if cache_dir is None:
-        cache_dir = get_cache_dir()
-    if isinstance(cache_dir, Path):
-        cache_dir = str(cache_dir)
-    temporary_cache_dir = os.path.join(cache_dir, 'temp')
-    os.makedirs(temporary_cache_dir, exist_ok=True)
-
-    group_or_owner, name = model_id_to_group_owner_name(model_id)
-
-    cache = ModelFileSystemCache(cache_dir, group_or_owner, name)
-
-    # if local_files_only is `True` and the file already exists in cached_path
-    # return the cached path
-    if local_files_only:
-        cached_file_path = cache.get_file_by_path(file_path)
-        if cached_file_path is not None:
-            logger.warning(
-                "File exists in local cache, but we're not sure it's up to date"
+
+    def __init__(
+            self,
+            model: Optional[Union[TorchModel, nn.Module, str]] = None,
+            cfg_file: Optional[str] = None,
+            cfg_modify_fn: Optional[Callable] = None,
+            arg_parse_fn: Optional[Callable] = None,
+            data_collator: Optional[Union[Callable, Dict[str,
+                                                         Callable]]] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            preprocessor: Optional[Union[BasePreprocessor,
+                                         Dict[str, BasePreprocessor]]] = None,
+            optimizers: Tuple[torch.optim.Optimizer,
+                              torch.optim.lr_scheduler._LRScheduler] = (None,
+                                                                        None),
+            model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
+            seed: int = 42,
+            **kwargs):
+        model = BaseModel.from_pretrained(
+            model, revision=model_revision, invoked_by=Invoke.TRAINER)
+        model_dir = model.model_dir
+        self.cfg_modify_fn = cfg_modify_fn
+
+        work_dir = kwargs.get('work_dir', 'workspace')
+        os.makedirs(work_dir, exist_ok=True)
+        ignore_file_set = set()
+        if cfg_file is not None:
+            cfg_file = self.get_config_file(cfg_file)
+            dst = os.path.abspath(
+                os.path.join(work_dir, ModelFile.CONFIGURATION))
+            src = os.path.abspath(cfg_file)
+            if src != dst:
+                shutil.copy(src, work_dir)
+            ignore_file_set.add(ModelFile.CONFIGURATION)
+        recursive_overwrite(
+            model_dir, work_dir, ignore=ignore_patterns(*ignore_file_set))
+        cfg_file = os.path.join(work_dir, ModelFile.CONFIGURATION)
+        cfg = self.rebuild_config(Config.from_file(cfg_file))
+        if cfg_modify_fn is not None:
+            cfg = self.cfg_modify_fn(cfg)
+            with open(cfg_file, 'w') as writer:
+                json.dump(dict(cfg), fp=writer, indent=4)
+        if preprocessor is None:
+            preprocessor = {
+                ConfigKeys.train:
+                OfaPreprocessor(
+                    model_dir=work_dir, mode=ModeKeys.TRAIN, no_collate=True),
+                ConfigKeys.val:
+                OfaPreprocessor(
+                    model_dir=work_dir, mode=ModeKeys.EVAL, no_collate=True),
+            }
+        # use torchrun launch
+        world_size = int(os.environ.get('WORLD_SIZE', 1))
+        epoch_steps = math.ceil(
+            len(train_dataset) /  # noqa
+            (cfg.train.dataloader.batch_size_per_gpu * world_size))  # noqa
+        cfg.train.lr_scheduler.num_train_steps = epoch_steps * cfg.train.max_epochs
+        cfg.train.criterion.tokenizer = model.tokenizer
+        self.criterion = AdjustLabelSmoothedCrossEntropyCriterion(
+            cfg.train.criterion)
+        if optimizers[0] is None:
+            optimizer = build_optimizer(model, cfg=cfg.train.optimizer)
+        else:
+            optimizer = optimizers[0]
+        if optimizers[1] is None:
+            scheduler_class, scheduler_args = get_schedule(
+                cfg.train.lr_scheduler)
+            if scheduler_class is not None:
+                lr_scheduler = scheduler_class(**{'optimizer': optimizer},
+                                               **scheduler_args)
+            else:
+                lr_scheduler = None
+        else:
+            lr_scheduler = optimizers[1]
+        optimizers = (optimizer, lr_scheduler)
+        if data_collator is None:
+            data_collator = partial(
+                collate_fn,
+                pad_idx=model.tokenizer.pad_token_id,
+                eos_idx=model.tokenizer.eos_token_id,
             )
-            return cached_file_path
+        if 'launcher' not in kwargs and cfg.train.get('launcher', None):
+            kwargs['launcher'] = cfg.train.launcher
+        if 'use_fp16' not in kwargs and cfg.train.get('use_fp16', False):
+            kwargs['use_fp16'] = cfg.train.use_fp16
+        kwargs['to_tensor'] = False
+        super().__init__(
+            model=model,
+            cfg_file=cfg_file,
+            arg_parse_fn=arg_parse_fn,
+            cfg_modify_fn=cfg_modify_fn,
+            data_collator=data_collator,
+            train_dataset=train_dataset,
+            eval_dataset=eval_dataset,
+            preprocessor=preprocessor,
+            optimizers=optimizers,
+            seed=seed,
+            **kwargs,
+        )
+
+    def rebuild_config(self, cfg: Config):
+        r"""
+        rebuild config if `cfg_modify_fn` is not `None`.
+        """
+        if self.cfg_modify_fn is not None:
+            cfg = self.cfg_modify_fn(cfg)
+        return cfg
+
+    def get_config_file(self, config_file: str):
+        r"""
+        support local file/ url or model_id with revision
+        """
+        if os.path.exists(config_file):
+            return config_file
         else:
-            raise ValueError(
-                'Cannot find the requested files in the cached path and outgoing'
-                ' traffic has been disabled. To enable model look-ups and downloads'
-                " online, set 'local_files_only' to False.")
-
-    _api = HubApi()
-    headers = {
-        'user-agent': ModelScopeConfig.get_user_agent(user_agent=user_agent, )
-    }
-    if cookies is None:
-        cookies = ModelScopeConfig.get_cookies()
-
-    revision = _api.get_valid_revision(
-        model_id, revision=revision, cookies=cookies)
-    file_to_download_info = None
-    # we need to confirm the version is up-to-date
-    # we need to get the file list to check if the latest version is cached, if so return, otherwise download
-    model_files = _api.get_model_files(
-        model_id=model_id,
-        revision=revision,
-        recursive=True,
-        use_cookies=False if cookies is None else cookies)
-
-    for model_file in model_files:
-        if model_file['Type'] == 'tree':
-            continue
-
-        if model_file['Path'] == file_path:
-            if cache.exists(model_file):
-                logger.debug(
-                    f'File {model_file["Name"]} already in cache, skip downloading!'
-                )
-                return cache.get_file_by_info(model_file)
+            temp_name = tempfile.TemporaryDirectory().name
+            if len(config_file.split('#')) == 2:
+                model_id = config_file.split('#')[0]
+                revision = config_file.split('#')[-1].split('=')[-1]
             else:
-                file_to_download_info = model_file
-            break
-
-    if file_to_download_info is None:
-        raise NotExistError('The file path: %s not exist in: %s' %
-                            (file_path, model_id))
-
-    # we need to download again
-    url_to_download = get_file_download_url(model_id, file_path, revision)
-    file_to_download_info = {
-        'Path': file_path,
-        'Revision': file_to_download_info['Revision'],
-        FILE_HASH: file_to_download_info[FILE_HASH]
-    }
-
-    temp_file_name = next(tempfile._get_candidate_names())
-    http_get_file(
-        url_to_download,
-        temporary_cache_dir,
-        temp_file_name,
-        headers=headers,
-        cookies=None if cookies is None else cookies.get_dict())
-    temp_file_path = os.path.join(temporary_cache_dir, temp_file_name)
-    # for download with commit we can't get Sha256
-    if file_to_download_info[FILE_HASH] is not None:
-        file_integrity_validation(temp_file_path,
-                                  file_to_download_info[FILE_HASH])
-    return cache.put_file(file_to_download_info,
-                          os.path.join(temporary_cache_dir, temp_file_name))
-
-
-def get_file_download_url(model_id: str, file_path: str, revision: str):
-    """Format file download url according to `model_id`, `revision` and `file_path`.
-    e.g., Given `model_id=john/bert`, `revision=master`, `file_path=README.md`,
-    the resulted download url is: https://modelscope.cn/api/v1/models/john/bert/repo?Revision=master&FilePath=README.md
-
-    Args:
-        model_id (str): The model_id.
-        file_path (str): File path
-        revision (str): File revision.
-
-    Returns:
-        str: The file url.
-    """
-    download_url_template = '{endpoint}/api/v1/models/{model_id}/repo?Revision={revision}&FilePath={file_path}'
-    return download_url_template.format(
-        endpoint=get_endpoint(),
-        model_id=model_id,
-        revision=revision,
-        file_path=file_path,
-    )
-
-
-def http_get_file(
-    url: str,
-    local_dir: str,
-    file_name: str,
-    cookies: CookieJar,
-    headers: Optional[Dict[str, str]] = None,
-):
-    """Download remote file, will retry 5 times before giving up on errors.
-
-    Args:
-        url(str):
-            actual download url of the file
-        local_dir(str):
-            local directory where the downloaded file stores
-        file_name(str):
-            name of the file stored in `local_dir`
-        cookies(CookieJar):
-            cookies used to authentication the user, which is used for downloading private repos
-        headers(Dict[str, str], optional):
-            http headers to carry necessary info when requesting the remote file
-
-    Raises:
-        FileDownloadError: File download failed.
-
-    """
-    total = -1
-    temp_file_manager = partial(
-        tempfile.NamedTemporaryFile, mode='wb', dir=local_dir, delete=False)
-    get_headers = {} if headers is None else copy.deepcopy(headers)
-    with temp_file_manager() as temp_file:
-        logger.debug('downloading %s to %s', url, temp_file.name)
-        # retry sleep 0.5s, 1s, 2s, 4s
-        retry = Retry(
-            total=API_FILE_DOWNLOAD_RETRY_TIMES,
-            backoff_factor=1,
-            allowed_methods=['GET'])
-        while True:
-            try:
-                downloaded_size = temp_file.tell()
-                get_headers['Range'] = 'bytes=%d-' % downloaded_size
-                r = requests.get(
-                    url,
-                    stream=True,
-                    headers=get_headers,
-                    cookies=cookies,
-                    timeout=API_FILE_DOWNLOAD_TIMEOUT)
-                r.raise_for_status()
-                content_length = r.headers.get('Content-Length')
-                total = int(
-                    content_length) if content_length is not None else None
-                progress = tqdm(
-                    unit='B',
-                    unit_scale=True,
-                    unit_divisor=1024,
-                    total=total,
-                    initial=downloaded_size,
-                    desc='Downloading',
-                )
-                for chunk in r.iter_content(
-                        chunk_size=API_FILE_DOWNLOAD_CHUNK_SIZE):
-                    if chunk:  # filter out keep-alive new chunks
-                        progress.update(len(chunk))
-                        temp_file.write(chunk)
-                progress.close()
-                break
-            except (Exception) as e:  # no matter what happen, we will retry.
-                retry = retry.increment('GET', url, error=e)
-                retry.sleep()
-
-    logger.debug('storing %s in cache at %s', url, local_dir)
-    downloaded_length = os.path.getsize(temp_file.name)
-    if total != downloaded_length:
-        os.remove(temp_file.name)
-        msg = 'File %s download incomplete, content_length: %s but the \
-                    file downloaded length: %s, please download again' % (
-            file_name, total, downloaded_length)
-        logger.error(msg)
-        raise FileDownloadError(msg)
-    os.replace(temp_file.name, os.path.join(local_dir, file_name))
+                model_id = config_file
+                revision = DEFAULT_MODEL_REVISION
+            file_name = model_file_download(
+                model_id,
+                file_path=ModelFile.CONFIGURATION,
+                revision=revision,
+                cache_dir=temp_name)
+            return file_name
+
+    def train_step(self, model, inputs):
+        r"""
+        A single training step.
+
+        step 1. Let the model in a trainable state.
+        step 2. Execute the criterion function.
+        step 3. Update the logging variable's value.
+        step 4. Update the training result.
+
+        Args:
+            model (:obj:`torch.nn.Module` or :obj:`TorchModel`): The model to be run.
+            inputs (`dict`): model inputs.
+        """
+        model = model.module if self._dist or is_parallel(model) else model
+        model.train()
+        loss, sample_size, logging_output = self.criterion(model, inputs)
+        train_outputs = {'loss': loss}
+        # add model output info to log
+        if 'log_vars' not in train_outputs:
+            default_keys_pattern = ['loss']
+            match_keys = set([])
+            for key_p in default_keys_pattern:
+                match_keys.update(
+                    [key for key in train_outputs.keys() if key_p in key])
+            log_vars = {}
+            for key in match_keys:
+                value = train_outputs.get(key, None)
+                if value is not None:
+                    if dist.is_available() and dist.is_initialized():
+                        value = value.data.clone()
+                        dist.all_reduce(value.div_(dist.get_world_size()))
+                    log_vars.update({key: value.item()})
+            self.log_buffer.update(log_vars)
+        else:
+            self.log_buffer.update(train_outputs['log_vars'])
+        self.train_outputs = train_outputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/git.py` & `weathon-0.0.0.14/weathon/utils/hub/git.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import subprocess
 from typing import List, Optional
 
-from modelscope.utils.logger import get_logger
-from ..utils.constant import MASTER_MODEL_BRANCH
-from .errors import GitError
+from weathon.utils.constants import MASTER_MODEL_BRANCH
+from weathon.utils.logger import get_logger
+from weathon.errors.hub_error import GitError
 
 logger = get_logger()
 
 
 class Singleton(type):
     _instances = {}
 
@@ -126,15 +124,15 @@
         logger.debug(clone_args)
         clone_args = clone_args.split(' ')
         response = self._run_git_command(*clone_args)
         logger.debug(response.stdout.decode('utf8'))
         return response
 
     def add_user_info(self, repo_base_dir, repo_name):
-        from modelscope.hub.api import ModelScopeConfig
+        from weathon.utils.hub.api import ModelScopeConfig
         user_name, user_email = ModelScopeConfig.get_user_info()
         if user_name and user_email:
             # config user.name and user.email if exist
             config_user_name_args = '-C %s/%s config user.name %s' % (
                 repo_base_dir, repo_name, user_name)
             response = self._run_git_command(*config_user_name_args.split(' '))
             logger.debug(response.stdout.decode('utf8'))
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/push_to_hub.py` & `weathon-0.0.0.14/weathon/utils/hub/push_to_hub.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,16 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import concurrent.futures
 import os
 
-from modelscope.hub.api import HubApi
-from modelscope.hub.constants import ModelVisibility
-from modelscope.utils.constant import DEFAULT_REPOSITORY_REVISION
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import DEFAULT_REPOSITORY_REVISION
+from weathon.utils.hub.api import HubApi
+from weathon.utils.constants.constants import ModelVisibility
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 _executor = concurrent.futures.ProcessPoolExecutor(max_workers=8)
 
 
 def _api_push_to_hub(repo_name,
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/repository.py` & `weathon-0.0.0.14/weathon/utils/hub/repository.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Optional
 
-from modelscope.hub.errors import GitError, InvalidParameter, NotLoginException
-from modelscope.utils.constant import (DEFAULT_DATASET_REVISION,
-                                       DEFAULT_REPOSITORY_REVISION,
-                                       MASTER_MODEL_BRANCH)
-from modelscope.utils.logger import get_logger
+from weathon.errors.hub_error import GitError, InvalidParameter, NotLoginException
+from weathon.utils.logger import get_logger
 from .git import GitCommandWrapper
-from .utils.utils import get_endpoint
+from weathon.utils.constants.constants import END_POINT
+from weathon.utils.constants import DEFAULT_REPOSITORY_REVISION, MASTER_MODEL_BRANCH, DEFAULT_DATASET_REVISION
 
 logger = get_logger()
 
 
 class Repository:
     """A local representation of the model git repository.
     """
@@ -43,15 +39,15 @@
         self.model_base_dir = os.path.dirname(model_dir)
         self.model_repo_name = os.path.basename(model_dir)
 
         if not revision:
             err_msg = 'a non-default value of revision cannot be empty.'
             raise InvalidParameter(err_msg)
 
-        from modelscope.hub.api import ModelScopeConfig
+        from weathon.utils.hub.api import ModelScopeConfig
         if auth_token:
             self.auth_token = auth_token
         else:
             self.auth_token = ModelScopeConfig.get_token()
 
         git_wrapper = GitCommandWrapper()
         if not git_wrapper.is_lfs_installed():
@@ -74,15 +70,15 @@
         # add user info if login
         self.git_wrapper.add_user_info(self.model_base_dir,
                                        self.model_repo_name)
         if self.auth_token:  # config remote with auth token
             self.git_wrapper.config_auth_token(self.model_dir, self.auth_token)
 
     def _get_model_id_url(self, model_id):
-        url = f'{get_endpoint()}/{model_id}.git'
+        url = f'{END_POINT}/{model_id}.git'
         return url
 
     def _get_remote_url(self):
         try:
             remote = self.git_wrapper.get_repo_remote_url(self.model_dir)
         except GitError:
             remote = None
@@ -229,15 +225,15 @@
         self.repo_base_dir = os.path.dirname(self.repo_work_dir)
         self.repo_name = os.path.basename(self.repo_work_dir)
 
         if not revision:
             err_msg = 'a non-default value of revision cannot be empty.'
             raise InvalidParameter(err_msg)
         self.revision = revision
-        from modelscope.hub.api import ModelScopeConfig
+        from weathon.utils.hub.api import ModelScopeConfig
         if auth_token:
             self.auth_token = auth_token
         else:
             self.auth_token = ModelScopeConfig.get_token()
 
         self.git_wrapper = GitCommandWrapper(git_path)
         os.makedirs(self.repo_work_dir, exist_ok=True)
@@ -299,15 +295,15 @@
             repo_dir=self.repo_work_dir,
             token=self.auth_token,
             url=remote_url,
             local_branch=branch,
             remote_branch=branch)
 
     def _get_repo_url(self, dataset_id):
-        return f'{get_endpoint()}/datasets/{dataset_id}.git'
+        return f'{END_POINT}/datasets/{dataset_id}.git'
 
     def _get_remote_url(self):
         try:
             remote = self.git_wrapper.get_repo_remote_url(self.repo_work_dir)
         except GitError:
             remote = None
         return remote
```

### Comparing `weathon-0.0.0.13/weathon/dl/hub/utils/caching.py` & `weathon-0.0.0.14/weathon/utils/fileio/caching.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import hashlib
 import os
 import pickle
 import tempfile
 from shutil import move, rmtree
 
-from modelscope.hub.constants import MODEL_META_FILE_NAME, MODEL_META_MODEL_ID
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.constants import MODEL_META_FILE_NAME, MODEL_META_MODEL_ID
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 """Implements caching functionality, used internally only
 """
 
 
 class FileSystemCache(object):
```

### Comparing `weathon-0.0.0.13/weathon/dl/metainfo.py` & `weathon-0.0.0.14/weathon/utils/constants/metainfo.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.utils.constant import Fields, Tasks
+from weathon.utils.constants import Fields, Tasks
 
 
 class Models(object):
     """ Names for different models.
 
         Holds the standard model name to use for identifying different model.
     This should be used to register models.
@@ -1169,7 +1168,106 @@
 class CustomDatasets(object):
     """ Names for different datasets.
     """
     PairedDataset = 'PairedDataset'
     SiddDataset = 'SiddDataset'
     GoproDataset = 'GoproDataset'
     RedsDataset = 'RedsDataset'
+
+
+
+PREPROCESSOR_MAP = {
+    # nlp
+    (Models.canmt, Tasks.competency_aware_translation): Preprocessors.canmt_translation,
+    # bart
+    (Models.bart, Tasks.text_error_correction):Preprocessors.text_error_correction,
+
+    # bert
+    (Models.bert, Tasks.backbone): Preprocessors.sen_cls_tokenizer,
+    (Models.bert, Tasks.document_segmentation): Preprocessors.document_segmentation,
+    (Models.bert, Tasks.fill_mask): Preprocessors.fill_mask,
+    (Models.bert, Tasks.sentence_embedding): Preprocessors.sentence_embedding,
+    (Models.bert, Tasks.text_classification): Preprocessors.sen_cls_tokenizer,
+    (Models.bert, Tasks.nli): Preprocessors.sen_cls_tokenizer,
+    (Models.bert, Tasks.sentiment_classification): Preprocessors.sen_cls_tokenizer,
+    (Models.bert, Tasks.sentence_similarity): Preprocessors.sen_cls_tokenizer,
+    (Models.bert, Tasks.zero_shot_classification): Preprocessors.sen_cls_tokenizer,
+    (Models.bert, Tasks.text_ranking): Preprocessors.text_ranking,
+    (Models.bert, Tasks.part_of_speech): Preprocessors.token_cls_tokenizer,
+    (Models.bert, Tasks.token_classification): Preprocessors.token_cls_tokenizer,
+    (Models.bert, Tasks.word_segmentation): Preprocessors.token_cls_tokenizer,
+
+    # bloom
+    (Models.bloom, Tasks.backbone): Preprocessors.text_gen_tokenizer,
+
+    # gpt_neo
+    # gpt_neo may have different preprocessors, but now only one
+    (Models.gpt_neo, Tasks.backbone): Preprocessors.sentence_piece,
+
+    # gpt3 has different preprocessors by different sizes of models, so they are not listed here.
+
+    # palm_v2
+    (Models.palm, Tasks.backbone): Preprocessors.text_gen_tokenizer,
+
+    # T5
+    (Models.T5, Tasks.backbone): Preprocessors.text2text_gen_preprocessor,
+    (Models.T5, Tasks.text2text_generation): Preprocessors.text2text_gen_preprocessor,
+
+    # deberta_v2
+    (Models.deberta_v2, Tasks.backbone): Preprocessors.sen_cls_tokenizer,
+    (Models.deberta_v2, Tasks.fill_mask): Preprocessors.fill_mask,
+
+    # ponet
+    (Models.ponet, Tasks.fill_mask): Preprocessors.fill_mask_ponet,
+
+    # structbert
+    (Models.structbert, Tasks.backbone): Preprocessors.sen_cls_tokenizer,
+    (Models.structbert, Tasks.fill_mask): Preprocessors.fill_mask,
+    (Models.structbert, Tasks.faq_question_answering): Preprocessors.faq_question_answering_preprocessor,
+    (Models.structbert, Tasks.text_classification): Preprocessors.sen_cls_tokenizer,
+    (Models.structbert, Tasks.nli): Preprocessors.sen_cls_tokenizer,
+    (Models.structbert, Tasks.sentiment_classification):  Preprocessors.sen_cls_tokenizer,
+    (Models.structbert, Tasks.sentence_similarity): Preprocessors.sen_cls_tokenizer,
+    (Models.structbert, Tasks.zero_shot_classification): Preprocessors.sen_cls_tokenizer,
+    (Models.structbert, Tasks.part_of_speech): Preprocessors.token_cls_tokenizer,
+    (Models.token_classification_for_ner, Tasks.named_entity_recognition):  Preprocessors.token_cls_tokenizer,
+    (Models.structbert, Tasks.token_classification): Preprocessors.token_cls_tokenizer,
+    (Models.structbert, Tasks.word_segmentation): Preprocessors.token_cls_tokenizer,
+
+    # doc2bot
+    (Models.doc2bot, Tasks.document_grounded_dialog_generate): Preprocessors.document_grounded_dialog_generate,
+    (Models.doc2bot, Tasks.document_grounded_dialog_rerank):  Preprocessors.document_grounded_dialog_rerank,
+    (Models.doc2bot, Tasks.document_grounded_dialog_retrieval): Preprocessors.document_grounded_dialog_retrieval,
+
+    # veco
+    (Models.veco, Tasks.backbone): Preprocessors.sen_cls_tokenizer,
+    (Models.veco, Tasks.fill_mask): Preprocessors.fill_mask,
+    (Models.veco, Tasks.text_classification): Preprocessors.sen_cls_tokenizer,
+    (Models.veco, Tasks.nli): Preprocessors.sen_cls_tokenizer,
+    (Models.veco, Tasks.sentiment_classification):  Preprocessors.sen_cls_tokenizer,
+    (Models.veco, Tasks.sentence_similarity): Preprocessors.sen_cls_tokenizer,
+
+    # ner models
+    (Models.lcrf, Tasks.named_entity_recognition): Preprocessors.sequence_labeling_tokenizer,
+    (Models.lcrf, Tasks.word_segmentation): Preprocessors.sequence_labeling_tokenizer,
+    (Models.lcrf, Tasks.part_of_speech): Preprocessors.sequence_labeling_tokenizer,
+    (Models.lcrf_wseg, Tasks.word_segmentation): Preprocessors.sequence_labeling_tokenizer,
+    (Models.tcrf_wseg, Tasks.word_segmentation): Preprocessors.sequence_labeling_tokenizer,
+    (Models.tcrf, Tasks.named_entity_recognition): Preprocessors.sequence_labeling_tokenizer,
+
+    # task models
+    (TaskModels.token_classification, Tasks.token_classification): Preprocessors.sequence_labeling_tokenizer,
+    (TaskModels.token_classification, Tasks.part_of_speech): Preprocessors.sequence_labeling_tokenizer,
+    (TaskModels.token_classification, Tasks.named_entity_recognition): Preprocessors.sequence_labeling_tokenizer,
+    (TaskModels.text_classification, Tasks.text_classification): Preprocessors.sen_cls_tokenizer,
+    (TaskModels.fill_mask, Tasks.fill_mask): Preprocessors.fill_mask,
+    (TaskModels.feature_extraction, Tasks.feature_extraction): Preprocessors.feature_extraction,
+    (TaskModels.information_extraction, Tasks.information_extraction): Preprocessors.re_tokenizer,
+    (TaskModels.text_ranking, Tasks.text_ranking): Preprocessors.text_ranking,
+    (TaskModels.text_generation, Tasks.text_generation): Preprocessors.text_gen_tokenizer,
+
+    # cv
+    (Models.tinynas_detection, Tasks.image_object_detection): Preprocessors.object_detection_tinynas_preprocessor,
+    (Models.tinynas_damoyolo, Tasks.image_object_detection): Preprocessors.object_detection_tinynas_preprocessor,
+    (Models.tinynas_damoyolo, Tasks.domain_specific_object_detection): Preprocessors.object_detection_tinynas_preprocessor,
+    (Models.controllable_image_generation, Tasks.controllable_image_generation):  Preprocessors.controllable_image_generation_preprocessor,
+}
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/__init__.py` & `weathon-0.0.0.14/weathon/metrics/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .audio_noise_metric import AudioNoiseMetric
-    from .base import Metric
-    from .builder import METRICS, build_metric, task_default_metrics
     from .image_color_enhance_metric import ImageColorEnhanceMetric
     from .image_denoise_metric import ImageDenoiseMetric
     from .image_instance_segmentation_metric import \
         ImageInstanceSegmentationCOCOMetric
     from .image_portrait_enhancement_metric import ImagePortraitEnhancementMetric
     from .sequence_classification_metric import SequenceClassificationMetric
     from .text_generation_metric import TextGenerationMetric
@@ -31,16 +28,14 @@
     from .loss_metric import LossMetric
     from .image_colorization_metric import ImageColorizationMetric
     from .ocr_recognition_metric import OCRRecognitionMetric
     from .translation_evaluation_metric import TranslationEvaluationMetric
 else:
     _import_structure = {
         'audio_noise_metric': ['AudioNoiseMetric'],
-        'base': ['Metric'],
-        'builder': ['METRICS', 'build_metric', 'task_default_metrics'],
         'image_color_enhance_metric': ['ImageColorEnhanceMetric'],
         'image_denoise_metric': ['ImageDenoiseMetric'],
         'image_instance_segmentation_metric':
         ['ImageInstanceSegmentationCOCOMetric'],
         'image_portrait_enhancement_metric':
         ['ImagePortraitEnhancementMetric'],
         'sequence_classification_metric': ['SequenceClassificationMetric'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/accuracy_metric.py` & `weathon-0.0.0.14/weathon/metrics/ned_metric.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,70 +1,98 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict
 
 import numpy as np
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
+from weathon.utils.constants.output_constant import OutputKeys
+
 
-from modelscope.metainfo import Metrics
-from modelscope.outputs import OutputKeys
-from modelscope.utils.chinese_utils import remove_space_between_chinese_chars
-from modelscope.utils.registry import default_group
-from modelscope.utils.tensor_utils import torch_nested_numpify
-from .base import Metric
-from .builder import METRICS, MetricKeys
 
 
-@METRICS.register_module(group_key=default_group, module_name=Metrics.accuracy)
-class AccuracyMetric(Metric):
-    """The metric computation class for classification classes.
+@METRICS.register_module(group_key=default_group, module_name=Metrics.NED)
+class NedMetric(BaseMetric):
+    """The ned metric computation class for classification classes.
 
-    This metric class calculates accuracy for the whole input batches.
+    This metric class calculates the levenshtein distance between sentences for the whole input batches.
     """
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.preds = []
         self.labels = []
 
     def add(self, outputs: Dict, inputs: Dict):
         label_name = OutputKeys.LABEL if OutputKeys.LABEL in inputs else OutputKeys.LABELS
         ground_truths = inputs[label_name]
-        eval_results = None
+        eval_results = outputs[label_name]
         for key in [
                 OutputKeys.CAPTION, OutputKeys.TEXT, OutputKeys.BOXES,
-                OutputKeys.LABEL, OutputKeys.LABELS, OutputKeys.SCORES
+                OutputKeys.LABELS, OutputKeys.SCORES
         ]:
             if key in outputs and outputs[key] is not None:
                 eval_results = outputs[key]
                 break
         assert type(ground_truths) == type(eval_results)
-        ground_truths = torch_nested_numpify(ground_truths)
-        for truth in ground_truths:
-            self.labels.append(truth)
-        eval_results = torch_nested_numpify(eval_results)
-        for result in eval_results:
-            if isinstance(truth, str):
-                if isinstance(result, list):
-                    result = result[0]
-                assert isinstance(result, str), 'both truth and pred are str'
-                self.preds.append(remove_space_between_chinese_chars(result))
-            else:
-                self.preds.append(result)
+        if isinstance(ground_truths, list):
+            self.preds.extend(eval_results)
+            self.labels.extend(ground_truths)
+        elif isinstance(ground_truths, np.ndarray):
+            self.preds.extend(eval_results.tolist())
+            self.labels.extend(ground_truths.tolist())
+        else:
+            raise Exception('only support list or np.ndarray')
 
     def evaluate(self):
         assert len(self.preds) == len(self.labels)
         return {
-            MetricKeys.ACCURACY: (np.asarray([
-                pred == ref for pred, ref in zip(self.preds, self.labels)
+            MetricKeys.NED: (np.asarray([
+                1.0 - NedMetric._distance(pred, ref)
+                for pred, ref in zip(self.preds, self.labels)
             ])).mean().item()
         }
 
-    def merge(self, other: 'AccuracyMetric'):
+    def merge(self, other: 'NedMetric'):
         self.preds.extend(other.preds)
         self.labels.extend(other.labels)
 
     def __getstate__(self):
         return self.preds, self.labels
 
     def __setstate__(self, state):
         self.__init__()
         self.preds, self.labels = state
+
+    @staticmethod
+    def _distance(pred, ref):
+        if pred is None or ref is None:
+            raise TypeError('Argument (pred or ref) is NoneType.')
+        if pred == ref:
+            return 0.0
+        if len(pred) == 0:
+            return len(ref)
+        if len(ref) == 0:
+            return len(pred)
+        m_len = max(len(pred), len(ref))
+        if m_len == 0:
+            return 0.0
+
+        def levenshtein(s0, s1):
+            v0 = [0] * (len(s1) + 1)
+            v1 = [0] * (len(s1) + 1)
+
+            for i in range(len(v0)):
+                v0[i] = i
+
+            for i in range(len(s0)):
+                v1[0] = i + 1
+                for j in range(len(s1)):
+                    cost = 1
+                    if s0[i] == s1[j]:
+                        cost = 0
+                    v1[j + 1] = min(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost)
+                v0, v1 = v1, v0
+            return v0[len(s1)]
+
+        return levenshtein(pred, ref) / m_len
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/action_detection_evaluator.py` & `weathon-0.0.0.14/weathon/metrics/action_detection_evaluator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import copy
 import logging
 import os.path as osp
 from collections import OrderedDict
 
 import numpy as np
 import pandas as pd
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/audio_noise_metric.py` & `weathon-0.0.0.14/weathon/metrics/audio_noise_metric.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,20 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict
 
-from modelscope.metainfo import Metrics
-from modelscope.metrics.base import Metric
-from modelscope.metrics.builder import METRICS, MetricKeys
-from modelscope.utils.registry import default_group
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.audio_noise_metric)
-class AudioNoiseMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.audio_noise_metric)
+class AudioNoiseMetric(BaseMetric):
     """
     The metric computation class for acoustic noise suppression task.
     """
 
     def __init__(self):
         self.loss = []
         self.amp_loss = []
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/base.py` & `weathon-0.0.0.14/weathon/base/metric.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from abc import ABC, abstractmethod
 from typing import Dict
 
 
-class Metric(ABC):
+
+
+class BaseMetric(ABC):
     """The metric base class for computing metrics.
 
     The subclasses can either compute a single metric like 'accuracy', or compute the
     complex metrics for a specific task with or without other Metric subclasses.
     """
 
     def __init__(self, *args, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/bleu_metric.py` & `weathon-0.0.0.14/weathon/metrics/bleu_metric.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,22 +1,23 @@
 from itertools import zip_longest
 from typing import Dict
 
 import sacrebleu
 
-from modelscope.metainfo import Metrics
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
 
 EVAL_BLEU_ORDER = 4
 
 
 @METRICS.register_module(group_key=default_group, module_name=Metrics.BLEU)
-class BleuMetric(Metric):
+class BleuMetric(BaseMetric):
     """The metric computation bleu for text generation classes.
 
     This metric class calculates accuracy for the whole input batches.
     """
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/builder.py` & `weathon-0.0.0.14/weathon/utils/constants/metric_constant.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,9 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Dict, Mapping, Union
-
-from modelscope.metainfo import Metrics
-from modelscope.utils.config import ConfigDict
-from modelscope.utils.constant import Tasks
-from modelscope.utils.registry import Registry, build_from_cfg, default_group
-
-METRICS = Registry('metrics')
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Metrics
 
 
 class MetricKeys(object):
     ACCURACY = 'accuracy'
     F1 = 'f1'
     Binary_F1 = 'binary-f1'
     Macro_F1 = 'macro-f1'
@@ -75,25 +68,7 @@
     Tasks.image_quality_assessment_mos:
     [Metrics.image_quality_assessment_mos_metric],
     Tasks.bad_image_detecting: [Metrics.accuracy],
     Tasks.ocr_recognition: [Metrics.ocr_recognition_metric],
     Tasks.efficient_diffusion_tuning: [Metrics.loss_metric],
     Tasks.translation_evaluation: [Metrics.translation_evaluation_metric]
 }
-
-
-def build_metric(metric_cfg: Union[str, Dict],
-                 field: str = default_group,
-                 default_args: dict = None):
-    """ Build metric given metric_name and field.
-
-    Args:
-        metric_name (str | dict): The metric name or metric config dict.
-        field (str, optional):  The field of this metric, default value: 'default' for all fields.
-        default_args (dict, optional): Default initialization arguments.
-    """
-    if isinstance(metric_cfg, Mapping):
-        assert 'type' in metric_cfg
-    else:
-        metric_cfg = ConfigDict({'type': metric_cfg})
-    return build_from_cfg(
-        metric_cfg, METRICS, group_key=field, default_args=default_args)
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/ciderD/ciderD.py` & `weathon-0.0.0.14/weathon/metrics/ciderD/ciderD.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/ciderD/ciderD_scorer.py` & `weathon-0.0.0.14/weathon/metrics/ciderD/ciderD_scorer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/image_color_enhance_metric.py` & `weathon-0.0.0.14/weathon/metrics/image_color_enhance_metric.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,18 +2,26 @@
 # https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/metrics
 
 from typing import Dict
 
 import cv2
 import numpy as np
 
-from modelscope.metainfo import Metrics
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.metrics.video_super_resolution_metric.metric_util import _convert_input_type_range, \
+    _convert_output_type_range
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
+
+
+# from weathon.utils.registry import default_group
+# from .base import Metric
+# from .builder import METRICS, MetricKeys
 
 
 def bgr2ycbcr(img, y_only=False):
     """Convert a BGR image to YCbCr image.
 
     The bgr version of rgb2ycbcr.
     It implements the ITU-R BT.601 conversion for standard-definition
@@ -223,17 +231,16 @@
 
     ssims = []
     for i in range(img.shape[2]):
         ssims.append(_ssim(img[..., i], img2[..., i]))
     return np.array(ssims).mean()
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.image_color_enhance_metric)
-class ImageColorEnhanceMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.image_color_enhance_metric)
+class ImageColorEnhanceMetric(BaseMetric):
     """The metric computation class for image color enhance classes.
     """
 
     def __init__(self):
         self.preds = []
         self.targets = []
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/image_colorization_metric.py` & `weathon-0.0.0.14/weathon/metrics/image_colorization_metric.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,32 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Dict
 
-import cv2
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from scipy import linalg
 from torchvision import models
 
-from modelscope.metainfo import Metrics
-from modelscope.models.cv.image_inpainting.modules.inception import InceptionV3
-from modelscope.utils.registry import default_group
-from modelscope.utils.tensor_utils import (torch_nested_detach,
-                                           torch_nested_numpify)
-from .base import Metric
-from .builder import METRICS, MetricKeys
-from .image_denoise_metric import calculate_psnr
-from .image_inpainting_metric import FIDScore
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+# from weathon.utils.registry import default_group
+# from .base import Metric
+# from .builder import METRICS, MetricKeys
+# from .image_denoise_metric import calculate_psnr
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.image_colorization_metric)
-class ImageColorizationMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.image_colorization_metric)
+class ImageColorizationMetric(BaseMetric):
     """The metric computation class for image colorization.
     """
 
     def __init__(self):
         self.preds = []
         self.targets = []
         self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/image_denoise_metric.py` & `weathon-0.0.0.14/weathon/metrics/image_denoise_metric.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,27 +1,22 @@
-# ------------------------------------------------------------------------
-# Copyright (c) Alibaba, Inc. and its affiliates.
-# ------------------------------------------------------------------------
-# modified from https://github.com/megvii-research/NAFNet/blob/main/basicsr/metrics/psnr_ssim.py
-# ------------------------------------------------------------------------
 from typing import Dict
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Metrics
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.image_denoise_metric)
-class ImageDenoiseMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.image_denoise_metric)
+class ImageDenoiseMetric(BaseMetric):
     """The metric computation class for image denoise classes.
     """
     pred_name = 'pred'
     label_name = 'target'
 
     def __init__(self):
         super(ImageDenoiseMetric, self).__init__()
@@ -118,15 +113,15 @@
 
     if crop_border != 0:
         img1 = img1[crop_border:-crop_border, crop_border:-crop_border, ...]
         img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]
 
     def _psnr(img1, img2):
 
-        mse = np.mean((img1 - img2)**2)
+        mse = np.mean((img1 - img2) ** 2)
         if mse == 0:
             return float('inf')
         max_value = 1. if img1.max() <= 1 else 255.
         return 20. * np.log10(max_value / np.sqrt(mse))
 
     return _psnr(img1, img2)
 
@@ -197,30 +192,30 @@
     Args:
         img (ndarray): Images with range [0, 255] with order 'HWC'.
         img2 (ndarray): Images with range [0, 255] with order 'HWC'.
     Returns:
         float: SSIM result.
     """
 
-    c1 = (0.01 * max_value)**2
-    c2 = (0.03 * max_value)**2
+    c1 = (0.01 * max_value) ** 2
+    c2 = (0.03 * max_value) ** 2
 
     img = img.astype(np.float64)
     img2 = img2.astype(np.float64)
     kernel = cv2.getGaussianKernel(11, 1.5)
     window = np.outer(kernel, kernel.transpose())
 
     mu1 = cv2.filter2D(img, -1, window)[5:-5,
-                                        5:-5]  # valid mode for window size 11
+          5:-5]  # valid mode for window size 11
     mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]
-    mu1_sq = mu1**2
-    mu2_sq = mu2**2
+    mu1_sq = mu1 ** 2
+    mu2_sq = mu2 ** 2
     mu1_mu2 = mu1 * mu2
-    sigma1_sq = cv2.filter2D(img**2, -1, window)[5:-5, 5:-5] - mu1_sq
-    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq
+    sigma1_sq = cv2.filter2D(img ** 2, -1, window)[5:-5, 5:-5] - mu1_sq
+    sigma2_sq = cv2.filter2D(img2 ** 2, -1, window)[5:-5, 5:-5] - mu2_sq
     sigma12 = cv2.filter2D(img * img2, -1, window)[5:-5, 5:-5] - mu1_mu2
 
     tmp1 = (2 * mu1_mu2 + c1) * (2 * sigma12 + c2)
     tmp2 = (mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2)
     ssim_map = tmp1 / tmp2
     return ssim_map.mean()
 
@@ -253,31 +248,31 @@
     It is called by func:`calculate_ssim`.
     Args:
         img1 (ndarray): Images with range [0, 255]/[0, 1] with order 'HWC'.
         img2 (ndarray): Images with range [0, 255]/[0, 1] with order 'HWC'.
     Returns:
         float: ssim result.
     """
-    C1 = (0.01 * max_value)**2
-    C2 = (0.03 * max_value)**2
+    C1 = (0.01 * max_value) ** 2
+    C2 = (0.03 * max_value) ** 2
     img1 = img1.astype(np.float64)
     img2 = img2.astype(np.float64)
 
     kernel = _generate_3d_gaussian_kernel().cuda()
 
     img1 = torch.tensor(img1).float().cuda()
     img2 = torch.tensor(img2).float().cuda()
 
     mu1 = _3d_gaussian_calculator(img1, kernel)
     mu2 = _3d_gaussian_calculator(img2, kernel)
 
-    mu1_sq = mu1**2
-    mu2_sq = mu2**2
+    mu1_sq = mu1 ** 2
+    mu2_sq = mu2 ** 2
     mu1_mu2 = mu1 * mu2
-    sigma1_sq = _3d_gaussian_calculator(img1**2, kernel) - mu1_sq
-    sigma2_sq = _3d_gaussian_calculator(img2**2, kernel) - mu2_sq
+    sigma1_sq = _3d_gaussian_calculator(img1 ** 2, kernel) - mu1_sq
+    sigma2_sq = _3d_gaussian_calculator(img2 ** 2, kernel) - mu2_sq
     sigma12 = _3d_gaussian_calculator(img1 * img2, kernel) - mu1_mu2
 
     tmp1 = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)
     tmp2 = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)
     ssim_map = tmp1 / tmp2
     return float(ssim_map.mean())
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/image_inpainting_metric.py` & `weathon-0.0.0.14/weathon/metrics/image_inpainting_metric.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,21 +5,22 @@
 from typing import Dict
 
 import numpy as np
 import torch
 import torch.nn.functional as F
 from scipy import linalg
 
-from modelscope.metainfo import Metrics
-from modelscope.models.cv.image_inpainting.modules.inception import InceptionV3
-from modelscope.utils.registry import default_group
-from modelscope.utils.tensor_utils import (torch_nested_detach,
-                                           torch_nested_numpify)
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.models.cv.image_inpainting.modules.inception import InceptionV3
+from weathon.utils.constants.metric_constant import MetricKeys
+from weathon.utils.tensor_utils import (torch_nested_detach,torch_nested_numpify)
+
 
 
 def fid_calculate_activation_statistics(act):
     mu = np.mean(act, axis=0)
     sigma = np.cov(act, rowvar=False)
     return mu, sigma
 
@@ -177,17 +178,16 @@
         return ssim_map.mean(1).mean(1).mean(1)
 
     def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,
                               missing_keys, unexpected_keys, error_msgs):
         return
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.image_inpainting_metric)
-class ImageInpaintingMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.image_inpainting_metric)
+class ImageInpaintingMetric(BaseMetric):
     """The metric computation class for image inpainting classes.
     """
 
     def __init__(self):
         self.preds = []
         self.targets = []
         self.SSIM = SSIM(window_size=11, size_average=False).eval()
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/image_instance_segmentation_metric.py` & `weathon-0.0.0.14/weathon/metrics/image_instance_segmentation_metric.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,23 +6,23 @@
 from typing import Any, Dict
 
 import numpy as np
 import pycocotools.mask as mask_util
 from pycocotools.coco import COCO
 from pycocotools.cocoeval import COCOeval
 
-from modelscope.fileio import dump, load
-from modelscope.metainfo import Metrics
-from modelscope.metrics import METRICS, Metric
-from modelscope.utils.registry import default_group
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.fileio import dump
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.image_ins_seg_coco_metric)
-class ImageInstanceSegmentationCOCOMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.image_ins_seg_coco_metric)
+class ImageInstanceSegmentationCOCOMetric(BaseMetric):
     """The metric computation class for COCO-style image instance segmentation.
     """
 
     def __init__(self):
         self.ann_file = None
         self.classes = None
         self.metrics = ['bbox', 'segm']
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/image_portrait_enhancement_metric.py` & `weathon-0.0.0.14/weathon/metrics/image_portrait_enhancement_metric.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,19 @@
 # Part of the implementation is borrowed and modified from BasicSR, publicly available at
 # https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/metrics/psnr_ssim.py
 from typing import Dict
 
 import cv2
 import numpy as np
 
-from modelscope.metainfo import Metrics
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
 
 
 def calculate_psnr(img, img2):
     assert img.shape == img2.shape, (
         f'Image shapes are different: {img.shape}, {img2.shape}.')
 
     img = img.astype(np.float64)
@@ -20,18 +21,16 @@
 
     mse = np.mean((img - img2)**2)
     if mse == 0:
         return float('inf')
     return 10. * np.log10(255. * 255. / mse)
 
 
-@METRICS.register_module(
-    group_key=default_group,
-    module_name=Metrics.image_portrait_enhancement_metric)
-class ImagePortraitEnhancementMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.image_portrait_enhancement_metric)
+class ImagePortraitEnhancementMetric(BaseMetric):
     """The metric for image-portrait-enhancement task.
     """
 
     def __init__(self):
         self.preds = []
         self.targets = []
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/image_quality_assessment_degradation_metric.py` & `weathon-0.0.0.14/weathon/metrics/image_quality_assessment_degradation_metric.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,31 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import sys
 import tempfile
 from collections import defaultdict
 from typing import Dict
 
 import cv2
 import numpy as np
 import torch
+from datasets import Metric
 from scipy.stats import pearsonr, spearmanr
 from tqdm import tqdm
 
-from modelscope.metainfo import Metrics
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
 
 
-@METRICS.register_module(
-    group_key=default_group,
-    module_name=Metrics.image_quality_assessment_degradation_metric)
-class ImageQualityAssessmentDegradationMetric(Metric):
+@METRICS.register_module(group_key=default_group,module_name=Metrics.image_quality_assessment_degradation_metric)
+class ImageQualityAssessmentDegradationMetric(BaseMetric):
     """The metric for image-quality-assessment-degradation task.
     """
 
     def __init__(self):
         self.inputs = defaultdict(list)
         self.outputs = defaultdict(list)
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/image_quality_assessment_mos_metric.py` & `weathon-0.0.0.14/weathon/metrics/image_quality_assessment_mos_metric.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,30 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import sys
 import tempfile
 from typing import Dict
 
 import cv2
 import numpy as np
 import torch
 from scipy.stats import pearsonr, spearmanr
 from tqdm import tqdm
 
-from modelscope.metainfo import Metrics
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+
 
 
-@METRICS.register_module(
-    group_key=default_group,
-    module_name=Metrics.image_quality_assessment_mos_metric)
-class ImageQualityAssessmentMosMetric(Metric):
+@METRICS.register_module(group_key=default_group,module_name=Metrics.image_quality_assessment_mos_metric)
+class ImageQualityAssessmentMosMetric(BaseMetric):
     """The metric for image-quality-assessment-mos task.
     """
 
     def __init__(self):
         self.inputs = []
         self.outputs = []
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/inbatch_recall_metric.py` & `weathon-0.0.0.14/weathon/metrics/inbatch_recall_metric.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,24 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Metrics
-from modelscope.outputs import OutputKeys
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.output_constant import OutputKeys
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.inbatch_recall)
-class InbatchRecallMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.inbatch_recall)
+class InbatchRecallMetric(BaseMetric):
     """The metric computation class for in-batch retrieval classes.
 
     This metric class calculates in-batch image recall@1 for each input batch.
     """
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/map_metric.py` & `weathon-0.0.0.14/weathon/metrics/map_metric.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict
 
 import numpy as np
 
-from modelscope.metainfo import Metrics
-from modelscope.outputs import OutputKeys
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
+from weathon.utils.constants.output_constant import OutputKeys
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.multi_average_precision)
-class AveragePrecisionMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.multi_average_precision)
+class AveragePrecisionMetric(BaseMetric):
     """The metric computation class for multi average precision classes.
 
     This metric class calculates multi average precision for the whole input batches.
     """
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/ned_metric.py` & `weathon-0.0.0.14/weathon/metrics/accuracy_metric.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,98 +1,68 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict
 
 import numpy as np
 
-from modelscope.metainfo import Metrics
-from modelscope.outputs import OutputKeys
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.chinese_utils import remove_space_between_chinese_chars
+from weathon.utils.constants.metric_constant import MetricKeys
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.tensor_utils import torch_nested_numpify
 
 
-@METRICS.register_module(group_key=default_group, module_name=Metrics.NED)
-class NedMetric(Metric):
-    """The ned metric computation class for classification classes.
+@METRICS.register_module(group_key=default_group, module_name=Metrics.accuracy)
+class AccuracyMetric(BaseMetric):
+    """The metric computation class for classification classes.
 
-    This metric class calculates the levenshtein distance between sentences for the whole input batches.
+    This metric class calculates accuracy for the whole input batches.
     """
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.preds = []
         self.labels = []
 
     def add(self, outputs: Dict, inputs: Dict):
         label_name = OutputKeys.LABEL if OutputKeys.LABEL in inputs else OutputKeys.LABELS
         ground_truths = inputs[label_name]
-        eval_results = outputs[label_name]
+        eval_results = None
         for key in [
                 OutputKeys.CAPTION, OutputKeys.TEXT, OutputKeys.BOXES,
-                OutputKeys.LABELS, OutputKeys.SCORES
+                OutputKeys.LABEL, OutputKeys.LABELS, OutputKeys.SCORES
         ]:
             if key in outputs and outputs[key] is not None:
                 eval_results = outputs[key]
                 break
         assert type(ground_truths) == type(eval_results)
-        if isinstance(ground_truths, list):
-            self.preds.extend(eval_results)
-            self.labels.extend(ground_truths)
-        elif isinstance(ground_truths, np.ndarray):
-            self.preds.extend(eval_results.tolist())
-            self.labels.extend(ground_truths.tolist())
-        else:
-            raise Exception('only support list or np.ndarray')
+        ground_truths = torch_nested_numpify(ground_truths)
+        for truth in ground_truths:
+            self.labels.append(truth)
+        eval_results = torch_nested_numpify(eval_results)
+        for result in eval_results:
+            if isinstance(truth, str):
+                if isinstance(result, list):
+                    result = result[0]
+                assert isinstance(result, str), 'both truth and pred are str'
+                self.preds.append(remove_space_between_chinese_chars(result))
+            else:
+                self.preds.append(result)
 
     def evaluate(self):
         assert len(self.preds) == len(self.labels)
-        return {
-            MetricKeys.NED: (np.asarray([
-                1.0 - NedMetric._distance(pred, ref)
-                for pred, ref in zip(self.preds, self.labels)
+        return {MetricKeys.ACCURACY: (np.asarray([
+                pred == ref for pred, ref in zip(self.preds, self.labels)
             ])).mean().item()
         }
 
-    def merge(self, other: 'NedMetric'):
+    def merge(self, other: 'AccuracyMetric'):
         self.preds.extend(other.preds)
         self.labels.extend(other.labels)
 
     def __getstate__(self):
         return self.preds, self.labels
 
     def __setstate__(self, state):
         self.__init__()
         self.preds, self.labels = state
-
-    @staticmethod
-    def _distance(pred, ref):
-        if pred is None or ref is None:
-            raise TypeError('Argument (pred or ref) is NoneType.')
-        if pred == ref:
-            return 0.0
-        if len(pred) == 0:
-            return len(ref)
-        if len(ref) == 0:
-            return len(pred)
-        m_len = max(len(pred), len(ref))
-        if m_len == 0:
-            return 0.0
-
-        def levenshtein(s0, s1):
-            v0 = [0] * (len(s1) + 1)
-            v1 = [0] * (len(s1) + 1)
-
-            for i in range(len(v0)):
-                v0[i] = i
-
-            for i in range(len(s0)):
-                v1[0] = i + 1
-                for j in range(len(s1)):
-                    cost = 1
-                    if s0[i] == s1[j]:
-                        cost = 0
-                    v1[j + 1] = min(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost)
-                v0, v1 = v1, v0
-            return v0[len(s1)]
-
-        return levenshtein(pred, ref) / m_len
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/ocr_recognition_metric.py` & `weathon-0.0.0.14/weathon/metrics/ocr_recognition_metric.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,18 +1,24 @@
 from typing import Dict
 
 import edit_distance as ed
 import numpy as np
 import torch
 import torch.nn.functional as F
+from datasets import Metric
 
-from modelscope.metainfo import Metrics
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
+
+
+# from weathon.utils.registry import default_group
+# from .base import Metric
+# from .builder import METRICS, MetricKeys
 
 
 def cal_distance(label_list, pre_list):
     y = ed.SequenceMatcher(a=label_list, b=pre_list)
     yy = y.get_opcodes()
     insert = 0
     delete = 0
@@ -24,17 +30,16 @@
             delete += item[2] - item[1]
         if item[0] == 'replace':
             replace += item[-1] - item[-2]
     distance = insert + delete + replace
     return distance, (delete, replace, insert)
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.ocr_recognition_metric)
-class OCRRecognitionMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.ocr_recognition_metric)
+class OCRRecognitionMetric(BaseMetric):
     """The metric computation class for ocr recognition.
     """
 
     def __init__(self, *args, **kwargs):
         self.preds = []
         self.targets = []
         self.loss_sum = 0.
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/prediction_saving_wrapper.py` & `weathon-0.0.0.14/weathon/metrics/prediction_saving_wrapper.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,26 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict
 
 import numpy as np
 from sklearn.metrics import accuracy_score, f1_score
 
-from modelscope.metainfo import Metrics
-from modelscope.outputs import OutputKeys
-from modelscope.utils.registry import default_group
-from modelscope.utils.tensor_utils import (torch_nested_detach,
-                                           torch_nested_numpify)
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.prediction_saving_wrapper)
-class PredictionSavingWrapper(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.prediction_saving_wrapper)
+class PredictionSavingWrapper(BaseMetric):
     """The wrapper to save predictions to file.
     Args:
         saving_fn: The saving_fn used to save predictions to files.
     """
 
     def __init__(self, saving_fn, **kwargs):
         super().__init__(**kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/referring_video_object_segmentation_metric.py` & `weathon-0.0.0.14/weathon/metrics/referring_video_object_segmentation_metric.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,27 @@
 # Part of the implementation is borrowed and modified from MTTR,
 # publicly available at https://github.com/mttr2021/MTTR
 from typing import Dict
 
 import numpy as np
 import torch
+from datasets import Metric
 from pycocotools.coco import COCO
 from pycocotools.cocoeval import COCOeval
 from pycocotools.mask import decode
 from tqdm import tqdm
 
-from modelscope.metainfo import Metrics
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
 
 
-@METRICS.register_module(
-    group_key=default_group,
-    module_name=Metrics.referring_video_object_segmentation_metric)
-class ReferringVideoObjectSegmentationMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.referring_video_object_segmentation_metric)
+class ReferringVideoObjectSegmentationMetric(BaseMetric):
     """The metric computation class for movie scene segmentation classes.
     """
 
     def __init__(self,
                  ann_file=None,
                  calculate_precision_and_iou_metrics=True):
         self.ann_file = ann_file
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/sequence_classification_metric.py` & `weathon-0.0.0.14/weathon/metrics/sequence_classification_metric.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,26 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict
 
 import numpy as np
 from sklearn.metrics import accuracy_score, f1_score
 
-from modelscope.metainfo import Metrics
-from modelscope.outputs import OutputKeys
-from modelscope.utils.registry import default_group
-from modelscope.utils.tensor_utils import (torch_nested_detach,
-                                           torch_nested_numpify)
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.tensor_utils import torch_nested_detach, torch_nested_numpify
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.seq_cls_metric)
-class SequenceClassificationMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.seq_cls_metric)
+class SequenceClassificationMetric(BaseMetric):
     """The metric computation class for sequence classification tasks.
 
     This metric class calculates accuracy/F1 of all the input batches.
 
     Args:
         label_name: The key of label column in the 'inputs' arg.
         logit_name: The key of logits column in the 'inputs' arg.
@@ -51,27 +48,27 @@
         assert len(preds.shape) == 2, 'Only support predictions with shape: (batch_size, num_labels),' \
                                       'multi-label classification is not supported in this metric class.'
         preds_max = np.argmax(preds, axis=1)
         if preds.shape[1] > 2:
             metrics = {
                 MetricKeys.ACCURACY: accuracy_score(labels, preds_max),
                 MetricKeys.Micro_F1:
-                f1_score(labels, preds_max, average='micro'),
+                    f1_score(labels, preds_max, average='micro'),
                 MetricKeys.Macro_F1:
-                f1_score(labels, preds_max, average='macro'),
+                    f1_score(labels, preds_max, average='macro'),
             }
 
             metrics[MetricKeys.F1] = metrics[MetricKeys.Micro_F1]
             return metrics
         else:
             metrics = {
                 MetricKeys.ACCURACY:
-                accuracy_score(labels, preds_max),
+                    accuracy_score(labels, preds_max),
                 MetricKeys.Binary_F1:
-                f1_score(labels, preds_max, average='binary'),
+                    f1_score(labels, preds_max, average='binary'),
             }
             metrics[MetricKeys.F1] = metrics[MetricKeys.Binary_F1]
             return metrics
 
     def merge(self, other: 'SequenceClassificationMetric'):
         self.preds.extend(other.preds)
         self.labels.extend(other.labels)
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/text_generation_metric.py` & `weathon-0.0.0.14/weathon/metrics/text_generation_metric.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict, Iterable, List
 
+from datasets import Metric
 from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu
 from rouge import Rouge
 
-from modelscope.metainfo import Metrics
-from modelscope.metrics.base import Metric
-from modelscope.metrics.builder import METRICS, MetricKeys
-from modelscope.utils.chinese_utils import rebuild_chinese_str
-from modelscope.utils.registry import default_group
-
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.chinese_utils import rebuild_chinese_str
+from weathon.utils.constants.metric_constant import MetricKeys
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.text_gen_metric)
+@METRICS.register_module(group_key=default_group, module_name=Metrics.text_gen_metric)
 class TextGenerationMetric(Metric):
     """The metric computation class for text generation classes.
 
     This metric class calculates F1 of the rouge scores for the whole evaluation dataset.
 
     Args:
         target_text: The key of the target text column in the `inputs` arg.
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/text_ranking_metric.py` & `weathon-0.0.0.14/weathon/metrics/text_ranking_metric.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,22 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict, List
 
 import numpy as np
+from datasets import Metric
+
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
+
 
-from modelscope.metainfo import Metrics
-from modelscope.metrics.base import Metric
-from modelscope.metrics.builder import METRICS, MetricKeys
-from modelscope.utils.registry import default_group
+# from weathon.metrics.base import Metric
+# from weathon.metrics.builder import METRICS, MetricKeys
+# from weathon.utils.registry import default_group
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.text_ranking_metric)
-class TextRankingMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.text_ranking_metric)
+class TextRankingMetric(BaseMetric):
     """The metric computation class for text ranking classes.
 
     This metric class calculates mrr and ndcg metric for the whole evaluation dataset.
 
     Args:
         target_text: The key of the target text column in the `inputs` arg.
         pred_text: The key of the predicted text column in the `outputs` arg.
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/token_classification_metric.py` & `weathon-0.0.0.14/weathon/metrics/token_classification_metric.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import importlib
 from typing import Dict, List, Optional, Union
 
 import numpy as np
+from datasets import Metric
 
-from modelscope.outputs import OutputKeys
-from ..metainfo import Metrics
-from ..utils.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from ..base import BaseMetric
+from ..registry import METRICS
+from ..registry.registry import default_group
+from ..utils.constants.metric_constant import MetricKeys
+from ..utils.constants.output_constant import OutputKeys
 from ..utils.tensor_utils import torch_nested_detach, torch_nested_numpify
-from .base import Metric
-from .builder import METRICS, MetricKeys
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.token_cls_metric)
-class TokenClassificationMetric(Metric):
+
+@METRICS.register_module(group_key=default_group, module_name=Metrics.token_cls_metric)
+class TokenClassificationMetric(BaseMetric):
     """The metric computation class for token-classification task.
 
     This metric class uses seqeval to calculate the scores.
 
     Args:
         label_name(str, `optional`): The key of label column in the 'inputs' arg.
         logit_name(str, `optional`): The key of logits column in the 'inputs' arg.
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/translation_evaluation_metric.py` & `weathon-0.0.0.14/weathon/metrics/translation_evaluation_metric.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,26 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import importlib
 from typing import Dict, List, Union
 
+from datasets import Metric
 from pandas import DataFrame
 
-from modelscope.metainfo import Metrics
-from modelscope.metrics.base import Metric
-from modelscope.metrics.builder import METRICS, MetricKeys
-from modelscope.models.nlp.unite.configuration import InputFormat
-from modelscope.utils.logger import get_logger
-from modelscope.utils.registry import default_group
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.logger import get_logger
+# from weathon.utils.registry import default_group
+# from weathon.metrics.base import Metric
+# from weathon.metrics.builder import METRICS, MetricKeys
 
 logger = get_logger()
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.translation_evaluation_metric)
+@METRICS.register_module(group_key=default_group, module_name=Metrics.translation_evaluation_metric)
 class TranslationEvaluationMetric(Metric):
     r"""The metric class for translation evaluation.
 
     """
 
     def __init__(self, gap_threshold: float = 25.0):
         r"""Build a translation evaluation metric, following the designed
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/video_frame_interpolation_metric.py` & `weathon-0.0.0.14/weathon/metrics/video_frame_interpolation_metric.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,29 +1,31 @@
-# ------------------------------------------------------------------------
-# Copyright (c) Alibaba, Inc. and its affiliates.
-# ------------------------------------------------------------------------
 import math
 from math import exp
 from typing import Dict
 
 import lpips
 import numpy as np
 import torch
 import torch.nn.functional as F
+from datasets import Metric
 
-from modelscope.metainfo import Metrics
-from modelscope.metrics.base import Metric
-from modelscope.metrics.builder import METRICS, MetricKeys
-from modelscope.utils.registry import default_group
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.utils.constants.metric_constant import MetricKeys
 
 
-@METRICS.register_module(
-    group_key=default_group,
-    module_name=Metrics.video_frame_interpolation_metric)
-class VideoFrameInterpolationMetric(Metric):
+# from weathon.metrics.base import Metric
+# from weathon.metrics.builder import METRICS, MetricKeys
+# from weathon.utils.registry import default_group
+
+
+@METRICS.register_module(group_key=default_group, module_name=Metrics.video_frame_interpolation_metric)
+class VideoFrameInterpolationMetric(BaseMetric):
     """The metric computation class for video frame interpolation,
     which will return PSNR, SSIM and LPIPS.
     """
     pred_name = 'pred'
     label_name = 'target'
 
     def __init__(self):
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/video_stabilization_metric.py` & `weathon-0.0.0.14/weathon/metrics/video_stabilization_metric.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,30 +1,33 @@
 # Part of the implementation is borrowed and modified from DIFRINT,
 # publicly available at https://github.com/jinsc37/DIFRINT/blob/master/metrics.py
 
-import os
-import sys
 import tempfile
 from typing import Dict
 
 import cv2
 import numpy as np
 from tqdm import tqdm
 
-from modelscope.metainfo import Metrics
-from modelscope.models.cv.video_stabilization.utils.WarpUtils import \
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.models.cv.video_stabilization.utils.WarpUtils import \
     warpListImage
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.utils.constants.metric_constant import MetricKeys
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.video_stabilization_metric)
-class VideoStabilizationMetric(Metric):
+# from weathon.utils.registry import default_group
+# from .base import Metric
+# from .builder import METRICS, MetricKeys
+
+
+@METRICS.register_module(group_key=default_group, module_name=Metrics.video_stabilization_metric)
+class VideoStabilizationMetric(BaseMetric):
     """The metric for video summarization task.
     """
 
     def __init__(self):
         self.inputs = []
         self.outputs = []
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/video_summarization_metric.py` & `weathon-0.0.0.14/weathon/metrics/video_summarization_metric.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,20 +1,22 @@
 # Part of the implementation is borrowed and modified from PGL-SUM,
 # publicly available at https://github.com/e-apostolidis/PGL-SUM
 
 from typing import Dict
 
 import numpy as np
 
-from modelscope.metainfo import Metrics
-from modelscope.models.cv.video_summarization.summarizer import \
-    generate_summary
-from modelscope.utils.registry import default_group
-from .base import Metric
-from .builder import METRICS, MetricKeys
+from weathon.base import BaseMetric
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.models.cv.video_summarization.summarizer import generate_summary
+# from weathon.utils.registry import default_group
+# from .base import Metric
+# from .builder import METRICS, MetricKeys
 
 
 def evaluate_summary(predicted_summary, user_summary, eval_method):
     """ Compare the predicted summary with the user defined one(s).
 
     :param ndarray predicted_summary: The generated summary from our model.
     :param ndarray user_summary: The user defined ground truth summaries (or summary).
@@ -54,17 +56,16 @@
     n_frames = inputs['n_frames'].cpu().numpy()[0]
     positions = inputs['positions'].cpu().numpy()[0]
     summary = generate_summary([sb], [scores], [n_frames], [positions])[0]
     f_score = evaluate_summary(summary, user_summary, 'avg')
     return f_score
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.video_summarization_metric)
-class VideoSummarizationMetric(Metric):
+@METRICS.register_module(group_key=default_group, module_name=Metrics.video_summarization_metric)
+class VideoSummarizationMetric(BaseMetric):
     """The metric for video summarization task.
     """
 
     def __init__(self):
         self.inputs = []
         self.outputs = []
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/matlab_functions.py` & `weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/matlab_functions.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/metric_util.py` & `weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/metric_util.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/niqe.py` & `weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/niqe.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,23 +5,19 @@
 import math
 
 import cv2
 import numpy as np
 from scipy.ndimage import convolve
 from scipy.special import gamma
 
-from modelscope.hub.file_download import model_file_download
-from modelscope.metrics.video_super_resolution_metric.matlab_functions import \
-    imresize
-from modelscope.metrics.video_super_resolution_metric.metric_util import (
-    reorder_image, to_y_channel)
+from weathon.metrics.video_super_resolution_metric.matlab_functions import imresize
+from weathon.metrics.video_super_resolution_metric.metric_util import (reorder_image, to_y_channel)
+from weathon.utils.hub.file_download import model_file_download
 
-downloaded_file_path = model_file_download(
-    model_id='damo/cv_realbasicvsr_video-super-resolution_videolq',
-    file_path='niqe_pris_params.npz')
+downloaded_file_path = model_file_download(model_id='damo/cv_realbasicvsr_video-super-resolution_videolq',file_path='niqe_pris_params.npz')
 
 
 def estimate_aggd_param(block):
     """Estimate AGGD (Asymmetric Generalized Gaussian Distribution) parameters.
     Args:
         block (ndarray): 2D Image block.
     Returns:
```

### Comparing `weathon-0.0.0.13/weathon/dl/metrics/video_super_resolution_metric/video_super_resolution_metric.py` & `weathon-0.0.0.14/weathon/metrics/video_super_resolution_metric/video_super_resolution_metric.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,22 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Dict
 
 import numpy as np
+from datasets import Metric
 
-from modelscope.metainfo import Metrics
-from modelscope.metrics.base import Metric
-from modelscope.metrics.builder import METRICS, MetricKeys
-from modelscope.metrics.video_super_resolution_metric.niqe import \
-    calculate_niqe
-from modelscope.utils.registry import default_group
+from weathon.registry import METRICS
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Metrics
+from weathon.metrics.video_super_resolution_metric.niqe import calculate_niqe
+from weathon.utils.constants.metric_constant import MetricKeys
 
 
-@METRICS.register_module(
-    group_key=default_group, module_name=Metrics.video_super_resolution_metric)
+@METRICS.register_module(group_key=default_group, module_name=Metrics.video_super_resolution_metric)
 class VideoSuperResolutionMetric(Metric):
     """The metric computation class for real-world video super-resolution classes.
     """
     pred_name = 'pred'
 
     def __init__(self):
         super(VideoSuperResolutionMetric, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/activations.py` & `weathon-0.0.0.14/weathon/models/audio/aec/layers/activations.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch.nn as nn
 
 from .layer_base import LayerBase
 
 
 class RectifiedLinear(LayerBase):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/affine_transform.py` & `weathon-0.0.0.14/weathon/models/audio/aec/layers/affine_transform.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch as th
 import torch.nn as nn
 
 from .layer_base import (LayerBase, expect_kaldi_matrix, expect_token_number,
                          to_kaldi_matrix)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/deep_fsmn.py` & `weathon-0.0.0.14/weathon/models/audio/aec/layers/deep_fsmn.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch as th
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .layer_base import (LayerBase, expect_kaldi_matrix, expect_token_number,
                          to_kaldi_matrix)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/layer_base.py` & `weathon-0.0.0.14/weathon/models/audio/aec/layers/layer_base.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import abc
 import re
 
 import numpy as np
 import torch.nn as nn
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/aec/layers/uni_deep_fsmn.py` & `weathon-0.0.0.14/weathon/models/audio/aec/layers/uni_deep_fsmn.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch as th
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .layer_base import (LayerBase, expect_kaldi_matrix, expect_token_number,
                          to_kaldi_matrix)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/aec/network/loss.py` & `weathon-0.0.0.14/weathon/models/audio/aec/network/loss.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn.functional as F
 
 from .modulation_loss import (GaborSTRFConv, MelScale,
                               ModulationDomainLossModule)
 
 EPS = 1e-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/aec/network/modulation_loss.py` & `weathon-0.0.0.14/weathon/models/audio/aec/network/modulation_loss.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torchaudio.transforms import MelScale
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/aec/network/se_net.py` & `weathon-0.0.0.14/weathon/models/audio/aec/network/se_net.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.audio.aec.layers.activations import (RectifiedLinear,
+from weathon.models.audio.aec.layers.activations import (RectifiedLinear,
                                                             Sigmoid)
-from modelscope.models.audio.aec.layers.affine_transform import AffineTransform
-from modelscope.models.audio.aec.layers.deep_fsmn import DeepFsmn
-from modelscope.models.audio.aec.layers.uni_deep_fsmn import (Conv2d,
+from weathon.models.audio.aec.layers.affine_transform import AffineTransform
+from weathon.models.audio.aec.layers.deep_fsmn import DeepFsmn
+from weathon.models.audio.aec.layers.uni_deep_fsmn import (Conv2d,
                                                               UniDeepFsmn)
 
 
 class MaskNet(nn.Module):
 
     def __init__(self,
                  indim,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/data/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,23 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .frcrn import FRCRNDecorator
+    from .transforms import PadToSquare
 
 else:
     _import_structure = {
-        'frcrn': ['FRCRNDecorator'],
-        'dnoise_net': ['DenoiseNet'],
+        'transforms': ['PadToSquare'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
         module_spec=__spec__,
         extra_objects={},
     )
+
+# from .transforms import *  # noqa F403
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/complex_nn.py` & `weathon-0.0.0.14/weathon/models/audio/ans/complex_nn.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 #
 # The implementation of class ComplexConv2d, ComplexConvTranspose2d and
 # ComplexBatchNorm2d here is modified based on Jongho Choi(sweetcocoa@snu.ac.kr
 # / Seoul National Univ., ESTsoft ) and publicly available at
 # https://github.com/sweetcocoa/DeepComplexUNetPyTorch
 
 import torch
 import torch.nn as nn
 
-from modelscope.models.audio.ans.layers.uni_deep_fsmn import UniDeepFsmn
+from weathon.models.audio.ans.layers.uni_deep_fsmn import UniDeepFsmn
 
 
 class ComplexUniDeepFsmn(nn.Module):
 
     def __init__(self, nIn, nHidden=128, nOut=128):
         super(ComplexUniDeepFsmn, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/conv_stft.py` & `weathon-0.0.0.14/weathon/models/audio/ans/conv_stft.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from scipy.signal import get_window
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/frcrn.py` & `weathon-0.0.0.14/weathon/models/audio/ans/frcrn.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,40 +1,36 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Dict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
 from .conv_stft import ConviSTFT, ConvSTFT
 from .unet import UNet
 
 
-@MODELS.register_module(
-    Tasks.acoustic_noise_suppression,
-    module_name=Models.speech_frcrn_ans_cirm_16k)
+@MODELS.register_module(Tasks.acoustic_noise_suppression, module_name=Models.speech_frcrn_ans_cirm_16k)
 class FRCRNDecorator(TorchModel):
     r""" A decorator of FRCRN for integrating into modelscope framework """
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the frcrn model from the `model_dir` path.
 
         Args:
             model_dir (str): the model path.
         """
         super().__init__(model_dir, *args, **kwargs)
         self.model = FRCRN(*args, **kwargs)
-        model_bin_file = os.path.join(model_dir,
-                                      ModelFile.TORCH_MODEL_BIN_FILE)
+        model_bin_file = os.path.join(model_dir, ModelFile.TORCH_MODEL_BIN_FILE)
         if os.path.exists(model_bin_file):
             checkpoint = torch.load(
                 model_bin_file, map_location=torch.device('cpu'))
             if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                 # the new trained model by user is based on FRCRNDecorator
                 self.load_state_dict(checkpoint['state_dict'])
             else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/activations.py` & `weathon-0.0.0.14/weathon/models/audio/ans/layers/activations.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,12 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch.nn as nn
 
-from modelscope.models.audio.ans.layers.layer_base import LayerBase
+from weathon.models.audio.ans.layers.layer_base import LayerBase
 
 
 class RectifiedLinear(LayerBase):
 
     def __init__(self, input_dim, output_dim):
         super(RectifiedLinear, self).__init__()
         self.dim = input_dim
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/affine_transform.py` & `weathon-0.0.0.14/weathon/models/audio/ans/layers/affine_transform.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch as th
 import torch.nn as nn
 
-from modelscope.models.audio.ans.layers.layer_base import (LayerBase,
+from weathon.models.audio.ans.layers.layer_base import (LayerBase,
                                                            to_kaldi_matrix)
-from modelscope.utils.audio.audio_utils import (expect_kaldi_matrix,
+from weathon.utils.audio.audio_utils import (expect_kaldi_matrix,
                                                 expect_token_number)
 
 
 class AffineTransform(LayerBase):
 
     def __init__(self, input_dim, output_dim):
         super(AffineTransform, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/layers/uni_deep_fsmn.py` & `weathon-0.0.0.14/weathon/models/audio/ans/layers/uni_deep_fsmn.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.audio.ans.layers.layer_base import (LayerBase,
+from weathon.models.audio.ans.layers.layer_base import (LayerBase,
                                                            to_kaldi_matrix)
-from modelscope.utils.audio.audio_utils import (expect_kaldi_matrix,
+from weathon.utils.audio.audio_utils import (expect_kaldi_matrix,
                                                 expect_token_number)
 
 
 class UniDeepFsmn(LayerBase):
 
     def __init__(self, input_dim, output_dim, lorder=1, hidden_size=None):
         super(UniDeepFsmn, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/se_module_complex.py` & `weathon-0.0.0.14/weathon/models/audio/ans/se_module_complex.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 from torch import nn
 
 
 class SELayer(nn.Module):
 
     def __init__(self, channel, reduction=16):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/ans/unet.py` & `weathon-0.0.0.14/weathon/models/audio/ans/unet.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 #
 # The implementation here is modified based on
 # Jongho Choi(sweetcocoa@snu.ac.kr / Seoul National Univ., ESTsoft )
 # and publicly available at
 # https://github.com/sweetcocoa/DeepComplexUNetPyTorch
 
 import torch
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/asr/__init__.py` & `weathon-0.0.0.14/weathon/models/audio/asr/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .generic_automatic_speech_recognition import GenericAutomaticSpeechRecognition
 
 else:
     _import_structure = {
         'generic_automatic_speech_recognition':
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/asr/generic_automatic_speech_recognition.py` & `weathon-0.0.0.14/weathon/models/audio/asr/generic_automatic_speech_recognition.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Frameworks, Tasks
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+# from weathon.base import BaseModel
+# from weathon.registry import MODELS
+# from weathon.utils.constant import Frameworks, Tasks
 
 __all__ = ['GenericAutomaticSpeechRecognition']
 
 
-@MODELS.register_module(
-    Tasks.auto_speech_recognition, module_name=Models.generic_asr)
-@MODELS.register_module(
-    Tasks.voice_activity_detection, module_name=Models.generic_asr)
-@MODELS.register_module(
-    Tasks.language_score_prediction, module_name=Models.generic_asr)
+@MODELS.register_module(Tasks.auto_speech_recognition, module_name=Models.generic_asr)
+@MODELS.register_module(Tasks.voice_activity_detection, module_name=Models.generic_asr)
+@MODELS.register_module(Tasks.language_score_prediction, module_name=Models.generic_asr)
 @MODELS.register_module(Tasks.speech_timestamp, module_name=Models.generic_asr)
-class GenericAutomaticSpeechRecognition(Model):
+class GenericAutomaticSpeechRecognition(BaseModel):
 
     def __init__(self, model_dir: str, am_model_name: str,
                  model_config: Dict[str, Any], *args, **kwargs):
         """initialize the info of model.
 
         Args:
             model_dir (str): the model path.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/asr/wenet_automatic_speech_recognition.py` & `weathon-0.0.0.14/weathon/models/audio/asr/wenet_automatic_speech_recognition.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
 import json
 import wenetruntime as wenet
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+
 
 __all__ = ['WeNetAutomaticSpeechRecognition']
 
 
-@MODELS.register_module(
-    Tasks.auto_speech_recognition, module_name=Models.wenet_asr)
-class WeNetAutomaticSpeechRecognition(Model):
+@MODELS.register_module(Tasks.auto_speech_recognition, module_name=Models.wenet_asr)
+class WeNetAutomaticSpeechRecognition(BaseModel):
 
     def __init__(self, model_dir: str, am_model_name: str,
                  model_config: Dict[str, Any], *args, **kwargs):
         """initialize the info of model.
 
         Args:
             model_dir (str): the model path.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/itn/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_binary_quant_classification/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .generic_inverse_text_processing import GenericInverseTextProcessing
+    from .binary_quant_model import BinaryQuantClassificationModel
 
 else:
     _import_structure = {
-        'generic_inverse_text_processing': ['GenericInverseTextProcessing'],
+        'binary_quant_model': ['BinaryQuantClassificationModel'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/itn/generic_inverse_text_processing.py` & `weathon-0.0.0.14/weathon/models/audio/punc/generic_punctuation.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,42 +1,42 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Frameworks, Tasks
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+# from weathon.base import BaseModel
+# from weathon.registry import MODELS
+# from weathon.utils.constant import Frameworks, Tasks
 
 
-@MODELS.register_module(
-    Tasks.inverse_text_processing, module_name=Models.generic_itn)
-class GenericInverseTextProcessing(Model):
+@MODELS.register_module(Tasks.punctuation, module_name=Models.generic_punc)
+class PunctuationProcessing(BaseModel):
 
-    def __init__(self, model_dir: str, itn_model_name: str,
-                 model_config: Dict[str, Any], *args, **kwargs):
+    def __init__(self, model_dir: str, punc_model_name: str,
+                 punc_model_config: Dict[str, Any], *args, **kwargs):
         """initialize the info of model.
 
         Args:
             model_dir (str): the model path.
-            itn_model_name (str): the itn model name from configuration.json
-            model_config (Dict[str, Any]): the detail config about model from configuration.json
+            punc_model_name (str): the itn model name from configuration.json
+            punc_model_config (Dict[str, Any]): the detail config about model from configuration.json
         """
-        super().__init__(model_dir, itn_model_name, model_config, *args,
+        super().__init__(model_dir, punc_model_name, punc_model_config, *args,
                          **kwargs)
         self.model_cfg = {
             # the recognition model dir path
             'model_workspace': model_dir,
             # the itn model name
-            'itn_model': itn_model_name,
+            'punc_model': punc_model_name,
             # the am model file path
-            'itn_model_path': os.path.join(model_dir, itn_model_name),
+            'punc_model_path': os.path.join(model_dir, punc_model_name),
             # the recognition model config dict
-            'model_config': model_config
+            'model_config': punc_model_config
         }
 
     def forward(self) -> Dict[str, Any]:
         """
           just return the model config
 
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/motion_generation/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,22 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .generic_key_word_spotting import GenericKeyWordSpotting
-    from .farfield.model import FSMNSeleNetV2Decorator
-    from .nearfield.model import FSMNDecorator
 
+    from .model import create_model, load_model_wo_clip
+    from .modules.cfg_sampler import ClassifierFreeSampleModel
 else:
     _import_structure = {
-        'generic_key_word_spotting': ['GenericKeyWordSpotting'],
-        'farfield.model': ['FSMNSeleNetV2Decorator'],
-        'nearfield.model': ['FSMNDecorator'],
+        'model': ['create_model', 'load_model_wo_clip'],
+        'modules.cfg_sampler': ['ClassifierFreeSampleModel']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/fsmn.py` & `weathon-0.0.0.14/weathon/models/audio/kws/farfield/fsmn.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .model_def import (HEADER_BLOCK_SIZE, ActivationType, LayerType, f32ToI32,
                         printNeonMatrix, printNeonVector)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/fsmn_sele_v2.py` & `weathon-0.0.0.14/weathon/models/audio/kws/farfield/fsmn_sele_v2.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .fsmn import AffineTransform, Fsmn, LinearTransform, RectifiedLinear
 from .model_def import HEADER_BLOCK_SIZE, ActivationType, LayerType, f32ToI32
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/fsmn_sele_v3.py` & `weathon-0.0.0.14/weathon/models/audio/kws/farfield/fsmn_sele_v3.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .fsmn import AffineTransform, Fsmn, LinearTransform, RectifiedLinear
 from .model_def import HEADER_BLOCK_SIZE, ActivationType, LayerType, f32ToI32
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/model.py` & `weathon-0.0.0.14/weathon/models/audio/kws/farfield/model.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,25 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import tempfile
 from typing import Dict, Optional
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.utils.audio.audio_utils import update_conf
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.audio.audio_utils import update_conf
+from weathon.utils.typing import Tensor
 from .fsmn_sele_v2 import FSMNSeleNetV2
 from .fsmn_sele_v3 import FSMNSeleNetV3
 
 
-@MODELS.register_module(
-    Tasks.keyword_spotting, module_name=Models.speech_dfsmn_kws_char_farfield)
+@MODELS.register_module(Tasks.keyword_spotting, module_name=Models.speech_dfsmn_kws_char_farfield)
 class FSMNSeleNetV2Decorator(TorchModel):
     r""" A decorator of FSMNSeleNetV2 for integrating into modelscope framework """
 
     MODEL_CLASS = FSMNSeleNetV2
     MODEL_TXT = 'model.txt'
     SC_CONFIG = 'sound_connect.conf'
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/farfield/model_def.py` & `weathon-0.0.0.14/weathon/models/audio/kws/farfield/model_def.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 import struct
 from enum import Enum
 
 HEADER_BLOCK_SIZE = 10
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/generic_key_word_spotting.py` & `weathon-0.0.0.14/weathon/models/audio/kws/generic_key_word_spotting.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,22 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+# from weathon.base import BaseModel
+# from weathon.registry import MODELS
+# from weathon.utils.constants import Tasks
 
 __all__ = ['GenericKeyWordSpotting']
 
 
 @MODELS.register_module(Tasks.keyword_spotting, module_name=Models.kws_kwsbp)
-class GenericKeyWordSpotting(Model):
+class GenericKeyWordSpotting(BaseModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the info of model.
 
         Args:
             model_dir (str): the model path.
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/nearfield/cmvn.py` & `weathon-0.0.0.14/weathon/models/audio/kws/nearfield/cmvn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/nearfield/fsmn.py` & `weathon-0.0.0.14/weathon/models/audio/kws/nearfield/fsmn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/kws/nearfield/model.py` & `weathon-0.0.0.14/weathon/models/audio/kws/nearfield/model.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,30 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import sys
 import tempfile
 from typing import Dict, Optional, Tuple
 
 import torch
 import torch.nn as nn
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.utils.audio.audio_utils import update_conf
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
 from .cmvn import GlobalCMVN, load_kaldi_cmvn
 from .fsmn import FSMN
 
 
-@MODELS.register_module(
-    Tasks.keyword_spotting,
-    module_name=Models.speech_kws_fsmn_char_ctc_nearfield)
+@MODELS.register_module(Tasks.keyword_spotting, module_name=Models.speech_kws_fsmn_char_ctc_nearfield)
 class FSMNDecorator(TorchModel):
     r""" A decorator of FSMN for integrating into modelscope framework """
 
     def __init__(self,
                  model_dir: str,
                  cmvn_file: str = None,
                  backbone: dict = None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/punc/generic_punctuation.py` & `weathon-0.0.0.14/weathon/models/audio/sv/generic_speaker_verification.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,41 +1,39 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Frameworks, Tasks
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
 
-@MODELS.register_module(Tasks.punctuation, module_name=Models.generic_punc)
-class PunctuationProcessing(Model):
+@MODELS.register_module(Tasks.speaker_verification, module_name=Models.generic_sv)
+@MODELS.register_module(Tasks.speaker_diarization, module_name=Models.generic_sv)
+class SpeakerVerification(BaseModel):
 
-    def __init__(self, model_dir: str, punc_model_name: str,
-                 punc_model_config: Dict[str, Any], *args, **kwargs):
+    def __init__(self, model_dir: str, model_name: str,
+                 model_config: Dict[str, Any], *args, **kwargs):
         """initialize the info of model.
 
         Args:
             model_dir (str): the model path.
-            punc_model_name (str): the itn model name from configuration.json
-            punc_model_config (Dict[str, Any]): the detail config about model from configuration.json
+            model_name (str): the itn model name from configuration.json
+            model_config (Dict[str, Any]): the detail config about model from configuration.json
         """
-        super().__init__(model_dir, punc_model_name, punc_model_config, *args,
-                         **kwargs)
+        super().__init__(model_dir, model_name, model_config, *args, **kwargs)
         self.model_cfg = {
             # the recognition model dir path
             'model_workspace': model_dir,
             # the itn model name
-            'punc_model': punc_model_name,
+            'model_name': model_name,
             # the am model file path
-            'punc_model_path': os.path.join(model_dir, punc_model_name),
+            'model_path': os.path.join(model_dir, model_name),
             # the recognition model config dict
-            'model_config': punc_model_config
+            'model_config': model_config
         }
 
     def forward(self) -> Dict[str, Any]:
         """
           just return the model config
 
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/separation/layer_norm.py` & `weathon-0.0.0.14/weathon/models/audio/separation/layer_norm.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/separation/mossformer.py` & `weathon-0.0.0.14/weathon/models/audio/separation/mossformer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import copy
 import os
 from typing import Any, Dict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models import MODELS, TorchModel
-from modelscope.models.audio.separation.mossformer_block import (
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.audio.separation.mossformer_block import (
     MossFormerModule, ScaledSinuEmbedding)
-from modelscope.models.audio.separation.mossformer_conv_module import (
+from weathon.models.audio.separation.mossformer_conv_module import (
     CumulativeLayerNorm, GlobalLayerNorm)
-from modelscope.models.base import Tensor
-from modelscope.utils.constant import Tasks
+# from weathon.utils.typing import Tensor
+# from weathon.utils.constants import Tasks
+# from weathon.models import MODELS, TorchModel
+
 
 EPS = 1e-8
 
 
-@MODELS.register_module(
-    Tasks.speech_separation,
-    module_name=Models.speech_mossformer_separation_temporal_8k)
+@MODELS.register_module(Tasks.speech_separation, module_name=Models.speech_mossformer_separation_temporal_8k)
 class MossFormer(TorchModel):
     """Library to support MossFormer speech separation.
 
         Args:
             model_dir (str): the model path.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/separation/mossformer_block.py` & `weathon-0.0.0.14/weathon/models/audio/separation/mossformer_block.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn.functional as F
 from torch import einsum, nn
 
-from modelscope.models.audio.separation.mossformer_conv_module import \
+from weathon.models.audio.separation.mossformer_conv_module import \
     MossFormerConvModule
 
 
 def exists(val):
     return val is not None
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/separation/mossformer_conv_module.py` & `weathon-0.0.0.14/weathon/models/audio/separation/mossformer_conv_module.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torch.nn.init as init
 from torch import Tensor
 
 EPS = 1e-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/sv/DTDNN.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/mod_resnet.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,195 +1,229 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# The implementation is modified from torchvision
+# under BSD-3-Clause License
+# https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py
 
-import os
+import math
 from collections import OrderedDict
-from typing import Any, Dict, Union
 
 import torch
 import torch.nn as nn
-import torch.nn.functional as F
-import torchaudio.compliance.kaldi as Kaldi
+from torch.utils import model_zoo
 
-from modelscope.metainfo import Models
-from modelscope.models import MODELS, TorchModel
-from modelscope.models.audio.sv.DTDNN_layers import (BasicResBlock,
-                                                     CAMDenseTDNNBlock,
-                                                     DenseLayer, StatsPool,
-                                                     TDNNLayer, TransitLayer,
-                                                     get_nonlinear)
-from modelscope.utils.constant import Tasks
 
+def load_weights_sequential(target, source_state, extra_chan=1):
 
-class FCM(nn.Module):
+    new_dict = OrderedDict()
+
+    for k1, v1 in target.state_dict().items():
+        if 'num_batches_tracked' not in k1:
+            if k1 in source_state:
+                tar_v = source_state[k1]
+
+                if v1.shape != tar_v.shape:
+                    # Init the new segmentation channel with zeros
+                    # print(v1.shape, tar_v.shape)
+                    c, _, w, h = v1.shape
+                    pads = torch.zeros((c, extra_chan, w, h),
+                                       device=tar_v.device)
+                    nn.init.orthogonal_(pads)
+                    tar_v = torch.cat([tar_v, pads], 1)
+
+                new_dict[k1] = tar_v
+
+    target.load_state_dict(new_dict, strict=False)
+
+
+model_urls = {
+    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
+    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
+}
+
+
+def conv3x3(in_planes, out_planes, stride=1, dilation=1, bias=True):
+    return nn.Conv2d(
+        in_planes,
+        out_planes,
+        kernel_size=3,
+        stride=stride,
+        padding=dilation,
+        bias=bias,
+        dilation=dilation)
+
+
+class BasicBlock(nn.Module):
+    expansion = 1
 
     def __init__(self,
-                 block=BasicResBlock,
-                 num_blocks=[2, 2],
-                 m_channels=32,
-                 feat_dim=80):
-        super(FCM, self).__init__()
-        self.in_planes = m_channels
-        self.conv1 = nn.Conv2d(
-            1, m_channels, kernel_size=3, stride=1, padding=1, bias=False)
-        self.bn1 = nn.BatchNorm2d(m_channels)
+                 inplanes,
+                 planes,
+                 stride=1,
+                 downsample=None,
+                 dilation=1,
+                 bias=True):
+        super(BasicBlock, self).__init__()
+        self.conv1 = conv3x3(
+            inplanes, planes, stride=stride, dilation=dilation, bias=bias)
+        self.bn1 = nn.BatchNorm2d(planes)
+        self.relu = nn.ReLU(inplace=True)
+        self.conv2 = conv3x3(
+            planes, planes, stride=1, dilation=dilation, bias=bias)
+        self.bn2 = nn.BatchNorm2d(planes)
+        self.downsample = downsample
+        self.stride = stride
 
-        self.layer1 = self._make_layer(
-            block, m_channels, num_blocks[0], stride=2)
-        self.layer2 = self._make_layer(
-            block, m_channels, num_blocks[0], stride=2)
+    def forward(self, x):
+        residual = x
+
+        out = self.conv1(x)
+        out = self.bn1(out)
+        out = self.relu(out)
 
+        out = self.conv2(out)
+        out = self.bn2(out)
+
+        if self.downsample is not None:
+            residual = self.downsample(x)
+
+        out += residual
+        out = self.relu(out)
+
+        return out
+
+
+class Bottleneck(nn.Module):
+    expansion = 4
+
+    def __init__(self,
+                 inplanes,
+                 planes,
+                 stride=1,
+                 downsample=None,
+                 dilation=1,
+                 bias=True):
+        super(Bottleneck, self).__init__()
+        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=bias)
+        self.bn1 = nn.BatchNorm2d(planes)
         self.conv2 = nn.Conv2d(
-            m_channels,
-            m_channels,
+            planes,
+            planes,
             kernel_size=3,
-            stride=(2, 1),
-            padding=1,
-            bias=False)
-        self.bn2 = nn.BatchNorm2d(m_channels)
-        self.out_channels = m_channels * (feat_dim // 8)
-
-    def _make_layer(self, block, planes, num_blocks, stride):
-        strides = [stride] + [1] * (num_blocks - 1)
-        layers = []
-        for stride in strides:
-            layers.append(block(self.in_planes, planes, stride))
-            self.in_planes = planes * block.expansion
-        return nn.Sequential(*layers)
+            stride=stride,
+            dilation=dilation,
+            padding=dilation,
+            bias=bias)
+        self.bn2 = nn.BatchNorm2d(planes)
+        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=bias)
+        self.bn3 = nn.BatchNorm2d(planes * 4)
+        self.relu = nn.ReLU(inplace=True)
+        self.downsample = downsample
+        self.stride = stride
 
     def forward(self, x):
-        x = x.unsqueeze(1)
-        out = F.relu(self.bn1(self.conv1(x)))
-        out = self.layer1(out)
-        out = self.layer2(out)
-        out = F.relu(self.bn2(self.conv2(out)))
+        residual = x
+
+        out = self.conv1(x)
+        out = self.bn1(out)
+        out = self.relu(out)
+
+        out = self.conv2(out)
+        out = self.bn2(out)
+        out = self.relu(out)
+
+        out = self.conv3(out)
+        out = self.bn3(out)
+
+        if self.downsample is not None:
+            residual = self.downsample(x)
+
+        out += residual
+        out = self.relu(out)
 
-        shape = out.shape
-        out = out.reshape(shape[0], shape[1] * shape[2], shape[3])
         return out
 
 
-class CAMPPlus(nn.Module):
+class ResNet(nn.Module):
 
-    def __init__(self,
-                 feat_dim=80,
-                 embedding_size=512,
-                 growth_rate=32,
-                 bn_size=4,
-                 init_channels=128,
-                 config_str='batchnorm-relu',
-                 memory_efficient=True,
-                 output_level='segment'):
-        super(CAMPPlus, self).__init__()
-
-        self.head = FCM(feat_dim=feat_dim)
-        channels = self.head.out_channels
-        self.output_level = output_level
-
-        self.xvector = nn.Sequential(
-            OrderedDict([
-                ('tdnn',
-                 TDNNLayer(
-                     channels,
-                     init_channels,
-                     5,
-                     stride=2,
-                     dilation=1,
-                     padding=-1,
-                     config_str=config_str)),
-            ]))
-        channels = init_channels
-        for i, (num_layers, kernel_size, dilation) in enumerate(
-                zip((12, 24, 16), (3, 3, 3), (1, 2, 2))):
-            block = CAMDenseTDNNBlock(
-                num_layers=num_layers,
-                in_channels=channels,
-                out_channels=growth_rate,
-                bn_channels=bn_size * growth_rate,
-                kernel_size=kernel_size,
-                dilation=dilation,
-                config_str=config_str,
-                memory_efficient=memory_efficient)
-            self.xvector.add_module('block%d' % (i + 1), block)
-            channels = channels + num_layers * growth_rate
-            self.xvector.add_module(
-                'transit%d' % (i + 1),
-                TransitLayer(
-                    channels, channels // 2, bias=False,
-                    config_str=config_str))
-            channels //= 2
-
-        self.xvector.add_module('out_nonlinear',
-                                get_nonlinear(config_str, channels))
-
-        if self.output_level == 'segment':
-            self.xvector.add_module('stats', StatsPool())
-            self.xvector.add_module(
-                'dense',
-                DenseLayer(
-                    channels * 2, embedding_size, config_str='batchnorm_'))
-        else:
-            assert self.output_level == 'frame', '`output_level` should be set to \'segment\' or \'frame\'. '
+    def __init__(self, block, layers=(3, 4, 23, 3), extra_chan=1, bias=True):
+        self.inplanes = 64
+        super(ResNet, self).__init__()
+        self.conv1 = nn.Conv2d(
+            3 + extra_chan, 64, kernel_size=7, stride=2, padding=3, bias=bias)
+        self.bn1 = nn.BatchNorm2d(64)
+        self.relu = nn.ReLU(inplace=True)
+        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
+        self.layer1 = self._make_layer(block, 64, layers[0], bias=bias)
+        self.layer2 = self._make_layer(
+            block, 128, layers[1], stride=2, bias=bias)
+        self.layer3 = self._make_layer(
+            block, 256, layers[2], stride=2, bias=bias)
+        self.layer4 = self._make_layer(
+            block, 512, layers[3], stride=2, bias=bias)
 
         for m in self.modules():
-            if isinstance(m, (nn.Conv1d, nn.Linear)):
-                nn.init.kaiming_normal_(m.weight.data)
-                if m.bias is not None:
-                    nn.init.zeros_(m.bias)
+            if isinstance(m, nn.Conv2d):
+                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
+                m.weight.data.normal_(0, math.sqrt(2. / n))
+                try:
+                    m.bias.data.zero_()
+                except Exception:
+                    pass
+            elif isinstance(m, nn.BatchNorm2d):
+                m.weight.data.fill_(1)
+                m.bias.data.zero_()
+
+    def _make_layer(self,
+                    block,
+                    planes,
+                    blocks,
+                    stride=1,
+                    dilation=1,
+                    bias=True):
+        downsample = None
+        if stride != 1 or self.inplanes != planes * block.expansion:
+            downsample = nn.Sequential(
+                nn.Conv2d(
+                    self.inplanes,
+                    planes * block.expansion,
+                    kernel_size=1,
+                    stride=stride,
+                    bias=bias),
+                nn.BatchNorm2d(planes * block.expansion),
+            )
+
+        layers = [
+            block(self.inplanes, planes, stride, downsample, dilation, bias)
+        ]
+        self.inplanes = planes * block.expansion
+        for i in range(1, blocks):
+            layers.append(
+                block(self.inplanes, planes, dilation=dilation, bias=bias))
 
-    def forward(self, x):
-        x = x.permute(0, 2, 1)  # (B,T,F) => (B,F,T)
-        x = self.head(x)
-        x = self.xvector(x)
-        if self.output_level == 'frame':
-            x = x.transpose(1, 2)
-        return x
-
-
-@MODELS.register_module(
-    Tasks.speaker_verification, module_name=Models.campplus_sv)
-class SpeakerVerificationCAMPPlus(TorchModel):
-    r"""A fast and efficient speaker embedding model, using a 2-dimensional convolution residual network as the head
-    and a densely connected time delay neural network as the backbone.
-    Args:
-        model_dir: A model dir.
-        model_config: The model config.
-    """
-
-    def __init__(self, model_dir, model_config: Dict[str, Any], *args,
-                 **kwargs):
-        super().__init__(model_dir, model_config, *args, **kwargs)
-        self.model_config = model_config
-        self.other_config = kwargs
-
-        self.feature_dim = self.model_config['fbank_dim']
-        self.emb_size = self.model_config['emb_size']
-
-        self.embedding_model = CAMPPlus(self.feature_dim, self.emb_size)
-
-        pretrained_model_name = kwargs['pretrained_model']
-        self.__load_check_point(pretrained_model_name)
-
-        self.embedding_model.eval()
-
-    def forward(self, audio):
-        assert len(audio.shape) == 2 and audio.shape[
-            0] == 1, 'modelscope error: the shape of input audio to model needs to be [1, T]'
-        # audio shape: [1, T]
-        feature = self.__extract_feature(audio)
-        embedding = self.embedding_model(feature)
-
-        return embedding
-
-    def __extract_feature(self, audio):
-        feature = Kaldi.fbank(audio, num_mel_bins=self.feature_dim)
-        feature = feature - feature.mean(dim=0, keepdim=True)
-        feature = feature.unsqueeze(0)
-        return feature
-
-    def __load_check_point(self, pretrained_model_name, device=None):
-        if not device:
-            device = torch.device('cpu')
-        self.embedding_model.load_state_dict(
-            torch.load(
-                os.path.join(self.model_dir, pretrained_model_name),
-                map_location=device),
-            strict=True)
+        return nn.Sequential(*layers)
+
+
+def resnet18(pretrained=True, extra_chan=0):
+    model = ResNet(BasicBlock, [2, 2, 2, 2], extra_chan=extra_chan)
+    if pretrained and torch.distributed.is_initialized():
+        local_rank = torch.distributed.get_rank()
+        load_weights_sequential(
+            model,
+            model_zoo.load_url(
+                model_urls['resnet18'],
+                model_dir='pretrain/resnet18-{}'.format(local_rank)),
+            extra_chan)
+    return model
+
+
+def resnet50(pretrained=True, extra_chan=0):
+    model = ResNet(Bottleneck, [3, 4, 6, 3], extra_chan=extra_chan, bias=False)
+
+    if pretrained and torch.distributed.is_initialized():
+        local_rank = torch.distributed.get_rank()
+        load_weights_sequential(
+            model,
+            model_zoo.load_url(
+                model_urls['resnet50'],
+                model_dir='pretrain/resnet50-{}'.format(local_rank)),
+            extra_chan)
+        print(torch.distributed.get_rank(), 'resnet 50 is loading...')
+    return model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/sv/DTDNN_layers.py` & `weathon-0.0.0.14/weathon/models/audio/sv/DTDNN_layers.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """ Some implementations are adapted from https://github.com/yuyq96/D-TDNN
 """
 
 import torch
 import torch.nn.functional as F
 import torch.utils.checkpoint as cp
 from torch import nn
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/sv/ERes2Net.py` & `weathon-0.0.0.14/weathon/models/audio/sv/ERes2Net.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """ Res2Net implementation is adapted from https://github.com/wenet-e2e/wespeaker.
     ERes2Net incorporates both local and global feature fusion techniques to improve the performance. The local feature
     fusion (LFF) fuses the features within one single residual block to extract the local signal.
     The global feature fusion (GFF) takes acoustic features of different scales as input to aggregate global signal.
 """
 import math
 import os
-from typing import Any, Dict, Union
+from typing import Any, Dict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torchaudio.compliance.kaldi as Kaldi
 
-import modelscope.models.audio.sv.pooling_layers as pooling_layers
-from modelscope.metainfo import Models
-from modelscope.models import MODELS, TorchModel
-from modelscope.models.audio.sv.fusion import AFF
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.models.audio.sv import pooling_layers
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.audio.sv.fusion import AFF
 
 
 class ReLU(nn.Hardtanh):
 
     def __init__(self, inplace=False):
         super(ReLU, self).__init__(0, 20, inplace)
 
@@ -290,16 +290,15 @@
             out = self.seg_bn_1(out)
             embed_b = self.seg_2(out)
             return embed_b
         else:
             return embed_a
 
 
-@MODELS.register_module(
-    Tasks.speaker_verification, module_name=Models.eres2net_sv)
+@MODELS.register_module(Tasks.speaker_verification, module_name=Models.eres2net_sv)
 class SpeakerVerificationERes2Net(TorchModel):
     r"""Enhanced Res2Net architecture with local and global feature fusion. ERes2Net is mainly composed
     of LFF and GFF. The LFF extracts localization-preserved speaker features and strengthen the local information
     interaction. GFF fuses multi-scale feature maps in bottom-up pathway to obtain global information.
     Args:
         model_dir: A model dir.
         model_config: The model config.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/sv/ecapa_tdnn.py` & `weathon-0.0.0.14/weathon/models/audio/sv/ecapa_tdnn.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,22 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """ This ECAPA-TDNN implementation is adapted from https://github.com/speechbrain/speechbrain.
 """
 import math
 import os
 from typing import Any, Dict, Union
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torchaudio.compliance.kaldi as Kaldi
 
-from modelscope.metainfo import Models
-from modelscope.models import MODELS, TorchModel
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+# from weathon.models import MODELS, TorchModel
+# from weathon.utils.constants import Tasks
 
 
 def length_to_mask(length, max_len=None, dtype=None, device=None):
     assert len(length.shape) == 1
 
     if max_len is None:
         max_len = length.max().long().item()
@@ -450,16 +452,15 @@
         # Final linear transformation
         x = self.fc(x)
 
         x = x.transpose(1, 2).squeeze(1)
         return x
 
 
-@MODELS.register_module(
-    Tasks.speaker_verification, module_name=Models.ecapa_tdnn_sv)
+@MODELS.register_module(Tasks.speaker_verification, module_name=Models.ecapa_tdnn_sv)
 class SpeakerVerificationECAPATDNN(TorchModel):
 
     def __init__(self, model_dir, model_config: Dict[str, Any], *args,
                  **kwargs):
         super().__init__(model_dir, model_config, *args, **kwargs)
         self.model_config = model_config
         self.other_config = kwargs
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/sv/fusion.py` & `weathon-0.0.0.14/weathon/models/audio/sv/fusion.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
 
 class AFF(nn.Module):
 
     def __init__(self, channels=64, r=4):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/sv/pooling_layers.py` & `weathon-0.0.0.14/weathon/models/audio/sv/pooling_layers.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """ This implementation is adapted from https://github.com/wenet-e2e/wespeaker.
 """
 import torch
 import torch.nn as nn
 
 
 class TAP(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/sv/rdino.py` & `weathon-0.0.0.14/weathon/models/audio/sv/rdino.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """ This ECAPA-TDNN implementation is adapted from https://github.com/speechbrain/speechbrain.
     RDINOHead implementation is adapted from DINO framework.
 """
 import math
 import os
-from typing import Any, Dict, Union
+from typing import Any, Dict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torchaudio.compliance.kaldi as Kaldi
 
-from modelscope.metainfo import Models
-from modelscope.models import MODELS, TorchModel
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+# from weathon.models import MODELS, TorchModel
+# from weathon.utils.constants import Tasks
 
 
 def length_to_mask(length, max_len=None, dtype=None, device=None):
     assert len(length.shape) == 1
 
     if max_len is None:
         max_len = length.max().long().item()
@@ -514,16 +516,15 @@
 
     def forward(self, x):
         x = self.backbone(x)
         output = self.head(x)
         return output
 
 
-@MODELS.register_module(
-    Tasks.speaker_verification, module_name=Models.rdino_tdnn_sv)
+@MODELS.register_module(Tasks.speaker_verification, module_name=Models.rdino_tdnn_sv)
 class SpeakerVerification_RDINO(TorchModel):
 
     def __init__(self, model_dir, model_config: Dict[str, Any], *args,
                  **kwargs):
         super().__init__(model_dir, model_config, *args, **kwargs)
         self.model_config = model_config
         self.other_config = kwargs
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/sv/speaker_change_locator.py` & `weathon-0.0.0.14/weathon/models/audio/sv/speaker_change_locator.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from collections import OrderedDict
 from typing import Any, Dict, Union
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torchaudio.compliance.kaldi as Kaldi
 
-from modelscope.metainfo import Models
-from modelscope.models import MODELS, TorchModel
-from modelscope.models.audio.sv.DTDNN import CAMPPlus
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.audio.sv.DTDNN import CAMPPlus
+# from weathon.utils.constants import Tasks
+# from weathon.models import MODELS, TorchModel
+
 
 
 class MultiHeadSelfAttention(nn.Module):
 
     def __init__(self, n_units, h=8, dropout=0.1):
         super(MultiHeadSelfAttention, self).__init__()
         self.linearQ = nn.Linear(n_units, n_units)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/tts/sambert_hifi.py` & `weathon-0.0.0.14/weathon/models/audio/tts/sambert_hifi.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,43 +1,39 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from __future__ import (absolute_import, division, print_function,
                         unicode_literals)
 import datetime
 import os
 import shutil
-import wave
 import zipfile
 
 import json
 import matplotlib.pyplot as plt
 import numpy as np
-import yaml
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.utils.audio.audio_utils import (TtsCustomParams, TtsTrainType,
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+
+from weathon.utils.audio.audio_utils import (TtsCustomParams, TtsTrainType,
                                                 ndarray_pcm_to_wav)
-from modelscope.utils.audio.tts_exceptions import (
+from weathon.utils.audio.tts_exceptions import (
     TtsFrontendInitializeFailedException,
-    TtsFrontendLanguageTypeInvalidException, TtsModelConfigurationException,
-    TtsVoiceNotExistsException)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+    TtsFrontendLanguageTypeInvalidException, TtsVoiceNotExistsException)
+from weathon.utils.logger import get_logger
 from .voice import Voice
 
 __all__ = ['SambertHifigan']
 
+
 logger = get_logger()
 
 
-@MODELS.register_module(
-    Tasks.text_to_speech, module_name=Models.sambert_hifigan)
-class SambertHifigan(Model):
+@MODELS.register_module(Tasks.text_to_speech, module_name=Models.sambert_hifigan)
+class SambertHifigan(BaseModel):
 
     def __init__(self, model_dir, *args, **kwargs):
         super().__init__(model_dir, *args, **kwargs)
         self.model_dir = model_dir
         self.sample_rate = kwargs.get('sample_rate', 16000)
         self.is_train = False
         if 'is_train' in kwargs:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/audio/tts/voice.py` & `weathon-0.0.0.14/weathon/models/audio/tts/voice.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import pickle as pkl
 import time
 from collections import OrderedDict
 from threading import Lock
 
 import json
@@ -13,18 +11,18 @@
 from kantts.datasets.dataset import get_am_datasets, get_voc_datasets
 from kantts.models import model_builder
 from kantts.train.loss import criterion_builder
 from kantts.train.trainer import GAN_Trainer, Sambert_Trainer, distributed_init
 from kantts.utils.ling_unit.ling_unit import KanTtsLinguisticUnit
 from torch.utils.data import DataLoader
 
-from modelscope.utils.audio.audio_utils import TtsCustomParams
-from modelscope.utils.audio.tts_exceptions import (
+from weathon.utils.audio.audio_utils import TtsCustomParams
+from weathon.utils.audio.tts_exceptions import (
     TtsModelConfigurationException, TtsModelNotExistsException)
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def count_parameters(model):
     return sum(p.numel() for p in model.parameters() if p.requires_grad)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/base/base_torch_model.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_recognition/model.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,147 +1,163 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
-from copy import deepcopy
-from functools import partial
-from typing import Any, Callable, Dict, List, Optional, Union
 
 import torch
-from packaging import version
-from torch import nn
-from torch.nn.parallel import DataParallel, DistributedDataParallel
-
-from modelscope.utils.checkpoint import (save_checkpoint, save_configuration,
-                                         save_pretrained)
-from modelscope.utils.file_utils import func_receive_dict_inputs
-from modelscope.utils.logger import get_logger
-from .base_model import Model
-
-logger = get_logger()
+import torch.nn.functional as F
 
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.config.config import Config
+from weathon.utils.logger import get_logger
+from .modules.convnextvit import ConvNextViT
+from .modules.crnn import CRNN
+
+LOGGER = get_logger()
+
+
+def flatten_label(target):
+    label_flatten = []
+    label_length = []
+    label_dict = []
+    for i in range(0, target.size()[0]):
+        cur_label = target[i].tolist()
+        temp_label = cur_label[:cur_label.index(0)]
+        label_flatten += temp_label
+        label_dict.append(temp_label)
+        label_length.append(len(temp_label))
+    label_flatten = torch.LongTensor(label_flatten)
+    label_length = torch.IntTensor(label_length)
+    return (label_dict, label_length, label_flatten)
+
+
+class cha_encdec():
+
+    def __init__(self, charMapping, case_sensitive=True):
+        self.case_sensitive = case_sensitive
+        self.text_seq_len = 160
+        self.charMapping = charMapping
+
+    def encode(self, label_batch):
+        max_len = max([len(s) for s in label_batch])
+        out = torch.zeros(len(label_batch), max_len + 1).long()
+        for i in range(0, len(label_batch)):
+            if not self.case_sensitive:
+                cur_encoded = torch.tensor([
+                    self.charMapping[char.lower()] - 1 if char.lower()
+                    in self.charMapping else len(self.charMapping)
+                    for char in label_batch[i]
+                ]) + 1
+            else:
+                cur_encoded = torch.tensor([
+                    self.charMapping[char]
+                    - 1 if char in self.charMapping else len(self.charMapping)
+                    for char in label_batch[i]
+                ]) + 1
+            out[i][0:len(cur_encoded)] = cur_encoded
+        out = torch.cat(
+            (out, torch.zeros(
+                (out.size(0), self.text_seq_len - out.size(1))).type_as(out)),
+            dim=1)
+        label_dict, label_length, label_flatten = flatten_label(out)
+        return label_dict, label_length, label_flatten
 
-class TorchModel(Model, torch.nn.Module):
-    """ Base model interface for pytorch
 
-    """
+@MODELS.register_module(Tasks.ocr_recognition, module_name=Models.ocr_recognition)
+class OCRRecognition(TorchModel):
 
-    def __init__(self, model_dir=None, *args, **kwargs):
-        super().__init__(model_dir, *args, **kwargs)
-        torch.nn.Module.__init__(self)
+    def __init__(self, model_dir: str, **kwargs):
+        """initialize the ocr recognition model from the `model_dir` path.
 
-    def __call__(self, *args, **kwargs) -> Dict[str, Any]:
-        # Adapting a model with only one dict arg, and the arg name must be input or inputs
-        if func_receive_dict_inputs(self.forward):
-            return self.postprocess(self.forward(args[0], **kwargs))
+        Args:
+            model_dir (str): the model path.
+        """
+        super().__init__(model_dir, **kwargs)
+        model_path = os.path.join(model_dir, ModelFile.TORCH_MODEL_FILE)
+        cfgs = Config.from_file(
+            os.path.join(model_dir, ModelFile.CONFIGURATION))
+        self.do_chunking = cfgs.model.inference_kwargs.do_chunking
+        self.target_height = cfgs.model.inference_kwargs.img_height
+        self.target_width = cfgs.model.inference_kwargs.img_width
+        self.recognizer = None
+        if cfgs.model.recognizer == 'ConvNextViT':
+            self.recognizer = ConvNextViT()
+        elif cfgs.model.recognizer == 'CRNN':
+            self.recognizer = CRNN()
         else:
-            return self.postprocess(self.forward(*args, **kwargs))
+            raise TypeError(
+                f'recognizer should be either ConvNextViT, CRNN, but got {cfgs.model.recognizer}'
+            )
+        if model_path != '':
+            params_pretrained = torch.load(model_path, map_location='cpu')
+            model_dict = self.recognizer.state_dict()
+            # remove prefix for finetuned models
+            check_point = {
+                k.replace('recognizer.', ''): v
+                for k, v in params_pretrained.items()
+            }
+            model_dict.update(check_point)
+            self.recognizer.load_state_dict(model_dict)
+
+        dict_path = os.path.join(model_dir, ModelFile.VOCAB_FILE)
+        self.labelMapping = dict()
+        self.charMapping = dict()
+        with open(dict_path, 'r', encoding='utf-8') as f:
+            lines = f.readlines()
+            cnt = 1
+            # ConvNextViT model start from index=2
+            if self.do_chunking:
+                cnt += 1
+            for line in lines:
+                line = line.strip('\n')
+                self.labelMapping[cnt] = line
+                self.charMapping[line] = cnt
+                cnt += 1
 
-    def _load_pretrained(self,
-                         net,
-                         load_path,
-                         strict=True,
-                         param_key='params'):
-        if isinstance(net, (DataParallel, DistributedDataParallel)):
-            net = net.module
-        load_net = torch.load(
-            load_path, map_location=lambda storage, loc: storage)
-        if param_key is not None:
-            if param_key not in load_net and 'params' in load_net:
-                param_key = 'params'
-                logger.info(
-                    f'Loading: {param_key} does not exist, use params.')
-            if param_key in load_net:
-                load_net = load_net[param_key]
-        logger.info(
-            f'Loading {net.__class__.__name__} model from {load_path}, with param key: [{param_key}].'
-        )
-        # remove unnecessary 'module.'
-        for k, v in deepcopy(load_net).items():
-            if k.startswith('module.'):
-                load_net[k[7:]] = v
-                load_net.pop(k)
-        net.load_state_dict(load_net, strict=strict)
-        logger.info('load model done.')
-        return net
+        self.encdec = cha_encdec(self.charMapping)
+        self.criterion_CTC = torch.nn.CTCLoss(zero_infinity=True)
 
-    def forward(self, *args, **kwargs) -> Dict[str, Any]:
-        raise NotImplementedError
-
-    def post_init(self):
-        """
-        A method executed at the end of each model initialization, to execute code that needs the model's
-        modules properly initialized (such as weight initialization).
+    def forward(self, inputs):
         """
-        self.init_weights()
-
-    def init_weights(self):
-        # Initialize weights
-        self.apply(self._init_weights)
-
-    def _init_weights(self, module):
-        """Initialize the weights"""
-        if isinstance(module, nn.Linear):
-            # Slightly different from the TF version which uses truncated_normal for initialization
-            # cf https://github.com/pytorch/pytorch/pull/5617
-            module.weight.data.normal_(mean=0.0, std=0.02)
-            if module.bias is not None:
-                module.bias.data.zero_()
-        elif isinstance(module, nn.Embedding):
-            module.weight.data.normal_(mean=0.0, std=0.02)
-            if module.padding_idx is not None:
-                module.weight.data[module.padding_idx].zero_()
-        elif isinstance(module, nn.LayerNorm):
-            module.bias.data.zero_()
-            module.weight.data.fill_(1.0)
-
-    def save_pretrained(self,
-                        target_folder: Union[str, os.PathLike],
-                        save_checkpoint_names: Union[str, List[str]] = None,
-                        save_function: Callable = partial(
-                            save_checkpoint, with_meta=False),
-                        config: Optional[dict] = None,
-                        save_config_function: Callable = save_configuration,
-                        **kwargs):
-        """save the pretrained model, its configuration and other related files to a directory,
-            so that it can be re-loaded
-
         Args:
-            target_folder (Union[str, os.PathLike]):
-            Directory to which to save. Will be created if it doesn't exist.
-
-            save_checkpoint_names (Union[str, List[str]]):
-            The checkpoint names to be saved in the target_folder
-
-            save_function (Callable, optional):
-            The function to use to save the state dictionary.
-
-            config (Optional[dict], optional):
-            The config for the configuration.json, might not be identical with model.config
-
-            save_config_function (Callble, optional):
-            The function to use to save the configuration.
+            img (`torch.Tensor`): batched image tensor,
+                shape of each tensor is [N, 1, H, W].
 
+        Return:
+            `probs [T, N, Classes] of the sequence feature`
         """
-        if config is None and hasattr(self, 'cfg'):
-            config = self.cfg
-
-        save_pretrained(self, target_folder, save_checkpoint_names,
-                        save_function, **kwargs)
+        return self.recognizer(inputs)
 
-        if config is not None:
-            save_config_function(target_folder, config)
-
-    def compile(self, **kwargs):
-        """Compile torch model with torch>=2.0
-
-        Args:
-            kwargs:
-                backend: The backend param of torch.compile
-                mode: The mode param of torch.compile
-        """
-        if version.parse(torch.__version__) >= version.parse('2.0.0.dev'):
-            return torch.compile(self, **kwargs)
+    def do_step(self, batch):
+        inputs = batch['images']
+        labels = batch['labels']
+        bs = inputs.shape[0]
+        if self.do_chunking:
+            inputs = inputs.view(bs * 3, 1, self.target_height, 300)
         else:
-            logger.warning(
-                f'Torch compiling needs torch version >= 2.0.0, your torch version is : {torch.__version__},'
-                f' returns original model')
-            return self
+            inputs = inputs.view(bs, 1, self.target_height, self.target_width)
+        output = self(inputs)
+        probs = output['probs'].permute(1, 0, 2)
+        _, label_length, label_flatten = self.encdec.encode(labels)
+        probs_sizes = torch.IntTensor([probs.size(0)] * probs.size(1))
+        loss = self.criterion_CTC(
+            probs.log_softmax(2), label_flatten, probs_sizes, label_length)
+        output = dict(loss=loss, preds=output['preds'])
+        return output
+
+    def postprocess(self, inputs):
+        outprobs = inputs
+        outprobs = F.softmax(outprobs, dim=-1)
+        preds = torch.argmax(outprobs, -1)
+        batchSize, length = preds.shape
+        final_str_list = []
+        for i in range(batchSize):
+            pred_idx = preds[i].cpu().data.tolist()
+            last_p = 0
+            str_pred = []
+            for p in pred_idx:
+                if p != last_p and p != 0:
+                    str_pred.append(self.labelMapping[p])
+                last_p = p
+            final_str = ''.join(str_pred)
+            final_str_list.append(final_str)
+        return {'preds': final_str_list, 'probs': inputs}
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/builder.py` & `weathon-0.0.0.14/weathon/registry/model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,97 +1,82 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.metainfo import Models
-from modelscope.utils.config import ConfigDict
-from modelscope.utils.constant import Tasks
-from modelscope.utils.import_utils import INDEX_KEY, LazyImportModule
-from modelscope.utils.logger import get_logger
-from modelscope.utils.registry import Registry, build_from_cfg
-from modelscope.utils.task_utils import get_task_by_subtask_name
+from weathon.registry.registry import Registry, build_from_cfg
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.config.config import ConfigDict
+from weathon.utils.logger import get_logger
+from weathon.utils.task_utils import get_task_by_subtask_name
 
 logger = get_logger()
 
 MODELS = Registry('models')
-BACKBONES = MODELS
 HEADS = Registry('heads')
-
-modules = LazyImportModule.AST_INDEX[INDEX_KEY]
-for module_index in list(modules.keys()):
-    if module_index[1] == Tasks.backbone and module_index[0] == 'BACKBONES':
-        modules[(MODELS.name.upper(), module_index[1],
-                 module_index[2])] = modules[module_index]
+BACKBONES = MODELS
+def register_models():
+    from weathon.utils.ast_utils import INDEX_KEY
+    from weathon.utils.import_utils import LazyImportModule
+    modules = LazyImportModule.AST_INDEX[INDEX_KEY]
+    for module_index in list(modules.keys()):
+        if module_index[1] == Tasks.backbone and module_index[0] == 'BACKBONES':
+            modules[(MODELS.name.upper(), module_index[1], module_index[2])] = modules[module_index]
 
 
-def build_model(cfg: ConfigDict,
-                task_name: str = None,
-                default_args: dict = None):
+def build_model(cfg: ConfigDict, task_name: str = None, default_args: dict = None):
     """ build model given model config dict
 
     Args:
         cfg (:obj:`ConfigDict`): config dict for model object.
         task_name (str, optional):  task name, refer to
             :obj:`Tasks` for more details
         default_args (dict, optional): Default initialization arguments.
     """
     try:
-        model = build_from_cfg(
-            cfg, MODELS, group_key=task_name, default_args=default_args)
+        model = build_from_cfg(cfg, MODELS, group_key=task_name, default_args=default_args)
     except KeyError as e:
         # Handle subtask with a backbone model that hasn't been registered
         # All the subtask with a parent task should have a task model, otherwise it is not a
         # valid subtask
         parent_task, task_model_type = get_task_by_subtask_name(task_name)
         if task_model_type is None:
             raise KeyError(e)
         cfg['type'] = task_model_type
-        model = build_from_cfg(
-            cfg, MODELS, group_key=parent_task, default_args=default_args)
+        model = build_from_cfg(cfg, MODELS, group_key=parent_task, default_args=default_args)
     return model
 
 
-def build_backbone(cfg: ConfigDict, default_args: dict = None):
+def build_backbone(cfg: ConfigDict, task_name:str = Tasks.backbone, default_args: dict = None):
     """ build backbone given backbone config dict
 
     Args:
         cfg (:obj:`ConfigDict`): config dict for backbone object.
         default_args (dict, optional): Default initialization arguments.
     """
     if not cfg.get('init_backbone', False):
         model_dir = cfg.pop('model_dir', None)
     else:
         model_dir = cfg.get('model_dir', None)
-
     try:
-        model = build_from_cfg(
-            cfg,
-            BACKBONES,
-            group_key=Tasks.backbone,
-            default_args=default_args)
+        model = build_from_cfg(cfg, BACKBONES, group_key=task_name, default_args=default_args)
     except KeyError:
         # Handle backbone that is not in the register group by using transformers AutoModel.
         # AutoModel are mostly using in NLP and part of Multi-Modal, while the number of backbone in CVAudio and MM
-        # is limited, thus could be added and registered in Modelscope directly
-        logger.warning(
-            f'The backbone {cfg.type} is not registered in modelscope, try to import the backbone from hf transformers.'
-        )
+        # is limited, thus could be added and registered in weathon directly
+        logger.warning(f'The backbone {cfg.type} is not registered in weathon, try to import the backbone from hf transformers.')
         cfg['type'] = Models.transformers
         cfg['model_dir'] = model_dir
-        model = build_from_cfg(
-            cfg,
-            BACKBONES,
-            group_key=Tasks.backbone,
-            default_args=default_args)
+        model = build_from_cfg(cfg, BACKBONES, group_key=task_name, default_args=default_args)
     return model
 
 
-def build_head(cfg: ConfigDict,
-               task_name: str = None,
-               default_args: dict = None):
+def build_head(cfg: ConfigDict, task_name: str = None, default_args: dict = None):
     """ build head given config dict
 
     Args:
         cfg (:obj:`ConfigDict`): config dict for head object.
         task_name (str, optional):  task name, refer to
             :obj:`Tasks` for more details
         default_args (dict, optional): Default initialization arguments.
     """
-    return build_from_cfg(
-        cfg, HEADS, group_key=task_name, default_args=default_args)
+    return build_from_cfg(cfg, HEADS, group_key=task_name, default_args=default_args)
+
+
+
+register_models
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 # yapf: disable
 from . import (action_recognition, animal_recognition, bad_image_detecting,
                body_2d_keypoints, body_3d_keypoints, cartoon,
                cmdssl_video_embedding, controllable_image_generation,
                crowd_counting, face_detection, face_generation,
                face_reconstruction, human_reconstruction, image_classification,
                image_color_enhance, image_colorization, image_defrcn_fewshot,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_model.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,68 +1,58 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from .mmdet_ms import MaskScoringNRoIHead, SingleRoINExtractor
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from .mmdet_ms.backbones import ViT
+from .mmdet_ms.dense_heads import RPNNHead
+from .mmdet_ms.necks import FPNF
+from .mmdet_ms.roi_heads import FCNMaskNHead, Shared4Conv1FCBBoxNHead
 
 
+@MODELS.register_module(Tasks.human_detection, module_name=Models.detection)
 @MODELS.register_module(
-    Tasks.image_object_detection, module_name=Models.mask_scoring)
-class AbnormalDetectionModel(TorchModel):
+    Tasks.image_object_detection, module_name=Models.detection)
+class DetectionModel(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """str -- model file root."""
         super().__init__(model_dir, *args, **kwargs)
 
         from mmcv.runner import load_checkpoint
         from mmdet.datasets import replace_ImageToTensor
         from mmdet.datasets.pipelines import Compose
         from mmdet.models import build_detector
 
         model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)
         config_path = osp.join(model_dir, 'mmcv_config.py')
         config = Config.from_file(config_path)
         config.model.pretrained = None
-        self.model = build_detector(
-            config.model, test_cfg=config.get('test_cfg'))
+        self.model = build_detector(config.model)
 
         checkpoint = load_checkpoint(
             self.model, model_path, map_location='cpu')
         self.class_names = checkpoint['meta']['CLASSES']
         config.test_pipeline[0].type = 'LoadImageFromWebcam'
         self.transform_input = Compose(
             replace_ImageToTensor(config.test_pipeline))
         self.model.cfg = config
         self.model.eval()
         self.score_thr = config.score_thr
 
     def inference(self, data):
-        """data is dict,contain img and img_metas,follow with mmdet.
-        Args:
-            imgs (List[Tensor]): the outer list indicates test-time
-                augmentations and inner Tensor should have a shape NxCxHxW,
-                which contains all images in the batch.
-            img_metas (List[List[dict]]): the outer list indicates test-time
-                augs (multiscale, flip, etc.) and the inner list indicates
-                images in a batch.
-        """
+        """data is dict,contain img and img_metas,follow with mmdet."""
 
         with torch.no_grad():
-            results = self.model(
-                return_loss=False,
-                rescale=True,
-                img=data['img'],
-                img_metas=data['img_metas'])
+            results = self.model(return_loss=False, rescale=True, **data)
         return results
 
     def preprocess(self, image):
         """image is numpy return is dict contain img and img_metas,follow with mmdet."""
 
         from mmcv.parallel import collate, scatter
         data = dict(img=image)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py` & `weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py` & `weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/action_detection/action_detection_onnx.py` & `weathon-0.0.0.14/weathon/models/cv/action_detection/action_detection_onnx.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,28 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import os.path as osp
-import shutil
 import subprocess
 import uuid
 from tempfile import TemporaryDirectory
 from urllib.parse import urlparse
 
 import cv2
 import numpy as np
 import onnxruntime as rt
 
-from modelscope.hub.file_download import http_get_file
-from modelscope.models import Model
-from modelscope.utils.constant import Devices
-from modelscope.utils.device import verify_device
+from weathon.base import BaseModel
+# from weathon.utils.hub import http_get_file
+# from weathon.models import Model
+# from weathon.utils.constant import Devices
+from weathon.utils.device import verify_device
+from weathon.utils.hub.file_download import http_get_file
 
 
-class ActionDetONNX(Model):
+class ActionDetONNX(BaseModel):
 
     def __init__(self, model_dir, config, *args, **kwargs):
         super().__init__(self, model_dir, *args, **kwargs)
         model_file = osp.join(config['model_file'])
         device_type, device_id = verify_device(self._device_name)
         options = rt.SessionOptions()
         op_num_threads = config.get('op_num_threads', 1)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/action_detection/modules/action_detection_pytorch.py` & `weathon-0.0.0.14/weathon/models/cv/action_detection/modules/action_detection_pytorch.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import logging
 from typing import Dict, List
 
 import torch
 import torch.nn as nn
 from detectron2.layers import ShapeSpec
 from detectron2.modeling import postprocessing
@@ -11,15 +9,15 @@
 from detectron2.modeling.box_regression import _dense_box_regression_loss
 from detectron2.modeling.meta_arch.fcos import FCOS, FCOSHead
 from detectron2.structures import (Boxes, ImageList, Instances,
                                    pairwise_point_box_distance)
 from fvcore.nn import sigmoid_focal_loss_jit
 from torch.nn import functional as F
 
-from modelscope.models.base import TorchModel
+from weathon.base import TorchModel
 from .resnet import Bottleneck3D, ResNet3D
 
 logger = logging.getLogger('detectron2.modelscope.' + __name__)
 
 
 class ActionDetector(FCOS, TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/action_detection/modules/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/action_detection/modules/resnet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 from detectron2.modeling import Backbone
 
 
 def conv1x3x3(in_planes, out_planes, stride=(1, 1, 1)):
     return nn.Conv3d(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/action_recognition/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
 
     from .models import BaseVideoModel
     from .tada_convnext import TadaConvNeXt
     from .temporal_patch_shift_transformer import PatchShiftTransformer
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/models.py` & `weathon-0.0.0.14/weathon/models/cv/action_recognition/models.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/s3dg.py` & `weathon-0.0.0.14/weathon/models/cv/action_recognition/s3dg.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/tada_convnext.py` & `weathon-0.0.0.14/weathon/models/cv/action_recognition/tada_convnext.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/action_recognition/temporal_patch_shift_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/action_recognition/temporal_patch_shift_transformer.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 import torch.nn as nn
 import torch.nn.functional as F
 import torch.utils.checkpoint as checkpoint
 import torchvision.transforms as T
 from einops import rearrange
 from timm.models.layers import DropPath, Mlp, trunc_normal_
 
-from modelscope.models import TorchModel
+from weathon.base import TorchModel
 
 
 def normal_init(module, mean=0., std=1., bias=0.):
     if hasattr(module, 'weight') and module.weight is not None:
         nn.init.normal_(module.weight, mean, std)
     if hasattr(module, 'bias') and module.bias is not None:
         nn.init.constant_(module.bias, bias)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/animal_recognition/__init__.py` & `weathon-0.0.0.14/weathon/hooks/compression/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-
-    from .resnet import ResNet, Bottleneck
-    from .splat import SplAtConv2d
+    from .sparsity_hook import SparsityHook
+    from .utils import SparseLinear, convert_sparse_network
 
 else:
     _import_structure = {
-        'resnet': ['ResNet', 'Bottleneck'],
-        'splat': ['SplAtConv2d']
+        'sparsity_hook': ['SparsityHook'],
+        'utils': ['convert_sparse_network', 'SparseLinear'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/animal_recognition/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/animal_recognition/resnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/animal_recognition/splat.py` & `weathon-0.0.0.14/weathon/models/cv/animal_recognition/splat.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/bad_image_detecting/bad_image_detecting.py` & `weathon-0.0.0.14/weathon/models/cv/bad_image_detecting/bad_image_detecting.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,31 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from typing import Any, Dict, Union
+from typing import Dict, Union
 
-import numpy as np
 import torch.cuda
 from torchvision import models
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
+from weathon.utils.typing import Tensor
 
 logger = get_logger()
 
 __all__ = ['BadImageDetecting']
 
 
-@MODELS.register_module(
-    Tasks.bad_image_detecting, module_name=Models.bad_image_detecting)
+@MODELS.register_module(Tasks.bad_image_detecting, module_name=Models.bad_image_detecting)
 class BadImageDetecting(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the image_quality_assessment_mos model from the `model_dir` path.
 
         Args:
             model_dir (str): the model path.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_2d_keypoints/hrnet_basic_modules.py` & `weathon-0.0.0.14/weathon/models/cv/body_2d_keypoints/hrnet_basic_modules.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_2d_keypoints/hrnet_v2.py` & `weathon-0.0.0.14/weathon/models/cv/body_2d_keypoints/hrnet_v2.py`

 * *Files 13% similar despite different names*

```diff
@@ -3,25 +3,24 @@
 import os
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.body_2d_keypoints.hrnet_basic_modules import (
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.cv.body_2d_keypoints.hrnet_basic_modules import (
     BN_MOMENTUM, BasicBlock, Bottleneck, HighResolutionModule, blocks_dict)
-from modelscope.models.cv.body_2d_keypoints.w48 import cfg_128x128_15
-from modelscope.utils.constant import Tasks
+from weathon.models.cv.body_2d_keypoints.w48 import cfg_128x128_15
 
 
-@MODELS.register_module(
-    Tasks.body_2d_keypoints, module_name=Models.body_2d_keypoints)
+@MODELS.register_module(Tasks.body_2d_keypoints, module_name=Models.body_2d_keypoints)
 class PoseHighResolutionNetV2(TorchModel):
 
     def __init__(self, cfg=None, **kwargs):
         if cfg is None:
             cfg = cfg_128x128_15
         self.inplanes = 64
         extra = cfg['MODEL']['EXTRA']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_2d_keypoints/w48.py` & `weathon-0.0.0.14/weathon/models/cv/body_2d_keypoints/w48.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .cannonical_pose import BodyKeypointsDetection3D
     from .hdformer import HDFormerDetector
 else:
     _import_structure = {
         'cannonical_pose': ['BodyKeypointsDetection3D'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,37 +1,34 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import logging
 import os.path as osp
 from typing import Any, Dict, List, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.body_3d_keypoints.cannonical_pose.canonical_pose_modules import (
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.models.cv.body_3d_keypoints.cannonical_pose.canonical_pose_modules import (
     TemporalModel, TransCan3Dkeys)
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['BodyKeypointsDetection3D']
 
 
 class KeypointsTypes(object):
     POSES_CAMERA = 'poses_camera'
     POSES_TRAJ = 'poses_traj'
 
 
-@MODELS.register_module(
-    Tasks.body_3d_keypoints, module_name=Models.body_3d_keypoints)
+@MODELS.register_module(Tasks.body_3d_keypoints, module_name=Models.body_3d_keypoints)
 class BodyKeypointsDetection3D(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
 
         super().__init__(model_dir, *args, **kwargs)
 
         self.model_dir = model_dir
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/backbone.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/backbone.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,19 +2,19 @@
 # The implementation is also open-sourced by the authors as Hanyuan Chen, and is available publicly on
 # https://github.com/hyer/HDFormer
 # --------------------------------------------------------
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.body_3d_keypoints.hdformer.block import \
+from weathon.models.cv.body_3d_keypoints.hdformer.block import \
     HightOrderAttentionBlock
-from modelscope.models.cv.body_3d_keypoints.hdformer.directed_graph import (
+from weathon.models.cv.body_3d_keypoints.hdformer.directed_graph import (
     DiGraph, Graph)
-from modelscope.models.cv.body_3d_keypoints.hdformer.skeleton import \
+from weathon.models.cv.body_3d_keypoints.hdformer.skeleton import \
     get_skeleton
 
 
 class HDFormerNet(nn.Module):
 
     def __init__(self, cfg):
         super(HDFormerNet, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/block.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/block.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/directed_graph.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/directed_graph.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import sys
 from typing import List, Tuple
 
 import numpy as np
 
 sys.path.insert(0, './')
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/hdformer.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/hdformer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.body_3d_keypoints.hdformer.backbone import \
+from weathon.models.cv.body_3d_keypoints.hdformer.backbone import \
     HDFormerNet
 
 
 class HDFormer(nn.Module):
 
     def __init__(self, cfg):
         super(HDFormer, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,33 +1,31 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
-from typing import Any, Dict, List, Union
+from typing import Any, Dict
 
 import numpy as np
 import torch
 import torch.backends.cudnn as cudnn
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.body_3d_keypoints.hdformer.hdformer import HDFormer
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.models.cv.body_3d_keypoints.hdformer.hdformer import HDFormer
+from weathon.utils.config.config import Config
+from weathon.utils.logger import get_logger
 
 
 class KeypointsTypes(object):
     POSES_CAMERA = 'poses_camera'
 
 
 logger = get_logger()
 
 
-@MODELS.register_module(
-    Tasks.body_3d_keypoints, module_name=Models.body_3d_keypoints_hdformer)
+@MODELS.register_module(Tasks.body_3d_keypoints, module_name=Models.body_3d_keypoints_hdformer)
 class HDFormerDetector(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         super().__init__(model_dir, *args, **kwargs)
         self.model_dir = model_dir
 
         cudnn.benchmark = True
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/body_3d_keypoints/hdformer/skeleton.py` & `weathon-0.0.0.14/weathon/models/cv/body_3d_keypoints/hdformer/skeleton.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .facelib.facer import FaceAna
     from .mtcnn_pytorch.src.align_trans import (get_reference_facial_points,
                                                 warp_and_crop_face)
     from .utils import (get_f5p, padTo16x, resize_size, all_file,
                         tf_data_loader, write_batch_image)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/LK/lk.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/LK/lk.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # The implementation is adopted from https://github.com/610265158/Peppa_Pig_Face_Engine
 
 import numpy as np
 
-from modelscope.models.cv.cartoon.facelib.config import config as cfg
+from weathon.models.cv.cartoon.facelib.config import config as cfg
 
 
 class GroupTrack():
 
     def __init__(self):
         self.old_frame = None
         self.previous_landmarks_set = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/config.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/config.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/face_detector.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/face_detector.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/face_landmark.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/face_landmark.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/facelib/facer.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/facelib/facer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/loss.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/loss.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/model_tf.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/model_tf.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict
 
 import tensorflow as tf
 
-from modelscope.models.base import Model, Tensor
+from weathon.base import BaseModel, Tensor
 from .loss import content_loss, guided_filter, style_loss, total_variation_loss
 from .network import unet_generator
 
 
 class CartoonModel(Model):
 
     def __init__(self, model_dir, *args, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/network.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/network.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cartoon/utils.py` & `weathon-0.0.0.14/weathon/models/cv/cartoon/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import random
 
 import cv2
 import numpy as np
 import tensorflow as tf
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .c3d import C3D
     from .resnet2p1d import resnet26_2p1d
     from .resnet3d import resnet26_3d
 
 else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/c3d.py` & `weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/c3d.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/resnet2p1d.py` & `weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/resnet2p1d.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/cmdssl_video_embedding/resnet3d.py` & `weathon-0.0.0.14/weathon/models/cv/cmdssl_video_embedding/resnet3d.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/annotator.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/annotator.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/api.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/api.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/midas/vit.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/midas/vit.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/midas/utils.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/midas/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/mlsd/utils.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/mlsd/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/body.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/body.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/hand.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/hand.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/model.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/annotator/openpose/util.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/annotator/openpose/util.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/controllable_image_generation/controlnet.py` & `weathon-0.0.0.14/weathon/models/cv/controllable_image_generation/controlnet.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,21 +14,21 @@
 import torch
 import torch.nn as nn
 from control_ldm.cldm.hack import disable_verbosity, enable_sliced_attention
 from control_ldm.cldm.model import create_model, load_state_dict
 from control_ldm.ldm.models.diffusion.ddim import DDIMSampler
 from PIL import Image
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 __all__ = ['ControlNet']
 
 
 @MODELS.register_module(
     Tasks.controllable_image_generation,
     module_name=Models.controllable_image_generation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/crowd_counting/cc_model.py` & `weathon-0.0.0.14/weathon/models/cv/crowd_counting/cc_model.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,18 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
-from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
 
 
 @MODELS.register_module(
     Tasks.crowd_counting, module_name=Models.crowd_counting)
 class HRNetCrowdCounting(TorchModel):
 
     def __init__(self, model_dir: str, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/crowd_counting/hrnet_aspp_relu.py` & `weathon-0.0.0.14/weathon/models/cv/crowd_counting/hrnet_aspp_relu.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 import numpy as np
 import torch
 import torch._utils
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 BN_MOMENTUM = 0.01  # 0.01 for seg
 logger = get_logger()
 
 
 def conv3x3(in_planes, out_planes, stride=1):
     """3x3 convolution with padding"""
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py` & `weathon-0.0.0.14/weathon/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,18 +9,18 @@
 import torch.nn as nn
 import torch.nn.functional as F
 import torchvision
 from PIL import Image
 from torch.autograd import Variable
 from torchvision import datasets, models, transforms
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.face_attribute_recognition, module_name=Models.fairface)
 class FaceAttributeRecognition(TorchModel):
 
     def __init__(self, model_path, device='cuda'):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .mogface import MogFaceDetector
     from .mtcnn import MtcnnFaceDetector
     from .retinaface import RetinaFaceDetection
     from .ulfd_slim import UlfdFaceDetector
     from .scrfd import ScrfdDetect
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/detectors.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/detectors.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,19 @@
 # The implementation is based on MogFace, available at
 # https://github.com/damo-cv/MogFace
-import os
 
 import cv2
 import numpy as np
 import torch
 import torch.backends.cudnn as cudnn
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
 from .mogface import MogFace
 from .utils import MogPriorBox, mogdecode, py_cpu_nms
 
 
 @MODELS.register_module(Tasks.face_detection, module_name=Models.mogface)
 class MogFaceDetector(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/mogface.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/mogface.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/mogprednet.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/mogprednet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/resnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mogface/models/utils.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mogface/models/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/box_utils.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/box_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/detector.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/detector.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,18 +3,18 @@
 
 import numpy as np
 import torch
 import torch.backends.cudnn as cudnn
 from PIL import Image
 from torch.autograd import Variable
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
 from .box_utils import calibrate_box, convert_to_square, get_image_boxes, nms
 from .first_stage import run_first_stage
 from .get_nets import ONet, PNet, RNet
 
 
 @MODELS.register_module(Tasks.face_detection, module_name=Models.mtcnn)
 class MtcnnFaceDetector(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/first_stage.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/first_stage.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/mtcnn/models/get_nets.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/mtcnn/models/get_nets.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/LK/lk.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/LK/lk.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/face_detector.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/face_detector.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/face_landmark.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/face_landmark.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/peppa_pig_face/facer.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/peppa_pig_face/facer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/detection.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/detection.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 # The implementation is based on resnet, available at https://github.com/biubug6/Pytorch_Retinaface
 import cv2
 import numpy as np
 import torch
 import torch.backends.cudnn as cudnn
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .models.retinaface import RetinaFace
 from .utils import PriorBox, decode, decode_landm, py_cpu_nms
 
 
 @MODELS.register_module(Tasks.face_detection, module_name=Models.retinaface)
 class RetinaFaceDetection(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/models/net.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/models/net.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/models/retinaface.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/models/retinaface.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/retinaface/utils.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 import torch
 import torch.nn.functional as F
 from mmdet.models.builder import BACKBONES
 from torch import nn
 
-from modelscope.models.cv.tinynas_classfication import (basic_blocks,
+from weathon.models.cv.tinynas_classfication import (basic_blocks,
                                                         plain_net_utils)
 
 
 @BACKBONES.register_module()
 class MasterNet(plain_net_utils.PlainNet):
 
     def __init__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/preprocessor.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/preprocessor.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Union
 
 import numpy as np
 from PIL import Image
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.constant import Fields, ModeKeys
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.constants import Fields, ModeKeys
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.object_detection_scrfd)
-class SCRFDPreprocessor(Preprocessor):
+class SCRFDPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str = None, mode: str = ModeKeys.INFERENCE):
         """The base constructor for all the fill-mask preprocessors.
 
         Args:
             model_dir (str): model directory to initialize some resource
             mode: The mode for the preprocessor.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/scrfd_detect.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/scrfd_detect.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,22 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
-from copy import deepcopy
 from typing import Any, Dict, List, Union
 
-import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.outputs.cv_outputs import DetectionOutput
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.output.cv_outputs import DetectionOutput
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ScrfdDetect']
 
 
 @MODELS.register_module(Tasks.face_detection, module_name=Models.scrfd)
@@ -30,19 +27,14 @@
             model_dir (str): the model path.
         """
         super().__init__(model_dir, *args, **kwargs)
         from mmcv import Config
         from mmcv.parallel import MMDataParallel
         from mmcv.runner import load_checkpoint
         from mmdet.models import build_detector
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets import RetinaFaceDataset
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import RandomSquareCrop
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones import ResNetV1e
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.dense_heads import SCRFDHead
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors import SCRFD
         cfg_file = kwargs.get('config_file', 'mmcv_scrfd.py')
         cfg = Config.fromfile(osp.join(model_dir, cfg_file))
         model_file = kwargs.get('model_file', ModelFile.TORCH_MODEL_BIN_FILE)
         ckpt_path = osp.join(model_dir, model_file)
         cfg.model.test_cfg.score_thr = kwargs.get('score_thr', 0.3)
         detector = build_detector(cfg.model)
         logger.info(f'loading model from {ckpt_path}')
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/scrfd/tinymog_detect.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/scrfd/damofd_detect.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,31 +1,30 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from copy import deepcopy
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .scrfd_detect import ScrfdDetect
 
 logger = get_logger()
 
-__all__ = ['TinyMogDetect']
+__all__ = ['DamoFdDetect']
 
 
-@MODELS.register_module(Tasks.face_detection, module_name=Models.tinymog)
-class TinyMogDetect(ScrfdDetect):
+@MODELS.register_module(Tasks.face_detection, module_name=Models.damofd)
+class DamoFdDetect(ScrfdDetect):
 
     def __init__(self, model_dir, *args, **kwargs):
         """
         initialize the tinymog face detection model from the `model_dir` path.
         """
-        config_file = 'mmcv_tinymog.py'
+        config_file = 'DamoFD_lms.py'
         kwargs['config_file'] = config_file
         kwargs['model_file'] = ModelFile.TORCH_MODEL_FILE
         super().__init__(model_dir, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/box_utils.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/box_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_detection/ulfd_slim/vision/transforms.py` & `weathon-0.0.0.14/weathon/models/cv/face_detection/ulfd_slim/vision/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/face_emotion/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .emotion_model import EfficientNetForFaceEmotion
 
 else:
     _import_structure = {'emotion_model': ['EfficientNetForFaceEmotion']}
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/efficient/model.py` & `weathon-0.0.0.14/weathon/models/cv/face_emotion/efficient/model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/efficient/utils.py` & `weathon-0.0.0.14/weathon/models/cv/face_emotion/efficient/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/emotion_infer.py` & `weathon-0.0.0.14/weathon/models/cv/face_emotion/emotion_infer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 import torch
 from PIL import Image
 from torch import nn
 from torchvision import transforms
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 from .face_alignment.face_align import face_detection_PIL_v2
 
 logger = get_logger()
 
 
 def transform_PIL(img_pil):
     val_transforms = transforms.Compose([
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/emotion_model.py` & `weathon-0.0.0.14/weathon/models/cv/face_emotion/emotion_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,18 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
-import os
-import sys
 
 import torch
-import torch.nn.functional as F
 from torch import nn
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.face_emotion.efficient import EfficientNet
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.face_emotion.efficient import EfficientNet
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @MODELS.register_module(Tasks.face_emotion, module_name=Models.face_emotion)
 class EfficientNetForFaceEmotion(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/face_alignment/face.py` & `weathon-0.0.0.14/weathon/models/cv/face_emotion/face_alignment/face.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_emotion/face_alignment/face_align.py` & `weathon-0.0.0.14/weathon/models/cv/face_emotion/face_alignment/face_align.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_generation/op/conv2d_gradfix.py` & `weathon-0.0.0.14/weathon/models/cv/face_generation/op/conv2d_gradfix.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_generation/op/fused_act.py` & `weathon-0.0.0.14/weathon/models/cv/face_generation/op/fused_act.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_generation/op/upfirdn2d.py` & `weathon-0.0.0.14/weathon/models/cv/face_generation/op/upfirdn2d.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_generation/stylegan2.py` & `weathon-0.0.0.14/weathon/models/cv/face_generation/stylegan2.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_degradation/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,19 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .det_infer import NanoDetForFaceHumanHandDetection
+    from .image_quality_assessment_degradation import ImageQualityAssessmentDegradation
 
 else:
-    _import_structure = {'det_infer': ['NanoDetForFaceHumanHandDetection']}
+    _import_structure = {
+        'image_quality_assessment_degradation':
+        ['ImageQualityAssessmentDegradation']
+    }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/det_infer.py` & `weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/det_infer.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .one_stage_detector import OneStageDetector
 
 logger = get_logger()
 
 
 def load_model_weight(model_dir, device):
     checkpoint = torch.load(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/ghost_pan.py` & `weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/ghost_pan.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/nanodet_plus_head.py` & `weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/nanodet_plus_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/one_stage_detector.py` & `weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/one_stage_detector.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/shufflenetv2.py` & `weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/shufflenetv2.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_human_hand_detection/utils.py` & `weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/align_face.py` & `weathon-0.0.0.14/weathon/models/cv/face_recognition/align_face.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py` & `weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/common.py` & `weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/common.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py` & `weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/model_irse.py` & `weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/model_irse.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/backbone/model_resnet.py` & `weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/backbone/model_resnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_recognition/torchkit/rts_backbone.py` & `weathon-0.0.0.14/weathon/models/cv/face_recognition/torchkit/rts_backbone.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from collections import namedtuple
 from math import lgamma
 
 import torch
 import torch.nn as nn
 from torch.nn import (AdaptiveAvgPool2d, BatchNorm1d, BatchNorm2d, Conv2d,
                       Dropout, Linear, MaxPool2d, Module, PReLU, ReLU,
                       Sequential, Sigmoid)
 from torch.nn.modules.flatten import Flatten
 
-from modelscope.models import MODELS
-from modelscope.models.base import TorchModel
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.models import MODELS
+from weathon.models.base import TorchModel
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @MODELS.register_module('face-recognition', 'rts-backbone')
 class RTSBackbone(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/bfm.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/bfm.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/de_retouching_module.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/de_retouching_module.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 
 from .unet import UNet
 
 
 class DeRetouchingModule():
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 
 from .nets.large_base_lmks_net import LargeBaseLmksNet
 
 BASE_LANDMARK_NUM = 106
 INPUT_SIZE = 224
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 from torch.nn import functional as F
 
 INPUT_SIZE = 224
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch.nn as nn
 
 FACE_PART_SIZE = 56
 
 
 class InvertedResidual(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/facerecon_model.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/facerecon_model.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from collections import OrderedDict
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.models import MODELS, TorchModel
-from modelscope.models.cv.face_reconstruction.models import opt
+from weathon.models import MODELS, TorchModel
+from weathon.models.cv.face_reconstruction.models import opt
 from .. import utils
 from . import networks
 from .bfm import ParametricFaceModel
 from .de_retouching_module import DeRetouchingModule
 from .losses import TVLoss, photo_loss
 from .nv_diffrast import MeshRenderer
 from .pix2pix.pix2pix_model import Pix2PixModel
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/losses.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/losses.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from kornia.geometry import warp_affine
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/networks.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/networks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/nv_diffrast.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/nv_diffrast.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/pix2pix/networks.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/pix2pix/networks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 class Pix2PixOptions():
 
     def __init__(self):
         self.gpu_ids = []
         self.input_nc = 3
         self.output_nc = 3
         self.ngf = 64
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/renderer.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/renderer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/models/unet.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/models/unet.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import warnings
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 warnings.filterwarnings(action='ignore')
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/face_reconstruction/utils.py` & `weathon-0.0.0.14/weathon/models/cv/face_reconstruction/utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import argparse
 import math
 import os
 import os.path as osp
 from array import array
 
 import cv2
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py` & `weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,18 +6,18 @@
 import numpy as np
 import torch
 import torch.backends.cudnn as cudnn
 import torch.nn.functional as F
 from PIL import Image
 from torch.autograd import Variable
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 from . import transforms
 from .vgg import VGG
 
 
 @MODELS.register_module(
     Tasks.facial_expression_recognition, module_name=Models.fer)
 class FacialExpressionRecognition(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/fer/transforms.py` & `weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/fer/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/facial_expression_recognition/fer/vgg.py` & `weathon-0.0.0.14/weathon/models/cv/facial_expression_recognition/fer/vgg.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # The implementation is based on Facial-Expression-Recognition, available at
 # https://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torch.autograd import Variable
 
-from modelscope.utils.config import Config
+from weathon.utils.config.config import Config
 
 
 class VGG(nn.Module):
 
     def __init__(self, vgg_name, cfg_path):
         super(VGG, self).__init__()
         model_cfg = Config.from_file(cfg_path)['models']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py` & `weathon-0.0.0.14/weathon/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
 import cv2
 import numpy as np
 import torch
 import torch.backends.cudnn as cudnn
 import torch.nn.functional as F
 from PIL import Image
 from torch.autograd import Variable
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 from .manual_landmark_net import LandmarkConfidence
 
 
 @MODELS.register_module(Tasks.face_2d_keypoints, module_name=Models.flc)
 class FacialLandmarkConfidence(TorchModel):
 
     def __init__(self, model_path, device='cuda'):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py` & `weathon-0.0.0.14/weathon/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 
 import torch
 import torch.nn.functional as F
 from torch.nn import (AdaptiveAvgPool2d, BatchNorm2d, Conv2d, Linear,
                       MaxPool2d, Module, Parameter, ReLU, Sequential)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/hand_static/networks.py` & `weathon-0.0.0.14/weathon/models/cv/hand_static/networks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/Reconstruction.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/Reconstruction.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,32 +1,31 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Optional
 
 import cv2
 import numpy as np
 import PIL.Image as Image
 import torch
 import torchvision.transforms as transforms
 from skimage.io import imread
 from skimage.transform import estimate_transform, warp
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.human_reconstruction.models.detectors import \
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.human_reconstruction.models.detectors import \
     FasterRCNN
-from modelscope.models.cv.human_reconstruction.models.human_segmenter import \
+from weathon.models.cv.human_reconstruction.models.human_segmenter import \
     human_segmenter
-from modelscope.models.cv.human_reconstruction.models.networks import define_G
-from modelscope.models.cv.human_reconstruction.models.PixToMesh import \
+from weathon.models.cv.human_reconstruction.models.networks import define_G
+from weathon.models.cv.human_reconstruction.models.PixToMesh import \
     Pixto3DNet
-from modelscope.models.cv.human_reconstruction.utils import create_grid
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.models.cv.human_reconstruction.utils import create_grid
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @MODELS.register_module(
     Tasks.human_reconstruction, module_name=Models.human_reconstruction)
 class HumanReconstruction(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/Embedding.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/Embedding.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 from torch import nn
 
 
 class Embedding(nn.Module):
 
     def __init__(self, in_channels, N_freqs, logscale=True):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/PixToMesh.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/PixToMesh.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
 from .Embedding import Embedding
 from .geometry import index, orthogonal, perspective
 from .Res_backbone import Res_hournet
 from .Surface_head import Surface_Head
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/Res_backbone.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/Res_backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 class BlurPool(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/Surface_head.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/Surface_head.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 class Surface_Head(nn.Module):
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/detectors.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/detectors.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/geometry.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/geometry.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/human_segmenter.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/human_segmenter.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/models/networks.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/models/networks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/human_reconstruction/utils.py` & `weathon-0.0.0.14/weathon/models/cv/human_reconstruction/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_binary_quant_classification/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,18 +1,20 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
+
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .binary_quant_model import BinaryQuantClassificationModel
+
+    from .model_translation import UNet
 
 else:
     _import_structure = {
-        'binary_quant_model': ['BinaryQuantClassificationModel'],
+        'image_to_image_translation_model': ['UNet'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_binary_quant_classification/binary_quant_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_binary_quant_classification/binary_quant_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from collections import OrderedDict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.hub import read_config
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .bnext import BNext
 
 logger = get_logger()
 
 __all__ = ['BinaryQuantClassificationModel']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_binary_quant_classification/bnext.py` & `weathon-0.0.0.14/weathon/models/cv/image_binary_quant_classification/bnext.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/image_body_reshaping.py` & `weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/image_body_reshaping.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from typing import Any, Dict
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .model import FlowGenerator
 from .person_info import PersonInfo
 from .pose_estimator.body import Body
 from .slim_utils import image_warp_grid1, resize_on_long_side
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/model.py` & `weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/model.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 class ConvLayer(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/person_info.py` & `weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/person_info.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import copy
 
 import cv2
 import numpy as np
 import torch
 
 from .slim_utils import (enlarge_box_tblr, gen_skeleton_map,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/pose_estimator/body.py` & `weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/pose_estimator/body.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/pose_estimator/model.py` & `weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/pose_estimator/model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/pose_estimator/util.py` & `weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/pose_estimator/util.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_body_reshaping/slim_utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_body_reshaping/slim_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 import os
 import random
 
 import cv2
 import numba
 import numpy as np
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_classification/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .mmcls_model import ClassificationModel
-    from .resnet50_cc import ContentCheckBackbone
-
+    from .configuration import PlugNLGConfig
+    from .backbone import PlugModel
+    from .distributed_plug import DistributedPlug
 else:
     _import_structure = {
-        'mmcls_model': ['ClassificationModel'],
-        'resnet50_cc': ['ContentCheckBackbone'],
+        'configuration': ['PlugNLGConfig'],
+        'backbone': ['PlugModel'],
+        'distributed_plug': ['DistributedPlug'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_classification/backbones/beit_v2.py` & `weathon-0.0.0.14/weathon/models/cv/image_classification/backbones/beit_v2.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_classification/backbones/nextvit.py` & `weathon-0.0.0.14/weathon/models/cv/image_classification/backbones/nextvit.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_classification/mmcls_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_classification/mmcls_model.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.image_classification, module_name=Models.classification_model)
 class ClassificationModel(TorchModel):
 
     def __init__(self, model_dir: str, **kwargs):
         import mmcv
         from mmcls.models import build_classifier
-        import modelscope.models.cv.image_classification.backbones
-        from modelscope.utils.hub import read_config
+        from weathon.utils.hub.utils import read_config
 
         super().__init__(model_dir)
 
         self.config_type = 'ms_config'
         mm_config = os.path.join(model_dir, 'config.py')
         if os.path.exists(mm_config):
             cfg = mmcv.Config.fromfile(mm_config)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_classification/resnet50_cc.py` & `weathon-0.0.0.14/weathon/models/cv/image_classification/resnet50_cc.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from collections import namedtuple
-from math import lgamma
 
 import torch
 import torch.nn as nn
 from torchvision import models
 
-from modelscope.metainfo import Models
-from modelscope.models import MODELS
-from modelscope.models.base import TorchModel
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models import MODELS
+from weathon.models.base import TorchModel
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @MODELS.register_module(Tasks.image_classification, Models.content_check)
 class ContentCheckBackbone(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_classification/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_classification/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import collections.abc
 import math
 import os.path as osp
 from itertools import repeat
 
 import numpy as np
 import torch
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/heads/__init__.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,22 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .image_color_enhance import ImageColorEnhance
-    from .adaint import AdaIntImageColorEnhance
-    from .deeplpf import DeepLPFImageColorEnhance
-
+    from .text_classification_head import TextClassificationHead
+    from .torch_pretrain_head import BertMLMHead, RobertaMLMHead
 else:
     _import_structure = {
-        'image_color_enhance': ['ImageColorEnhance'],
-        'adaint': ['AdaIntImageColorEnhance'],
-        'deeplpf': ['DeepLPFImageColorEnhance']
+        'text_classification_head': ['TextClassificationHead'],
+        'torch_pretrain_head': ['BertMLMHead', 'RobertaMLMHead'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/adaint/adaint.py` & `weathon-0.0.0.14/weathon/models/cv/image_color_enhance/adaint/adaint.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,29 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import numbers
 import os.path as osp
 from typing import Dict, Union
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torchvision
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['AdaIntImageColorEnhance']
 
 try:
-    from modelscope.ops.ailut import ailut_transform
+    from weathon.utils.ops.ailut import ailut_transform
 except ImportError:
     raise ImportError(
         'The model [AdaInt] requires cuda extension to be installed.')
 
 
 class BasicBlock(nn.Sequential):
     r"""The basic block module (Conv+LeakyReLU[+InstanceNorm]).
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/csrnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_color_enhance/csrnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py` & `weathon-0.0.0.14/weathon/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Dict, Union
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .deeplpfnet import DeepLPFNet
 
 logger = get_logger()
 
 __all__ = ['DeepLPFImageColorEnhance']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/deeplpf/deeplpfnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_color_enhance/deeplpf/deeplpfnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_color_enhance/image_color_enhance.py` & `weathon-0.0.0.14/weathon/models/cv/image_color_enhance/image_color_enhance.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Dict, Union
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .csrnet import CSRNet, L1Loss
 
 logger = get_logger()
 
 __all__ = ['ImageColorEnhance']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .unet import DynamicUnetWide, DynamicUnetDeep, NormType
     from .ddcolor import DDColorForImageColorization
 
 else:
     _import_structure = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/ddcolor.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/ddcolor.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
 from .utils.convnext import ConvNeXt
 from .utils.position_encoding import PositionEmbeddingSine
 from .utils.transformer_utils import (MLP, CrossAttentionLayer, FFNLayer,
                                       SelfAttentionLayer)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from copy import deepcopy
 from typing import Dict, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .ddcolor import DDColor
 from .loss import L1Loss
 
 logger = get_logger()
 
 __all__ = ['DDColorForImageColorization']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/loss.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/loss.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/convnext.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/convnext.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/position_encoding.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/position_encoding.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/transformer_utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/transformer_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/unet.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/unet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/ddcolor/utils/vgg.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/ddcolor/utils/vgg.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/unet/unet.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/unet/unet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_colorization/unet/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_colorization/unet/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_debanding/rrdb/rrdb_image_debanding.py` & `weathon-0.0.0.14/weathon/models/cv/image_debanding/rrdb/rrdb_image_debanding.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 '''RRDB debanding network
 This model use rrdbnet to achieve image debanding task.
 Training data is obtained from:
 https://github.com/akshay-kap/Meng-699-Image-Banding-detection
 '''
 import os.path as osp
 from typing import Dict, Union
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.super_resolution import RRDBNet
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.super_resolution import RRDBNet
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['RRDBImageDebanding']
 
 
 @MODELS.register_module(Tasks.image_debanding, module_name=Models.rrdb)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_deblur/nafnet_for_image_deblur.py` & `weathon-0.0.0.14/weathon/models/cv/image_deblur/nafnet_for_image_deblur.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
 import torch.cuda
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_denoise.nafnet.NAFNet_arch import (NAFNet,
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_denoise.nafnet.NAFNet_arch import (NAFNet,
                                                                    PSNRLoss)
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 __all__ = ['NAFNetForImageDeblur']
 
 
 @MODELS.register_module(Tasks.image_deblurring, module_name=Models.nafnet)
 class NAFNetForImageDeblur(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.msdatasets import MsDataset
-from modelscope.utils.config import Config
-from modelscope.utils.constant import DownloadMode, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.msdatasets import MsDataset
+from weathon.utils.config.config import Config
+from weathon.utils.constant import DownloadMode, ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .models.calibration_layer import PrototypicalCalibrationBlock
 from .models.defrcn import DeFRCN
 from .utils.configuration_mapper import CfgMapper
 from .utils.register_data import register_data
 from .utils.requirements_check import requires_version
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/evaluation/evaluator.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/evaluation/evaluator.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/calibration_layer.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/calibration_layer.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 import cv2
 import torch
 from detectron2.data import DatasetMapper, build_detection_test_loader
 from detectron2.modeling.poolers import ROIPooler
 from detectron2.structures import ImageList
 from sklearn.metrics.pairwise import cosine_similarity
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 from .resnet import resnet101
 
 
 class DatasetMapperIns(DatasetMapper):
 
     def __init__(self, cfg, is_train: bool):
         super(DatasetMapperIns, self).__init__(cfg, is_train)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/defrcn.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/defrcn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/fast_rcnn.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/fast_rcnn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/gdl.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/gdl.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/resnet.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 from torchvision.models.resnet import BasicBlock, Bottleneck, ResNet
 
 __all__ = [
     'ResNetFeatures', 'resnet18', 'resnet34', 'resnet50', 'resnet101',
     'resnet152'
 ]
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/models/roi_heads.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/models/roi_heads.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/coco_register.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/coco_register.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # The implementation is adopted from er-muyue/DeFRCN
 # made publicly available under the MIT License at
 # https://github.com/er-muyue/DeFRCN/blob/main/defrcn/config/defaults.py
 
 from detectron2.config.defaults import _C
 
-from modelscope.utils.config import Config
+from weathon.utils.config.config import Config
 
 
 def detectron2_default_cfg():
 
     _CC = _C
 
     # ----------- Backbone ----------- #
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/register_data.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/register_data.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from .coco_register import register_all_coco
 from .voc_register import register_all_voc
 
 
 def register_data(data_type='pascal_voc', data_dir=None):
 
     if data_type == 'pascal_voc':
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/requirements_check.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/requirements_check.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import importlib
 import sys
 from collections import OrderedDict
 
 from packaging import version
 
-from modelscope.utils.import_utils import _torch_available
+from weathon.utils.import_utils import _torch_available
 
 if sys.version_info < (3, 8):
     import importlib_metadata
 else:
     import importlib.metadata as importlib_metadata
 
 DETECTRON2_REQUIRED_VERSION = version.parse('0.3')
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_defrcn_fewshot/utils/voc_register.py` & `weathon-0.0.0.14/weathon/models/cv/image_defrcn_fewshot/utils/voc_register.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,17 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .nafnet_for_image_denoise import NAFNetForImageDenoise
+    from .video_knet import (
+        KNetTrack, )
+    from .neck import MSDeformAttnPixelDecoder
 
 else:
-    _import_structure = {'nafnet_for_image_denoise': ['NAFNetForImageDenoise']}
+    _import_structure = {
+        'video_knet': ['KNetTrack'],
+        'neck': ['MSDeformAttnPixelDecoder']
+    }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/nafnet/NAFNet_arch.py` & `weathon-0.0.0.14/weathon/models/cv/image_denoise/nafnet/NAFNet_arch.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/nafnet/arch_util.py` & `weathon-0.0.0.14/weathon/models/cv/image_denoise/nafnet/arch_util.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_denoise/nafnet_for_image_denoise.py` & `weathon-0.0.0.14/weathon/models/cv/image_denoise/nafnet_for_image_denoise.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
 import torch.cuda
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .nafnet.NAFNet_arch import NAFNet, PSNRLoss
 
 logger = get_logger()
 __all__ = ['NAFNetForImageDenoise']
 
 
 @MODELS.register_module(Tasks.image_denoising, module_name=Models.nafnet)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/newcrf_depth.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/newcrf_depth.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .newcrf_layers import NewCRF
 from .swin_transformer import SwinTransformer
 from .uper_crf_head import PSP
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/newcrf_layers.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/newcrf_layers.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torch.utils.checkpoint as checkpoint
 from timm.models.layers import DropPath, to_2tuple, trunc_normal_
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/newcrf_utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/newcrf_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import os.path as osp
 import pkgutil
 import warnings
 from collections import OrderedDict
 from importlib import import_module
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/swin_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/networks/uper_crf_head.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation/networks/uper_crf_head.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from mmcv.cnn import ConvModule
 
 from .newcrf_utils import normal_init, resize
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation/newcrfs_model.py` & `weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/rcp_model.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,53 +1,63 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_depth_estimation.networks.newcrf_depth import \
-    NewCRFDepth
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
+from .sf_rcp import SF_RCP
+
+logger = get_logger()
 
 
 @MODELS.register_module(
-    Tasks.image_depth_estimation, module_name=Models.newcrfs_depth_estimation)
-class DepthEstimation(TorchModel):
+    Tasks.pointcloud_sceneflow_estimation,
+    module_name=Models.rcp_sceneflow_estimation)
+class SceneFlowEstimation(TorchModel):
 
     def __init__(self, model_dir: str, **kwargs):
         """str -- model file root."""
         super().__init__(model_dir, **kwargs)
 
+        assert torch.cuda.is_available(
+        ), 'current model only support run in gpu'
+
         # build model
-        self.model = NewCRFDepth(
-            version='large07', inv_depth=False, max_depth=10)
+        self.model = SF_RCP(
+            npoint=8192,
+            use_instance_norm=False,
+            model_name='SF_RCP',
+            use_insrance_norm=False,
+            use_curvature=True)
 
         # load model
         model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)
-        checkpoint = torch.load(model_path)
 
-        state_dict = {}
-        for k in checkpoint['model'].keys():
-            if k.startswith('module.'):
-                state_dict[k[7:]] = checkpoint['model'][k]
-            else:
-                state_dict[k] = checkpoint['model'][k]
-        self.model.load_state_dict(state_dict)
+        logger.info(f'load ckpt from:{model_path}')
+
+        checkpoint = torch.load(model_path, map_location='cpu')
+
+        self.model.load_state_dict({k: v for k, v in checkpoint.items()})
+        self.model.cuda()
         self.model.eval()
 
     def forward(self, Inputs):
-        return self.model(Inputs['imgs'])
+
+        return self.model(Inputs['pcd1'], Inputs['pcd2'], Inputs['pcd1'],
+                          Inputs['pcd2'])[-1]
 
     def postprocess(self, Inputs):
-        depth_result = Inputs
+        output = Inputs['output']
+
+        results = {OutputKeys.OUTPUT: output.detach().cpu().numpy()[0]}
 
-        results = {OutputKeys.DEPTHS: depth_result}
         return results
 
     def inference(self, data):
         results = self.forward(data)
 
         return results
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/product_segmentation/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .depth_estimation_bts_model import DepthEstimationBtsModel
+    from .seg_infer import F3NetProductSegmentation
 
 else:
-    _import_structure = {
-        'depth_estimation_bts_model': ['DepthEstimationBtsModel']
-    }
+    _import_structure = {'seg_infer': ['F3NetProductSegmentation']}
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .networks.bts_model import BtsModel
 
 logger = get_logger()
 __all__ = ['DepthEstimationBtsModel']
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/bts_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/bts_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
 from .decoder import Decoder
 from .encoder import Encoder
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/decoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/decoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/encoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/encoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_depth_estimation_bts/networks/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_depth_estimation_bts/networks/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_driving_perception/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .image_driving_percetion_model import YOLOPv2
     from .preprocessor import ImageDrivingPerceptionPreprocessor
     from .utils import (scale_coords, non_max_suppression,
                         split_for_trace_model, driving_area_mask,
                         lane_line_mask)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/image_driving_percetion_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_driving_perception/image_driving_percetion_model.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['YOLOPv2']
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/preprocessor.py` & `weathon-0.0.0.14/weathon/models/cv/image_driving_perception/preprocessor.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Union
+from typing import Any, Dict
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.type_assert import type_assert
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.image_driving_perception_preprocessor)
-class ImageDrivingPerceptionPreprocessor(Preprocessor):
+class ImageDrivingPerceptionPreprocessor(BasePreprocessor):
 
     def __init__(self, mode: str = ModeKeys.INFERENCE, *args, **kwargs):
         """
         Args:
             model_dir (str): model directory to initialize some resource.
             mode: The mode for the preprocessor.
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_driving_perception/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_driving_perception/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/gan_wrap.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/gan_wrap.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
 import cv2
 import numpy as np
 import torch
 import torch.nn.functional as F
 from PIL import Image
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/model.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/op/fused_act.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/op/fused_act.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facegan/op/upfirdn2d.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facegan/op/upfirdn2d.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facelib/align_trans.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facelib/align_trans.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/facelib/matlab_cp2tform.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/facelib/matlab_cp2tform.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/image_face_fusion.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/image_face_fusion.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from collections import OrderedDict
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL.Image as Image
 import torch
 import torch.nn.functional as F
 import torchvision.transforms as transforms
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.face_detection.peppa_pig_face.facer import FaceAna
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.face_detection.peppa_pig_face.facer import FaceAna
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .facegan.gan_wrap import GANWrap
 from .facelib.align_trans import (get_f5p, get_reference_facial_points,
                                   warp_and_crop_face)
 from .network.aei_flow_net import AEI_Net
 from .network.bfm import ParametricFaceModel
 from .network.facerecon_model import ReconNetWrapper
 from .network.model_irse import Backbone
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/aad_layer.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/aad_layer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
 from .ops import SpectralNorm
 
 
 class AADLayer(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/aei_flow_net.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/aei_flow_net.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .aad_layer import AAD_ResBlk
 from .dense_motion import DenseMotionNetwork
 from .ops import SpectralNorm, init_func
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/bfm.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/bfm.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/dense_motion.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/dense_motion.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/facerecon_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/facerecon_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/model_irse.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/model_irse.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_face_fusion/network/ops.py` & `weathon-0.0.0.14/weathon/models/cv/image_face_fusion/network/ops.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn.functional as F
 from torch import nn
 from torch.nn import Parameter
 
 
 def init_func(m, init_type='xavier', gain=0.02):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_human_parsing/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .m2fp_net import M2FP
     from parsing_utils import center_to_target_size_test
 else:
     _import_structure = {
         'm2fp_net': ['M2FP'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/backbone/__init__.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .deeplab_resnet import build_resnet_deeplab_backbone
-
+    from .disco_guided_diffusion import DiscoDiffusionPipeline
+    from .utils import resize
 else:
     _import_structure = {
-        'deeplab_resnet': ['build_resnet_deeplab_backbone'],
+        'disco_guided_diffusion': ['DiscoDiffusionPipeline'],
+        'utils': ['resize'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/backbone/deeplab_resnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_human_parsing/backbone/deeplab_resnet.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 # https://github.com/facebookresearch/detectron2/blob/main/projects/DeepLab/deeplab/resnet.py
 
 import numpy as np
 import torch
 import torch.nn.functional as F
 from torch import nn
 
-from modelscope.models.cv.image_instance_segmentation.maskdino.utils import \
+from weathon.models.cv.image_instance_segmentation.maskdino.utils import \
     Conv2d
 
 
 def get_norm(norm, out_channels):
     if norm is None:
         return None
     if isinstance(norm, str):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp/__init__.py` & `weathon-0.0.0.14/weathon/models/multi_modal/soonet/__init__.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,20 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .m2fp_encoder import MSDeformAttnPixelDecoder
-    from .m2fp_decoder import MultiScaleMaskedTransformerDecoder
-
+    from .tokenizer import SimpleTokenizer
+    from .model import SOONet
+    from .utils import decode_video
+    from .clip import load_clip
 else:
     _import_structure = {
-        'm2fp_encoder': ['MSDeformAttnPixelDecoder'],
-        'm2fp_decoder': ['MultiScaleMaskedTransformerDecoder'],
+        'model': ['SOONet'],
+        'tokenizer': ['SimpleTokenizer'],
+        'utils': ['decode_video'],
+        'clip': ['load_clip']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp/m2fp_decoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp/m2fp_decoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # The implementation is adopted from Mask2Former, made publicly available under the MIT License at
 # https://github.com/facebookresearch/Mask2Former
 
 import torch
 from torch import nn
 from torch.nn import functional as F
 
-from modelscope.models.cv.image_colorization.ddcolor.utils.transformer_utils import (
+from weathon.models.cv.image_colorization.ddcolor.utils.transformer_utils import (
     MLP, CrossAttentionLayer, FFNLayer, SelfAttentionLayer)
-from modelscope.models.cv.image_instance_segmentation.maskdino.position_encoding import \
+from weathon.models.cv.image_instance_segmentation.maskdino.position_encoding import \
     PositionEmbeddingSine
-from modelscope.models.cv.image_instance_segmentation.maskdino.utils import \
+from weathon.models.cv.image_instance_segmentation.maskdino.utils import \
     Conv2d
 
 
 class MultiScaleMaskedTransformerDecoder(nn.Module):
 
     def __init__(
         self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp/m2fp_encoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp/m2fp_encoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,19 +5,19 @@
 
 import numpy as np
 import torch
 from torch import nn
 from torch.cuda.amp import autocast
 from torch.nn import functional as F
 
-from modelscope.models.cv.image_instance_segmentation.maskdino.maskdino_encoder import \
+from weathon.models.cv.image_instance_segmentation.maskdino.maskdino_encoder import \
     MSDeformAttnTransformerEncoderOnly
-from modelscope.models.cv.image_instance_segmentation.maskdino.position_encoding import \
+from weathon.models.cv.image_instance_segmentation.maskdino.position_encoding import \
     PositionEmbeddingSine
-from modelscope.models.cv.image_instance_segmentation.maskdino.utils import \
+from weathon.models.cv.image_instance_segmentation.maskdino.utils import \
     Conv2d
 
 
 class MSDeformAttnPixelDecoder(nn.Module):
 
     def __init__(
         self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/m2fp_net.py` & `weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp_net.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,21 +3,21 @@
 import os
 from typing import Any, Dict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_instance_segmentation.maskdino_swin import \
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_instance_segmentation.maskdino_swin import \
     ImageList
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .backbone import build_resnet_deeplab_backbone
 from .m2fp.m2fp_decoder import MultiScaleMaskedTransformerDecoder
 from .m2fp.m2fp_encoder import MSDeformAttnPixelDecoder
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_human_parsing/parsing_utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_human_parsing/parsing_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/base.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 """
 from typing import Dict, Tuple
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 from .modules.adversarial import NonSaturatingWithR1
 from .modules.ffc import FFCResNetGenerator
 from .modules.perceptual import ResNetPL
 from .modules.pix2pixhd import NLayerDiscriminator
 
 LOGGER = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/default.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/default.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 https://github.com/saic-mdal/lama
 """
 import bisect
 
 import torch
 import torch.nn.functional as F
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 from .base import BaseInpaintingTrainingModule
 from .modules.feature_matching import feature_matching_loss, masked_l1_loss
 
 LOGGER = get_logger()
 
 
 def set_requires_grad(module, value):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/model.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/model.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 LOGGER = get_logger()
 
 
 @MODELS.register_module(
     Tasks.image_inpainting, module_name=Models.image_inpainting)
 class FFTInpainting(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/ade20k/base.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/ade20k/base.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/ade20k/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/ade20k/resnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/adversarial.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/adversarial.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/feature_matching.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/feature_matching.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/ffc.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/ffc.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/inception.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/inception.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 https://github.com/saic-mdal/lama
 """
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torchvision import models
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 try:
     from torchvision.models.utils import load_state_dict_from_url
 except ImportError:
     from torch.utils.model_zoo import load_url as load_state_dict_from_url
 
 # Inception weights ported to Pytorch from
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/perceptual.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/perceptual.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/modules/pix2pixhd.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/modules/pix2pixhd.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_inpainting/refinement.py` & `weathon-0.0.0.14/weathon/models/cv/image_inpainting/refinement.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .cascade_mask_rcnn_swin import CascadeMaskRCNNSwin
     from .maskdino_swin import MaskDINOSwin
     from .model import CascadeMaskRCNNSwinModel
     from .maskdino_model import MaskDINOSwinModel
     from .fastinst_model import FastInst
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/backbones/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/video_frame_interpolation/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .swin_transformer import SwinTransformer
-    from .swin_transformer import D2SwinTransformer
-    from .resnet import build_resnet_backbone
+    from .video_frame_interpolation_dataset import VideoFrameInterpolationDataset
 
 else:
     _import_structure = {
-        'swin_transformer': ['SwinTransformer', 'D2SwinTransformer'],
-        'resnet': ['build_resnet_backbone']
+        'video_frame_interpolation_dataset':
+        ['VideoFrameInterpolationDataset'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/backbones/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/backbones/resnet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # Part of the implementation is borrowed and modified from Detectron2, publicly available at
 # https://github.com/facebookresearch/detectron2/blob/main/projects/DeepLab/deeplab/resnet.py
 
 import torch.nn.functional as F
 from torch import nn
 
-from modelscope.models.cv.image_human_parsing.backbone.deeplab_resnet import (
+from weathon.models.cv.image_human_parsing.backbone.deeplab_resnet import (
     BottleneckBlock, DeeplabResNet, get_norm)
-from modelscope.models.cv.image_instance_segmentation.maskdino.utils import \
+from weathon.models.cv.image_instance_segmentation.maskdino.utils import \
     Conv2d
 
 
 class BasicStem(nn.Module):
     """
     The standard ResNet stem (layers before the first residual block),
     with a conv, relu and max_pool.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/backbones/swin_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/backbones/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,18 +3,18 @@
 import os
 from collections import OrderedDict
 
 import torch
 import torch.distributed as dist
 import torch.nn as nn
 
-from modelscope.models.cv.image_instance_segmentation.backbones import \
+from weathon.models.cv.image_instance_segmentation.backbones import \
     SwinTransformer
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def build_backbone(cfg):
     assert isinstance(cfg, dict)
     cfg = cfg.copy()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/datasets/transforms.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/datasets/transforms.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import numpy as np
 
-from modelscope.fileio import File
+from weathon.fileio import File
 
 
 def build_preprocess_transform(cfg):
     assert isinstance(cfg, dict)
     cfg = cfg.copy()
     type = cfg.pop('type')
     if type == 'LoadImageFromFile':
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 
 import torch
 from torch import nn
 from torch.nn import functional as F
 
-from modelscope.models.cv.image_colorization.ddcolor.utils.transformer_utils import (
+from weathon.models.cv.image_colorization.ddcolor.utils.transformer_utils import (
     MLP, CrossAttentionLayer, FFNLayer, SelfAttentionLayer)
 
 
 class QueryProposal(nn.Module):
 
     def __init__(self, num_features, num_queries, num_classes):
         super().__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import logging
 from typing import Callable, Optional, Union
 
 import torch
 from torch import nn
 from torch.nn import functional as F
 
-from modelscope.models.cv.image_instance_segmentation.maskdino.utils import \
+from weathon.models.cv.image_instance_segmentation.maskdino.utils import \
     Conv2d
 
 
 # This is a modified FPN decoder.
 class BaseFPN(nn.Module):
 
     def __init__(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/fastinst_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/fastinst_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,21 +3,21 @@
 import os
 from typing import Any, Dict, List
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_instance_segmentation.maskdino_swin import \
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_instance_segmentation.maskdino_swin import \
     ImageList
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .backbones import build_resnet_backbone
 from .fastinst.fastinst_decoder import FastInstDecoder
 from .fastinst.fastinst_encoder import PyramidPoolingModuleFPN
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .maskdino_encoder import MaskDINOEncoder
     from .maskdino_decoder import MaskDINODecoder
 
 else:
     _import_structure = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/dino_decoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/dino_decoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,16 +5,14 @@
 # ------------------------------------------------------------------------------------------------
 # Modified from https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/tree/pytorch_1.0.0
 # ------------------------------------------------------------------------------------------------
 
 # Copyright (c) Facebook, Inc. and its affiliates.
 # Modified by Bowen Cheng from https://github.com/fundamentalvision/Deformable-DETR
 
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from __future__ import absolute_import, division, print_function
 import math
 import warnings
 
 import torch
 import torch.nn.functional as F
 from mmcv.ops.multi_scale_deform_attn import (
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/position_encoding.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/position_encoding.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_instance_segmentation import MaskDINOSwin
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_instance_segmentation import MaskDINOSwin
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.image_segmentation, module_name=Models.maskdino_swin)
 class MaskDINOSwinModel(TorchModel):
 
     def __init__(self, model_dir=None, *args, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/maskdino_swin.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/maskdino_swin.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,18 +5,18 @@
 
 import os
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.image_instance_segmentation.backbones import \
+from weathon.models.cv.image_instance_segmentation.backbones import \
     D2SwinTransformer
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 from .maskdino.maskdino_decoder import MaskDINODecoder
 from .maskdino.maskdino_encoder import MaskDINOEncoder
 
 logger = get_logger()
 
 
 class MaskDINOSwin(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/model.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/model.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_instance_segmentation import \
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_instance_segmentation import \
     CascadeMaskRCNNSwin
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.image_segmentation, module_name=Models.cascade_mask_rcnn_swin)
 class CascadeMaskRCNNSwinModel(TorchModel):
 
     def __init__(self, model_dir=None, *args, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_instance_segmentation/postprocess_utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_instance_segmentation/postprocess_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import itertools
 
 import cv2
 import numpy as np
 import pycocotools.mask as maskUtils
 import torch
 
-from modelscope.outputs import OutputKeys
+from weathon.outputs import OutputKeys
 
 
 def get_seg_bboxes(bboxes, labels, segms=None, class_names=None, score_thr=0.):
     assert bboxes.ndim == 2, \
         f' bboxes ndim should be 2, but its ndim is {bboxes.ndim}.'
     assert labels.ndim == 1, \
         f' labels ndim should be 1, but its ndim is {labels.ndim}.'
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assmessment_mos/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .quadtree_attention_model import QuadTreeAttentionForImageMatching
+    from .image_quality_assessment_mos_dataset import ImageQualityAssessmentMosDataset
 
 else:
     _import_structure = {
-        'quadtree_attention_model': ['QuadTreeAttentionForImageMatching'],
+        'image_quality_assessment_mos_dataset':
+        ['ImageQualityAssessmentMosDataset'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/config/default.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/config/default.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/backbone/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/backbone/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch.nn as nn
 import torch.nn.functional as F
 from timm.models.layers import trunc_normal_
 
-from modelscope.ops.quadtree_attention import QTAttA, QTAttB
+from weathon.utils.ops.quadtree_attention import QTAttA, QTAttB
 
 
 class QuadtreeAttention(nn.Module):
 
     def __init__(
         self,
         dim,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_matching/quadtree_attention_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_matching/quadtree_attention_model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,21 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
-from pathlib import Path
 
-import cv2
-import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
 from .config.default import get_cfg_defaults
 from .loftr_quadtree.loftr import LoFTR
 from .utils.misc import lower_config
 
 
 @MODELS.register_module(
     Tasks.image_matching, module_name=Models.quadtree_attention_image_matching)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_portrait_enhancement/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .casmvs_model import ImageMultiViewDepthEstimation
+    from .image_portrait_enhancement_dataset import ImagePortraitEnhancementDataset
 
 else:
     _import_structure = {
-        'casmvs_model': ['ImageMultiViewDepthEstimation'],
+        'image_portrait_enhancement_dataset':
+        ['ImagePortraitEnhancementDataset'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/cas_mvsnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/cas_mvsnet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .module import (CostRegNet, FeatureNet, RefineNet, depth_regression,
                      get_depth_range_samples, homo_warping)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/casmvs_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/casmvs_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,26 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import os.path as osp
 
 import cv2
 import numpy as np
 import torch
 from easydict import EasyDict as edict
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .cas_mvsnet import CascadeMVSNet
 from .colmap2mvsnet import processing_single_scene
 from .depth_filter import pcd_depth_filter
 from .general_eval_dataset import MVSDataset, save_pfm
-from .utils import (generate_pointcloud, numpy2torch, tensor2numpy, tocuda,
+from .utils import (numpy2torch, tensor2numpy, tocuda,
                     write_cam)
 
 logger = get_logger()
 
 
 @MODELS.register_module(
     Tasks.image_multi_view_depth_estimation,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/depth_filter.py` & `weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/depth_filter.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/general_eval_dataset.py` & `weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/general_eval_dataset.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import re
 import sys
 
 import cv2
 import numpy as np
 from PIL import Image
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/module.py` & `weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/module.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_mvs_depth_estimation/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_mvs_depth_estimation/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_paintbyexample/model.py` & `weathon-0.0.0.14/weathon/models/cv/image_paintbyexample/model.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,20 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from typing import Any, Dict, Optional, Union
 
 import torch
 from omegaconf import OmegaConf
 from paint_ldm.util import instantiate_from_config
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 LOGGER = get_logger()
 
 
 def load_model_from_config(config, ckpt, verbose=False):
     LOGGER.info(f'Loading model from {ckpt}')
     pl_sd = torch.load(ckpt, map_location='cpu')
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_panoptic_segmentation/__init__.py` & `weathon-0.0.0.14/weathon/models/multi_modal/rleg/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,18 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .panseg_model import SwinLPanopticSegmentation
+
+    from .rleg import RLEGForMultiModalEmbedding
 
 else:
     _import_structure = {
-        'panseg_model': ['SwinLPanopticSegmentation'],
+        'rleg': ['RLEGForMultiModalEmbedding'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_panoptic_segmentation/panseg_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_panoptic_segmentation/panseg_model.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.image_segmentation, module_name=Models.panoptic_segmentation)
 class SwinLPanopticSegmentation(TorchModel):
 
     def __init__(self, model_dir: str, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/video_human_matting/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,19 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .image_portrait_enhancement import ImagePortraitEnhancement
+    from .model import VideoMattingNetwork
+    from .model import preprocess
 
 else:
-    _import_structure = {
-        'image_portrait_enhancement': ['ImagePortraitEnhancement']
-    }
+    _import_structure = {'model': ['VideoMattingNetwork', 'preprocess']}
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/align_faces.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/align_faces.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Part of the implementation is borrowed and modified from Face-Alignment,
 # publicly available at https://github.com/foamliu/Face-Alignment/blob/master/align_faces.py
 import cv2
 import numpy as np
 from skimage import transform as trans
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 # reference facial points, a list of coordinates (x,y)
 REFERENCE_FACIAL_POINTS = [[30.29459953, 51.69630051],
                            [65.53179932, 51.50139999],
                            [48.02519989,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/eqface/fqa.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/eqface/fqa.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
 import cv2
 import numpy as np
 import torch
 
 from .model_resnet import FaceQuality, ResNet
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/eqface/model_resnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/eqface/model_resnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/gpen.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/gpen.py`

 * *Files 0% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 import random
 
 import torch
 from torch import nn
 from torch.autograd import Function
 from torch.nn import functional as F
 
-from modelscope.models.cv.face_generation.op import (FusedLeakyReLU,
+from weathon.models.cv.face_generation.op import (FusedLeakyReLU,
                                                      fused_leaky_relu,
                                                      upfirdn2d)
 
 
 class PixelNorm(nn.Module):
 
     def __init__(self):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/image_portrait_enhancement.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/image_portrait_enhancement.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 import os.path as osp
 from typing import Any, Dict, List, Union
 
 import torch
 import torch.nn.functional as F
 from torch import autograd, nn
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .gpen import Discriminator, FullGenerator
 from .losses.losses import IDLoss, L1Loss
 
 logger = get_logger()
 
 __all__ = ['ImagePortraitEnhancement']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/losses/helpers.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/losses/helpers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/losses/losses.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/losses/losses.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/losses/model_irse.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/losses/model_irse.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/detection.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/detection.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/models/net.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/models/net.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_portrait_enhancement/retinaface/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_portrait_enhancement/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_skychange/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,21 +1,19 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
-
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-
-    from .model import StructuredProbingModel
+    from .skychange_model import ImageSkychange
+    from .preprocessor import ImageSkyChangePreprocessor
 
 else:
-    _import_structure = {
-        'model': ['StructuredProbingModel'],
-    }
+    _import_structure = {'skychange_model': ['ImageSkychange']}
+    _import_structure = {'preprocessor': ['ImageSkyChangePreprocessor']}
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/backbone.py` & `weathon-0.0.0.14/weathon/models/cv/image_probing_model/backbone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/model.py` & `weathon-0.0.0.14/weathon/models/cv/image_probing_model/model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,22 +1,17 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
 import os
-from typing import Any, Dict
 
-import json
 import torch
-import torch.nn as nn
-import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
 from .backbone import CLIP, ProbingModel
 
 
 @MODELS.register_module(
     Tasks.image_classification, module_name=Models.image_probing_model)
 class StructuredProbingModel(TorchModel):
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_probing_model/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_probing_model/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_degradation/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,20 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .image_quality_assessment_degradation import ImageQualityAssessmentDegradation
+    from .nerf_recon_acc import NeRFReconAcc
+    from .nerf_preprocess import NeRFReconPreprocessor
 
 else:
-    _import_structure = {
-        'image_quality_assessment_degradation':
-        ['ImageQualityAssessmentDegradation']
-    }
+    _import_structure = {'nerf_recon_acc': ['NeRFReconAcc']}
+    _import_structure = {'nerf_preprocess': ['NeRFReconPreprocessor']}
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_degradation/degradation_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_degradation/degradation_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from typing import Any, Dict, Union
+from typing import Dict, Union
 
 import torch.cuda
 import torch.nn as nn
-import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_quality_assessment_degradation.degradation_model import \
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_quality_assessment_degradation.degradation_model import \
     DegradationIQA
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ImageQualityAssessmentDegradation']
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/face_human_hand_detection/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .image_quality_assessment_man import ImageQualityAssessmentMAN
+    from .det_infer import NanoDetForFaceHumanHandDetection
 
 else:
-    _import_structure = {
-        'image_quality_assessment_man': ['ImageQualityAssessmentMAN']
-    }
+    _import_structure = {'det_infer': ['NanoDetForFaceHumanHandDetection']}
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/image_quality_assessment_man.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_man/image_quality_assessment_man.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
 import torch.cuda
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_quality_assessment_man.maniqa import MANIQA
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_quality_assessment_man.maniqa import MANIQA
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ImageQualityAssessmentMAN']
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/maniqa.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_man/maniqa.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_man/swin.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_man/swin.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/backbones/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/heads/simple_head.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/heads/simple_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py` & `weathon-0.0.0.14/weathon/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
 import torch.cuda
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_quality_assessment_mos.censeo_ivqa_model import \
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_quality_assessment_mos.censeo_ivqa_model import \
     CenseoIVQAModel
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ImageQualityAssessmentMos']
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_reid_person/pass_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_reid_person/pass_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -3,19 +3,19 @@
 
 import os
 from enum import Enum
 
 import torch
 import torch.nn as nn
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .transreid_model import vit_base_patch16_224_TransReID
 
 
 class Fusions(Enum):
     CAT = 'cat'
     MEAN = 'mean'
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_reid_person/transreid_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_reid_person/transreid_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_probing_model/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,18 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
+
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .image_restoration_model import ImageRestorationModel
+
+    from .model import StructuredProbingModel
 
 else:
     _import_structure = {
-        'image_restoration_model': ['ImageRestorationModel'],
+        'model': ['StructuredProbingModel'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/demoire_models/nets.py` & `weathon-0.0.0.14/weathon/models/cv/image_restoration/demoire_models/nets.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_restoration/image_restoration_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_restoration/image_restoration_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .demoire_models import model_map
 
 
 @MODELS.register_module(
     Tasks.image_demoireing, module_name=Models.image_restoration)
 class ImageRestorationModel(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .semantic_seg_model import SemanticSegmentation
     from .segformer import Segformer
     from .ddpm_segmentation_model import DDPMSegmentationModel
 
 else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,15 @@
 # The implementation here is modified based on ddpm-segmentation,
 # originally Apache 2.0 License and publicly available at https://github.com/yandex-research/ddpm-segmentation
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import List
 
 import torch
 from torch import nn
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def create_feature_extractor(model_type, **kwargs):
     """ Create the feature extractor for <model_type> architecture. """
     if model_type == 'ddpm':
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,9 @@
 # The implementation here is modified based on ddpm-segmentation,
 # originally Apache 2.0 License and publicly available at https://github.com/yandex-research/ddpm-segmentation
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from collections import Counter
 
 import numpy as np
 import torch
 import torch.nn as nn
 from PIL import Image
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_seg/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_seg/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,21 @@
 # The implementation here is modified based on ddpm-segmentation,
 # originally Apache 2.0 License and publicly available at https://github.com/yandex-research/ddpm-segmentation
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict
 
 import torch
 from ddpm_guided_diffusion.script_util import model_and_diffusion_defaults
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .ddpm_seg.feature_extractors import (collect_features,
                                           create_feature_extractor)
 from .ddpm_seg.pixel_classifier import (load_ensemble, pixel_classifier,
                                         predict_labels, save_predictions)
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn.functional as F
 from mmdet.models.builder import HEADS
 
 from .base_panoptic_fusion_head import BasePanopticFusionHead
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/semantic_seg_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/semantic_seg_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.image_semantic_segmentation import (pan_merge,
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.image_semantic_segmentation import (pan_merge,
                                                               vit_adapter)
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.image_segmentation, module_name=Models.swinL_semantic_segmentation)
 @MODELS.register_module(
     Tasks.image_segmentation,
     module_name=Models.vitadapter_semantic_segmentation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py` & `weathon-0.0.0.14/weathon/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,19 +1,20 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .skychange_model import ImageSkychange
-    from .preprocessor import ImageSkyChangePreprocessor
+    from .table_question_answering_preprocessor import TableQuestionAnsweringPreprocessor
+    from .fields import MultiWOZBPETextField, IntentBPETextField
 
 else:
-    _import_structure = {'skychange_model': ['ImageSkychange']}
-    _import_structure = {'preprocessor': ['ImageSkyChangePreprocessor']}
+    _import_structure = {
+        'table_question_answering_preprocessor':
+        ['TableQuestionAnsweringPreprocessor'],
+    }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/preprocessor.py` & `weathon-0.0.0.14/weathon/models/cv/image_skychange/preprocessor.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,36 +1,32 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numbers
-import pdb
 from typing import Any, Dict, Union
 
 import cv2
-import json
 import numpy as np
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.constant import Fields, ModeKeys
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.constants import Fields, ModeKeys
 
 _cv2_pad_to_str = {
     'constant': cv2.BORDER_CONSTANT,
     'edge': cv2.BORDER_REPLICATE,
     'reflect': cv2.BORDER_REFLECT_101,
     'symmetric': cv2.BORDER_REFLECT,
 }
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.image_sky_change_preprocessor)
-class ImageSkyChangePreprocessor(Preprocessor):
+class ImageSkyChangePreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str = None,
                  mode: str = ModeKeys.INFERENCE,
                  coarse_model_width=640,
                  coarse_model_height=640,
                  refine_model_width=1280,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/BlockModules.py` & `weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/BlockModules.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/hrnet_backnone.py` & `weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/hrnet_backnone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py` & `weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/ptsemseg/unet.py` & `weathon-0.0.0.14/weathon/models/cv/image_skychange/ptsemseg/unet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/skychange.py` & `weathon-0.0.0.14/weathon/models/cv/image_skychange/skychange.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numbers
 import os
 import pdb
 from collections import deque
 
 import cv2
 import json
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_skychange/skychange_model.py` & `weathon-0.0.0.14/weathon/models/cv/image_skychange/skychange_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,21 @@
-import math
 import os
-import pdb
 import time
 from collections import OrderedDict
-from typing import Any, Dict, List, Union
+from typing import Any, Dict
 
 import cv2
-import json
 import torch
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models import Model
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .ptsemseg.hrnet_super_and_ocr import HrnetSuperAndOcr
 from .ptsemseg.unet import Unet
 from .skychange import blend
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/data/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assessment_degradation/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .transforms import PadToSquare
+    from .image_quality_assessment_degradation_dataset import ImageQualityAssessmentDegradationDataset
 
 else:
     _import_structure = {
-        'transforms': ['PadToSquare'],
+        'image_quality_assessment_degradation_dataset':
+        ['ImageQualityAssessmentDegradationDataset'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
         module_spec=__spec__,
         extra_objects={},
     )
-
-# from .transforms import *  # noqa F403
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/data/transforms.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/data/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/model.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/models/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/video_super_resolution/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .autoencoder import VQAutoencoder
-    from .clip import VisionTransformer
+    from .real_basicvsr_for_video_super_resolution import RealBasicVSRNetForVideoSR
+    from .msrresnet_lite_model import MSRResNetLiteModel
 
 else:
     _import_structure = {
-        'autoencoder': ['VQAutoencoder'],
-        'clip': ['VisionTransformer']
+        'real_basicvsr_for_video_super_resolution':
+        ['RealBasicVSRNetForVideoSR'],
+        'msrresnet_lite_model': ['MSRResNetLiteModel']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/models/autoencoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/models/autoencoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/models/clip.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/models/clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/ops/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/T5/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,18 +1,19 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .diffusion import GaussianDiffusion, beta_schedule
+    from .backbone import T5Model
+    from .text2text_generation import T5ForConditionalGeneration
 
 else:
     _import_structure = {
-        'diffusion': ['GaussianDiffusion', 'beta_schedule'],
+        'backbone': ['T5Model'],
+        'text2text_generation': ['T5ForConditionalGeneration'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/ops/diffusion.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/ops/diffusion.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_generation/ops/losses.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/ops/losses.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/__init__.py` & `weathon-0.0.0.14/weathon/models/audio/kws/__init__.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,20 +1,21 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
-
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-
-    from .model_translation import UNet
+    from .generic_key_word_spotting import GenericKeyWordSpotting
+    from .farfield.model import FSMNSeleNetV2Decorator
+    from .nearfield.model import FSMNDecorator
 
 else:
     _import_structure = {
-        'image_to_image_translation_model': ['UNet'],
+        'generic_key_word_spotting': ['GenericKeyWordSpotting'],
+        'farfield.model': ['FSMNSeleNetV2Decorator'],
+        'nearfield.model': ['FSMNDecorator'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/data/transforms.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/data/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/model_translation.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/model_translation.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/models/autoencoder.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/models/autoencoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/models/clip.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/models/clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/apps.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/apps.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/degradation.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/degradation.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/diffusion.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/diffusion.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/losses.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/losses.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/metrics.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/metrics.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/random_color.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/random_color.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/random_mask.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/random_mask.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/svd.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/svd.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/image_to_image_translation/ops/utils.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_translation/ops/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torchvision.models as models
 
 from ..utils import StripPooling
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import timm
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/misc/fourier.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/misc/fourier.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 from PIL import Image
 from scipy.fft import fft2, ifft2
 
 AL = 1
 pas = 50
 highpas = 250
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/misc/panostretch.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/misc/panostretch.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import functools
 
 import numpy as np
 from scipy.ndimage import map_coordinates
 
 
 def uv_meshgrid(w, h):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/misc/post_proc.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/misc/post_proc.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 from scipy.ndimage import map_coordinates
 from scipy.spatial.distance import pdist, squareform
 from sklearn.decomposition import PCA
 
 PI = float(np.pi)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/modality/layout.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/modality/layout.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 
 import numpy as np
 import torch
 import torch.nn as nn
 from scipy.ndimage.filters import maximum_filter
 from shapely.geometry import Polygon
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/panovit.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/panovit.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from . import backbone, modality
 from .utils import visualize_a_data
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/networks/utils.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/networks/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 class StripPooling(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/indoor_layout_estimation/panovit.py` & `weathon-0.0.0.14/weathon/models/cv/indoor_layout_estimation/panovit.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import numpy as np
 import torch
 from yacs.config import CfgNode as CN
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.indoor_layout_estimation.networks.panovit import \
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.indoor_layout_estimation.networks.panovit import \
     PanoVIT
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.indoor_layout_estimation,
     module_name=Models.panovit_layout_estimation)
 class LayoutEstimation(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Modified by Zhipu.AI
+# Original Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .summarizer import (
-        ClipItVideoSummarization, )
-
+    from .mglm_for_text_summarization import MGLMForTextSummarization
 else:
     _import_structure = {
-        'summarizer': [
-            'ClipItVideoSummarization',
-        ]
+        'mglm_for_text_summarization': ['MGLMForTextSummarization'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/summarizer.py` & `weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/summarizer.py`

 * *Files 12% similar despite different names*

```diff
@@ -11,27 +11,24 @@
 import torch
 import torch.nn as nn
 from bmt_clipit.sample.single_video_prediction import (caption_proposals,
                                                        generate_proposals,
                                                        load_cap_model,
                                                        load_prop_model)
 from bmt_clipit.utilities.proposal_utils import non_max_suppresion
-from torch.nn.parallel import DataParallel, DistributedDataParallel
 from videofeatures_clipit.models.i3d.extract_i3d import ExtractI3D
 from videofeatures_clipit.models.vggish.extract_vggish import ExtractVGGish
-from videofeatures_clipit.utils.utils import (fix_tensorflow_gpu_allocation,
-                                              form_list_from_user_input)
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.language_guided_video_summarization.transformer import \
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.language_guided_video_summarization.transformer import \
     Transformer
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def extract_text(args):
     # Loading models and other essential stuff
     cap_cfg, cap_model, train_dataset = load_cap_model(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/layers.py` & `weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/layers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/models.py` & `weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/models.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/modules.py` & `weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/modules.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/language_guided_video_summarization/transformer/sub_layers.py` & `weathon-0.0.0.14/weathon/models/cv/language_guided_video_summarization/transformer/sub_layers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/__init__.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,20 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# The DAMO-YOLO implementation is also open-sourced by the authors at https://github.com/tinyvision/damo-yolo.
+
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
+    from .tinynas_detector import Tinynas_detector
+    from .tinynas_damoyolo import DamoYolo
 
-    from .model import create_model, load_model_wo_clip
-    from .modules.cfg_sampler import ClassifierFreeSampleModel
 else:
     _import_structure = {
-        'model': ['create_model', 'load_model_wo_clip'],
-        'modules.cfg_sampler': ['ClassifierFreeSampleModel']
+        'tinynas_detector': ['TinynasDetector'],
+        'tinynas_damoyolo': ['DamoYolo'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/model.py` & `weathon-0.0.0.14/weathon/models/cv/motion_generation/model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/cfg_sampler.py` & `weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/cfg_sampler.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/gaussian_diffusion.py` & `weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/gaussian_diffusion.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/mdm.py` & `weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/mdm.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/respace.py` & `weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/respace.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/rotation2xyz.py` & `weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/rotation2xyz.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # This code is borrowed and modified from Human Motion Diffusion Model,
 # made publicly available under MIT license at https://github.com/GuyTevet/motion-diffusion-model
 
 import torch
 
-from modelscope.utils.cv.motion_utils import rotation_conversions as geometry
+from weathon.utils.cv.motion_utils import rotation_conversions as geometry
 from .smpl import JOINTSTYPE_ROOT, SMPL
 
 JOINTSTYPES = ['a2m', 'a2mpl', 'smpl', 'vibe', 'vertices']
 
 
 class Rotation2xyz:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/motion_generation/modules/smpl.py` & `weathon-0.0.0.14/weathon/models/cv/motion_generation/modules/smpl.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
 
     from .model import MovieSceneSegmentationModel
     from .datasets import MovieSceneSegmentationDataset
 
 else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/get_model.py` & `weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/get_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/model.py` & `weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/model.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,20 +12,20 @@
 import torch.nn as nn
 import torch.nn.functional as F
 import torchvision.transforms as TF
 from PIL import Image
 from shotdetect_scenedetect_lgss import shot_detector
 from tqdm import tqdm
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .get_model import get_contextual_relation_network, get_shot_encoder
 from .utils.save_op import get_pred_boundary, pred2scene, scene2video
 
 logger = get_logger()
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/head.py` & `weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/save_op.py` & `weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/save_op.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/shot_encoder.py` & `weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/shot_encoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/movie_scene_segmentation/utils/trn.py` & `weathon-0.0.0.14/weathon/models/cv/movie_scene_segmentation/utils/trn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_to_image_generation/models/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,19 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .nerf_recon_acc import NeRFReconAcc
-    from .nerf_preprocess import NeRFReconPreprocessor
+    from .autoencoder import VQAutoencoder
+    from .clip import VisionTransformer
 
 else:
-    _import_structure = {'nerf_recon_acc': ['NeRFReconAcc']}
-    _import_structure = {'nerf_preprocess': ['NeRFReconPreprocessor']}
+    _import_structure = {
+        'autoencoder': ['VQAutoencoder'],
+        'clip': ['VisionTransformer']
+    }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py` & `weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 import os
 
 import json
 import numpy as np
 import torch
 import torch.nn.functional as F
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/dataloader/read_write_model.py` & `weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/dataloader/read_write_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/nerf_preprocess.py` & `weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/nerf_preprocess.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,30 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import glob
 import os
 import subprocess
 from typing import Any, Dict, Union
 
 import cv2
-import numpy as np
-import tensorflow as tf
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.nerf_recon_acc_preprocessor)
-class NeRFReconPreprocessor(Preprocessor):
+class NeRFReconPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  mode=ModeKeys.INFERENCE,
                  data_type='colmap',
                  use_mask=True,
                  match_type='exhaustive_matcher',
                  frame_count=60,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/nerf_recon_acc.py` & `weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/nerf_recon_acc.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import glob
 import os
 import time
 
 import cv2
 import numpy as np
 import torch
 import tqdm
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 from .dataloader.nerf_dataset import BlenderDataset, ColmapDataset
 from .network.nerf import NeRFModel
 from .network.utils import PSNR
 
 logger = get_logger()
 
 __all__ = ['NeRFReconAcc']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/network/nerf.py` & `weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/network/nerf.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/network/segmenter.py` & `weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/network/segmenter.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import tensorflow as tf
 
 
 class ObjectSegmenter(object):
     """use ObjectSegmenter to segment object from input video.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/nerf_recon_acc/network/utils.py` & `weathon-0.0.0.14/weathon/models/cv/nerf_recon_acc/network/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/__init__.py` & `weathon-0.0.0.14/weathon/hooks/logger/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,26 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .mmdet_model import DetectionModel
-    from .yolox_pai import YOLOX
-    from .dino import DINO
-
+    from .base import LoggerHook
+    from .tensorboard_hook import TensorboardHook
+    from .text_logger_hook import TextLoggerHook
 else:
     _import_structure = {
-        'mmdet_model': ['DetectionModel'],
-        'yolox_pai': ['YOLOX'],
-        'dino': ['DINO']
+        'base': ['LoggerHook'],
+        'tensorboard_hook': ['TensorboardHook'],
+        'text_logger_hook': ['TextLoggerHook']
     }
-
     import sys
-
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
         module_spec=__spec__,
         extra_objects={},
     )
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_model.py` & `weathon-0.0.0.14/weathon/models/cv/abnormal_object_detection/mmdet_model.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,59 +1,70 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from .mmdet_ms.backbones import ViT
-from .mmdet_ms.dense_heads import RPNNHead
-from .mmdet_ms.necks import FPNF
-from .mmdet_ms.roi_heads import FCNMaskNHead, Shared4Conv1FCBBoxNHead
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+# from weathon.models.base.base_torch_model import TorchModel
+# from weathon.registry import MODELS
+# from weathon.utils.constants import ModelFile, Tasks
 
+from weathon.utils.config.config import Config
+from .mmdet_ms import MaskScoringNRoIHead, SingleRoINExtractor
 
-@MODELS.register_module(Tasks.human_detection, module_name=Models.detection)
-@MODELS.register_module(
-    Tasks.image_object_detection, module_name=Models.detection)
-class DetectionModel(TorchModel):
+
+@MODELS.register_module(Tasks.image_object_detection, module_name=Models.mask_scoring)
+class AbnormalDetectionModel(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """str -- model file root."""
         super().__init__(model_dir, *args, **kwargs)
 
         from mmcv.runner import load_checkpoint
         from mmdet.datasets import replace_ImageToTensor
         from mmdet.datasets.pipelines import Compose
         from mmdet.models import build_detector
 
         model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)
         config_path = osp.join(model_dir, 'mmcv_config.py')
         config = Config.from_file(config_path)
         config.model.pretrained = None
-        self.model = build_detector(config.model)
+        self.model = build_detector(
+            config.model, test_cfg=config.get('test_cfg'))
 
         checkpoint = load_checkpoint(
             self.model, model_path, map_location='cpu')
         self.class_names = checkpoint['meta']['CLASSES']
         config.test_pipeline[0].type = 'LoadImageFromWebcam'
         self.transform_input = Compose(
             replace_ImageToTensor(config.test_pipeline))
         self.model.cfg = config
         self.model.eval()
         self.score_thr = config.score_thr
 
     def inference(self, data):
-        """data is dict,contain img and img_metas,follow with mmdet."""
+        """data is dict,contain img and img_metas,follow with mmdet.
+        Args:
+            imgs (List[Tensor]): the outer list indicates test-time
+                augmentations and inner Tensor should have a shape NxCxHxW,
+                which contains all images in the batch.
+            img_metas (List[List[dict]]): the outer list indicates test-time
+                augs (multiscale, flip, etc.) and the inner list indicates
+                images in a batch.
+        """
 
         with torch.no_grad():
-            results = self.model(return_loss=False, rescale=True, **data)
+            results = self.model(
+                return_loss=False,
+                rescale=True,
+                img=data['img'],
+                img_metas=data['img_metas'])
         return results
 
     def preprocess(self, image):
         """image is numpy return is dict contain img and img_metas,follow with mmdet."""
 
         from mmcv.parallel import collate, scatter
         data = dict(img=image)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/backbones/vit.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/backbones/vit.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/necks/fpn.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/necks/fpn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/utils/checkpoint.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/utils/checkpoint.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/depe_detect.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/depe_detect.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import os.path as osp
 from typing import Any, Dict, List, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['DepeDetect']
 
 
 @MODELS.register_module(Tasks.object_detection_3d, module_name=Models.depe)
@@ -29,15 +28,15 @@
         initialize the 3d object detection model from the `model_dir` path.
         Args:
             model_dir (str): the model path.
         """
         super().__init__(model_dir, *args, **kwargs)
         from mmcv.runner import load_checkpoint
         import modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin
-        from modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.detectors import Petr3D
+        from weathon.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.detectors import Petr3D
 
         # build model and load checkpoint
         config_path = osp.join(model_dir, ModelFile.CONFIGURATION)
         config = Config.from_file(config_path)
         detector = Petr3D(**config.model.network_param)
         model_file = kwargs.get('model_file', ModelFile.TORCH_MODEL_BIN_FILE)
         ckpt_path = osp.join(model_dir, model_file)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 """
 import torch
 from mmdet.core.bbox.assigners import AssignResult, BaseAssigner
 from mmdet.core.bbox.builder import BBOX_ASSIGNERS
 from mmdet.core.bbox.match_costs import build_match_cost
 from mmdet.models.utils.transformer import inverse_sigmoid
 
-from modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.util import \
+from weathon.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.util import \
     normalize_bbox
 
 try:
     from scipy.optimize import linear_sum_assignment
 except ImportError:
     linear_sum_assignment = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 https://github.com/megvii-research/PETR/blob/main/projects/mmdet3d_plugin/core/bbox/coders
 """
 import torch
 import torch.nn.functional as F
 from mmdet.core.bbox import BaseBBoxCoder
 from mmdet.core.bbox.builder import BBOX_CODERS
 
-from modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.util import \
+from weathon.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.util import \
     denormalize_bbox
 
 
 @BBOX_CODERS.register_module()
 class NMSFreeCoder(BaseBBoxCoder):
     """Bbox coder for NMS-free detector.
     Args:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py`

 * *Files 0% similar despite different names*

```diff
@@ -18,15 +18,15 @@
                         reduce_mean)
 from mmdet.models import HEADS, build_loss
 from mmdet.models.dense_heads.anchor_free_head import AnchorFreeHead
 from mmdet.models.utils import NormedLinear, build_transformer
 from mmdet.models.utils.transformer import inverse_sigmoid
 from torch.cuda.amp.autocast_mode import autocast
 
-from modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.util import \
+from weathon.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.util import \
     normalize_bbox
 from .depth_net import DepthNet
 
 
 def pos2posemb3d(pos, num_pos_feats=128, temperature=10000):
     scale = 2 * math.pi
     pos = pos * scale
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/object_detection_3d/depe/result_vis.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection_3d/depe/result_vis.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/model.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_detection/model.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import numpy as np
 import torch
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.config.config import Config
+from weathon.utils.logger import get_logger
 from .modules.dbnet import DBModel, VLPTModel
 from .utils import boxes_from_bitmap, polygons_from_bitmap
 
 LOGGER = get_logger()
 
 
 @MODELS.register_module(Tasks.ocr_detection, module_name=Models.ocr_detection)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/modules/dbnet.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_detection/modules/dbnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/modules/seg_detector_loss.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_detection/modules/seg_detector_loss.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/preprocessor.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_detection/preprocessor.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,27 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 import os
-from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor, load_image
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModeKeys, ModelFile
+from weathon.base import BasePreprocessor
+from weathon.preprocessors import load_image
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys, ModelFile
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.utils.config.config import Config
 
 
-@PREPROCESSORS.register_module(
-    Fields.cv, module_name=Preprocessors.ocr_detection)
-class OCRDetectionPreprocessor(Preprocessor):
+@PREPROCESSORS.register_module(Fields.cv, module_name=Preprocessors.ocr_detection)
+class OCRDetectionPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, mode: str = ModeKeys.INFERENCE):
         """The base constructor for all ocr recognition preprocessors.
 
         Args:
             model_dir (str): model directory to initialize some resource
             mode: The mode for the preprocessor.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_detection/utils.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_detection/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import cv2
 import numpy as np
 import pyclipper
 from shapely.geometry import Polygon
 
 
 def rboxes_to_polygons(rboxes):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/convnext.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/convnext.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/convnextvit.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_convnext_transformer.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,20 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
-from .convnext import convnext_tiny
-from .vitstr import vitstr_tiny
+from .ocr_modules.convnext import convnext_tiny
+from .ocr_modules.vitstr import vitstr_tiny
 
 
-class ConvNextViT(nn.Module):
+class OCRRecModel(nn.Module):
 
-    def __init__(self):
-        super(ConvNextViT, self).__init__()
+    def __init__(self, num_classes):
+        super(OCRRecModel, self).__init__()
         self.cnn_model = convnext_tiny()
-        self.vitstr = vitstr_tiny(num_tokens=7644)
+        self.num_classes = num_classes
+        self.vitstr = vitstr_tiny(num_tokens=num_classes)
 
     def forward(self, input):
         """ Transformation stage """
         features = self.cnn_model(input)
-        output = self.vitstr(features)
+        prediction = self.vitstr(features)
+        prediction = torch.nn.functional.softmax(prediction, dim=-1)
+
+        output = torch.argmax(prediction, -1)
         return output
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/crnn.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/crnn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/timm_tinyc.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/timm_tinyc.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/modules/vitstr.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_recognition/modules/vitstr.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/ocr_recognition/preprocessor.py` & `weathon-0.0.0.14/weathon/models/cv/ocr_recognition/preprocessor.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor, load_image
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModeKeys, ModelFile
+from weathon.models.cv.video_single_object_tracking.utils.utils import Preprocessor
+from weathon.preprocessors import load_image
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys, ModelFile
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.utils.config.config import Config
 
 
-@PREPROCESSORS.register_module(
-    Fields.cv, module_name=Preprocessors.ocr_recognition)
-class OCRRecognitionPreprocessor(Preprocessor):
+@PREPROCESSORS.register_module(Fields.cv, module_name=Preprocessors.ocr_recognition)
+class OCRRecognitionPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, mode: str = ModeKeys.INFERENCE):
         """The base constructor for all ocr recognition preprocessors.
 
         Args:
             model_dir (str): model directory to initialize some resource
             mode: The mode for the preprocessor.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/open_vocabulary_detection_vild/vild.py` & `weathon-0.0.0.14/weathon/models/cv/open_vocabulary_detection_vild/vild.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
@@ -10,29 +9,27 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 import os
-from typing import Any, Dict, Union
+from typing import Any, Dict
 
 import clip
 import numpy as np
 import tensorflow.compat.v1 as tf
 import torch.cuda
 from scipy.special import softmax
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_model import Model
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_model import Model
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @MODELS.register_module(
     Tasks.open_vocabulary_detection,
     module_name=Models.open_vocabulary_detection_vild)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/equi.py` & `weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/equi.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from __future__ import absolute_import, division, print_function
 from collections import OrderedDict
 
 import numpy as np
 import torch
 import torch.nn as nn
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/layers.py` & `weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/layers.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 class Conv3x3(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/mobilenet.py` & `weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/mobilenet.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Modified from https://github.com/pytorch/vision/blob/master/torchvision/models/mobilenet.py
 from torch import nn
 
 try:
     from torch.hub import load_state_dict_from_url
 except ImportError:
     from torch.utils.model_zoo import load_url as load_state_dict_from_url
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/resnet.py` & `weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/resnet.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Modified from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py
 import torch
 import torch.nn as nn
 
 try:
     from torch.hub import load_state_dict_from_url
 except ImportError:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/unifuse.py` & `weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/unifuse.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from __future__ import absolute_import, division, print_function
 from collections import OrderedDict
 
 import numpy as np
 import torch
 import torch.nn as nn
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/networks/util.py` & `weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/networks/util.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import cv2
 import numpy as np
 from scipy.ndimage import map_coordinates
 
 
 class Equirec2Cube:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/panorama_depth_estimation/unifuse_model.py` & `weathon-0.0.0.14/weathon/models/cv/panorama_depth_estimation/unifuse_model.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import numpy as np
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.panorama_depth_estimation.networks import (Equi,
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.panorama_depth_estimation.networks import (Equi,
                                                                      UniFuse)
-from modelscope.models.cv.panorama_depth_estimation.networks.util import \
+from weathon.models.cv.panorama_depth_estimation.networks.util import \
     Equirec2Cube
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @MODELS.register_module(
     Tasks.panorama_depth_estimation,
     module_name=Models.unifuse_depth_estimation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/pedestrian_attribute_recognition/model.py` & `weathon-0.0.0.14/weathon/models/cv/pedestrian_attribute_recognition/model.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,25 +1,22 @@
 # The implementation is based on
 # "Improving Pedestrian Attribute Recognition With Weakly-Supervised Multi-Scale Attribute-Specific Localization",
 # ICCV 2019, Seoul, paper available at https://arxiv.org/abs/1910.04562
 # Poster available at https://chufengt.github.io/publication/pedestrian-attribute/iccv_poster_id2029.pdf
 
-import os
-
-import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torch.nn import init
 from torchvision import models
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
 
 
 def gem(x, p=3, eps=1e-6):
     return F.adaptive_avg_pool2d(F.relu(x + eps).pow(p), (1, 1)).pow(1. / p)
 
 
 class GeM(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/common.py` & `weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/common.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from . import pointnet2_utils as pointutils
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py` & `weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/rcp_model.py` & `weathon-0.0.0.14/weathon/pipelines/cv/realtime_video_object_detection_pipeline.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,64 +1,58 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
+from typing import Any, Dict, List, Union
 
+import cv2
+import json
 import numpy as np
 import torch
+from PIL import Image
+from torchvision import transforms
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
-from .sf_rcp import SF_RCP
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.stream_yolo import RealtimeVideoDetector
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Model, Pipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import load_image
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
-@MODELS.register_module(
-    Tasks.pointcloud_sceneflow_estimation,
-    module_name=Models.rcp_sceneflow_estimation)
-class SceneFlowEstimation(TorchModel):
-
-    def __init__(self, model_dir: str, **kwargs):
-        """str -- model file root."""
-        super().__init__(model_dir, **kwargs)
-
-        assert torch.cuda.is_available(
-        ), 'current model only support run in gpu'
-
-        # build model
-        self.model = SF_RCP(
-            npoint=8192,
-            use_instance_norm=False,
-            model_name='SF_RCP',
-            use_insrance_norm=False,
-            use_curvature=True)
-
-        # load model
-        model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)
-
-        logger.info(f'load ckpt from:{model_path}')
-
-        checkpoint = torch.load(model_path, map_location='cpu')
-
-        self.model.load_state_dict({k: v for k, v in checkpoint.items()})
-        self.model.cuda()
-        self.model.eval()
-
-    def forward(self, Inputs):
-
-        return self.model(Inputs['pcd1'], Inputs['pcd2'], Inputs['pcd1'],
-                          Inputs['pcd2'])[-1]
-
-    def postprocess(self, Inputs):
-        output = Inputs['output']
-
-        results = {OutputKeys.OUTPUT: output.detach().cpu().numpy()[0]}
-
-        return results
-
-    def inference(self, data):
-        results = self.forward(data)
-
-        return results
+@PIPELINES.register_module(
+    Tasks.video_object_detection,
+    module_name=Pipelines.realtime_video_object_detection)
+class RealtimeVideoObjectDetectionPipeline(Pipeline):
+
+    def __init__(self, model: str, **kwargs):
+        super().__init__(model=model, **kwargs)
+
+    def preprocess(self, input: Input) -> Dict[Tensor, Union[str, np.ndarray]]:
+        return input
+
+    def forward(self, input: Input) -> Dict[Tensor, Dict[str, np.ndarray]]:
+        self.video_path = input
+        # Processing the whole video and return results for each frame
+        forward_output = self.model.inference_video(self.video_path)
+        return {'forward_output': forward_output}
+
+    def postprocess(self, input: Dict[Tensor, Dict[str, np.ndarray]],
+                    **kwargs) -> str:
+        forward_output = input['forward_output']
+
+        scores, boxes, labels, timestamps = [], [], [], []
+        for result in forward_output:
+            box, score, label, timestamp = result
+            scores.append(score)
+            boxes.append(box)
+            labels.append(label)
+            timestamps.append(timestamp)
+
+        return {
+            OutputKeys.BOXES: boxes,
+            OutputKeys.SCORES: scores,
+            OutputKeys.LABELS: labels,
+            OutputKeys.TIMESTAMPS: timestamps,
+        }
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py` & `weathon-0.0.0.14/weathon/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .common import (PointNetFeaturePropogation, PointNetSetAbstraction,
                      PointWiseOptimLayer, Sinkhorn)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
 
     from .item_model import ProductRetrievalEmbedding
 
 else:
     _import_structure = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/item_detection.py` & `weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/item_detection.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/item_embedding.py` & `weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/item_embedding.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/product_retrieval_embedding/item_model.py` & `weathon-0.0.0.14/weathon/models/cv/product_retrieval_embedding/item_model.py`

 * *Files 15% similar despite different names*

```diff
@@ -2,25 +2,25 @@
 
 import os.path as osp
 from typing import Any, Dict
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.product_retrieval_embedding.item_detection import \
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.product_retrieval_embedding.item_detection import \
     YOLOXONNX
-from modelscope.models.cv.product_retrieval_embedding.item_embedding import (
+from weathon.models.cv.product_retrieval_embedding.item_embedding import (
     preprocess, resnet50_embed)
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.device import create_device
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.device import create_device
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ProductRetrievalEmbedding']
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/product_segmentation/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/fields/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,17 +1,19 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .seg_infer import F3NetProductSegmentation
-
+    from .gen_field import MultiWOZBPETextField
+    from .intent_field import IntentBPETextField
 else:
-    _import_structure = {'seg_infer': ['F3NetProductSegmentation']}
+    _import_structure = {
+        'gen_field': ['MultiWOZBPETextField'],
+        'intent_field': ['IntentBPETextField']
+    }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/product_segmentation/net.py` & `weathon-0.0.0.14/weathon/models/cv/product_segmentation/net.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/product_segmentation/seg_infer.py` & `weathon-0.0.0.14/weathon/models/cv/product_segmentation/seg_infer.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
 import cv2
 import numpy as np
 import torch
 from PIL import Image
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .net import F3Net
 
 logger = get_logger()
 
 
 def load_state_dict(model_dir, device):
     _dict = torch.load(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/model.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/model.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,20 +2,20 @@
 # publicly available at https://github.com/mttr2021/MTTR
 
 import os.path as osp
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .utils import (MTTR, A2DSentencesPostProcess, HungarianMatcher,
                     ReferYoutubeVOSPostProcess, SetCriterion,
                     flatten_temporal_batch_dims,
                     nested_tensor_from_videos_list)
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/backbone.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/backbone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/criterion.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/criterion.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/matcher.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/matcher.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/misc.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/misc.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/mttr.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/mttr.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/postprocessing.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/postprocessing.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/segmentation.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/segmentation.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/referring_video_object_segmentation/utils/swin_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/referring_video_object_segmentation/utils/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/robust_image_classification/easyrobust_model.py` & `weathon-0.0.0.14/weathon/models/cv/robust_image_classification/easyrobust_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
 import torch
 import torch.nn as nn
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 
 
 def normalize_fn(tensor, mean, std):
     """Differentiable version of torchvision.functional.normalize"""
     # here we assume the color channel is in at dim=1
     mean = mean[None, :, None, None]
     std = std[None, :, None, None]
@@ -41,15 +40,15 @@
 class EasyRobustModel(TorchModel):
 
     def __init__(self, model_dir: str, **kwargs):
         import easyrobust.models
         from timm.models import create_model
         from mmcls.datasets import ImageNet
         import modelscope.models.cv.image_classification.backbones
-        from modelscope.utils.hub import read_config
+        from weathon.utils.hub.utils import read_config
 
         super().__init__(model_dir)
 
         self.config_type = 'ms_config'
         self.CLASSES = ImageNet.CLASSES
         cfg = read_config(model_dir)
         cfg.model.mm_model.pretrained = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/backbone/Res2Net_v1b.py` & `weathon-0.0.0.14/weathon/models/cv/salient_detection/models/backbone/Res2Net_v1b.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/modules.py` & `weathon-0.0.0.14/weathon/models/cv/salient_detection/models/modules.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .utils import ConvBNReLU
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/senet.py` & `weathon-0.0.0.14/weathon/models/cv/salient_detection/models/senet.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .backbone import res2net50_v1b_26w_4s as res2net
 from .modules import AMFusion, AreaLayer, EdgeLayer, StructureE
 from .utils import ASPP, CBAM, ConvBNReLU
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/u2net.py` & `weathon-0.0.0.14/weathon/models/cv/salient_detection/models/u2net.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/models/utils.py` & `weathon-0.0.0.14/weathon/models/cv/salient_detection/models/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/salient_detection/salient_model.py` & `weathon-0.0.0.14/weathon/models/cv/salient_detection/salient_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 import cv2
 import torch
 from PIL import Image
 from torchvision import transforms
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .models import U2NET, SENet
 
 
 @MODELS.register_module(
     Tasks.semantic_segmentation, module_name=Models.detection)
 class SalientDetection(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/common.py` & `weathon-0.0.0.14/weathon/models/cv/shop_segmentation/common.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/head_fpn.py` & `weathon-0.0.0.14/weathon/models/cv/shop_segmentation/head_fpn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/models.py` & `weathon-0.0.0.14/weathon/models/cv/shop_segmentation/models.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/neck_fpn.py` & `weathon-0.0.0.14/weathon/models/cv/shop_segmentation/neck_fpn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/shop_seg_base.py` & `weathon-0.0.0.14/weathon/models/cv/shop_segmentation/shop_seg_base.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/shop_seg_model.py` & `weathon-0.0.0.14/weathon/models/cv/shop_segmentation/shop_seg_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,27 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import os.path as osp
-from typing import Any, Dict
-
-import json
 import numpy as np
 import torch
-import torch.nn as nn
 import torch.nn.functional as F
 from PIL import Image
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.shop_segmentation import SHOPSEG
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.shop_segmentation import SHOPSEG
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ShopSegmentation']
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/shop_segmentation/utils.py` & `weathon-0.0.0.14/weathon/models/cv/shop_segmentation/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/detection_model/detection_module.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/detection_model/detection_module.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
 
 class ConvBNActiv(nn.Module):
 
     def __init__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/detection_model/detection_unet_in.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/detection_model/detection_unet_in.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from ..weights_init import weights_init
 from .detection_module import ConvBNActiv
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/inpainting_model/gconv.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/inpainting_model/gconv.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
 
 class GatedConvBNActiv(nn.Module):
 
     def __init__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/inpainting_model/inpainting_unet.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/inpainting_model/inpainting_unet.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.skin_retouching.inpainting_model.gconv import \
+from weathon.models.cv.skin_retouching.inpainting_model.gconv import \
     GatedConvBNActiv
 from ..weights_init import weights_init
 
 
 class RetouchingNet(nn.Module):
 
     def __init__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/box_utils.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/box_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/net.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/net.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/network.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/network.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/predict_single.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/predict_single.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/prior_box.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/prior_box.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/retinaface/utils.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/unet_deploy.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/unet_deploy.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import warnings
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from .weights_init import weights_init
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/utils.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import time
 from typing import Dict, List, Optional, Tuple, Union
 
 import cv2
 import numpy as np
 import torch
 import torch.nn.functional as F
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/skin_retouching/weights_init.py` & `weathon-0.0.0.14/weathon/models/cv/skin_retouching/weights_init.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
 
 def weights_init(init_type='kaiming', gain=0.02):
 
     def init_func(m):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/__init__.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,17 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
+
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .realtime_video_detector import RealtimeVideoDetector
+    from .model_zoo import get_zennet
+
 else:
     _import_structure = {
-        'realtime_video_detector': ['RealtimeVideoDetector'],
+        'model_zoo': ['get_zennet'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/data/data_augment.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/data/data_augment.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/default/streamyolo.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/default/streamyolo.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/exp/yolox_base.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/exp/yolox_base.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/darknet.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/darknet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/dfp_pafpn.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/dfp_pafpn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/network_blocks.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/network_blocks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/streamyolo.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/streamyolo.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/models/tal_head.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/models/tal_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/realtime_video_detector.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/realtime_video_detector.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,26 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import argparse
-import logging as logger
 import os
 import os.path as osp
-import time
 
 import cv2
-import json
 import numpy as np
 import torch
 from tqdm import tqdm
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.preprocessors import LoadImage
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .data.data_augment import ValTransform
 from .exp import get_exp_by_name
 from .utils import postprocess, timestamp_format
 
 
 @MODELS.register_module(
     group_key=Tasks.video_object_detection,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/stream_yolo/utils/boxes.py` & `weathon-0.0.0.14/weathon/models/cv/stream_yolo/utils/boxes.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/__init__.py` & `weathon-0.0.0.14/weathon/lrscheduler/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,20 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .rrdbnet_arch import RRDBNet
-    from .ecbsr_model import ECBSRModel
+    from .warmup import BaseWarmup, ConstantWarmup, ExponentialWarmup, LinearWarmup
 
 else:
     _import_structure = {
-        'rrdbnet_arch': ['RRDBNet'],
-        'ecbsr_model': ['ECBSRModel']
+        'warmup':['BaseWarmup', 'ConstantWarmup', 'ExponentialWarmup', 'LinearWarmup']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/arch_util.py` & `weathon-0.0.0.14/weathon/models/cv/super_resolution/arch_util.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/ecb.py` & `weathon-0.0.0.14/weathon/models/cv/super_resolution/ecb.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/ecbsr_model.py` & `weathon-0.0.0.14/weathon/models/cv/super_resolution/ecbsr_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
 import torch
 import torch.cuda
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .ecb import ECB
 
 logger = get_logger()
 __all__ = ['ECBSRModel']
 
 
 @MODELS.register_module(Tasks.image_super_resolution, module_name=Models.ecbsr)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/super_resolution/rrdbnet_arch.py` & `weathon-0.0.0.14/weathon/models/cv/super_resolution/rrdbnet_arch.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/lineless_table_process.py` & `weathon-0.0.0.14/weathon/models/cv/table_recognition/lineless_table_process.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/model_lore.py` & `weathon-0.0.0.14/weathon/models/cv/table_recognition/model_lore.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import copy
 import math
 from os.path import join
 from typing import Any, Dict
 
 import numpy as np
 import torch
 import torch.nn.functional as F
 from torch import nn
 
-from modelscope.metainfo import Models
-from modelscope.models import MODELS, TorchModel
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models import MODELS, TorchModel
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .lineless_table_process import (get_affine_transform,
                                      get_affine_transform_upper_left,
                                      load_lore_model, process_detect_output,
                                      process_logic_output)
 from .modules.lore_detector import LoreDetectModel
 from .modules.lore_processor import LoreProcessModel
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/modules/lore_detector.py` & `weathon-0.0.0.14/weathon/models/cv/table_recognition/modules/lore_detector.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/table_recognition/modules/lore_processor.py` & `weathon-0.0.0.14/weathon/models/cv/table_recognition/modules/lore_processor.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/clip.py` & `weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_base.py` & `weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_base.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_blocks.py` & `weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_blocks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_model.py` & `weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_model.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict
 
 import json
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from PIL import Image
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.text_driven_segmentation import \
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.text_driven_segmentation import \
     TextDrivenSegmentation
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 __all__ = ['TextDrivenSeg']
 
 
 @MODELS.register_module(
     Tasks.text_driven_segmentation,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_net.py` & `weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_net.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/lseg_vit.py` & `weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/lseg_vit.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/model.py` & `weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/text_driven_segmentation/simple_tokenizer.py` & `weathon-0.0.0.14/weathon/models/cv/text_driven_segmentation/simple_tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/__init__.py` & `weathon-0.0.0.14/weathon/trainers/audio/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,20 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-# The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
-
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .model_zoo import get_zennet
+    print('TYPE_CHECKING...')
+    from .tts_trainer import KanttsTrainer
+    from .ans_trainer import ANSTrainer
+    from .kws_nearfield_trainer import KWSNearfieldTrainer
+    from .kws_farfield_trainer import KWSFarfieldTrainer
 
 else:
     _import_structure = {
-        'model_zoo': ['get_zennet'],
+        'tts_trainer': ['KanttsTrainer'],
+        'ans_trainer': ['ANSTrainer'],
+        'kws_nearfield_trainer': ['KWSNearfieldTrainer'],
+        'kws_farfield_trainer': ['KWSFarfieldTrainer'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/basic_blocks.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/basic_blocks.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 import uuid
 
 import numpy as np
 import torch
 import torch.nn.functional as F
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/global_utils.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/global_utils.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 
 def smart_round(x, base=None):
     if base is None:
         if x > 32 * 8:
             round_base = 32
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/master_net.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/master_net.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 import torch
 import torch.nn.functional as F
 from torch import nn
 
 from . import basic_blocks, plain_net_utils
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/plain_net_utils.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/plain_net_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 from torch import nn
 
 from . import (basic_blocks, super_blocks, super_res_idwexkx, super_res_k1kxk1,
                super_res_kxkx)
 from .global_utils import create_netblock_list_from_str_inner
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/super_blocks.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/super_blocks.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 import uuid
 
 from torch import nn
 
 from . import basic_blocks, global_utils
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/super_res_idwexkx.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/super_res_idwexkx.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 import uuid
 
 from torch import nn
 
 from . import basic_blocks, global_utils
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/super_res_k1kxk1.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/super_res_k1kxk1.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 import uuid
 
 from torch import nn
 
 from . import basic_blocks, global_utils
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_classfication/super_res_kxkx.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_classfication/super_res_kxkx.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The ZenNAS implementation is also open-sourced by the authors, and available at https://github.com/idstcv/ZenNAS.
 
 import uuid
 
 from torch import nn
 
 from . import basic_blocks, global_utils
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/apis/detector_evaluater.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/apis/detector_evaluater.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,18 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 
 import torch
 
-from modelscope.models.cv.tinynas_detection.damo.apis.detector_inference import \
+from weathon.models.cv.tinynas_detection.damo.apis.detector_inference import \
     inference
-from modelscope.models.cv.tinynas_detection.damo.detectors.detector import \
+from weathon.models.cv.tinynas_detection.damo.detectors.detector import \
     build_local_model
-from modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo import (
+from weathon.msdatasets.dataset_cls.custom_datasets.damoyolo import (
     build_dataloader, build_dataset)
 
 
 def mkdir(path):
     if not os.path.exists(path):
         os.makedirs(path)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/apis/detector_inference.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/apis/detector_inference.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,17 @@
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
 import torch
 from tqdm import tqdm
 
-from modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo import evaluate
-from modelscope.utils.logger import get_logger
-from modelscope.utils.timer import Timer, get_time_str
-from modelscope.utils.torch_utils import (all_gather, get_world_size,
+from weathon.msdatasets.dataset_cls.custom_datasets.damoyolo import evaluate
+from weathon.utils.logger import get_logger
+from weathon.utils.timer import Timer, get_time_str
+from weathon.utils.torch_utils import (all_gather, get_world_size,
                                           is_master, synchronize)
 
 logger = get_logger()
 
 
 def compute_on_dataset(model, data_loader, device, timer=None, tta=False):
     model.eval()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import copy
 
 from .darknet import CSPDarknet
 from .tinynas_csp import load_tinynas_net as load_tinynas_net_csp
 from .tinynas_res import load_tinynas_net as load_tinynas_net_res
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,12 @@
 # Copyright (c) Megvii Inc. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 from torch import nn
 
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.base_ops import (
+from weathon.models.cv.tinynas_detection.damo.base_models.core.base_ops import (
     BaseConv, CSPLayer, DWConv, Focus, ResLayer, SPPBottleneck)
 
 
 class CSPDarknet(nn.Module):
 
     def __init__(
         self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.ops import (
+from weathon.models.cv.tinynas_detection.damo.base_models.core.ops import (
     Focus, RepConv, SPPBottleneck, get_activation)
-from modelscope.utils.file_utils import read_file
+from weathon.utils.fileio.file_utils import read_file
 
 
 class ConvKXBN(nn.Module):
 
     def __init__(self, in_c, out_c, kernel_size, stride):
         super(ConvKXBN, self).__init__()
         self.conv1 = nn.Conv2d(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.ops import (
+from weathon.models.cv.tinynas_detection.damo.base_models.core.ops import (
     Focus, RepConv, SPPBottleneck, get_activation)
-from modelscope.utils.file_utils import read_file
+from weathon.utils.fileio.file_utils import read_file
 
 
 class ConvKXBN(nn.Module):
 
     def __init__(self, in_c, out_c, kernel_size, stride):
         super(ConvKXBN, self).__init__()
         self.conv1 = nn.Conv2d(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/base_ops.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/base_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The DAMO-YOLO implementation is also open-sourced by the authors at https://github.com/tinyvision/damo-yolo.
 import math
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The DAMO-YOLO implementation is also open-sourced by the authors at https://github.com/tinyvision/damo-yolo.
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/ops.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 class SiLU(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # Copyright (c) OpenMMLab. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import warnings
 
 import torch
 import torch.nn.functional as F
 
-from modelscope.models.cv.tinynas_detection.damo.utils.boxes import \
+from weathon.models.cv.tinynas_detection.damo.utils.boxes import \
     bbox_overlaps
 
 
 class BaseAssigner(object):
     """Base assigner that assigns boxes to ground truth boxes."""
 
     def assign(self, bboxes, gt_bboxes, gt_bboxes_ignore=None, gt_labels=None):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The DAMO-YOLO implementation is also open-sourced by the authors at https://github.com/tinyvision/damo-yolo.
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torch.nn.init as init
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/utils.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,8 @@
 # Copyright (c) OpenMMLab. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from functools import partial
 
 import torch
 import torch.distributed as dist
 import torch.nn as nn
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/core/weight_init.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/core/weight_init.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The DAMO-YOLO implementation is also open-sourced by the authors at https://github.com/tinyvision/damo-yolo.
 
 import functools
 from functools import partial
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.base_ops import (
+from weathon.models.cv.tinynas_detection.damo.base_models.core.base_ops import (
     BaseConv, DWConv)
 
 
 class Scale(nn.Module):
 
     def __init__(self, scale=1.0):
         super(Scale, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.ops import \
+from weathon.models.cv.tinynas_detection.damo.base_models.core.ops import \
     ConvBNAct
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.ota_assigner import \
+from weathon.models.cv.tinynas_detection.damo.base_models.core.ota_assigner import \
     AlignOTAAssigner
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.utils import (
+from weathon.models.cv.tinynas_detection.damo.base_models.core.utils import (
     Scale, multi_apply, reduce_mean)
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.weight_init import (
+from weathon.models.cv.tinynas_detection.damo.base_models.core.weight_init import (
     bias_init_with_prob, normal_init)
-from modelscope.models.cv.tinynas_detection.damo.base_models.losses.gfocal_loss import (
+from weathon.models.cv.tinynas_detection.damo.base_models.losses.gfocal_loss import (
     DistributionFocalLoss, GIoULoss, QualityFocalLoss)
-from modelscope.models.cv.tinynas_detection.damo.utils import postprocess
+from weathon.models.cv.tinynas_detection.damo.utils import postprocess
 
 
 def distance2bbox(points, distance, max_shape=None):
     """Decode distance prediction to bounding box.
     """
     x1 = points[..., 0] - distance[..., 0]
     y1 = points[..., 1] - distance[..., 1]
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 class FeatureLoss(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 import functools
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.tinynas_detection.damo.utils.boxes import \
+from weathon.models.cv.tinynas_detection.damo.utils.boxes import \
     bbox_overlaps
 
 
 def reduce_loss(loss, reduction):
     """Reduce loss as specified.
     Args:
         loss (Tensor): Elementwise loss tensor.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import collections
 
 import networkx as nx
 
 Node = collections.namedtuple('Node', ['id', 'inputs', 'type'])
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The DAMO-YOLO implementation is also open-sourced by the authors at https://github.com/tinyvision/damo-yolo.
 
 import math
 from collections import OrderedDict
 from functools import partial
 from typing import Callable, List, Optional, Tuple, Union
 
@@ -10,15 +9,15 @@
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from timm import create_model
 from timm.models.layers import (Swish, create_conv2d, create_pool2d,
                                 get_act_layer)
 
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.base_ops import (
+from weathon.models.cv.tinynas_detection.damo.base_models.core.base_ops import (
     CSPLayer, ShuffleBlock, ShuffleCSPLayer)
 from .giraffe_config import get_graph_config
 
 _ACT_LAYER = Swish
 
 
 class SequentialList(nn.Sequential):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.tinynas_detection.damo.base_models.core.ops import (
+from weathon.models.cv.tinynas_detection.damo.base_models.core.ops import (
     ConvBNAct, CSPStage)
 
 
 class GiraffeNeckV2(nn.Module):
 
     def __init__(
         self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/detectors/detector.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/detectors/detector.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 from torch.nn.parallel import DistributedDataParallel as DDP
 
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.cv.tinynas_detection.damo.base_models.backbones import \
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.models.cv.tinynas_detection.damo.base_models.backbones import \
     build_backbone
-from modelscope.models.cv.tinynas_detection.damo.base_models.heads import \
+from weathon.models.cv.tinynas_detection.damo.base_models.heads import \
     build_head
-from modelscope.models.cv.tinynas_detection.damo.base_models.necks import \
+from weathon.models.cv.tinynas_detection.damo.base_models.necks import \
     build_neck
-from modelscope.models.cv.tinynas_detection.damo.structures.image_list import \
+from weathon.models.cv.tinynas_detection.damo.structures.image_list import \
     to_image_list
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class Detector(TorchModel):
 
     def __init__(self, config):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/structures/bounding_box.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/structures/bounding_box.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/structures/boxlist_ops.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/structures/boxlist_ops.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/structures/image_list.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/structures/image_list.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/utils/boxes.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/utils/boxes.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 # Copyright (c) Megvii Inc. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch
 import torchvision
 
-from modelscope.models.cv.tinynas_detection.damo.structures.bounding_box import \
+from weathon.models.cv.tinynas_detection.damo.structures.bounding_box import \
     BoxList
 
 __all__ = [
     'filter_box',
     'postprocess',
     'bboxes_iou',
     'matrix_iou',
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/damo/utils/model_utils.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/damo/utils/model_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/detector.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/detector.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The DAMO-YOLO implementation is also open-sourced by the authors at https://github.com/tinyvision/damo-yolo.
 
 import os.path as osp
 import pickle
 
 import torch
 import torch.nn as nn
 import torchvision
 
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.cv.tinynas_detection.damo.base_models.backbones import \
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.models.cv.tinynas_detection.damo.base_models.backbones import \
     build_backbone
-from modelscope.models.cv.tinynas_detection.damo.base_models.heads import \
+from weathon.models.cv.tinynas_detection.damo.base_models.heads import \
     build_head
-from modelscope.models.cv.tinynas_detection.damo.base_models.necks import \
+from weathon.models.cv.tinynas_detection.damo.base_models.necks import \
     build_neck
-from modelscope.outputs.cv_outputs import DetectionOutput
+from weathon.utils.output.cv_outputs import DetectionOutput
 from .utils import parse_config
 
 
 class SingleStageDetector(TorchModel):
     """
     The base class of single stage detector.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/tinynas_detection/utils.py` & `weathon-0.0.0.14/weathon/models/cv/tinynas_detection/utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # The DAMO-YOLO implementation is also open-sourced by the authors, and available
 # at https://github.com/tinyvision/damo-yolo.
 
 import importlib
 import os
 import shutil
 import sys
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/UNet_for_video_deinterlace.py` & `weathon-0.0.0.14/weathon/models/cv/video_deinterlace/UNet_for_video_deinterlace.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from copy import deepcopy
 from typing import Any, Dict, Union
 
 import torch.cuda
 import torch.nn.functional as F
 from torch.nn.parallel import DataParallel, DistributedDataParallel
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.video_deinterlace.deinterlace_arch import \
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.video_deinterlace.deinterlace_arch import \
     DeinterlaceNet
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 __all__ = ['UNetForVideoDeinterlace']
 
 
 def convert(param):
     return {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/archs.py` & `weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/archs.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 import torch.fft
 import torch.nn as nn
 import torch.nn.functional as F
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/deep_fourier_upsampling.py` & `weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/deep_fourier_upsampling.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/enh.py` & `weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/enh.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_deinterlace.models.archs import (DoubleConv,
+from weathon.models.cv.video_deinterlace.models.archs import (DoubleConv,
                                                                  DownConv,
                                                                  TripleConv,
                                                                  UpCatConv)
-from modelscope.models.cv.video_deinterlace.models.utils import warp
+from weathon.models.cv.video_deinterlace.models.utils import warp
 
 
 class DeinterlaceEnh(nn.Module):
     """Defines a U-Net video enhancement module
 
     Arg:
         num_in_ch (int): Channel number of inputs. Default: 3.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/fre.py` & `weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/fre.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_deinterlace.models.archs import (DoubleConv,
+from weathon.models.cv.video_deinterlace.models.archs import (DoubleConv,
                                                                  DownConv,
                                                                  TripleConv,
                                                                  UpCatConv)
-from modelscope.models.cv.video_deinterlace.models.deep_fourier_upsampling import \
+from weathon.models.cv.video_deinterlace.models.deep_fourier_upsampling import \
     freup_Periodicpadding
 
 
 class DeinterlaceFre(nn.Module):
 
     def __init__(self, num_in_ch=3, num_out_ch=3, ngf=64):
         """Defines a video deinterlace module.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_deinterlace/models/utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_deinterlace/models/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 
 
 def warp(im, flow):
 
     def _repeat(x, n_repeats):
         rep = torch.ones((1, n_repeats), dtype=torch.int32)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/configs/default_config.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/configs/default_config.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/dro_model.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/dro_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,32 +1,31 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import os.path as osp
 from glob import glob
 
 import cv2
 import numpy as np
 import torch
 import tqdm
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.video_depth_estimation.models.model_wrapper import \
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.video_depth_estimation.models.model_wrapper import \
     ModelWrapper
-from modelscope.models.cv.video_depth_estimation.utils.augmentations import (
+from weathon.models.cv.video_depth_estimation.utils.augmentations import (
     resize_image, to_tensor)
-from modelscope.models.cv.video_depth_estimation.utils.config import \
+from weathon.models.cv.video_depth_estimation.utils.config import \
     parse_test_file
-from modelscope.models.cv.video_depth_estimation.utils.depth import (
+from weathon.models.cv.video_depth_estimation.utils.depth import (
     inv2depth, viz_inv_depth, write_depth)
-from modelscope.models.cv.video_depth_estimation.utils.image import (
+from weathon.models.cv.video_depth_estimation.utils.image import (
     get_intrinsics, load_image, parse_video)
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.video_depth_estimation,
     module_name=Models.dro_resnet18_depth_estimation)
 class DROEstimation(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/camera.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/camera.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from functools import lru_cache
 
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.video_depth_estimation.geometry.camera_utils import \
+from weathon.models.cv.video_depth_estimation.geometry.camera_utils import \
     scale_intrinsics
-from modelscope.models.cv.video_depth_estimation.geometry.pose import Pose
-from modelscope.models.cv.video_depth_estimation.utils.image import image_grid
+from weathon.models.cv.video_depth_estimation.geometry.pose import Pose
+from weathon.models.cv.video_depth_estimation.utils.image import image_grid
 
 
 class Camera(nn.Module):
     """
     Differentiable camera class implementing reconstruction and projection
     functions for a pinhole model.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/camera_utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/camera_utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn.functional as funct
 
 ########################################################################################################################
 
 
 def construct_K(fx, fy, cx, cy, dtype=torch.float, device=None):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/pose.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/pose.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 
-from modelscope.models.cv.video_depth_estimation.geometry.pose_utils import (
+from weathon.models.cv.video_depth_estimation.geometry.pose_utils import (
     invert_pose, pose_vec2mat)
 
 ########################################################################################################################
 
 
 class Pose:
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/geometry/pose_utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/geometry/pose_utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 from torch._C import dtype
 
 
 def mat2euler(mat):
     euler = torch.ones(mat.shape[0], 3, dtype=mat.dtype, device=mat.device)
@@ -77,15 +76,15 @@
     """Convert Euler parameters to transformation matrix."""
     if mode is None:
         return vec
     trans, rot = vec[:, :3].unsqueeze(-1), vec[:, 3:]
     if mode == 'euler':
         rot_mat = euler2mat(rot)
     elif mode == 'axis_angle':
-        from modelscope.models.cv.video_depth_estimation.geometry.pose_trans import axis_angle_to_matrix
+        from weathon.models.cv.video_depth_estimation.geometry.pose_trans import axis_angle_to_matrix
         rot_mat = axis_angle_to_matrix(rot)
     else:
         raise ValueError('Rotation mode not supported {}'.format(mode))
     mat = torch.cat([rot_mat, trans], dim=2)  # [B,3,4]
     return mat
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/model_checkpoint.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/model_checkpoint.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/model_utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/model_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # Part of the implementation is borrowed and modified from PackNet-SfM,
 # made publicly available under the MIT License at https://github.com/TRI-ML/packnet-sfm
-from modelscope.models.cv.video_depth_estimation.utils.types import (is_list,
+from weathon.models.cv.video_depth_estimation.utils.types import (is_list,
                                                                      is_numpy,
                                                                      is_tensor)
 
 
 def merge_outputs(*outputs):
     """
     Merges model outputs for logging
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/model_wrapper.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/model_wrapper.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,17 +3,17 @@
 import importlib
 import random
 from collections import OrderedDict
 
 import numpy as np
 import torch
 
-from modelscope.models.cv.video_depth_estimation.utils.load import (
+from weathon.models.cv.video_depth_estimation.utils.load import (
     filter_args, load_class, load_class_args_create, load_network)
-from modelscope.models.cv.video_depth_estimation.utils.misc import pcolor
+from weathon.models.cv.video_depth_estimation.utils.misc import pcolor
 
 
 class ModelWrapper(torch.nn.Module):
     """
     Top-level torch.nn.Module wrapper around a SfmModel (pose+depth networks).
     Designed to use models with high-level Trainer classes (cf. trainers/).
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/sfm_model_mf.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/sfm_model_mf.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Part of the implementation is borrowed and modified from PackNet-SfM,
 # made publicly available under the MIT License at https://github.com/TRI-ML/packnet-sfm
 import random
 
 import torch.nn as nn
 
-from modelscope.models.cv.video_depth_estimation.geometry.pose import Pose
-from modelscope.models.cv.video_depth_estimation.utils.image import \
+from weathon.models.cv.video_depth_estimation.geometry.pose import Pose
+from weathon.models.cv.video_depth_estimation.utils.image import \
     flip_lr as flip_lr_img
-from modelscope.models.cv.video_depth_estimation.utils.image import (
+from weathon.models.cv.video_depth_estimation.utils.image import (
     flip_lr_intr, flip_mf_model, interpolate_scales)
-from modelscope.models.cv.video_depth_estimation.utils.misc import make_list
+from weathon.models.cv.video_depth_estimation.utils.misc import make_list
 
 
 class SfmModelMF(nn.Module):
     """
     Model class encapsulating a pose and depth networks.
 
     Parameters
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/models/sup_model_mf.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/models/sup_model_mf.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Part of the implementation is borrowed and modified from PackNet-SfM,
 # made publicly available under the MIT License at https://github.com/TRI-ML/packnet-sfm
-from modelscope.models.cv.video_depth_estimation.models.model_utils import \
+from weathon.models.cv.video_depth_estimation.models.model_utils import \
     merge_outputs
-from modelscope.models.cv.video_depth_estimation.models.sfm_model_mf import \
+from weathon.models.cv.video_depth_estimation.models.sfm_model_mf import \
     SfmModelMF
-from modelscope.models.cv.video_depth_estimation.utils.depth import depth2inv
+from weathon.models.cv.video_depth_estimation.utils.depth import depth2inv
 
 
 class SupModelMF(SfmModelMF):
     """
     Model that inherits a depth and pose network from SfmModel and
     includes the photometric loss for self-supervised training.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,24 +2,24 @@
 # made publicly available under the MIT License at https://github.com/TRI-ML/packnet-sfm
 from functools import partial
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_depth_estimation.geometry.camera import (
+from weathon.models.cv.video_depth_estimation.geometry.camera import (
     Camera, Pose)
-from modelscope.models.cv.video_depth_estimation.networks.layers.resnet.layers import \
+from weathon.models.cv.video_depth_estimation.networks.layers.resnet.layers import \
     disp_to_depth
-from modelscope.models.cv.video_depth_estimation.networks.optim.extractor import \
+from weathon.models.cv.video_depth_estimation.networks.optim.extractor import \
     ResNetEncoder
-from modelscope.models.cv.video_depth_estimation.networks.optim.update import (
+from weathon.models.cv.video_depth_estimation.networks.optim.update import (
     BasicUpdateBlockDepth, BasicUpdateBlockPose, DepthHead, PoseHead,
     UpMaskNet)
-from modelscope.models.cv.video_depth_estimation.utils.depth import inv2depth
+from weathon.models.cv.video_depth_estimation.utils.depth import inv2depth
 
 
 class DepthPoseNet(nn.Module):
 
     def __init__(self, version=None, min_depth=0.1, max_depth=100, **kwargs):
         super().__init__()
         self.min_depth = min_depth
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/layers.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/layers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/optim/extractor.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/optim/extractor.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/networks/optim/update.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/networks/optim/update.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/augmentations.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/augmentations.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import random
 
 import cv2
 import numpy as np
 import torchvision.transforms as transforms
 from PIL import Image
 
-from modelscope.models.cv.video_depth_estimation.utils.misc import filter_dict
+from weathon.models.cv.video_depth_estimation.utils.misc import filter_dict
 
 ########################################################################################################################
 
 
 def resize_image(image, shape, interpolation=Image.ANTIALIAS):
     """
     Resizes input image.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/config.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/config.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,19 +2,19 @@
 # made publicly available under the MIT License at https://github.com/TRI-ML/packnet-sfm
 import os
 from datetime import datetime
 
 import torch
 from yacs.config import CfgNode
 
-from modelscope.models.cv.video_depth_estimation.utils.horovod import on_rank_0
-from modelscope.models.cv.video_depth_estimation.utils.load import (
+from weathon.models.cv.video_depth_estimation.utils.horovod import on_rank_0
+from weathon.models.cv.video_depth_estimation.utils.load import (
     backwards_state_dict, load_class)
-from modelscope.models.cv.video_depth_estimation.utils.misc import make_list
-from modelscope.models.cv.video_depth_estimation.utils.types import (is_cfg,
+from weathon.models.cv.video_depth_estimation.utils.misc import make_list
+from weathon.models.cv.video_depth_estimation.utils.types import (is_cfg,
                                                                      is_list)
 
 
 def prep_dataset(config):
     """
     Expand dataset configuration to match split length
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/depth.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/depth.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # Part of the implementation is borrowed and modified from PackNet-SfM,
 # made publicly available under the MIT License at https://github.com/TRI-ML/packnet-sfm
 import numpy as np
 import torch
 import torchvision.transforms as transforms
 from matplotlib.cm import get_cmap
 
-from modelscope.models.cv.video_depth_estimation.utils.image import (
+from weathon.models.cv.video_depth_estimation.utils.image import (
     flip_lr, gradient_x, gradient_y, interpolate_image, load_image)
-from modelscope.models.cv.video_depth_estimation.utils.types import (is_seq,
+from weathon.models.cv.video_depth_estimation.utils.types import (is_seq,
                                                                      is_tensor)
 
 
 def load_depth(file):
     """
     Load a depth map from file
     Parameters
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/horovod.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/horovod.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/image.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/image.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 
 import cv2
 import numpy as np
 import torch
 import torch.nn.functional as funct
 from PIL import Image
 
-from modelscope.models.cv.video_depth_estimation.utils.misc import same_shape
+from weathon.models.cv.video_depth_estimation.utils.misc import same_shape
 
 
 def parse_video(video_file, save_root, sample_rate=10):
     os.makedirs(save_root, exist_ok=True)
 
     cap = cv2.VideoCapture(video_file)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/image_gt.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/image_gt.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 from functools import lru_cache
 
 import cv2
 import torch
 import torch.nn.functional as funct
 from PIL import Image
 
-from modelscope.models.cv.video_depth_estimation.utils.misc import same_shape
+from weathon.models.cv.video_depth_estimation.utils.misc import same_shape
 
 
 def load_image(path):
     """
     Read an image using PIL
 
     Parameters
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/load.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/load.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,19 +5,19 @@
 import os
 import warnings
 from collections import OrderedDict
 from inspect import signature
 
 import torch
 
-from modelscope.models.cv.video_depth_estimation.utils.horovod import print0
-from modelscope.models.cv.video_depth_estimation.utils.misc import (make_list,
+from weathon.models.cv.video_depth_estimation.utils.horovod import print0
+from weathon.models.cv.video_depth_estimation.utils.misc import (make_list,
                                                                     pcolor,
                                                                     same_shape)
-from modelscope.models.cv.video_depth_estimation.utils.types import is_str
+from weathon.models.cv.video_depth_estimation.utils.types import is_str
 
 
 def set_debug(debug):
     """
     Enable or disable debug terminal logging
 
     Parameters
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/misc.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/misc.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # Part of the implementation is borrowed and modified from PackNet-SfM,
 # made publicly available under the MIT License at https://github.com/TRI-ML/packnet-sfm
 from termcolor import colored
 
-from modelscope.models.cv.video_depth_estimation.utils.types import is_list
+from weathon.models.cv.video_depth_estimation.utils.types import is_list
 
 ########################################################################################################################
 
 
 def filter_dict(dictionary, keywords):
     """
     Returns only the keywords that are part of a dictionary
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_depth_estimation/utils/types.py` & `weathon-0.0.0.14/weathon/models/cv/video_depth_estimation/utils/types.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/VFINet_arch.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/VFINet_arch.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.video_frame_interpolation.flow_model.raft import RAFT
-from modelscope.models.cv.video_frame_interpolation.interp_model.IFNet_swin import \
+from weathon.models.cv.video_frame_interpolation.flow_model.raft import RAFT
+from weathon.models.cv.video_frame_interpolation.interp_model.IFNet_swin import \
     IFNet
-from modelscope.models.cv.video_frame_interpolation.interp_model.refinenet_arch import (
+from weathon.models.cv.video_frame_interpolation.interp_model.refinenet_arch import (
     InterpNet, InterpNetDs)
 
 
 class VFINet(nn.Module):
 
     def __init__(self, args, Ds_flag=False):
         super(VFINet, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from copy import deepcopy
 from typing import Any, Dict, Union
 
 import torch.cuda
 import torch.nn.functional as F
 from torch.nn.parallel import DataParallel, DistributedDataParallel
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-# from modelscope.models.cv.video_super_resolution.common import charbonnier_loss
-from modelscope.models.cv.video_frame_interpolation.VFINet_arch import VFINet
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+# from weathon.models.cv.video_super_resolution.common import charbonnier_loss
+from weathon.models.cv.video_frame_interpolation.VFINet_arch import VFINet
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 __all__ = ['VFINetForVideoFrameInterpolation']
 
 
 def convert(param):
     return {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/corr.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/corr.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # The implementation is adopted from RAFT,
 # made publicly available under the BSD-3-Clause license at https://github.com/princeton-vl/RAFT
 
 import torch
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_frame_interpolation.utils.utils import (
+from weathon.models.cv.video_frame_interpolation.utils.utils import (
     bilinear_sampler, coords_grid)
 
 
 class CorrBlock:
 
     def __init__(self, fmap1, fmap2, num_levels=4, radius=4):
         self.num_levels = num_levels
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/extractor.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/extractor.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/raft.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/raft.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,21 +2,21 @@
 # made publicly available under the BSD-3-Clause license at https://github.com/princeton-vl/RAFT
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_frame_interpolation.flow_model.corr import (
+from weathon.models.cv.video_frame_interpolation.flow_model.corr import (
     AlternateCorrBlock, CorrBlock)
-from modelscope.models.cv.video_frame_interpolation.flow_model.extractor import (
+from weathon.models.cv.video_frame_interpolation.flow_model.extractor import (
     BasicEncoder, SmallEncoder)
-from modelscope.models.cv.video_frame_interpolation.flow_model.update import (
+from weathon.models.cv.video_frame_interpolation.flow_model.update import (
     BasicUpdateBlock, SmallUpdateBlock)
-from modelscope.models.cv.video_frame_interpolation.utils.utils import (
+from weathon.models.cv.video_frame_interpolation.utils.utils import (
     bilinear_sampler, coords_grid, upflow8)
 
 autocast = torch.cuda.amp.autocast
 
 
 class RAFT(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/flow_model/update.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/flow_model/update.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from timm.models.layers import trunc_normal_
 
-from modelscope.models.cv.video_frame_interpolation.interp_model.transformer_layers import (
+from weathon.models.cv.video_frame_interpolation.interp_model.transformer_layers import (
     RTFL, PatchEmbed, PatchUnEmbed)
 
 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
 
 backwarp_tenGrid = {}
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/UNet.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/UNet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/flow_reversal.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/flow_reversal.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Part of the implementation is borrowed and modified from QVI, publicly available at https://github.com/xuxy09/QVI
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_frame_interpolation.interp_model.flow_reversal import \
+from weathon.models.cv.video_frame_interpolation.interp_model.flow_reversal import \
     FlowReversal
-from modelscope.models.cv.video_frame_interpolation.interp_model.IFNet_swin import \
+from weathon.models.cv.video_frame_interpolation.interp_model.IFNet_swin import \
     IFNet
-from modelscope.models.cv.video_frame_interpolation.interp_model.UNet import \
+from weathon.models.cv.video_frame_interpolation.interp_model.UNet import \
     Small_UNet_Ds
 
 
 class AcFusionLayer(nn.Module):
 
     def __init__(self, ):
         super(AcFusionLayer, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/interp_model/transformer_layers.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/interp_model/transformer_layers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/utils/scene_change_detection.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/utils/scene_change_detection.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 
 def calc_hist(img_tensor):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_frame_interpolation/utils/utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_frame_interpolation/utils/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/decoder.py` & `weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/decoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/deep_guided_filter.py` & `weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/deep_guided_filter.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/effv2.py` & `weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/effv2.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/lraspp.py` & `weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/lraspp.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_human_matting/models/matting.py` & `weathon-0.0.0.14/weathon/models/cv/video_human_matting/models/matting.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_inpainting/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/video_inpainting/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .inpainting_model import VideoInpainting
 
 else:
     _import_structure = {'inpainting_model': ['VideoInpainting']}
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_inpainting/inpainting.py` & `weathon-0.0.0.14/weathon/models/cv/video_inpainting/inpainting.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_inpainting/inpainting_model.py` & `weathon-0.0.0.14/weathon/models/cv/video_inpainting/inpainting_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,20 +7,20 @@
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import torchvision.models as models
 
-from modelscope.metainfo import Models
-from modelscope.models import Model
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models import Model
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class BaseNetwork(nn.Module):
 
     def __init__(self):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import TYPE_CHECKING
+# Modified by Zhipu.AI
+# Original Copyright (c) Alibaba, Inc. and its affiliates.
+from typing import TYPE_CHECKING, Union
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .video_knet import (
-        KNetTrack, )
-    from .neck import MSDeformAttnPixelDecoder
-
+    from .codegeex_for_code_translation import CodeGeeXForCodeTranslation
+    from .codegeex_for_code_generation import CodeGeeXForCodeGeneration
 else:
     _import_structure = {
-        'video_knet': ['KNetTrack'],
-        'neck': ['MSDeformAttnPixelDecoder']
+        'codegeex_for_code_translation': ['CodeGeeXForCodeTranslation'],
+        'codegeex_for_code_generation': ['CodeGeeXForCodeGeneration'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_head.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_iter_head.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_iter_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_update_head.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/head/kernel_updator.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/head/kernel_updator.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/neck/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_human_parsing/m2fp/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,18 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .msdeformattn_decoder import (
-        MSDeformAttnPixelDecoder, )
+    from .m2fp_encoder import MSDeformAttnPixelDecoder
+    from .m2fp_decoder import MultiScaleMaskedTransformerDecoder
 
 else:
-    _import_structure = {'msdeformattn_decoder': ['MSDeformAttnPixelDecoder']}
+    _import_structure = {
+        'm2fp_encoder': ['MSDeformAttnPixelDecoder'],
+        'm2fp_decoder': ['MultiScaleMaskedTransformerDecoder'],
+    }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/track/kernel_update_head.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/track/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_instance_segmentation/video_knet.py` & `weathon-0.0.0.14/weathon/models/cv/video_instance_segmentation/video_knet.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,19 @@
 # The implementation is adopted from Video-K-Net,
 # made publicly available at https://github.com/lxtGH/Video-K-Net follow the MIT license
 
 import torch.nn as nn
 from mmdet.models import build_head, build_neck
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.video_panoptic_segmentation.backbone.swin_transformer import \
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.video_panoptic_segmentation.backbone.swin_transformer import \
     SwinTransformerDIY
-from modelscope.models.cv.video_panoptic_segmentation.head.semantic_fpn_wrapper import \
-    SemanticFPNWrapper
-from modelscope.utils.constant import Tasks
-from .head.kernel_frame_iter_head import KernelFrameIterHeadVideo
-from .head.kernel_head import ConvKernelHeadVideo
-from .head.kernel_iter_head import KernelIterHeadVideo
-from .head.kernel_update_head import KernelUpdateHead
-from .head.kernel_updator import KernelUpdator
-from .neck import MSDeformAttnPixelDecoder
-from .track.kernel_update_head import KernelUpdateHeadVideo
-from .track.mask_hungarian_assigner import MaskHungarianAssignerVideo
+from weathon.utils.constants import Tasks
 
 
 @MODELS.register_module(
     Tasks.video_instance_segmentation,
     module_name=Models.video_instance_segmentation)
 class KNetTrack(TorchModel):
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/__init__.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .video_multi_object_tracking import VideoMultiObjectTracking
-
+    from .stable_diffusion import StableDiffusionWrapperPipeline
+    from .stable_diffusion import ChineseStableDiffusionPipeline
 else:
     _import_structure = {
-        'video_multi_object_tracking': ['VideoMultiObjectTracking'],
+        'stable_diffusion':
+        ['StableDiffusionWrapperPipeline', 'ChineseStableDiffusionPipeline']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/common.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/common.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/decode.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/decode.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # The implementation is adopted from FairMOT,
 # made publicly available under the MIT License at https://github.com/ifzhang/FairMOT
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.video_multi_object_tracking.utils.utils import (
+from weathon.models.cv.video_multi_object_tracking.utils.utils import (
     _gather_feat, _tranpose_and_gather_feat)
 
 
 def _nms(heat, kernel=3):
     pad = (kernel - 1) // 2
 
     hmax = nn.functional.max_pool2d(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/model.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/model.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # The implementation is adopted from FairMOT,
 # made publicly available under the MIT License at https://github.com/ifzhang/FairMOT
 import torch
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 from .yolo import get_pose_net as get_pose_net_yolo
 
 logger = get_logger()
 
 _model_factory = {'yolo': get_pose_net_yolo}
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/models/yolo.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/models/yolo.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # The implementation is adopted from FairMOT,
 # made publicly available under the MIT License at https://github.com/ifzhang/FairMOT
 import math
 from copy import deepcopy
 
 import torch.nn as nn
 
-from modelscope.models.base import TorchModel
-from modelscope.utils.logger import get_logger
+from weathon.models.base import TorchModel
+from weathon.utils.logger import get_logger
 from .common import C3, SPP, Concat, Conv, Focus
 
 logger = get_logger()
 
 backbone_param = {
     'nc':
     80,
@@ -41,15 +41,15 @@
             if m.bias is not None:
                 nn.init.constant_(m.bias, 0)
 
 
 class Model(nn.Module):
 
     def __init__(self, config=backbone_param, ch=3, nc=None, anchors=None):
-        super(Model, self).__init__()
+        super(BaseModel, self).__init__()
         self.yaml = config  # model dict
 
         # Define model
         ch = self.yaml['ch'] = self.yaml.get('ch', ch)  # input channels
         if nc and nc != self.yaml['nc']:
             self.yaml['nc'] = nc  # override yaml value
         self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/tracker/basetrack.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/tracker/basetrack.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/tracker/matching.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/tracker/matching.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # The implementation is adopted from FairMOT,
 # made publicly available under the MIT License at https://github.com/ifzhang/FairMOT
 import lap
 import numpy as np
 from scipy.spatial.distance import cdist
 
-from modelscope.models.cv.video_multi_object_tracking.utils import \
+from weathon.models.cv.video_multi_object_tracking.utils import \
     kalman_filter
-from modelscope.models.cv.video_multi_object_tracking.utils.utils import \
+from weathon.models.cv.video_multi_object_tracking.utils.utils import \
     bbox_iou
 
 
 def linear_assignment(cost_matrix, thresh):
     if cost_matrix.size == 0:
         return np.empty((0, 2),
                         dtype=int), tuple(range(cost_matrix.shape[0])), tuple(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/tracker/multitracker.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/tracker/multitracker.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,26 +2,26 @@
 # made publicly available under the MIT License at https://github.com/ifzhang/FairMOT
 from collections import deque
 
 import numpy as np
 import torch
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_multi_object_tracking.models.decode import \
+from weathon.models.cv.video_multi_object_tracking.models.decode import \
     mot_decode
-from modelscope.models.cv.video_multi_object_tracking.models.model import (
+from weathon.models.cv.video_multi_object_tracking.models.model import (
     create_model, load_model)
-from modelscope.models.cv.video_multi_object_tracking.tracker import matching
-from modelscope.models.cv.video_multi_object_tracking.tracker.basetrack import (
+from weathon.models.cv.video_multi_object_tracking.tracker import matching
+from weathon.models.cv.video_multi_object_tracking.tracker.basetrack import (
     BaseTrack, TrackState)
-from modelscope.models.cv.video_multi_object_tracking.utils.kalman_filter import \
+from weathon.models.cv.video_multi_object_tracking.utils.kalman_filter import \
     KalmanFilter
-from modelscope.models.cv.video_multi_object_tracking.utils.utils import (
+from weathon.models.cv.video_multi_object_tracking.utils.utils import (
     _tranpose_and_gather_feat, ctdet_post_process)
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class STrack(BaseTrack):
     shared_kalman = KalmanFilter()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/image.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/image.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/kalman_filter.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/kalman_filter.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_multi_object_tracking/utils/visualization.py` & `weathon-0.0.0.14/weathon/models/cv/video_multi_object_tracking/utils/visualization.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/aggregate.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/aggregate.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/cbam.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/cbam.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/eval_network.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/eval_network.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # Adopted from https://github.com/Limingxing00/RDE-VOS-CVPR2022
 # under MIT License
 
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.video_object_segmentation.modules import (
+from weathon.models.cv.video_object_segmentation.modules import (
     KeyEncoder, KeyProjection, MemCrompress, ValueEncoder)
-from modelscope.models.cv.video_object_segmentation.network import Decoder
+from weathon.models.cv.video_object_segmentation.network import Decoder
 
 
 class RDE_VOS(nn.Module):
 
     def __init__(self, repeat=0):
         super().__init__()
         self.key_encoder = KeyEncoder()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/inference_core.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/inference_core.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # Adopted from https://github.com/Limingxing00/RDE-VOS-CVPR2022
 # under MIT License
 
 import torch
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_object_segmentation.aggregate import aggregate
-from modelscope.models.cv.video_object_segmentation.inference_memory_bank import \
+from weathon.models.cv.video_object_segmentation.aggregate import aggregate
+from weathon.models.cv.video_object_segmentation.inference_memory_bank import \
     MemoryBank
 
 
 def pad_divide_by(in_img, d, in_size=None):
     if in_size is None:
         h, w = in_img.shape[-2:]
     else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/inference_memory_bank.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/inference_memory_bank.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/model.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/model.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.video_object_segmentation.eval_network import RDE_VOS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.video_object_segmentation.eval_network import RDE_VOS
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @MODELS.register_module(
     Tasks.video_object_segmentation,
     module_name=Models.video_object_segmentation)
 class VideoObjectSegmentation(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/modules.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/modules.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 # under MIT License
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torchvision import models
 
-from modelscope.models.cv.video_object_segmentation import cbam, mod_resnet
+from weathon.models.cv.video_object_segmentation import cbam, mod_resnet
 
 
 class ResBlock(nn.Module):
 
     def __init__(self, indim, outdim=None):
         super(ResBlock, self).__init__()
         if outdim is None:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_object_segmentation/network.py` & `weathon-0.0.0.14/weathon/models/cv/video_object_segmentation/network.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 import math
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_object_segmentation.modules import (
+from weathon.models.cv.video_object_segmentation.modules import (
     KeyEncoder, KeyProjection, MemCrompress, ResBlock, UpsampleBlock,
     ValueEncoder, ValueEncoderSO)
 
 
 class Decoder(nn.Module):
 
     def __init__(self):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/kernel_head.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/kernel_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/kernel_update_head.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/kernel_updator.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/kernel_updator.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/mask.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/mask.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/head/track_heads.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/head/track_heads.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/neck/fpn.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/neck/fpn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/video_k_net.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/video_k_net.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,25 +3,23 @@
 
 import numpy as np
 import torch
 import torch.nn as nn
 from mmcv.cnn import build_activation_layer, build_norm_layer
 from mmdet.models.builder import build_head
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
 from .backbone.swin_transformer import SwinTransformerDIY
 from .head.kernel_head import ConvKernelHead
-from .head.kernel_iter_head import VideoKernelIterHead
 from .head.track_heads import QuasiDenseMaskEmbedHeadGTMask
 from .neck.fpn import FPN
-from .track.quasi_dense_embed_tracker import (QuasiDenseEmbedTracker,
-                                              build_tracker)
+from .track.quasi_dense_embed_tracker import (build_tracker)
 from .visualizer import vip_seg_id_to_label
 
 
 def coords2bbox_all(coords):
     left = coords[:, 0].min().item()
     top = coords[:, 1].min().item()
     right = coords[:, 0].max().item()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_panoptic_segmentation/visualizer.py` & `weathon-0.0.0.14/weathon/models/cv/video_panoptic_segmentation/visualizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/config/ostrack.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/config/ostrack.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/attn.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/attn.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/attn_blocks.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/attn_blocks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/head.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/layers/patch_embed.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/layers/patch_embed.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # The implementation is adopted from OSTrack,
 # made publicly available under the MIT License at https://github.com/botaoye/OSTrack/
 import torch.nn as nn
 from timm.models.layers import to_2tuple
 
-from modelscope.models.cv.video_single_object_tracking.models.layers.patch_embed import \
+from weathon.models.cv.video_single_object_tracking.models.layers.patch_embed import \
     PatchEmbed
 
 
 class BaseBackbone(nn.Module):
 
     def __init__(self):
         super().__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/ostrack.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/ostrack.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # The implementation is adopted from OSTrack,
 # made publicly available under the MIT License at https://github.com/botaoye/OSTrack/
 import torch
 from torch import nn
 
-from modelscope.models.cv.video_single_object_tracking.models.layers.head import \
+from weathon.models.cv.video_single_object_tracking.models.layers.head import \
     build_box_head
 from .vit_ce import vit_base_patch16_224_ce
 
 
 class OSTrack(nn.Module):
     """ This is the base class for OSTrack """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,17 +2,17 @@
 # made publicly available under the MIT License at https://github.com/botaoye/OSTrack/
 from functools import partial
 
 import torch
 import torch.nn as nn
 from timm.models.layers import DropPath, Mlp, to_2tuple
 
-from modelscope.models.cv.video_single_object_tracking.models.layers.attn_blocks import \
+from weathon.models.cv.video_single_object_tracking.models.layers.attn_blocks import \
     CEBlock
-from modelscope.models.cv.video_single_object_tracking.models.layers.patch_embed import \
+from weathon.models.cv.video_single_object_tracking.models.layers.patch_embed import \
     PatchEmbed
 from .base_backbone import BaseBackbone
 from .utils import combine_tokens, recover_tokens
 
 
 class Attention(nn.Module):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/procontext/procontext.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/procontext/procontext.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # The ProContEXT implementation is also open-sourced by the authors,
 # and available at https://github.com/jp-lan/ProContEXT
 import torch
 from torch import nn
 
-from modelscope.models.cv.video_single_object_tracking.models.layers.head import \
+from weathon.models.cv.video_single_object_tracking.models.layers.head import \
     build_box_head
 from .vit_ce import vit_base_patch16_224_ce
 
 
 class ProContEXT(nn.Module):
     """ This is the base class for ProContEXT """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/procontext/utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/procontext/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/models/procontext/vit_ce.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/models/procontext/vit_ce.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,21 +2,21 @@
 # and available at https://github.com/jp-lan/ProContEXT
 from functools import partial
 
 import torch
 import torch.nn as nn
 from timm.models.layers import to_2tuple
 
-from modelscope.models.cv.video_single_object_tracking.models.layers.attn_blocks import \
+from weathon.models.cv.video_single_object_tracking.models.layers.attn_blocks import \
     CEBlock
-from modelscope.models.cv.video_single_object_tracking.models.layers.patch_embed import \
+from weathon.models.cv.video_single_object_tracking.models.layers.patch_embed import \
     PatchEmbed
-from modelscope.models.cv.video_single_object_tracking.models.ostrack.utils import (
+from weathon.models.cv.video_single_object_tracking.models.ostrack.utils import (
     combine_tokens, recover_tokens)
-from modelscope.models.cv.video_single_object_tracking.models.ostrack.vit_ce import \
+from weathon.models.cv.video_single_object_tracking.models.ostrack.vit_ce import \
     VisionTransformerCE
 from .utils import combine_multi_tokens
 
 
 class VisionTransformerCE_ProContEXT(VisionTransformerCE):
     """ Vision Transformer with candidate elimination (CE) module
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/tracker/ostrack.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/tracker/ostrack.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # The implementation is adopted from OSTrack,
 # made publicly available under the MIT License at https://github.com/botaoye/OSTrack/
 import torch
 
-from modelscope.models.cv.video_single_object_tracking.config.ostrack import \
+from weathon.models.cv.video_single_object_tracking.config.ostrack import \
     cfg
-from modelscope.models.cv.video_single_object_tracking.models.ostrack.ostrack import \
+from weathon.models.cv.video_single_object_tracking.models.ostrack.ostrack import \
     build_ostrack
-from modelscope.models.cv.video_single_object_tracking.utils.utils import (
+from weathon.models.cv.video_single_object_tracking.utils.utils import (
     Preprocessor, clip_box, generate_mask_cond, hann2d, sample_target,
     transform_image_to_crop)
 
 
 class OSTrack():
 
     def __init__(self, ckpt_path, device):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/tracker/procontext.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/tracker/procontext.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # The ProContEXT implementation is also open-sourced by the authors,
 # and available at https://github.com/jp-lan/ProContEXT
 from copy import deepcopy
 
 import torch
 
-from modelscope.models.cv.video_single_object_tracking.models.procontext.procontext import \
+from weathon.models.cv.video_single_object_tracking.models.procontext.procontext import \
     build_procontext
-from modelscope.models.cv.video_single_object_tracking.utils.utils import (
+from weathon.models.cv.video_single_object_tracking.utils.utils import (
     Preprocessor, clip_box, generate_mask_cond, hann2d, sample_target,
     transform_image_to_crop)
 
 
 class ProContEXT():
 
     def __init__(self, ckpt_path, device, cfg):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_single_object_tracking/utils/utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_single_object_tracking/utils/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/DUT_raft.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/DUT_raft.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,20 +4,20 @@
 import sys
 
 import cv2
 import numpy as np
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.video_stabilization.utils.image_utils import topk_map
-from modelscope.models.cv.video_stabilization.utils.IterativeSmooth import \
+from weathon.models.cv.video_stabilization.utils.image_utils import topk_map
+from weathon.models.cv.video_stabilization.utils.IterativeSmooth import \
     generateSmooth
-from modelscope.models.cv.video_stabilization.utils.MedianFilter import (
+from weathon.models.cv.video_stabilization.utils.MedianFilter import (
     MultiMotionPropagate, SingleMotionPropagate)
-from modelscope.models.cv.video_stabilization.utils.RAFTUtils import \
+from weathon.models.cv.video_stabilization.utils.RAFTUtils import \
     InputPadder
 from .config import cfg
 from .MotionPro import MotionPro
 from .RAFT.raft import RAFT
 from .rf_det_so import RFDetSO
 from .Smoother import Smoother
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/MotionPro.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/MotionPro.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,17 +5,17 @@
 import os
 
 import cv2
 import numpy as np
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.video_stabilization.utils.MedianFilter import \
+from weathon.models.cv.video_stabilization.utils.MedianFilter import \
     MedianPool2d
-from modelscope.models.cv.video_stabilization.utils.ProjectionUtils import (
+from weathon.models.cv.video_stabilization.utils.ProjectionUtils import (
     multiHomoEstimate, singleHomoEstimate)
 from .config import cfg
 
 
 class MotionPro(nn.Module):
 
     def __init__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/corr.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/corr.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Part of the implementation is borrowed and modified from RAFT,
 # publicly available at https://github.com/princeton-vl/RAFT
 
 import torch
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_stabilization.utils.RAFTUtils import (
+from weathon.models.cv.video_stabilization.utils.RAFTUtils import (
     bilinear_sampler, coords_grid)
 
 try:
     import alt_cuda_corr
 except Exception:
     # alt_cuda_corr is not compiled
     pass
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/extractor.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/extractor.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/raft.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/raft.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 # publicly available at https://github.com/princeton-vl/RAFT
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_stabilization.utils.RAFTUtils import (
+from weathon.models.cv.video_stabilization.utils.RAFTUtils import (
     bilinear_sampler, coords_grid, upflow8)
 from .corr import AlternateCorrBlock, CorrBlock
 from .extractor import BasicEncoder, SmallEncoder
 from .update import BasicUpdateBlock, SmallUpdateBlock
 
 try:
     autocast = torch.cuda.amp.autocast
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/RAFT/update.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/RAFT/update.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/Smoother.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/Smoother.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 import math
 
 import numpy as np
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.video_stabilization.utils.IterativeSmooth import \
+from weathon.models.cv.video_stabilization.utils.IterativeSmooth import \
     generateSmooth
 
 
 class Smoother(nn.Module):
 
     def __init__(self, inplanes=2, embeddingSize=64, hiddenSize=64, kernel=5):
         super(Smoother, self).__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/config.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/config.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/rf_det_module.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/rf_det_module.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 # Part of the implementation is borrowed and modified from DUTCode,
 # publicly available at https://github.com/Annbless/DUTCode
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_stabilization.utils.image_utils import (
+from weathon.models.cv.video_stabilization.utils.image_utils import (
     filter_border, get_gauss_filter_weight, nms, topk_map)
 
 
 class RFDetModule(nn.Module):
 
     def __init__(
         self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUT/rf_det_so.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUT/rf_det_so.py`

 * *Files 7% similar despite different names*

```diff
@@ -3,17 +3,17 @@
 # Part of the implementation is borrowed and modified from DUTCode,
 # publicly available at https://github.com/Annbless/DUTCode
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_stabilization.utils.image_utils import (
+from weathon.models.cv.video_stabilization.utils.image_utils import (
     soft_max_and_argmax_1d, soft_nms_3d)
-from modelscope.models.cv.video_stabilization.utils.math_utils import L2Norm
+from weathon.models.cv.video_stabilization.utils.math_utils import L2Norm
 from .rf_det_module import RFDetModule
 
 
 class RFDetSO(RFDetModule):
 
     def __init__(
         self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/DUTRAFTStabilizer.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/DUTRAFTStabilizer.py`

 * *Files 10% similar despite different names*

```diff
@@ -8,24 +8,24 @@
 from typing import Any, Dict, Optional, Union
 
 import cv2
 import numpy as np
 import torch
 import torch.nn as nn
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.video_stabilization.DUT.config import cfg
-from modelscope.models.cv.video_stabilization.DUT.DUT_raft import DUT
-from modelscope.preprocessors.cv import VideoReader, stabilization_preprocessor
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.video_stabilization.DUT.config import cfg
+from weathon.models.cv.video_stabilization.DUT.DUT_raft import DUT
+from weathon.preprocessors.cv import VideoReader, stabilization_preprocessor
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 __all__ = ['DUTRAFTStabilizer']
 
 
 @MODELS.register_module(
     Tasks.video_stabilization, module_name=Models.video_stabilization)
 class DUTRAFTStabilizer(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/IterativeSmooth.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/IterativeSmooth.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/MedianFilter.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/MedianFilter.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import cv2
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torch.nn.modules.utils import _pair, _quadruple
 
-from modelscope.models.cv.video_stabilization.utils.ProjectionUtils import (
+from weathon.models.cv.video_stabilization.utils.ProjectionUtils import (
     HomoCalc, HomoProj, MotionDistanceMeasure)
 from ..DUT.config import cfg
 
 
 class MedianPool2d(nn.Module):
     """ Median pool (usable as median filter when stride=1) module.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/ProjectionUtils.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/ProjectionUtils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/RAFTUtils.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/RAFTUtils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/WarpUtils.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/WarpUtils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/image_utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/image_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 # Part of the implementation is borrowed and modified from DUTCode,
 # publicly available at https://github.com/Annbless/DUTCode
 
 import torch
 from skimage import transform
 from torch.nn import functional as F
 
-from modelscope.models.cv.video_stabilization.utils.math_utils import L2Norm
+from weathon.models.cv.video_stabilization.utils.math_utils import L2Norm
 
 
 def clip_patch(kpts_byxc, kpts_scale, kpts_ori, im_info, images, PSIZE):
     """
     clip patch from im_C, im_S, im_info, im_raw.
     :param kpts_byxc: tensor #(B*topk, 4): the 4 correspond to (b, y, x, 0) each element in it has length B*topk
     :param kpts_scale: tensor(B*topk): image scale value corresponding to topk keypoints in all batch
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_stabilization/utils/math_utils.py` & `weathon-0.0.0.14/weathon/models/cv/video_stabilization/utils/math_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py` & `weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # Copyright (c) 2014-2021 Megvii Inc.
 # Copyright (c) 2022-2023 Alibaba, Inc. and its affiliates. All rights reserved.
 
-from modelscope.models.cv.stream_yolo.exp.yolox_base import Exp
+from weathon.models.cv.stream_yolo.exp.yolox_base import Exp
 
 
 class LongShortNetExp(Exp):
 
     def __init__(self):
         super(Exp, self).__init__()
         self.depth = 1.0
@@ -19,15 +19,15 @@
         self.merge_cfg = dict()
 
     def get_model(self):
         from ..models.longshort import LONGSHORT
         from ..models.dfp_pafpn_long import DFPPAFPNLONG
         from ..models.dfp_pafpn_short import DFPPAFPNSHORT
         from ..models.longshort_backbone_neck import BACKBONENECK
-        from modelscope.models.cv.stream_yolo.models.tal_head import TALHead
+        from weathon.models.cv.stream_yolo.models.tal_head import TALHead
         import torch.nn as nn
 
         if getattr(self, 'model', None) is None:
             in_channels = [256, 512, 1024]
             long_backbone = (
                 DFPPAFPNLONG(
                     self.depth,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/longshortnet.py` & `weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/longshortnet.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,29 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import argparse
 import logging as logger
 import os
 import os.path as osp
 import time
 
 import cv2
 import json
 import numpy as np
 import torch
 from tqdm import tqdm
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.stream_yolo.data.data_augment import ValTransform
-from modelscope.models.cv.stream_yolo.utils import (postprocess,
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.stream_yolo.data.data_augment import ValTransform
+from weathon.models.cv.stream_yolo.utils import (postprocess,
                                                     timestamp_format)
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.preprocessors import LoadImage
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .exp.longshortnet_base import LongShortNetExp
 
 
 @MODELS.register_module(
     group_key=Tasks.video_object_detection, module_name=Models.longshortnet)
 class LongShortNet(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py` & `weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,16 +3,16 @@
 
 from collections import defaultdict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.stream_yolo.models.darknet import CSPDarknet
-from modelscope.models.cv.stream_yolo.models.network_blocks import (BaseConv,
+from weathon.models.cv.stream_yolo.models.darknet import CSPDarknet
+from weathon.models.cv.stream_yolo.models.network_blocks import (BaseConv,
                                                                     DWConv)
 
 
 class DFPPAFPNLONG(nn.Module):
 
     def __init__(self,
                  depth=1.0,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py` & `weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,16 +3,16 @@
 
 from collections import defaultdict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.stream_yolo.models.darknet import CSPDarknet
-from modelscope.models.cv.stream_yolo.models.network_blocks import (BaseConv,
+from weathon.models.cv.stream_yolo.models.darknet import CSPDarknet
+from weathon.models.cv.stream_yolo.models.network_blocks import (BaseConv,
                                                                     DWConv)
 
 
 class DFPPAFPNSHORT(nn.Module):
 
     def __init__(self,
                  depth=1.0,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/longshort.py` & `weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/longshort.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Copyright (c) 2014-2021 Megvii Inc.
 # Copyright (c) 2022-2023 Alibaba, Inc. and its affiliates. All rights reserved.
 
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.stream_yolo.models.network_blocks import BaseConv
+from weathon.models.cv.stream_yolo.models.network_blocks import BaseConv
 
 
 class LONGSHORT(nn.Module):
 
     def __init__(self,
                  long_backbone=None,
                  short_backbone=None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py` & `weathon-0.0.0.14/weathon/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # Copyright (c) 2014-2021 Megvii Inc.
 # Copyright (c) 2022-2023 Alibaba, Inc. and its affiliates. All rights reserved.
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.stream_yolo.models.darknet import CSPDarknet
-from modelscope.models.cv.stream_yolo.models.network_blocks import (BaseConv,
+from weathon.models.cv.stream_yolo.models.darknet import CSPDarknet
+from weathon.models.cv.stream_yolo.models.network_blocks import (BaseConv,
                                                                     CSPLayer,
                                                                     DWConv)
 
 
 class BACKBONENECK(nn.Module):
 
     def __init__(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/__init__.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,18 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .summarizer import (PGLVideoSummarization, summary_format)
-
+    from .stable_diffusion_pipeline import StableDiffusionWrapperPipeline
+    from .chinese_stable_diffusion_pipeline import ChineseStableDiffusionPipeline
 else:
     _import_structure = {
-        'summarizer': ['PGLVideoSummarization', 'summary_format']
+        'stable_diffusion_pipeline': ['StableDiffusionWrapperPipeline'],
+        'chinese_stable_diffusion_pipeline':
+        ['ChineseStableDiffusionPipeline']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/base_model.py` & `weathon-0.0.0.14/weathon/models/cv/video_summarization/base_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/kts/cpd_auto.py` & `weathon-0.0.0.14/weathon/models/cv/video_summarization/kts/cpd_auto.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/kts/cpd_nonlin.py` & `weathon-0.0.0.14/weathon/models/cv/video_summarization/kts/cpd_nonlin.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/pgl_sum.py` & `weathon-0.0.0.14/weathon/models/cv/video_summarization/pgl_sum.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_summarization/summarizer.py` & `weathon-0.0.0.14/weathon/models/cv/video_summarization/summarizer.py`

 * *Files 7% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 import os.path as osp
 from typing import Dict, Union
 
 import numpy as np
 import torch
 import torch.nn as nn
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.video_summarization.kts.cpd_auto import cpd_auto
-from modelscope.models.cv.video_summarization.pgl_sum import PGL_SUM
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor, TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.video_summarization.kts.cpd_auto import cpd_auto
+from weathon.models.cv.video_summarization.pgl_sum import PGL_SUM
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def get_change_points(video_feat, n_frame):
     video_feat = np.array(video_feat, np.float32)
     K = np.dot(video_feat, video_feat.T)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/basicvsr_net.py` & `weathon-0.0.0.14/weathon/models/cv/video_super_resolution/basicvsr_net.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 # made publicly available under the Apache 2.0 License at
 # https://github.com/open-mmlab/mmediting/blob/master/mmedit/models/backbones/sr_backbones/basicvsr_net.py
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.cv.video_super_resolution.common import (
+from weathon.models.cv.video_super_resolution.common import (
     PixelShufflePack, ResidualBlockNoBN, flow_warp, make_layer)
 
 
 class ConvModule(nn.Module):
 
     def __init__(self,
                  in_channels,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/common.py` & `weathon-0.0.0.14/weathon/models/cv/video_super_resolution/common.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/msrresnet_lite_model.py` & `weathon-0.0.0.14/weathon/models/cv/video_super_resolution/msrresnet_lite_model.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import functools
 import os
-from typing import Any, Dict, Union
+from typing import Dict, Union
 
 import torch
 import torch.cuda
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .common import ResidualBlockNoBN, make_layer
 
 logger = get_logger()
 __all__ = ['MSRResNetLiteModel']
 
 
 @MODELS.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py` & `weathon-0.0.0.14/weathon/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
 import torch.cuda
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.cv.video_super_resolution.common import charbonnier_loss
-from modelscope.models.cv.video_super_resolution.real_basicvsr_net import \
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.models.cv.video_super_resolution.common import charbonnier_loss
+from weathon.models.cv.video_super_resolution.real_basicvsr_net import \
     RealBasicVSRNet
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 __all__ = ['RealBasicVSRNetForVideoSR']
 
 
 @MODELS.register_module(
     Tasks.video_super_resolution, module_name=Models.real_basicvsr)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/video_super_resolution/real_basicvsr_net.py` & `weathon-0.0.0.14/weathon/models/cv/video_super_resolution/real_basicvsr_net.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # The implementation is adopted from mmedit,
 # made publicly available under the Apache 2.0 License at
 # https://github.com/open-mmlab/mmediting/blob/master/mmedit/models/backbones/sr_backbones/real_basicvsr_net.py
 
 import torch
 import torch.nn as nn
 
-from modelscope.models.cv.video_super_resolution.basicvsr_net import (
+from weathon.models.cv.video_super_resolution.basicvsr_net import (
     BasicVSRNet, ResidualBlocksWithInputConv)
 
 
 class RealBasicVSRNet(nn.Module):
     """RealBasicVSR network structure for real-world video super-resolution.
     Support only x4 upsampling.
     Paper:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vidt/backbone.py` & `weathon-0.0.0.14/weathon/models/cv/vidt/backbone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vidt/deformable_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/vidt/deformable_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vidt/fpn_fusion.py` & `weathon-0.0.0.14/weathon/models/cv/vidt/fpn_fusion.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vidt/head.py` & `weathon-0.0.0.14/weathon/models/cv/vidt/head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vidt/model.py` & `weathon-0.0.0.14/weathon/models/cv/vidt/model.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # Copyright 2022-2023 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
 import os
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 from .backbone import SwinTransformer
 from .deformable_transformer import DeformableTransformer
 from .fpn_fusion import FPNFusionModule
 from .head import Detector
 
 
 @MODELS.register_module(Tasks.image_object_detection, module_name=Models.vidt)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/virual_tryon/sdafnet.py` & `weathon-0.0.0.14/weathon/models/cv/virual_tryon/sdafnet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 import random
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 
 
 def apply_offset(offset):
     sizes = list(offset.size()[2:])
     grid_list = torch.meshgrid(
         [torch.arange(size, device=offset.device) for size in sizes])
     grid_list = reversed(grid_list)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/backbone.py` & `weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/backbone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/head.py` & `weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/model.py` & `weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # Copyright 2022-2023 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
 from .vision_efficient_tuning import VisionEfficientTuning
 
 
 @MODELS.register_module(
     Tasks.vision_efficient_tuning, module_name=Models.vision_efficient_tuning)
 class VisionEfficientTuningModel(TorchModel):
     """ The implementation of vision efficient tuning model based on TorchModel.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/petl.py` & `weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/petl.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/timm_helpers.py` & `weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/timm_helpers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/timm_vision_transformer.py` & `weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/timm_vision_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/timm_weight_init.py` & `weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/timm_weight_init.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_efficient_tuning/vision_efficient_tuning.py` & `weathon-0.0.0.14/weathon/models/cv/vision_efficient_tuning/vision_efficient_tuning.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 import os
 from collections import OrderedDict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile
 
 
 class VisionEfficientTuning(nn.Module):
     """ The implementation of vision efficient tuning.
 
     This model is constructed with the following parts:
         - 'backbone': pre-trained backbone model with parameters.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/backbone.py` & `weathon-0.0.0.14/weathon/models/cv/vision_middleware/backbone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/head.py` & `weathon-0.0.0.14/weathon/models/cv/vision_middleware/head.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/model.py` & `weathon-0.0.0.14/weathon/models/cv/vision_middleware/model.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,19 +4,19 @@
 from typing import Any, Dict
 
 import json
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import ModelFile, Tasks
 from .backbone import build_backbone
 from .head import FPNSegmentor, LinearClassifier
 
 
 @MODELS.register_module(
     Tasks.image_segmentation, module_name=Models.vision_middleware)
 class VisionMiddlewareModel(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vision_middleware/vim.py` & `weathon-0.0.0.14/weathon/models/cv/vision_middleware/vim.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/vop_retrieval/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .basic_utils import set_seed, get_state_dict, load_data, init_transform_dict, load_frames_from_video
     from .model import VoP
     from .model_se import VoP_SE
     from .tokenization_clip import LengthAdaptiveTokenizer
 else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/backbone.py` & `weathon-0.0.0.14/weathon/models/cv/vop_retrieval/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 import numpy as np
 import torch
 import torch.nn.functional as F
 from torch import nn
 from tqdm import tqdm
 
-from modelscope.models.base.base_torch_model import TorchModel
+from weathon.models.base.base_torch_model import TorchModel
 
 
 class LayerNorm(nn.LayerNorm):
 
     def forward(self, x: torch.Tensor):
         orig_type = x.dtype
         ret = super().forward(x.type(torch.float32))
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/basic_utils.py` & `weathon-0.0.0.14/weathon/models/cv/vop_retrieval/basic_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/model.py` & `weathon-0.0.0.14/weathon/models/cv/vop_retrieval/model.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,19 +3,19 @@
 import os
 import os.path as osp
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .backbone import load_clip
 from .basic_utils import get_state_dict, set_seed
 
 
 @MODELS.register_module(
     Tasks.vop_retrieval, module_name=Models.vop_retrieval_model)
 class VoP(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/model_se.py` & `weathon-0.0.0.14/weathon/models/cv/vop_retrieval/model_se.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,23 +1,18 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
-import os
 import os.path as osp
 
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .backbone import load_clip
-from .basic_utils import get_state_dict, set_seed
+from .basic_utils import get_state_dict
 
 
 @MODELS.register_module(
     Tasks.vop_retrieval, module_name=Models.vop_retrieval_model_se)
 class VideoTextRetrievalModelSeries(TorchModel):
     """
         The implementation of 'VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval'.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/cv/vop_retrieval/tokenization_clip.py` & `weathon-0.0.0.14/weathon/models/cv/vop_retrieval/tokenization_clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/__init__.py` & `weathon-0.0.0.14/weathon/models/multi_modal/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
 
     from .clip import CLIPForMultiModalEmbedding
     from .gemm import GEMMForMultiModalEmbedding
     from .rleg import RLEGForMultiModalEmbedding
     from .team import TEAMForMultiModalSimilarity
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/bert_tokenizer.py` & `weathon-0.0.0.14/weathon/models/multi_modal/clip/bert_tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/configuration_bert.py` & `weathon-0.0.0.14/weathon/models/multi_modal/clip/configuration_bert.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/clip/model.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,22 +19,22 @@
 
 import json
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.clip.bert_tokenizer import FullTokenizer
-from modelscope.models.multi_modal.clip.configuration_bert import BertConfig
-from modelscope.models.multi_modal.clip.modeling_bert import BertModel
-from modelscope.utils.constant import ModeKeys, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.multi_modal.clip.bert_tokenizer import FullTokenizer
+from weathon.models.multi_modal.clip.configuration_bert import BertConfig
+from weathon.models.multi_modal.clip.modeling_bert import BertModel
+from weathon.utils.constant import ModeKeys, ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['CLIPForMultiModalEmbedding']
 
 
 class Bottleneck(nn.Module):
@@ -559,15 +559,15 @@
             logger.info('Use GPU {} for finetuning & inference'.format(
                 int(os.environ.get('LOCAL_RANK', 0))))
         else:
             self.clip_model.float()
             logger.info('Use CPU for finetuning & inference')
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        from modelscope.outputs import OutputKeys
+        from weathon.outputs import OutputKeys
         output = {
             OutputKeys.IMG_EMBEDDING: None,
             OutputKeys.TEXT_EMBEDDING: None
         }
         mode = input.get('mode', ModeKeys.INFERENCE)
 
         # encode the image
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/clip/modeling_bert.py` & `weathon-0.0.0.14/weathon/models/multi_modal/clip/modeling_bert.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/clip_interrogator/model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/clip_interrogator/model.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,21 +16,21 @@
 from PIL import Image
 from safetensors.numpy import load_file, save_file
 from tqdm import tqdm
 from transformers import (AutoModelForCausalLM, AutoProcessor,
                           Blip2ForConditionalGeneration,
                           BlipForConditionalGeneration)
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['CLIP_Interrogator']
 
 CAPTION_MODELS = {
     'blip-base': 'blip-image-captioning-base',
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/diffusion.py` & `weathon-0.0.0.14/weathon/models/multi_modal/diffusion/diffusion.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # Part of the implementation is borrowed and modified from latent-diffusion,
 # publicly available at https://github.com/CompVis/latent-diffusion.
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 import math
 
 import torch
 
-from modelscope.models.multi_modal.dpm_solver_pytorch import (
+from weathon.models.multi_modal.dpm_solver_pytorch import (
     DPM_Solver, NoiseScheduleVP, model_wrapper, model_wrapper_guided_diffusion)
 
 __all__ = ['GaussianDiffusion', 'beta_schedule']
 
 
 def kl_divergence(mu1, logvar1, mu2, logvar2):
     a = -1.0 + logvar2 - logvar1 + torch.exp(logvar1 - logvar2)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/diffusion/model.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,31 +4,31 @@
 
 import json
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models import Model
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.diffusion.diffusion import (
+from weathon.utils.constants.metainfo import Models
+from weathon.models import Model
+from weathon.registry import MODELS
+from weathon.models.multi_modal.diffusion.diffusion import (
     GaussianDiffusion, beta_schedule)
-from modelscope.models.multi_modal.diffusion.structbert import (BertConfig,
+from weathon.models.multi_modal.diffusion.structbert import (BertConfig,
                                                                 BertModel)
-from modelscope.models.multi_modal.diffusion.tokenizer import FullTokenizer
-from modelscope.models.multi_modal.diffusion.unet_generator import \
+from weathon.models.multi_modal.diffusion.tokenizer import FullTokenizer
+from weathon.models.multi_modal.diffusion.unet_generator import \
     DiffusionGenerator
-from modelscope.models.multi_modal.diffusion.unet_upsampler_256 import \
+from weathon.models.multi_modal.diffusion.unet_upsampler_256 import \
     SuperResUNet256
-from modelscope.models.multi_modal.diffusion.unet_upsampler_1024 import \
+from weathon.models.multi_modal.diffusion.unet_upsampler_1024 import \
     SuperResUNet1024
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.device import create_device
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.device import create_device
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['DiffusionForTextToImageSynthesis']
 
 
 def make_diffusion(schedule,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/structbert.py` & `weathon-0.0.0.14/weathon/models/multi_modal/diffusion/structbert.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/tokenizer.py` & `weathon-0.0.0.14/weathon/models/multi_modal/diffusion/tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/unet_generator.py` & `weathon-0.0.0.14/weathon/models/multi_modal/diffusion/unet_generator.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/unet_upsampler_1024.py` & `weathon-0.0.0.14/weathon/models/multi_modal/diffusion/unet_upsampler_1024.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/diffusion/unet_upsampler_256.py` & `weathon-0.0.0.14/weathon/models/multi_modal/diffusion/unet_upsampler_256.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/dpm_solver_pytorch.py` & `weathon-0.0.0.14/weathon/models/multi_modal/dpm_solver_pytorch.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py` & `weathon-0.0.0.14/weathon/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py`

 * *Files 5% similar despite different names*

```diff
@@ -11,23 +11,23 @@
 from diffusers import (AutoencoderKL, DDPMScheduler, DiffusionPipeline,
                        DPMSolverMultistepScheduler, UNet2DConditionModel,
                        utils)
 from diffusers.models import cross_attention
 from diffusers.utils import deprecation_utils
 from transformers import CLIPTextModel, CLIPTokenizer
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.tuners.control_sd_lora import ControlLoRATuner
-from modelscope.tuners.sd_lora import LoRATuner
-from modelscope.utils.checkpoint import save_checkpoint, save_configuration
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.tuners.control_sd_lora import ControlLoRATuner
+from weathon.tuners.sd_lora import LoRATuner
+from weathon.utils.checkpoint import save_checkpoint, save_configuration
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 
 utils.deprecate = lambda *arg, **kwargs: None
 deprecation_utils.deprecate = lambda *arg, **kwargs: None
 cross_attention.deprecate = lambda *arg, **kwargs: None
 
 __tuner_MAP__ = {'lora': LoRATuner, 'control_lora': ControlLoRATuner}
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/gemm/gemm_base.py` & `weathon-0.0.0.14/weathon/models/multi_modal/gemm/gemm_base.py`

 * *Files 0% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 import json
 import numpy as np
 import torch
 import torch.nn.functional as F
 from torch import nn
 from torch.nn import LayerNorm
 
-from modelscope.models.multi_modal.gemm.tokenizer import (SimpleTokenizer,
+from weathon.models.multi_modal.gemm.tokenizer import (SimpleTokenizer,
                                                           clip_tokenize)
 
 
 class Bottleneck(nn.Module):
     """ ResNet style bottleneck module
     From https://github.com/openai/CLIP/blob/main/clip/model.py
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/gemm/gemm_model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/rleg/rleg.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,61 +1,54 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 """ Generative Multimodal Model Wrapper."""
-import os.path as osp
 from typing import Any, Dict
 
-import json
-import numpy as np
 import torch
-import torch.nn as nn
-import torch.nn.functional as F
-from PIL import Image
 from torchvision import transforms as T
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.gemm.gemm_base import GEMMModel
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.multi_modal.rleg.model import RLEGModel
+from weathon.outputs import OutputKeys
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
-__all__ = ['GEMMForMultiModalEmbedding']
+__all__ = ['RLEGForMultiModalEmbedding']
 
 
 @MODELS.register_module(
-    Tasks.generative_multi_modal_embedding, module_name=Models.gemm)
-class GEMMForMultiModalEmbedding(TorchModel):
-    """ Generative multi-modal model for multi-modal embedding
+    Tasks.generative_multi_modal_embedding, module_name=Models.rleg)
+class RLEGForMultiModalEmbedding(TorchModel):
+    """ Generative multi-modal model for multi-modal embedding.
+    The model is trained by representation learning with embedding generation.
     Inputs could be image or text or both of them.
     Outputs could be features of input image or text,
-    image caption could also be produced when image is available.
     """
 
     def __init__(self, model_dir, device_id=0, *args, **kwargs):
         super().__init__(
             model_dir=model_dir, device_id=device_id, *args, **kwargs)
-        self.gemm_model = GEMMModel(model_dir=model_dir)
+        self.model = RLEGModel(model_dir=model_dir)
         pretrained_params = torch.load('{}/{}'.format(
             model_dir, ModelFile.TORCH_MODEL_BIN_FILE))
-        self.gemm_model.load_state_dict(pretrained_params)
-        self.gemm_model.eval()
+        self.model.load_state_dict(pretrained_params)
+        self.model.eval()
         self.device_id = device_id
         if self.device_id >= 0 and torch.cuda.is_available():
-            self.gemm_model.to('cuda:{}'.format(self.device_id))
+            self.model.to('cuda:{}'.format(self.device_id))
             logger.info('Use GPU: {}'.format(self.device_id))
         else:
             self.device_id = -1
             logger.info('Use CPU for inference')
         self.img_preprocessor = T.Compose([
-            T.Resize(224),
-            T.CenterCrop(224),
+            T.Resize((224, 224)),
             T.ToTensor(),
             T.Normalize((0.48145466, 0.4578275, 0.40821073),
                         (0.26862954, 0.26130258, 0.27577711))
         ])
 
     def parse_image(self, input_img):
         if input_img is None:
@@ -66,29 +59,27 @@
             img_tensor = img_tensor.to('cuda:{}'.format(self.device_id))
         return img_tensor
 
     def parse_text(self, text_str):
         if text_str is None or len(text_str) == 0:
             return None
         if isinstance(text_str, str):
-            text_ids_tensor = self.gemm_model.tokenize(text_str)
+            text_ids_tensor = self.model.tokenize(text_str)
         else:
             raise TypeError(f'text should be str, but got {type(text_str)}')
         if self.device_id >= 0:
             text_ids_tensor = text_ids_tensor.to('cuda:{}'.format(
                 self.device_id))
         return text_ids_tensor.view(1, -1)
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
         image_input = input.get('image', input.get('img', None))
         text_input = input.get('text', input.get('txt', None))
-        captioning_input = input.get('captioning', None)
         image = self.parse_image(image_input)
         text = self.parse_text(text_input)
-        captioning = captioning_input is True or text_input == ''
-        out = self.gemm_model(image, text, captioning)
+        out = self.model(image, text)
         output = {
             OutputKeys.IMG_EMBEDDING: out.get('image_feature', None),
             OutputKeys.TEXT_EMBEDDING: out.get('text_feature', None),
             OutputKeys.CAPTION: out.get('caption', None)
         }
         return output
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/gemm/tokenizer.py` & `weathon-0.0.0.14/weathon/models/multi_modal/gemm/tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,19 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .unet import HFUNetModel
-    from .script import create_diffusion
+    from .common_utils import SubPreprocessor
+    from .parse import get_label
+    from .preprocess_dataset import \
+        preprocess_dataset
+    from .process_dataset import \
+        process_dataset, process_tables
+
 else:
     _import_structure = {
-        'unet': ['HFUNetModel'],
-        'script': ['create_diffusion']
+        'common_utils': ['SubPreprocessor'],
+        'parse': ['get_label'],
+        'preprocess_dataset': ['preprocess_dataset'],
+        'process_dataset': ['process_dataset', 'process_tables'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/gaussian_diffusion.py` & `weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/gaussian_diffusion.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/respace.py` & `weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/respace.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/script.py` & `weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/script.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # This code is borrowed and modified from Guided Diffusion Model,
 # made publicly available under MIT license
 # at https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/disco_project
 
-from modelscope.models.cv.motion_generation.modules.respace import \
+from weathon.models.cv.motion_generation.modules.respace import \
     space_timesteps
 from . import gaussian_diffusion as gd
 from .respace import SpacedDiffusion
 
 
 def create_diffusion(diffusion_config):
     predict_xstart = False
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/guided_diffusion/unet.py` & `weathon-0.0.0.14/weathon/models/multi_modal/guided_diffusion/unet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/__init__.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mgeo/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .backbone import (MGeo, MGeoPreTrainedModel)
     from .text_classification import MGeoForSequenceClassification
     from .token_classification import MGeoForTokenClassification
     from .text_ranking import MGeoForTextRanking
 else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/backbone.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mgeo/backbone.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,6372 +1,6356 @@
 00000000: 696d 706f 7274 206d 6174 680a 696d 706f  import math.impo
-00000010: 7274 206f 730a 696d 706f 7274 2072 616e  rt os.import ran
-00000020: 646f 6d0a 696d 706f 7274 2077 6172 6e69  dom.import warni
-00000030: 6e67 730a 6672 6f6d 2064 6174 6163 6c61  ngs.from datacla
-00000040: 7373 6573 2069 6d70 6f72 7420 6461 7461  sses import data
-00000050: 636c 6173 730a 6672 6f6d 2074 7970 696e  class.from typin
-00000060: 6720 696d 706f 7274 204f 7074 696f 6e61  g import Optiona
-00000070: 6c2c 2054 7570 6c65 0a0a 696d 706f 7274  l, Tuple..import
-00000080: 2074 6f72 6368 0a69 6d70 6f72 7420 746f   torch.import to
-00000090: 7263 682e 6e6e 2e66 756e 6374 696f 6e61  rch.nn.functiona
-000000a0: 6c20 6173 2046 0a69 6d70 6f72 7420 746f  l as F.import to
-000000b0: 7263 682e 7574 696c 732e 6368 6563 6b70  rch.utils.checkp
-000000c0: 6f69 6e74 0a69 6d70 6f72 7420 7472 616e  oint.import tran
-000000d0: 7366 6f72 6d65 7273 0a66 726f 6d20 746f  sformers.from to
-000000e0: 7263 6820 696d 706f 7274 2054 656e 736f  rch import Tenso
-000000f0: 722c 2064 6576 6963 652c 2064 7479 7065  r, device, dtype
-00000100: 2c20 6e6e 0a66 726f 6d20 746f 7263 682e  , nn.from torch.
-00000110: 6e6e 2069 6d70 6f72 7420 4372 6f73 7345  nn import CrossE
-00000120: 6e74 726f 7079 4c6f 7373 2c20 4d53 454c  ntropyLoss, MSEL
-00000130: 6f73 730a 6672 6f6d 2074 7261 6e73 666f  oss.from transfo
-00000140: 726d 6572 732e 6163 7469 7661 7469 6f6e  rmers.activation
-00000150: 7320 696d 706f 7274 2041 4354 3246 4e0a  s import ACT2FN.
-00000160: 6672 6f6d 2074 7261 6e73 666f 726d 6572  from transformer
-00000170: 732e 6669 6c65 5f75 7469 6c73 2069 6d70  s.file_utils imp
-00000180: 6f72 7420 284d 6f64 656c 4f75 7470 7574  ort (ModelOutput
-00000190: 2c20 6164 645f 636f 6465 5f73 616d 706c  , add_code_sampl
-000001a0: 655f 646f 6373 7472 696e 6773 2c0a 2020  e_docstrings,.  
-000001b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000001c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000001d0: 2020 2061 6464 5f73 7461 7274 5f64 6f63     add_start_doc
-000001e0: 7374 7269 6e67 732c 0a20 2020 2020 2020  strings,.       
-000001f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000200: 2020 2020 2020 2020 2020 2020 2020 6164                ad
-00000210: 645f 7374 6172 745f 646f 6373 7472 696e  d_start_docstrin
-00000220: 6773 5f74 6f5f 6d6f 6465 6c5f 666f 7277  gs_to_model_forw
-00000230: 6172 642c 0a20 2020 2020 2020 2020 2020  ard,.           
-00000240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000250: 2020 2020 2020 2020 2020 7265 706c 6163            replac
-00000260: 655f 7265 7475 726e 5f64 6f63 7374 7269  e_return_docstri
-00000270: 6e67 7329 0a66 726f 6d20 7472 616e 7366  ngs).from transf
-00000280: 6f72 6d65 7273 2e6d 6f64 656c 696e 675f  ormers.modeling_
-00000290: 6f75 7470 7574 7320 696d 706f 7274 2028  outputs import (
-000002a0: 0a20 2020 2042 6173 654d 6f64 656c 4f75  .    BaseModelOu
-000002b0: 7470 7574 5769 7468 5061 7374 416e 6443  tputWithPastAndC
-000002c0: 726f 7373 4174 7465 6e74 696f 6e73 2c0a  rossAttentions,.
-000002d0: 2020 2020 4261 7365 4d6f 6465 6c4f 7574      BaseModelOut
-000002e0: 7075 7457 6974 6850 6f6f 6c69 6e67 416e  putWithPoolingAn
-000002f0: 6443 726f 7373 4174 7465 6e74 696f 6e73  dCrossAttentions
-00000300: 2c0a 2020 2020 4361 7573 616c 4c4d 4f75  ,.    CausalLMOu
-00000310: 7470 7574 5769 7468 4372 6f73 7341 7474  tputWithCrossAtt
-00000320: 656e 7469 6f6e 732c 204d 6173 6b65 644c  entions, MaskedL
-00000330: 4d4f 7574 7075 742c 0a20 2020 204d 756c  MOutput,.    Mul
-00000340: 7469 706c 6543 686f 6963 654d 6f64 656c  tipleChoiceModel
-00000350: 4f75 7470 7574 2c20 4e65 7874 5365 6e74  Output, NextSent
-00000360: 656e 6365 5072 6564 6963 746f 724f 7574  encePredictorOut
-00000370: 7075 742c 0a20 2020 2051 7565 7374 696f  put,.    Questio
-00000380: 6e41 6e73 7765 7269 6e67 4d6f 6465 6c4f  nAnsweringModelO
-00000390: 7574 7075 742c 2053 6571 7565 6e63 6543  utput, SequenceC
-000003a0: 6c61 7373 6966 6965 724f 7574 7075 742c  lassifierOutput,
-000003b0: 0a20 2020 2054 6f6b 656e 436c 6173 7369  .    TokenClassi
-000003c0: 6669 6572 4f75 7470 7574 290a 6672 6f6d  fierOutput).from
-000003d0: 2074 7261 6e73 666f 726d 6572 732e 6d6f   transformers.mo
-000003e0: 6465 6c69 6e67 5f75 7469 6c73 2069 6d70  deling_utils imp
-000003f0: 6f72 7420 2850 7265 5472 6169 6e65 644d  ort (PreTrainedM
-00000400: 6f64 656c 2c0a 2020 2020 2020 2020 2020  odel,.          
-00000410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000420: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-00000430: 7070 6c79 5f63 6875 6e6b 696e 675f 746f  pply_chunking_to
-00000440: 5f66 6f72 7761 7264 2c0a 2020 2020 2020  _forward,.      
-00000450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000470: 2020 2066 696e 645f 7072 756e 6561 626c     find_pruneabl
-00000480: 655f 6865 6164 735f 616e 645f 696e 6469  e_heads_and_indi
-00000490: 6365 732c 0a20 2020 2020 2020 2020 2020  ces,.           
-000004a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000004b0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-000004c0: 756e 655f 6c69 6e65 6172 5f6c 6179 6572  une_linear_layer
-000004d0: 290a 6672 6f6d 2074 7261 6e73 666f 726d  ).from transform
-000004e0: 6572 732e 6d6f 6465 6c73 2e62 6572 742e  ers.models.bert.
-000004f0: 636f 6e66 6967 7572 6174 696f 6e5f 6265  configuration_be
-00000500: 7274 2069 6d70 6f72 7420 4265 7274 436f  rt import BertCo
-00000510: 6e66 6967 0a66 726f 6d20 7472 616e 7366  nfig.from transf
-00000520: 6f72 6d65 7273 2e75 7469 6c73 2069 6d70  ormers.utils imp
-00000530: 6f72 7420 6c6f 6767 696e 670a 0a66 726f  ort logging..fro
-00000540: 6d20 6d6f 6465 6c73 636f 7065 2e6d 6574  m modelscope.met
-00000550: 6169 6e66 6f20 696d 706f 7274 204d 6f64  ainfo import Mod
-00000560: 656c 730a 6672 6f6d 206d 6f64 656c 7363  els.from modelsc
-00000570: 6f70 652e 6d6f 6465 6c73 2069 6d70 6f72  ope.models impor
-00000580: 7420 4d6f 6465 6c2c 2054 6f72 6368 4d6f  t Model, TorchMo
-00000590: 6465 6c0a 6672 6f6d 206d 6f64 656c 7363  del.from modelsc
-000005a0: 6f70 652e 6d6f 6465 6c73 2e62 7569 6c64  ope.models.build
-000005b0: 6572 2069 6d70 6f72 7420 4d4f 4445 4c53  er import MODELS
-000005c0: 0a66 726f 6d20 6d6f 6465 6c73 636f 7065  .from modelscope
-000005d0: 2e6f 7574 7075 7473 2069 6d70 6f72 7420  .outputs import 
-000005e0: 4174 7465 6e74 696f 6e42 6163 6b62 6f6e  AttentionBackbon
-000005f0: 654d 6f64 656c 4f75 7470 7574 0a66 726f  eModelOutput.fro
-00000600: 6d20 6d6f 6465 6c73 636f 7065 2e75 7469  m modelscope.uti
-00000610: 6c73 2e63 6f6e 7374 616e 7420 696d 706f  ls.constant impo
-00000620: 7274 2054 6173 6b73 0a66 726f 6d20 6d6f  rt Tasks.from mo
-00000630: 6465 6c73 636f 7065 2e75 7469 6c73 2e6e  delscope.utils.n
-00000640: 6c70 2e75 7469 6c73 2069 6d70 6f72 7420  lp.utils import 
-00000650: 7061 7273 655f 6c61 6265 6c73 5f69 6e5f  parse_labels_in_
-00000660: 6f72 6465 720a 0a74 7261 6e73 666f 726d  order..transform
-00000670: 6572 732e 6c6f 6767 696e 672e 7365 745f  ers.logging.set_
-00000680: 7665 7262 6f73 6974 795f 6572 726f 7228  verbosity_error(
-00000690: 290a 0a6c 6f67 6765 7220 3d20 6c6f 6767  )..logger = logg
-000006a0: 696e 672e 6765 745f 6c6f 6767 6572 2829  ing.get_logger()
-000006b0: 0a0a 5f43 4f4e 4649 475f 464f 525f 444f  .._CONFIG_FOR_DO
-000006c0: 4320 3d20 2742 6572 7443 6f6e 6669 6727  C = 'BertConfig'
-000006d0: 0a5f 544f 4b45 4e49 5a45 525f 464f 525f  ._TOKENIZER_FOR_
-000006e0: 444f 4320 3d20 2742 6572 7454 6f6b 656e  DOC = 'BertToken
-000006f0: 697a 6572 270a 0a0a 6465 6620 6c6f 6164  izer'...def load
-00000700: 5f74 665f 7765 6967 6874 735f 696e 5f62  _tf_weights_in_b
-00000710: 6572 7428 6d6f 6465 6c2c 2063 6f6e 6669  ert(model, confi
-00000720: 672c 2074 665f 6368 6563 6b70 6f69 6e74  g, tf_checkpoint
-00000730: 5f70 6174 6829 3a0a 2020 2020 2222 224c  _path):.    """L
-00000740: 6f61 6420 7466 2063 6865 636b 706f 696e  oad tf checkpoin
-00000750: 7473 2069 6e20 6120 7079 746f 7263 6820  ts in a pytorch 
-00000760: 6d6f 6465 6c2e 2222 220a 2020 2020 7472  model.""".    tr
-00000770: 793a 0a20 2020 2020 2020 2069 6d70 6f72  y:.        impor
-00000780: 7420 7265 0a0a 2020 2020 2020 2020 696d  t re..        im
-00000790: 706f 7274 206e 756d 7079 2061 7320 6e70  port numpy as np
-000007a0: 0a20 2020 2020 2020 2069 6d70 6f72 7420  .        import 
-000007b0: 7465 6e73 6f72 666c 6f77 2061 7320 7466  tensorflow as tf
-000007c0: 0a20 2020 2065 7863 6570 7420 496d 706f  .    except Impo
-000007d0: 7274 4572 726f 723a 0a20 2020 2020 2020  rtError:.       
-000007e0: 206c 6f67 6765 722e 6572 726f 7228 0a20   logger.error(. 
-000007f0: 2020 2020 2020 2020 2020 2027 4c6f 6164             'Load
-00000800: 696e 6720 6120 5465 6e73 6f72 466c 6f77  ing a TensorFlow
-00000810: 206d 6f64 656c 2069 6e20 5079 546f 7263   model in PyTorc
-00000820: 682c 2072 6571 7569 7265 7320 5465 6e73  h, requires Tens
-00000830: 6f72 466c 6f77 2074 6f20 6265 2069 6e73  orFlow to be ins
-00000840: 7461 6c6c 6564 2e20 506c 6561 7365 2073  talled. Please s
-00000850: 6565 2027 0a20 2020 2020 2020 2020 2020  ee '.           
-00000860: 2027 6874 7470 733a 2f2f 7777 772e 7465   'https://www.te
-00000870: 6e73 6f72 666c 6f77 2e6f 7267 2f69 6e73  nsorflow.org/ins
-00000880: 7461 6c6c 2f20 666f 7220 696e 7374 616c  tall/ for instal
-00000890: 6c61 7469 6f6e 2069 6e73 7472 7563 7469  lation instructi
-000008a0: 6f6e 732e 270a 2020 2020 2020 2020 290a  ons.'.        ).
-000008b0: 2020 2020 2020 2020 7261 6973 650a 2020          raise.  
-000008c0: 2020 7466 5f70 6174 6820 3d20 6f73 2e70    tf_path = os.p
-000008d0: 6174 682e 6162 7370 6174 6828 7466 5f63  ath.abspath(tf_c
-000008e0: 6865 636b 706f 696e 745f 7061 7468 290a  heckpoint_path).
-000008f0: 2020 2020 6c6f 6767 6572 2e69 6e66 6f28      logger.info(
-00000900: 2743 6f6e 7665 7274 696e 6720 5465 6e73  'Converting Tens
-00000910: 6f72 466c 6f77 2063 6865 636b 706f 696e  orFlow checkpoin
-00000920: 7420 6672 6f6d 207b 7d27 2e66 6f72 6d61  t from {}'.forma
-00000930: 7428 7466 5f70 6174 6829 290a 2020 2020  t(tf_path)).    
-00000940: 2320 4c6f 6164 2077 6569 6768 7473 2066  # Load weights f
-00000950: 726f 6d20 5446 206d 6f64 656c 0a20 2020  rom TF model.   
-00000960: 2069 6e69 745f 7661 7273 203d 2074 662e   init_vars = tf.
-00000970: 7472 6169 6e2e 6c69 7374 5f76 6172 6961  train.list_varia
-00000980: 626c 6573 2874 665f 7061 7468 290a 2020  bles(tf_path).  
-00000990: 2020 6e61 6d65 7320 3d20 5b5d 0a20 2020    names = [].   
-000009a0: 2061 7272 6179 7320 3d20 5b5d 0a20 2020   arrays = [].   
-000009b0: 2066 6f72 206e 616d 652c 2073 6861 7065   for name, shape
-000009c0: 2069 6e20 696e 6974 5f76 6172 733a 0a20   in init_vars:. 
-000009d0: 2020 2020 2020 206c 6f67 6765 722e 696e         logger.in
-000009e0: 666f 2827 4c6f 6164 696e 6720 5446 2077  fo('Loading TF w
-000009f0: 6569 6768 7420 7b7d 2077 6974 6820 7368  eight {} with sh
-00000a00: 6170 6520 7b7d 272e 666f 726d 6174 286e  ape {}'.format(n
-00000a10: 616d 652c 2073 6861 7065 2929 0a20 2020  ame, shape)).   
-00000a20: 2020 2020 2061 7272 6179 203d 2074 662e       array = tf.
-00000a30: 7472 6169 6e2e 6c6f 6164 5f76 6172 6961  train.load_varia
-00000a40: 626c 6528 7466 5f70 6174 682c 206e 616d  ble(tf_path, nam
-00000a50: 6529 0a20 2020 2020 2020 206e 616d 6573  e).        names
-00000a60: 2e61 7070 656e 6428 6e61 6d65 290a 2020  .append(name).  
-00000a70: 2020 2020 2020 6172 7261 7973 2e61 7070        arrays.app
-00000a80: 656e 6428 6172 7261 7929 0a0a 2020 2020  end(array)..    
-00000a90: 666f 7220 6e61 6d65 2c20 6172 7261 7920  for name, array 
-00000aa0: 696e 207a 6970 286e 616d 6573 2c20 6172  in zip(names, ar
-00000ab0: 7261 7973 293a 0a20 2020 2020 2020 206e  rays):.        n
-00000ac0: 616d 6520 3d20 6e61 6d65 2e73 706c 6974  ame = name.split
-00000ad0: 2827 2f27 290a 2020 2020 2020 2020 2320  ('/').        # 
-00000ae0: 6164 616d 5f76 2061 6e64 2061 6461 6d5f  adam_v and adam_
-00000af0: 6d20 6172 6520 7661 7269 6162 6c65 7320  m are variables 
-00000b00: 7573 6564 2069 6e20 4164 616d 5765 6967  used in AdamWeig
-00000b10: 6874 4465 6361 794f 7074 696d 697a 6572  htDecayOptimizer
-00000b20: 2074 6f0a 2020 2020 2020 2020 2320 6361   to.        # ca
-00000b30: 6c63 756c 6174 6564 206d 2061 6e64 2076  lculated m and v
-00000b40: 2077 6869 6368 2061 7265 206e 6f74 2072   which are not r
-00000b50: 6571 7569 7265 6420 666f 7220 7573 696e  equired for usin
-00000b60: 6720 7072 6574 7261 696e 6564 206d 6f64  g pretrained mod
-00000b70: 656c 0a20 2020 2020 2020 2069 6620 616e  el.        if an
-00000b80: 7928 6e20 696e 205b 0a20 2020 2020 2020  y(n in [.       
-00000b90: 2020 2020 2020 2020 2027 6164 616d 5f76           'adam_v
-00000ba0: 272c 2027 6164 616d 5f6d 272c 2027 4164  ', 'adam_m', 'Ad
-00000bb0: 616d 5765 6967 6874 4465 6361 794f 7074  amWeightDecayOpt
-00000bc0: 696d 697a 6572 272c 0a20 2020 2020 2020  imizer',.       
-00000bd0: 2020 2020 2020 2020 2027 4164 616d 5765           'AdamWe
-00000be0: 6967 6874 4465 6361 794f 7074 696d 697a  ightDecayOptimiz
-00000bf0: 6572 5f31 272c 2027 676c 6f62 616c 5f73  er_1', 'global_s
-00000c00: 7465 7027 0a20 2020 2020 2020 205d 2066  tep'.        ] f
-00000c10: 6f72 206e 2069 6e20 6e61 6d65 293a 0a20  or n in name):. 
-00000c20: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
-00000c30: 722e 696e 666f 2827 536b 6970 7069 6e67  r.info('Skipping
-00000c40: 207b 7d27 2e66 6f72 6d61 7428 272f 272e   {}'.format('/'.
-00000c50: 6a6f 696e 286e 616d 6529 2929 0a20 2020  join(name))).   
-00000c60: 2020 2020 2020 2020 2063 6f6e 7469 6e75           continu
-00000c70: 650a 2020 2020 2020 2020 706f 696e 7465  e.        pointe
-00000c80: 7220 3d20 6d6f 6465 6c0a 2020 2020 2020  r = model.      
-00000c90: 2020 666f 7220 6d5f 6e61 6d65 2069 6e20    for m_name in 
-00000ca0: 6e61 6d65 3a0a 2020 2020 2020 2020 2020  name:.          
-00000cb0: 2020 6966 2072 652e 6675 6c6c 6d61 7463    if re.fullmatc
-00000cc0: 6828 7227 5b41 2d5a 612d 7a5d 2b5f 5c64  h(r'[A-Za-z]+_\d
-00000cd0: 2b27 2c20 6d5f 6e61 6d65 293a 0a20 2020  +', m_name):.   
-00000ce0: 2020 2020 2020 2020 2020 2020 2073 636f               sco
-00000cf0: 7065 5f6e 616d 6573 203d 2072 652e 7370  pe_names = re.sp
-00000d00: 6c69 7428 7227 5f28 5c64 2b29 272c 206d  lit(r'_(\d+)', m
-00000d10: 5f6e 616d 6529 0a20 2020 2020 2020 2020  _name).         
-00000d20: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00000d30: 2020 2020 2020 2020 2073 636f 7065 5f6e           scope_n
-00000d40: 616d 6573 203d 205b 6d5f 6e61 6d65 5d0a  ames = [m_name].
-00000d50: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-00000d60: 636f 7065 5f6e 616d 6573 5b30 5d20 3d3d  cope_names[0] ==
-00000d70: 2027 6b65 726e 656c 2720 6f72 2073 636f   'kernel' or sco
-00000d80: 7065 5f6e 616d 6573 5b30 5d20 3d3d 2027  pe_names[0] == '
-00000d90: 6761 6d6d 6127 3a0a 2020 2020 2020 2020  gamma':.        
-00000da0: 2020 2020 2020 2020 706f 696e 7465 7220          pointer 
-00000db0: 3d20 6765 7461 7474 7228 706f 696e 7465  = getattr(pointe
-00000dc0: 722c 2027 7765 6967 6874 2729 0a20 2020  r, 'weight').   
-00000dd0: 2020 2020 2020 2020 2065 6c69 6620 7363           elif sc
-00000de0: 6f70 655f 6e61 6d65 735b 305d 203d 3d20  ope_names[0] == 
-00000df0: 276f 7574 7075 745f 6269 6173 2720 6f72  'output_bias' or
-00000e00: 2073 636f 7065 5f6e 616d 6573 5b30 5d20   scope_names[0] 
-00000e10: 3d3d 2027 6265 7461 273a 0a20 2020 2020  == 'beta':.     
-00000e20: 2020 2020 2020 2020 2020 2070 6f69 6e74             point
-00000e30: 6572 203d 2067 6574 6174 7472 2870 6f69  er = getattr(poi
-00000e40: 6e74 6572 2c20 2762 6961 7327 290a 2020  nter, 'bias').  
-00000e50: 2020 2020 2020 2020 2020 656c 6966 2073            elif s
-00000e60: 636f 7065 5f6e 616d 6573 5b30 5d20 3d3d  cope_names[0] ==
-00000e70: 2027 6f75 7470 7574 5f77 6569 6768 7473   'output_weights
-00000e80: 273a 0a20 2020 2020 2020 2020 2020 2020  ':.             
-00000e90: 2020 2070 6f69 6e74 6572 203d 2067 6574     pointer = get
-00000ea0: 6174 7472 2870 6f69 6e74 6572 2c20 2777  attr(pointer, 'w
-00000eb0: 6569 6768 7427 290a 2020 2020 2020 2020  eight').        
-00000ec0: 2020 2020 656c 6966 2073 636f 7065 5f6e      elif scope_n
-00000ed0: 616d 6573 5b30 5d20 3d3d 2027 7371 7561  ames[0] == 'squa
-00000ee0: 6427 3a0a 2020 2020 2020 2020 2020 2020  d':.            
-00000ef0: 2020 2020 706f 696e 7465 7220 3d20 6765      pointer = ge
-00000f00: 7461 7474 7228 706f 696e 7465 722c 2027  tattr(pointer, '
-00000f10: 636c 6173 7369 6669 6572 2729 0a20 2020  classifier').   
-00000f20: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00000f30: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00000f40: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
-00000f50: 2020 2020 2020 2020 706f 696e 7465 7220          pointer 
-00000f60: 3d20 6765 7461 7474 7228 706f 696e 7465  = getattr(pointe
-00000f70: 722c 2073 636f 7065 5f6e 616d 6573 5b30  r, scope_names[0
-00000f80: 5d29 0a20 2020 2020 2020 2020 2020 2020  ]).             
-00000f90: 2020 2065 7863 6570 7420 4174 7472 6962     except Attrib
-00000fa0: 7574 6545 7272 6f72 3a0a 2020 2020 2020  uteError:.      
-00000fb0: 2020 2020 2020 2020 2020 2020 2020 6c6f                lo
-00000fc0: 6767 6572 2e69 6e66 6f28 2753 6b69 7070  gger.info('Skipp
-00000fd0: 696e 6720 7b7d 272e 666f 726d 6174 2827  ing {}'.format('
-00000fe0: 2f27 2e6a 6f69 6e28 6e61 6d65 2929 290a  /'.join(name))).
-00000ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001000: 2020 2020 636f 6e74 696e 7565 0a20 2020      continue.   
-00001010: 2020 2020 2020 2020 2069 6620 6c65 6e28           if len(
-00001020: 7363 6f70 655f 6e61 6d65 7329 203e 3d20  scope_names) >= 
-00001030: 323a 0a20 2020 2020 2020 2020 2020 2020  2:.             
-00001040: 2020 206e 756d 203d 2069 6e74 2873 636f     num = int(sco
-00001050: 7065 5f6e 616d 6573 5b31 5d29 0a20 2020  pe_names[1]).   
-00001060: 2020 2020 2020 2020 2020 2020 2070 6f69               poi
-00001070: 6e74 6572 203d 2070 6f69 6e74 6572 5b6e  nter = pointer[n
-00001080: 756d 5d0a 2020 2020 2020 2020 6966 206d  um].        if m
-00001090: 5f6e 616d 655b 2d31 313a 5d20 3d3d 2027  _name[-11:] == '
-000010a0: 5f65 6d62 6564 6469 6e67 7327 3a0a 2020  _embeddings':.  
-000010b0: 2020 2020 2020 2020 2020 706f 696e 7465            pointe
-000010c0: 7220 3d20 6765 7461 7474 7228 706f 696e  r = getattr(poin
-000010d0: 7465 722c 2027 7765 6967 6874 2729 0a20  ter, 'weight'). 
-000010e0: 2020 2020 2020 2065 6c69 6620 6d5f 6e61         elif m_na
-000010f0: 6d65 203d 3d20 276b 6572 6e65 6c27 3a0a  me == 'kernel':.
-00001100: 2020 2020 2020 2020 2020 2020 6172 7261              arra
-00001110: 7920 3d20 6e70 2e74 7261 6e73 706f 7365  y = np.transpose
-00001120: 2861 7272 6179 290a 2020 2020 2020 2020  (array).        
-00001130: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
-00001140: 2061 7373 6572 7420 280a 2020 2020 2020   assert (.      
-00001150: 2020 2020 2020 2020 2020 706f 696e 7465            pointe
-00001160: 722e 7368 6170 6520 3d3d 2061 7272 6179  r.shape == array
-00001170: 2e73 6861 7065 0a20 2020 2020 2020 2020  .shape.         
-00001180: 2020 2029 2c20 6627 506f 696e 7465 7220     ), f'Pointer 
-00001190: 7368 6170 6520 7b70 6f69 6e74 6572 2e73  shape {pointer.s
-000011a0: 6861 7065 7d20 616e 6420 6172 7261 7920  hape} and array 
-000011b0: 7368 6170 6520 7b61 7272 6179 2e73 6861  shape {array.sha
-000011c0: 7065 7d20 6d69 736d 6174 6368 6564 270a  pe} mismatched'.
-000011d0: 2020 2020 2020 2020 6578 6365 7074 2041          except A
-000011e0: 7373 6572 7469 6f6e 4572 726f 7220 6173  ssertionError as
-000011f0: 2065 3a0a 2020 2020 2020 2020 2020 2020   e:.            
-00001200: 652e 6172 6773 202b 3d20 2870 6f69 6e74  e.args += (point
-00001210: 6572 2e73 6861 7065 2c20 6172 7261 792e  er.shape, array.
-00001220: 7368 6170 6529 0a20 2020 2020 2020 2020  shape).         
-00001230: 2020 2072 6169 7365 0a20 2020 2020 2020     raise.       
-00001240: 206c 6f67 6765 722e 696e 666f 2827 496e   logger.info('In
-00001250: 6974 6961 6c69 7a65 2050 7954 6f72 6368  itialize PyTorch
-00001260: 2077 6569 6768 7420 7b7d 272e 666f 726d   weight {}'.form
-00001270: 6174 286e 616d 6529 290a 2020 2020 2020  at(name)).      
-00001280: 2020 706f 696e 7465 722e 6461 7461 203d    pointer.data =
-00001290: 2074 6f72 6368 2e66 726f 6d5f 6e75 6d70   torch.from_nump
-000012a0: 7928 6172 7261 7929 0a20 2020 2072 6574  y(array).    ret
-000012b0: 7572 6e20 6d6f 6465 6c0a 0a0a 636c 6173  urn model...clas
-000012c0: 7320 4769 7345 6d62 6564 6469 6e67 7328  s GisEmbeddings(
-000012d0: 6e6e 2e4d 6f64 756c 6529 3a0a 2020 2020  nn.Module):.    
-000012e0: 2222 2243 6f6e 7374 7275 6374 2074 6865  """Construct the
-000012f0: 2065 6d62 6564 6469 6e67 7320 6672 6f6d   embeddings from
-00001300: 2077 6f72 642c 2070 6f73 6974 696f 6e20   word, position 
-00001310: 616e 6420 746f 6b65 6e5f 7479 7065 2065  and token_type e
-00001320: 6d62 6564 6469 6e67 732e 2222 220a 0a20  mbeddings.""".. 
-00001330: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00001340: 7365 6c66 2c20 636f 6e66 6967 293a 0a20  self, config):. 
-00001350: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-00001360: 5f69 6e69 745f 5f28 290a 2020 2020 2020  _init__().      
-00001370: 2020 7365 6c66 2e77 6f72 645f 656d 6265    self.word_embe
-00001380: 6464 696e 6773 203d 206e 6e2e 456d 6265  ddings = nn.Embe
-00001390: 6464 696e 6728 0a20 2020 2020 2020 2020  dding(.         
-000013a0: 2020 2063 6f6e 6669 672e 766f 6361 625f     config.vocab_
-000013b0: 7369 7a65 2c20 636f 6e66 6967 2e68 6964  size, config.hid
-000013c0: 6465 6e5f 7369 7a65 2c20 7061 6464 696e  den_size, paddin
-000013d0: 675f 6964 783d 3029 0a20 2020 2020 2020  g_idx=0).       
-000013e0: 2073 656c 662e 706f 7369 7469 6f6e 5f65   self.position_e
-000013f0: 6d62 6564 6469 6e67 7320 3d20 6e6e 2e45  mbeddings = nn.E
-00001400: 6d62 6564 6469 6e67 2863 6f6e 6669 672e  mbedding(config.
-00001410: 6d61 785f 706f 7369 7469 6f6e 5f65 6d62  max_position_emb
-00001420: 6564 6469 6e67 732c 0a20 2020 2020 2020  eddings,.       
-00001430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001450: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
-00001460: 6869 6464 656e 5f73 697a 6529 0a20 2020  hidden_size).   
-00001470: 2020 2020 2073 656c 662e 746f 6b65 6e5f       self.token_
-00001480: 7479 7065 5f65 6d62 6564 6469 6e67 7320  type_embeddings 
-00001490: 3d20 6e6e 2e45 6d62 6564 6469 6e67 280a  = nn.Embedding(.
-000014a0: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
-000014b0: 6967 2e74 7970 655f 766f 6361 625f 7369  ig.type_vocab_si
-000014c0: 7a65 2c20 636f 6e66 6967 2e68 6964 6465  ze, config.hidde
-000014d0: 6e5f 7369 7a65 2c20 7061 6464 696e 675f  n_size, padding_
-000014e0: 6964 783d 3029 0a20 2020 2020 2020 2073  idx=0).        s
-000014f0: 656c 662e 7265 6c5f 7479 7065 5f65 6d62  elf.rel_type_emb
-00001500: 6564 6469 6e67 7320 3d20 6e6e 2e45 6d62  eddings = nn.Emb
-00001510: 6564 6469 6e67 280a 2020 2020 2020 2020  edding(.        
-00001520: 2020 2020 636f 6e66 6967 2e72 656c 5f74      config.rel_t
-00001530: 7970 655f 766f 6361 625f 7369 7a65 2c20  ype_vocab_size, 
-00001540: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
-00001550: 7a65 2c20 7061 6464 696e 675f 6964 783d  ze, padding_idx=
-00001560: 3029 0a20 2020 2020 2020 2073 656c 662e  0).        self.
-00001570: 6162 736f 6c75 7465 5f78 5f65 6d62 6564  absolute_x_embed
-00001580: 6469 6e67 7320 3d20 6e6e 2e45 6d62 6564  dings = nn.Embed
-00001590: 6469 6e67 280a 2020 2020 2020 2020 2020  ding(.          
-000015a0: 2020 636f 6e66 6967 2e61 6273 6f6c 7574    config.absolut
-000015b0: 655f 785f 766f 6361 625f 7369 7a65 2c20  e_x_vocab_size, 
-000015c0: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
-000015d0: 7a65 2c20 7061 6464 696e 675f 6964 783d  ze, padding_idx=
-000015e0: 3029 0a20 2020 2020 2020 2073 656c 662e  0).        self.
-000015f0: 6162 736f 6c75 7465 5f79 5f65 6d62 6564  absolute_y_embed
-00001600: 6469 6e67 7320 3d20 6e6e 2e45 6d62 6564  dings = nn.Embed
-00001610: 6469 6e67 280a 2020 2020 2020 2020 2020  ding(.          
-00001620: 2020 636f 6e66 6967 2e61 6273 6f6c 7574    config.absolut
-00001630: 655f 795f 766f 6361 625f 7369 7a65 2c20  e_y_vocab_size, 
-00001640: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
-00001650: 7a65 2c20 7061 6464 696e 675f 6964 783d  ze, padding_idx=
-00001660: 3029 0a20 2020 2020 2020 2073 656c 662e  0).        self.
-00001670: 7265 6c61 7469 7665 5f78 5f65 6d62 6564  relative_x_embed
-00001680: 6469 6e67 7320 3d20 6e6e 2e45 6d62 6564  dings = nn.Embed
-00001690: 6469 6e67 280a 2020 2020 2020 2020 2020  ding(.          
-000016a0: 2020 636f 6e66 6967 2e72 656c 6174 6976    config.relativ
-000016b0: 655f 785f 766f 6361 625f 7369 7a65 2c20  e_x_vocab_size, 
-000016c0: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
-000016d0: 7a65 2c20 7061 6464 696e 675f 6964 783d  ze, padding_idx=
-000016e0: 3029 0a20 2020 2020 2020 2073 656c 662e  0).        self.
-000016f0: 7265 6c61 7469 7665 5f79 5f65 6d62 6564  relative_y_embed
-00001700: 6469 6e67 7320 3d20 6e6e 2e45 6d62 6564  dings = nn.Embed
-00001710: 6469 6e67 280a 2020 2020 2020 2020 2020  ding(.          
-00001720: 2020 636f 6e66 6967 2e72 656c 6174 6976    config.relativ
-00001730: 655f 795f 766f 6361 625f 7369 7a65 2c20  e_y_vocab_size, 
-00001740: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
-00001750: 7a65 2c20 7061 6464 696e 675f 6964 783d  ze, padding_idx=
-00001760: 3029 0a20 2020 2020 2020 2069 6620 6861  0).        if ha
-00001770: 7361 7474 7228 636f 6e66 6967 2c20 2770  sattr(config, 'p
-00001780: 726f 765f 766f 6361 625f 7369 7a65 2729  rov_vocab_size')
-00001790: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
-000017a0: 6c66 2e70 726f 765f 656d 6265 6464 696e  lf.prov_embeddin
-000017b0: 6773 203d 206e 6e2e 456d 6265 6464 696e  gs = nn.Embeddin
-000017c0: 6728 0a20 2020 2020 2020 2020 2020 2020  g(.             
-000017d0: 2020 2063 6f6e 6669 672e 7072 6f76 5f76     config.prov_v
-000017e0: 6f63 6162 5f73 697a 652c 2063 6f6e 6669  ocab_size, confi
-000017f0: 672e 6869 6464 656e 5f73 697a 652c 2070  g.hidden_size, p
-00001800: 6164 6469 6e67 5f69 6478 3d30 290a 2020  adding_idx=0).  
-00001810: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
-00001820: 6974 795f 656d 6265 6464 696e 6773 203d  ity_embeddings =
-00001830: 206e 6e2e 456d 6265 6464 696e 6728 0a20   nn.Embedding(. 
-00001840: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00001850: 6f6e 6669 672e 6369 7479 5f76 6f63 6162  onfig.city_vocab
-00001860: 5f73 697a 652c 2063 6f6e 6669 672e 6869  _size, config.hi
-00001870: 6464 656e 5f73 697a 652c 2070 6164 6469  dden_size, paddi
-00001880: 6e67 5f69 6478 3d30 290a 2020 2020 2020  ng_idx=0).      
-00001890: 2020 2020 2020 7365 6c66 2e64 6973 745f        self.dist_
-000018a0: 656d 6265 6464 696e 6773 203d 206e 6e2e  embeddings = nn.
-000018b0: 456d 6265 6464 696e 6728 0a20 2020 2020  Embedding(.     
-000018c0: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
-000018d0: 672e 6469 7374 5f76 6f63 6162 5f73 697a  g.dist_vocab_siz
-000018e0: 652c 2063 6f6e 6669 672e 6869 6464 656e  e, config.hidden
-000018f0: 5f73 697a 652c 2070 6164 6469 6e67 5f69  _size, padding_i
-00001900: 6478 3d30 290a 0a20 2020 2020 2020 2023  dx=0)..        #
-00001910: 2073 656c 662e 4c61 7965 724e 6f72 6d20   self.LayerNorm 
-00001920: 6973 206e 6f74 2073 6e61 6b65 2d63 6173  is not snake-cas
-00001930: 6564 2074 6f20 7374 6963 6b20 7769 7468  ed to stick with
-00001940: 2054 656e 736f 7246 6c6f 7720 6d6f 6465   TensorFlow mode
-00001950: 6c20 7661 7269 6162 6c65 206e 616d 6520  l variable name 
-00001960: 616e 6420 6265 2061 626c 6520 746f 206c  and be able to l
-00001970: 6f61 640a 2020 2020 2020 2020 2320 616e  oad.        # an
-00001980: 7920 5465 6e73 6f72 466c 6f77 2063 6865  y TensorFlow che
-00001990: 636b 706f 696e 7420 6669 6c65 0a20 2020  ckpoint file.   
-000019a0: 2020 2020 2073 656c 662e 4c61 7965 724e       self.LayerN
-000019b0: 6f72 6d20 3d20 6e6e 2e4c 6179 6572 4e6f  orm = nn.LayerNo
-000019c0: 726d 280a 2020 2020 2020 2020 2020 2020  rm(.            
-000019d0: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
-000019e0: 7a65 2c20 6570 733d 636f 6e66 6967 2e6c  ze, eps=config.l
-000019f0: 6179 6572 5f6e 6f72 6d5f 6570 7329 0a20  ayer_norm_eps). 
-00001a00: 2020 2020 2020 2073 656c 662e 6472 6f70         self.drop
-00001a10: 6f75 7420 3d20 6e6e 2e44 726f 706f 7574  out = nn.Dropout
-00001a20: 2863 6f6e 6669 672e 6869 6464 656e 5f64  (config.hidden_d
-00001a30: 726f 706f 7574 5f70 726f 6229 0a0a 2020  ropout_prob)..  
-00001a40: 2020 2020 2020 2320 706f 7369 7469 6f6e        # position
-00001a50: 5f69 6473 2028 312c 206c 656e 2070 6f73  _ids (1, len pos
-00001a60: 6974 696f 6e20 656d 6229 2069 7320 636f  ition emb) is co
-00001a70: 6e74 6967 756f 7573 2069 6e20 6d65 6d6f  ntiguous in memo
-00001a80: 7279 2061 6e64 2065 7870 6f72 7465 6420  ry and exported 
-00001a90: 7768 656e 2073 6572 6961 6c69 7a65 640a  when serialized.
-00001aa0: 2020 2020 2020 2020 7365 6c66 2e72 6567          self.reg
-00001ab0: 6973 7465 725f 6275 6666 6572 280a 2020  ister_buffer(.  
-00001ac0: 2020 2020 2020 2020 2020 2770 6f73 6974            'posit
-00001ad0: 696f 6e5f 6964 7327 2c0a 2020 2020 2020  ion_ids',.      
-00001ae0: 2020 2020 2020 746f 7263 682e 6172 616e        torch.aran
-00001af0: 6765 2863 6f6e 6669 672e 6d61 785f 706f  ge(config.max_po
-00001b00: 7369 7469 6f6e 5f65 6d62 6564 6469 6e67  sition_embedding
-00001b10: 7329 2e65 7870 616e 6428 2831 2c20 2d31  s).expand((1, -1
-00001b20: 2929 290a 2020 2020 2020 2020 7365 6c66  ))).        self
-00001b30: 2e70 6f73 6974 696f 6e5f 656d 6265 6464  .position_embedd
-00001b40: 696e 675f 7479 7065 203d 2067 6574 6174  ing_type = getat
-00001b50: 7472 2863 6f6e 6669 672c 0a20 2020 2020  tr(config,.     
-00001b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001b80: 2020 2020 2020 2020 2020 2770 6f73 6974            'posit
-00001b90: 696f 6e5f 656d 6265 6464 696e 675f 7479  ion_embedding_ty
-00001ba0: 7065 272c 0a20 2020 2020 2020 2020 2020  pe',.           
-00001bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001bd0: 2020 2020 2761 6273 6f6c 7574 6527 290a      'absolute').
-00001be0: 0a20 2020 2020 2020 2073 656c 662e 636f  .        self.co
-00001bf0: 6e66 6967 203d 2063 6f6e 6669 670a 0a20  nfig = config.. 
-00001c00: 2020 2064 6566 2066 6f72 7761 7264 2873     def forward(s
-00001c10: 656c 662c 0a20 2020 2020 2020 2020 2020  elf,.           
-00001c20: 2020 2020 2069 6e70 7574 5f69 6473 3d4e       input_ids=N
-00001c30: 6f6e 652c 0a20 2020 2020 2020 2020 2020  one,.           
-00001c40: 2020 2020 2074 6f6b 656e 5f74 7970 655f       token_type_
-00001c50: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
-00001c60: 2020 2020 2020 2020 2020 706f 7369 7469            positi
-00001c70: 6f6e 5f69 6473 3d4e 6f6e 652c 0a20 2020  on_ids=None,.   
-00001c80: 2020 2020 2020 2020 2020 2020 2069 6e70               inp
-00001c90: 7574 735f 656d 6265 6473 3d4e 6f6e 652c  uts_embeds=None,
-00001ca0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001cb0: 2070 6173 745f 6b65 795f 7661 6c75 6573   past_key_values
-00001cc0: 5f6c 656e 6774 683d 302c 0a20 2020 2020  _length=0,.     
-00001cd0: 2020 2020 2020 2020 2020 2072 656c 5f74             rel_t
-00001ce0: 7970 655f 6964 733d 4e6f 6e65 2c0a 2020  ype_ids=None,.  
-00001cf0: 2020 2020 2020 2020 2020 2020 2020 6162                ab
-00001d00: 736f 6c75 7465 5f70 6f73 6974 696f 6e5f  solute_position_
-00001d10: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
-00001d20: 2020 2020 2020 2020 2020 7265 6c61 7469            relati
-00001d30: 7665 5f70 6f73 6974 696f 6e5f 6964 733d  ve_position_ids=
-00001d40: 4e6f 6e65 2c0a 2020 2020 2020 2020 2020  None,.          
-00001d50: 2020 2020 2020 7072 6f76 5f69 6473 3d4e        prov_ids=N
-00001d60: 6f6e 652c 0a20 2020 2020 2020 2020 2020  one,.           
-00001d70: 2020 2020 2063 6974 795f 6964 733d 4e6f       city_ids=No
-00001d80: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
-00001d90: 2020 2020 6469 7374 5f69 6473 3d4e 6f6e      dist_ids=Non
-00001da0: 6529 3a0a 2020 2020 2020 2020 6966 2069  e):.        if i
-00001db0: 6e70 7574 5f69 6473 2069 7320 6e6f 7420  nput_ids is not 
-00001dc0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00001dd0: 2020 696e 7075 745f 7368 6170 6520 3d20    input_shape = 
-00001de0: 696e 7075 745f 6964 732e 7369 7a65 2829  input_ids.size()
-00001df0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00001e00: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00001e10: 5f73 6861 7065 203d 2069 6e70 7574 735f  _shape = inputs_
-00001e20: 656d 6265 6473 2e73 697a 6528 295b 3a2d  embeds.size()[:-
-00001e30: 315d 0a0a 2020 2020 2020 2020 7365 715f  1]..        seq_
-00001e40: 6c65 6e67 7468 203d 2069 6e70 7574 5f73  length = input_s
-00001e50: 6861 7065 5b31 5d0a 0a20 2020 2020 2020  hape[1]..       
-00001e60: 2069 6620 706f 7369 7469 6f6e 5f69 6473   if position_ids
-00001e70: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
-00001e80: 2020 2020 2020 706f 7369 7469 6f6e 5f69        position_i
-00001e90: 6473 203d 2073 656c 662e 706f 7369 7469  ds = self.positi
-00001ea0: 6f6e 5f69 6473 5b3a 2c0a 2020 2020 2020  on_ids[:,.      
-00001eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001ed0: 2020 2020 2020 2070 6173 745f 6b65 795f         past_key_
-00001ee0: 7661 6c75 6573 5f6c 656e 6774 683a 7365  values_length:se
-00001ef0: 715f 6c65 6e67 7468 0a20 2020 2020 2020  q_length.       
-00001f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001f20: 2020 2020 2020 2b20 7061 7374 5f6b 6579        + past_key
-00001f30: 5f76 616c 7565 735f 6c65 6e67 7468 5d0a  _values_length].
-00001f40: 0a20 2020 2020 2020 2069 6620 746f 6b65  .        if toke
-00001f50: 6e5f 7479 7065 5f69 6473 2069 7320 4e6f  n_type_ids is No
-00001f60: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00001f70: 746f 6b65 6e5f 7479 7065 5f69 6473 203d  token_type_ids =
-00001f80: 2074 6f72 6368 2e7a 6572 6f73 280a 2020   torch.zeros(.  
-00001f90: 2020 2020 2020 2020 2020 2020 2020 696e                in
-00001fa0: 7075 745f 7368 6170 652c 2064 7479 7065  put_shape, dtype
-00001fb0: 3d74 6f72 6368 2e6c 6f6e 672c 2064 6576  =torch.long, dev
-00001fc0: 6963 653d 7365 6c66 2e70 6f73 6974 696f  ice=self.positio
-00001fd0: 6e5f 6964 732e 6465 7669 6365 290a 0a20  n_ids.device).. 
-00001fe0: 2020 2020 2020 2069 6620 696e 7075 7473         if inputs
-00001ff0: 5f65 6d62 6564 7320 6973 204e 6f6e 653a  _embeds is None:
-00002000: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
-00002010: 7574 735f 656d 6265 6473 203d 2073 656c  uts_embeds = sel
-00002020: 662e 776f 7264 5f65 6d62 6564 6469 6e67  f.word_embedding
-00002030: 7328 696e 7075 745f 6964 7329 0a0a 2020  s(input_ids)..  
-00002040: 2020 2020 2020 746f 6b65 6e5f 7479 7065        token_type
-00002050: 5f65 6d62 6564 6469 6e67 7320 3d20 7365  _embeddings = se
-00002060: 6c66 2e74 6f6b 656e 5f74 7970 655f 656d  lf.token_type_em
-00002070: 6265 6464 696e 6773 2874 6f6b 656e 5f74  beddings(token_t
-00002080: 7970 655f 6964 7329 0a0a 2020 2020 2020  ype_ids)..      
-00002090: 2020 656d 6265 6464 696e 6773 203d 2069    embeddings = i
-000020a0: 6e70 7574 735f 656d 6265 6473 202b 2074  nputs_embeds + t
-000020b0: 6f6b 656e 5f74 7970 655f 656d 6265 6464  oken_type_embedd
-000020c0: 696e 6773 0a20 2020 2020 2020 2069 6620  ings.        if 
-000020d0: 7365 6c66 2e70 6f73 6974 696f 6e5f 656d  self.position_em
-000020e0: 6265 6464 696e 675f 7479 7065 203d 3d20  bedding_type == 
-000020f0: 2761 6273 6f6c 7574 6527 3a0a 2020 2020  'absolute':.    
-00002100: 2020 2020 2020 2020 706f 7369 7469 6f6e          position
-00002110: 5f65 6d62 6564 6469 6e67 7320 3d20 7365  _embeddings = se
-00002120: 6c66 2e70 6f73 6974 696f 6e5f 656d 6265  lf.position_embe
-00002130: 6464 696e 6773 2870 6f73 6974 696f 6e5f  ddings(position_
-00002140: 6964 7329 0a20 2020 2020 2020 2020 2020  ids).           
-00002150: 2065 6d62 6564 6469 6e67 7320 2b3d 2070   embeddings += p
-00002160: 6f73 6974 696f 6e5f 656d 6265 6464 696e  osition_embeddin
-00002170: 6773 0a20 2020 2020 2020 2065 6d62 6564  gs.        embed
-00002180: 6469 6e67 7320 2b3d 2073 656c 662e 7265  dings += self.re
-00002190: 6c5f 7479 7065 5f65 6d62 6564 6469 6e67  l_type_embedding
-000021a0: 7328 7265 6c5f 7479 7065 5f69 6473 290a  s(rel_type_ids).
-000021b0: 2020 2020 2020 2020 656d 6265 6464 696e          embeddin
-000021c0: 6773 202b 3d20 7365 6c66 2e61 6273 6f6c  gs += self.absol
-000021d0: 7574 655f 785f 656d 6265 6464 696e 6773  ute_x_embeddings
-000021e0: 2861 6273 6f6c 7574 655f 706f 7369 7469  (absolute_positi
-000021f0: 6f6e 5f69 6473 5b3a 2c20 3a2c 0a20 2020  on_ids[:, :,.   
-00002200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000010: 7274 206f 730a 6672 6f6d 2064 6174 6163  rt os.from datac
+00000020: 6c61 7373 6573 2069 6d70 6f72 7420 6461  lasses import da
+00000030: 7461 636c 6173 730a 6672 6f6d 2074 7970  taclass.from typ
+00000040: 696e 6720 696d 706f 7274 204f 7074 696f  ing import Optio
+00000050: 6e61 6c2c 2054 7570 6c65 0a0a 696d 706f  nal, Tuple..impo
+00000060: 7274 2074 6f72 6368 0a69 6d70 6f72 7420  rt torch.import 
+00000070: 746f 7263 682e 6e6e 2e66 756e 6374 696f  torch.nn.functio
+00000080: 6e61 6c20 6173 2046 0a69 6d70 6f72 7420  nal as F.import 
+00000090: 746f 7263 682e 7574 696c 732e 6368 6563  torch.utils.chec
+000000a0: 6b70 6f69 6e74 0a69 6d70 6f72 7420 7472  kpoint.import tr
+000000b0: 616e 7366 6f72 6d65 7273 0a66 726f 6d20  ansformers.from 
+000000c0: 746f 7263 6820 696d 706f 7274 2054 656e  torch import Ten
+000000d0: 736f 722c 2064 6576 6963 652c 206e 6e0a  sor, device, nn.
+000000e0: 6672 6f6d 2074 6f72 6368 2e6e 6e20 696d  from torch.nn im
+000000f0: 706f 7274 2043 726f 7373 456e 7472 6f70  port CrossEntrop
+00000100: 794c 6f73 732c 204d 5345 4c6f 7373 0a66  yLoss, MSELoss.f
+00000110: 726f 6d20 7472 616e 7366 6f72 6d65 7273  rom transformers
+00000120: 2e61 6374 6976 6174 696f 6e73 2069 6d70  .activations imp
+00000130: 6f72 7420 4143 5432 464e 0a66 726f 6d20  ort ACT2FN.from 
+00000140: 7472 616e 7366 6f72 6d65 7273 2e66 696c  transformers.fil
+00000150: 655f 7574 696c 7320 696d 706f 7274 2028  e_utils import (
+00000160: 4d6f 6465 6c4f 7574 7075 7429 0a66 726f  ModelOutput).fro
+00000170: 6d20 7472 616e 7366 6f72 6d65 7273 2e6d  m transformers.m
+00000180: 6f64 656c 696e 675f 6f75 7470 7574 7320  odeling_outputs 
+00000190: 696d 706f 7274 2028 0a20 2020 2042 6173  import (.    Bas
+000001a0: 654d 6f64 656c 4f75 7470 7574 5769 7468  eModelOutputWith
+000001b0: 5061 7374 416e 6443 726f 7373 4174 7465  PastAndCrossAtte
+000001c0: 6e74 696f 6e73 2c0a 2020 2020 4261 7365  ntions,.    Base
+000001d0: 4d6f 6465 6c4f 7574 7075 7457 6974 6850  ModelOutputWithP
+000001e0: 6f6f 6c69 6e67 416e 6443 726f 7373 4174  oolingAndCrossAt
+000001f0: 7465 6e74 696f 6e73 2c0a 2020 2020 4361  tentions,.    Ca
+00000200: 7573 616c 4c4d 4f75 7470 7574 5769 7468  usalLMOutputWith
+00000210: 4372 6f73 7341 7474 656e 7469 6f6e 732c  CrossAttentions,
+00000220: 204d 6173 6b65 644c 4d4f 7574 7075 742c   MaskedLMOutput,
+00000230: 0a20 2020 204d 756c 7469 706c 6543 686f  .    MultipleCho
+00000240: 6963 654d 6f64 656c 4f75 7470 7574 2c20  iceModelOutput, 
+00000250: 4e65 7874 5365 6e74 656e 6365 5072 6564  NextSentencePred
+00000260: 6963 746f 724f 7574 7075 742c 0a20 2020  ictorOutput,.   
+00000270: 2051 7565 7374 696f 6e41 6e73 7765 7269   QuestionAnsweri
+00000280: 6e67 4d6f 6465 6c4f 7574 7075 742c 2053  ngModelOutput, S
+00000290: 6571 7565 6e63 6543 6c61 7373 6966 6965  equenceClassifie
+000002a0: 724f 7574 7075 742c 0a20 2020 2054 6f6b  rOutput,.    Tok
+000002b0: 656e 436c 6173 7369 6669 6572 4f75 7470  enClassifierOutp
+000002c0: 7574 290a 6672 6f6d 2074 7261 6e73 666f  ut).from transfo
+000002d0: 726d 6572 732e 6d6f 6465 6c69 6e67 5f75  rmers.modeling_u
+000002e0: 7469 6c73 2069 6d70 6f72 7420 2850 7265  tils import (Pre
+000002f0: 5472 6169 6e65 644d 6f64 656c 2c0a 2020  TrainedModel,.  
+00000300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000320: 2020 2020 2020 2061 7070 6c79 5f63 6875         apply_chu
+00000330: 6e6b 696e 675f 746f 5f66 6f72 7761 7264  nking_to_forward
+00000340: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00000350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000360: 2020 2020 2020 2020 2020 2066 696e 645f             find_
+00000370: 7072 756e 6561 626c 655f 6865 6164 735f  pruneable_heads_
+00000380: 616e 645f 696e 6469 6365 732c 0a20 2020  and_indices,.   
+00000390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000003a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000003b0: 2020 2020 2020 7072 756e 655f 6c69 6e65        prune_line
+000003c0: 6172 5f6c 6179 6572 290a 6672 6f6d 2074  ar_layer).from t
+000003d0: 7261 6e73 666f 726d 6572 732e 6d6f 6465  ransformers.mode
+000003e0: 6c73 2e62 6572 742e 636f 6e66 6967 7572  ls.bert.configur
+000003f0: 6174 696f 6e5f 6265 7274 2069 6d70 6f72  ation_bert impor
+00000400: 7420 4265 7274 436f 6e66 6967 0a66 726f  t BertConfig.fro
+00000410: 6d20 7472 616e 7366 6f72 6d65 7273 2e75  m transformers.u
+00000420: 7469 6c73 2069 6d70 6f72 7420 6c6f 6767  tils import logg
+00000430: 696e 670a 0a66 726f 6d20 7765 6174 686f  ing..from weatho
+00000440: 6e2e 7574 696c 732e 636f 6e73 7461 6e74  n.utils.constant
+00000450: 732e 6d65 7461 696e 666f 2069 6d70 6f72  s.metainfo impor
+00000460: 7420 4d6f 6465 6c73 0a66 726f 6d20 7765  t Models.from we
+00000470: 6174 686f 6e2e 6261 7365 2069 6d70 6f72  athon.base impor
+00000480: 7420 546f 7263 684d 6f64 656c 0a66 726f  t TorchModel.fro
+00000490: 6d20 7765 6174 686f 6e2e 7265 6769 7374  m weathon.regist
+000004a0: 7279 2069 6d70 6f72 7420 4d4f 4445 4c53  ry import MODELS
+000004b0: 0a66 726f 6d20 7765 6174 686f 6e2e 7574  .from weathon.ut
+000004c0: 696c 732e 6f75 7470 7574 2e6e 6c70 5f6f  ils.output.nlp_o
+000004d0: 7574 7075 7473 2069 6d70 6f72 7420 4174  utputs import At
+000004e0: 7465 6e74 696f 6e42 6163 6b62 6f6e 654d  tentionBackboneM
+000004f0: 6f64 656c 4f75 7470 7574 0a66 726f 6d20  odelOutput.from 
+00000500: 7765 6174 686f 6e2e 7574 696c 732e 636f  weathon.utils.co
+00000510: 6e73 7461 6e74 7320 696d 706f 7274 2054  nstants import T
+00000520: 6173 6b73 0a66 726f 6d20 7765 6174 686f  asks.from weatho
+00000530: 6e2e 7574 696c 732e 6e6c 702e 7574 696c  n.utils.nlp.util
+00000540: 7320 696d 706f 7274 2070 6172 7365 5f6c  s import parse_l
+00000550: 6162 656c 735f 696e 5f6f 7264 6572 0a0a  abels_in_order..
+00000560: 7472 616e 7366 6f72 6d65 7273 2e6c 6f67  transformers.log
+00000570: 6769 6e67 2e73 6574 5f76 6572 626f 7369  ging.set_verbosi
+00000580: 7479 5f65 7272 6f72 2829 0a0a 6c6f 6767  ty_error()..logg
+00000590: 6572 203d 206c 6f67 6769 6e67 2e67 6574  er = logging.get
+000005a0: 5f6c 6f67 6765 7228 290a 0a5f 434f 4e46  _logger().._CONF
+000005b0: 4947 5f46 4f52 5f44 4f43 203d 2027 4265  IG_FOR_DOC = 'Be
+000005c0: 7274 436f 6e66 6967 270a 5f54 4f4b 454e  rtConfig'._TOKEN
+000005d0: 495a 4552 5f46 4f52 5f44 4f43 203d 2027  IZER_FOR_DOC = '
+000005e0: 4265 7274 546f 6b65 6e69 7a65 7227 0a0a  BertTokenizer'..
+000005f0: 0a64 6566 206c 6f61 645f 7466 5f77 6569  .def load_tf_wei
+00000600: 6768 7473 5f69 6e5f 6265 7274 286d 6f64  ghts_in_bert(mod
+00000610: 656c 2c20 636f 6e66 6967 2c20 7466 5f63  el, config, tf_c
+00000620: 6865 636b 706f 696e 745f 7061 7468 293a  heckpoint_path):
+00000630: 0a20 2020 2022 2222 4c6f 6164 2074 6620  .    """Load tf 
+00000640: 6368 6563 6b70 6f69 6e74 7320 696e 2061  checkpoints in a
+00000650: 2070 7974 6f72 6368 206d 6f64 656c 2e22   pytorch model."
+00000660: 2222 0a20 2020 2074 7279 3a0a 2020 2020  "".    try:.    
+00000670: 2020 2020 696d 706f 7274 2072 650a 0a20      import re.. 
+00000680: 2020 2020 2020 2069 6d70 6f72 7420 6e75         import nu
+00000690: 6d70 7920 6173 206e 700a 2020 2020 2020  mpy as np.      
+000006a0: 2020 696d 706f 7274 2074 656e 736f 7266    import tensorf
+000006b0: 6c6f 7720 6173 2074 660a 2020 2020 6578  low as tf.    ex
+000006c0: 6365 7074 2049 6d70 6f72 7445 7272 6f72  cept ImportError
+000006d0: 3a0a 2020 2020 2020 2020 6c6f 6767 6572  :.        logger
+000006e0: 2e65 7272 6f72 280a 2020 2020 2020 2020  .error(.        
+000006f0: 2020 2020 274c 6f61 6469 6e67 2061 2054      'Loading a T
+00000700: 656e 736f 7246 6c6f 7720 6d6f 6465 6c20  ensorFlow model 
+00000710: 696e 2050 7954 6f72 6368 2c20 7265 7175  in PyTorch, requ
+00000720: 6972 6573 2054 656e 736f 7246 6c6f 7720  ires TensorFlow 
+00000730: 746f 2062 6520 696e 7374 616c 6c65 642e  to be installed.
+00000740: 2050 6c65 6173 6520 7365 6520 270a 2020   Please see '.  
+00000750: 2020 2020 2020 2020 2020 2768 7474 7073            'https
+00000760: 3a2f 2f77 7777 2e74 656e 736f 7266 6c6f  ://www.tensorflo
+00000770: 772e 6f72 672f 696e 7374 616c 6c2f 2066  w.org/install/ f
+00000780: 6f72 2069 6e73 7461 6c6c 6174 696f 6e20  or installation 
+00000790: 696e 7374 7275 6374 696f 6e73 2e27 0a20  instructions.'. 
+000007a0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+000007b0: 2072 6169 7365 0a20 2020 2074 665f 7061   raise.    tf_pa
+000007c0: 7468 203d 206f 732e 7061 7468 2e61 6273  th = os.path.abs
+000007d0: 7061 7468 2874 665f 6368 6563 6b70 6f69  path(tf_checkpoi
+000007e0: 6e74 5f70 6174 6829 0a20 2020 206c 6f67  nt_path).    log
+000007f0: 6765 722e 696e 666f 2827 436f 6e76 6572  ger.info('Conver
+00000800: 7469 6e67 2054 656e 736f 7246 6c6f 7720  ting TensorFlow 
+00000810: 6368 6563 6b70 6f69 6e74 2066 726f 6d20  checkpoint from 
+00000820: 7b7d 272e 666f 726d 6174 2874 665f 7061  {}'.format(tf_pa
+00000830: 7468 2929 0a20 2020 2023 204c 6f61 6420  th)).    # Load 
+00000840: 7765 6967 6874 7320 6672 6f6d 2054 4620  weights from TF 
+00000850: 6d6f 6465 6c0a 2020 2020 696e 6974 5f76  model.    init_v
+00000860: 6172 7320 3d20 7466 2e74 7261 696e 2e6c  ars = tf.train.l
+00000870: 6973 745f 7661 7269 6162 6c65 7328 7466  ist_variables(tf
+00000880: 5f70 6174 6829 0a20 2020 206e 616d 6573  _path).    names
+00000890: 203d 205b 5d0a 2020 2020 6172 7261 7973   = [].    arrays
+000008a0: 203d 205b 5d0a 2020 2020 666f 7220 6e61   = [].    for na
+000008b0: 6d65 2c20 7368 6170 6520 696e 2069 6e69  me, shape in ini
+000008c0: 745f 7661 7273 3a0a 2020 2020 2020 2020  t_vars:.        
+000008d0: 6c6f 6767 6572 2e69 6e66 6f28 274c 6f61  logger.info('Loa
+000008e0: 6469 6e67 2054 4620 7765 6967 6874 207b  ding TF weight {
+000008f0: 7d20 7769 7468 2073 6861 7065 207b 7d27  } with shape {}'
+00000900: 2e66 6f72 6d61 7428 6e61 6d65 2c20 7368  .format(name, sh
+00000910: 6170 6529 290a 2020 2020 2020 2020 6172  ape)).        ar
+00000920: 7261 7920 3d20 7466 2e74 7261 696e 2e6c  ray = tf.train.l
+00000930: 6f61 645f 7661 7269 6162 6c65 2874 665f  oad_variable(tf_
+00000940: 7061 7468 2c20 6e61 6d65 290a 2020 2020  path, name).    
+00000950: 2020 2020 6e61 6d65 732e 6170 7065 6e64      names.append
+00000960: 286e 616d 6529 0a20 2020 2020 2020 2061  (name).        a
+00000970: 7272 6179 732e 6170 7065 6e64 2861 7272  rrays.append(arr
+00000980: 6179 290a 0a20 2020 2066 6f72 206e 616d  ay)..    for nam
+00000990: 652c 2061 7272 6179 2069 6e20 7a69 7028  e, array in zip(
+000009a0: 6e61 6d65 732c 2061 7272 6179 7329 3a0a  names, arrays):.
+000009b0: 2020 2020 2020 2020 6e61 6d65 203d 206e          name = n
+000009c0: 616d 652e 7370 6c69 7428 272f 2729 0a20  ame.split('/'). 
+000009d0: 2020 2020 2020 2023 2061 6461 6d5f 7620         # adam_v 
+000009e0: 616e 6420 6164 616d 5f6d 2061 7265 2076  and adam_m are v
+000009f0: 6172 6961 626c 6573 2075 7365 6420 696e  ariables used in
+00000a00: 2041 6461 6d57 6569 6768 7444 6563 6179   AdamWeightDecay
+00000a10: 4f70 7469 6d69 7a65 7220 746f 0a20 2020  Optimizer to.   
+00000a20: 2020 2020 2023 2063 616c 6375 6c61 7465       # calculate
+00000a30: 6420 6d20 616e 6420 7620 7768 6963 6820  d m and v which 
+00000a40: 6172 6520 6e6f 7420 7265 7175 6972 6564  are not required
+00000a50: 2066 6f72 2075 7369 6e67 2070 7265 7472   for using pretr
+00000a60: 6169 6e65 6420 6d6f 6465 6c0a 2020 2020  ained model.    
+00000a70: 2020 2020 6966 2061 6e79 286e 2069 6e20      if any(n in 
+00000a80: 5b0a 2020 2020 2020 2020 2020 2020 2020  [.              
+00000a90: 2020 2761 6461 6d5f 7627 2c20 2761 6461    'adam_v', 'ada
+00000aa0: 6d5f 6d27 2c20 2741 6461 6d57 6569 6768  m_m', 'AdamWeigh
+00000ab0: 7444 6563 6179 4f70 7469 6d69 7a65 7227  tDecayOptimizer'
+00000ac0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00000ad0: 2020 2741 6461 6d57 6569 6768 7444 6563    'AdamWeightDec
+00000ae0: 6179 4f70 7469 6d69 7a65 725f 3127 2c20  ayOptimizer_1', 
+00000af0: 2767 6c6f 6261 6c5f 7374 6570 270a 2020  'global_step'.  
+00000b00: 2020 2020 2020 5d20 666f 7220 6e20 696e        ] for n in
+00000b10: 206e 616d 6529 3a0a 2020 2020 2020 2020   name):.        
+00000b20: 2020 2020 6c6f 6767 6572 2e69 6e66 6f28      logger.info(
+00000b30: 2753 6b69 7070 696e 6720 7b7d 272e 666f  'Skipping {}'.fo
+00000b40: 726d 6174 2827 2f27 2e6a 6f69 6e28 6e61  rmat('/'.join(na
+00000b50: 6d65 2929 290a 2020 2020 2020 2020 2020  me))).          
+00000b60: 2020 636f 6e74 696e 7565 0a20 2020 2020    continue.     
+00000b70: 2020 2070 6f69 6e74 6572 203d 206d 6f64     pointer = mod
+00000b80: 656c 0a20 2020 2020 2020 2066 6f72 206d  el.        for m
+00000b90: 5f6e 616d 6520 696e 206e 616d 653a 0a20  _name in name:. 
+00000ba0: 2020 2020 2020 2020 2020 2069 6620 7265             if re
+00000bb0: 2e66 756c 6c6d 6174 6368 2872 275b 412d  .fullmatch(r'[A-
+00000bc0: 5a61 2d7a 5d2b 5f5c 642b 272c 206d 5f6e  Za-z]+_\d+', m_n
+00000bd0: 616d 6529 3a0a 2020 2020 2020 2020 2020  ame):.          
+00000be0: 2020 2020 2020 7363 6f70 655f 6e61 6d65        scope_name
+00000bf0: 7320 3d20 7265 2e73 706c 6974 2872 275f  s = re.split(r'_
+00000c00: 285c 642b 2927 2c20 6d5f 6e61 6d65 290a  (\d+)', m_name).
+00000c10: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00000c20: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00000c30: 2020 7363 6f70 655f 6e61 6d65 7320 3d20    scope_names = 
+00000c40: 5b6d 5f6e 616d 655d 0a20 2020 2020 2020  [m_name].       
+00000c50: 2020 2020 2069 6620 7363 6f70 655f 6e61       if scope_na
+00000c60: 6d65 735b 305d 203d 3d20 276b 6572 6e65  mes[0] == 'kerne
+00000c70: 6c27 206f 7220 7363 6f70 655f 6e61 6d65  l' or scope_name
+00000c80: 735b 305d 203d 3d20 2767 616d 6d61 273a  s[0] == 'gamma':
+00000c90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00000ca0: 2070 6f69 6e74 6572 203d 2067 6574 6174   pointer = getat
+00000cb0: 7472 2870 6f69 6e74 6572 2c20 2777 6569  tr(pointer, 'wei
+00000cc0: 6768 7427 290a 2020 2020 2020 2020 2020  ght').          
+00000cd0: 2020 656c 6966 2073 636f 7065 5f6e 616d    elif scope_nam
+00000ce0: 6573 5b30 5d20 3d3d 2027 6f75 7470 7574  es[0] == 'output
+00000cf0: 5f62 6961 7327 206f 7220 7363 6f70 655f  _bias' or scope_
+00000d00: 6e61 6d65 735b 305d 203d 3d20 2762 6574  names[0] == 'bet
+00000d10: 6127 3a0a 2020 2020 2020 2020 2020 2020  a':.            
+00000d20: 2020 2020 706f 696e 7465 7220 3d20 6765      pointer = ge
+00000d30: 7461 7474 7228 706f 696e 7465 722c 2027  tattr(pointer, '
+00000d40: 6269 6173 2729 0a20 2020 2020 2020 2020  bias').         
+00000d50: 2020 2065 6c69 6620 7363 6f70 655f 6e61     elif scope_na
+00000d60: 6d65 735b 305d 203d 3d20 276f 7574 7075  mes[0] == 'outpu
+00000d70: 745f 7765 6967 6874 7327 3a0a 2020 2020  t_weights':.    
+00000d80: 2020 2020 2020 2020 2020 2020 706f 696e              poin
+00000d90: 7465 7220 3d20 6765 7461 7474 7228 706f  ter = getattr(po
+00000da0: 696e 7465 722c 2027 7765 6967 6874 2729  inter, 'weight')
+00000db0: 0a20 2020 2020 2020 2020 2020 2065 6c69  .            eli
+00000dc0: 6620 7363 6f70 655f 6e61 6d65 735b 305d  f scope_names[0]
+00000dd0: 203d 3d20 2773 7175 6164 273a 0a20 2020   == 'squad':.   
+00000de0: 2020 2020 2020 2020 2020 2020 2070 6f69               poi
+00000df0: 6e74 6572 203d 2067 6574 6174 7472 2870  nter = getattr(p
+00000e00: 6f69 6e74 6572 2c20 2763 6c61 7373 6966  ointer, 'classif
+00000e10: 6965 7227 290a 2020 2020 2020 2020 2020  ier').          
+00000e20: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00000e30: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+00000e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000e50: 2070 6f69 6e74 6572 203d 2067 6574 6174   pointer = getat
+00000e60: 7472 2870 6f69 6e74 6572 2c20 7363 6f70  tr(pointer, scop
+00000e70: 655f 6e61 6d65 735b 305d 290a 2020 2020  e_names[0]).    
+00000e80: 2020 2020 2020 2020 2020 2020 6578 6365              exce
+00000e90: 7074 2041 7474 7269 6275 7465 4572 726f  pt AttributeErro
+00000ea0: 723a 0a20 2020 2020 2020 2020 2020 2020  r:.             
+00000eb0: 2020 2020 2020 206c 6f67 6765 722e 696e         logger.in
+00000ec0: 666f 2827 536b 6970 7069 6e67 207b 7d27  fo('Skipping {}'
+00000ed0: 2e66 6f72 6d61 7428 272f 272e 6a6f 696e  .format('/'.join
+00000ee0: 286e 616d 6529 2929 0a20 2020 2020 2020  (name))).       
+00000ef0: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
+00000f00: 7469 6e75 650a 2020 2020 2020 2020 2020  tinue.          
+00000f10: 2020 6966 206c 656e 2873 636f 7065 5f6e    if len(scope_n
+00000f20: 616d 6573 2920 3e3d 2032 3a0a 2020 2020  ames) >= 2:.    
+00000f30: 2020 2020 2020 2020 2020 2020 6e75 6d20              num 
+00000f40: 3d20 696e 7428 7363 6f70 655f 6e61 6d65  = int(scope_name
+00000f50: 735b 315d 290a 2020 2020 2020 2020 2020  s[1]).          
+00000f60: 2020 2020 2020 706f 696e 7465 7220 3d20        pointer = 
+00000f70: 706f 696e 7465 725b 6e75 6d5d 0a20 2020  pointer[num].   
+00000f80: 2020 2020 2069 6620 6d5f 6e61 6d65 5b2d       if m_name[-
+00000f90: 3131 3a5d 203d 3d20 275f 656d 6265 6464  11:] == '_embedd
+00000fa0: 696e 6773 273a 0a20 2020 2020 2020 2020  ings':.         
+00000fb0: 2020 2070 6f69 6e74 6572 203d 2067 6574     pointer = get
+00000fc0: 6174 7472 2870 6f69 6e74 6572 2c20 2777  attr(pointer, 'w
+00000fd0: 6569 6768 7427 290a 2020 2020 2020 2020  eight').        
+00000fe0: 656c 6966 206d 5f6e 616d 6520 3d3d 2027  elif m_name == '
+00000ff0: 6b65 726e 656c 273a 0a20 2020 2020 2020  kernel':.       
+00001000: 2020 2020 2061 7272 6179 203d 206e 702e       array = np.
+00001010: 7472 616e 7370 6f73 6528 6172 7261 7929  transpose(array)
+00001020: 0a20 2020 2020 2020 2074 7279 3a0a 2020  .        try:.  
+00001030: 2020 2020 2020 2020 2020 6173 7365 7274            assert
+00001040: 2028 0a20 2020 2020 2020 2020 2020 2020   (.             
+00001050: 2020 2070 6f69 6e74 6572 2e73 6861 7065     pointer.shape
+00001060: 203d 3d20 6172 7261 792e 7368 6170 650a   == array.shape.
+00001070: 2020 2020 2020 2020 2020 2020 292c 2066              ), f
+00001080: 2750 6f69 6e74 6572 2073 6861 7065 207b  'Pointer shape {
+00001090: 706f 696e 7465 722e 7368 6170 657d 2061  pointer.shape} a
+000010a0: 6e64 2061 7272 6179 2073 6861 7065 207b  nd array shape {
+000010b0: 6172 7261 792e 7368 6170 657d 206d 6973  array.shape} mis
+000010c0: 6d61 7463 6865 6427 0a20 2020 2020 2020  matched'.       
+000010d0: 2065 7863 6570 7420 4173 7365 7274 696f   except Assertio
+000010e0: 6e45 7272 6f72 2061 7320 653a 0a20 2020  nError as e:.   
+000010f0: 2020 2020 2020 2020 2065 2e61 7267 7320           e.args 
+00001100: 2b3d 2028 706f 696e 7465 722e 7368 6170  += (pointer.shap
+00001110: 652c 2061 7272 6179 2e73 6861 7065 290a  e, array.shape).
+00001120: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00001130: 650a 2020 2020 2020 2020 6c6f 6767 6572  e.        logger
+00001140: 2e69 6e66 6f28 2749 6e69 7469 616c 697a  .info('Initializ
+00001150: 6520 5079 546f 7263 6820 7765 6967 6874  e PyTorch weight
+00001160: 207b 7d27 2e66 6f72 6d61 7428 6e61 6d65   {}'.format(name
+00001170: 2929 0a20 2020 2020 2020 2070 6f69 6e74  )).        point
+00001180: 6572 2e64 6174 6120 3d20 746f 7263 682e  er.data = torch.
+00001190: 6672 6f6d 5f6e 756d 7079 2861 7272 6179  from_numpy(array
+000011a0: 290a 2020 2020 7265 7475 726e 206d 6f64  ).    return mod
+000011b0: 656c 0a0a 0a63 6c61 7373 2047 6973 456d  el...class GisEm
+000011c0: 6265 6464 696e 6773 286e 6e2e 4d6f 6475  beddings(nn.Modu
+000011d0: 6c65 293a 0a20 2020 2022 2222 436f 6e73  le):.    """Cons
+000011e0: 7472 7563 7420 7468 6520 656d 6265 6464  truct the embedd
+000011f0: 696e 6773 2066 726f 6d20 776f 7264 2c20  ings from word, 
+00001200: 706f 7369 7469 6f6e 2061 6e64 2074 6f6b  position and tok
+00001210: 656e 5f74 7970 6520 656d 6265 6464 696e  en_type embeddin
+00001220: 6773 2e22 2222 0a0a 2020 2020 6465 6620  gs."""..    def 
+00001230: 5f5f 696e 6974 5f5f 2873 656c 662c 2063  __init__(self, c
+00001240: 6f6e 6669 6729 3a0a 2020 2020 2020 2020  onfig):.        
+00001250: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
+00001260: 2829 0a20 2020 2020 2020 2073 656c 662e  ().        self.
+00001270: 776f 7264 5f65 6d62 6564 6469 6e67 7320  word_embeddings 
+00001280: 3d20 6e6e 2e45 6d62 6564 6469 6e67 280a  = nn.Embedding(.
+00001290: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+000012a0: 6967 2e76 6f63 6162 5f73 697a 652c 2063  ig.vocab_size, c
+000012b0: 6f6e 6669 672e 6869 6464 656e 5f73 697a  onfig.hidden_siz
+000012c0: 652c 2070 6164 6469 6e67 5f69 6478 3d30  e, padding_idx=0
+000012d0: 290a 2020 2020 2020 2020 7365 6c66 2e70  ).        self.p
+000012e0: 6f73 6974 696f 6e5f 656d 6265 6464 696e  osition_embeddin
+000012f0: 6773 203d 206e 6e2e 456d 6265 6464 696e  gs = nn.Embeddin
+00001300: 6728 636f 6e66 6967 2e6d 6178 5f70 6f73  g(config.max_pos
+00001310: 6974 696f 6e5f 656d 6265 6464 696e 6773  ition_embeddings
+00001320: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00001330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001350: 2020 636f 6e66 6967 2e68 6964 6465 6e5f    config.hidden_
+00001360: 7369 7a65 290a 2020 2020 2020 2020 7365  size).        se
+00001370: 6c66 2e74 6f6b 656e 5f74 7970 655f 656d  lf.token_type_em
+00001380: 6265 6464 696e 6773 203d 206e 6e2e 456d  beddings = nn.Em
+00001390: 6265 6464 696e 6728 0a20 2020 2020 2020  bedding(.       
+000013a0: 2020 2020 2063 6f6e 6669 672e 7479 7065       config.type
+000013b0: 5f76 6f63 6162 5f73 697a 652c 2063 6f6e  _vocab_size, con
+000013c0: 6669 672e 6869 6464 656e 5f73 697a 652c  fig.hidden_size,
+000013d0: 2070 6164 6469 6e67 5f69 6478 3d30 290a   padding_idx=0).
+000013e0: 2020 2020 2020 2020 7365 6c66 2e72 656c          self.rel
+000013f0: 5f74 7970 655f 656d 6265 6464 696e 6773  _type_embeddings
+00001400: 203d 206e 6e2e 456d 6265 6464 696e 6728   = nn.Embedding(
+00001410: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
+00001420: 6669 672e 7265 6c5f 7479 7065 5f76 6f63  fig.rel_type_voc
+00001430: 6162 5f73 697a 652c 2063 6f6e 6669 672e  ab_size, config.
+00001440: 6869 6464 656e 5f73 697a 652c 2070 6164  hidden_size, pad
+00001450: 6469 6e67 5f69 6478 3d30 290a 2020 2020  ding_idx=0).    
+00001460: 2020 2020 7365 6c66 2e61 6273 6f6c 7574      self.absolut
+00001470: 655f 785f 656d 6265 6464 696e 6773 203d  e_x_embeddings =
+00001480: 206e 6e2e 456d 6265 6464 696e 6728 0a20   nn.Embedding(. 
+00001490: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
+000014a0: 672e 6162 736f 6c75 7465 5f78 5f76 6f63  g.absolute_x_voc
+000014b0: 6162 5f73 697a 652c 2063 6f6e 6669 672e  ab_size, config.
+000014c0: 6869 6464 656e 5f73 697a 652c 2070 6164  hidden_size, pad
+000014d0: 6469 6e67 5f69 6478 3d30 290a 2020 2020  ding_idx=0).    
+000014e0: 2020 2020 7365 6c66 2e61 6273 6f6c 7574      self.absolut
+000014f0: 655f 795f 656d 6265 6464 696e 6773 203d  e_y_embeddings =
+00001500: 206e 6e2e 456d 6265 6464 696e 6728 0a20   nn.Embedding(. 
+00001510: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
+00001520: 672e 6162 736f 6c75 7465 5f79 5f76 6f63  g.absolute_y_voc
+00001530: 6162 5f73 697a 652c 2063 6f6e 6669 672e  ab_size, config.
+00001540: 6869 6464 656e 5f73 697a 652c 2070 6164  hidden_size, pad
+00001550: 6469 6e67 5f69 6478 3d30 290a 2020 2020  ding_idx=0).    
+00001560: 2020 2020 7365 6c66 2e72 656c 6174 6976      self.relativ
+00001570: 655f 785f 656d 6265 6464 696e 6773 203d  e_x_embeddings =
+00001580: 206e 6e2e 456d 6265 6464 696e 6728 0a20   nn.Embedding(. 
+00001590: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
+000015a0: 672e 7265 6c61 7469 7665 5f78 5f76 6f63  g.relative_x_voc
+000015b0: 6162 5f73 697a 652c 2063 6f6e 6669 672e  ab_size, config.
+000015c0: 6869 6464 656e 5f73 697a 652c 2070 6164  hidden_size, pad
+000015d0: 6469 6e67 5f69 6478 3d30 290a 2020 2020  ding_idx=0).    
+000015e0: 2020 2020 7365 6c66 2e72 656c 6174 6976      self.relativ
+000015f0: 655f 795f 656d 6265 6464 696e 6773 203d  e_y_embeddings =
+00001600: 206e 6e2e 456d 6265 6464 696e 6728 0a20   nn.Embedding(. 
+00001610: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
+00001620: 672e 7265 6c61 7469 7665 5f79 5f76 6f63  g.relative_y_voc
+00001630: 6162 5f73 697a 652c 2063 6f6e 6669 672e  ab_size, config.
+00001640: 6869 6464 656e 5f73 697a 652c 2070 6164  hidden_size, pad
+00001650: 6469 6e67 5f69 6478 3d30 290a 2020 2020  ding_idx=0).    
+00001660: 2020 2020 6966 2068 6173 6174 7472 2863      if hasattr(c
+00001670: 6f6e 6669 672c 2027 7072 6f76 5f76 6f63  onfig, 'prov_voc
+00001680: 6162 5f73 697a 6527 293a 0a20 2020 2020  ab_size'):.     
+00001690: 2020 2020 2020 2073 656c 662e 7072 6f76         self.prov
+000016a0: 5f65 6d62 6564 6469 6e67 7320 3d20 6e6e  _embeddings = nn
+000016b0: 2e45 6d62 6564 6469 6e67 280a 2020 2020  .Embedding(.    
+000016c0: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+000016d0: 6967 2e70 726f 765f 766f 6361 625f 7369  ig.prov_vocab_si
+000016e0: 7a65 2c20 636f 6e66 6967 2e68 6964 6465  ze, config.hidde
+000016f0: 6e5f 7369 7a65 2c20 7061 6464 696e 675f  n_size, padding_
+00001700: 6964 783d 3029 0a20 2020 2020 2020 2020  idx=0).         
+00001710: 2020 2073 656c 662e 6369 7479 5f65 6d62     self.city_emb
+00001720: 6564 6469 6e67 7320 3d20 6e6e 2e45 6d62  eddings = nn.Emb
+00001730: 6564 6469 6e67 280a 2020 2020 2020 2020  edding(.        
+00001740: 2020 2020 2020 2020 636f 6e66 6967 2e63          config.c
+00001750: 6974 795f 766f 6361 625f 7369 7a65 2c20  ity_vocab_size, 
+00001760: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
+00001770: 7a65 2c20 7061 6464 696e 675f 6964 783d  ze, padding_idx=
+00001780: 3029 0a20 2020 2020 2020 2020 2020 2073  0).            s
+00001790: 656c 662e 6469 7374 5f65 6d62 6564 6469  elf.dist_embeddi
+000017a0: 6e67 7320 3d20 6e6e 2e45 6d62 6564 6469  ngs = nn.Embeddi
+000017b0: 6e67 280a 2020 2020 2020 2020 2020 2020  ng(.            
+000017c0: 2020 2020 636f 6e66 6967 2e64 6973 745f      config.dist_
+000017d0: 766f 6361 625f 7369 7a65 2c20 636f 6e66  vocab_size, conf
+000017e0: 6967 2e68 6964 6465 6e5f 7369 7a65 2c20  ig.hidden_size, 
+000017f0: 7061 6464 696e 675f 6964 783d 3029 0a0a  padding_idx=0)..
+00001800: 2020 2020 2020 2020 2320 7365 6c66 2e4c          # self.L
+00001810: 6179 6572 4e6f 726d 2069 7320 6e6f 7420  ayerNorm is not 
+00001820: 736e 616b 652d 6361 7365 6420 746f 2073  snake-cased to s
+00001830: 7469 636b 2077 6974 6820 5465 6e73 6f72  tick with Tensor
+00001840: 466c 6f77 206d 6f64 656c 2076 6172 6961  Flow model varia
+00001850: 626c 6520 6e61 6d65 2061 6e64 2062 6520  ble name and be 
+00001860: 6162 6c65 2074 6f20 6c6f 6164 0a20 2020  able to load.   
+00001870: 2020 2020 2023 2061 6e79 2054 656e 736f       # any Tenso
+00001880: 7246 6c6f 7720 6368 6563 6b70 6f69 6e74  rFlow checkpoint
+00001890: 2066 696c 650a 2020 2020 2020 2020 7365   file.        se
+000018a0: 6c66 2e4c 6179 6572 4e6f 726d 203d 206e  lf.LayerNorm = n
+000018b0: 6e2e 4c61 7965 724e 6f72 6d28 0a20 2020  n.LayerNorm(.   
+000018c0: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
+000018d0: 6869 6464 656e 5f73 697a 652c 2065 7073  hidden_size, eps
+000018e0: 3d63 6f6e 6669 672e 6c61 7965 725f 6e6f  =config.layer_no
+000018f0: 726d 5f65 7073 290a 2020 2020 2020 2020  rm_eps).        
+00001900: 7365 6c66 2e64 726f 706f 7574 203d 206e  self.dropout = n
+00001910: 6e2e 4472 6f70 6f75 7428 636f 6e66 6967  n.Dropout(config
+00001920: 2e68 6964 6465 6e5f 6472 6f70 6f75 745f  .hidden_dropout_
+00001930: 7072 6f62 290a 0a20 2020 2020 2020 2023  prob)..        #
+00001940: 2070 6f73 6974 696f 6e5f 6964 7320 2831   position_ids (1
+00001950: 2c20 6c65 6e20 706f 7369 7469 6f6e 2065  , len position e
+00001960: 6d62 2920 6973 2063 6f6e 7469 6775 6f75  mb) is contiguou
+00001970: 7320 696e 206d 656d 6f72 7920 616e 6420  s in memory and 
+00001980: 6578 706f 7274 6564 2077 6865 6e20 7365  exported when se
+00001990: 7269 616c 697a 6564 0a20 2020 2020 2020  rialized.       
+000019a0: 2073 656c 662e 7265 6769 7374 6572 5f62   self.register_b
+000019b0: 7566 6665 7228 0a20 2020 2020 2020 2020  uffer(.         
+000019c0: 2020 2027 706f 7369 7469 6f6e 5f69 6473     'position_ids
+000019d0: 272c 0a20 2020 2020 2020 2020 2020 2074  ',.            t
+000019e0: 6f72 6368 2e61 7261 6e67 6528 636f 6e66  orch.arange(conf
+000019f0: 6967 2e6d 6178 5f70 6f73 6974 696f 6e5f  ig.max_position_
+00001a00: 656d 6265 6464 696e 6773 292e 6578 7061  embeddings).expa
+00001a10: 6e64 2828 312c 202d 3129 2929 0a20 2020  nd((1, -1))).   
+00001a20: 2020 2020 2073 656c 662e 706f 7369 7469       self.positi
+00001a30: 6f6e 5f65 6d62 6564 6469 6e67 5f74 7970  on_embedding_typ
+00001a40: 6520 3d20 6765 7461 7474 7228 636f 6e66  e = getattr(conf
+00001a50: 6967 2c0a 2020 2020 2020 2020 2020 2020  ig,.            
+00001a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001a80: 2020 2027 706f 7369 7469 6f6e 5f65 6d62     'position_emb
+00001a90: 6564 6469 6e67 5f74 7970 6527 2c0a 2020  edding_type',.  
+00001aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001ac0: 2020 2020 2020 2020 2020 2020 2027 6162               'ab
+00001ad0: 736f 6c75 7465 2729 0a0a 2020 2020 2020  solute')..      
+00001ae0: 2020 7365 6c66 2e63 6f6e 6669 6720 3d20    self.config = 
+00001af0: 636f 6e66 6967 0a0a 2020 2020 6465 6620  config..    def 
+00001b00: 666f 7277 6172 6428 7365 6c66 2c0a 2020  forward(self,.  
+00001b10: 2020 2020 2020 2020 2020 2020 2020 696e                in
+00001b20: 7075 745f 6964 733d 4e6f 6e65 2c0a 2020  put_ids=None,.  
+00001b30: 2020 2020 2020 2020 2020 2020 2020 746f                to
+00001b40: 6b65 6e5f 7479 7065 5f69 6473 3d4e 6f6e  ken_type_ids=Non
+00001b50: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00001b60: 2020 2070 6f73 6974 696f 6e5f 6964 733d     position_ids=
+00001b70: 4e6f 6e65 2c0a 2020 2020 2020 2020 2020  None,.          
+00001b80: 2020 2020 2020 696e 7075 7473 5f65 6d62        inputs_emb
+00001b90: 6564 733d 4e6f 6e65 2c0a 2020 2020 2020  eds=None,.      
+00001ba0: 2020 2020 2020 2020 2020 7061 7374 5f6b            past_k
+00001bb0: 6579 5f76 616c 7565 735f 6c65 6e67 7468  ey_values_length
+00001bc0: 3d30 2c0a 2020 2020 2020 2020 2020 2020  =0,.            
+00001bd0: 2020 2020 7265 6c5f 7479 7065 5f69 6473      rel_type_ids
+00001be0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2020  =None,.         
+00001bf0: 2020 2020 2020 2061 6273 6f6c 7574 655f         absolute_
+00001c00: 706f 7369 7469 6f6e 5f69 6473 3d4e 6f6e  position_ids=Non
+00001c10: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00001c20: 2020 2072 656c 6174 6976 655f 706f 7369     relative_posi
+00001c30: 7469 6f6e 5f69 6473 3d4e 6f6e 652c 0a20  tion_ids=None,. 
+00001c40: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00001c50: 726f 765f 6964 733d 4e6f 6e65 2c0a 2020  rov_ids=None,.  
+00001c60: 2020 2020 2020 2020 2020 2020 2020 6369                ci
+00001c70: 7479 5f69 6473 3d4e 6f6e 652c 0a20 2020  ty_ids=None,.   
+00001c80: 2020 2020 2020 2020 2020 2020 2064 6973               dis
+00001c90: 745f 6964 733d 4e6f 6e65 293a 0a20 2020  t_ids=None):.   
+00001ca0: 2020 2020 2069 6620 696e 7075 745f 6964       if input_id
+00001cb0: 7320 6973 206e 6f74 204e 6f6e 653a 0a20  s is not None:. 
+00001cc0: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00001cd0: 5f73 6861 7065 203d 2069 6e70 7574 5f69  _shape = input_i
+00001ce0: 6473 2e73 697a 6528 290a 2020 2020 2020  ds.size().      
+00001cf0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00001d00: 2020 2020 696e 7075 745f 7368 6170 6520      input_shape 
+00001d10: 3d20 696e 7075 7473 5f65 6d62 6564 732e  = inputs_embeds.
+00001d20: 7369 7a65 2829 5b3a 2d31 5d0a 0a20 2020  size()[:-1]..   
+00001d30: 2020 2020 2073 6571 5f6c 656e 6774 6820       seq_length 
+00001d40: 3d20 696e 7075 745f 7368 6170 655b 315d  = input_shape[1]
+00001d50: 0a0a 2020 2020 2020 2020 6966 2070 6f73  ..        if pos
+00001d60: 6974 696f 6e5f 6964 7320 6973 204e 6f6e  ition_ids is Non
+00001d70: 653a 0a20 2020 2020 2020 2020 2020 2070  e:.            p
+00001d80: 6f73 6974 696f 6e5f 6964 7320 3d20 7365  osition_ids = se
+00001d90: 6c66 2e70 6f73 6974 696f 6e5f 6964 735b  lf.position_ids[
+00001da0: 3a2c 0a20 2020 2020 2020 2020 2020 2020  :,.             
+00001db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001dd0: 7061 7374 5f6b 6579 5f76 616c 7565 735f  past_key_values_
+00001de0: 6c65 6e67 7468 3a73 6571 5f6c 656e 6774  length:seq_lengt
+00001df0: 680a 2020 2020 2020 2020 2020 2020 2020  h.              
+00001e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001e10: 2020 2020 2020 2020 2020 2020 2020 202b                 +
+00001e20: 2070 6173 745f 6b65 795f 7661 6c75 6573   past_key_values
+00001e30: 5f6c 656e 6774 685d 0a0a 2020 2020 2020  _length]..      
+00001e40: 2020 6966 2074 6f6b 656e 5f74 7970 655f    if token_type_
+00001e50: 6964 7320 6973 204e 6f6e 653a 0a20 2020  ids is None:.   
+00001e60: 2020 2020 2020 2020 2074 6f6b 656e 5f74           token_t
+00001e70: 7970 655f 6964 7320 3d20 746f 7263 682e  ype_ids = torch.
+00001e80: 7a65 726f 7328 0a20 2020 2020 2020 2020  zeros(.         
+00001e90: 2020 2020 2020 2069 6e70 7574 5f73 6861         input_sha
+00001ea0: 7065 2c20 6474 7970 653d 746f 7263 682e  pe, dtype=torch.
+00001eb0: 6c6f 6e67 2c20 6465 7669 6365 3d73 656c  long, device=sel
+00001ec0: 662e 706f 7369 7469 6f6e 5f69 6473 2e64  f.position_ids.d
+00001ed0: 6576 6963 6529 0a0a 2020 2020 2020 2020  evice)..        
+00001ee0: 6966 2069 6e70 7574 735f 656d 6265 6473  if inputs_embeds
+00001ef0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00001f00: 2020 2020 2020 696e 7075 7473 5f65 6d62        inputs_emb
+00001f10: 6564 7320 3d20 7365 6c66 2e77 6f72 645f  eds = self.word_
+00001f20: 656d 6265 6464 696e 6773 2869 6e70 7574  embeddings(input
+00001f30: 5f69 6473 290a 0a20 2020 2020 2020 2074  _ids)..        t
+00001f40: 6f6b 656e 5f74 7970 655f 656d 6265 6464  oken_type_embedd
+00001f50: 696e 6773 203d 2073 656c 662e 746f 6b65  ings = self.toke
+00001f60: 6e5f 7479 7065 5f65 6d62 6564 6469 6e67  n_type_embedding
+00001f70: 7328 746f 6b65 6e5f 7479 7065 5f69 6473  s(token_type_ids
+00001f80: 290a 0a20 2020 2020 2020 2065 6d62 6564  )..        embed
+00001f90: 6469 6e67 7320 3d20 696e 7075 7473 5f65  dings = inputs_e
+00001fa0: 6d62 6564 7320 2b20 746f 6b65 6e5f 7479  mbeds + token_ty
+00001fb0: 7065 5f65 6d62 6564 6469 6e67 730a 2020  pe_embeddings.  
+00001fc0: 2020 2020 2020 6966 2073 656c 662e 706f        if self.po
+00001fd0: 7369 7469 6f6e 5f65 6d62 6564 6469 6e67  sition_embedding
+00001fe0: 5f74 7970 6520 3d3d 2027 6162 736f 6c75  _type == 'absolu
+00001ff0: 7465 273a 0a20 2020 2020 2020 2020 2020  te':.           
+00002000: 2070 6f73 6974 696f 6e5f 656d 6265 6464   position_embedd
+00002010: 696e 6773 203d 2073 656c 662e 706f 7369  ings = self.posi
+00002020: 7469 6f6e 5f65 6d62 6564 6469 6e67 7328  tion_embeddings(
+00002030: 706f 7369 7469 6f6e 5f69 6473 290a 2020  position_ids).  
+00002040: 2020 2020 2020 2020 2020 656d 6265 6464            embedd
+00002050: 696e 6773 202b 3d20 706f 7369 7469 6f6e  ings += position
+00002060: 5f65 6d62 6564 6469 6e67 730a 2020 2020  _embeddings.    
+00002070: 2020 2020 656d 6265 6464 696e 6773 202b      embeddings +
+00002080: 3d20 7365 6c66 2e72 656c 5f74 7970 655f  = self.rel_type_
+00002090: 656d 6265 6464 696e 6773 2872 656c 5f74  embeddings(rel_t
+000020a0: 7970 655f 6964 7329 0a20 2020 2020 2020  ype_ids).       
+000020b0: 2065 6d62 6564 6469 6e67 7320 2b3d 2073   embeddings += s
+000020c0: 656c 662e 6162 736f 6c75 7465 5f78 5f65  elf.absolute_x_e
+000020d0: 6d62 6564 6469 6e67 7328 6162 736f 6c75  mbeddings(absolu
+000020e0: 7465 5f70 6f73 6974 696f 6e5f 6964 735b  te_position_ids[
+000020f0: 3a2c 203a 2c0a 2020 2020 2020 2020 2020  :, :,.          
+00002100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002130: 2020 2020 2020 2020 2020 2020 2030 5d29               0])
+00002140: 0a20 2020 2020 2020 2065 6d62 6564 6469  .        embeddi
+00002150: 6e67 7320 2b3d 2073 656c 662e 6162 736f  ngs += self.abso
+00002160: 6c75 7465 5f79 5f65 6d62 6564 6469 6e67  lute_y_embedding
+00002170: 7328 6162 736f 6c75 7465 5f70 6f73 6974  s(absolute_posit
+00002180: 696f 6e5f 6964 735b 3a2c 203a 2c0a 2020  ion_ids[:, :,.  
+00002190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000021a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000021b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000021c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000021d0: 2020 2020 2031 5d29 0a20 2020 2020 2020       1]).       
+000021e0: 2065 6d62 6564 6469 6e67 7320 2b3d 2073   embeddings += s
+000021f0: 656c 662e 6162 736f 6c75 7465 5f78 5f65  elf.absolute_x_e
+00002200: 6d62 6564 6469 6e67 7328 6162 736f 6c75  mbeddings(absolu
+00002210: 7465 5f70 6f73 6974 696f 6e5f 6964 735b  te_position_ids[
+00002220: 3a2c 203a 2c0a 2020 2020 2020 2020 2020  :, :,.          
 00002230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002240: 2020 2020 305d 290a 2020 2020 2020 2020      0]).        
-00002250: 656d 6265 6464 696e 6773 202b 3d20 7365  embeddings += se
-00002260: 6c66 2e61 6273 6f6c 7574 655f 795f 656d  lf.absolute_y_em
-00002270: 6265 6464 696e 6773 2861 6273 6f6c 7574  beddings(absolut
-00002280: 655f 706f 7369 7469 6f6e 5f69 6473 5b3a  e_position_ids[:
-00002290: 2c20 3a2c 0a20 2020 2020 2020 2020 2020  , :,.           
-000022a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000022b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002260: 2020 2020 2020 2020 2020 2020 2032 5d29               2])
+00002270: 0a20 2020 2020 2020 2065 6d62 6564 6469  .        embeddi
+00002280: 6e67 7320 2b3d 2073 656c 662e 6162 736f  ngs += self.abso
+00002290: 6c75 7465 5f79 5f65 6d62 6564 6469 6e67  lute_y_embedding
+000022a0: 7328 6162 736f 6c75 7465 5f70 6f73 6974  s(absolute_posit
+000022b0: 696f 6e5f 6964 735b 3a2c 203a 2c0a 2020  ion_ids[:, :,.  
 000022c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000022d0: 2020 2020 2020 2020 2020 2020 315d 290a              1]).
-000022e0: 2020 2020 2020 2020 656d 6265 6464 696e          embeddin
-000022f0: 6773 202b 3d20 7365 6c66 2e61 6273 6f6c  gs += self.absol
-00002300: 7574 655f 785f 656d 6265 6464 696e 6773  ute_x_embeddings
-00002310: 2861 6273 6f6c 7574 655f 706f 7369 7469  (absolute_positi
-00002320: 6f6e 5f69 6473 5b3a 2c20 3a2c 0a20 2020  on_ids[:, :,.   
-00002330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000022d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000022e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000022f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002300: 2020 2020 2033 5d29 0a20 2020 2020 2020       3]).       
+00002310: 2065 6d62 6564 6469 6e67 7320 2b3d 2073   embeddings += s
+00002320: 656c 662e 7265 6c61 7469 7665 5f78 5f65  elf.relative_x_e
+00002330: 6d62 6564 6469 6e67 7328 7265 6c61 7469  mbeddings(relati
+00002340: 7665 5f70 6f73 6974 696f 6e5f 6964 735b  ve_position_ids[
+00002350: 3a2c 203a 2c0a 2020 2020 2020 2020 2020  :, :,.          
 00002360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002370: 2020 2020 325d 290a 2020 2020 2020 2020      2]).        
-00002380: 656d 6265 6464 696e 6773 202b 3d20 7365  embeddings += se
-00002390: 6c66 2e61 6273 6f6c 7574 655f 795f 656d  lf.absolute_y_em
-000023a0: 6265 6464 696e 6773 2861 6273 6f6c 7574  beddings(absolut
-000023b0: 655f 706f 7369 7469 6f6e 5f69 6473 5b3a  e_position_ids[:
-000023c0: 2c20 3a2c 0a20 2020 2020 2020 2020 2020  , :,.           
-000023d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000023e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002390: 2020 2020 2020 2020 2020 2020 2030 5d29               0])
+000023a0: 0a20 2020 2020 2020 2065 6d62 6564 6469  .        embeddi
+000023b0: 6e67 7320 2b3d 2073 656c 662e 7265 6c61  ngs += self.rela
+000023c0: 7469 7665 5f79 5f65 6d62 6564 6469 6e67  tive_y_embedding
+000023d0: 7328 7265 6c61 7469 7665 5f70 6f73 6974  s(relative_posit
+000023e0: 696f 6e5f 6964 735b 3a2c 203a 2c0a 2020  ion_ids[:, :,.  
 000023f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002400: 2020 2020 2020 2020 2020 2020 335d 290a              3]).
-00002410: 2020 2020 2020 2020 656d 6265 6464 696e          embeddin
-00002420: 6773 202b 3d20 7365 6c66 2e72 656c 6174  gs += self.relat
-00002430: 6976 655f 785f 656d 6265 6464 696e 6773  ive_x_embeddings
-00002440: 2872 656c 6174 6976 655f 706f 7369 7469  (relative_positi
-00002450: 6f6e 5f69 6473 5b3a 2c20 3a2c 0a20 2020  on_ids[:, :,.   
-00002460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002430: 2020 2020 2031 5d29 0a20 2020 2020 2020       1]).       
+00002440: 2065 6d62 6564 6469 6e67 7320 2b3d 2073   embeddings += s
+00002450: 656c 662e 7265 6c61 7469 7665 5f78 5f65  elf.relative_x_e
+00002460: 6d62 6564 6469 6e67 7328 7265 6c61 7469  mbeddings(relati
+00002470: 7665 5f70 6f73 6974 696f 6e5f 6964 735b  ve_position_ids[
+00002480: 3a2c 203a 2c0a 2020 2020 2020 2020 2020  :, :,.          
 00002490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000024a0: 2020 2020 305d 290a 2020 2020 2020 2020      0]).        
-000024b0: 656d 6265 6464 696e 6773 202b 3d20 7365  embeddings += se
-000024c0: 6c66 2e72 656c 6174 6976 655f 795f 656d  lf.relative_y_em
-000024d0: 6265 6464 696e 6773 2872 656c 6174 6976  beddings(relativ
-000024e0: 655f 706f 7369 7469 6f6e 5f69 6473 5b3a  e_position_ids[:
-000024f0: 2c20 3a2c 0a20 2020 2020 2020 2020 2020  , :,.           
-00002500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000024a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000024b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000024c0: 2020 2020 2020 2020 2020 2020 2032 5d29               2])
+000024d0: 0a20 2020 2020 2020 2065 6d62 6564 6469  .        embeddi
+000024e0: 6e67 7320 2b3d 2073 656c 662e 7265 6c61  ngs += self.rela
+000024f0: 7469 7665 5f79 5f65 6d62 6564 6469 6e67  tive_y_embedding
+00002500: 7328 7265 6c61 7469 7665 5f70 6f73 6974  s(relative_posit
+00002510: 696f 6e5f 6964 735b 3a2c 203a 2c0a 2020  ion_ids[:, :,.  
 00002520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002530: 2020 2020 2020 2020 2020 2020 315d 290a              1]).
-00002540: 2020 2020 2020 2020 656d 6265 6464 696e          embeddin
-00002550: 6773 202b 3d20 7365 6c66 2e72 656c 6174  gs += self.relat
-00002560: 6976 655f 785f 656d 6265 6464 696e 6773  ive_x_embeddings
-00002570: 2872 656c 6174 6976 655f 706f 7369 7469  (relative_positi
-00002580: 6f6e 5f69 6473 5b3a 2c20 3a2c 0a20 2020  on_ids[:, :,.   
-00002590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000025a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000025b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000025c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000025d0: 2020 2020 325d 290a 2020 2020 2020 2020      2]).        
-000025e0: 656d 6265 6464 696e 6773 202b 3d20 7365  embeddings += se
-000025f0: 6c66 2e72 656c 6174 6976 655f 795f 656d  lf.relative_y_em
-00002600: 6265 6464 696e 6773 2872 656c 6174 6976  beddings(relativ
-00002610: 655f 706f 7369 7469 6f6e 5f69 6473 5b3a  e_position_ids[:
-00002620: 2c20 3a2c 0a20 2020 2020 2020 2020 2020  , :,.           
-00002630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002660: 2020 2020 2020 2020 2020 2020 335d 290a              3]).
-00002670: 2020 2020 2020 2020 6966 2070 726f 765f          if prov_
-00002680: 6964 7320 6973 206e 6f74 204e 6f6e 653a  ids is not None:
-00002690: 0a20 2020 2020 2020 2020 2020 2065 6d62  .            emb
-000026a0: 6564 6469 6e67 7320 2b3d 2073 656c 662e  eddings += self.
-000026b0: 7072 6f76 5f65 6d62 6564 6469 6e67 7328  prov_embeddings(
-000026c0: 7072 6f76 5f69 6473 290a 2020 2020 2020  prov_ids).      
-000026d0: 2020 2020 2020 656d 6265 6464 696e 6773        embeddings
-000026e0: 202b 3d20 7365 6c66 2e63 6974 795f 656d   += self.city_em
-000026f0: 6265 6464 696e 6773 2863 6974 795f 6964  beddings(city_id
-00002700: 7329 0a20 2020 2020 2020 2020 2020 2065  s).            e
-00002710: 6d62 6564 6469 6e67 7320 2b3d 2073 656c  mbeddings += sel
-00002720: 662e 6469 7374 5f65 6d62 6564 6469 6e67  f.dist_embedding
-00002730: 7328 6469 7374 5f69 6473 290a 0a20 2020  s(dist_ids)..   
-00002740: 2020 2020 2065 6d62 6564 6469 6e67 7320       embeddings 
-00002750: 3d20 7365 6c66 2e4c 6179 6572 4e6f 726d  = self.LayerNorm
-00002760: 2865 6d62 6564 6469 6e67 7329 0a20 2020  (embeddings).   
-00002770: 2020 2020 2065 6d62 6564 6469 6e67 7320       embeddings 
-00002780: 3d20 7365 6c66 2e64 726f 706f 7574 2865  = self.dropout(e
-00002790: 6d62 6564 6469 6e67 7329 0a20 2020 2020  mbeddings).     
-000027a0: 2020 2072 6574 7572 6e20 656d 6265 6464     return embedd
-000027b0: 696e 6773 0a0a 0a63 6c61 7373 2042 6572  ings...class Ber
-000027c0: 7445 6d62 6564 6469 6e67 7328 6e6e 2e4d  tEmbeddings(nn.M
-000027d0: 6f64 756c 6529 3a0a 2020 2020 2222 2243  odule):.    """C
-000027e0: 6f6e 7374 7275 6374 2074 6865 2065 6d62  onstruct the emb
-000027f0: 6564 6469 6e67 7320 6672 6f6d 2077 6f72  eddings from wor
-00002800: 642c 2070 6f73 6974 696f 6e20 616e 6420  d, position and 
-00002810: 746f 6b65 6e5f 7479 7065 0a20 2020 2065  token_type.    e
-00002820: 6d62 6564 6469 6e67 732e 2222 220a 0a20  mbeddings.""".. 
-00002830: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00002840: 7365 6c66 2c20 636f 6e66 6967 293a 0a20  self, config):. 
-00002850: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-00002860: 5f69 6e69 745f 5f28 290a 2020 2020 2020  _init__().      
-00002870: 2020 7365 6c66 2e77 6f72 645f 656d 6265    self.word_embe
-00002880: 6464 696e 6773 203d 206e 6e2e 456d 6265  ddings = nn.Embe
-00002890: 6464 696e 6728 0a20 2020 2020 2020 2020  dding(.         
-000028a0: 2020 2063 6f6e 6669 672e 766f 6361 625f     config.vocab_
-000028b0: 7369 7a65 2c0a 2020 2020 2020 2020 2020  size,.          
-000028c0: 2020 636f 6e66 6967 2e68 6964 6465 6e5f    config.hidden_
-000028d0: 7369 7a65 2c0a 2020 2020 2020 2020 2020  size,.          
-000028e0: 2020 7061 6464 696e 675f 6964 783d 636f    padding_idx=co
-000028f0: 6e66 6967 2e70 6164 5f74 6f6b 656e 5f69  nfig.pad_token_i
-00002900: 6429 0a20 2020 2020 2020 2073 656c 662e  d).        self.
-00002910: 706f 7369 7469 6f6e 5f65 6d62 6564 6469  position_embeddi
-00002920: 6e67 7320 3d20 6e6e 2e45 6d62 6564 6469  ngs = nn.Embeddi
-00002930: 6e67 2863 6f6e 6669 672e 6d61 785f 706f  ng(config.max_po
-00002940: 7369 7469 6f6e 5f65 6d62 6564 6469 6e67  sition_embedding
-00002950: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
-00002960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002980: 2020 2063 6f6e 6669 672e 6869 6464 656e     config.hidden
-00002990: 5f73 697a 6529 0a20 2020 2020 2020 2073  _size).        s
-000029a0: 656c 662e 746f 6b65 6e5f 7479 7065 5f65  elf.token_type_e
-000029b0: 6d62 6564 6469 6e67 7320 3d20 6e6e 2e45  mbeddings = nn.E
-000029c0: 6d62 6564 6469 6e67 2863 6f6e 6669 672e  mbedding(config.
-000029d0: 7479 7065 5f76 6f63 6162 5f73 697a 652c  type_vocab_size,
-000029e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000029f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a10: 2020 2063 6f6e 6669 672e 6869 6464 656e     config.hidden
-00002a20: 5f73 697a 6529 0a0a 2020 2020 2020 2020  _size)..        
-00002a30: 2320 7365 6c66 2e4c 6179 6572 4e6f 726d  # self.LayerNorm
-00002a40: 2069 7320 6e6f 7420 736e 616b 652d 6361   is not snake-ca
-00002a50: 7365 6420 746f 2073 7469 636b 2077 6974  sed to stick wit
-00002a60: 6820 5465 6e73 6f72 466c 6f77 206d 6f64  h TensorFlow mod
-00002a70: 656c 2076 6172 6961 626c 6520 6e61 6d65  el variable name
-00002a80: 2061 6e64 2062 6520 6162 6c65 2074 6f20   and be able to 
-00002a90: 6c6f 6164 0a20 2020 2020 2020 2023 2061  load.        # a
-00002aa0: 6e79 2054 656e 736f 7246 6c6f 7720 6368  ny TensorFlow ch
-00002ab0: 6563 6b70 6f69 6e74 2066 696c 650a 2020  eckpoint file.  
-00002ac0: 2020 2020 2020 7365 6c66 2e4c 6179 6572        self.Layer
-00002ad0: 4e6f 726d 203d 206e 6e2e 4c61 7965 724e  Norm = nn.LayerN
-00002ae0: 6f72 6d28 0a20 2020 2020 2020 2020 2020  orm(.           
-00002af0: 2063 6f6e 6669 672e 6869 6464 656e 5f73   config.hidden_s
-00002b00: 697a 652c 2065 7073 3d63 6f6e 6669 672e  ize, eps=config.
-00002b10: 6c61 7965 725f 6e6f 726d 5f65 7073 290a  layer_norm_eps).
-00002b20: 2020 2020 2020 2020 7365 6c66 2e64 726f          self.dro
-00002b30: 706f 7574 203d 206e 6e2e 4472 6f70 6f75  pout = nn.Dropou
-00002b40: 7428 636f 6e66 6967 2e68 6964 6465 6e5f  t(config.hidden_
-00002b50: 6472 6f70 6f75 745f 7072 6f62 290a 0a20  dropout_prob).. 
-00002b60: 2020 2020 2020 2023 2070 6f73 6974 696f         # positio
-00002b70: 6e5f 6964 7320 2831 2c20 6c65 6e20 706f  n_ids (1, len po
-00002b80: 7369 7469 6f6e 2065 6d62 2920 6973 2063  sition emb) is c
-00002b90: 6f6e 7469 6775 6f75 7320 696e 206d 656d  ontiguous in mem
-00002ba0: 6f72 7920 616e 6420 6578 706f 7274 6564  ory and exported
-00002bb0: 2077 6865 6e20 7365 7269 616c 697a 6564   when serialized
-00002bc0: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
-00002bd0: 6769 7374 6572 5f62 7566 6665 7228 0a20  gister_buffer(. 
-00002be0: 2020 2020 2020 2020 2020 2027 706f 7369             'posi
-00002bf0: 7469 6f6e 5f69 6473 272c 0a20 2020 2020  tion_ids',.     
-00002c00: 2020 2020 2020 2074 6f72 6368 2e61 7261         torch.ara
-00002c10: 6e67 6528 636f 6e66 6967 2e6d 6178 5f70  nge(config.max_p
-00002c20: 6f73 6974 696f 6e5f 656d 6265 6464 696e  osition_embeddin
-00002c30: 6773 292e 6578 7061 6e64 2828 312c 202d  gs).expand((1, -
-00002c40: 3129 2929 0a20 2020 2020 2020 2073 656c  1))).        sel
-00002c50: 662e 706f 7369 7469 6f6e 5f65 6d62 6564  f.position_embed
-00002c60: 6469 6e67 5f74 7970 6520 3d20 6765 7461  ding_type = geta
-00002c70: 7474 7228 636f 6e66 6967 2c0a 2020 2020  ttr(config,.    
-00002c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ca0: 2020 2020 2020 2020 2020 2027 706f 7369             'posi
-00002cb0: 7469 6f6e 5f65 6d62 6564 6469 6e67 5f74  tion_embedding_t
-00002cc0: 7970 6527 2c0a 2020 2020 2020 2020 2020  ype',.          
-00002cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002cf0: 2020 2020 2027 6162 736f 6c75 7465 2729       'absolute')
-00002d00: 0a0a 2020 2020 2020 2020 7365 6c66 2e63  ..        self.c
-00002d10: 6f6e 6669 6720 3d20 636f 6e66 6967 0a0a  onfig = config..
-00002d20: 2020 2020 6465 6620 666f 7277 6172 6428      def forward(
-00002d30: 7365 6c66 2c0a 2020 2020 2020 2020 2020  self,.          
-00002d40: 2020 2020 2020 696e 7075 745f 6964 733d        input_ids=
-00002d50: 4e6f 6e65 2c0a 2020 2020 2020 2020 2020  None,.          
-00002d60: 2020 2020 2020 746f 6b65 6e5f 7479 7065        token_type
-00002d70: 5f69 6473 3d4e 6f6e 652c 0a20 2020 2020  _ids=None,.     
-00002d80: 2020 2020 2020 2020 2020 2070 6f73 6974             posit
-00002d90: 696f 6e5f 6964 733d 4e6f 6e65 2c0a 2020  ion_ids=None,.  
-00002da0: 2020 2020 2020 2020 2020 2020 2020 696e                in
-00002db0: 7075 7473 5f65 6d62 6564 733d 4e6f 6e65  puts_embeds=None
-00002dc0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00002dd0: 2020 7061 7374 5f6b 6579 5f76 616c 7565    past_key_value
-00002de0: 735f 6c65 6e67 7468 3d30 2c0a 2020 2020  s_length=0,.    
-00002df0: 2020 2020 2020 2020 2020 2020 7265 6c5f              rel_
-00002e00: 7479 7065 5f69 6473 3d4e 6f6e 652c 0a20  type_ids=None,. 
-00002e10: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-00002e20: 6273 6f6c 7574 655f 706f 7369 7469 6f6e  bsolute_position
-00002e30: 5f69 6473 3d4e 6f6e 652c 0a20 2020 2020  _ids=None,.     
-00002e40: 2020 2020 2020 2020 2020 2072 656c 6174             relat
-00002e50: 6976 655f 706f 7369 7469 6f6e 5f69 6473  ive_position_ids
-00002e60: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
-00002e70: 6966 2069 6e70 7574 5f69 6473 2069 7320  if input_ids is 
-00002e80: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-00002e90: 2020 2020 2020 696e 7075 745f 7368 6170        input_shap
-00002ea0: 6520 3d20 696e 7075 745f 6964 732e 7369  e = input_ids.si
-00002eb0: 7a65 2829 0a20 2020 2020 2020 2065 6c73  ze().        els
-00002ec0: 653a 0a20 2020 2020 2020 2020 2020 2069  e:.            i
-00002ed0: 6e70 7574 5f73 6861 7065 203d 2069 6e70  nput_shape = inp
-00002ee0: 7574 735f 656d 6265 6473 2e73 697a 6528  uts_embeds.size(
-00002ef0: 295b 3a2d 315d 0a0a 2020 2020 2020 2020  )[:-1]..        
-00002f00: 7365 715f 6c65 6e67 7468 203d 2069 6e70  seq_length = inp
-00002f10: 7574 5f73 6861 7065 5b31 5d0a 0a20 2020  ut_shape[1]..   
-00002f20: 2020 2020 2069 6620 706f 7369 7469 6f6e       if position
-00002f30: 5f69 6473 2069 7320 4e6f 6e65 3a0a 2020  _ids is None:.  
-00002f40: 2020 2020 2020 2020 2020 706f 7369 7469            positi
-00002f50: 6f6e 5f69 6473 203d 2073 656c 662e 706f  on_ids = self.po
-00002f60: 7369 7469 6f6e 5f69 6473 5b3a 2c0a 2020  sition_ids[:,.  
-00002f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f90: 2020 2020 2020 2020 2020 2070 6173 745f             past_
-00002fa0: 6b65 795f 7661 6c75 6573 5f6c 656e 6774  key_values_lengt
-00002fb0: 683a 7365 715f 6c65 6e67 7468 0a20 2020  h:seq_length.   
-00002fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002fe0: 2020 2020 2020 2020 2020 2b20 7061 7374            + past
-00002ff0: 5f6b 6579 5f76 616c 7565 735f 6c65 6e67  _key_values_leng
-00003000: 7468 5d0a 0a20 2020 2020 2020 2069 6620  th]..        if 
-00003010: 746f 6b65 6e5f 7479 7065 5f69 6473 2069  token_type_ids i
-00003020: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-00003030: 2020 2020 746f 6b65 6e5f 7479 7065 5f69      token_type_i
-00003040: 6473 203d 2074 6f72 6368 2e7a 6572 6f73  ds = torch.zeros
-00003050: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00003060: 2020 696e 7075 745f 7368 6170 652c 2064    input_shape, d
-00003070: 7479 7065 3d74 6f72 6368 2e6c 6f6e 672c  type=torch.long,
-00003080: 2064 6576 6963 653d 7365 6c66 2e70 6f73   device=self.pos
-00003090: 6974 696f 6e5f 6964 732e 6465 7669 6365  ition_ids.device
-000030a0: 290a 0a20 2020 2020 2020 2069 6620 696e  )..        if in
-000030b0: 7075 7473 5f65 6d62 6564 7320 6973 204e  puts_embeds is N
-000030c0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-000030d0: 2069 6e70 7574 735f 656d 6265 6473 203d   inputs_embeds =
-000030e0: 2073 656c 662e 776f 7264 5f65 6d62 6564   self.word_embed
-000030f0: 6469 6e67 7328 696e 7075 745f 6964 7329  dings(input_ids)
-00003100: 0a0a 2020 2020 2020 2020 746f 6b65 6e5f  ..        token_
-00003110: 7479 7065 5f65 6d62 6564 6469 6e67 7320  type_embeddings 
-00003120: 3d20 7365 6c66 2e74 6f6b 656e 5f74 7970  = self.token_typ
-00003130: 655f 656d 6265 6464 696e 6773 2874 6f6b  e_embeddings(tok
-00003140: 656e 5f74 7970 655f 6964 7329 0a0a 2020  en_type_ids)..  
-00003150: 2020 2020 2020 656d 6265 6464 696e 6773        embeddings
-00003160: 203d 2069 6e70 7574 735f 656d 6265 6473   = inputs_embeds
-00003170: 202b 2074 6f6b 656e 5f74 7970 655f 656d   + token_type_em
-00003180: 6265 6464 696e 6773 0a20 2020 2020 2020  beddings.       
-00003190: 2069 6620 7365 6c66 2e70 6f73 6974 696f   if self.positio
-000031a0: 6e5f 656d 6265 6464 696e 675f 7479 7065  n_embedding_type
-000031b0: 203d 3d20 2761 6273 6f6c 7574 6527 3a0a   == 'absolute':.
-000031c0: 2020 2020 2020 2020 2020 2020 706f 7369              posi
-000031d0: 7469 6f6e 5f65 6d62 6564 6469 6e67 7320  tion_embeddings 
-000031e0: 3d20 7365 6c66 2e70 6f73 6974 696f 6e5f  = self.position_
-000031f0: 656d 6265 6464 696e 6773 2870 6f73 6974  embeddings(posit
-00003200: 696f 6e5f 6964 7329 0a20 2020 2020 2020  ion_ids).       
-00003210: 2020 2020 2065 6d62 6564 6469 6e67 7320       embeddings 
-00003220: 2b3d 2070 6f73 6974 696f 6e5f 656d 6265  += position_embe
-00003230: 6464 696e 6773 0a20 2020 2020 2020 2065  ddings.        e
-00003240: 6d62 6564 6469 6e67 7320 3d20 7365 6c66  mbeddings = self
-00003250: 2e4c 6179 6572 4e6f 726d 2865 6d62 6564  .LayerNorm(embed
-00003260: 6469 6e67 7329 0a20 2020 2020 2020 2065  dings).        e
-00003270: 6d62 6564 6469 6e67 7320 3d20 7365 6c66  mbeddings = self
-00003280: 2e64 726f 706f 7574 2865 6d62 6564 6469  .dropout(embeddi
-00003290: 6e67 7329 0a20 2020 2020 2020 2072 6574  ngs).        ret
-000032a0: 7572 6e20 656d 6265 6464 696e 6773 0a0a  urn embeddings..
-000032b0: 0a63 6c61 7373 2042 6572 7453 656c 6641  .class BertSelfA
-000032c0: 7474 656e 7469 6f6e 286e 6e2e 4d6f 6475  ttention(nn.Modu
-000032d0: 6c65 293a 0a0a 2020 2020 6465 6620 5f5f  le):..    def __
-000032e0: 696e 6974 5f5f 2873 656c 662c 2063 6f6e  init__(self, con
-000032f0: 6669 672c 2069 735f 6372 6f73 735f 6174  fig, is_cross_at
-00003300: 7465 6e74 696f 6e29 3a0a 2020 2020 2020  tention):.      
-00003310: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
-00003320: 5f5f 2829 0a20 2020 2020 2020 2073 656c  __().        sel
-00003330: 662e 636f 6e66 6967 203d 2063 6f6e 6669  f.config = confi
-00003340: 670a 2020 2020 2020 2020 6966 2063 6f6e  g.        if con
-00003350: 6669 672e 6869 6464 656e 5f73 697a 6520  fig.hidden_size 
-00003360: 2520 636f 6e66 6967 2e6e 756d 5f61 7474  % config.num_att
-00003370: 656e 7469 6f6e 5f68 6561 6473 2021 3d20  ention_heads != 
-00003380: 3020 616e 6420 6e6f 7420 6861 7361 7474  0 and not hasatt
-00003390: 7228 0a20 2020 2020 2020 2020 2020 2020  r(.             
-000033a0: 2020 2063 6f6e 6669 672c 2027 656d 6265     config, 'embe
-000033b0: 6464 696e 675f 7369 7a65 2729 3a0a 2020  dding_size'):.  
-000033c0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-000033d0: 5661 6c75 6545 7272 6f72 280a 2020 2020  ValueError(.    
-000033e0: 2020 2020 2020 2020 2020 2020 2754 6865              'The
-000033f0: 2068 6964 6465 6e20 7369 7a65 2028 2564   hidden size (%d
-00003400: 2920 6973 206e 6f74 2061 206d 756c 7469  ) is not a multi
-00003410: 706c 6520 6f66 2074 6865 206e 756d 6265  ple of the numbe
-00003420: 7220 6f66 2061 7474 656e 7469 6f6e 2027  r of attention '
-00003430: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003440: 2027 6865 6164 7320 2825 6429 2720 250a   'heads (%d)' %.
-00003450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003460: 2863 6f6e 6669 672e 6869 6464 656e 5f73  (config.hidden_s
-00003470: 697a 652c 2063 6f6e 6669 672e 6e75 6d5f  ize, config.num_
-00003480: 6174 7465 6e74 696f 6e5f 6865 6164 7329  attention_heads)
-00003490: 290a 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-000034a0: 6e75 6d5f 6174 7465 6e74 696f 6e5f 6865  num_attention_he
-000034b0: 6164 7320 3d20 636f 6e66 6967 2e6e 756d  ads = config.num
-000034c0: 5f61 7474 656e 7469 6f6e 5f68 6561 6473  _attention_heads
-000034d0: 0a20 2020 2020 2020 2073 656c 662e 6174  .        self.at
-000034e0: 7465 6e74 696f 6e5f 6865 6164 5f73 697a  tention_head_siz
-000034f0: 6520 3d20 696e 7428 636f 6e66 6967 2e68  e = int(config.h
-00003500: 6964 6465 6e5f 7369 7a65 0a20 2020 2020  idden_size.     
-00003510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003530: 2020 2f20 636f 6e66 6967 2e6e 756d 5f61    / config.num_a
-00003540: 7474 656e 7469 6f6e 5f68 6561 6473 290a  ttention_heads).
-00003550: 2020 2020 2020 2020 7365 6c66 2e61 6c6c          self.all
-00003560: 5f68 6561 645f 7369 7a65 203d 2073 656c  _head_size = sel
-00003570: 662e 6e75 6d5f 6174 7465 6e74 696f 6e5f  f.num_attention_
-00003580: 6865 6164 7320 2a20 7365 6c66 2e61 7474  heads * self.att
-00003590: 656e 7469 6f6e 5f68 6561 645f 7369 7a65  ention_head_size
-000035a0: 0a0a 2020 2020 2020 2020 7365 6c66 2e71  ..        self.q
-000035b0: 7565 7279 203d 206e 6e2e 4c69 6e65 6172  uery = nn.Linear
-000035c0: 2863 6f6e 6669 672e 6869 6464 656e 5f73  (config.hidden_s
-000035d0: 697a 652c 2073 656c 662e 616c 6c5f 6865  ize, self.all_he
-000035e0: 6164 5f73 697a 6529 0a20 2020 2020 2020  ad_size).       
-000035f0: 2069 6620 6973 5f63 726f 7373 5f61 7474   if is_cross_att
-00003600: 656e 7469 6f6e 3a0a 2020 2020 2020 2020  ention:.        
-00003610: 2020 2020 7365 6c66 2e6b 6579 203d 206e      self.key = n
-00003620: 6e2e 4c69 6e65 6172 2863 6f6e 6669 672e  n.Linear(config.
-00003630: 656e 636f 6465 725f 7769 6474 682c 2073  encoder_width, s
-00003640: 656c 662e 616c 6c5f 6865 6164 5f73 697a  elf.all_head_siz
-00003650: 6529 0a20 2020 2020 2020 2020 2020 2073  e).            s
-00003660: 656c 662e 7661 6c75 6520 3d20 6e6e 2e4c  elf.value = nn.L
-00003670: 696e 6561 7228 636f 6e66 6967 2e65 6e63  inear(config.enc
-00003680: 6f64 6572 5f77 6964 7468 2c20 7365 6c66  oder_width, self
-00003690: 2e61 6c6c 5f68 6561 645f 7369 7a65 290a  .all_head_size).
-000036a0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-000036b0: 2020 2020 2020 2020 2020 7365 6c66 2e6b            self.k
-000036c0: 6579 203d 206e 6e2e 4c69 6e65 6172 2863  ey = nn.Linear(c
-000036d0: 6f6e 6669 672e 6869 6464 656e 5f73 697a  onfig.hidden_siz
-000036e0: 652c 2073 656c 662e 616c 6c5f 6865 6164  e, self.all_head
-000036f0: 5f73 697a 6529 0a20 2020 2020 2020 2020  _size).         
-00003700: 2020 2073 656c 662e 7661 6c75 6520 3d20     self.value = 
-00003710: 6e6e 2e4c 696e 6561 7228 636f 6e66 6967  nn.Linear(config
-00003720: 2e68 6964 6465 6e5f 7369 7a65 2c20 7365  .hidden_size, se
-00003730: 6c66 2e61 6c6c 5f68 6561 645f 7369 7a65  lf.all_head_size
-00003740: 290a 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00003750: 6472 6f70 6f75 7420 3d20 6e6e 2e44 726f  dropout = nn.Dro
-00003760: 706f 7574 2863 6f6e 6669 672e 6174 7465  pout(config.atte
-00003770: 6e74 696f 6e5f 7072 6f62 735f 6472 6f70  ntion_probs_drop
-00003780: 6f75 745f 7072 6f62 290a 2020 2020 2020  out_prob).      
-00003790: 2020 7365 6c66 2e70 6f73 6974 696f 6e5f    self.position_
-000037a0: 656d 6265 6464 696e 675f 7479 7065 203d  embedding_type =
-000037b0: 2067 6574 6174 7472 2863 6f6e 6669 672c   getattr(config,
-000037c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000037d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000037e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000037f0: 2770 6f73 6974 696f 6e5f 656d 6265 6464  'position_embedd
-00003800: 696e 675f 7479 7065 272c 0a20 2020 2020  ing_type',.     
-00003810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003830: 2020 2020 2020 2020 2020 2761 6273 6f6c            'absol
-00003840: 7574 6527 290a 2020 2020 2020 2020 6966  ute').        if
-00003850: 2073 656c 662e 706f 7369 7469 6f6e 5f65   self.position_e
-00003860: 6d62 6564 6469 6e67 5f74 7970 6520 3d3d  mbedding_type ==
-00003870: 2027 7265 6c61 7469 7665 5f6b 6579 2720   'relative_key' 
-00003880: 6f72 2073 656c 662e 706f 7369 7469 6f6e  or self.position
-00003890: 5f65 6d62 6564 6469 6e67 5f74 7970 6520  _embedding_type 
-000038a0: 3d3d 2027 7265 6c61 7469 7665 5f6b 6579  == 'relative_key
-000038b0: 5f71 7565 7279 273a 0a20 2020 2020 2020  _query':.       
-000038c0: 2020 2020 2073 656c 662e 6d61 785f 706f       self.max_po
-000038d0: 7369 7469 6f6e 5f65 6d62 6564 6469 6e67  sition_embedding
-000038e0: 7320 3d20 636f 6e66 6967 2e6d 6178 5f70  s = config.max_p
-000038f0: 6f73 6974 696f 6e5f 656d 6265 6464 696e  osition_embeddin
-00003900: 6773 0a20 2020 2020 2020 2020 2020 2073  gs.            s
-00003910: 656c 662e 6469 7374 616e 6365 5f65 6d62  elf.distance_emb
-00003920: 6564 6469 6e67 203d 206e 6e2e 456d 6265  edding = nn.Embe
-00003930: 6464 696e 6728 0a20 2020 2020 2020 2020  dding(.         
-00003940: 2020 2020 2020 2032 202a 2063 6f6e 6669         2 * confi
-00003950: 672e 6d61 785f 706f 7369 7469 6f6e 5f65  g.max_position_e
-00003960: 6d62 6564 6469 6e67 7320 2d20 312c 0a20  mbeddings - 1,. 
-00003970: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00003980: 656c 662e 6174 7465 6e74 696f 6e5f 6865  elf.attention_he
-00003990: 6164 5f73 697a 6529 0a20 2020 2020 2020  ad_size).       
-000039a0: 2073 656c 662e 7361 7665 5f61 7474 656e   self.save_atten
-000039b0: 7469 6f6e 203d 2046 616c 7365 0a0a 2020  tion = False..  
-000039c0: 2020 6465 6620 7361 7665 5f61 7474 6e5f    def save_attn_
-000039d0: 6772 6164 6965 6e74 7328 7365 6c66 2c20  gradients(self, 
-000039e0: 6174 746e 5f67 7261 6469 656e 7473 293a  attn_gradients):
-000039f0: 0a20 2020 2020 2020 2073 656c 662e 6174  .        self.at
-00003a00: 746e 5f67 7261 6469 656e 7473 203d 2061  tn_gradients = a
-00003a10: 7474 6e5f 6772 6164 6965 6e74 730a 0a20  ttn_gradients.. 
-00003a20: 2020 2064 6566 2067 6574 5f61 7474 6e5f     def get_attn_
-00003a30: 6772 6164 6965 6e74 7328 7365 6c66 293a  gradients(self):
-00003a40: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00003a50: 7365 6c66 2e61 7474 6e5f 6772 6164 6965  self.attn_gradie
-00003a60: 6e74 730a 0a20 2020 2064 6566 2073 6176  nts..    def sav
-00003a70: 655f 6174 7465 6e74 696f 6e5f 6d61 7028  e_attention_map(
-00003a80: 7365 6c66 2c20 6174 7465 6e74 696f 6e5f  self, attention_
-00003a90: 6d61 7029 3a0a 2020 2020 2020 2020 7365  map):.        se
-00003aa0: 6c66 2e61 7474 656e 7469 6f6e 5f6d 6170  lf.attention_map
-00003ab0: 203d 2061 7474 656e 7469 6f6e 5f6d 6170   = attention_map
-00003ac0: 0a0a 2020 2020 6465 6620 6765 745f 6174  ..    def get_at
-00003ad0: 7465 6e74 696f 6e5f 6d61 7028 7365 6c66  tention_map(self
-00003ae0: 293a 0a20 2020 2020 2020 2072 6574 7572  ):.        retur
-00003af0: 6e20 7365 6c66 2e61 7474 656e 7469 6f6e  n self.attention
-00003b00: 5f6d 6170 0a0a 2020 2020 6465 6620 7472  _map..    def tr
-00003b10: 616e 7370 6f73 655f 666f 725f 7363 6f72  anspose_for_scor
-00003b20: 6573 2873 656c 662c 2078 293a 0a20 2020  es(self, x):.   
-00003b30: 2020 2020 206e 6577 5f78 5f73 6861 7065       new_x_shape
-00003b40: 203d 2078 2e73 697a 6528 295b 3a2d 315d   = x.size()[:-1]
-00003b50: 202b 2028 7365 6c66 2e6e 756d 5f61 7474   + (self.num_att
-00003b60: 656e 7469 6f6e 5f68 6561 6473 2c0a 2020  ention_heads,.  
-00003b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003b90: 2020 2020 2073 656c 662e 6174 7465 6e74       self.attent
-00003ba0: 696f 6e5f 6865 6164 5f73 697a 6529 0a20  ion_head_size). 
-00003bb0: 2020 2020 2020 2078 203d 2078 2e76 6965         x = x.vie
-00003bc0: 7728 2a6e 6577 5f78 5f73 6861 7065 290a  w(*new_x_shape).
-00003bd0: 2020 2020 2020 2020 7265 7475 726e 2078          return x
-00003be0: 2e70 6572 6d75 7465 2830 2c20 322c 2031  .permute(0, 2, 1
-00003bf0: 2c20 3329 0a0a 2020 2020 6465 6620 666f  , 3)..    def fo
-00003c00: 7277 6172 6428 0a20 2020 2020 2020 2073  rward(.        s
-00003c10: 656c 662c 0a20 2020 2020 2020 2068 6964  elf,.        hid
-00003c20: 6465 6e5f 7374 6174 6573 2c0a 2020 2020  den_states,.    
-00003c30: 2020 2020 6174 7465 6e74 696f 6e5f 6d61      attention_ma
-00003c40: 736b 3d4e 6f6e 652c 0a20 2020 2020 2020  sk=None,.       
-00003c50: 2068 6561 645f 6d61 736b 3d4e 6f6e 652c   head_mask=None,
-00003c60: 0a20 2020 2020 2020 2065 6e63 6f64 6572  .        encoder
-00003c70: 5f68 6964 6465 6e5f 7374 6174 6573 3d4e  _hidden_states=N
-00003c80: 6f6e 652c 0a20 2020 2020 2020 2065 6e63  one,.        enc
-00003c90: 6f64 6572 5f61 7474 656e 7469 6f6e 5f6d  oder_attention_m
-00003ca0: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
-00003cb0: 2020 7061 7374 5f6b 6579 5f76 616c 7565    past_key_value
-00003cc0: 3d4e 6f6e 652c 0a20 2020 2020 2020 206f  =None,.        o
-00003cd0: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
-00003ce0: 3d46 616c 7365 2c0a 2020 2020 293a 0a20  =False,.    ):. 
-00003cf0: 2020 2020 2020 206d 6978 6564 5f71 7565         mixed_que
-00003d00: 7279 5f6c 6179 6572 203d 2073 656c 662e  ry_layer = self.
-00003d10: 7175 6572 7928 6869 6464 656e 5f73 7461  query(hidden_sta
-00003d20: 7465 7329 0a0a 2020 2020 2020 2020 2320  tes)..        # 
-00003d30: 4966 2074 6869 7320 6973 2069 6e73 7461  If this is insta
-00003d40: 6e74 6961 7465 6420 6173 2061 2063 726f  ntiated as a cro
-00003d50: 7373 2d61 7474 656e 7469 6f6e 206d 6f64  ss-attention mod
-00003d60: 756c 652c 2074 6865 206b 6579 730a 2020  ule, the keys.  
-00003d70: 2020 2020 2020 2320 616e 6420 7661 6c75        # and valu
-00003d80: 6573 2063 6f6d 6520 6672 6f6d 2061 6e20  es come from an 
-00003d90: 656e 636f 6465 723b 2074 6865 2061 7474  encoder; the att
-00003da0: 656e 7469 6f6e 206d 6173 6b20 6e65 6564  ention mask need
-00003db0: 7320 746f 2062 650a 2020 2020 2020 2020  s to be.        
-00003dc0: 2320 7375 6368 2074 6861 7420 7468 6520  # such that the 
-00003dd0: 656e 636f 6465 7227 7320 7061 6464 696e  encoder's paddin
-00003de0: 6720 746f 6b65 6e73 2061 7265 206e 6f74  g tokens are not
-00003df0: 2061 7474 656e 6465 6420 746f 2e0a 2020   attended to..  
-00003e00: 2020 2020 2020 6973 5f63 726f 7373 5f61        is_cross_a
-00003e10: 7474 656e 7469 6f6e 203d 2065 6e63 6f64  ttention = encod
-00003e20: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
-00003e30: 2069 7320 6e6f 7420 4e6f 6e65 0a0a 2020   is not None..  
-00003e40: 2020 2020 2020 6966 2069 735f 6372 6f73        if is_cros
-00003e50: 735f 6174 7465 6e74 696f 6e3a 0a20 2020  s_attention:.   
-00003e60: 2020 2020 2020 2020 206b 6579 5f6c 6179           key_lay
-00003e70: 6572 203d 2073 656c 662e 7472 616e 7370  er = self.transp
-00003e80: 6f73 655f 666f 725f 7363 6f72 6573 280a  ose_for_scores(.
-00003e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003ea0: 7365 6c66 2e6b 6579 2865 6e63 6f64 6572  self.key(encoder
-00003eb0: 5f68 6964 6465 6e5f 7374 6174 6573 2929  _hidden_states))
-00003ec0: 0a20 2020 2020 2020 2020 2020 2076 616c  .            val
-00003ed0: 7565 5f6c 6179 6572 203d 2073 656c 662e  ue_layer = self.
-00003ee0: 7472 616e 7370 6f73 655f 666f 725f 7363  transpose_for_sc
-00003ef0: 6f72 6573 280a 2020 2020 2020 2020 2020  ores(.          
-00003f00: 2020 2020 2020 7365 6c66 2e76 616c 7565        self.value
-00003f10: 2865 6e63 6f64 6572 5f68 6964 6465 6e5f  (encoder_hidden_
-00003f20: 7374 6174 6573 2929 0a20 2020 2020 2020  states)).       
-00003f30: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
-00003f40: 6173 6b20 3d20 656e 636f 6465 725f 6174  ask = encoder_at
-00003f50: 7465 6e74 696f 6e5f 6d61 736b 0a20 2020  tention_mask.   
-00003f60: 2020 2020 2065 6c69 6620 7061 7374 5f6b       elif past_k
-00003f70: 6579 5f76 616c 7565 2069 7320 6e6f 7420  ey_value is not 
-00003f80: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00003f90: 2020 6b65 795f 6c61 7965 7220 3d20 7365    key_layer = se
-00003fa0: 6c66 2e74 7261 6e73 706f 7365 5f66 6f72  lf.transpose_for
-00003fb0: 5f73 636f 7265 7328 7365 6c66 2e6b 6579  _scores(self.key
-00003fc0: 2868 6964 6465 6e5f 7374 6174 6573 2929  (hidden_states))
-00003fd0: 0a20 2020 2020 2020 2020 2020 2076 616c  .            val
-00003fe0: 7565 5f6c 6179 6572 203d 2073 656c 662e  ue_layer = self.
-00003ff0: 7472 616e 7370 6f73 655f 666f 725f 7363  transpose_for_sc
-00004000: 6f72 6573 2873 656c 662e 7661 6c75 6528  ores(self.value(
-00004010: 6869 6464 656e 5f73 7461 7465 7329 290a  hidden_states)).
-00004020: 2020 2020 2020 2020 2020 2020 6b65 795f              key_
-00004030: 6c61 7965 7220 3d20 746f 7263 682e 6361  layer = torch.ca
-00004040: 7428 5b70 6173 745f 6b65 795f 7661 6c75  t([past_key_valu
-00004050: 655b 305d 2c20 6b65 795f 6c61 7965 725d  e[0], key_layer]
-00004060: 2c20 6469 6d3d 3229 0a20 2020 2020 2020  , dim=2).       
-00004070: 2020 2020 2076 616c 7565 5f6c 6179 6572       value_layer
-00004080: 203d 2074 6f72 6368 2e63 6174 285b 7061   = torch.cat([pa
-00004090: 7374 5f6b 6579 5f76 616c 7565 5b31 5d2c  st_key_value[1],
-000040a0: 2076 616c 7565 5f6c 6179 6572 5d2c 2064   value_layer], d
-000040b0: 696d 3d32 290a 2020 2020 2020 2020 656c  im=2).        el
-000040c0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-000040d0: 6b65 795f 6c61 7965 7220 3d20 7365 6c66  key_layer = self
-000040e0: 2e74 7261 6e73 706f 7365 5f66 6f72 5f73  .transpose_for_s
-000040f0: 636f 7265 7328 7365 6c66 2e6b 6579 2868  cores(self.key(h
-00004100: 6964 6465 6e5f 7374 6174 6573 2929 0a20  idden_states)). 
-00004110: 2020 2020 2020 2020 2020 2076 616c 7565             value
-00004120: 5f6c 6179 6572 203d 2073 656c 662e 7472  _layer = self.tr
-00004130: 616e 7370 6f73 655f 666f 725f 7363 6f72  anspose_for_scor
-00004140: 6573 2873 656c 662e 7661 6c75 6528 6869  es(self.value(hi
-00004150: 6464 656e 5f73 7461 7465 7329 290a 0a20  dden_states)).. 
-00004160: 2020 2020 2020 2071 7565 7279 5f6c 6179         query_lay
-00004170: 6572 203d 2073 656c 662e 7472 616e 7370  er = self.transp
-00004180: 6f73 655f 666f 725f 7363 6f72 6573 286d  ose_for_scores(m
-00004190: 6978 6564 5f71 7565 7279 5f6c 6179 6572  ixed_query_layer
-000041a0: 290a 0a20 2020 2020 2020 2070 6173 745f  )..        past_
-000041b0: 6b65 795f 7661 6c75 6520 3d20 286b 6579  key_value = (key
-000041c0: 5f6c 6179 6572 2c20 7661 6c75 655f 6c61  _layer, value_la
-000041d0: 7965 7229 0a0a 2020 2020 2020 2020 2320  yer)..        # 
-000041e0: 5461 6b65 2074 6865 2064 6f74 2070 726f  Take the dot pro
-000041f0: 6475 6374 2062 6574 7765 656e 2022 7175  duct between "qu
-00004200: 6572 7922 2061 6e64 2022 6b65 7922 2074  ery" and "key" t
-00004210: 6f20 6765 7420 7468 6520 7261 7720 6174  o get the raw at
-00004220: 7465 6e74 696f 6e20 7363 6f72 6573 2e0a  tention scores..
-00004230: 2020 2020 2020 2020 6174 7465 6e74 696f          attentio
-00004240: 6e5f 7363 6f72 6573 203d 2074 6f72 6368  n_scores = torch
-00004250: 2e6d 6174 6d75 6c28 7175 6572 795f 6c61  .matmul(query_la
-00004260: 7965 722c 0a20 2020 2020 2020 2020 2020  yer,.           
-00004270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004280: 2020 2020 2020 2020 2020 2020 206b 6579               key
-00004290: 5f6c 6179 6572 2e74 7261 6e73 706f 7365  _layer.transpose
-000042a0: 282d 312c 202d 3229 290a 0a20 2020 2020  (-1, -2))..     
-000042b0: 2020 2069 6620 7365 6c66 2e70 6f73 6974     if self.posit
-000042c0: 696f 6e5f 656d 6265 6464 696e 675f 7479  ion_embedding_ty
-000042d0: 7065 203d 3d20 2772 656c 6174 6976 655f  pe == 'relative_
-000042e0: 6b65 7927 206f 7220 7365 6c66 2e70 6f73  key' or self.pos
-000042f0: 6974 696f 6e5f 656d 6265 6464 696e 675f  ition_embedding_
-00004300: 7479 7065 203d 3d20 2772 656c 6174 6976  type == 'relativ
-00004310: 655f 6b65 795f 7175 6572 7927 3a0a 2020  e_key_query':.  
-00004320: 2020 2020 2020 2020 2020 7365 715f 6c65            seq_le
-00004330: 6e67 7468 203d 2068 6964 6465 6e5f 7374  ngth = hidden_st
-00004340: 6174 6573 2e73 697a 6528 295b 315d 0a20  ates.size()[1]. 
-00004350: 2020 2020 2020 2020 2020 2070 6f73 6974             posit
-00004360: 696f 6e5f 6964 735f 6c20 3d20 746f 7263  ion_ids_l = torc
-00004370: 682e 6172 616e 6765 280a 2020 2020 2020  h.arange(.      
-00004380: 2020 2020 2020 2020 2020 7365 715f 6c65            seq_le
-00004390: 6e67 7468 2c20 6474 7970 653d 746f 7263  ngth, dtype=torc
-000043a0: 682e 6c6f 6e67 2c0a 2020 2020 2020 2020  h.long,.        
-000043b0: 2020 2020 2020 2020 6465 7669 6365 3d68          device=h
-000043c0: 6964 6465 6e5f 7374 6174 6573 2e64 6576  idden_states.dev
-000043d0: 6963 6529 2e76 6965 7728 2d31 2c20 3129  ice).view(-1, 1)
-000043e0: 0a20 2020 2020 2020 2020 2020 2070 6f73  .            pos
-000043f0: 6974 696f 6e5f 6964 735f 7220 3d20 746f  ition_ids_r = to
-00004400: 7263 682e 6172 616e 6765 280a 2020 2020  rch.arange(.    
-00004410: 2020 2020 2020 2020 2020 2020 7365 715f              seq_
-00004420: 6c65 6e67 7468 2c20 6474 7970 653d 746f  length, dtype=to
-00004430: 7263 682e 6c6f 6e67 2c0a 2020 2020 2020  rch.long,.      
-00004440: 2020 2020 2020 2020 2020 6465 7669 6365            device
-00004450: 3d68 6964 6465 6e5f 7374 6174 6573 2e64  =hidden_states.d
-00004460: 6576 6963 6529 2e76 6965 7728 312c 202d  evice).view(1, -
-00004470: 3129 0a20 2020 2020 2020 2020 2020 2064  1).            d
-00004480: 6973 7461 6e63 6520 3d20 706f 7369 7469  istance = positi
-00004490: 6f6e 5f69 6473 5f6c 202d 2070 6f73 6974  on_ids_l - posit
-000044a0: 696f 6e5f 6964 735f 720a 2020 2020 2020  ion_ids_r.      
-000044b0: 2020 2020 2020 706f 7369 7469 6f6e 616c        positional
-000044c0: 5f65 6d62 6564 6469 6e67 203d 2073 656c  _embedding = sel
-000044d0: 662e 6469 7374 616e 6365 5f65 6d62 6564  f.distance_embed
-000044e0: 6469 6e67 280a 2020 2020 2020 2020 2020  ding(.          
-000044f0: 2020 2020 2020 6469 7374 616e 6365 202b        distance +
-00004500: 2073 656c 662e 6d61 785f 706f 7369 7469   self.max_positi
-00004510: 6f6e 5f65 6d62 6564 6469 6e67 7320 2d20  on_embeddings - 
-00004520: 3129 0a20 2020 2020 2020 2020 2020 2070  1).            p
-00004530: 6f73 6974 696f 6e61 6c5f 656d 6265 6464  ositional_embedd
-00004540: 696e 6720 3d20 706f 7369 7469 6f6e 616c  ing = positional
-00004550: 5f65 6d62 6564 6469 6e67 2e74 6f28 0a20  _embedding.to(. 
-00004560: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00004570: 7479 7065 3d71 7565 7279 5f6c 6179 6572  type=query_layer
-00004580: 2e64 7479 7065 2920 2023 2066 7031 3620  .dtype)  # fp16 
-00004590: 636f 6d70 6174 6962 696c 6974 790a 0a20  compatibility.. 
-000045a0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-000045b0: 6c66 2e70 6f73 6974 696f 6e5f 656d 6265  lf.position_embe
-000045c0: 6464 696e 675f 7479 7065 203d 3d20 2772  dding_type == 'r
-000045d0: 656c 6174 6976 655f 6b65 7927 3a0a 2020  elative_key':.  
-000045e0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-000045f0: 6c61 7469 7665 5f70 6f73 6974 696f 6e5f  lative_position_
-00004600: 7363 6f72 6573 203d 2074 6f72 6368 2e65  scores = torch.e
-00004610: 696e 7375 6d28 0a20 2020 2020 2020 2020  insum(.         
-00004620: 2020 2020 2020 2020 2020 2027 6268 6c64             'bhld
-00004630: 2c6c 7264 2d3e 6268 6c72 272c 2071 7565  ,lrd->bhlr', que
-00004640: 7279 5f6c 6179 6572 2c20 706f 7369 7469  ry_layer, positi
-00004650: 6f6e 616c 5f65 6d62 6564 6469 6e67 290a  onal_embedding).
-00004660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004670: 6174 7465 6e74 696f 6e5f 7363 6f72 6573  attention_scores
-00004680: 203d 2061 7474 656e 7469 6f6e 5f73 636f   = attention_sco
-00004690: 7265 7320 2b20 7265 6c61 7469 7665 5f70  res + relative_p
-000046a0: 6f73 6974 696f 6e5f 7363 6f72 6573 0a20  osition_scores. 
-000046b0: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-000046c0: 7365 6c66 2e70 6f73 6974 696f 6e5f 656d  self.position_em
-000046d0: 6265 6464 696e 675f 7479 7065 203d 3d20  bedding_type == 
-000046e0: 2772 656c 6174 6976 655f 6b65 795f 7175  'relative_key_qu
-000046f0: 6572 7927 3a0a 2020 2020 2020 2020 2020  ery':.          
-00004700: 2020 2020 2020 7265 6c61 7469 7665 5f70        relative_p
-00004710: 6f73 6974 696f 6e5f 7363 6f72 6573 5f71  osition_scores_q
-00004720: 7565 7279 203d 2074 6f72 6368 2e65 696e  uery = torch.ein
-00004730: 7375 6d28 0a20 2020 2020 2020 2020 2020  sum(.           
-00004740: 2020 2020 2020 2020 2027 6268 6c64 2c6c           'bhld,l
-00004750: 7264 2d3e 6268 6c72 272c 2071 7565 7279  rd->bhlr', query
-00004760: 5f6c 6179 6572 2c20 706f 7369 7469 6f6e  _layer, position
-00004770: 616c 5f65 6d62 6564 6469 6e67 290a 2020  al_embedding).  
-00004780: 2020 2020 2020 2020 2020 2020 2020 7265                re
-00004790: 6c61 7469 7665 5f70 6f73 6974 696f 6e5f  lative_position_
-000047a0: 7363 6f72 6573 5f6b 6579 203d 2074 6f72  scores_key = tor
-000047b0: 6368 2e65 696e 7375 6d28 0a20 2020 2020  ch.einsum(.     
-000047c0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-000047d0: 6268 7264 2c6c 7264 2d3e 6268 6c72 272c  bhrd,lrd->bhlr',
-000047e0: 206b 6579 5f6c 6179 6572 2c20 706f 7369   key_layer, posi
-000047f0: 7469 6f6e 616c 5f65 6d62 6564 6469 6e67  tional_embedding
-00004800: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00004810: 2020 6174 7465 6e74 696f 6e5f 7363 6f72    attention_scor
-00004820: 6573 203d 2061 7474 656e 7469 6f6e 5f73  es = attention_s
-00004830: 636f 7265 7320 2b20 7265 6c61 7469 7665  cores + relative
-00004840: 5f70 6f73 6974 696f 6e5f 7363 6f72 6573  _position_scores
-00004850: 5f71 7565 7279 202b 2072 656c 6174 6976  _query + relativ
-00004860: 655f 706f 7369 7469 6f6e 5f73 636f 7265  e_position_score
-00004870: 735f 6b65 790a 0a20 2020 2020 2020 2061  s_key..        a
-00004880: 7474 656e 7469 6f6e 5f73 636f 7265 7320  ttention_scores 
-00004890: 3d20 6174 7465 6e74 696f 6e5f 7363 6f72  = attention_scor
-000048a0: 6573 202f 206d 6174 682e 7371 7274 280a  es / math.sqrt(.
-000048b0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000048c0: 2e61 7474 656e 7469 6f6e 5f68 6561 645f  .attention_head_
-000048d0: 7369 7a65 290a 2020 2020 2020 2020 6966  size).        if
-000048e0: 2061 7474 656e 7469 6f6e 5f6d 6173 6b20   attention_mask 
-000048f0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-00004900: 2020 2020 2020 2020 2023 2041 7070 6c79           # Apply
-00004910: 2074 6865 2061 7474 656e 7469 6f6e 206d   the attention m
-00004920: 6173 6b20 6973 2028 7072 6563 6f6d 7075  ask is (precompu
-00004930: 7465 6420 666f 7220 616c 6c20 6c61 7965  ted for all laye
-00004940: 7273 2069 6e20 4265 7274 4d6f 6465 6c20  rs in BertModel 
-00004950: 666f 7277 6172 6428 2920 6675 6e63 7469  forward() functi
-00004960: 6f6e 290a 2020 2020 2020 2020 2020 2020  on).            
-00004970: 6174 7465 6e74 696f 6e5f 7363 6f72 6573  attention_scores
-00004980: 203d 2061 7474 656e 7469 6f6e 5f73 636f   = attention_sco
-00004990: 7265 7320 2b20 6174 7465 6e74 696f 6e5f  res + attention_
-000049a0: 6d61 736b 0a0a 2020 2020 2020 2020 2320  mask..        # 
-000049b0: 4e6f 726d 616c 697a 6520 7468 6520 6174  Normalize the at
-000049c0: 7465 6e74 696f 6e20 7363 6f72 6573 2074  tention scores t
-000049d0: 6f20 7072 6f62 6162 696c 6974 6965 732e  o probabilities.
-000049e0: 0a20 2020 2020 2020 2061 7474 656e 7469  .        attenti
-000049f0: 6f6e 5f70 726f 6273 203d 206e 6e2e 536f  on_probs = nn.So
-00004a00: 6674 6d61 7828 6469 6d3d 2d31 2928 6174  ftmax(dim=-1)(at
-00004a10: 7465 6e74 696f 6e5f 7363 6f72 6573 290a  tention_scores).
-00004a20: 0a20 2020 2020 2020 2069 6620 6973 5f63  .        if is_c
-00004a30: 726f 7373 5f61 7474 656e 7469 6f6e 2061  ross_attention a
-00004a40: 6e64 2073 656c 662e 7361 7665 5f61 7474  nd self.save_att
-00004a50: 656e 7469 6f6e 3a0a 2020 2020 2020 2020  ention:.        
-00004a60: 2020 2020 7365 6c66 2e73 6176 655f 6174      self.save_at
-00004a70: 7465 6e74 696f 6e5f 6d61 7028 6174 7465  tention_map(atte
-00004a80: 6e74 696f 6e5f 7072 6f62 7329 0a20 2020  ntion_probs).   
-00004a90: 2020 2020 2020 2020 2061 7474 656e 7469           attenti
-00004aa0: 6f6e 5f70 726f 6273 2e72 6567 6973 7465  on_probs.registe
-00004ab0: 725f 686f 6f6b 2873 656c 662e 7361 7665  r_hook(self.save
-00004ac0: 5f61 7474 6e5f 6772 6164 6965 6e74 7329  _attn_gradients)
-00004ad0: 0a0a 2020 2020 2020 2020 2320 5468 6973  ..        # This
-00004ae0: 2069 7320 6163 7475 616c 6c79 2064 726f   is actually dro
-00004af0: 7070 696e 6720 6f75 7420 656e 7469 7265  pping out entire
-00004b00: 2074 6f6b 656e 7320 746f 2061 7474 656e   tokens to atten
-00004b10: 6420 746f 2c20 7768 6963 6820 6d69 6768  d to, which migh
-00004b20: 740a 2020 2020 2020 2020 2320 7365 656d  t.        # seem
-00004b30: 2061 2062 6974 2075 6e75 7375 616c 2c20   a bit unusual, 
-00004b40: 6275 7420 6973 2074 616b 656e 2066 726f  but is taken fro
-00004b50: 6d20 7468 6520 6f72 6967 696e 616c 2054  m the original T
-00004b60: 7261 6e73 666f 726d 6572 2070 6170 6572  ransformer paper
-00004b70: 2e0a 2020 2020 2020 2020 6174 7465 6e74  ..        attent
-00004b80: 696f 6e5f 7072 6f62 735f 6472 6f70 7065  ion_probs_droppe
-00004b90: 6420 3d20 7365 6c66 2e64 726f 706f 7574  d = self.dropout
-00004ba0: 2861 7474 656e 7469 6f6e 5f70 726f 6273  (attention_probs
-00004bb0: 290a 0a20 2020 2020 2020 2023 204d 6173  )..        # Mas
-00004bc0: 6b20 6865 6164 7320 6966 2077 6520 7761  k heads if we wa
-00004bd0: 6e74 2074 6f0a 2020 2020 2020 2020 6966  nt to.        if
-00004be0: 2068 6561 645f 6d61 736b 2069 7320 6e6f   head_mask is no
-00004bf0: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-00004c00: 2020 2020 6174 7465 6e74 696f 6e5f 7072      attention_pr
-00004c10: 6f62 735f 6472 6f70 7065 6420 3d20 6174  obs_dropped = at
-00004c20: 7465 6e74 696f 6e5f 7072 6f62 735f 6472  tention_probs_dr
-00004c30: 6f70 7065 6420 2a20 6865 6164 5f6d 6173  opped * head_mas
-00004c40: 6b0a 0a20 2020 2020 2020 2063 6f6e 7465  k..        conte
-00004c50: 7874 5f6c 6179 6572 203d 2074 6f72 6368  xt_layer = torch
-00004c60: 2e6d 6174 6d75 6c28 6174 7465 6e74 696f  .matmul(attentio
-00004c70: 6e5f 7072 6f62 735f 6472 6f70 7065 642c  n_probs_dropped,
-00004c80: 2076 616c 7565 5f6c 6179 6572 290a 0a20   value_layer).. 
-00004c90: 2020 2020 2020 2063 6f6e 7465 7874 5f6c         context_l
-00004ca0: 6179 6572 203d 2063 6f6e 7465 7874 5f6c  ayer = context_l
-00004cb0: 6179 6572 2e70 6572 6d75 7465 2830 2c20  ayer.permute(0, 
-00004cc0: 322c 2031 2c20 3329 2e63 6f6e 7469 6775  2, 1, 3).contigu
-00004cd0: 6f75 7328 290a 2020 2020 2020 2020 6e65  ous().        ne
-00004ce0: 775f 636f 6e74 6578 745f 6c61 7965 725f  w_context_layer_
-00004cf0: 7368 6170 6520 3d20 636f 6e74 6578 745f  shape = context_
-00004d00: 6c61 7965 722e 7369 7a65 2829 5b3a 2d32  layer.size()[:-2
-00004d10: 5d20 2b20 280a 2020 2020 2020 2020 2020  ] + (.          
-00004d20: 2020 7365 6c66 2e61 6c6c 5f68 6561 645f    self.all_head_
-00004d30: 7369 7a65 2c20 290a 2020 2020 2020 2020  size, ).        
-00004d40: 636f 6e74 6578 745f 6c61 7965 7220 3d20  context_layer = 
-00004d50: 636f 6e74 6578 745f 6c61 7965 722e 7669  context_layer.vi
-00004d60: 6577 282a 6e65 775f 636f 6e74 6578 745f  ew(*new_context_
-00004d70: 6c61 7965 725f 7368 6170 6529 0a0a 2020  layer_shape)..  
-00004d80: 2020 2020 2020 6f75 7470 7574 7320 3d20        outputs = 
-00004d90: 2863 6f6e 7465 7874 5f6c 6179 6572 2c0a  (context_layer,.
-00004da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004db0: 2020 2061 7474 656e 7469 6f6e 5f70 726f     attention_pro
-00004dc0: 6273 2920 6966 206f 7574 7075 745f 6174  bs) if output_at
-00004dd0: 7465 6e74 696f 6e73 2065 6c73 6520 2863  tentions else (c
-00004de0: 6f6e 7465 7874 5f6c 6179 6572 2c20 290a  ontext_layer, ).
-00004df0: 0a20 2020 2020 2020 206f 7574 7075 7473  .        outputs
-00004e00: 203d 206f 7574 7075 7473 202b 2028 7061   = outputs + (pa
-00004e10: 7374 5f6b 6579 5f76 616c 7565 2c20 290a  st_key_value, ).
-00004e20: 2020 2020 2020 2020 7265 7475 726e 206f          return o
-00004e30: 7574 7075 7473 0a0a 0a63 6c61 7373 2042  utputs...class B
-00004e40: 6572 7453 656c 664f 7574 7075 7428 6e6e  ertSelfOutput(nn
-00004e50: 2e4d 6f64 756c 6529 3a0a 0a20 2020 2064  .Module):..    d
-00004e60: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-00004e70: 2c20 636f 6e66 6967 293a 0a20 2020 2020  , config):.     
-00004e80: 2020 2073 7570 6572 2829 2e5f 5f69 6e69     super().__ini
-00004e90: 745f 5f28 290a 2020 2020 2020 2020 7365  t__().        se
-00004ea0: 6c66 2e64 656e 7365 203d 206e 6e2e 4c69  lf.dense = nn.Li
-00004eb0: 6e65 6172 2863 6f6e 6669 672e 6869 6464  near(config.hidd
-00004ec0: 656e 5f73 697a 652c 2063 6f6e 6669 672e  en_size, config.
-00004ed0: 6869 6464 656e 5f73 697a 6529 0a20 2020  hidden_size).   
-00004ee0: 2020 2020 2073 656c 662e 4c61 7965 724e       self.LayerN
-00004ef0: 6f72 6d20 3d20 6e6e 2e4c 6179 6572 4e6f  orm = nn.LayerNo
-00004f00: 726d 280a 2020 2020 2020 2020 2020 2020  rm(.            
-00004f10: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
-00004f20: 7a65 2c20 6570 733d 636f 6e66 6967 2e6c  ze, eps=config.l
-00004f30: 6179 6572 5f6e 6f72 6d5f 6570 7329 0a20  ayer_norm_eps). 
-00004f40: 2020 2020 2020 2073 656c 662e 6472 6f70         self.drop
-00004f50: 6f75 7420 3d20 6e6e 2e44 726f 706f 7574  out = nn.Dropout
-00004f60: 2863 6f6e 6669 672e 6869 6464 656e 5f64  (config.hidden_d
-00004f70: 726f 706f 7574 5f70 726f 6229 0a0a 2020  ropout_prob)..  
-00004f80: 2020 6465 6620 666f 7277 6172 6428 7365    def forward(se
-00004f90: 6c66 2c20 6869 6464 656e 5f73 7461 7465  lf, hidden_state
-00004fa0: 732c 2069 6e70 7574 5f74 656e 736f 7229  s, input_tensor)
-00004fb0: 3a0a 2020 2020 2020 2020 6869 6464 656e  :.        hidden
-00004fc0: 5f73 7461 7465 7320 3d20 7365 6c66 2e64  _states = self.d
-00004fd0: 656e 7365 2868 6964 6465 6e5f 7374 6174  ense(hidden_stat
-00004fe0: 6573 290a 2020 2020 2020 2020 6869 6464  es).        hidd
-00004ff0: 656e 5f73 7461 7465 7320 3d20 7365 6c66  en_states = self
-00005000: 2e64 726f 706f 7574 2868 6964 6465 6e5f  .dropout(hidden_
-00005010: 7374 6174 6573 290a 2020 2020 2020 2020  states).        
-00005020: 6869 6464 656e 5f73 7461 7465 7320 3d20  hidden_states = 
-00005030: 7365 6c66 2e4c 6179 6572 4e6f 726d 2868  self.LayerNorm(h
-00005040: 6964 6465 6e5f 7374 6174 6573 202b 2069  idden_states + i
-00005050: 6e70 7574 5f74 656e 736f 7229 0a20 2020  nput_tensor).   
-00005060: 2020 2020 2072 6574 7572 6e20 6869 6464       return hidd
-00005070: 656e 5f73 7461 7465 730a 0a0a 636c 6173  en_states...clas
-00005080: 7320 4265 7274 4174 7465 6e74 696f 6e28  s BertAttention(
-00005090: 6e6e 2e4d 6f64 756c 6529 3a0a 0a20 2020  nn.Module):..   
-000050a0: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
-000050b0: 6c66 2c20 636f 6e66 6967 2c20 6973 5f63  lf, config, is_c
-000050c0: 726f 7373 5f61 7474 656e 7469 6f6e 3d46  ross_attention=F
-000050d0: 616c 7365 293a 0a20 2020 2020 2020 2073  alse):.        s
-000050e0: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
-000050f0: 290a 2020 2020 2020 2020 7365 6c66 2e73  ).        self.s
-00005100: 656c 6620 3d20 4265 7274 5365 6c66 4174  elf = BertSelfAt
-00005110: 7465 6e74 696f 6e28 636f 6e66 6967 2c20  tention(config, 
-00005120: 6973 5f63 726f 7373 5f61 7474 656e 7469  is_cross_attenti
-00005130: 6f6e 290a 2020 2020 2020 2020 7365 6c66  on).        self
-00005140: 2e6f 7574 7075 7420 3d20 4265 7274 5365  .output = BertSe
-00005150: 6c66 4f75 7470 7574 2863 6f6e 6669 6729  lfOutput(config)
-00005160: 0a20 2020 2020 2020 2073 656c 662e 7072  .        self.pr
-00005170: 756e 6564 5f68 6561 6473 203d 2073 6574  uned_heads = set
-00005180: 2829 0a0a 2020 2020 6465 6620 7072 756e  ()..    def prun
-00005190: 655f 6865 6164 7328 7365 6c66 2c20 6865  e_heads(self, he
-000051a0: 6164 7329 3a0a 2020 2020 2020 2020 6966  ads):.        if
-000051b0: 206c 656e 2868 6561 6473 2920 3d3d 2030   len(heads) == 0
-000051c0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
-000051d0: 7475 726e 0a20 2020 2020 2020 2068 6561  turn.        hea
-000051e0: 6473 2c20 696e 6465 7820 3d20 6669 6e64  ds, index = find
-000051f0: 5f70 7275 6e65 6162 6c65 5f68 6561 6473  _pruneable_heads
-00005200: 5f61 6e64 5f69 6e64 6963 6573 280a 2020  _and_indices(.  
-00005210: 2020 2020 2020 2020 2020 6865 6164 732c            heads,
-00005220: 2073 656c 662e 7365 6c66 2e6e 756d 5f61   self.self.num_a
-00005230: 7474 656e 7469 6f6e 5f68 6561 6473 2c0a  ttention_heads,.
-00005240: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00005250: 2e73 656c 662e 6174 7465 6e74 696f 6e5f  .self.attention_
-00005260: 6865 6164 5f73 697a 652c 2073 656c 662e  head_size, self.
-00005270: 7072 756e 6564 5f68 6561 6473 290a 0a20  pruned_heads).. 
-00005280: 2020 2020 2020 2023 2050 7275 6e65 206c         # Prune l
-00005290: 696e 6561 7220 6c61 7965 7273 0a20 2020  inear layers.   
-000052a0: 2020 2020 2073 656c 662e 7365 6c66 2e71       self.self.q
-000052b0: 7565 7279 203d 2070 7275 6e65 5f6c 696e  uery = prune_lin
-000052c0: 6561 725f 6c61 7965 7228 7365 6c66 2e73  ear_layer(self.s
-000052d0: 656c 662e 7175 6572 792c 2069 6e64 6578  elf.query, index
-000052e0: 290a 2020 2020 2020 2020 7365 6c66 2e73  ).        self.s
-000052f0: 656c 662e 6b65 7920 3d20 7072 756e 655f  elf.key = prune_
-00005300: 6c69 6e65 6172 5f6c 6179 6572 2873 656c  linear_layer(sel
-00005310: 662e 7365 6c66 2e6b 6579 2c20 696e 6465  f.self.key, inde
-00005320: 7829 0a20 2020 2020 2020 2073 656c 662e  x).        self.
-00005330: 7365 6c66 2e76 616c 7565 203d 2070 7275  self.value = pru
-00005340: 6e65 5f6c 696e 6561 725f 6c61 7965 7228  ne_linear_layer(
-00005350: 7365 6c66 2e73 656c 662e 7661 6c75 652c  self.self.value,
-00005360: 2069 6e64 6578 290a 2020 2020 2020 2020   index).        
-00005370: 7365 6c66 2e6f 7574 7075 742e 6465 6e73  self.output.dens
-00005380: 6520 3d20 7072 756e 655f 6c69 6e65 6172  e = prune_linear
-00005390: 5f6c 6179 6572 2873 656c 662e 6f75 7470  _layer(self.outp
-000053a0: 7574 2e64 656e 7365 2c20 696e 6465 782c  ut.dense, index,
-000053b0: 2064 696d 3d31 290a 0a20 2020 2020 2020   dim=1)..       
-000053c0: 2023 2055 7064 6174 6520 6879 7065 7220   # Update hyper 
-000053d0: 7061 7261 6d73 2061 6e64 2073 746f 7265  params and store
-000053e0: 2070 7275 6e65 6420 6865 6164 730a 2020   pruned heads.  
-000053f0: 2020 2020 2020 7365 6c66 2e73 656c 662e        self.self.
-00005400: 6e75 6d5f 6174 7465 6e74 696f 6e5f 6865  num_attention_he
-00005410: 6164 7320 3d20 7365 6c66 2e73 656c 662e  ads = self.self.
-00005420: 6e75 6d5f 6174 7465 6e74 696f 6e5f 6865  num_attention_he
-00005430: 6164 7320 2d20 6c65 6e28 0a20 2020 2020  ads - len(.     
-00005440: 2020 2020 2020 2068 6561 6473 290a 2020         heads).  
-00005450: 2020 2020 2020 7365 6c66 2e73 656c 662e        self.self.
-00005460: 616c 6c5f 6865 6164 5f73 697a 6520 3d20  all_head_size = 
-00005470: 7365 6c66 2e73 656c 662e 6174 7465 6e74  self.self.attent
-00005480: 696f 6e5f 6865 6164 5f73 697a 6520 2a20  ion_head_size * 
-00005490: 7365 6c66 2e73 656c 662e 6e75 6d5f 6174  self.self.num_at
-000054a0: 7465 6e74 696f 6e5f 6865 6164 730a 2020  tention_heads.  
-000054b0: 2020 2020 2020 7365 6c66 2e70 7275 6e65        self.prune
-000054c0: 645f 6865 6164 7320 3d20 7365 6c66 2e70  d_heads = self.p
-000054d0: 7275 6e65 645f 6865 6164 732e 756e 696f  runed_heads.unio
-000054e0: 6e28 6865 6164 7329 0a0a 2020 2020 6465  n(heads)..    de
-000054f0: 6620 666f 7277 6172 6428 0a20 2020 2020  f forward(.     
-00005500: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
-00005510: 2068 6964 6465 6e5f 7374 6174 6573 2c0a   hidden_states,.
-00005520: 2020 2020 2020 2020 6174 7465 6e74 696f          attentio
-00005530: 6e5f 6d61 736b 3d4e 6f6e 652c 0a20 2020  n_mask=None,.   
-00005540: 2020 2020 2068 6561 645f 6d61 736b 3d4e       head_mask=N
-00005550: 6f6e 652c 0a20 2020 2020 2020 2065 6e63  one,.        enc
-00005560: 6f64 6572 5f68 6964 6465 6e5f 7374 6174  oder_hidden_stat
-00005570: 6573 3d4e 6f6e 652c 0a20 2020 2020 2020  es=None,.       
-00005580: 2065 6e63 6f64 6572 5f61 7474 656e 7469   encoder_attenti
-00005590: 6f6e 5f6d 6173 6b3d 4e6f 6e65 2c0a 2020  on_mask=None,.  
-000055a0: 2020 2020 2020 7061 7374 5f6b 6579 5f76        past_key_v
-000055b0: 616c 7565 3d4e 6f6e 652c 0a20 2020 2020  alue=None,.     
-000055c0: 2020 206f 7574 7075 745f 6174 7465 6e74     output_attent
-000055d0: 696f 6e73 3d46 616c 7365 2c0a 2020 2020  ions=False,.    
-000055e0: 293a 0a20 2020 2020 2020 2073 656c 665f  ):.        self_
-000055f0: 6f75 7470 7574 7320 3d20 7365 6c66 2e73  outputs = self.s
-00005600: 656c 6628 0a20 2020 2020 2020 2020 2020  elf(.           
-00005610: 2068 6964 6465 6e5f 7374 6174 6573 2c0a   hidden_states,.
-00005620: 2020 2020 2020 2020 2020 2020 6174 7465              atte
-00005630: 6e74 696f 6e5f 6d61 736b 2c0a 2020 2020  ntion_mask,.    
-00005640: 2020 2020 2020 2020 6865 6164 5f6d 6173          head_mas
-00005650: 6b2c 0a20 2020 2020 2020 2020 2020 2065  k,.            e
-00005660: 6e63 6f64 6572 5f68 6964 6465 6e5f 7374  ncoder_hidden_st
-00005670: 6174 6573 2c0a 2020 2020 2020 2020 2020  ates,.          
-00005680: 2020 656e 636f 6465 725f 6174 7465 6e74    encoder_attent
-00005690: 696f 6e5f 6d61 736b 2c0a 2020 2020 2020  ion_mask,.      
-000056a0: 2020 2020 2020 7061 7374 5f6b 6579 5f76        past_key_v
-000056b0: 616c 7565 2c0a 2020 2020 2020 2020 2020  alue,.          
-000056c0: 2020 6f75 7470 7574 5f61 7474 656e 7469    output_attenti
-000056d0: 6f6e 732c 0a20 2020 2020 2020 2029 0a20  ons,.        ). 
-000056e0: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
-000056f0: 5f6f 7574 7075 7420 3d20 7365 6c66 2e6f  _output = self.o
-00005700: 7574 7075 7428 7365 6c66 5f6f 7574 7075  utput(self_outpu
-00005710: 7473 5b30 5d2c 2068 6964 6465 6e5f 7374  ts[0], hidden_st
-00005720: 6174 6573 290a 2020 2020 2020 2020 6f75  ates).        ou
-00005730: 7470 7574 7320 3d20 2861 7474 656e 7469  tputs = (attenti
-00005740: 6f6e 5f6f 7574 7075 742c 0a20 2020 2020  on_output,.     
-00005750: 2020 2020 2020 2020 2020 2020 2020 2920                ) 
-00005760: 2b20 7365 6c66 5f6f 7574 7075 7473 5b31  + self_outputs[1
-00005770: 3a5d 2020 2320 6164 6420 6174 7465 6e74  :]  # add attent
-00005780: 696f 6e73 2069 6620 7765 206f 7574 7075  ions if we outpu
-00005790: 7420 7468 656d 0a20 2020 2020 2020 2072  t them.        r
-000057a0: 6574 7572 6e20 6f75 7470 7574 730a 0a0a  eturn outputs...
-000057b0: 636c 6173 7320 4265 7274 496e 7465 726d  class BertInterm
-000057c0: 6564 6961 7465 286e 6e2e 4d6f 6475 6c65  ediate(nn.Module
-000057d0: 293a 0a0a 2020 2020 6465 6620 5f5f 696e  ):..    def __in
-000057e0: 6974 5f5f 2873 656c 662c 2063 6f6e 6669  it__(self, confi
-000057f0: 6729 3a0a 2020 2020 2020 2020 7375 7065  g):.        supe
-00005800: 7228 292e 5f5f 696e 6974 5f5f 2829 0a20  r().__init__(). 
-00005810: 2020 2020 2020 2073 656c 662e 6465 6e73         self.dens
-00005820: 6520 3d20 6e6e 2e4c 696e 6561 7228 636f  e = nn.Linear(co
-00005830: 6e66 6967 2e68 6964 6465 6e5f 7369 7a65  nfig.hidden_size
-00005840: 2c20 636f 6e66 6967 2e69 6e74 6572 6d65  , config.interme
-00005850: 6469 6174 655f 7369 7a65 290a 2020 2020  diate_size).    
-00005860: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
-00005870: 6528 636f 6e66 6967 2e68 6964 6465 6e5f  e(config.hidden_
-00005880: 6163 742c 2073 7472 293a 0a20 2020 2020  act, str):.     
-00005890: 2020 2020 2020 2073 656c 662e 696e 7465         self.inte
-000058a0: 726d 6564 6961 7465 5f61 6374 5f66 6e20  rmediate_act_fn 
-000058b0: 3d20 4143 5432 464e 5b63 6f6e 6669 672e  = ACT2FN[config.
-000058c0: 6869 6464 656e 5f61 6374 5d0a 2020 2020  hidden_act].    
-000058d0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-000058e0: 2020 2020 2020 7365 6c66 2e69 6e74 6572        self.inter
-000058f0: 6d65 6469 6174 655f 6163 745f 666e 203d  mediate_act_fn =
-00005900: 2063 6f6e 6669 672e 6869 6464 656e 5f61   config.hidden_a
-00005910: 6374 0a0a 2020 2020 6465 6620 666f 7277  ct..    def forw
-00005920: 6172 6428 7365 6c66 2c20 6869 6464 656e  ard(self, hidden
-00005930: 5f73 7461 7465 7329 3a0a 2020 2020 2020  _states):.      
-00005940: 2020 6869 6464 656e 5f73 7461 7465 7320    hidden_states 
-00005950: 3d20 7365 6c66 2e64 656e 7365 2868 6964  = self.dense(hid
-00005960: 6465 6e5f 7374 6174 6573 290a 2020 2020  den_states).    
-00005970: 2020 2020 6869 6464 656e 5f73 7461 7465      hidden_state
-00005980: 7320 3d20 7365 6c66 2e69 6e74 6572 6d65  s = self.interme
-00005990: 6469 6174 655f 6163 745f 666e 2868 6964  diate_act_fn(hid
-000059a0: 6465 6e5f 7374 6174 6573 290a 2020 2020  den_states).    
-000059b0: 2020 2020 7265 7475 726e 2068 6964 6465      return hidde
-000059c0: 6e5f 7374 6174 6573 0a0a 0a63 6c61 7373  n_states...class
-000059d0: 2042 6572 744f 7574 7075 7428 6e6e 2e4d   BertOutput(nn.M
-000059e0: 6f64 756c 6529 3a0a 0a20 2020 2064 6566  odule):..    def
-000059f0: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
-00005a00: 636f 6e66 6967 293a 0a20 2020 2020 2020  config):.       
-00005a10: 2073 7570 6572 2829 2e5f 5f69 6e69 745f   super().__init_
-00005a20: 5f28 290a 2020 2020 2020 2020 7365 6c66  _().        self
-00005a30: 2e64 656e 7365 203d 206e 6e2e 4c69 6e65  .dense = nn.Line
-00005a40: 6172 2863 6f6e 6669 672e 696e 7465 726d  ar(config.interm
-00005a50: 6564 6961 7465 5f73 697a 652c 2063 6f6e  ediate_size, con
-00005a60: 6669 672e 6869 6464 656e 5f73 697a 6529  fig.hidden_size)
-00005a70: 0a20 2020 2020 2020 2073 656c 662e 4c61  .        self.La
-00005a80: 7965 724e 6f72 6d20 3d20 6e6e 2e4c 6179  yerNorm = nn.Lay
-00005a90: 6572 4e6f 726d 280a 2020 2020 2020 2020  erNorm(.        
-00005aa0: 2020 2020 636f 6e66 6967 2e68 6964 6465      config.hidde
-00005ab0: 6e5f 7369 7a65 2c20 6570 733d 636f 6e66  n_size, eps=conf
-00005ac0: 6967 2e6c 6179 6572 5f6e 6f72 6d5f 6570  ig.layer_norm_ep
-00005ad0: 7329 0a20 2020 2020 2020 2073 656c 662e  s).        self.
-00005ae0: 6472 6f70 6f75 7420 3d20 6e6e 2e44 726f  dropout = nn.Dro
-00005af0: 706f 7574 2863 6f6e 6669 672e 6869 6464  pout(config.hidd
-00005b00: 656e 5f64 726f 706f 7574 5f70 726f 6229  en_dropout_prob)
-00005b10: 0a0a 2020 2020 6465 6620 666f 7277 6172  ..    def forwar
-00005b20: 6428 7365 6c66 2c20 6869 6464 656e 5f73  d(self, hidden_s
-00005b30: 7461 7465 732c 2069 6e70 7574 5f74 656e  tates, input_ten
-00005b40: 736f 7229 3a0a 2020 2020 2020 2020 6869  sor):.        hi
-00005b50: 6464 656e 5f73 7461 7465 7320 3d20 7365  dden_states = se
-00005b60: 6c66 2e64 656e 7365 2868 6964 6465 6e5f  lf.dense(hidden_
-00005b70: 7374 6174 6573 290a 2020 2020 2020 2020  states).        
-00005b80: 6869 6464 656e 5f73 7461 7465 7320 3d20  hidden_states = 
-00005b90: 7365 6c66 2e64 726f 706f 7574 2868 6964  self.dropout(hid
-00005ba0: 6465 6e5f 7374 6174 6573 290a 2020 2020  den_states).    
-00005bb0: 2020 2020 6869 6464 656e 5f73 7461 7465      hidden_state
-00005bc0: 7320 3d20 7365 6c66 2e4c 6179 6572 4e6f  s = self.LayerNo
-00005bd0: 726d 2868 6964 6465 6e5f 7374 6174 6573  rm(hidden_states
-00005be0: 202b 2069 6e70 7574 5f74 656e 736f 7229   + input_tensor)
-00005bf0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00005c00: 6869 6464 656e 5f73 7461 7465 730a 0a0a  hidden_states...
-00005c10: 636c 6173 7320 4265 7274 4c61 7965 7228  class BertLayer(
-00005c20: 6e6e 2e4d 6f64 756c 6529 3a0a 0a20 2020  nn.Module):..   
-00005c30: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
-00005c40: 6c66 2c20 636f 6e66 6967 2c20 6c61 7965  lf, config, laye
-00005c50: 725f 6e75 6d29 3a0a 2020 2020 2020 2020  r_num):.        
-00005c60: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
-00005c70: 2829 0a20 2020 2020 2020 2073 656c 662e  ().        self.
-00005c80: 636f 6e66 6967 203d 2063 6f6e 6669 670a  config = config.
-00005c90: 2020 2020 2020 2020 7365 6c66 2e63 6875          self.chu
-00005ca0: 6e6b 5f73 697a 655f 6665 6564 5f66 6f72  nk_size_feed_for
-00005cb0: 7761 7264 203d 2063 6f6e 6669 672e 6368  ward = config.ch
-00005cc0: 756e 6b5f 7369 7a65 5f66 6565 645f 666f  unk_size_feed_fo
-00005cd0: 7277 6172 640a 2020 2020 2020 2020 7365  rward.        se
-00005ce0: 6c66 2e73 6571 5f6c 656e 5f64 696d 203d  lf.seq_len_dim =
-00005cf0: 2031 0a20 2020 2020 2020 2073 656c 662e   1.        self.
-00005d00: 6174 7465 6e74 696f 6e20 3d20 4265 7274  attention = Bert
-00005d10: 4174 7465 6e74 696f 6e28 636f 6e66 6967  Attention(config
-00005d20: 290a 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00005d30: 6861 735f 6372 6f73 735f 6174 7465 6e74  has_cross_attent
-00005d40: 696f 6e20 3d20 286c 6179 6572 5f6e 756d  ion = (layer_num
-00005d50: 203e 3d20 636f 6e66 6967 2e66 7573 696f   >= config.fusio
-00005d60: 6e5f 6c61 7965 7229 0a20 2020 2020 2020  n_layer).       
-00005d70: 2069 6620 7365 6c66 2e68 6173 5f63 726f   if self.has_cro
-00005d80: 7373 5f61 7474 656e 7469 6f6e 3a0a 2020  ss_attention:.  
-00005d90: 2020 2020 2020 2020 2020 7365 6c66 2e6c            self.l
-00005da0: 6179 6572 5f6e 756d 203d 206c 6179 6572  ayer_num = layer
-00005db0: 5f6e 756d 0a20 2020 2020 2020 2020 2020  _num.           
-00005dc0: 2073 656c 662e 6372 6f73 7361 7474 656e   self.crossatten
-00005dd0: 7469 6f6e 203d 2042 6572 7441 7474 656e  tion = BertAtten
-00005de0: 7469 6f6e 280a 2020 2020 2020 2020 2020  tion(.          
-00005df0: 2020 2020 2020 636f 6e66 6967 2c20 6973        config, is
-00005e00: 5f63 726f 7373 5f61 7474 656e 7469 6f6e  _cross_attention
-00005e10: 3d54 7275 6529 0a20 2020 2020 2020 2073  =True).        s
-00005e20: 656c 662e 696e 7465 726d 6564 6961 7465  elf.intermediate
-00005e30: 203d 2042 6572 7449 6e74 6572 6d65 6469   = BertIntermedi
-00005e40: 6174 6528 636f 6e66 6967 290a 2020 2020  ate(config).    
-00005e50: 2020 2020 7365 6c66 2e6f 7574 7075 7420      self.output 
-00005e60: 3d20 4265 7274 4f75 7470 7574 2863 6f6e  = BertOutput(con
-00005e70: 6669 6729 0a0a 2020 2020 6465 6620 666f  fig)..    def fo
-00005e80: 7277 6172 6428 0a20 2020 2020 2020 2073  rward(.        s
-00005e90: 656c 662c 0a20 2020 2020 2020 2068 6964  elf,.        hid
-00005ea0: 6465 6e5f 7374 6174 6573 2c0a 2020 2020  den_states,.    
-00005eb0: 2020 2020 6174 7465 6e74 696f 6e5f 6d61      attention_ma
-00005ec0: 736b 3d4e 6f6e 652c 0a20 2020 2020 2020  sk=None,.       
-00005ed0: 2068 6561 645f 6d61 736b 3d4e 6f6e 652c   head_mask=None,
-00005ee0: 0a20 2020 2020 2020 2065 6e63 6f64 6572  .        encoder
-00005ef0: 5f68 6964 6465 6e5f 7374 6174 6573 3d4e  _hidden_states=N
-00005f00: 6f6e 652c 0a20 2020 2020 2020 2065 6e63  one,.        enc
-00005f10: 6f64 6572 5f61 7474 656e 7469 6f6e 5f6d  oder_attention_m
-00005f20: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
-00005f30: 2020 7061 7374 5f6b 6579 5f76 616c 7565    past_key_value
-00005f40: 3d4e 6f6e 652c 0a20 2020 2020 2020 206f  =None,.        o
-00005f50: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
-00005f60: 3d46 616c 7365 2c0a 2020 2020 293a 0a20  =False,.    ):. 
-00005f70: 2020 2020 2020 2023 2064 6563 6f64 6572         # decoder
-00005f80: 2075 6e69 2d64 6972 6563 7469 6f6e 616c   uni-directional
-00005f90: 2073 656c 662d 6174 7465 6e74 696f 6e20   self-attention 
-00005fa0: 6361 6368 6564 206b 6579 2f76 616c 7565  cached key/value
-00005fb0: 7320 7475 706c 6520 6973 2061 740a 2020  s tuple is at.  
-00005fc0: 2020 2020 2020 2320 706f 7369 7469 6f6e        # position
-00005fd0: 7320 312c 320a 2020 2020 2020 2020 7365  s 1,2.        se
-00005fe0: 6c66 5f61 7474 6e5f 7061 7374 5f6b 6579  lf_attn_past_key
-00005ff0: 5f76 616c 7565 203d 2070 6173 745f 6b65  _value = past_ke
-00006000: 795f 7661 6c75 655b 3a0a 2020 2020 2020  y_value[:.      
-00006010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006030: 2020 2020 2020 2020 2020 2020 325d 2069              2] i
-00006040: 6620 7061 7374 5f6b 6579 5f76 616c 7565  f past_key_value
-00006050: 2069 7320 6e6f 7420 4e6f 6e65 2065 6c73   is not None els
-00006060: 6520 4e6f 6e65 0a20 2020 2020 2020 2073  e None.        s
-00006070: 656c 665f 6174 7465 6e74 696f 6e5f 6f75  elf_attention_ou
-00006080: 7470 7574 7320 3d20 7365 6c66 2e61 7474  tputs = self.att
-00006090: 656e 7469 6f6e 280a 2020 2020 2020 2020  ention(.        
-000060a0: 2020 2020 6869 6464 656e 5f73 7461 7465      hidden_state
-000060b0: 732c 0a20 2020 2020 2020 2020 2020 2061  s,.            a
-000060c0: 7474 656e 7469 6f6e 5f6d 6173 6b2c 0a20  ttention_mask,. 
-000060d0: 2020 2020 2020 2020 2020 2068 6561 645f             head_
-000060e0: 6d61 736b 2c0a 2020 2020 2020 2020 2020  mask,.          
-000060f0: 2020 6f75 7470 7574 5f61 7474 656e 7469    output_attenti
-00006100: 6f6e 733d 6f75 7470 7574 5f61 7474 656e  ons=output_atten
-00006110: 7469 6f6e 732c 0a20 2020 2020 2020 2020  tions,.         
-00006120: 2020 2070 6173 745f 6b65 795f 7661 6c75     past_key_valu
-00006130: 653d 7365 6c66 5f61 7474 6e5f 7061 7374  e=self_attn_past
-00006140: 5f6b 6579 5f76 616c 7565 2c0a 2020 2020  _key_value,.    
-00006150: 2020 2020 290a 2020 2020 2020 2020 6174      ).        at
-00006160: 7465 6e74 696f 6e5f 6f75 7470 7574 203d  tention_output =
-00006170: 2073 656c 665f 6174 7465 6e74 696f 6e5f   self_attention_
-00006180: 6f75 7470 7574 735b 305d 0a0a 2020 2020  outputs[0]..    
-00006190: 2020 2020 6f75 7470 7574 7320 3d20 7365      outputs = se
-000061a0: 6c66 5f61 7474 656e 7469 6f6e 5f6f 7574  lf_attention_out
-000061b0: 7075 7473 5b31 3a2d 315d 0a20 2020 2020  puts[1:-1].     
-000061c0: 2020 2070 7265 7365 6e74 5f6b 6579 5f76     present_key_v
-000061d0: 616c 7565 203d 2073 656c 665f 6174 7465  alue = self_atte
-000061e0: 6e74 696f 6e5f 6f75 7470 7574 735b 2d31  ntion_outputs[-1
-000061f0: 5d0a 0a20 2020 2020 2020 2069 6620 7365  ]..        if se
-00006200: 6c66 2e68 6173 5f63 726f 7373 5f61 7474  lf.has_cross_att
-00006210: 656e 7469 6f6e 3a0a 2020 2020 2020 2020  ention:.        
-00006220: 2020 2020 6173 7365 7274 2065 6e63 6f64      assert encod
-00006230: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
-00006240: 2069 7320 6e6f 7420 4e6f 6e65 2c20 2765   is not None, 'e
-00006250: 6e63 6f64 6572 5f68 6964 6465 6e5f 7374  ncoder_hidden_st
-00006260: 6174 6573 206d 7573 7420 6265 2067 6976  ates must be giv
-00006270: 656e 2066 6f72 2063 726f 7373 2d61 7474  en for cross-att
-00006280: 656e 7469 6f6e 206c 6179 6572 7327 0a0a  ention layers'..
-00006290: 2020 2020 2020 2020 2020 2020 6966 2074              if t
-000062a0: 7970 6528 656e 636f 6465 725f 6869 6464  ype(encoder_hidd
-000062b0: 656e 5f73 7461 7465 7329 203d 3d20 6c69  en_states) == li
-000062c0: 7374 3a0a 2020 2020 2020 2020 2020 2020  st:.            
-000062d0: 2020 2020 6372 6f73 735f 6174 7465 6e74      cross_attent
-000062e0: 696f 6e5f 6f75 7470 7574 7320 3d20 7365  ion_outputs = se
-000062f0: 6c66 2e63 726f 7373 6174 7465 6e74 696f  lf.crossattentio
-00006300: 6e28 0a20 2020 2020 2020 2020 2020 2020  n(.             
-00006310: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
-00006320: 5f6f 7574 7075 742c 0a20 2020 2020 2020  _output,.       
-00006330: 2020 2020 2020 2020 2020 2020 2061 7474               att
-00006340: 656e 7469 6f6e 5f6d 6173 6b2c 0a20 2020  ention_mask,.   
-00006350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006360: 2068 6561 645f 6d61 736b 2c0a 2020 2020   head_mask,.    
+00002530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002560: 2020 2020 2033 5d29 0a20 2020 2020 2020       3]).       
+00002570: 2069 6620 7072 6f76 5f69 6473 2069 7320   if prov_ids is 
+00002580: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00002590: 2020 2020 2020 656d 6265 6464 696e 6773        embeddings
+000025a0: 202b 3d20 7365 6c66 2e70 726f 765f 656d   += self.prov_em
+000025b0: 6265 6464 696e 6773 2870 726f 765f 6964  beddings(prov_id
+000025c0: 7329 0a20 2020 2020 2020 2020 2020 2065  s).            e
+000025d0: 6d62 6564 6469 6e67 7320 2b3d 2073 656c  mbeddings += sel
+000025e0: 662e 6369 7479 5f65 6d62 6564 6469 6e67  f.city_embedding
+000025f0: 7328 6369 7479 5f69 6473 290a 2020 2020  s(city_ids).    
+00002600: 2020 2020 2020 2020 656d 6265 6464 696e          embeddin
+00002610: 6773 202b 3d20 7365 6c66 2e64 6973 745f  gs += self.dist_
+00002620: 656d 6265 6464 696e 6773 2864 6973 745f  embeddings(dist_
+00002630: 6964 7329 0a0a 2020 2020 2020 2020 656d  ids)..        em
+00002640: 6265 6464 696e 6773 203d 2073 656c 662e  beddings = self.
+00002650: 4c61 7965 724e 6f72 6d28 656d 6265 6464  LayerNorm(embedd
+00002660: 696e 6773 290a 2020 2020 2020 2020 656d  ings).        em
+00002670: 6265 6464 696e 6773 203d 2073 656c 662e  beddings = self.
+00002680: 6472 6f70 6f75 7428 656d 6265 6464 696e  dropout(embeddin
+00002690: 6773 290a 2020 2020 2020 2020 7265 7475  gs).        retu
+000026a0: 726e 2065 6d62 6564 6469 6e67 730a 0a0a  rn embeddings...
+000026b0: 636c 6173 7320 4265 7274 456d 6265 6464  class BertEmbedd
+000026c0: 696e 6773 286e 6e2e 4d6f 6475 6c65 293a  ings(nn.Module):
+000026d0: 0a20 2020 2022 2222 436f 6e73 7472 7563  .    """Construc
+000026e0: 7420 7468 6520 656d 6265 6464 696e 6773  t the embeddings
+000026f0: 2066 726f 6d20 776f 7264 2c20 706f 7369   from word, posi
+00002700: 7469 6f6e 2061 6e64 2074 6f6b 656e 5f74  tion and token_t
+00002710: 7970 650a 2020 2020 656d 6265 6464 696e  ype.    embeddin
+00002720: 6773 2e22 2222 0a0a 2020 2020 6465 6620  gs."""..    def 
+00002730: 5f5f 696e 6974 5f5f 2873 656c 662c 2063  __init__(self, c
+00002740: 6f6e 6669 6729 3a0a 2020 2020 2020 2020  onfig):.        
+00002750: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
+00002760: 2829 0a20 2020 2020 2020 2073 656c 662e  ().        self.
+00002770: 776f 7264 5f65 6d62 6564 6469 6e67 7320  word_embeddings 
+00002780: 3d20 6e6e 2e45 6d62 6564 6469 6e67 280a  = nn.Embedding(.
+00002790: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+000027a0: 6967 2e76 6f63 6162 5f73 697a 652c 0a20  ig.vocab_size,. 
+000027b0: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
+000027c0: 672e 6869 6464 656e 5f73 697a 652c 0a20  g.hidden_size,. 
+000027d0: 2020 2020 2020 2020 2020 2070 6164 6469             paddi
+000027e0: 6e67 5f69 6478 3d63 6f6e 6669 672e 7061  ng_idx=config.pa
+000027f0: 645f 746f 6b65 6e5f 6964 290a 2020 2020  d_token_id).    
+00002800: 2020 2020 7365 6c66 2e70 6f73 6974 696f      self.positio
+00002810: 6e5f 656d 6265 6464 696e 6773 203d 206e  n_embeddings = n
+00002820: 6e2e 456d 6265 6464 696e 6728 636f 6e66  n.Embedding(conf
+00002830: 6967 2e6d 6178 5f70 6f73 6974 696f 6e5f  ig.max_position_
+00002840: 656d 6265 6464 696e 6773 2c0a 2020 2020  embeddings,.    
+00002850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002870: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+00002880: 6967 2e68 6964 6465 6e5f 7369 7a65 290a  ig.hidden_size).
+00002890: 2020 2020 2020 2020 7365 6c66 2e74 6f6b          self.tok
+000028a0: 656e 5f74 7970 655f 656d 6265 6464 696e  en_type_embeddin
+000028b0: 6773 203d 206e 6e2e 456d 6265 6464 696e  gs = nn.Embeddin
+000028c0: 6728 636f 6e66 6967 2e74 7970 655f 766f  g(config.type_vo
+000028d0: 6361 625f 7369 7a65 2c0a 2020 2020 2020  cab_size,.      
+000028e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000028f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002900: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+00002910: 6967 2e68 6964 6465 6e5f 7369 7a65 290a  ig.hidden_size).
+00002920: 0a20 2020 2020 2020 2023 2073 656c 662e  .        # self.
+00002930: 4c61 7965 724e 6f72 6d20 6973 206e 6f74  LayerNorm is not
+00002940: 2073 6e61 6b65 2d63 6173 6564 2074 6f20   snake-cased to 
+00002950: 7374 6963 6b20 7769 7468 2054 656e 736f  stick with Tenso
+00002960: 7246 6c6f 7720 6d6f 6465 6c20 7661 7269  rFlow model vari
+00002970: 6162 6c65 206e 616d 6520 616e 6420 6265  able name and be
+00002980: 2061 626c 6520 746f 206c 6f61 640a 2020   able to load.  
+00002990: 2020 2020 2020 2320 616e 7920 5465 6e73        # any Tens
+000029a0: 6f72 466c 6f77 2063 6865 636b 706f 696e  orFlow checkpoin
+000029b0: 7420 6669 6c65 0a20 2020 2020 2020 2073  t file.        s
+000029c0: 656c 662e 4c61 7965 724e 6f72 6d20 3d20  elf.LayerNorm = 
+000029d0: 6e6e 2e4c 6179 6572 4e6f 726d 280a 2020  nn.LayerNorm(.  
+000029e0: 2020 2020 2020 2020 2020 636f 6e66 6967            config
+000029f0: 2e68 6964 6465 6e5f 7369 7a65 2c20 6570  .hidden_size, ep
+00002a00: 733d 636f 6e66 6967 2e6c 6179 6572 5f6e  s=config.layer_n
+00002a10: 6f72 6d5f 6570 7329 0a20 2020 2020 2020  orm_eps).       
+00002a20: 2073 656c 662e 6472 6f70 6f75 7420 3d20   self.dropout = 
+00002a30: 6e6e 2e44 726f 706f 7574 2863 6f6e 6669  nn.Dropout(confi
+00002a40: 672e 6869 6464 656e 5f64 726f 706f 7574  g.hidden_dropout
+00002a50: 5f70 726f 6229 0a0a 2020 2020 2020 2020  _prob)..        
+00002a60: 2320 706f 7369 7469 6f6e 5f69 6473 2028  # position_ids (
+00002a70: 312c 206c 656e 2070 6f73 6974 696f 6e20  1, len position 
+00002a80: 656d 6229 2069 7320 636f 6e74 6967 756f  emb) is contiguo
+00002a90: 7573 2069 6e20 6d65 6d6f 7279 2061 6e64  us in memory and
+00002aa0: 2065 7870 6f72 7465 6420 7768 656e 2073   exported when s
+00002ab0: 6572 6961 6c69 7a65 640a 2020 2020 2020  erialized.      
+00002ac0: 2020 7365 6c66 2e72 6567 6973 7465 725f    self.register_
+00002ad0: 6275 6666 6572 280a 2020 2020 2020 2020  buffer(.        
+00002ae0: 2020 2020 2770 6f73 6974 696f 6e5f 6964      'position_id
+00002af0: 7327 2c0a 2020 2020 2020 2020 2020 2020  s',.            
+00002b00: 746f 7263 682e 6172 616e 6765 2863 6f6e  torch.arange(con
+00002b10: 6669 672e 6d61 785f 706f 7369 7469 6f6e  fig.max_position
+00002b20: 5f65 6d62 6564 6469 6e67 7329 2e65 7870  _embeddings).exp
+00002b30: 616e 6428 2831 2c20 2d31 2929 290a 2020  and((1, -1))).  
+00002b40: 2020 2020 2020 7365 6c66 2e70 6f73 6974        self.posit
+00002b50: 696f 6e5f 656d 6265 6464 696e 675f 7479  ion_embedding_ty
+00002b60: 7065 203d 2067 6574 6174 7472 2863 6f6e  pe = getattr(con
+00002b70: 6669 672c 0a20 2020 2020 2020 2020 2020  fig,.           
+00002b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ba0: 2020 2020 2770 6f73 6974 696f 6e5f 656d      'position_em
+00002bb0: 6265 6464 696e 675f 7479 7065 272c 0a20  bedding_type',. 
+00002bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002be0: 2020 2020 2020 2020 2020 2020 2020 2761                'a
+00002bf0: 6273 6f6c 7574 6527 290a 0a20 2020 2020  bsolute')..     
+00002c00: 2020 2073 656c 662e 636f 6e66 6967 203d     self.config =
+00002c10: 2063 6f6e 6669 670a 0a20 2020 2064 6566   config..    def
+00002c20: 2066 6f72 7761 7264 2873 656c 662c 0a20   forward(self,. 
+00002c30: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00002c40: 6e70 7574 5f69 6473 3d4e 6f6e 652c 0a20  nput_ids=None,. 
+00002c50: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+00002c60: 6f6b 656e 5f74 7970 655f 6964 733d 4e6f  oken_type_ids=No
+00002c70: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
+00002c80: 2020 2020 706f 7369 7469 6f6e 5f69 6473      position_ids
+00002c90: 3d4e 6f6e 652c 0a20 2020 2020 2020 2020  =None,.         
+00002ca0: 2020 2020 2020 2069 6e70 7574 735f 656d         inputs_em
+00002cb0: 6265 6473 3d4e 6f6e 652c 0a20 2020 2020  beds=None,.     
+00002cc0: 2020 2020 2020 2020 2020 2070 6173 745f             past_
+00002cd0: 6b65 795f 7661 6c75 6573 5f6c 656e 6774  key_values_lengt
+00002ce0: 683d 302c 0a20 2020 2020 2020 2020 2020  h=0,.           
+00002cf0: 2020 2020 2072 656c 5f74 7970 655f 6964       rel_type_id
+00002d00: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
+00002d10: 2020 2020 2020 2020 6162 736f 6c75 7465          absolute
+00002d20: 5f70 6f73 6974 696f 6e5f 6964 733d 4e6f  _position_ids=No
+00002d30: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
+00002d40: 2020 2020 7265 6c61 7469 7665 5f70 6f73      relative_pos
+00002d50: 6974 696f 6e5f 6964 733d 4e6f 6e65 293a  ition_ids=None):
+00002d60: 0a20 2020 2020 2020 2069 6620 696e 7075  .        if inpu
+00002d70: 745f 6964 7320 6973 206e 6f74 204e 6f6e  t_ids is not Non
+00002d80: 653a 0a20 2020 2020 2020 2020 2020 2069  e:.            i
+00002d90: 6e70 7574 5f73 6861 7065 203d 2069 6e70  nput_shape = inp
+00002da0: 7574 5f69 6473 2e73 697a 6528 290a 2020  ut_ids.size().  
+00002db0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00002dc0: 2020 2020 2020 2020 696e 7075 745f 7368          input_sh
+00002dd0: 6170 6520 3d20 696e 7075 7473 5f65 6d62  ape = inputs_emb
+00002de0: 6564 732e 7369 7a65 2829 5b3a 2d31 5d0a  eds.size()[:-1].
+00002df0: 0a20 2020 2020 2020 2073 6571 5f6c 656e  .        seq_len
+00002e00: 6774 6820 3d20 696e 7075 745f 7368 6170  gth = input_shap
+00002e10: 655b 315d 0a0a 2020 2020 2020 2020 6966  e[1]..        if
+00002e20: 2070 6f73 6974 696f 6e5f 6964 7320 6973   position_ids is
+00002e30: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00002e40: 2020 2070 6f73 6974 696f 6e5f 6964 7320     position_ids 
+00002e50: 3d20 7365 6c66 2e70 6f73 6974 696f 6e5f  = self.position_
+00002e60: 6964 735b 3a2c 0a20 2020 2020 2020 2020  ids[:,.         
+00002e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e90: 2020 2020 7061 7374 5f6b 6579 5f76 616c      past_key_val
+00002ea0: 7565 735f 6c65 6e67 7468 3a73 6571 5f6c  ues_length:seq_l
+00002eb0: 656e 6774 680a 2020 2020 2020 2020 2020  ength.          
+00002ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ee0: 2020 202b 2070 6173 745f 6b65 795f 7661     + past_key_va
+00002ef0: 6c75 6573 5f6c 656e 6774 685d 0a0a 2020  lues_length]..  
+00002f00: 2020 2020 2020 6966 2074 6f6b 656e 5f74        if token_t
+00002f10: 7970 655f 6964 7320 6973 204e 6f6e 653a  ype_ids is None:
+00002f20: 0a20 2020 2020 2020 2020 2020 2074 6f6b  .            tok
+00002f30: 656e 5f74 7970 655f 6964 7320 3d20 746f  en_type_ids = to
+00002f40: 7263 682e 7a65 726f 7328 0a20 2020 2020  rch.zeros(.     
+00002f50: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00002f60: 5f73 6861 7065 2c20 6474 7970 653d 746f  _shape, dtype=to
+00002f70: 7263 682e 6c6f 6e67 2c20 6465 7669 6365  rch.long, device
+00002f80: 3d73 656c 662e 706f 7369 7469 6f6e 5f69  =self.position_i
+00002f90: 6473 2e64 6576 6963 6529 0a0a 2020 2020  ds.device)..    
+00002fa0: 2020 2020 6966 2069 6e70 7574 735f 656d      if inputs_em
+00002fb0: 6265 6473 2069 7320 4e6f 6e65 3a0a 2020  beds is None:.  
+00002fc0: 2020 2020 2020 2020 2020 696e 7075 7473            inputs
+00002fd0: 5f65 6d62 6564 7320 3d20 7365 6c66 2e77  _embeds = self.w
+00002fe0: 6f72 645f 656d 6265 6464 696e 6773 2869  ord_embeddings(i
+00002ff0: 6e70 7574 5f69 6473 290a 0a20 2020 2020  nput_ids)..     
+00003000: 2020 2074 6f6b 656e 5f74 7970 655f 656d     token_type_em
+00003010: 6265 6464 696e 6773 203d 2073 656c 662e  beddings = self.
+00003020: 746f 6b65 6e5f 7479 7065 5f65 6d62 6564  token_type_embed
+00003030: 6469 6e67 7328 746f 6b65 6e5f 7479 7065  dings(token_type
+00003040: 5f69 6473 290a 0a20 2020 2020 2020 2065  _ids)..        e
+00003050: 6d62 6564 6469 6e67 7320 3d20 696e 7075  mbeddings = inpu
+00003060: 7473 5f65 6d62 6564 7320 2b20 746f 6b65  ts_embeds + toke
+00003070: 6e5f 7479 7065 5f65 6d62 6564 6469 6e67  n_type_embedding
+00003080: 730a 2020 2020 2020 2020 6966 2073 656c  s.        if sel
+00003090: 662e 706f 7369 7469 6f6e 5f65 6d62 6564  f.position_embed
+000030a0: 6469 6e67 5f74 7970 6520 3d3d 2027 6162  ding_type == 'ab
+000030b0: 736f 6c75 7465 273a 0a20 2020 2020 2020  solute':.       
+000030c0: 2020 2020 2070 6f73 6974 696f 6e5f 656d       position_em
+000030d0: 6265 6464 696e 6773 203d 2073 656c 662e  beddings = self.
+000030e0: 706f 7369 7469 6f6e 5f65 6d62 6564 6469  position_embeddi
+000030f0: 6e67 7328 706f 7369 7469 6f6e 5f69 6473  ngs(position_ids
+00003100: 290a 2020 2020 2020 2020 2020 2020 656d  ).            em
+00003110: 6265 6464 696e 6773 202b 3d20 706f 7369  beddings += posi
+00003120: 7469 6f6e 5f65 6d62 6564 6469 6e67 730a  tion_embeddings.
+00003130: 2020 2020 2020 2020 656d 6265 6464 696e          embeddin
+00003140: 6773 203d 2073 656c 662e 4c61 7965 724e  gs = self.LayerN
+00003150: 6f72 6d28 656d 6265 6464 696e 6773 290a  orm(embeddings).
+00003160: 2020 2020 2020 2020 656d 6265 6464 696e          embeddin
+00003170: 6773 203d 2073 656c 662e 6472 6f70 6f75  gs = self.dropou
+00003180: 7428 656d 6265 6464 696e 6773 290a 2020  t(embeddings).  
+00003190: 2020 2020 2020 7265 7475 726e 2065 6d62        return emb
+000031a0: 6564 6469 6e67 730a 0a0a 636c 6173 7320  eddings...class 
+000031b0: 4265 7274 5365 6c66 4174 7465 6e74 696f  BertSelfAttentio
+000031c0: 6e28 6e6e 2e4d 6f64 756c 6529 3a0a 0a20  n(nn.Module):.. 
+000031d0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+000031e0: 7365 6c66 2c20 636f 6e66 6967 2c20 6973  self, config, is
+000031f0: 5f63 726f 7373 5f61 7474 656e 7469 6f6e  _cross_attention
+00003200: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
+00003210: 2829 2e5f 5f69 6e69 745f 5f28 290a 2020  ().__init__().  
+00003220: 2020 2020 2020 7365 6c66 2e63 6f6e 6669        self.confi
+00003230: 6720 3d20 636f 6e66 6967 0a20 2020 2020  g = config.     
+00003240: 2020 2069 6620 636f 6e66 6967 2e68 6964     if config.hid
+00003250: 6465 6e5f 7369 7a65 2025 2063 6f6e 6669  den_size % confi
+00003260: 672e 6e75 6d5f 6174 7465 6e74 696f 6e5f  g.num_attention_
+00003270: 6865 6164 7320 213d 2030 2061 6e64 206e  heads != 0 and n
+00003280: 6f74 2068 6173 6174 7472 280a 2020 2020  ot hasattr(.    
+00003290: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+000032a0: 6967 2c20 2765 6d62 6564 6469 6e67 5f73  ig, 'embedding_s
+000032b0: 697a 6527 293a 0a20 2020 2020 2020 2020  ize'):.         
+000032c0: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+000032d0: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
+000032e0: 2020 2020 2027 5468 6520 6869 6464 656e       'The hidden
+000032f0: 2073 697a 6520 2825 6429 2069 7320 6e6f   size (%d) is no
+00003300: 7420 6120 6d75 6c74 6970 6c65 206f 6620  t a multiple of 
+00003310: 7468 6520 6e75 6d62 6572 206f 6620 6174  the number of at
+00003320: 7465 6e74 696f 6e20 270a 2020 2020 2020  tention '.      
+00003330: 2020 2020 2020 2020 2020 2768 6561 6473            'heads
+00003340: 2028 2564 2927 2025 0a20 2020 2020 2020   (%d)' %.       
+00003350: 2020 2020 2020 2020 2028 636f 6e66 6967           (config
+00003360: 2e68 6964 6465 6e5f 7369 7a65 2c20 636f  .hidden_size, co
+00003370: 6e66 6967 2e6e 756d 5f61 7474 656e 7469  nfig.num_attenti
+00003380: 6f6e 5f68 6561 6473 2929 0a0a 2020 2020  on_heads))..    
+00003390: 2020 2020 7365 6c66 2e6e 756d 5f61 7474      self.num_att
+000033a0: 656e 7469 6f6e 5f68 6561 6473 203d 2063  ention_heads = c
+000033b0: 6f6e 6669 672e 6e75 6d5f 6174 7465 6e74  onfig.num_attent
+000033c0: 696f 6e5f 6865 6164 730a 2020 2020 2020  ion_heads.      
+000033d0: 2020 7365 6c66 2e61 7474 656e 7469 6f6e    self.attention
+000033e0: 5f68 6561 645f 7369 7a65 203d 2069 6e74  _head_size = int
+000033f0: 2863 6f6e 6669 672e 6869 6464 656e 5f73  (config.hidden_s
+00003400: 697a 650a 2020 2020 2020 2020 2020 2020  ize.            
+00003410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003420: 2020 2020 2020 2020 2020 202f 2063 6f6e             / con
+00003430: 6669 672e 6e75 6d5f 6174 7465 6e74 696f  fig.num_attentio
+00003440: 6e5f 6865 6164 7329 0a20 2020 2020 2020  n_heads).       
+00003450: 2073 656c 662e 616c 6c5f 6865 6164 5f73   self.all_head_s
+00003460: 697a 6520 3d20 7365 6c66 2e6e 756d 5f61  ize = self.num_a
+00003470: 7474 656e 7469 6f6e 5f68 6561 6473 202a  ttention_heads *
+00003480: 2073 656c 662e 6174 7465 6e74 696f 6e5f   self.attention_
+00003490: 6865 6164 5f73 697a 650a 0a20 2020 2020  head_size..     
+000034a0: 2020 2073 656c 662e 7175 6572 7920 3d20     self.query = 
+000034b0: 6e6e 2e4c 696e 6561 7228 636f 6e66 6967  nn.Linear(config
+000034c0: 2e68 6964 6465 6e5f 7369 7a65 2c20 7365  .hidden_size, se
+000034d0: 6c66 2e61 6c6c 5f68 6561 645f 7369 7a65  lf.all_head_size
+000034e0: 290a 2020 2020 2020 2020 6966 2069 735f  ).        if is_
+000034f0: 6372 6f73 735f 6174 7465 6e74 696f 6e3a  cross_attention:
+00003500: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00003510: 662e 6b65 7920 3d20 6e6e 2e4c 696e 6561  f.key = nn.Linea
+00003520: 7228 636f 6e66 6967 2e65 6e63 6f64 6572  r(config.encoder
+00003530: 5f77 6964 7468 2c20 7365 6c66 2e61 6c6c  _width, self.all
+00003540: 5f68 6561 645f 7369 7a65 290a 2020 2020  _head_size).    
+00003550: 2020 2020 2020 2020 7365 6c66 2e76 616c          self.val
+00003560: 7565 203d 206e 6e2e 4c69 6e65 6172 2863  ue = nn.Linear(c
+00003570: 6f6e 6669 672e 656e 636f 6465 725f 7769  onfig.encoder_wi
+00003580: 6474 682c 2073 656c 662e 616c 6c5f 6865  dth, self.all_he
+00003590: 6164 5f73 697a 6529 0a20 2020 2020 2020  ad_size).       
+000035a0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+000035b0: 2020 2073 656c 662e 6b65 7920 3d20 6e6e     self.key = nn
+000035c0: 2e4c 696e 6561 7228 636f 6e66 6967 2e68  .Linear(config.h
+000035d0: 6964 6465 6e5f 7369 7a65 2c20 7365 6c66  idden_size, self
+000035e0: 2e61 6c6c 5f68 6561 645f 7369 7a65 290a  .all_head_size).
+000035f0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00003600: 2e76 616c 7565 203d 206e 6e2e 4c69 6e65  .value = nn.Line
+00003610: 6172 2863 6f6e 6669 672e 6869 6464 656e  ar(config.hidden
+00003620: 5f73 697a 652c 2073 656c 662e 616c 6c5f  _size, self.all_
+00003630: 6865 6164 5f73 697a 6529 0a0a 2020 2020  head_size)..    
+00003640: 2020 2020 7365 6c66 2e64 726f 706f 7574      self.dropout
+00003650: 203d 206e 6e2e 4472 6f70 6f75 7428 636f   = nn.Dropout(co
+00003660: 6e66 6967 2e61 7474 656e 7469 6f6e 5f70  nfig.attention_p
+00003670: 726f 6273 5f64 726f 706f 7574 5f70 726f  robs_dropout_pro
+00003680: 6229 0a20 2020 2020 2020 2073 656c 662e  b).        self.
+00003690: 706f 7369 7469 6f6e 5f65 6d62 6564 6469  position_embeddi
+000036a0: 6e67 5f74 7970 6520 3d20 6765 7461 7474  ng_type = getatt
+000036b0: 7228 636f 6e66 6967 2c0a 2020 2020 2020  r(config,.      
+000036c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000036d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000036e0: 2020 2020 2020 2020 2027 706f 7369 7469           'positi
+000036f0: 6f6e 5f65 6d62 6564 6469 6e67 5f74 7970  on_embedding_typ
+00003700: 6527 2c0a 2020 2020 2020 2020 2020 2020  e',.            
+00003710: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003730: 2020 2027 6162 736f 6c75 7465 2729 0a20     'absolute'). 
+00003740: 2020 2020 2020 2069 6620 7365 6c66 2e70         if self.p
+00003750: 6f73 6974 696f 6e5f 656d 6265 6464 696e  osition_embeddin
+00003760: 675f 7479 7065 203d 3d20 2772 656c 6174  g_type == 'relat
+00003770: 6976 655f 6b65 7927 206f 7220 7365 6c66  ive_key' or self
+00003780: 2e70 6f73 6974 696f 6e5f 656d 6265 6464  .position_embedd
+00003790: 696e 675f 7479 7065 203d 3d20 2772 656c  ing_type == 'rel
+000037a0: 6174 6976 655f 6b65 795f 7175 6572 7927  ative_key_query'
+000037b0: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
+000037c0: 6c66 2e6d 6178 5f70 6f73 6974 696f 6e5f  lf.max_position_
+000037d0: 656d 6265 6464 696e 6773 203d 2063 6f6e  embeddings = con
+000037e0: 6669 672e 6d61 785f 706f 7369 7469 6f6e  fig.max_position
+000037f0: 5f65 6d62 6564 6469 6e67 730a 2020 2020  _embeddings.    
+00003800: 2020 2020 2020 2020 7365 6c66 2e64 6973          self.dis
+00003810: 7461 6e63 655f 656d 6265 6464 696e 6720  tance_embedding 
+00003820: 3d20 6e6e 2e45 6d62 6564 6469 6e67 280a  = nn.Embedding(.
+00003830: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003840: 3220 2a20 636f 6e66 6967 2e6d 6178 5f70  2 * config.max_p
+00003850: 6f73 6974 696f 6e5f 656d 6265 6464 696e  osition_embeddin
+00003860: 6773 202d 2031 2c0a 2020 2020 2020 2020  gs - 1,.        
+00003870: 2020 2020 2020 2020 7365 6c66 2e61 7474          self.att
+00003880: 656e 7469 6f6e 5f68 6561 645f 7369 7a65  ention_head_size
+00003890: 290a 2020 2020 2020 2020 7365 6c66 2e73  ).        self.s
+000038a0: 6176 655f 6174 7465 6e74 696f 6e20 3d20  ave_attention = 
+000038b0: 4661 6c73 650a 0a20 2020 2064 6566 2073  False..    def s
+000038c0: 6176 655f 6174 746e 5f67 7261 6469 656e  ave_attn_gradien
+000038d0: 7473 2873 656c 662c 2061 7474 6e5f 6772  ts(self, attn_gr
+000038e0: 6164 6965 6e74 7329 3a0a 2020 2020 2020  adients):.      
+000038f0: 2020 7365 6c66 2e61 7474 6e5f 6772 6164    self.attn_grad
+00003900: 6965 6e74 7320 3d20 6174 746e 5f67 7261  ients = attn_gra
+00003910: 6469 656e 7473 0a0a 2020 2020 6465 6620  dients..    def 
+00003920: 6765 745f 6174 746e 5f67 7261 6469 656e  get_attn_gradien
+00003930: 7473 2873 656c 6629 3a0a 2020 2020 2020  ts(self):.      
+00003940: 2020 7265 7475 726e 2073 656c 662e 6174    return self.at
+00003950: 746e 5f67 7261 6469 656e 7473 0a0a 2020  tn_gradients..  
+00003960: 2020 6465 6620 7361 7665 5f61 7474 656e    def save_atten
+00003970: 7469 6f6e 5f6d 6170 2873 656c 662c 2061  tion_map(self, a
+00003980: 7474 656e 7469 6f6e 5f6d 6170 293a 0a20  ttention_map):. 
+00003990: 2020 2020 2020 2073 656c 662e 6174 7465         self.atte
+000039a0: 6e74 696f 6e5f 6d61 7020 3d20 6174 7465  ntion_map = atte
+000039b0: 6e74 696f 6e5f 6d61 700a 0a20 2020 2064  ntion_map..    d
+000039c0: 6566 2067 6574 5f61 7474 656e 7469 6f6e  ef get_attention
+000039d0: 5f6d 6170 2873 656c 6629 3a0a 2020 2020  _map(self):.    
+000039e0: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+000039f0: 6174 7465 6e74 696f 6e5f 6d61 700a 0a20  attention_map.. 
+00003a00: 2020 2064 6566 2074 7261 6e73 706f 7365     def transpose
+00003a10: 5f66 6f72 5f73 636f 7265 7328 7365 6c66  _for_scores(self
+00003a20: 2c20 7829 3a0a 2020 2020 2020 2020 6e65  , x):.        ne
+00003a30: 775f 785f 7368 6170 6520 3d20 782e 7369  w_x_shape = x.si
+00003a40: 7a65 2829 5b3a 2d31 5d20 2b20 2873 656c  ze()[:-1] + (sel
+00003a50: 662e 6e75 6d5f 6174 7465 6e74 696f 6e5f  f.num_attention_
+00003a60: 6865 6164 732c 0a20 2020 2020 2020 2020  heads,.         
+00003a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003a80: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00003a90: 6c66 2e61 7474 656e 7469 6f6e 5f68 6561  lf.attention_hea
+00003aa0: 645f 7369 7a65 290a 2020 2020 2020 2020  d_size).        
+00003ab0: 7820 3d20 782e 7669 6577 282a 6e65 775f  x = x.view(*new_
+00003ac0: 785f 7368 6170 6529 0a20 2020 2020 2020  x_shape).       
+00003ad0: 2072 6574 7572 6e20 782e 7065 726d 7574   return x.permut
+00003ae0: 6528 302c 2032 2c20 312c 2033 290a 0a20  e(0, 2, 1, 3).. 
+00003af0: 2020 2064 6566 2066 6f72 7761 7264 280a     def forward(.
+00003b00: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00003b10: 2020 2020 2020 6869 6464 656e 5f73 7461        hidden_sta
+00003b20: 7465 732c 0a20 2020 2020 2020 2061 7474  tes,.        att
+00003b30: 656e 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65  ention_mask=None
+00003b40: 2c0a 2020 2020 2020 2020 6865 6164 5f6d  ,.        head_m
+00003b50: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
+00003b60: 2020 656e 636f 6465 725f 6869 6464 656e    encoder_hidden
+00003b70: 5f73 7461 7465 733d 4e6f 6e65 2c0a 2020  _states=None,.  
+00003b80: 2020 2020 2020 656e 636f 6465 725f 6174        encoder_at
+00003b90: 7465 6e74 696f 6e5f 6d61 736b 3d4e 6f6e  tention_mask=Non
+00003ba0: 652c 0a20 2020 2020 2020 2070 6173 745f  e,.        past_
+00003bb0: 6b65 795f 7661 6c75 653d 4e6f 6e65 2c0a  key_value=None,.
+00003bc0: 2020 2020 2020 2020 6f75 7470 7574 5f61          output_a
+00003bd0: 7474 656e 7469 6f6e 733d 4661 6c73 652c  ttentions=False,
+00003be0: 0a20 2020 2029 3a0a 2020 2020 2020 2020  .    ):.        
+00003bf0: 6d69 7865 645f 7175 6572 795f 6c61 7965  mixed_query_laye
+00003c00: 7220 3d20 7365 6c66 2e71 7565 7279 2868  r = self.query(h
+00003c10: 6964 6465 6e5f 7374 6174 6573 290a 0a20  idden_states).. 
+00003c20: 2020 2020 2020 2023 2049 6620 7468 6973         # If this
+00003c30: 2069 7320 696e 7374 616e 7469 6174 6564   is instantiated
+00003c40: 2061 7320 6120 6372 6f73 732d 6174 7465   as a cross-atte
+00003c50: 6e74 696f 6e20 6d6f 6475 6c65 2c20 7468  ntion module, th
+00003c60: 6520 6b65 7973 0a20 2020 2020 2020 2023  e keys.        #
+00003c70: 2061 6e64 2076 616c 7565 7320 636f 6d65   and values come
+00003c80: 2066 726f 6d20 616e 2065 6e63 6f64 6572   from an encoder
+00003c90: 3b20 7468 6520 6174 7465 6e74 696f 6e20  ; the attention 
+00003ca0: 6d61 736b 206e 6565 6473 2074 6f20 6265  mask needs to be
+00003cb0: 0a20 2020 2020 2020 2023 2073 7563 6820  .        # such 
+00003cc0: 7468 6174 2074 6865 2065 6e63 6f64 6572  that the encoder
+00003cd0: 2773 2070 6164 6469 6e67 2074 6f6b 656e  's padding token
+00003ce0: 7320 6172 6520 6e6f 7420 6174 7465 6e64  s are not attend
+00003cf0: 6564 2074 6f2e 0a20 2020 2020 2020 2069  ed to..        i
+00003d00: 735f 6372 6f73 735f 6174 7465 6e74 696f  s_cross_attentio
+00003d10: 6e20 3d20 656e 636f 6465 725f 6869 6464  n = encoder_hidd
+00003d20: 656e 5f73 7461 7465 7320 6973 206e 6f74  en_states is not
+00003d30: 204e 6f6e 650a 0a20 2020 2020 2020 2069   None..        i
+00003d40: 6620 6973 5f63 726f 7373 5f61 7474 656e  f is_cross_atten
+00003d50: 7469 6f6e 3a0a 2020 2020 2020 2020 2020  tion:.          
+00003d60: 2020 6b65 795f 6c61 7965 7220 3d20 7365    key_layer = se
+00003d70: 6c66 2e74 7261 6e73 706f 7365 5f66 6f72  lf.transpose_for
+00003d80: 5f73 636f 7265 7328 0a20 2020 2020 2020  _scores(.       
+00003d90: 2020 2020 2020 2020 2073 656c 662e 6b65           self.ke
+00003da0: 7928 656e 636f 6465 725f 6869 6464 656e  y(encoder_hidden
+00003db0: 5f73 7461 7465 7329 290a 2020 2020 2020  _states)).      
+00003dc0: 2020 2020 2020 7661 6c75 655f 6c61 7965        value_laye
+00003dd0: 7220 3d20 7365 6c66 2e74 7261 6e73 706f  r = self.transpo
+00003de0: 7365 5f66 6f72 5f73 636f 7265 7328 0a20  se_for_scores(. 
+00003df0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00003e00: 656c 662e 7661 6c75 6528 656e 636f 6465  elf.value(encode
+00003e10: 725f 6869 6464 656e 5f73 7461 7465 7329  r_hidden_states)
+00003e20: 290a 2020 2020 2020 2020 2020 2020 6174  ).            at
+00003e30: 7465 6e74 696f 6e5f 6d61 736b 203d 2065  tention_mask = e
+00003e40: 6e63 6f64 6572 5f61 7474 656e 7469 6f6e  ncoder_attention
+00003e50: 5f6d 6173 6b0a 2020 2020 2020 2020 656c  _mask.        el
+00003e60: 6966 2070 6173 745f 6b65 795f 7661 6c75  if past_key_valu
+00003e70: 6520 6973 206e 6f74 204e 6f6e 653a 0a20  e is not None:. 
+00003e80: 2020 2020 2020 2020 2020 206b 6579 5f6c             key_l
+00003e90: 6179 6572 203d 2073 656c 662e 7472 616e  ayer = self.tran
+00003ea0: 7370 6f73 655f 666f 725f 7363 6f72 6573  spose_for_scores
+00003eb0: 2873 656c 662e 6b65 7928 6869 6464 656e  (self.key(hidden
+00003ec0: 5f73 7461 7465 7329 290a 2020 2020 2020  _states)).      
+00003ed0: 2020 2020 2020 7661 6c75 655f 6c61 7965        value_laye
+00003ee0: 7220 3d20 7365 6c66 2e74 7261 6e73 706f  r = self.transpo
+00003ef0: 7365 5f66 6f72 5f73 636f 7265 7328 7365  se_for_scores(se
+00003f00: 6c66 2e76 616c 7565 2868 6964 6465 6e5f  lf.value(hidden_
+00003f10: 7374 6174 6573 2929 0a20 2020 2020 2020  states)).       
+00003f20: 2020 2020 206b 6579 5f6c 6179 6572 203d       key_layer =
+00003f30: 2074 6f72 6368 2e63 6174 285b 7061 7374   torch.cat([past
+00003f40: 5f6b 6579 5f76 616c 7565 5b30 5d2c 206b  _key_value[0], k
+00003f50: 6579 5f6c 6179 6572 5d2c 2064 696d 3d32  ey_layer], dim=2
+00003f60: 290a 2020 2020 2020 2020 2020 2020 7661  ).            va
+00003f70: 6c75 655f 6c61 7965 7220 3d20 746f 7263  lue_layer = torc
+00003f80: 682e 6361 7428 5b70 6173 745f 6b65 795f  h.cat([past_key_
+00003f90: 7661 6c75 655b 315d 2c20 7661 6c75 655f  value[1], value_
+00003fa0: 6c61 7965 725d 2c20 6469 6d3d 3229 0a20  layer], dim=2). 
+00003fb0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00003fc0: 2020 2020 2020 2020 206b 6579 5f6c 6179           key_lay
+00003fd0: 6572 203d 2073 656c 662e 7472 616e 7370  er = self.transp
+00003fe0: 6f73 655f 666f 725f 7363 6f72 6573 2873  ose_for_scores(s
+00003ff0: 656c 662e 6b65 7928 6869 6464 656e 5f73  elf.key(hidden_s
+00004000: 7461 7465 7329 290a 2020 2020 2020 2020  tates)).        
+00004010: 2020 2020 7661 6c75 655f 6c61 7965 7220      value_layer 
+00004020: 3d20 7365 6c66 2e74 7261 6e73 706f 7365  = self.transpose
+00004030: 5f66 6f72 5f73 636f 7265 7328 7365 6c66  _for_scores(self
+00004040: 2e76 616c 7565 2868 6964 6465 6e5f 7374  .value(hidden_st
+00004050: 6174 6573 2929 0a0a 2020 2020 2020 2020  ates))..        
+00004060: 7175 6572 795f 6c61 7965 7220 3d20 7365  query_layer = se
+00004070: 6c66 2e74 7261 6e73 706f 7365 5f66 6f72  lf.transpose_for
+00004080: 5f73 636f 7265 7328 6d69 7865 645f 7175  _scores(mixed_qu
+00004090: 6572 795f 6c61 7965 7229 0a0a 2020 2020  ery_layer)..    
+000040a0: 2020 2020 7061 7374 5f6b 6579 5f76 616c      past_key_val
+000040b0: 7565 203d 2028 6b65 795f 6c61 7965 722c  ue = (key_layer,
+000040c0: 2076 616c 7565 5f6c 6179 6572 290a 0a20   value_layer).. 
+000040d0: 2020 2020 2020 2023 2054 616b 6520 7468         # Take th
+000040e0: 6520 646f 7420 7072 6f64 7563 7420 6265  e dot product be
+000040f0: 7477 6565 6e20 2271 7565 7279 2220 616e  tween "query" an
+00004100: 6420 226b 6579 2220 746f 2067 6574 2074  d "key" to get t
+00004110: 6865 2072 6177 2061 7474 656e 7469 6f6e  he raw attention
+00004120: 2073 636f 7265 732e 0a20 2020 2020 2020   scores..       
+00004130: 2061 7474 656e 7469 6f6e 5f73 636f 7265   attention_score
+00004140: 7320 3d20 746f 7263 682e 6d61 746d 756c  s = torch.matmul
+00004150: 2871 7565 7279 5f6c 6179 6572 2c0a 2020  (query_layer,.  
+00004160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004180: 2020 2020 2020 6b65 795f 6c61 7965 722e        key_layer.
+00004190: 7472 616e 7370 6f73 6528 2d31 2c20 2d32  transpose(-1, -2
+000041a0: 2929 0a0a 2020 2020 2020 2020 6966 2073  ))..        if s
+000041b0: 656c 662e 706f 7369 7469 6f6e 5f65 6d62  elf.position_emb
+000041c0: 6564 6469 6e67 5f74 7970 6520 3d3d 2027  edding_type == '
+000041d0: 7265 6c61 7469 7665 5f6b 6579 2720 6f72  relative_key' or
+000041e0: 2073 656c 662e 706f 7369 7469 6f6e 5f65   self.position_e
+000041f0: 6d62 6564 6469 6e67 5f74 7970 6520 3d3d  mbedding_type ==
+00004200: 2027 7265 6c61 7469 7665 5f6b 6579 5f71   'relative_key_q
+00004210: 7565 7279 273a 0a20 2020 2020 2020 2020  uery':.         
+00004220: 2020 2073 6571 5f6c 656e 6774 6820 3d20     seq_length = 
+00004230: 6869 6464 656e 5f73 7461 7465 732e 7369  hidden_states.si
+00004240: 7a65 2829 5b31 5d0a 2020 2020 2020 2020  ze()[1].        
+00004250: 2020 2020 706f 7369 7469 6f6e 5f69 6473      position_ids
+00004260: 5f6c 203d 2074 6f72 6368 2e61 7261 6e67  _l = torch.arang
+00004270: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
+00004280: 2020 2073 6571 5f6c 656e 6774 682c 2064     seq_length, d
+00004290: 7479 7065 3d74 6f72 6368 2e6c 6f6e 672c  type=torch.long,
+000042a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000042b0: 2064 6576 6963 653d 6869 6464 656e 5f73   device=hidden_s
+000042c0: 7461 7465 732e 6465 7669 6365 292e 7669  tates.device).vi
+000042d0: 6577 282d 312c 2031 290a 2020 2020 2020  ew(-1, 1).      
+000042e0: 2020 2020 2020 706f 7369 7469 6f6e 5f69        position_i
+000042f0: 6473 5f72 203d 2074 6f72 6368 2e61 7261  ds_r = torch.ara
+00004300: 6e67 6528 0a20 2020 2020 2020 2020 2020  nge(.           
+00004310: 2020 2020 2073 6571 5f6c 656e 6774 682c       seq_length,
+00004320: 2064 7479 7065 3d74 6f72 6368 2e6c 6f6e   dtype=torch.lon
+00004330: 672c 0a20 2020 2020 2020 2020 2020 2020  g,.             
+00004340: 2020 2064 6576 6963 653d 6869 6464 656e     device=hidden
+00004350: 5f73 7461 7465 732e 6465 7669 6365 292e  _states.device).
+00004360: 7669 6577 2831 2c20 2d31 290a 2020 2020  view(1, -1).    
+00004370: 2020 2020 2020 2020 6469 7374 616e 6365          distance
+00004380: 203d 2070 6f73 6974 696f 6e5f 6964 735f   = position_ids_
+00004390: 6c20 2d20 706f 7369 7469 6f6e 5f69 6473  l - position_ids
+000043a0: 5f72 0a20 2020 2020 2020 2020 2020 2070  _r.            p
+000043b0: 6f73 6974 696f 6e61 6c5f 656d 6265 6464  ositional_embedd
+000043c0: 696e 6720 3d20 7365 6c66 2e64 6973 7461  ing = self.dista
+000043d0: 6e63 655f 656d 6265 6464 696e 6728 0a20  nce_embedding(. 
+000043e0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+000043f0: 6973 7461 6e63 6520 2b20 7365 6c66 2e6d  istance + self.m
+00004400: 6178 5f70 6f73 6974 696f 6e5f 656d 6265  ax_position_embe
+00004410: 6464 696e 6773 202d 2031 290a 2020 2020  ddings - 1).    
+00004420: 2020 2020 2020 2020 706f 7369 7469 6f6e          position
+00004430: 616c 5f65 6d62 6564 6469 6e67 203d 2070  al_embedding = p
+00004440: 6f73 6974 696f 6e61 6c5f 656d 6265 6464  ositional_embedd
+00004450: 696e 672e 746f 280a 2020 2020 2020 2020  ing.to(.        
+00004460: 2020 2020 2020 2020 6474 7970 653d 7175          dtype=qu
+00004470: 6572 795f 6c61 7965 722e 6474 7970 6529  ery_layer.dtype)
+00004480: 2020 2320 6670 3136 2063 6f6d 7061 7469    # fp16 compati
+00004490: 6269 6c69 7479 0a0a 2020 2020 2020 2020  bility..        
+000044a0: 2020 2020 6966 2073 656c 662e 706f 7369      if self.posi
+000044b0: 7469 6f6e 5f65 6d62 6564 6469 6e67 5f74  tion_embedding_t
+000044c0: 7970 6520 3d3d 2027 7265 6c61 7469 7665  ype == 'relative
+000044d0: 5f6b 6579 273a 0a20 2020 2020 2020 2020  _key':.         
+000044e0: 2020 2020 2020 2072 656c 6174 6976 655f         relative_
+000044f0: 706f 7369 7469 6f6e 5f73 636f 7265 7320  position_scores 
+00004500: 3d20 746f 7263 682e 6569 6e73 756d 280a  = torch.einsum(.
+00004510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004520: 2020 2020 2762 686c 642c 6c72 642d 3e62      'bhld,lrd->b
+00004530: 686c 7227 2c20 7175 6572 795f 6c61 7965  hlr', query_laye
+00004540: 722c 2070 6f73 6974 696f 6e61 6c5f 656d  r, positional_em
+00004550: 6265 6464 696e 6729 0a20 2020 2020 2020  bedding).       
+00004560: 2020 2020 2020 2020 2061 7474 656e 7469           attenti
+00004570: 6f6e 5f73 636f 7265 7320 3d20 6174 7465  on_scores = atte
+00004580: 6e74 696f 6e5f 7363 6f72 6573 202b 2072  ntion_scores + r
+00004590: 656c 6174 6976 655f 706f 7369 7469 6f6e  elative_position
+000045a0: 5f73 636f 7265 730a 2020 2020 2020 2020  _scores.        
+000045b0: 2020 2020 656c 6966 2073 656c 662e 706f      elif self.po
+000045c0: 7369 7469 6f6e 5f65 6d62 6564 6469 6e67  sition_embedding
+000045d0: 5f74 7970 6520 3d3d 2027 7265 6c61 7469  _type == 'relati
+000045e0: 7665 5f6b 6579 5f71 7565 7279 273a 0a20  ve_key_query':. 
+000045f0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00004600: 656c 6174 6976 655f 706f 7369 7469 6f6e  elative_position
+00004610: 5f73 636f 7265 735f 7175 6572 7920 3d20  _scores_query = 
+00004620: 746f 7263 682e 6569 6e73 756d 280a 2020  torch.einsum(.  
+00004630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004640: 2020 2762 686c 642c 6c72 642d 3e62 686c    'bhld,lrd->bhl
+00004650: 7227 2c20 7175 6572 795f 6c61 7965 722c  r', query_layer,
+00004660: 2070 6f73 6974 696f 6e61 6c5f 656d 6265   positional_embe
+00004670: 6464 696e 6729 0a20 2020 2020 2020 2020  dding).         
+00004680: 2020 2020 2020 2072 656c 6174 6976 655f         relative_
+00004690: 706f 7369 7469 6f6e 5f73 636f 7265 735f  position_scores_
+000046a0: 6b65 7920 3d20 746f 7263 682e 6569 6e73  key = torch.eins
+000046b0: 756d 280a 2020 2020 2020 2020 2020 2020  um(.            
+000046c0: 2020 2020 2020 2020 2762 6872 642c 6c72          'bhrd,lr
+000046d0: 642d 3e62 686c 7227 2c20 6b65 795f 6c61  d->bhlr', key_la
+000046e0: 7965 722c 2070 6f73 6974 696f 6e61 6c5f  yer, positional_
+000046f0: 656d 6265 6464 696e 6729 0a20 2020 2020  embedding).     
+00004700: 2020 2020 2020 2020 2020 2061 7474 656e             atten
+00004710: 7469 6f6e 5f73 636f 7265 7320 3d20 6174  tion_scores = at
+00004720: 7465 6e74 696f 6e5f 7363 6f72 6573 202b  tention_scores +
+00004730: 2072 656c 6174 6976 655f 706f 7369 7469   relative_positi
+00004740: 6f6e 5f73 636f 7265 735f 7175 6572 7920  on_scores_query 
+00004750: 2b20 7265 6c61 7469 7665 5f70 6f73 6974  + relative_posit
+00004760: 696f 6e5f 7363 6f72 6573 5f6b 6579 0a0a  ion_scores_key..
+00004770: 2020 2020 2020 2020 6174 7465 6e74 696f          attentio
+00004780: 6e5f 7363 6f72 6573 203d 2061 7474 656e  n_scores = atten
+00004790: 7469 6f6e 5f73 636f 7265 7320 2f20 6d61  tion_scores / ma
+000047a0: 7468 2e73 7172 7428 0a20 2020 2020 2020  th.sqrt(.       
+000047b0: 2020 2020 2073 656c 662e 6174 7465 6e74       self.attent
+000047c0: 696f 6e5f 6865 6164 5f73 697a 6529 0a20  ion_head_size). 
+000047d0: 2020 2020 2020 2069 6620 6174 7465 6e74         if attent
+000047e0: 696f 6e5f 6d61 736b 2069 7320 6e6f 7420  ion_mask is not 
+000047f0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00004800: 2020 2320 4170 706c 7920 7468 6520 6174    # Apply the at
+00004810: 7465 6e74 696f 6e20 6d61 736b 2069 7320  tention mask is 
+00004820: 2870 7265 636f 6d70 7574 6564 2066 6f72  (precomputed for
+00004830: 2061 6c6c 206c 6179 6572 7320 696e 2042   all layers in B
+00004840: 6572 744d 6f64 656c 2066 6f72 7761 7264  ertModel forward
+00004850: 2829 2066 756e 6374 696f 6e29 0a20 2020  () function).   
+00004860: 2020 2020 2020 2020 2061 7474 656e 7469           attenti
+00004870: 6f6e 5f73 636f 7265 7320 3d20 6174 7465  on_scores = atte
+00004880: 6e74 696f 6e5f 7363 6f72 6573 202b 2061  ntion_scores + a
+00004890: 7474 656e 7469 6f6e 5f6d 6173 6b0a 0a20  ttention_mask.. 
+000048a0: 2020 2020 2020 2023 204e 6f72 6d61 6c69         # Normali
+000048b0: 7a65 2074 6865 2061 7474 656e 7469 6f6e  ze the attention
+000048c0: 2073 636f 7265 7320 746f 2070 726f 6261   scores to proba
+000048d0: 6269 6c69 7469 6573 2e0a 2020 2020 2020  bilities..      
+000048e0: 2020 6174 7465 6e74 696f 6e5f 7072 6f62    attention_prob
+000048f0: 7320 3d20 6e6e 2e53 6f66 746d 6178 2864  s = nn.Softmax(d
+00004900: 696d 3d2d 3129 2861 7474 656e 7469 6f6e  im=-1)(attention
+00004910: 5f73 636f 7265 7329 0a0a 2020 2020 2020  _scores)..      
+00004920: 2020 6966 2069 735f 6372 6f73 735f 6174    if is_cross_at
+00004930: 7465 6e74 696f 6e20 616e 6420 7365 6c66  tention and self
+00004940: 2e73 6176 655f 6174 7465 6e74 696f 6e3a  .save_attention:
+00004950: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00004960: 662e 7361 7665 5f61 7474 656e 7469 6f6e  f.save_attention
+00004970: 5f6d 6170 2861 7474 656e 7469 6f6e 5f70  _map(attention_p
+00004980: 726f 6273 290a 2020 2020 2020 2020 2020  robs).          
+00004990: 2020 6174 7465 6e74 696f 6e5f 7072 6f62    attention_prob
+000049a0: 732e 7265 6769 7374 6572 5f68 6f6f 6b28  s.register_hook(
+000049b0: 7365 6c66 2e73 6176 655f 6174 746e 5f67  self.save_attn_g
+000049c0: 7261 6469 656e 7473 290a 0a20 2020 2020  radients)..     
+000049d0: 2020 2023 2054 6869 7320 6973 2061 6374     # This is act
+000049e0: 7561 6c6c 7920 6472 6f70 7069 6e67 206f  ually dropping o
+000049f0: 7574 2065 6e74 6972 6520 746f 6b65 6e73  ut entire tokens
+00004a00: 2074 6f20 6174 7465 6e64 2074 6f2c 2077   to attend to, w
+00004a10: 6869 6368 206d 6967 6874 0a20 2020 2020  hich might.     
+00004a20: 2020 2023 2073 6565 6d20 6120 6269 7420     # seem a bit 
+00004a30: 756e 7573 7561 6c2c 2062 7574 2069 7320  unusual, but is 
+00004a40: 7461 6b65 6e20 6672 6f6d 2074 6865 206f  taken from the o
+00004a50: 7269 6769 6e61 6c20 5472 616e 7366 6f72  riginal Transfor
+00004a60: 6d65 7220 7061 7065 722e 0a20 2020 2020  mer paper..     
+00004a70: 2020 2061 7474 656e 7469 6f6e 5f70 726f     attention_pro
+00004a80: 6273 5f64 726f 7070 6564 203d 2073 656c  bs_dropped = sel
+00004a90: 662e 6472 6f70 6f75 7428 6174 7465 6e74  f.dropout(attent
+00004aa0: 696f 6e5f 7072 6f62 7329 0a0a 2020 2020  ion_probs)..    
+00004ab0: 2020 2020 2320 4d61 736b 2068 6561 6473      # Mask heads
+00004ac0: 2069 6620 7765 2077 616e 7420 746f 0a20   if we want to. 
+00004ad0: 2020 2020 2020 2069 6620 6865 6164 5f6d         if head_m
+00004ae0: 6173 6b20 6973 206e 6f74 204e 6f6e 653a  ask is not None:
+00004af0: 0a20 2020 2020 2020 2020 2020 2061 7474  .            att
+00004b00: 656e 7469 6f6e 5f70 726f 6273 5f64 726f  ention_probs_dro
+00004b10: 7070 6564 203d 2061 7474 656e 7469 6f6e  pped = attention
+00004b20: 5f70 726f 6273 5f64 726f 7070 6564 202a  _probs_dropped *
+00004b30: 2068 6561 645f 6d61 736b 0a0a 2020 2020   head_mask..    
+00004b40: 2020 2020 636f 6e74 6578 745f 6c61 7965      context_laye
+00004b50: 7220 3d20 746f 7263 682e 6d61 746d 756c  r = torch.matmul
+00004b60: 2861 7474 656e 7469 6f6e 5f70 726f 6273  (attention_probs
+00004b70: 5f64 726f 7070 6564 2c20 7661 6c75 655f  _dropped, value_
+00004b80: 6c61 7965 7229 0a0a 2020 2020 2020 2020  layer)..        
+00004b90: 636f 6e74 6578 745f 6c61 7965 7220 3d20  context_layer = 
+00004ba0: 636f 6e74 6578 745f 6c61 7965 722e 7065  context_layer.pe
+00004bb0: 726d 7574 6528 302c 2032 2c20 312c 2033  rmute(0, 2, 1, 3
+00004bc0: 292e 636f 6e74 6967 756f 7573 2829 0a20  ).contiguous(). 
+00004bd0: 2020 2020 2020 206e 6577 5f63 6f6e 7465         new_conte
+00004be0: 7874 5f6c 6179 6572 5f73 6861 7065 203d  xt_layer_shape =
+00004bf0: 2063 6f6e 7465 7874 5f6c 6179 6572 2e73   context_layer.s
+00004c00: 697a 6528 295b 3a2d 325d 202b 2028 0a20  ize()[:-2] + (. 
+00004c10: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00004c20: 616c 6c5f 6865 6164 5f73 697a 652c 2029  all_head_size, )
+00004c30: 0a20 2020 2020 2020 2063 6f6e 7465 7874  .        context
+00004c40: 5f6c 6179 6572 203d 2063 6f6e 7465 7874  _layer = context
+00004c50: 5f6c 6179 6572 2e76 6965 7728 2a6e 6577  _layer.view(*new
+00004c60: 5f63 6f6e 7465 7874 5f6c 6179 6572 5f73  _context_layer_s
+00004c70: 6861 7065 290a 0a20 2020 2020 2020 206f  hape)..        o
+00004c80: 7574 7075 7473 203d 2028 636f 6e74 6578  utputs = (contex
+00004c90: 745f 6c61 7965 722c 0a20 2020 2020 2020  t_layer,.       
+00004ca0: 2020 2020 2020 2020 2020 2020 6174 7465              atte
+00004cb0: 6e74 696f 6e5f 7072 6f62 7329 2069 6620  ntion_probs) if 
+00004cc0: 6f75 7470 7574 5f61 7474 656e 7469 6f6e  output_attention
+00004cd0: 7320 656c 7365 2028 636f 6e74 6578 745f  s else (context_
+00004ce0: 6c61 7965 722c 2029 0a0a 2020 2020 2020  layer, )..      
+00004cf0: 2020 6f75 7470 7574 7320 3d20 6f75 7470    outputs = outp
+00004d00: 7574 7320 2b20 2870 6173 745f 6b65 795f  uts + (past_key_
+00004d10: 7661 6c75 652c 2029 0a20 2020 2020 2020  value, ).       
+00004d20: 2072 6574 7572 6e20 6f75 7470 7574 730a   return outputs.
+00004d30: 0a0a 636c 6173 7320 4265 7274 5365 6c66  ..class BertSelf
+00004d40: 4f75 7470 7574 286e 6e2e 4d6f 6475 6c65  Output(nn.Module
+00004d50: 293a 0a0a 2020 2020 6465 6620 5f5f 696e  ):..    def __in
+00004d60: 6974 5f5f 2873 656c 662c 2063 6f6e 6669  it__(self, confi
+00004d70: 6729 3a0a 2020 2020 2020 2020 7375 7065  g):.        supe
+00004d80: 7228 292e 5f5f 696e 6974 5f5f 2829 0a20  r().__init__(). 
+00004d90: 2020 2020 2020 2073 656c 662e 6465 6e73         self.dens
+00004da0: 6520 3d20 6e6e 2e4c 696e 6561 7228 636f  e = nn.Linear(co
+00004db0: 6e66 6967 2e68 6964 6465 6e5f 7369 7a65  nfig.hidden_size
+00004dc0: 2c20 636f 6e66 6967 2e68 6964 6465 6e5f  , config.hidden_
+00004dd0: 7369 7a65 290a 2020 2020 2020 2020 7365  size).        se
+00004de0: 6c66 2e4c 6179 6572 4e6f 726d 203d 206e  lf.LayerNorm = n
+00004df0: 6e2e 4c61 7965 724e 6f72 6d28 0a20 2020  n.LayerNorm(.   
+00004e00: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
+00004e10: 6869 6464 656e 5f73 697a 652c 2065 7073  hidden_size, eps
+00004e20: 3d63 6f6e 6669 672e 6c61 7965 725f 6e6f  =config.layer_no
+00004e30: 726d 5f65 7073 290a 2020 2020 2020 2020  rm_eps).        
+00004e40: 7365 6c66 2e64 726f 706f 7574 203d 206e  self.dropout = n
+00004e50: 6e2e 4472 6f70 6f75 7428 636f 6e66 6967  n.Dropout(config
+00004e60: 2e68 6964 6465 6e5f 6472 6f70 6f75 745f  .hidden_dropout_
+00004e70: 7072 6f62 290a 0a20 2020 2064 6566 2066  prob)..    def f
+00004e80: 6f72 7761 7264 2873 656c 662c 2068 6964  orward(self, hid
+00004e90: 6465 6e5f 7374 6174 6573 2c20 696e 7075  den_states, inpu
+00004ea0: 745f 7465 6e73 6f72 293a 0a20 2020 2020  t_tensor):.     
+00004eb0: 2020 2068 6964 6465 6e5f 7374 6174 6573     hidden_states
+00004ec0: 203d 2073 656c 662e 6465 6e73 6528 6869   = self.dense(hi
+00004ed0: 6464 656e 5f73 7461 7465 7329 0a20 2020  dden_states).   
+00004ee0: 2020 2020 2068 6964 6465 6e5f 7374 6174       hidden_stat
+00004ef0: 6573 203d 2073 656c 662e 6472 6f70 6f75  es = self.dropou
+00004f00: 7428 6869 6464 656e 5f73 7461 7465 7329  t(hidden_states)
+00004f10: 0a20 2020 2020 2020 2068 6964 6465 6e5f  .        hidden_
+00004f20: 7374 6174 6573 203d 2073 656c 662e 4c61  states = self.La
+00004f30: 7965 724e 6f72 6d28 6869 6464 656e 5f73  yerNorm(hidden_s
+00004f40: 7461 7465 7320 2b20 696e 7075 745f 7465  tates + input_te
+00004f50: 6e73 6f72 290a 2020 2020 2020 2020 7265  nsor).        re
+00004f60: 7475 726e 2068 6964 6465 6e5f 7374 6174  turn hidden_stat
+00004f70: 6573 0a0a 0a63 6c61 7373 2042 6572 7441  es...class BertA
+00004f80: 7474 656e 7469 6f6e 286e 6e2e 4d6f 6475  ttention(nn.Modu
+00004f90: 6c65 293a 0a0a 2020 2020 6465 6620 5f5f  le):..    def __
+00004fa0: 696e 6974 5f5f 2873 656c 662c 2063 6f6e  init__(self, con
+00004fb0: 6669 672c 2069 735f 6372 6f73 735f 6174  fig, is_cross_at
+00004fc0: 7465 6e74 696f 6e3d 4661 6c73 6529 3a0a  tention=False):.
+00004fd0: 2020 2020 2020 2020 7375 7065 7228 292e          super().
+00004fe0: 5f5f 696e 6974 5f5f 2829 0a20 2020 2020  __init__().     
+00004ff0: 2020 2073 656c 662e 7365 6c66 203d 2042     self.self = B
+00005000: 6572 7453 656c 6641 7474 656e 7469 6f6e  ertSelfAttention
+00005010: 2863 6f6e 6669 672c 2069 735f 6372 6f73  (config, is_cros
+00005020: 735f 6174 7465 6e74 696f 6e29 0a20 2020  s_attention).   
+00005030: 2020 2020 2073 656c 662e 6f75 7470 7574       self.output
+00005040: 203d 2042 6572 7453 656c 664f 7574 7075   = BertSelfOutpu
+00005050: 7428 636f 6e66 6967 290a 2020 2020 2020  t(config).      
+00005060: 2020 7365 6c66 2e70 7275 6e65 645f 6865    self.pruned_he
+00005070: 6164 7320 3d20 7365 7428 290a 0a20 2020  ads = set()..   
+00005080: 2064 6566 2070 7275 6e65 5f68 6561 6473   def prune_heads
+00005090: 2873 656c 662c 2068 6561 6473 293a 0a20  (self, heads):. 
+000050a0: 2020 2020 2020 2069 6620 6c65 6e28 6865         if len(he
+000050b0: 6164 7329 203d 3d20 303a 0a20 2020 2020  ads) == 0:.     
+000050c0: 2020 2020 2020 2072 6574 7572 6e0a 2020         return.  
+000050d0: 2020 2020 2020 6865 6164 732c 2069 6e64        heads, ind
+000050e0: 6578 203d 2066 696e 645f 7072 756e 6561  ex = find_prunea
+000050f0: 626c 655f 6865 6164 735f 616e 645f 696e  ble_heads_and_in
+00005100: 6469 6365 7328 0a20 2020 2020 2020 2020  dices(.         
+00005110: 2020 2068 6561 6473 2c20 7365 6c66 2e73     heads, self.s
+00005120: 656c 662e 6e75 6d5f 6174 7465 6e74 696f  elf.num_attentio
+00005130: 6e5f 6865 6164 732c 0a20 2020 2020 2020  n_heads,.       
+00005140: 2020 2020 2073 656c 662e 7365 6c66 2e61       self.self.a
+00005150: 7474 656e 7469 6f6e 5f68 6561 645f 7369  ttention_head_si
+00005160: 7a65 2c20 7365 6c66 2e70 7275 6e65 645f  ze, self.pruned_
+00005170: 6865 6164 7329 0a0a 2020 2020 2020 2020  heads)..        
+00005180: 2320 5072 756e 6520 6c69 6e65 6172 206c  # Prune linear l
+00005190: 6179 6572 730a 2020 2020 2020 2020 7365  ayers.        se
+000051a0: 6c66 2e73 656c 662e 7175 6572 7920 3d20  lf.self.query = 
+000051b0: 7072 756e 655f 6c69 6e65 6172 5f6c 6179  prune_linear_lay
+000051c0: 6572 2873 656c 662e 7365 6c66 2e71 7565  er(self.self.que
+000051d0: 7279 2c20 696e 6465 7829 0a20 2020 2020  ry, index).     
+000051e0: 2020 2073 656c 662e 7365 6c66 2e6b 6579     self.self.key
+000051f0: 203d 2070 7275 6e65 5f6c 696e 6561 725f   = prune_linear_
+00005200: 6c61 7965 7228 7365 6c66 2e73 656c 662e  layer(self.self.
+00005210: 6b65 792c 2069 6e64 6578 290a 2020 2020  key, index).    
+00005220: 2020 2020 7365 6c66 2e73 656c 662e 7661      self.self.va
+00005230: 6c75 6520 3d20 7072 756e 655f 6c69 6e65  lue = prune_line
+00005240: 6172 5f6c 6179 6572 2873 656c 662e 7365  ar_layer(self.se
+00005250: 6c66 2e76 616c 7565 2c20 696e 6465 7829  lf.value, index)
+00005260: 0a20 2020 2020 2020 2073 656c 662e 6f75  .        self.ou
+00005270: 7470 7574 2e64 656e 7365 203d 2070 7275  tput.dense = pru
+00005280: 6e65 5f6c 696e 6561 725f 6c61 7965 7228  ne_linear_layer(
+00005290: 7365 6c66 2e6f 7574 7075 742e 6465 6e73  self.output.dens
+000052a0: 652c 2069 6e64 6578 2c20 6469 6d3d 3129  e, index, dim=1)
+000052b0: 0a0a 2020 2020 2020 2020 2320 5570 6461  ..        # Upda
+000052c0: 7465 2068 7970 6572 2070 6172 616d 7320  te hyper params 
+000052d0: 616e 6420 7374 6f72 6520 7072 756e 6564  and store pruned
+000052e0: 2068 6561 6473 0a20 2020 2020 2020 2073   heads.        s
+000052f0: 656c 662e 7365 6c66 2e6e 756d 5f61 7474  elf.self.num_att
+00005300: 656e 7469 6f6e 5f68 6561 6473 203d 2073  ention_heads = s
+00005310: 656c 662e 7365 6c66 2e6e 756d 5f61 7474  elf.self.num_att
+00005320: 656e 7469 6f6e 5f68 6561 6473 202d 206c  ention_heads - l
+00005330: 656e 280a 2020 2020 2020 2020 2020 2020  en(.            
+00005340: 6865 6164 7329 0a20 2020 2020 2020 2073  heads).        s
+00005350: 656c 662e 7365 6c66 2e61 6c6c 5f68 6561  elf.self.all_hea
+00005360: 645f 7369 7a65 203d 2073 656c 662e 7365  d_size = self.se
+00005370: 6c66 2e61 7474 656e 7469 6f6e 5f68 6561  lf.attention_hea
+00005380: 645f 7369 7a65 202a 2073 656c 662e 7365  d_size * self.se
+00005390: 6c66 2e6e 756d 5f61 7474 656e 7469 6f6e  lf.num_attention
+000053a0: 5f68 6561 6473 0a20 2020 2020 2020 2073  _heads.        s
+000053b0: 656c 662e 7072 756e 6564 5f68 6561 6473  elf.pruned_heads
+000053c0: 203d 2073 656c 662e 7072 756e 6564 5f68   = self.pruned_h
+000053d0: 6561 6473 2e75 6e69 6f6e 2868 6561 6473  eads.union(heads
+000053e0: 290a 0a20 2020 2064 6566 2066 6f72 7761  )..    def forwa
+000053f0: 7264 280a 2020 2020 2020 2020 7365 6c66  rd(.        self
+00005400: 2c0a 2020 2020 2020 2020 6869 6464 656e  ,.        hidden
+00005410: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
+00005420: 2061 7474 656e 7469 6f6e 5f6d 6173 6b3d   attention_mask=
+00005430: 4e6f 6e65 2c0a 2020 2020 2020 2020 6865  None,.        he
+00005440: 6164 5f6d 6173 6b3d 4e6f 6e65 2c0a 2020  ad_mask=None,.  
+00005450: 2020 2020 2020 656e 636f 6465 725f 6869        encoder_hi
+00005460: 6464 656e 5f73 7461 7465 733d 4e6f 6e65  dden_states=None
+00005470: 2c0a 2020 2020 2020 2020 656e 636f 6465  ,.        encode
+00005480: 725f 6174 7465 6e74 696f 6e5f 6d61 736b  r_attention_mask
+00005490: 3d4e 6f6e 652c 0a20 2020 2020 2020 2070  =None,.        p
+000054a0: 6173 745f 6b65 795f 7661 6c75 653d 4e6f  ast_key_value=No
+000054b0: 6e65 2c0a 2020 2020 2020 2020 6f75 7470  ne,.        outp
+000054c0: 7574 5f61 7474 656e 7469 6f6e 733d 4661  ut_attentions=Fa
+000054d0: 6c73 652c 0a20 2020 2029 3a0a 2020 2020  lse,.    ):.    
+000054e0: 2020 2020 7365 6c66 5f6f 7574 7075 7473      self_outputs
+000054f0: 203d 2073 656c 662e 7365 6c66 280a 2020   = self.self(.  
+00005500: 2020 2020 2020 2020 2020 6869 6464 656e            hidden
+00005510: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
+00005520: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
+00005530: 6173 6b2c 0a20 2020 2020 2020 2020 2020  ask,.           
+00005540: 2068 6561 645f 6d61 736b 2c0a 2020 2020   head_mask,.    
+00005550: 2020 2020 2020 2020 656e 636f 6465 725f          encoder_
+00005560: 6869 6464 656e 5f73 7461 7465 732c 0a20  hidden_states,. 
+00005570: 2020 2020 2020 2020 2020 2065 6e63 6f64             encod
+00005580: 6572 5f61 7474 656e 7469 6f6e 5f6d 6173  er_attention_mas
+00005590: 6b2c 0a20 2020 2020 2020 2020 2020 2070  k,.            p
+000055a0: 6173 745f 6b65 795f 7661 6c75 652c 0a20  ast_key_value,. 
+000055b0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+000055c0: 745f 6174 7465 6e74 696f 6e73 2c0a 2020  t_attentions,.  
+000055d0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+000055e0: 6174 7465 6e74 696f 6e5f 6f75 7470 7574  attention_output
+000055f0: 203d 2073 656c 662e 6f75 7470 7574 2873   = self.output(s
+00005600: 656c 665f 6f75 7470 7574 735b 305d 2c20  elf_outputs[0], 
+00005610: 6869 6464 656e 5f73 7461 7465 7329 0a20  hidden_states). 
+00005620: 2020 2020 2020 206f 7574 7075 7473 203d         outputs =
+00005630: 2028 6174 7465 6e74 696f 6e5f 6f75 7470   (attention_outp
+00005640: 7574 2c0a 2020 2020 2020 2020 2020 2020  ut,.            
+00005650: 2020 2020 2020 2029 202b 2073 656c 665f         ) + self_
+00005660: 6f75 7470 7574 735b 313a 5d20 2023 2061  outputs[1:]  # a
+00005670: 6464 2061 7474 656e 7469 6f6e 7320 6966  dd attentions if
+00005680: 2077 6520 6f75 7470 7574 2074 6865 6d0a   we output them.
+00005690: 2020 2020 2020 2020 7265 7475 726e 206f          return o
+000056a0: 7574 7075 7473 0a0a 0a63 6c61 7373 2042  utputs...class B
+000056b0: 6572 7449 6e74 6572 6d65 6469 6174 6528  ertIntermediate(
+000056c0: 6e6e 2e4d 6f64 756c 6529 3a0a 0a20 2020  nn.Module):..   
+000056d0: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
+000056e0: 6c66 2c20 636f 6e66 6967 293a 0a20 2020  lf, config):.   
+000056f0: 2020 2020 2073 7570 6572 2829 2e5f 5f69       super().__i
+00005700: 6e69 745f 5f28 290a 2020 2020 2020 2020  nit__().        
+00005710: 7365 6c66 2e64 656e 7365 203d 206e 6e2e  self.dense = nn.
+00005720: 4c69 6e65 6172 2863 6f6e 6669 672e 6869  Linear(config.hi
+00005730: 6464 656e 5f73 697a 652c 2063 6f6e 6669  dden_size, confi
+00005740: 672e 696e 7465 726d 6564 6961 7465 5f73  g.intermediate_s
+00005750: 697a 6529 0a20 2020 2020 2020 2069 6620  ize).        if 
+00005760: 6973 696e 7374 616e 6365 2863 6f6e 6669  isinstance(confi
+00005770: 672e 6869 6464 656e 5f61 6374 2c20 7374  g.hidden_act, st
+00005780: 7229 3a0a 2020 2020 2020 2020 2020 2020  r):.            
+00005790: 7365 6c66 2e69 6e74 6572 6d65 6469 6174  self.intermediat
+000057a0: 655f 6163 745f 666e 203d 2041 4354 3246  e_act_fn = ACT2F
+000057b0: 4e5b 636f 6e66 6967 2e68 6964 6465 6e5f  N[config.hidden_
+000057c0: 6163 745d 0a20 2020 2020 2020 2065 6c73  act].        els
+000057d0: 653a 0a20 2020 2020 2020 2020 2020 2073  e:.            s
+000057e0: 656c 662e 696e 7465 726d 6564 6961 7465  elf.intermediate
+000057f0: 5f61 6374 5f66 6e20 3d20 636f 6e66 6967  _act_fn = config
+00005800: 2e68 6964 6465 6e5f 6163 740a 0a20 2020  .hidden_act..   
+00005810: 2064 6566 2066 6f72 7761 7264 2873 656c   def forward(sel
+00005820: 662c 2068 6964 6465 6e5f 7374 6174 6573  f, hidden_states
+00005830: 293a 0a20 2020 2020 2020 2068 6964 6465  ):.        hidde
+00005840: 6e5f 7374 6174 6573 203d 2073 656c 662e  n_states = self.
+00005850: 6465 6e73 6528 6869 6464 656e 5f73 7461  dense(hidden_sta
+00005860: 7465 7329 0a20 2020 2020 2020 2068 6964  tes).        hid
+00005870: 6465 6e5f 7374 6174 6573 203d 2073 656c  den_states = sel
+00005880: 662e 696e 7465 726d 6564 6961 7465 5f61  f.intermediate_a
+00005890: 6374 5f66 6e28 6869 6464 656e 5f73 7461  ct_fn(hidden_sta
+000058a0: 7465 7329 0a20 2020 2020 2020 2072 6574  tes).        ret
+000058b0: 7572 6e20 6869 6464 656e 5f73 7461 7465  urn hidden_state
+000058c0: 730a 0a0a 636c 6173 7320 4265 7274 4f75  s...class BertOu
+000058d0: 7470 7574 286e 6e2e 4d6f 6475 6c65 293a  tput(nn.Module):
+000058e0: 0a0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+000058f0: 5f5f 2873 656c 662c 2063 6f6e 6669 6729  __(self, config)
+00005900: 3a0a 2020 2020 2020 2020 7375 7065 7228  :.        super(
+00005910: 292e 5f5f 696e 6974 5f5f 2829 0a20 2020  ).__init__().   
+00005920: 2020 2020 2073 656c 662e 6465 6e73 6520       self.dense 
+00005930: 3d20 6e6e 2e4c 696e 6561 7228 636f 6e66  = nn.Linear(conf
+00005940: 6967 2e69 6e74 6572 6d65 6469 6174 655f  ig.intermediate_
+00005950: 7369 7a65 2c20 636f 6e66 6967 2e68 6964  size, config.hid
+00005960: 6465 6e5f 7369 7a65 290a 2020 2020 2020  den_size).      
+00005970: 2020 7365 6c66 2e4c 6179 6572 4e6f 726d    self.LayerNorm
+00005980: 203d 206e 6e2e 4c61 7965 724e 6f72 6d28   = nn.LayerNorm(
+00005990: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
+000059a0: 6669 672e 6869 6464 656e 5f73 697a 652c  fig.hidden_size,
+000059b0: 2065 7073 3d63 6f6e 6669 672e 6c61 7965   eps=config.laye
+000059c0: 725f 6e6f 726d 5f65 7073 290a 2020 2020  r_norm_eps).    
+000059d0: 2020 2020 7365 6c66 2e64 726f 706f 7574      self.dropout
+000059e0: 203d 206e 6e2e 4472 6f70 6f75 7428 636f   = nn.Dropout(co
+000059f0: 6e66 6967 2e68 6964 6465 6e5f 6472 6f70  nfig.hidden_drop
+00005a00: 6f75 745f 7072 6f62 290a 0a20 2020 2064  out_prob)..    d
+00005a10: 6566 2066 6f72 7761 7264 2873 656c 662c  ef forward(self,
+00005a20: 2068 6964 6465 6e5f 7374 6174 6573 2c20   hidden_states, 
+00005a30: 696e 7075 745f 7465 6e73 6f72 293a 0a20  input_tensor):. 
+00005a40: 2020 2020 2020 2068 6964 6465 6e5f 7374         hidden_st
+00005a50: 6174 6573 203d 2073 656c 662e 6465 6e73  ates = self.dens
+00005a60: 6528 6869 6464 656e 5f73 7461 7465 7329  e(hidden_states)
+00005a70: 0a20 2020 2020 2020 2068 6964 6465 6e5f  .        hidden_
+00005a80: 7374 6174 6573 203d 2073 656c 662e 6472  states = self.dr
+00005a90: 6f70 6f75 7428 6869 6464 656e 5f73 7461  opout(hidden_sta
+00005aa0: 7465 7329 0a20 2020 2020 2020 2068 6964  tes).        hid
+00005ab0: 6465 6e5f 7374 6174 6573 203d 2073 656c  den_states = sel
+00005ac0: 662e 4c61 7965 724e 6f72 6d28 6869 6464  f.LayerNorm(hidd
+00005ad0: 656e 5f73 7461 7465 7320 2b20 696e 7075  en_states + inpu
+00005ae0: 745f 7465 6e73 6f72 290a 2020 2020 2020  t_tensor).      
+00005af0: 2020 7265 7475 726e 2068 6964 6465 6e5f    return hidden_
+00005b00: 7374 6174 6573 0a0a 0a63 6c61 7373 2042  states...class B
+00005b10: 6572 744c 6179 6572 286e 6e2e 4d6f 6475  ertLayer(nn.Modu
+00005b20: 6c65 293a 0a0a 2020 2020 6465 6620 5f5f  le):..    def __
+00005b30: 696e 6974 5f5f 2873 656c 662c 2063 6f6e  init__(self, con
+00005b40: 6669 672c 206c 6179 6572 5f6e 756d 293a  fig, layer_num):
+00005b50: 0a20 2020 2020 2020 2073 7570 6572 2829  .        super()
+00005b60: 2e5f 5f69 6e69 745f 5f28 290a 2020 2020  .__init__().    
+00005b70: 2020 2020 7365 6c66 2e63 6f6e 6669 6720      self.config 
+00005b80: 3d20 636f 6e66 6967 0a20 2020 2020 2020  = config.       
+00005b90: 2073 656c 662e 6368 756e 6b5f 7369 7a65   self.chunk_size
+00005ba0: 5f66 6565 645f 666f 7277 6172 6420 3d20  _feed_forward = 
+00005bb0: 636f 6e66 6967 2e63 6875 6e6b 5f73 697a  config.chunk_siz
+00005bc0: 655f 6665 6564 5f66 6f72 7761 7264 0a20  e_feed_forward. 
+00005bd0: 2020 2020 2020 2073 656c 662e 7365 715f         self.seq_
+00005be0: 6c65 6e5f 6469 6d20 3d20 310a 2020 2020  len_dim = 1.    
+00005bf0: 2020 2020 7365 6c66 2e61 7474 656e 7469      self.attenti
+00005c00: 6f6e 203d 2042 6572 7441 7474 656e 7469  on = BertAttenti
+00005c10: 6f6e 2863 6f6e 6669 6729 0a0a 2020 2020  on(config)..    
+00005c20: 2020 2020 7365 6c66 2e68 6173 5f63 726f      self.has_cro
+00005c30: 7373 5f61 7474 656e 7469 6f6e 203d 2028  ss_attention = (
+00005c40: 6c61 7965 725f 6e75 6d20 3e3d 2063 6f6e  layer_num >= con
+00005c50: 6669 672e 6675 7369 6f6e 5f6c 6179 6572  fig.fusion_layer
+00005c60: 290a 2020 2020 2020 2020 6966 2073 656c  ).        if sel
+00005c70: 662e 6861 735f 6372 6f73 735f 6174 7465  f.has_cross_atte
+00005c80: 6e74 696f 6e3a 0a20 2020 2020 2020 2020  ntion:.         
+00005c90: 2020 2073 656c 662e 6c61 7965 725f 6e75     self.layer_nu
+00005ca0: 6d20 3d20 6c61 7965 725f 6e75 6d0a 2020  m = layer_num.  
+00005cb0: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
+00005cc0: 726f 7373 6174 7465 6e74 696f 6e20 3d20  rossattention = 
+00005cd0: 4265 7274 4174 7465 6e74 696f 6e28 0a20  BertAttention(. 
+00005ce0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00005cf0: 6f6e 6669 672c 2069 735f 6372 6f73 735f  onfig, is_cross_
+00005d00: 6174 7465 6e74 696f 6e3d 5472 7565 290a  attention=True).
+00005d10: 2020 2020 2020 2020 7365 6c66 2e69 6e74          self.int
+00005d20: 6572 6d65 6469 6174 6520 3d20 4265 7274  ermediate = Bert
+00005d30: 496e 7465 726d 6564 6961 7465 2863 6f6e  Intermediate(con
+00005d40: 6669 6729 0a20 2020 2020 2020 2073 656c  fig).        sel
+00005d50: 662e 6f75 7470 7574 203d 2042 6572 744f  f.output = BertO
+00005d60: 7574 7075 7428 636f 6e66 6967 290a 0a20  utput(config).. 
+00005d70: 2020 2064 6566 2066 6f72 7761 7264 280a     def forward(.
+00005d80: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00005d90: 2020 2020 2020 6869 6464 656e 5f73 7461        hidden_sta
+00005da0: 7465 732c 0a20 2020 2020 2020 2061 7474  tes,.        att
+00005db0: 656e 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65  ention_mask=None
+00005dc0: 2c0a 2020 2020 2020 2020 6865 6164 5f6d  ,.        head_m
+00005dd0: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
+00005de0: 2020 656e 636f 6465 725f 6869 6464 656e    encoder_hidden
+00005df0: 5f73 7461 7465 733d 4e6f 6e65 2c0a 2020  _states=None,.  
+00005e00: 2020 2020 2020 656e 636f 6465 725f 6174        encoder_at
+00005e10: 7465 6e74 696f 6e5f 6d61 736b 3d4e 6f6e  tention_mask=Non
+00005e20: 652c 0a20 2020 2020 2020 2070 6173 745f  e,.        past_
+00005e30: 6b65 795f 7661 6c75 653d 4e6f 6e65 2c0a  key_value=None,.
+00005e40: 2020 2020 2020 2020 6f75 7470 7574 5f61          output_a
+00005e50: 7474 656e 7469 6f6e 733d 4661 6c73 652c  ttentions=False,
+00005e60: 0a20 2020 2029 3a0a 2020 2020 2020 2020  .    ):.        
+00005e70: 2320 6465 636f 6465 7220 756e 692d 6469  # decoder uni-di
+00005e80: 7265 6374 696f 6e61 6c20 7365 6c66 2d61  rectional self-a
+00005e90: 7474 656e 7469 6f6e 2063 6163 6865 6420  ttention cached 
+00005ea0: 6b65 792f 7661 6c75 6573 2074 7570 6c65  key/values tuple
+00005eb0: 2069 7320 6174 0a20 2020 2020 2020 2023   is at.        #
+00005ec0: 2070 6f73 6974 696f 6e73 2031 2c32 0a20   positions 1,2. 
+00005ed0: 2020 2020 2020 2073 656c 665f 6174 746e         self_attn
+00005ee0: 5f70 6173 745f 6b65 795f 7661 6c75 6520  _past_key_value 
+00005ef0: 3d20 7061 7374 5f6b 6579 5f76 616c 7565  = past_key_value
+00005f00: 5b3a 0a20 2020 2020 2020 2020 2020 2020  [:.             
+00005f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005f30: 2020 2020 2032 5d20 6966 2070 6173 745f       2] if past_
+00005f40: 6b65 795f 7661 6c75 6520 6973 206e 6f74  key_value is not
+00005f50: 204e 6f6e 6520 656c 7365 204e 6f6e 650a   None else None.
+00005f60: 2020 2020 2020 2020 7365 6c66 5f61 7474          self_att
+00005f70: 656e 7469 6f6e 5f6f 7574 7075 7473 203d  ention_outputs =
+00005f80: 2073 656c 662e 6174 7465 6e74 696f 6e28   self.attention(
+00005f90: 0a20 2020 2020 2020 2020 2020 2068 6964  .            hid
+00005fa0: 6465 6e5f 7374 6174 6573 2c0a 2020 2020  den_states,.    
+00005fb0: 2020 2020 2020 2020 6174 7465 6e74 696f          attentio
+00005fc0: 6e5f 6d61 736b 2c0a 2020 2020 2020 2020  n_mask,.        
+00005fd0: 2020 2020 6865 6164 5f6d 6173 6b2c 0a20      head_mask,. 
+00005fe0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+00005ff0: 745f 6174 7465 6e74 696f 6e73 3d6f 7574  t_attentions=out
+00006000: 7075 745f 6174 7465 6e74 696f 6e73 2c0a  put_attentions,.
+00006010: 2020 2020 2020 2020 2020 2020 7061 7374              past
+00006020: 5f6b 6579 5f76 616c 7565 3d73 656c 665f  _key_value=self_
+00006030: 6174 746e 5f70 6173 745f 6b65 795f 7661  attn_past_key_va
+00006040: 6c75 652c 0a20 2020 2020 2020 2029 0a20  lue,.        ). 
+00006050: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
+00006060: 5f6f 7574 7075 7420 3d20 7365 6c66 5f61  _output = self_a
+00006070: 7474 656e 7469 6f6e 5f6f 7574 7075 7473  ttention_outputs
+00006080: 5b30 5d0a 0a20 2020 2020 2020 206f 7574  [0]..        out
+00006090: 7075 7473 203d 2073 656c 665f 6174 7465  puts = self_atte
+000060a0: 6e74 696f 6e5f 6f75 7470 7574 735b 313a  ntion_outputs[1:
+000060b0: 2d31 5d0a 2020 2020 2020 2020 7072 6573  -1].        pres
+000060c0: 656e 745f 6b65 795f 7661 6c75 6520 3d20  ent_key_value = 
+000060d0: 7365 6c66 5f61 7474 656e 7469 6f6e 5f6f  self_attention_o
+000060e0: 7574 7075 7473 5b2d 315d 0a0a 2020 2020  utputs[-1]..    
+000060f0: 2020 2020 6966 2073 656c 662e 6861 735f      if self.has_
+00006100: 6372 6f73 735f 6174 7465 6e74 696f 6e3a  cross_attention:
+00006110: 0a20 2020 2020 2020 2020 2020 2061 7373  .            ass
+00006120: 6572 7420 656e 636f 6465 725f 6869 6464  ert encoder_hidd
+00006130: 656e 5f73 7461 7465 7320 6973 206e 6f74  en_states is not
+00006140: 204e 6f6e 652c 2027 656e 636f 6465 725f   None, 'encoder_
+00006150: 6869 6464 656e 5f73 7461 7465 7320 6d75  hidden_states mu
+00006160: 7374 2062 6520 6769 7665 6e20 666f 7220  st be given for 
+00006170: 6372 6f73 732d 6174 7465 6e74 696f 6e20  cross-attention 
+00006180: 6c61 7965 7273 270a 0a20 2020 2020 2020  layers'..       
+00006190: 2020 2020 2069 6620 7479 7065 2865 6e63       if type(enc
+000061a0: 6f64 6572 5f68 6964 6465 6e5f 7374 6174  oder_hidden_stat
+000061b0: 6573 2920 3d3d 206c 6973 743a 0a20 2020  es) == list:.   
+000061c0: 2020 2020 2020 2020 2020 2020 2063 726f               cro
+000061d0: 7373 5f61 7474 656e 7469 6f6e 5f6f 7574  ss_attention_out
+000061e0: 7075 7473 203d 2073 656c 662e 6372 6f73  puts = self.cros
+000061f0: 7361 7474 656e 7469 6f6e 280a 2020 2020  sattention(.    
+00006200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006210: 6174 7465 6e74 696f 6e5f 6f75 7470 7574  attention_output
+00006220: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00006230: 2020 2020 2020 6174 7465 6e74 696f 6e5f        attention_
+00006240: 6d61 736b 2c0a 2020 2020 2020 2020 2020  mask,.          
+00006250: 2020 2020 2020 2020 2020 6865 6164 5f6d            head_m
+00006260: 6173 6b2c 0a20 2020 2020 2020 2020 2020  ask,.           
+00006270: 2020 2020 2020 2020 2065 6e63 6f64 6572           encoder
+00006280: 5f68 6964 6465 6e5f 7374 6174 6573 5b28  _hidden_states[(
+00006290: 7365 6c66 2e6c 6179 6572 5f6e 756d 0a20  self.layer_num. 
+000062a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000062b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000062c0: 2020 2020 2020 2020 2020 2d20 7365 6c66            - self
+000062d0: 2e63 6f6e 6669 672e 6675 7369 6f6e 5f6c  .config.fusion_l
+000062e0: 6179 6572 290a 2020 2020 2020 2020 2020  ayer).          
+000062f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006310: 2520 6c65 6e28 656e 636f 6465 725f 6869  % len(encoder_hi
+00006320: 6464 656e 5f73 7461 7465 7329 5d2c 0a20  dden_states)],. 
+00006330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006340: 2020 2065 6e63 6f64 6572 5f61 7474 656e     encoder_atten
+00006350: 7469 6f6e 5f6d 6173 6b5b 2873 656c 662e  tion_mask[(self.
+00006360: 6c61 7965 725f 6e75 6d0a 2020 2020 2020  layer_num.      
 00006370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006380: 656e 636f 6465 725f 6869 6464 656e 5f73  encoder_hidden_s
-00006390: 7461 7465 735b 2873 656c 662e 6c61 7965  tates[(self.laye
-000063a0: 725f 6e75 6d0a 2020 2020 2020 2020 2020  r_num.          
-000063b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006390: 2020 2020 2020 2d20 7365 6c66 2e63 6f6e        - self.con
+000063a0: 6669 672e 6675 7369 6f6e 5f6c 6179 6572  fig.fusion_layer
+000063b0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
 000063c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000063d0: 202d 2073 656c 662e 636f 6e66 6967 2e66   - self.config.f
-000063e0: 7573 696f 6e5f 6c61 7965 7229 0a20 2020  usion_layer).   
-000063f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000063d0: 2020 2020 2020 2020 2020 2020 2025 206c               % l
+000063e0: 656e 2865 6e63 6f64 6572 5f68 6964 6465  en(encoder_hidde
+000063f0: 6e5f 7374 6174 6573 295d 2c0a 2020 2020  n_states)],.    
 00006400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006410: 2020 2020 2020 2025 206c 656e 2865 6e63         % len(enc
-00006420: 6f64 6572 5f68 6964 6465 6e5f 7374 6174  oder_hidden_stat
-00006430: 6573 295d 2c0a 2020 2020 2020 2020 2020  es)],.          
-00006440: 2020 2020 2020 2020 2020 656e 636f 6465            encode
-00006450: 725f 6174 7465 6e74 696f 6e5f 6d61 736b  r_attention_mask
-00006460: 5b28 7365 6c66 2e6c 6179 6572 5f6e 756d  [(self.layer_num
-00006470: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006490: 2020 2020 2020 2020 2020 2020 202d 2073               - s
-000064a0: 656c 662e 636f 6e66 6967 2e66 7573 696f  elf.config.fusio
-000064b0: 6e5f 6c61 7965 7229 0a20 2020 2020 2020  n_layer).       
-000064c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000064d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000064e0: 2020 2020 2520 6c65 6e28 656e 636f 6465      % len(encode
-000064f0: 725f 6869 6464 656e 5f73 7461 7465 7329  r_hidden_states)
-00006500: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00006510: 2020 2020 2020 206f 7574 7075 745f 6174         output_at
-00006520: 7465 6e74 696f 6e73 3d6f 7574 7075 745f  tentions=output_
-00006530: 6174 7465 6e74 696f 6e73 2c0a 2020 2020  attentions,.    
-00006540: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-00006550: 2020 2020 2020 2020 2020 2020 2020 6174                at
-00006560: 7465 6e74 696f 6e5f 6f75 7470 7574 203d  tention_output =
-00006570: 2063 726f 7373 5f61 7474 656e 7469 6f6e   cross_attention
-00006580: 5f6f 7574 7075 7473 5b30 5d0a 2020 2020  _outputs[0].    
-00006590: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-000065a0: 7574 7320 3d20 6f75 7470 7574 7320 2b20  uts = outputs + 
-000065b0: 6372 6f73 735f 6174 7465 6e74 696f 6e5f  cross_attention_
-000065c0: 6f75 7470 7574 735b 313a 2d31 5d0a 0a20  outputs[1:-1].. 
-000065d0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-000065e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000065f0: 2063 726f 7373 5f61 7474 656e 7469 6f6e   cross_attention
-00006600: 5f6f 7574 7075 7473 203d 2073 656c 662e  _outputs = self.
-00006610: 6372 6f73 7361 7474 656e 7469 6f6e 280a  crossattention(.
-00006620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006410: 6f75 7470 7574 5f61 7474 656e 7469 6f6e  output_attention
+00006420: 733d 6f75 7470 7574 5f61 7474 656e 7469  s=output_attenti
+00006430: 6f6e 732c 0a20 2020 2020 2020 2020 2020  ons,.           
+00006440: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00006450: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
+00006460: 5f6f 7574 7075 7420 3d20 6372 6f73 735f  _output = cross_
+00006470: 6174 7465 6e74 696f 6e5f 6f75 7470 7574  attention_output
+00006480: 735b 305d 0a20 2020 2020 2020 2020 2020  s[0].           
+00006490: 2020 2020 206f 7574 7075 7473 203d 206f       outputs = o
+000064a0: 7574 7075 7473 202b 2063 726f 7373 5f61  utputs + cross_a
+000064b0: 7474 656e 7469 6f6e 5f6f 7574 7075 7473  ttention_outputs
+000064c0: 5b31 3a2d 315d 0a0a 2020 2020 2020 2020  [1:-1]..        
+000064d0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000064e0: 2020 2020 2020 2020 2020 6372 6f73 735f            cross_
+000064f0: 6174 7465 6e74 696f 6e5f 6f75 7470 7574  attention_output
+00006500: 7320 3d20 7365 6c66 2e63 726f 7373 6174  s = self.crossat
+00006510: 7465 6e74 696f 6e28 0a20 2020 2020 2020  tention(.       
+00006520: 2020 2020 2020 2020 2020 2020 2061 7474               att
+00006530: 656e 7469 6f6e 5f6f 7574 7075 742c 0a20  ention_output,. 
+00006540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006550: 2020 2061 7474 656e 7469 6f6e 5f6d 6173     attention_mas
+00006560: 6b2c 0a20 2020 2020 2020 2020 2020 2020  k,.             
+00006570: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
+00006580: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00006590: 2020 2020 2020 656e 636f 6465 725f 6869        encoder_hi
+000065a0: 6464 656e 5f73 7461 7465 732c 0a20 2020  dden_states,.   
+000065b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000065c0: 2065 6e63 6f64 6572 5f61 7474 656e 7469   encoder_attenti
+000065d0: 6f6e 5f6d 6173 6b2c 0a20 2020 2020 2020  on_mask,.       
+000065e0: 2020 2020 2020 2020 2020 2020 206f 7574               out
+000065f0: 7075 745f 6174 7465 6e74 696f 6e73 3d6f  put_attentions=o
+00006600: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
+00006610: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00006620: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
 00006630: 2020 2020 6174 7465 6e74 696f 6e5f 6f75      attention_ou
-00006640: 7470 7574 2c0a 2020 2020 2020 2020 2020  tput,.          
-00006650: 2020 2020 2020 2020 2020 6174 7465 6e74            attent
-00006660: 696f 6e5f 6d61 736b 2c0a 2020 2020 2020  ion_mask,.      
-00006670: 2020 2020 2020 2020 2020 2020 2020 6865                he
-00006680: 6164 5f6d 6173 6b2c 0a20 2020 2020 2020  ad_mask,.       
-00006690: 2020 2020 2020 2020 2020 2020 2065 6e63               enc
-000066a0: 6f64 6572 5f68 6964 6465 6e5f 7374 6174  oder_hidden_stat
-000066b0: 6573 2c0a 2020 2020 2020 2020 2020 2020  es,.            
-000066c0: 2020 2020 2020 2020 656e 636f 6465 725f          encoder_
-000066d0: 6174 7465 6e74 696f 6e5f 6d61 736b 2c0a  attention_mask,.
-000066e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000066f0: 2020 2020 6f75 7470 7574 5f61 7474 656e      output_atten
-00006700: 7469 6f6e 733d 6f75 7470 7574 5f61 7474  tions=output_att
-00006710: 656e 7469 6f6e 732c 0a20 2020 2020 2020  entions,.       
-00006720: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
-00006730: 2020 2020 2020 2020 2020 2061 7474 656e             atten
-00006740: 7469 6f6e 5f6f 7574 7075 7420 3d20 6372  tion_output = cr
-00006750: 6f73 735f 6174 7465 6e74 696f 6e5f 6f75  oss_attention_ou
-00006760: 7470 7574 735b 305d 0a20 2020 2020 2020  tputs[0].       
-00006770: 2020 2020 2020 2020 206f 7574 7075 7473           outputs
-00006780: 203d 206f 7574 7075 7473 202b 2063 726f   = outputs + cro
-00006790: 7373 5f61 7474 656e 7469 6f6e 5f6f 7574  ss_attention_out
-000067a0: 7075 7473 5b0a 2020 2020 2020 2020 2020  puts[.          
-000067b0: 2020 2020 2020 2020 2020 313a 0a20 2020            1:.   
-000067c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000067d0: 202d 315d 2020 2320 6164 6420 6372 6f73   -1]  # add cros
-000067e0: 7320 6174 7465 6e74 696f 6e73 2069 6620  s attentions if 
-000067f0: 7765 206f 7574 7075 7420 6174 7465 6e74  we output attent
-00006800: 696f 6e20 7765 6967 6874 730a 2020 2020  ion weights.    
-00006810: 2020 2020 6c61 7965 725f 6f75 7470 7574      layer_output
-00006820: 203d 2061 7070 6c79 5f63 6875 6e6b 696e   = apply_chunkin
-00006830: 675f 746f 5f66 6f72 7761 7264 2873 656c  g_to_forward(sel
-00006840: 662e 6665 6564 5f66 6f72 7761 7264 5f63  f.feed_forward_c
-00006850: 6875 6e6b 2c0a 2020 2020 2020 2020 2020  hunk,.          
-00006860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006880: 2020 2020 2020 2073 656c 662e 6368 756e         self.chun
-00006890: 6b5f 7369 7a65 5f66 6565 645f 666f 7277  k_size_feed_forw
-000068a0: 6172 642c 0a20 2020 2020 2020 2020 2020  ard,.           
-000068b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000068c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000068d0: 2020 2020 2020 7365 6c66 2e73 6571 5f6c        self.seq_l
-000068e0: 656e 5f64 696d 2c0a 2020 2020 2020 2020  en_dim,.        
-000068f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006910: 2020 2020 2020 2020 2061 7474 656e 7469           attenti
-00006920: 6f6e 5f6f 7574 7075 7429 0a20 2020 2020  on_output).     
-00006930: 2020 206f 7574 7075 7473 203d 2028 6c61     outputs = (la
-00006940: 7965 725f 6f75 7470 7574 2c20 2920 2b20  yer_output, ) + 
-00006950: 6f75 7470 7574 730a 0a20 2020 2020 2020  outputs..       
-00006960: 206f 7574 7075 7473 203d 206f 7574 7075   outputs = outpu
-00006970: 7473 202b 2028 7072 6573 656e 745f 6b65  ts + (present_ke
-00006980: 795f 7661 6c75 652c 2029 0a0a 2020 2020  y_value, )..    
-00006990: 2020 2020 7265 7475 726e 206f 7574 7075      return outpu
-000069a0: 7473 0a0a 2020 2020 6465 6620 6665 6564  ts..    def feed
-000069b0: 5f66 6f72 7761 7264 5f63 6875 6e6b 2873  _forward_chunk(s
-000069c0: 656c 662c 2061 7474 656e 7469 6f6e 5f6f  elf, attention_o
-000069d0: 7574 7075 7429 3a0a 2020 2020 2020 2020  utput):.        
-000069e0: 696e 7465 726d 6564 6961 7465 5f6f 7574  intermediate_out
-000069f0: 7075 7420 3d20 7365 6c66 2e69 6e74 6572  put = self.inter
-00006a00: 6d65 6469 6174 6528 6174 7465 6e74 696f  mediate(attentio
-00006a10: 6e5f 6f75 7470 7574 290a 2020 2020 2020  n_output).      
-00006a20: 2020 6c61 7965 725f 6f75 7470 7574 203d    layer_output =
-00006a30: 2073 656c 662e 6f75 7470 7574 2869 6e74   self.output(int
-00006a40: 6572 6d65 6469 6174 655f 6f75 7470 7574  ermediate_output
-00006a50: 2c20 6174 7465 6e74 696f 6e5f 6f75 7470  , attention_outp
-00006a60: 7574 290a 2020 2020 2020 2020 7265 7475  ut).        retu
-00006a70: 726e 206c 6179 6572 5f6f 7574 7075 740a  rn layer_output.
-00006a80: 0a0a 636c 6173 7320 4265 7274 456e 636f  ..class BertEnco
-00006a90: 6465 7228 6e6e 2e4d 6f64 756c 6529 3a0a  der(nn.Module):.
-00006aa0: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00006ab0: 5f28 7365 6c66 2c20 636f 6e66 6967 293a  _(self, config):
-00006ac0: 0a20 2020 2020 2020 2073 7570 6572 2829  .        super()
-00006ad0: 2e5f 5f69 6e69 745f 5f28 290a 2020 2020  .__init__().    
-00006ae0: 2020 2020 7365 6c66 2e63 6f6e 6669 6720      self.config 
-00006af0: 3d20 636f 6e66 6967 0a20 2020 2020 2020  = config.       
-00006b00: 2073 656c 662e 6c61 7965 7220 3d20 6e6e   self.layer = nn
-00006b10: 2e4d 6f64 756c 654c 6973 7428 0a20 2020  .ModuleList(.   
-00006b20: 2020 2020 2020 2020 205b 4265 7274 4c61           [BertLa
-00006b30: 7965 7228 636f 6e66 6967 2c20 6929 2066  yer(config, i) f
-00006b40: 6f72 2069 2069 6e20 7261 6e67 6528 636f  or i in range(co
-00006b50: 6e66 6967 2e6e 756d 5f68 6964 6465 6e5f  nfig.num_hidden_
-00006b60: 6c61 7965 7273 295d 290a 0a20 2020 2064  layers)])..    d
-00006b70: 6566 2066 6f72 7761 7264 280a 2020 2020  ef forward(.    
-00006b80: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
-00006b90: 2020 6869 6464 656e 5f73 7461 7465 732c    hidden_states,
-00006ba0: 0a20 2020 2020 2020 2061 7474 656e 7469  .        attenti
-00006bb0: 6f6e 5f6d 6173 6b3d 4e6f 6e65 2c0a 2020  on_mask=None,.  
-00006bc0: 2020 2020 2020 6865 6164 5f6d 6173 6b3d        head_mask=
-00006bd0: 4e6f 6e65 2c0a 2020 2020 2020 2020 656e  None,.        en
-00006be0: 636f 6465 725f 6869 6464 656e 5f73 7461  coder_hidden_sta
-00006bf0: 7465 733d 4e6f 6e65 2c0a 2020 2020 2020  tes=None,.      
-00006c00: 2020 656e 636f 6465 725f 6174 7465 6e74    encoder_attent
-00006c10: 696f 6e5f 6d61 736b 3d4e 6f6e 652c 0a20  ion_mask=None,. 
-00006c20: 2020 2020 2020 2070 6173 745f 6b65 795f         past_key_
-00006c30: 7661 6c75 6573 3d4e 6f6e 652c 0a20 2020  values=None,.   
-00006c40: 2020 2020 2075 7365 5f63 6163 6865 3d4e       use_cache=N
-00006c50: 6f6e 652c 0a20 2020 2020 2020 206f 7574  one,.        out
-00006c60: 7075 745f 6174 7465 6e74 696f 6e73 3d46  put_attentions=F
-00006c70: 616c 7365 2c0a 2020 2020 2020 2020 6f75  alse,.        ou
-00006c80: 7470 7574 5f68 6964 6465 6e5f 7374 6174  tput_hidden_stat
-00006c90: 6573 3d46 616c 7365 2c0a 2020 2020 2020  es=False,.      
-00006ca0: 2020 7265 7475 726e 5f64 6963 743d 5472    return_dict=Tr
-00006cb0: 7565 2c0a 2020 2020 2020 2020 6d6f 6465  ue,.        mode
-00006cc0: 3d27 6d75 6c74 695f 6d6f 6461 6c27 2c0a  ='multi_modal',.
-00006cd0: 2020 2020 293a 0a20 2020 2020 2020 2061      ):.        a
-00006ce0: 6c6c 5f68 6964 6465 6e5f 7374 6174 6573  ll_hidden_states
-00006cf0: 203d 2028 2920 6966 206f 7574 7075 745f   = () if output_
-00006d00: 6869 6464 656e 5f73 7461 7465 7320 656c  hidden_states el
-00006d10: 7365 204e 6f6e 650a 2020 2020 2020 2020  se None.        
-00006d20: 616c 6c5f 7365 6c66 5f61 7474 656e 7469  all_self_attenti
-00006d30: 6f6e 7320 3d20 2829 2069 6620 6f75 7470  ons = () if outp
-00006d40: 7574 5f61 7474 656e 7469 6f6e 7320 656c  ut_attentions el
-00006d50: 7365 204e 6f6e 650a 2020 2020 2020 2020  se None.        
-00006d60: 616c 6c5f 6372 6f73 735f 6174 7465 6e74  all_cross_attent
-00006d70: 696f 6e73 203d 2028 0a20 2020 2020 2020  ions = (.       
-00006d80: 2029 2069 6620 6f75 7470 7574 5f61 7474   ) if output_att
-00006d90: 656e 7469 6f6e 7320 616e 6420 7365 6c66  entions and self
-00006da0: 2e63 6f6e 6669 672e 6164 645f 6372 6f73  .config.add_cros
-00006db0: 735f 6174 7465 6e74 696f 6e20 656c 7365  s_attention else
-00006dc0: 204e 6f6e 650a 0a20 2020 2020 2020 206e   None..        n
-00006dd0: 6578 745f 6465 636f 6465 725f 6361 6368  ext_decoder_cach
-00006de0: 6520 3d20 2829 2069 6620 7573 655f 6361  e = () if use_ca
-00006df0: 6368 6520 656c 7365 204e 6f6e 650a 0a20  che else None.. 
-00006e00: 2020 2020 2020 2069 6620 6d6f 6465 203d         if mode =
-00006e10: 3d20 2774 6578 7427 3a0a 2020 2020 2020  = 'text':.      
-00006e20: 2020 2020 2020 7374 6172 745f 6c61 7965        start_laye
-00006e30: 7220 3d20 300a 2020 2020 2020 2020 2020  r = 0.          
-00006e40: 2020 6f75 7470 7574 5f6c 6179 6572 203d    output_layer =
-00006e50: 2073 656c 662e 636f 6e66 6967 2e66 7573   self.config.fus
-00006e60: 696f 6e5f 6c61 7965 720a 0a20 2020 2020  ion_layer..     
-00006e70: 2020 2065 6c69 6620 6d6f 6465 203d 3d20     elif mode == 
-00006e80: 2771 7565 7279 273a 0a20 2020 2020 2020  'query':.       
-00006e90: 2020 2020 2073 7461 7274 5f6c 6179 6572       start_layer
-00006ea0: 203d 2030 0a20 2020 2020 2020 2020 2020   = 0.           
-00006eb0: 206f 7574 7075 745f 6c61 7965 7220 3d20   output_layer = 
-00006ec0: 7365 6c66 2e63 6f6e 6669 672e 6e75 6d5f  self.config.num_
-00006ed0: 6869 6464 656e 5f6c 6179 6572 730a 0a20  hidden_layers.. 
-00006ee0: 2020 2020 2020 2065 6c69 6620 6d6f 6465         elif mode
-00006ef0: 203d 3d20 2766 7573 696f 6e27 3a0a 2020   == 'fusion':.  
-00006f00: 2020 2020 2020 2020 2020 7374 6172 745f            start_
-00006f10: 6c61 7965 7220 3d20 7365 6c66 2e63 6f6e  layer = self.con
-00006f20: 6669 672e 6675 7369 6f6e 5f6c 6179 6572  fig.fusion_layer
-00006f30: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00006f40: 7075 745f 6c61 7965 7220 3d20 7365 6c66  put_layer = self
-00006f50: 2e63 6f6e 6669 672e 6e75 6d5f 6869 6464  .config.num_hidd
-00006f60: 656e 5f6c 6179 6572 730a 0a20 2020 2020  en_layers..     
-00006f70: 2020 2065 6c69 6620 6d6f 6465 203d 3d20     elif mode == 
-00006f80: 276d 756c 7469 5f6d 6f64 616c 273a 0a20  'multi_modal':. 
-00006f90: 2020 2020 2020 2020 2020 2073 7461 7274             start
-00006fa0: 5f6c 6179 6572 203d 2030 0a20 2020 2020  _layer = 0.     
-00006fb0: 2020 2020 2020 206f 7574 7075 745f 6c61         output_la
-00006fc0: 7965 7220 3d20 7365 6c66 2e63 6f6e 6669  yer = self.confi
-00006fd0: 672e 6e75 6d5f 6869 6464 656e 5f6c 6179  g.num_hidden_lay
-00006fe0: 6572 730a 0a20 2020 2020 2020 2066 6f72  ers..        for
-00006ff0: 2069 2069 6e20 7261 6e67 6528 7374 6172   i in range(star
-00007000: 745f 6c61 7965 722c 206f 7574 7075 745f  t_layer, output_
-00007010: 6c61 7965 7229 3a0a 2020 2020 2020 2020  layer):.        
-00007020: 2020 2020 6c61 7965 725f 6d6f 6475 6c65      layer_module
-00007030: 203d 2073 656c 662e 6c61 7965 725b 695d   = self.layer[i]
-00007040: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00007050: 6f75 7470 7574 5f68 6964 6465 6e5f 7374  output_hidden_st
-00007060: 6174 6573 3a0a 2020 2020 2020 2020 2020  ates:.          
-00007070: 2020 2020 2020 616c 6c5f 6869 6464 656e        all_hidden
-00007080: 5f73 7461 7465 7320 3d20 616c 6c5f 6869  _states = all_hi
-00007090: 6464 656e 5f73 7461 7465 7320 2b20 2868  dden_states + (h
-000070a0: 6964 6465 6e5f 7374 6174 6573 2c20 290a  idden_states, ).
-000070b0: 0a20 2020 2020 2020 2020 2020 206c 6179  .            lay
-000070c0: 6572 5f68 6561 645f 6d61 736b 203d 2068  er_head_mask = h
-000070d0: 6561 645f 6d61 736b 5b69 5d20 6966 2068  ead_mask[i] if h
-000070e0: 6561 645f 6d61 736b 2069 7320 6e6f 7420  ead_mask is not 
-000070f0: 4e6f 6e65 2065 6c73 6520 4e6f 6e65 0a20  None else None. 
-00007100: 2020 2020 2020 2020 2020 2070 6173 745f             past_
-00007110: 6b65 795f 7661 6c75 6520 3d20 7061 7374  key_value = past
-00007120: 5f6b 6579 5f76 616c 7565 735b 0a20 2020  _key_values[.   
-00007130: 2020 2020 2020 2020 2020 2020 2069 5d20               i] 
-00007140: 6966 2070 6173 745f 6b65 795f 7661 6c75  if past_key_valu
-00007150: 6573 2069 7320 6e6f 7420 4e6f 6e65 2065  es is not None e
-00007160: 6c73 6520 4e6f 6e65 0a0a 2020 2020 2020  lse None..      
-00007170: 2020 2020 2020 6966 2067 6574 6174 7472        if getattr
-00007180: 2873 656c 662e 636f 6e66 6967 2c20 2767  (self.config, 'g
-00007190: 7261 6469 656e 745f 6368 6563 6b70 6f69  radient_checkpoi
-000071a0: 6e74 696e 6727 2c0a 2020 2020 2020 2020  nting',.        
-000071b0: 2020 2020 2020 2020 2020 2020 2020 2046                 F
-000071c0: 616c 7365 2920 616e 6420 7365 6c66 2e74  alse) and self.t
-000071d0: 7261 696e 696e 673a 0a0a 2020 2020 2020  raining:..      
-000071e0: 2020 2020 2020 2020 2020 6966 2075 7365            if use
-000071f0: 5f63 6163 6865 3a0a 2020 2020 2020 2020  _cache:.        
-00007200: 2020 2020 2020 2020 2020 2020 6c6f 6767              logg
-00007210: 6572 2e77 6172 6e28 0a20 2020 2020 2020  er.warn(.       
-00007220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007230: 2027 6075 7365 5f63 6163 6865 3d54 7275   '`use_cache=Tru
-00007240: 6560 2069 7320 696e 636f 6d70 6174 6962  e` is incompatib
-00007250: 6c65 2077 6974 6820 6063 6f6e 6669 672e  le with `config.
-00007260: 6772 6164 6965 6e74 5f63 6865 636b 706f  gradient_checkpo
-00007270: 696e 7469 6e67 3d54 7275 6560 2e20 5365  inting=True`. Se
-00007280: 7474 696e 6720 270a 2020 2020 2020 2020  tting '.        
+00006640: 7470 7574 203d 2063 726f 7373 5f61 7474  tput = cross_att
+00006650: 656e 7469 6f6e 5f6f 7574 7075 7473 5b30  ention_outputs[0
+00006660: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+00006670: 2020 6f75 7470 7574 7320 3d20 6f75 7470    outputs = outp
+00006680: 7574 7320 2b20 6372 6f73 735f 6174 7465  uts + cross_atte
+00006690: 6e74 696f 6e5f 6f75 7470 7574 735b 0a20  ntion_outputs[. 
+000066a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000066b0: 2020 2031 3a0a 2020 2020 2020 2020 2020     1:.          
+000066c0: 2020 2020 2020 2020 2020 2d31 5d20 2023            -1]  #
+000066d0: 2061 6464 2063 726f 7373 2061 7474 656e   add cross atten
+000066e0: 7469 6f6e 7320 6966 2077 6520 6f75 7470  tions if we outp
+000066f0: 7574 2061 7474 656e 7469 6f6e 2077 6569  ut attention wei
+00006700: 6768 7473 0a20 2020 2020 2020 206c 6179  ghts.        lay
+00006710: 6572 5f6f 7574 7075 7420 3d20 6170 706c  er_output = appl
+00006720: 795f 6368 756e 6b69 6e67 5f74 6f5f 666f  y_chunking_to_fo
+00006730: 7277 6172 6428 7365 6c66 2e66 6565 645f  rward(self.feed_
+00006740: 666f 7277 6172 645f 6368 756e 6b2c 0a20  forward_chunk,. 
+00006750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006780: 7365 6c66 2e63 6875 6e6b 5f73 697a 655f  self.chunk_size_
+00006790: 6665 6564 5f66 6f72 7761 7264 2c0a 2020  feed_forward,.  
+000067a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000067b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000067c0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000067d0: 656c 662e 7365 715f 6c65 6e5f 6469 6d2c  elf.seq_len_dim,
+000067e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000067f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006810: 2020 6174 7465 6e74 696f 6e5f 6f75 7470    attention_outp
+00006820: 7574 290a 2020 2020 2020 2020 6f75 7470  ut).        outp
+00006830: 7574 7320 3d20 286c 6179 6572 5f6f 7574  uts = (layer_out
+00006840: 7075 742c 2029 202b 206f 7574 7075 7473  put, ) + outputs
+00006850: 0a0a 2020 2020 2020 2020 6f75 7470 7574  ..        output
+00006860: 7320 3d20 6f75 7470 7574 7320 2b20 2870  s = outputs + (p
+00006870: 7265 7365 6e74 5f6b 6579 5f76 616c 7565  resent_key_value
+00006880: 2c20 290a 0a20 2020 2020 2020 2072 6574  , )..        ret
+00006890: 7572 6e20 6f75 7470 7574 730a 0a20 2020  urn outputs..   
+000068a0: 2064 6566 2066 6565 645f 666f 7277 6172   def feed_forwar
+000068b0: 645f 6368 756e 6b28 7365 6c66 2c20 6174  d_chunk(self, at
+000068c0: 7465 6e74 696f 6e5f 6f75 7470 7574 293a  tention_output):
+000068d0: 0a20 2020 2020 2020 2069 6e74 6572 6d65  .        interme
+000068e0: 6469 6174 655f 6f75 7470 7574 203d 2073  diate_output = s
+000068f0: 656c 662e 696e 7465 726d 6564 6961 7465  elf.intermediate
+00006900: 2861 7474 656e 7469 6f6e 5f6f 7574 7075  (attention_outpu
+00006910: 7429 0a20 2020 2020 2020 206c 6179 6572  t).        layer
+00006920: 5f6f 7574 7075 7420 3d20 7365 6c66 2e6f  _output = self.o
+00006930: 7574 7075 7428 696e 7465 726d 6564 6961  utput(intermedia
+00006940: 7465 5f6f 7574 7075 742c 2061 7474 656e  te_output, atten
+00006950: 7469 6f6e 5f6f 7574 7075 7429 0a20 2020  tion_output).   
+00006960: 2020 2020 2072 6574 7572 6e20 6c61 7965       return laye
+00006970: 725f 6f75 7470 7574 0a0a 0a63 6c61 7373  r_output...class
+00006980: 2042 6572 7445 6e63 6f64 6572 286e 6e2e   BertEncoder(nn.
+00006990: 4d6f 6475 6c65 293a 0a0a 2020 2020 6465  Module):..    de
+000069a0: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
+000069b0: 2063 6f6e 6669 6729 3a0a 2020 2020 2020   config):.      
+000069c0: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
+000069d0: 5f5f 2829 0a20 2020 2020 2020 2073 656c  __().        sel
+000069e0: 662e 636f 6e66 6967 203d 2063 6f6e 6669  f.config = confi
+000069f0: 670a 2020 2020 2020 2020 7365 6c66 2e6c  g.        self.l
+00006a00: 6179 6572 203d 206e 6e2e 4d6f 6475 6c65  ayer = nn.Module
+00006a10: 4c69 7374 280a 2020 2020 2020 2020 2020  List(.          
+00006a20: 2020 5b42 6572 744c 6179 6572 2863 6f6e    [BertLayer(con
+00006a30: 6669 672c 2069 2920 666f 7220 6920 696e  fig, i) for i in
+00006a40: 2072 616e 6765 2863 6f6e 6669 672e 6e75   range(config.nu
+00006a50: 6d5f 6869 6464 656e 5f6c 6179 6572 7329  m_hidden_layers)
+00006a60: 5d29 0a0a 2020 2020 6465 6620 666f 7277  ])..    def forw
+00006a70: 6172 6428 0a20 2020 2020 2020 2073 656c  ard(.        sel
+00006a80: 662c 0a20 2020 2020 2020 2068 6964 6465  f,.        hidde
+00006a90: 6e5f 7374 6174 6573 2c0a 2020 2020 2020  n_states,.      
+00006aa0: 2020 6174 7465 6e74 696f 6e5f 6d61 736b    attention_mask
+00006ab0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2068  =None,.        h
+00006ac0: 6561 645f 6d61 736b 3d4e 6f6e 652c 0a20  ead_mask=None,. 
+00006ad0: 2020 2020 2020 2065 6e63 6f64 6572 5f68         encoder_h
+00006ae0: 6964 6465 6e5f 7374 6174 6573 3d4e 6f6e  idden_states=Non
+00006af0: 652c 0a20 2020 2020 2020 2065 6e63 6f64  e,.        encod
+00006b00: 6572 5f61 7474 656e 7469 6f6e 5f6d 6173  er_attention_mas
+00006b10: 6b3d 4e6f 6e65 2c0a 2020 2020 2020 2020  k=None,.        
+00006b20: 7061 7374 5f6b 6579 5f76 616c 7565 733d  past_key_values=
+00006b30: 4e6f 6e65 2c0a 2020 2020 2020 2020 7573  None,.        us
+00006b40: 655f 6361 6368 653d 4e6f 6e65 2c0a 2020  e_cache=None,.  
+00006b50: 2020 2020 2020 6f75 7470 7574 5f61 7474        output_att
+00006b60: 656e 7469 6f6e 733d 4661 6c73 652c 0a20  entions=False,. 
+00006b70: 2020 2020 2020 206f 7574 7075 745f 6869         output_hi
+00006b80: 6464 656e 5f73 7461 7465 733d 4661 6c73  dden_states=Fals
+00006b90: 652c 0a20 2020 2020 2020 2072 6574 7572  e,.        retur
+00006ba0: 6e5f 6469 6374 3d54 7275 652c 0a20 2020  n_dict=True,.   
+00006bb0: 2020 2020 206d 6f64 653d 276d 756c 7469       mode='multi
+00006bc0: 5f6d 6f64 616c 272c 0a20 2020 2029 3a0a  _modal',.    ):.
+00006bd0: 2020 2020 2020 2020 616c 6c5f 6869 6464          all_hidd
+00006be0: 656e 5f73 7461 7465 7320 3d20 2829 2069  en_states = () i
+00006bf0: 6620 6f75 7470 7574 5f68 6964 6465 6e5f  f output_hidden_
+00006c00: 7374 6174 6573 2065 6c73 6520 4e6f 6e65  states else None
+00006c10: 0a20 2020 2020 2020 2061 6c6c 5f73 656c  .        all_sel
+00006c20: 665f 6174 7465 6e74 696f 6e73 203d 2028  f_attentions = (
+00006c30: 2920 6966 206f 7574 7075 745f 6174 7465  ) if output_atte
+00006c40: 6e74 696f 6e73 2065 6c73 6520 4e6f 6e65  ntions else None
+00006c50: 0a20 2020 2020 2020 2061 6c6c 5f63 726f  .        all_cro
+00006c60: 7373 5f61 7474 656e 7469 6f6e 7320 3d20  ss_attentions = 
+00006c70: 280a 2020 2020 2020 2020 2920 6966 206f  (.        ) if o
+00006c80: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
+00006c90: 2061 6e64 2073 656c 662e 636f 6e66 6967   and self.config
+00006ca0: 2e61 6464 5f63 726f 7373 5f61 7474 656e  .add_cross_atten
+00006cb0: 7469 6f6e 2065 6c73 6520 4e6f 6e65 0a0a  tion else None..
+00006cc0: 2020 2020 2020 2020 6e65 7874 5f64 6563          next_dec
+00006cd0: 6f64 6572 5f63 6163 6865 203d 2028 2920  oder_cache = () 
+00006ce0: 6966 2075 7365 5f63 6163 6865 2065 6c73  if use_cache els
+00006cf0: 6520 4e6f 6e65 0a0a 2020 2020 2020 2020  e None..        
+00006d00: 6966 206d 6f64 6520 3d3d 2027 7465 7874  if mode == 'text
+00006d10: 273a 0a20 2020 2020 2020 2020 2020 2073  ':.            s
+00006d20: 7461 7274 5f6c 6179 6572 203d 2030 0a20  tart_layer = 0. 
+00006d30: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+00006d40: 745f 6c61 7965 7220 3d20 7365 6c66 2e63  t_layer = self.c
+00006d50: 6f6e 6669 672e 6675 7369 6f6e 5f6c 6179  onfig.fusion_lay
+00006d60: 6572 0a0a 2020 2020 2020 2020 656c 6966  er..        elif
+00006d70: 206d 6f64 6520 3d3d 2027 7175 6572 7927   mode == 'query'
+00006d80: 3a0a 2020 2020 2020 2020 2020 2020 7374  :.            st
+00006d90: 6172 745f 6c61 7965 7220 3d20 300a 2020  art_layer = 0.  
+00006da0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00006db0: 5f6c 6179 6572 203d 2073 656c 662e 636f  _layer = self.co
+00006dc0: 6e66 6967 2e6e 756d 5f68 6964 6465 6e5f  nfig.num_hidden_
+00006dd0: 6c61 7965 7273 0a0a 2020 2020 2020 2020  layers..        
+00006de0: 656c 6966 206d 6f64 6520 3d3d 2027 6675  elif mode == 'fu
+00006df0: 7369 6f6e 273a 0a20 2020 2020 2020 2020  sion':.         
+00006e00: 2020 2073 7461 7274 5f6c 6179 6572 203d     start_layer =
+00006e10: 2073 656c 662e 636f 6e66 6967 2e66 7573   self.config.fus
+00006e20: 696f 6e5f 6c61 7965 720a 2020 2020 2020  ion_layer.      
+00006e30: 2020 2020 2020 6f75 7470 7574 5f6c 6179        output_lay
+00006e40: 6572 203d 2073 656c 662e 636f 6e66 6967  er = self.config
+00006e50: 2e6e 756d 5f68 6964 6465 6e5f 6c61 7965  .num_hidden_laye
+00006e60: 7273 0a0a 2020 2020 2020 2020 656c 6966  rs..        elif
+00006e70: 206d 6f64 6520 3d3d 2027 6d75 6c74 695f   mode == 'multi_
+00006e80: 6d6f 6461 6c27 3a0a 2020 2020 2020 2020  modal':.        
+00006e90: 2020 2020 7374 6172 745f 6c61 7965 7220      start_layer 
+00006ea0: 3d20 300a 2020 2020 2020 2020 2020 2020  = 0.            
+00006eb0: 6f75 7470 7574 5f6c 6179 6572 203d 2073  output_layer = s
+00006ec0: 656c 662e 636f 6e66 6967 2e6e 756d 5f68  elf.config.num_h
+00006ed0: 6964 6465 6e5f 6c61 7965 7273 0a0a 2020  idden_layers..  
+00006ee0: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
+00006ef0: 616e 6765 2873 7461 7274 5f6c 6179 6572  ange(start_layer
+00006f00: 2c20 6f75 7470 7574 5f6c 6179 6572 293a  , output_layer):
+00006f10: 0a20 2020 2020 2020 2020 2020 206c 6179  .            lay
+00006f20: 6572 5f6d 6f64 756c 6520 3d20 7365 6c66  er_module = self
+00006f30: 2e6c 6179 6572 5b69 5d0a 2020 2020 2020  .layer[i].      
+00006f40: 2020 2020 2020 6966 206f 7574 7075 745f        if output_
+00006f50: 6869 6464 656e 5f73 7461 7465 733a 0a20  hidden_states:. 
+00006f60: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+00006f70: 6c6c 5f68 6964 6465 6e5f 7374 6174 6573  ll_hidden_states
+00006f80: 203d 2061 6c6c 5f68 6964 6465 6e5f 7374   = all_hidden_st
+00006f90: 6174 6573 202b 2028 6869 6464 656e 5f73  ates + (hidden_s
+00006fa0: 7461 7465 732c 2029 0a0a 2020 2020 2020  tates, )..      
+00006fb0: 2020 2020 2020 6c61 7965 725f 6865 6164        layer_head
+00006fc0: 5f6d 6173 6b20 3d20 6865 6164 5f6d 6173  _mask = head_mas
+00006fd0: 6b5b 695d 2069 6620 6865 6164 5f6d 6173  k[i] if head_mas
+00006fe0: 6b20 6973 206e 6f74 204e 6f6e 6520 656c  k is not None el
+00006ff0: 7365 204e 6f6e 650a 2020 2020 2020 2020  se None.        
+00007000: 2020 2020 7061 7374 5f6b 6579 5f76 616c      past_key_val
+00007010: 7565 203d 2070 6173 745f 6b65 795f 7661  ue = past_key_va
+00007020: 6c75 6573 5b0a 2020 2020 2020 2020 2020  lues[.          
+00007030: 2020 2020 2020 695d 2069 6620 7061 7374        i] if past
+00007040: 5f6b 6579 5f76 616c 7565 7320 6973 206e  _key_values is n
+00007050: 6f74 204e 6f6e 6520 656c 7365 204e 6f6e  ot None else Non
+00007060: 650a 0a20 2020 2020 2020 2020 2020 2069  e..            i
+00007070: 6620 6765 7461 7474 7228 7365 6c66 2e63  f getattr(self.c
+00007080: 6f6e 6669 672c 2027 6772 6164 6965 6e74  onfig, 'gradient
+00007090: 5f63 6865 636b 706f 696e 7469 6e67 272c  _checkpointing',
+000070a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000070b0: 2020 2020 2020 2020 4661 6c73 6529 2061          False) a
+000070c0: 6e64 2073 656c 662e 7472 6169 6e69 6e67  nd self.training
+000070d0: 3a0a 0a20 2020 2020 2020 2020 2020 2020  :..             
+000070e0: 2020 2069 6620 7573 655f 6361 6368 653a     if use_cache:
+000070f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007100: 2020 2020 206c 6f67 6765 722e 7761 726e       logger.warn
+00007110: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00007120: 2020 2020 2020 2020 2020 2760 7573 655f            '`use_
+00007130: 6361 6368 653d 5472 7565 6020 6973 2069  cache=True` is i
+00007140: 6e63 6f6d 7061 7469 626c 6520 7769 7468  ncompatible with
+00007150: 2060 636f 6e66 6967 2e67 7261 6469 656e   `config.gradien
+00007160: 745f 6368 6563 6b70 6f69 6e74 696e 673d  t_checkpointing=
+00007170: 5472 7565 602e 2053 6574 7469 6e67 2027  True`. Setting '
+00007180: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007190: 2020 2020 2020 2020 2027 6075 7365 5f63           '`use_c
+000071a0: 6163 6865 3d46 616c 7365 602e 2e2e 2729  ache=False`...')
+000071b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000071c0: 2020 2020 2075 7365 5f63 6163 6865 203d       use_cache =
+000071d0: 2046 616c 7365 0a0a 2020 2020 2020 2020   False..        
+000071e0: 2020 2020 2020 2020 6465 6620 6372 6561          def crea
+000071f0: 7465 5f63 7573 746f 6d5f 666f 7277 6172  te_custom_forwar
+00007200: 6428 6d6f 6475 6c65 293a 0a0a 2020 2020  d(module):..    
+00007210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007220: 6465 6620 6375 7374 6f6d 5f66 6f72 7761  def custom_forwa
+00007230: 7264 282a 696e 7075 7473 293a 0a20 2020  rd(*inputs):.   
+00007240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007250: 2020 2020 2072 6574 7572 6e20 6d6f 6475       return modu
+00007260: 6c65 282a 696e 7075 7473 2c20 7061 7374  le(*inputs, past
+00007270: 5f6b 6579 5f76 616c 7565 2c0a 2020 2020  _key_value,.    
+00007280: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00007290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000072a0: 2760 7573 655f 6361 6368 653d 4661 6c73  '`use_cache=Fals
-000072b0: 6560 2e2e 2e27 290a 2020 2020 2020 2020  e`...').        
-000072c0: 2020 2020 2020 2020 2020 2020 7573 655f              use_
-000072d0: 6361 6368 6520 3d20 4661 6c73 650a 0a20  cache = False.. 
-000072e0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-000072f0: 6566 2063 7265 6174 655f 6375 7374 6f6d  ef create_custom
-00007300: 5f66 6f72 7761 7264 286d 6f64 756c 6529  _forward(module)
-00007310: 3a0a 0a20 2020 2020 2020 2020 2020 2020  :..             
-00007320: 2020 2020 2020 2064 6566 2063 7573 746f         def custo
-00007330: 6d5f 666f 7277 6172 6428 2a69 6e70 7574  m_forward(*input
-00007340: 7329 3a0a 2020 2020 2020 2020 2020 2020  s):.            
-00007350: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00007360: 726e 206d 6f64 756c 6528 2a69 6e70 7574  rn module(*input
-00007370: 732c 2070 6173 745f 6b65 795f 7661 6c75  s, past_key_valu
-00007380: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-00007390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000073a0: 2020 2020 2020 2020 206f 7574 7075 745f           output_
-000073b0: 6174 7465 6e74 696f 6e73 290a 0a20 2020  attentions)..   
-000073c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000073d0: 2072 6574 7572 6e20 6375 7374 6f6d 5f66   return custom_f
-000073e0: 6f72 7761 7264 0a0a 2020 2020 2020 2020  orward..        
-000073f0: 2020 2020 2020 2020 6c61 7965 725f 6f75          layer_ou
-00007400: 7470 7574 7320 3d20 746f 7263 682e 7574  tputs = torch.ut
-00007410: 696c 732e 6368 6563 6b70 6f69 6e74 2e63  ils.checkpoint.c
-00007420: 6865 636b 706f 696e 7428 0a20 2020 2020  heckpoint(.     
-00007430: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00007440: 7265 6174 655f 6375 7374 6f6d 5f66 6f72  reate_custom_for
-00007450: 7761 7264 286c 6179 6572 5f6d 6f64 756c  ward(layer_modul
-00007460: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
-00007470: 2020 2020 2020 2020 6869 6464 656e 5f73          hidden_s
-00007480: 7461 7465 732c 0a20 2020 2020 2020 2020  tates,.         
-00007490: 2020 2020 2020 2020 2020 2061 7474 656e             atten
-000074a0: 7469 6f6e 5f6d 6173 6b2c 0a20 2020 2020  tion_mask,.     
-000074b0: 2020 2020 2020 2020 2020 2020 2020 206c                 l
-000074c0: 6179 6572 5f68 6561 645f 6d61 736b 2c0a  ayer_head_mask,.
-000074d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000074e0: 2020 2020 656e 636f 6465 725f 6869 6464      encoder_hidd
-000074f0: 656e 5f73 7461 7465 732c 0a20 2020 2020  en_states,.     
-00007500: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00007510: 6e63 6f64 6572 5f61 7474 656e 7469 6f6e  ncoder_attention
-00007520: 5f6d 6173 6b2c 0a20 2020 2020 2020 2020  _mask,.         
-00007530: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-00007540: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00007550: 2020 2020 2020 2020 2020 206c 6179 6572             layer
-00007560: 5f6f 7574 7075 7473 203d 206c 6179 6572  _outputs = layer
-00007570: 5f6d 6f64 756c 6528 0a20 2020 2020 2020  _module(.       
-00007580: 2020 2020 2020 2020 2020 2020 2068 6964               hid
-00007590: 6465 6e5f 7374 6174 6573 2c0a 2020 2020  den_states,.    
-000075a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000075b0: 6174 7465 6e74 696f 6e5f 6d61 736b 2c0a  attention_mask,.
-000075c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000075d0: 2020 2020 6c61 7965 725f 6865 6164 5f6d      layer_head_m
-000075e0: 6173 6b2c 0a20 2020 2020 2020 2020 2020  ask,.           
-000075f0: 2020 2020 2020 2020 2065 6e63 6f64 6572           encoder
-00007600: 5f68 6964 6465 6e5f 7374 6174 6573 2c0a  _hidden_states,.
-00007610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007620: 2020 2020 656e 636f 6465 725f 6174 7465      encoder_atte
-00007630: 6e74 696f 6e5f 6d61 736b 2c0a 2020 2020  ntion_mask,.    
-00007640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007650: 7061 7374 5f6b 6579 5f76 616c 7565 2c0a  past_key_value,.
-00007660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007670: 2020 2020 6f75 7470 7574 5f61 7474 656e      output_atten
-00007680: 7469 6f6e 732c 0a20 2020 2020 2020 2020  tions,.         
-00007690: 2020 2020 2020 2029 0a0a 2020 2020 2020         )..      
-000076a0: 2020 2020 2020 6869 6464 656e 5f73 7461        hidden_sta
-000076b0: 7465 7320 3d20 6c61 7965 725f 6f75 7470  tes = layer_outp
-000076c0: 7574 735b 305d 0a20 2020 2020 2020 2020  uts[0].         
-000076d0: 2020 2069 6620 7573 655f 6361 6368 653a     if use_cache:
-000076e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000076f0: 206e 6578 745f 6465 636f 6465 725f 6361   next_decoder_ca
-00007700: 6368 6520 2b3d 2028 6c61 7965 725f 6f75  che += (layer_ou
-00007710: 7470 7574 735b 2d31 5d2c 2029 0a20 2020  tputs[-1], ).   
-00007720: 2020 2020 2020 2020 2069 6620 6f75 7470           if outp
-00007730: 7574 5f61 7474 656e 7469 6f6e 733a 0a20  ut_attentions:. 
-00007740: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-00007750: 6c6c 5f73 656c 665f 6174 7465 6e74 696f  ll_self_attentio
-00007760: 6e73 203d 2061 6c6c 5f73 656c 665f 6174  ns = all_self_at
-00007770: 7465 6e74 696f 6e73 202b 2028 0a20 2020  tentions + (.   
-00007780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007790: 206c 6179 6572 5f6f 7574 7075 7473 5b31   layer_outputs[1
-000077a0: 5d2c 2029 0a0a 2020 2020 2020 2020 6966  ], )..        if
-000077b0: 206f 7574 7075 745f 6869 6464 656e 5f73   output_hidden_s
-000077c0: 7461 7465 733a 0a20 2020 2020 2020 2020  tates:.         
-000077d0: 2020 2061 6c6c 5f68 6964 6465 6e5f 7374     all_hidden_st
-000077e0: 6174 6573 203d 2061 6c6c 5f68 6964 6465  ates = all_hidde
-000077f0: 6e5f 7374 6174 6573 202b 2028 6869 6464  n_states + (hidd
-00007800: 656e 5f73 7461 7465 732c 2029 0a0a 2020  en_states, )..  
-00007810: 2020 2020 2020 6966 206e 6f74 2072 6574        if not ret
-00007820: 7572 6e5f 6469 6374 3a0a 2020 2020 2020  urn_dict:.      
-00007830: 2020 2020 2020 7265 7475 726e 2074 7570        return tup
-00007840: 6c65 2876 2066 6f72 2076 2069 6e20 5b0a  le(v for v in [.
-00007850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007860: 6869 6464 656e 5f73 7461 7465 732c 0a20  hidden_states,. 
-00007870: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00007880: 6578 745f 6465 636f 6465 725f 6361 6368  ext_decoder_cach
-00007890: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-000078a0: 2020 2061 6c6c 5f68 6964 6465 6e5f 7374     all_hidden_st
-000078b0: 6174 6573 2c0a 2020 2020 2020 2020 2020  ates,.          
-000078c0: 2020 2020 2020 616c 6c5f 7365 6c66 5f61        all_self_a
-000078d0: 7474 656e 7469 6f6e 732c 0a20 2020 2020  ttentions,.     
-000078e0: 2020 2020 2020 2020 2020 2061 6c6c 5f63             all_c
-000078f0: 726f 7373 5f61 7474 656e 7469 6f6e 732c  ross_attentions,
-00007900: 0a20 2020 2020 2020 2020 2020 205d 2069  .            ] i
-00007910: 6620 7620 6973 206e 6f74 204e 6f6e 6529  f v is not None)
-00007920: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00007930: 4261 7365 4d6f 6465 6c4f 7574 7075 7457  BaseModelOutputW
-00007940: 6974 6850 6173 7441 6e64 4372 6f73 7341  ithPastAndCrossA
-00007950: 7474 656e 7469 6f6e 7328 0a20 2020 2020  ttentions(.     
-00007960: 2020 2020 2020 206c 6173 745f 6869 6464         last_hidd
-00007970: 656e 5f73 7461 7465 3d68 6964 6465 6e5f  en_state=hidden_
-00007980: 7374 6174 6573 2c0a 2020 2020 2020 2020  states,.        
-00007990: 2020 2020 7061 7374 5f6b 6579 5f76 616c      past_key_val
-000079a0: 7565 733d 6e65 7874 5f64 6563 6f64 6572  ues=next_decoder
-000079b0: 5f63 6163 6865 2c0a 2020 2020 2020 2020  _cache,.        
-000079c0: 2020 2020 6869 6464 656e 5f73 7461 7465      hidden_state
-000079d0: 733d 616c 6c5f 6869 6464 656e 5f73 7461  s=all_hidden_sta
-000079e0: 7465 732c 0a20 2020 2020 2020 2020 2020  tes,.           
-000079f0: 2061 7474 656e 7469 6f6e 733d 616c 6c5f   attentions=all_
-00007a00: 7365 6c66 5f61 7474 656e 7469 6f6e 732c  self_attentions,
-00007a10: 0a20 2020 2020 2020 2020 2020 2063 726f  .            cro
-00007a20: 7373 5f61 7474 656e 7469 6f6e 733d 616c  ss_attentions=al
-00007a30: 6c5f 6372 6f73 735f 6174 7465 6e74 696f  l_cross_attentio
-00007a40: 6e73 2c0a 2020 2020 2020 2020 290a 0a0a  ns,.        )...
-00007a50: 636c 6173 7320 4265 7274 506f 6f6c 6572  class BertPooler
-00007a60: 286e 6e2e 4d6f 6475 6c65 293a 0a0a 2020  (nn.Module):..  
-00007a70: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-00007a80: 656c 662c 2063 6f6e 6669 6729 3a0a 2020  elf, config):.  
-00007a90: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
-00007aa0: 696e 6974 5f5f 2829 0a20 2020 2020 2020  init__().       
-00007ab0: 2073 656c 662e 6465 6e73 6520 3d20 6e6e   self.dense = nn
-00007ac0: 2e4c 696e 6561 7228 636f 6e66 6967 2e68  .Linear(config.h
-00007ad0: 6964 6465 6e5f 7369 7a65 2c20 636f 6e66  idden_size, conf
-00007ae0: 6967 2e68 6964 6465 6e5f 7369 7a65 290a  ig.hidden_size).
-00007af0: 2020 2020 2020 2020 7365 6c66 2e61 6374          self.act
-00007b00: 6976 6174 696f 6e20 3d20 6e6e 2e54 616e  ivation = nn.Tan
-00007b10: 6828 290a 0a20 2020 2064 6566 2066 6f72  h()..    def for
-00007b20: 7761 7264 2873 656c 662c 2068 6964 6465  ward(self, hidde
-00007b30: 6e5f 7374 6174 6573 293a 0a20 2020 2020  n_states):.     
-00007b40: 2020 2023 2057 6520 2270 6f6f 6c22 2074     # We "pool" t
-00007b50: 6865 206d 6f64 656c 2062 7920 7369 6d70  he model by simp
-00007b60: 6c79 2074 616b 696e 6720 7468 6520 6869  ly taking the hi
-00007b70: 6464 656e 2073 7461 7465 2063 6f72 7265  dden state corre
-00007b80: 7370 6f6e 6469 6e67 0a20 2020 2020 2020  sponding.       
-00007b90: 2023 2074 6f20 7468 6520 6669 7273 7420   # to the first 
-00007ba0: 746f 6b65 6e2e 0a20 2020 2020 2020 2066  token..        f
-00007bb0: 6972 7374 5f74 6f6b 656e 5f74 656e 736f  irst_token_tenso
-00007bc0: 7220 3d20 6869 6464 656e 5f73 7461 7465  r = hidden_state
-00007bd0: 735b 3a2c 2030 5d0a 2020 2020 2020 2020  s[:, 0].        
-00007be0: 706f 6f6c 6564 5f6f 7574 7075 7420 3d20  pooled_output = 
-00007bf0: 7365 6c66 2e64 656e 7365 2866 6972 7374  self.dense(first
-00007c00: 5f74 6f6b 656e 5f74 656e 736f 7229 0a20  _token_tensor). 
-00007c10: 2020 2020 2020 2070 6f6f 6c65 645f 6f75         pooled_ou
-00007c20: 7470 7574 203d 2073 656c 662e 6163 7469  tput = self.acti
-00007c30: 7661 7469 6f6e 2870 6f6f 6c65 645f 6f75  vation(pooled_ou
-00007c40: 7470 7574 290a 2020 2020 2020 2020 7265  tput).        re
-00007c50: 7475 726e 2070 6f6f 6c65 645f 6f75 7470  turn pooled_outp
-00007c60: 7574 0a0a 0a63 6c61 7373 2042 6572 7450  ut...class BertP
-00007c70: 7265 6469 6374 696f 6e48 6561 6454 7261  redictionHeadTra
-00007c80: 6e73 666f 726d 286e 6e2e 4d6f 6475 6c65  nsform(nn.Module
-00007c90: 293a 0a0a 2020 2020 6465 6620 5f5f 696e  ):..    def __in
-00007ca0: 6974 5f5f 2873 656c 662c 2063 6f6e 6669  it__(self, confi
-00007cb0: 6729 3a0a 2020 2020 2020 2020 7375 7065  g):.        supe
-00007cc0: 7228 292e 5f5f 696e 6974 5f5f 2829 0a20  r().__init__(). 
-00007cd0: 2020 2020 2020 2073 656c 662e 6465 6e73         self.dens
-00007ce0: 6520 3d20 6e6e 2e4c 696e 6561 7228 636f  e = nn.Linear(co
-00007cf0: 6e66 6967 2e68 6964 6465 6e5f 7369 7a65  nfig.hidden_size
-00007d00: 2c20 636f 6e66 6967 2e68 6964 6465 6e5f  , config.hidden_
-00007d10: 7369 7a65 290a 2020 2020 2020 2020 6966  size).        if
-00007d20: 2069 7369 6e73 7461 6e63 6528 636f 6e66   isinstance(conf
-00007d30: 6967 2e68 6964 6465 6e5f 6163 742c 2073  ig.hidden_act, s
-00007d40: 7472 293a 0a20 2020 2020 2020 2020 2020  tr):.           
-00007d50: 2073 656c 662e 7472 616e 7366 6f72 6d5f   self.transform_
-00007d60: 6163 745f 666e 203d 2041 4354 3246 4e5b  act_fn = ACT2FN[
-00007d70: 636f 6e66 6967 2e68 6964 6465 6e5f 6163  config.hidden_ac
-00007d80: 745d 0a20 2020 2020 2020 2065 6c73 653a  t].        else:
-00007d90: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00007da0: 662e 7472 616e 7366 6f72 6d5f 6163 745f  f.transform_act_
-00007db0: 666e 203d 2063 6f6e 6669 672e 6869 6464  fn = config.hidd
-00007dc0: 656e 5f61 6374 0a20 2020 2020 2020 2073  en_act.        s
-00007dd0: 656c 662e 4c61 7965 724e 6f72 6d20 3d20  elf.LayerNorm = 
-00007de0: 6e6e 2e4c 6179 6572 4e6f 726d 280a 2020  nn.LayerNorm(.  
-00007df0: 2020 2020 2020 2020 2020 636f 6e66 6967            config
-00007e00: 2e68 6964 6465 6e5f 7369 7a65 2c20 6570  .hidden_size, ep
-00007e10: 733d 636f 6e66 6967 2e6c 6179 6572 5f6e  s=config.layer_n
-00007e20: 6f72 6d5f 6570 7329 0a0a 2020 2020 6465  orm_eps)..    de
-00007e30: 6620 666f 7277 6172 6428 7365 6c66 2c20  f forward(self, 
-00007e40: 6869 6464 656e 5f73 7461 7465 7329 3a0a  hidden_states):.
-00007e50: 2020 2020 2020 2020 6869 6464 656e 5f73          hidden_s
-00007e60: 7461 7465 7320 3d20 7365 6c66 2e64 656e  tates = self.den
-00007e70: 7365 2868 6964 6465 6e5f 7374 6174 6573  se(hidden_states
-00007e80: 290a 2020 2020 2020 2020 6869 6464 656e  ).        hidden
-00007e90: 5f73 7461 7465 7320 3d20 7365 6c66 2e74  _states = self.t
-00007ea0: 7261 6e73 666f 726d 5f61 6374 5f66 6e28  ransform_act_fn(
-00007eb0: 6869 6464 656e 5f73 7461 7465 7329 0a20  hidden_states). 
-00007ec0: 2020 2020 2020 2068 6964 6465 6e5f 7374         hidden_st
-00007ed0: 6174 6573 203d 2073 656c 662e 4c61 7965  ates = self.Laye
-00007ee0: 724e 6f72 6d28 6869 6464 656e 5f73 7461  rNorm(hidden_sta
-00007ef0: 7465 7329 0a20 2020 2020 2020 2072 6574  tes).        ret
-00007f00: 7572 6e20 6869 6464 656e 5f73 7461 7465  urn hidden_state
-00007f10: 730a 0a0a 636c 6173 7320 4265 7274 4c4d  s...class BertLM
-00007f20: 5072 6564 6963 7469 6f6e 4865 6164 286e  PredictionHead(n
-00007f30: 6e2e 4d6f 6475 6c65 293a 0a0a 2020 2020  n.Module):..    
-00007f40: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-00007f50: 662c 2063 6f6e 6669 6729 3a0a 2020 2020  f, config):.    
-00007f60: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
-00007f70: 6974 5f5f 2829 0a20 2020 2020 2020 2073  it__().        s
-00007f80: 656c 662e 7472 616e 7366 6f72 6d20 3d20  elf.transform = 
-00007f90: 4265 7274 5072 6564 6963 7469 6f6e 4865  BertPredictionHe
-00007fa0: 6164 5472 616e 7366 6f72 6d28 636f 6e66  adTransform(conf
-00007fb0: 6967 290a 0a20 2020 2020 2020 2023 2054  ig)..        # T
-00007fc0: 6865 206f 7574 7075 7420 7765 6967 6874  he output weight
-00007fd0: 7320 6172 6520 7468 6520 7361 6d65 2061  s are the same a
-00007fe0: 7320 7468 6520 696e 7075 7420 656d 6265  s the input embe
-00007ff0: 6464 696e 6773 2c20 6275 7420 7468 6572  ddings, but ther
-00008000: 6520 6973 0a20 2020 2020 2020 2023 2061  e is.        # a
-00008010: 6e20 6f75 7470 7574 2d6f 6e6c 7920 6269  n output-only bi
-00008020: 6173 2066 6f72 2065 6163 6820 746f 6b65  as for each toke
-00008030: 6e2e 0a20 2020 2020 2020 2073 656c 662e  n..        self.
-00008040: 6465 636f 6465 7220 3d20 6e6e 2e4c 696e  decoder = nn.Lin
-00008050: 6561 7228 0a20 2020 2020 2020 2020 2020  ear(.           
-00008060: 2063 6f6e 6669 672e 6869 6464 656e 5f73   config.hidden_s
-00008070: 697a 652c 2063 6f6e 6669 672e 766f 6361  ize, config.voca
-00008080: 625f 7369 7a65 2c20 6269 6173 3d46 616c  b_size, bias=Fal
-00008090: 7365 290a 0a20 2020 2020 2020 2073 656c  se)..        sel
-000080a0: 662e 6269 6173 203d 206e 6e2e 5061 7261  f.bias = nn.Para
-000080b0: 6d65 7465 7228 746f 7263 682e 7a65 726f  meter(torch.zero
-000080c0: 7328 636f 6e66 6967 2e76 6f63 6162 5f73  s(config.vocab_s
-000080d0: 697a 6529 290a 0a20 2020 2020 2020 2023  ize))..        #
-000080e0: 204e 6565 6420 6120 6c69 6e6b 2062 6574   Need a link bet
-000080f0: 7765 656e 2074 6865 2074 776f 2076 6172  ween the two var
-00008100: 6961 626c 6573 2073 6f20 7468 6174 2074  iables so that t
-00008110: 6865 2062 6961 7320 6973 2063 6f72 7265  he bias is corre
-00008120: 6374 6c79 2072 6573 697a 6564 2077 6974  ctly resized wit
-00008130: 6820 6072 6573 697a 655f 746f 6b65 6e5f  h `resize_token_
-00008140: 656d 6265 6464 696e 6773 600a 2020 2020  embeddings`.    
-00008150: 2020 2020 7365 6c66 2e64 6563 6f64 6572      self.decoder
-00008160: 2e62 6961 7320 3d20 7365 6c66 2e62 6961  .bias = self.bia
-00008170: 730a 0a20 2020 2064 6566 2066 6f72 7761  s..    def forwa
-00008180: 7264 2873 656c 662c 2068 6964 6465 6e5f  rd(self, hidden_
-00008190: 7374 6174 6573 293a 0a20 2020 2020 2020  states):.       
-000081a0: 2068 6964 6465 6e5f 7374 6174 6573 203d   hidden_states =
-000081b0: 2073 656c 662e 7472 616e 7366 6f72 6d28   self.transform(
-000081c0: 6869 6464 656e 5f73 7461 7465 7329 0a20  hidden_states). 
-000081d0: 2020 2020 2020 2068 6964 6465 6e5f 7374         hidden_st
-000081e0: 6174 6573 203d 2073 656c 662e 6465 636f  ates = self.deco
-000081f0: 6465 7228 6869 6464 656e 5f73 7461 7465  der(hidden_state
-00008200: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
-00008210: 6e20 6869 6464 656e 5f73 7461 7465 730a  n hidden_states.
-00008220: 0a0a 636c 6173 7320 4265 7274 4f6e 6c79  ..class BertOnly
-00008230: 4d4c 4d48 6561 6428 6e6e 2e4d 6f64 756c  MLMHead(nn.Modul
-00008240: 6529 3a0a 0a20 2020 2064 6566 205f 5f69  e):..    def __i
-00008250: 6e69 745f 5f28 7365 6c66 2c20 636f 6e66  nit__(self, conf
-00008260: 6967 293a 0a20 2020 2020 2020 2073 7570  ig):.        sup
-00008270: 6572 2829 2e5f 5f69 6e69 745f 5f28 290a  er().__init__().
-00008280: 2020 2020 2020 2020 7365 6c66 2e70 7265          self.pre
-00008290: 6469 6374 696f 6e73 203d 2042 6572 744c  dictions = BertL
-000082a0: 4d50 7265 6469 6374 696f 6e48 6561 6428  MPredictionHead(
-000082b0: 636f 6e66 6967 290a 0a20 2020 2064 6566  config)..    def
-000082c0: 2066 6f72 7761 7264 2873 656c 662c 2073   forward(self, s
-000082d0: 6571 7565 6e63 655f 6f75 7470 7574 293a  equence_output):
-000082e0: 0a20 2020 2020 2020 2070 7265 6469 6374  .        predict
-000082f0: 696f 6e5f 7363 6f72 6573 203d 2073 656c  ion_scores = sel
-00008300: 662e 7072 6564 6963 7469 6f6e 7328 7365  f.predictions(se
-00008310: 7175 656e 6365 5f6f 7574 7075 7429 0a20  quence_output). 
-00008320: 2020 2020 2020 2072 6574 7572 6e20 7072         return pr
-00008330: 6564 6963 7469 6f6e 5f73 636f 7265 730a  ediction_scores.
-00008340: 0a0a 636c 6173 7320 4265 7274 4f6e 6c79  ..class BertOnly
-00008350: 4e53 5048 6561 6428 6e6e 2e4d 6f64 756c  NSPHead(nn.Modul
-00008360: 6529 3a0a 0a20 2020 2064 6566 205f 5f69  e):..    def __i
-00008370: 6e69 745f 5f28 7365 6c66 2c20 636f 6e66  nit__(self, conf
-00008380: 6967 293a 0a20 2020 2020 2020 2073 7570  ig):.        sup
-00008390: 6572 2829 2e5f 5f69 6e69 745f 5f28 290a  er().__init__().
-000083a0: 2020 2020 2020 2020 7365 6c66 2e73 6571          self.seq
-000083b0: 5f72 656c 6174 696f 6e73 6869 7020 3d20  _relationship = 
-000083c0: 6e6e 2e4c 696e 6561 7228 636f 6e66 6967  nn.Linear(config
-000083d0: 2e68 6964 6465 6e5f 7369 7a65 2c20 3229  .hidden_size, 2)
-000083e0: 0a0a 2020 2020 6465 6620 666f 7277 6172  ..    def forwar
-000083f0: 6428 7365 6c66 2c20 706f 6f6c 6564 5f6f  d(self, pooled_o
-00008400: 7574 7075 7429 3a0a 2020 2020 2020 2020  utput):.        
-00008410: 7365 715f 7265 6c61 7469 6f6e 7368 6970  seq_relationship
-00008420: 5f73 636f 7265 203d 2073 656c 662e 7365  _score = self.se
-00008430: 715f 7265 6c61 7469 6f6e 7368 6970 2870  q_relationship(p
-00008440: 6f6f 6c65 645f 6f75 7470 7574 290a 2020  ooled_output).  
-00008450: 2020 2020 2020 7265 7475 726e 2073 6571        return seq
-00008460: 5f72 656c 6174 696f 6e73 6869 705f 7363  _relationship_sc
-00008470: 6f72 650a 0a0a 636c 6173 7320 4265 7274  ore...class Bert
-00008480: 5072 6554 7261 696e 696e 6748 6561 6473  PreTrainingHeads
-00008490: 286e 6e2e 4d6f 6475 6c65 293a 0a0a 2020  (nn.Module):..  
-000084a0: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-000084b0: 656c 662c 2063 6f6e 6669 6729 3a0a 2020  elf, config):.  
-000084c0: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
-000084d0: 696e 6974 5f5f 2829 0a20 2020 2020 2020  init__().       
-000084e0: 2073 656c 662e 7072 6564 6963 7469 6f6e   self.prediction
-000084f0: 7320 3d20 4265 7274 4c4d 5072 6564 6963  s = BertLMPredic
-00008500: 7469 6f6e 4865 6164 2863 6f6e 6669 6729  tionHead(config)
-00008510: 0a20 2020 2020 2020 2073 656c 662e 7365  .        self.se
-00008520: 715f 7265 6c61 7469 6f6e 7368 6970 203d  q_relationship =
-00008530: 206e 6e2e 4c69 6e65 6172 2863 6f6e 6669   nn.Linear(confi
-00008540: 672e 6869 6464 656e 5f73 697a 652c 2032  g.hidden_size, 2
-00008550: 290a 0a20 2020 2064 6566 2066 6f72 7761  )..    def forwa
-00008560: 7264 2873 656c 662c 2073 6571 7565 6e63  rd(self, sequenc
-00008570: 655f 6f75 7470 7574 2c20 706f 6f6c 6564  e_output, pooled
-00008580: 5f6f 7574 7075 7429 3a0a 2020 2020 2020  _output):.      
-00008590: 2020 7072 6564 6963 7469 6f6e 5f73 636f    prediction_sco
-000085a0: 7265 7320 3d20 7365 6c66 2e70 7265 6469  res = self.predi
-000085b0: 6374 696f 6e73 2873 6571 7565 6e63 655f  ctions(sequence_
-000085c0: 6f75 7470 7574 290a 2020 2020 2020 2020  output).        
-000085d0: 7365 715f 7265 6c61 7469 6f6e 7368 6970  seq_relationship
-000085e0: 5f73 636f 7265 203d 2073 656c 662e 7365  _score = self.se
-000085f0: 715f 7265 6c61 7469 6f6e 7368 6970 2870  q_relationship(p
-00008600: 6f6f 6c65 645f 6f75 7470 7574 290a 2020  ooled_output).  
-00008610: 2020 2020 2020 7265 7475 726e 2070 7265        return pre
-00008620: 6469 6374 696f 6e5f 7363 6f72 6573 2c20  diction_scores, 
-00008630: 7365 715f 7265 6c61 7469 6f6e 7368 6970  seq_relationship
-00008640: 5f73 636f 7265 0a0a 0a63 6c61 7373 2042  _score...class B
-00008650: 6572 7450 7265 5472 6169 6e65 644d 6f64  ertPreTrainedMod
-00008660: 656c 2850 7265 5472 6169 6e65 644d 6f64  el(PreTrainedMod
-00008670: 656c 293a 0a20 2020 2022 2222 0a20 2020  el):.    """.   
-00008680: 2041 6e20 6162 7374 7261 6374 2063 6c61   An abstract cla
-00008690: 7373 2074 6f20 6861 6e64 6c65 2077 6569  ss to handle wei
-000086a0: 6768 7473 2069 6e69 7469 616c 697a 6174  ghts initializat
-000086b0: 696f 6e20 616e 6420 6120 7369 6d70 6c65  ion and a simple
-000086c0: 2069 6e74 6572 6661 6365 0a20 2020 2066   interface.    f
-000086d0: 6f72 2064 6f77 6e6c 6f61 6469 6e67 2061  or downloading a
-000086e0: 6e64 206c 6f61 6469 6e67 2070 7265 7472  nd loading pretr
-000086f0: 6169 6e65 6420 6d6f 6465 6c73 2e0a 2020  ained models..  
-00008700: 2020 2222 220a 0a20 2020 2063 6f6e 6669    """..    confi
-00008710: 675f 636c 6173 7320 3d20 4265 7274 436f  g_class = BertCo
-00008720: 6e66 6967 0a20 2020 206c 6f61 645f 7466  nfig.    load_tf
-00008730: 5f77 6569 6768 7473 203d 206c 6f61 645f  _weights = load_
-00008740: 7466 5f77 6569 6768 7473 5f69 6e5f 6265  tf_weights_in_be
-00008750: 7274 0a20 2020 2062 6173 655f 6d6f 6465  rt.    base_mode
-00008760: 6c5f 7072 6566 6978 203d 2027 6265 7274  l_prefix = 'bert
-00008770: 270a 2020 2020 5f6b 6579 735f 746f 5f69  '.    _keys_to_i
-00008780: 676e 6f72 655f 6f6e 5f6c 6f61 645f 6d69  gnore_on_load_mi
-00008790: 7373 696e 6720 3d20 5b72 2770 6f73 6974  ssing = [r'posit
-000087a0: 696f 6e5f 6964 7327 5d0a 0a20 2020 2064  ion_ids']..    d
-000087b0: 6566 205f 696e 6974 5f77 6569 6768 7473  ef _init_weights
-000087c0: 2873 656c 662c 206d 6f64 756c 6529 3a0a  (self, module):.
-000087d0: 2020 2020 2020 2020 2222 2220 496e 6974          """ Init
-000087e0: 6961 6c69 7a65 2074 6865 2077 6569 6768  ialize the weigh
-000087f0: 7473 2022 2222 0a20 2020 2020 2020 2069  ts """.        i
-00008800: 6620 6973 696e 7374 616e 6365 286d 6f64  f isinstance(mod
-00008810: 756c 652c 2028 6e6e 2e4c 696e 6561 722c  ule, (nn.Linear,
-00008820: 206e 6e2e 456d 6265 6464 696e 6729 293a   nn.Embedding)):
-00008830: 0a20 2020 2020 2020 2020 2020 2023 2053  .            # S
-00008840: 6c69 6768 746c 7920 6469 6666 6572 656e  lightly differen
-00008850: 7420 6672 6f6d 2074 6865 2054 4620 7665  t from the TF ve
-00008860: 7273 696f 6e20 7768 6963 6820 7573 6573  rsion which uses
-00008870: 2074 7275 6e63 6174 6564 5f6e 6f72 6d61   truncated_norma
-00008880: 6c20 666f 7220 696e 6974 6961 6c69 7a61  l for initializa
-00008890: 7469 6f6e 0a20 2020 2020 2020 2020 2020  tion.           
-000088a0: 2023 2063 6620 6874 7470 733a 2f2f 6769   # cf https://gi
-000088b0: 7468 7562 2e63 6f6d 2f70 7974 6f72 6368  thub.com/pytorch
-000088c0: 2f70 7974 6f72 6368 2f70 756c 6c2f 3536  /pytorch/pull/56
-000088d0: 3137 0a20 2020 2020 2020 2020 2020 206d  17.            m
-000088e0: 6f64 756c 652e 7765 6967 6874 2e64 6174  odule.weight.dat
-000088f0: 612e 6e6f 726d 616c 5f28 0a20 2020 2020  a.normal_(.     
-00008900: 2020 2020 2020 2020 2020 206d 6561 6e3d             mean=
-00008910: 302e 302c 2073 7464 3d73 656c 662e 636f  0.0, std=self.co
-00008920: 6e66 6967 2e69 6e69 7469 616c 697a 6572  nfig.initializer
-00008930: 5f72 616e 6765 290a 2020 2020 2020 2020  _range).        
-00008940: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
-00008950: 6d6f 6475 6c65 2c20 6e6e 2e4c 6179 6572  module, nn.Layer
-00008960: 4e6f 726d 293a 0a20 2020 2020 2020 2020  Norm):.         
-00008970: 2020 206d 6f64 756c 652e 6269 6173 2e64     module.bias.d
-00008980: 6174 612e 7a65 726f 5f28 290a 2020 2020  ata.zero_().    
-00008990: 2020 2020 2020 2020 6d6f 6475 6c65 2e77          module.w
-000089a0: 6569 6768 742e 6461 7461 2e66 696c 6c5f  eight.data.fill_
-000089b0: 2831 2e30 290a 2020 2020 2020 2020 6966  (1.0).        if
-000089c0: 2069 7369 6e73 7461 6e63 6528 6d6f 6475   isinstance(modu
-000089d0: 6c65 2c20 6e6e 2e4c 696e 6561 7229 2061  le, nn.Linear) a
-000089e0: 6e64 206d 6f64 756c 652e 6269 6173 2069  nd module.bias i
-000089f0: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
-00008a00: 2020 2020 2020 2020 6d6f 6475 6c65 2e62          module.b
-00008a10: 6961 732e 6461 7461 2e7a 6572 6f5f 2829  ias.data.zero_()
-00008a20: 0a0a 0a40 6461 7461 636c 6173 730a 636c  ...@dataclass.cl
-00008a30: 6173 7320 4265 7274 466f 7250 7265 5472  ass BertForPreTr
-00008a40: 6169 6e69 6e67 4f75 7470 7574 284d 6f64  ainingOutput(Mod
-00008a50: 656c 4f75 7470 7574 293a 0a20 2020 2022  elOutput):.    "
-00008a60: 2222 0a20 2020 204f 7574 7075 7420 7479  "".    Output ty
-00008a70: 7065 206f 6620 3a63 6c61 7373 3a60 7e74  pe of :class:`~t
-00008a80: 7261 6e73 666f 726d 6572 732e 4265 7274  ransformers.Bert
-00008a90: 466f 7250 7265 5472 6169 6e69 6e67 602e  ForPreTraining`.
-00008aa0: 2041 7267 733a 0a20 2020 2020 2020 206c   Args:.        l
-00008ab0: 6f73 7320 2860 6f70 7469 6f6e 616c 602c  oss (`optional`,
-00008ac0: 2072 6574 7572 6e65 6420 7768 656e 2060   returned when `
-00008ad0: 606c 6162 656c 7360 6020 6973 2070 726f  `labels`` is pro
-00008ae0: 7669 6465 642c 0a20 2020 2020 2020 2060  vided,.        `
-00008af0: 6074 6f72 6368 2e46 6c6f 6174 5465 6e73  `torch.FloatTens
-00008b00: 6f72 6060 206f 6620 7368 6170 6520 3a6f  or`` of shape :o
-00008b10: 626a 3a60 2831 2c29 6029 3a0a 2020 2020  bj:`(1,)`):.    
-00008b20: 2020 2020 2020 2020 546f 7461 6c20 6c6f          Total lo
-00008b30: 7373 2061 7320 7468 6520 7375 6d20 6f66  ss as the sum of
-00008b40: 2074 6865 206d 6173 6b65 6420 6c61 6e67   the masked lang
-00008b50: 7561 6765 206d 6f64 656c 696e 6720 6c6f  uage modeling lo
-00008b60: 7373 2061 6e64 2074 6865 0a20 2020 2020  ss and the.     
-00008b70: 2020 2020 2020 206e 6578 7420 7365 7175         next sequ
-00008b80: 656e 6365 2070 7265 6469 6374 696f 6e20  ence prediction 
-00008b90: 2863 6c61 7373 6966 6963 6174 696f 6e29  (classification)
-00008ba0: 206c 6f73 732e 0a20 2020 2020 2020 2070   loss..        p
-00008bb0: 7265 6469 6374 696f 6e5f 6c6f 6769 7473  rediction_logits
-00008bc0: 2028 3a6f 626a 3a60 746f 7263 682e 466c   (:obj:`torch.Fl
-00008bd0: 6f61 7454 656e 736f 7260 206f 6620 7368  oatTensor` of sh
-00008be0: 6170 6520 3a6f 626a 3a60 2862 6174 6368  ape :obj:`(batch
-00008bf0: 5f73 697a 652c 0a20 2020 2020 2020 2073  _size,.        s
-00008c00: 6571 7565 6e63 655f 6c65 6e67 7468 2c20  equence_length, 
-00008c10: 636f 6e66 6967 2e76 6f63 6162 5f73 697a  config.vocab_siz
-00008c20: 6529 6029 3a0a 2020 2020 2020 2020 2020  e)`):.          
-00008c30: 2020 5072 6564 6963 7469 6f6e 2073 636f    Prediction sco
-00008c40: 7265 7320 6f66 2074 6865 206c 616e 6775  res of the langu
-00008c50: 6167 6520 6d6f 6465 6c69 6e67 2068 6561  age modeling hea
-00008c60: 6420 2873 636f 7265 7320 666f 7220 6561  d (scores for ea
-00008c70: 6368 0a20 2020 2020 2020 2020 2020 2076  ch.            v
-00008c80: 6f63 6162 756c 6172 7920 746f 6b65 6e20  ocabulary token 
-00008c90: 6265 666f 7265 2053 6f66 744d 6178 292e  before SoftMax).
-00008ca0: 0a20 2020 2020 2020 2073 6571 5f72 656c  .        seq_rel
-00008cb0: 6174 696f 6e73 6869 705f 6c6f 6769 7473  ationship_logits
-00008cc0: 2028 3a6f 626a 3a60 746f 7263 682e 466c   (:obj:`torch.Fl
-00008cd0: 6f61 7454 656e 736f 7260 206f 6620 7368  oatTensor` of sh
-00008ce0: 6170 650a 2020 2020 2020 2020 3a6f 626a  ape.        :obj
-00008cf0: 3a60 2862 6174 6368 5f73 697a 652c 2032  :`(batch_size, 2
-00008d00: 2960 293a 0a20 2020 2020 2020 2020 2020  )`):.           
-00008d10: 2050 7265 6469 6374 696f 6e20 7363 6f72   Prediction scor
-00008d20: 6573 206f 6620 7468 6520 6e65 7874 2073  es of the next s
-00008d30: 6571 7565 6e63 6520 7072 6564 6963 7469  equence predicti
-00008d40: 6f6e 2028 636c 6173 7369 6669 6361 7469  on (classificati
-00008d50: 6f6e 290a 2020 2020 2020 2020 2020 2020  on).            
-00008d60: 6865 6164 2028 7363 6f72 6573 206f 6620  head (scores of 
-00008d70: 5472 7565 2f46 616c 7365 2063 6f6e 7469  True/False conti
-00008d80: 6e75 6174 696f 6e20 6265 666f 7265 2053  nuation before S
-00008d90: 6f66 744d 6178 292e 0a20 2020 2020 2020  oftMax)..       
-00008da0: 2068 6964 6465 6e5f 7374 6174 6573 2028   hidden_states (
-00008db0: 3a6f 626a 3a60 7475 706c 6528 746f 7263  :obj:`tuple(torc
-00008dc0: 682e 466c 6f61 7454 656e 736f 7229 602c  h.FloatTensor)`,
-00008dd0: 2060 6f70 7469 6f6e 616c 602c 2072 6574   `optional`, ret
-00008de0: 7572 6e65 640a 2020 2020 2020 2020 7768  urned.        wh
-00008df0: 656e 2060 606f 7574 7075 745f 6869 6464  en ``output_hidd
-00008e00: 656e 5f73 7461 7465 733d 5472 7565 6060  en_states=True``
-00008e10: 2069 7320 7061 7373 6564 206f 7220 7768   is passed or wh
-00008e20: 656e 0a20 2020 2020 2020 2060 6063 6f6e  en.        ``con
-00008e30: 6669 672e 6f75 7470 7574 5f68 6964 6465  fig.output_hidde
-00008e40: 6e5f 7374 6174 6573 3d54 7275 6560 6029  n_states=True``)
-00008e50: 3a0a 2020 2020 2020 2020 2020 2020 5475  :.            Tu
-00008e60: 706c 6520 6f66 203a 6f62 6a3a 6074 6f72  ple of :obj:`tor
-00008e70: 6368 2e46 6c6f 6174 5465 6e73 6f72 6020  ch.FloatTensor` 
-00008e80: 286f 6e65 2066 6f72 2074 6865 206f 7574  (one for the out
-00008e90: 7075 7420 6f66 2074 6865 0a20 2020 2020  put of the.     
-00008ea0: 2020 2020 2020 2065 6d62 6564 6469 6e67         embedding
-00008eb0: 7320 2b20 6f6e 6520 666f 7220 7468 6520  s + one for the 
-00008ec0: 6f75 7470 7574 206f 6620 6561 6368 206c  output of each l
-00008ed0: 6179 6572 2920 6f66 2073 6861 7065 0a20  ayer) of shape. 
-00008ee0: 2020 2020 2020 2020 2020 203a 6f62 6a3a             :obj:
-00008ef0: 6028 6261 7463 685f 7369 7a65 2c20 7365  `(batch_size, se
-00008f00: 7175 656e 6365 5f6c 656e 6774 682c 2068  quence_length, h
-00008f10: 6964 6465 6e5f 7369 7a65 2960 2e20 4869  idden_size)`. Hi
-00008f20: 6464 656e 2d73 7461 7465 7320 6f66 0a20  dden-states of. 
-00008f30: 2020 2020 2020 2020 2020 2074 6865 206d             the m
-00008f40: 6f64 656c 2061 7420 7468 6520 6f75 7470  odel at the outp
-00008f50: 7574 206f 6620 6561 6368 206c 6179 6572  ut of each layer
-00008f60: 2070 6c75 7320 7468 6520 696e 6974 6961   plus the initia
-00008f70: 6c20 656d 6265 6464 696e 670a 2020 2020  l embedding.    
-00008f80: 2020 2020 2020 2020 6f75 7470 7574 732e          outputs.
-00008f90: 0a20 2020 2020 2020 2061 7474 656e 7469  .        attenti
-00008fa0: 6f6e 7320 283a 6f62 6a3a 6074 7570 6c65  ons (:obj:`tuple
-00008fb0: 2874 6f72 6368 2e46 6c6f 6174 5465 6e73  (torch.FloatTens
-00008fc0: 6f72 2960 2c20 606f 7074 696f 6e61 6c60  or)`, `optional`
-00008fd0: 2c20 7265 7475 726e 6564 2077 6865 6e0a  , returned when.
-00008fe0: 2020 2020 2020 2020 6060 6f75 7470 7574          ``output
-00008ff0: 5f61 7474 656e 7469 6f6e 733d 5472 7565  _attentions=True
-00009000: 6060 2069 7320 7061 7373 6564 206f 7220  `` is passed or 
-00009010: 7768 656e 0a20 2020 2020 2020 2060 6063  when.        ``c
-00009020: 6f6e 6669 672e 6f75 7470 7574 5f61 7474  onfig.output_att
-00009030: 656e 7469 6f6e 733d 5472 7565 6060 293a  entions=True``):
-00009040: 0a20 2020 2020 2020 2020 2020 2054 7570  .            Tup
-00009050: 6c65 206f 6620 3a6f 626a 3a60 746f 7263  le of :obj:`torc
-00009060: 682e 466c 6f61 7454 656e 736f 7260 2028  h.FloatTensor` (
-00009070: 6f6e 6520 666f 7220 6561 6368 206c 6179  one for each lay
-00009080: 6572 2920 6f66 2073 6861 7065 0a20 2020  er) of shape.   
-00009090: 2020 2020 2020 2020 203a 6f62 6a3a 6028           :obj:`(
-000090a0: 6261 7463 685f 7369 7a65 2c20 6e75 6d5f  batch_size, num_
-000090b0: 6865 6164 732c 2073 6571 7565 6e63 655f  heads, sequence_
-000090c0: 6c65 6e67 7468 2c20 7365 7175 656e 6365  length, sequence
-000090d0: 5f6c 656e 6774 6829 602e 0a20 2020 2020  _length)`..     
-000090e0: 2020 2020 2020 2041 7474 656e 7469 6f6e         Attention
-000090f0: 7320 7765 6967 6874 7320 6166 7465 7220  s weights after 
-00009100: 7468 6520 6174 7465 6e74 696f 6e20 736f  the attention so
-00009110: 6674 6d61 782c 2075 7365 6420 746f 2063  ftmax, used to c
-00009120: 6f6d 7075 7465 2074 6865 0a20 2020 2020  ompute the.     
-00009130: 2020 2020 2020 2077 6569 6768 7465 6420         weighted 
-00009140: 6176 6572 6167 6520 696e 2074 6865 2073  average in the s
-00009150: 656c 662d 6174 7465 6e74 696f 6e20 6865  elf-attention he
-00009160: 6164 732e 0a20 2020 2022 2222 0a0a 2020  ads..    """..  
-00009170: 2020 6c6f 7373 3a20 4f70 7469 6f6e 616c    loss: Optional
-00009180: 5b74 6f72 6368 2e46 6c6f 6174 5465 6e73  [torch.FloatTens
-00009190: 6f72 5d20 3d20 4e6f 6e65 0a20 2020 2070  or] = None.    p
-000091a0: 7265 6469 6374 696f 6e5f 6c6f 6769 7473  rediction_logits
-000091b0: 3a20 746f 7263 682e 466c 6f61 7454 656e  : torch.FloatTen
-000091c0: 736f 7220 3d20 4e6f 6e65 0a20 2020 2073  sor = None.    s
-000091d0: 6571 5f72 656c 6174 696f 6e73 6869 705f  eq_relationship_
-000091e0: 6c6f 6769 7473 3a20 746f 7263 682e 466c  logits: torch.Fl
-000091f0: 6f61 7454 656e 736f 7220 3d20 4e6f 6e65  oatTensor = None
-00009200: 0a20 2020 2068 6964 6465 6e5f 7374 6174  .    hidden_stat
-00009210: 6573 3a20 4f70 7469 6f6e 616c 5b54 7570  es: Optional[Tup
-00009220: 6c65 5b74 6f72 6368 2e46 6c6f 6174 5465  le[torch.FloatTe
-00009230: 6e73 6f72 5d5d 203d 204e 6f6e 650a 2020  nsor]] = None.  
-00009240: 2020 6174 7465 6e74 696f 6e73 3a20 4f70    attentions: Op
-00009250: 7469 6f6e 616c 5b54 7570 6c65 5b74 6f72  tional[Tuple[tor
-00009260: 6368 2e46 6c6f 6174 5465 6e73 6f72 5d5d  ch.FloatTensor]]
-00009270: 203d 204e 6f6e 650a 0a0a 636c 6173 7320   = None...class 
-00009280: 4265 7274 4d6f 6465 6c28 4265 7274 5072  BertModel(BertPr
-00009290: 6554 7261 696e 6564 4d6f 6465 6c29 3a0a  eTrainedModel):.
-000092a0: 2020 2020 2222 220a 2020 2020 4e6f 7465      """.    Note
-000092b0: 6420 7468 6174 2074 6865 2062 6572 7420  d that the bert 
-000092c0: 6d6f 6465 6c20 6865 7265 2069 7320 736c  model here is sl
-000092d0: 6967 6874 6c79 2075 7064 6174 6564 2066  ightly updated f
-000092e0: 726f 6d20 6f72 6967 696e 616c 2062 6572  rom original ber
-000092f0: 742c 2073 6f20 7765 0a20 2020 206d 6169  t, so we.    mai
-00009300: 6e74 6961 6e20 7468 6520 636f 6465 2068  ntian the code h
-00009310: 6572 6520 696e 6465 7065 6e64 656e 746c  ere independentl
-00009320: 792e 2054 6865 2042 6572 7420 4d6f 6465  y. The Bert Mode
-00009330: 6c20 7472 616e 7366 6f72 6d65 7220 6f75  l transformer ou
-00009340: 7470 7574 7469 6e67 0a20 2020 2072 6177  tputting.    raw
-00009350: 2068 6964 6465 6e2d 7374 6174 6573 2077   hidden-states w
-00009360: 6974 686f 7574 2061 6e79 2073 7065 6369  ithout any speci
-00009370: 6669 6320 6865 6164 206f 6e20 746f 702e  fic head on top.
-00009380: 0a0a 2020 2020 5468 6973 206d 6f64 656c  ..    This model
-00009390: 2069 6e68 6572 6974 7320 6672 6f6d 205b   inherits from [
-000093a0: 6050 7265 5472 6169 6e65 644d 6f64 656c  `PreTrainedModel
-000093b0: 605d 2e20 4368 6563 6b20 7468 6520 7375  `]. Check the su
-000093c0: 7065 7263 6c61 7373 0a20 2020 2064 6f63  perclass.    doc
-000093d0: 756d 656e 7461 7469 6f6e 2066 6f72 2074  umentation for t
-000093e0: 6865 2067 656e 6572 6963 206d 6574 686f  he generic metho
-000093f0: 6473 2074 6865 206c 6962 7261 7279 2069  ds the library i
-00009400: 6d70 6c65 6d65 6e74 7320 666f 7220 616c  mplements for al
-00009410: 6c20 6974 730a 2020 2020 6d6f 6465 6c20  l its.    model 
-00009420: 2873 7563 6820 6173 2064 6f77 6e6c 6f61  (such as downloa
-00009430: 6469 6e67 206f 7220 7361 7669 6e67 2c20  ding or saving, 
-00009440: 7265 7369 7a69 6e67 2074 6865 2069 6e70  resizing the inp
-00009450: 7574 2065 6d62 6564 6469 6e67 732c 2070  ut embeddings, p
-00009460: 7275 6e69 6e67 0a20 2020 2068 6561 6473  runing.    heads
-00009470: 2065 7463 2e29 0a0a 2020 2020 5468 6973   etc.)..    This
-00009480: 206d 6f64 656c 2069 7320 616c 736f 2061   model is also a
-00009490: 2050 7954 6f72 6368 0a20 2020 205b 746f   PyTorch.    [to
-000094a0: 7263 682e 6e6e 2e4d 6f64 756c 655d 2868  rch.nn.Module](h
-000094b0: 7474 7073 3a2f 2f70 7974 6f72 6368 2e6f  ttps://pytorch.o
-000094c0: 7267 2f64 6f63 732f 7374 6162 6c65 2f6e  rg/docs/stable/n
-000094d0: 6e2e 6874 6d6c 2374 6f72 6368 2e6e 6e2e  n.html#torch.nn.
-000094e0: 4d6f 6475 6c65 290a 2020 2020 7375 6263  Module).    subc
-000094f0: 6c61 7373 2e20 5573 6520 6974 2061 7320  lass. Use it as 
-00009500: 6120 7265 6775 6c61 7220 5079 546f 7263  a regular PyTorc
-00009510: 6820 4d6f 6475 6c65 2061 6e64 2072 6566  h Module and ref
-00009520: 6572 2074 6f20 7468 6520 5079 546f 7263  er to the PyTorc
-00009530: 680a 2020 2020 646f 6375 6d65 6e74 6174  h.    documentat
-00009540: 696f 6e20 666f 7220 616c 6c20 6d61 7474  ion for all matt
-00009550: 6572 2072 656c 6174 6564 2074 6f20 6765  er related to ge
-00009560: 6e65 7261 6c20 7573 6167 6520 616e 6420  neral usage and 
-00009570: 6265 6861 7669 6f72 2e0a 0a20 2020 2050  behavior...    P
-00009580: 6172 616d 6574 6572 733a 0a20 2020 2020  arameters:.     
-00009590: 2020 2063 6f6e 6669 6720 285b 6042 6572     config ([`Ber
-000095a0: 7443 6f6e 6669 6760 5d29 3a20 4d6f 6465  tConfig`]): Mode
-000095b0: 6c20 636f 6e66 6967 7572 6174 696f 6e20  l configuration 
-000095c0: 636c 6173 7320 7769 7468 2061 6c6c 2074  class with all t
-000095d0: 6865 0a20 2020 2020 2020 2070 6172 616d  he.        param
-000095e0: 6574 6572 7320 6f66 2074 6865 206d 6f64  eters of the mod
-000095f0: 656c 2e0a 2020 2020 2020 2020 2020 2020  el..            
-00009600: 496e 6974 6961 6c69 7a69 6e67 2077 6974  Initializing wit
-00009610: 6820 6120 636f 6e66 6967 2066 696c 6520  h a config file 
-00009620: 646f 6573 206e 6f74 206c 6f61 6420 7468  does not load th
-00009630: 6520 7765 6967 6874 7320 6173 736f 6369  e weights associ
-00009640: 6174 6564 0a20 2020 2020 2020 2020 2020  ated.           
-00009650: 2077 6974 6820 7468 6520 6d6f 6465 6c2c   with the model,
-00009660: 206f 6e6c 7920 7468 6520 636f 6e66 6967   only the config
-00009670: 7572 6174 696f 6e2e 2043 6865 636b 206f  uration. Check o
-00009680: 7574 2074 6865 0a20 2020 2020 2020 2020  ut the.         
-00009690: 2020 205b 607e 5072 6554 7261 696e 6564     [`~PreTrained
-000096a0: 4d6f 6465 6c2e 6672 6f6d 5f70 7265 7472  Model.from_pretr
-000096b0: 6169 6e65 6460 5d20 6d65 7468 6f64 2074  ained`] method t
-000096c0: 6f20 6c6f 6164 2074 6865 206d 6f64 656c  o load the model
-000096d0: 0a20 2020 2020 2020 2020 2020 2077 6569  .            wei
-000096e0: 6768 7473 2e0a 0a20 2020 2054 6865 206d  ghts...    The m
-000096f0: 6f64 656c 2063 616e 2062 6568 6176 6520  odel can behave 
-00009700: 6173 2061 6e20 656e 636f 6465 7220 2877  as an encoder (w
-00009710: 6974 6820 6f6e 6c79 2073 656c 662d 6174  ith only self-at
-00009720: 7465 6e74 696f 6e29 2061 7320 7765 6c6c  tention) as well
-00009730: 2061 7320 610a 2020 2020 6465 636f 6465   as a.    decode
-00009740: 722c 2069 6e20 7768 6963 6820 6361 7365  r, in which case
-00009750: 2061 206c 6179 6572 206f 6620 6372 6f73   a layer of cros
-00009760: 732d 6174 7465 6e74 696f 6e20 6973 2061  s-attention is a
-00009770: 6464 6564 2062 6574 7765 656e 2074 6865  dded between the
-00009780: 0a20 2020 2073 656c 662d 6174 7465 6e74  .    self-attent
-00009790: 696f 6e20 6c61 7965 7273 2c20 666f 6c6c  ion layers, foll
-000097a0: 6f77 696e 6720 7468 6520 6172 6368 6974  owing the archit
-000097b0: 6563 7475 7265 2064 6573 6372 6962 6564  ecture described
-000097c0: 2069 6e20 5b41 7474 656e 7469 6f6e 2069   in [Attention i
-000097d0: 730a 2020 2020 616c 6c20 796f 7520 6e65  s.    all you ne
-000097e0: 6564 5d28 6874 7470 733a 2f2f 6172 7869  ed](https://arxi
-000097f0: 762e 6f72 672f 6162 732f 3137 3036 2e30  v.org/abs/1706.0
-00009800: 3337 3632 2920 6279 2041 7368 6973 6820  3762) by Ashish 
-00009810: 5661 7377 616e 692c 204e 6f61 6d0a 2020  Vaswani, Noam.  
-00009820: 2020 5368 617a 6565 722c 204e 696b 6920    Shazeer, Niki 
-00009830: 5061 726d 6172 2c20 4a61 6b6f 6220 5573  Parmar, Jakob Us
-00009840: 7a6b 6f72 6569 742c 204c 6c69 6f6e 204a  zkoreit, Llion J
-00009850: 6f6e 6573 2c20 4169 6461 6e20 4e2e 2047  ones, Aidan N. G
-00009860: 6f6d 657a 2c20 4c75 6b61 737a 0a20 2020  omez, Lukasz.   
-00009870: 204b 6169 7365 7220 616e 6420 496c 6c69   Kaiser and Illi
-00009880: 6120 506f 6c6f 7375 6b68 696e 2e0a 0a20  a Polosukhin... 
-00009890: 2020 2054 6f20 6265 6861 7665 2061 7320     To behave as 
-000098a0: 616e 2064 6563 6f64 6572 2074 6865 206d  an decoder the m
-000098b0: 6f64 656c 206e 6565 6473 2074 6f20 6265  odel needs to be
-000098c0: 2069 6e69 7469 616c 697a 6564 2077 6974   initialized wit
-000098d0: 6820 7468 650a 2020 2020 6069 735f 6465  h the.    `is_de
-000098e0: 636f 6465 7260 2061 7267 756d 656e 7420  coder` argument 
-000098f0: 6f66 2074 6865 2063 6f6e 6669 6775 7261  of the configura
-00009900: 7469 6f6e 2073 6574 2074 6f20 6054 7275  tion set to `Tru
-00009910: 6560 2e20 546f 2062 6520 7573 6564 2069  e`. To be used i
-00009920: 6e20 610a 2020 2020 5365 7132 5365 7120  n a.    Seq2Seq 
-00009930: 6d6f 6465 6c2c 2074 6865 206d 6f64 656c  model, the model
-00009940: 206e 6565 6473 2074 6f20 696e 6974 6961   needs to initia
-00009950: 6c69 7a65 6420 7769 7468 2062 6f74 6820  lized with both 
-00009960: 6069 735f 6465 636f 6465 7260 0a20 2020  `is_decoder`.   
-00009970: 2061 7267 756d 656e 7420 616e 6420 6061   argument and `a
-00009980: 6464 5f63 726f 7373 5f61 7474 656e 7469  dd_cross_attenti
-00009990: 6f6e 6020 7365 7420 746f 2060 5472 7565  on` set to `True
-000099a0: 603b 2061 6e20 6065 6e63 6f64 6572 5f68  `; an `encoder_h
-000099b0: 6964 6465 6e5f 7374 6174 6573 600a 2020  idden_states`.  
-000099c0: 2020 6973 2074 6865 6e20 6578 7065 6374    is then expect
-000099d0: 6564 2061 7320 616e 2069 6e70 7574 2074  ed as an input t
-000099e0: 6f20 7468 6520 666f 7277 6172 6420 7061  o the forward pa
-000099f0: 7373 2e0a 0a0a 2020 2020 2222 220a 0a20  ss....    """.. 
-00009a00: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00009a10: 7365 6c66 2c20 636f 6e66 6967 2c20 6164  self, config, ad
-00009a20: 645f 706f 6f6c 696e 675f 6c61 7965 723d  d_pooling_layer=
-00009a30: 5472 7565 293a 0a20 2020 2020 2020 2073  True):.        s
-00009a40: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
-00009a50: 636f 6e66 6967 290a 2020 2020 2020 2020  config).        
-00009a60: 7365 6c66 2e63 6f6e 6669 6720 3d20 636f  self.config = co
-00009a70: 6e66 6967 0a0a 2020 2020 2020 2020 6966  nfig..        if
-00009a80: 2063 6f6e 6669 672e 6769 735f 656d 6265   config.gis_embe
-00009a90: 6464 696e 6720 3d3d 2030 3a0a 2020 2020  dding == 0:.    
-00009aa0: 2020 2020 2020 2020 7365 6c66 2e65 6d62          self.emb
-00009ab0: 6564 6469 6e67 7320 3d20 4265 7274 456d  eddings = BertEm
-00009ac0: 6265 6464 696e 6773 2863 6f6e 6669 6729  beddings(config)
-00009ad0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00009ae0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00009af0: 656d 6265 6464 696e 6773 203d 2047 6973  embeddings = Gis
-00009b00: 456d 6265 6464 696e 6773 2863 6f6e 6669  Embeddings(confi
-00009b10: 6729 0a0a 2020 2020 2020 2020 7365 6c66  g)..        self
-00009b20: 2e65 6e63 6f64 6572 203d 2042 6572 7445  .encoder = BertE
-00009b30: 6e63 6f64 6572 2863 6f6e 6669 6729 0a0a  ncoder(config)..
-00009b40: 2020 2020 2020 2020 7365 6c66 2e70 6f6f          self.poo
-00009b50: 6c65 7220 3d20 4265 7274 506f 6f6c 6572  ler = BertPooler
-00009b60: 2863 6f6e 6669 6729 2069 6620 6164 645f  (config) if add_
-00009b70: 706f 6f6c 696e 675f 6c61 7965 7220 656c  pooling_layer el
-00009b80: 7365 204e 6f6e 650a 0a20 2020 2020 2020  se None..       
-00009b90: 2073 656c 662e 696e 6974 5f77 6569 6768   self.init_weigh
-00009ba0: 7473 2829 0a0a 2020 2020 6465 6620 6765  ts()..    def ge
-00009bb0: 745f 696e 7075 745f 656d 6265 6464 696e  t_input_embeddin
-00009bc0: 6773 2873 656c 6629 3a0a 2020 2020 2020  gs(self):.      
-00009bd0: 2020 7265 7475 726e 2073 656c 662e 656d    return self.em
-00009be0: 6265 6464 696e 6773 2e77 6f72 645f 656d  beddings.word_em
-00009bf0: 6265 6464 696e 6773 0a0a 2020 2020 6465  beddings..    de
-00009c00: 6620 7365 745f 696e 7075 745f 656d 6265  f set_input_embe
-00009c10: 6464 696e 6773 2873 656c 662c 2076 616c  ddings(self, val
-00009c20: 7565 293a 0a20 2020 2020 2020 2073 656c  ue):.        sel
-00009c30: 662e 656d 6265 6464 696e 6773 2e77 6f72  f.embeddings.wor
-00009c40: 645f 656d 6265 6464 696e 6773 203d 2076  d_embeddings = v
-00009c50: 616c 7565 0a0a 2020 2020 6465 6620 5f70  alue..    def _p
-00009c60: 7275 6e65 5f68 6561 6473 2873 656c 662c  rune_heads(self,
-00009c70: 2068 6561 6473 5f74 6f5f 7072 756e 6529   heads_to_prune)
-00009c80: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-00009c90: 2020 2020 2020 5072 756e 6573 2068 6561        Prunes hea
-00009ca0: 6473 206f 6620 7468 6520 6d6f 6465 6c2e  ds of the model.
-00009cb0: 2068 6561 6473 5f74 6f5f 7072 756e 653a   heads_to_prune:
-00009cc0: 2064 6963 7420 6f66 207b 6c61 7965 725f   dict of {layer_
-00009cd0: 6e75 6d3a 206c 6973 7420 6f66 2068 6561  num: list of hea
-00009ce0: 6473 2074 6f20 7072 756e 6520 696e 2074  ds to prune in t
-00009cf0: 6869 7320 6c61 7965 727d 2053 6565 2062  his layer} See b
-00009d00: 6173 650a 2020 2020 2020 2020 636c 6173  ase.        clas
-00009d10: 7320 5072 6554 7261 696e 6564 4d6f 6465  s PreTrainedMode
-00009d20: 6c0a 2020 2020 2020 2020 2222 220a 2020  l.        """.  
-00009d30: 2020 2020 2020 666f 7220 6c61 7965 722c        for layer,
-00009d40: 2068 6561 6473 2069 6e20 6865 6164 735f   heads in heads_
-00009d50: 746f 5f70 7275 6e65 2e69 7465 6d73 2829  to_prune.items()
-00009d60: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
-00009d70: 6c66 2e65 6e63 6f64 6572 2e6c 6179 6572  lf.encoder.layer
-00009d80: 5b6c 6179 6572 5d2e 6174 7465 6e74 696f  [layer].attentio
-00009d90: 6e2e 7072 756e 655f 6865 6164 7328 6865  n.prune_heads(he
-00009da0: 6164 7329 0a0a 2020 2020 6465 6620 6765  ads)..    def ge
-00009db0: 745f 6578 7465 6e64 6564 5f61 7474 656e  t_extended_atten
-00009dc0: 7469 6f6e 5f6d 6173 6b28 7365 6c66 2c20  tion_mask(self, 
-00009dd0: 6174 7465 6e74 696f 6e5f 6d61 736b 3a20  attention_mask: 
-00009de0: 5465 6e73 6f72 2c0a 2020 2020 2020 2020  Tensor,.        
-00009df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009e00: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
-00009e10: 745f 7368 6170 653a 2054 7570 6c65 5b69  t_shape: Tuple[i
-00009e20: 6e74 5d2c 2064 6576 6963 653a 2064 6576  nt], device: dev
-00009e30: 6963 652c 0a20 2020 2020 2020 2020 2020  ice,.           
-00009e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009e50: 2020 2020 2020 2020 2069 735f 6465 636f           is_deco
-00009e60: 6465 723a 2062 6f6f 6c29 202d 3e20 5465  der: bool) -> Te
-00009e70: 6e73 6f72 3a0a 2020 2020 2020 2020 2222  nsor:.        ""
-00009e80: 220a 2020 2020 2020 2020 4d61 6b65 7320  ".        Makes 
-00009e90: 6272 6f61 6463 6173 7461 626c 6520 6174  broadcastable at
-00009ea0: 7465 6e74 696f 6e20 616e 6420 6361 7573  tention and caus
-00009eb0: 616c 206d 6173 6b73 2073 6f20 7468 6174  al masks so that
-00009ec0: 2066 7574 7572 6520 616e 6420 6d61 736b   future and mask
-00009ed0: 6564 0a20 2020 2020 2020 2074 6f6b 656e  ed.        token
-00009ee0: 7320 6172 6520 6967 6e6f 7265 642e 0a0a  s are ignored...
-00009ef0: 2020 2020 2020 2020 4172 6775 6d65 6e74          Argument
-00009f00: 733a 0a20 2020 2020 2020 2020 2020 2061  s:.            a
-00009f10: 7474 656e 7469 6f6e 5f6d 6173 6b20 283a  ttention_mask (:
-00009f20: 6f62 6a3a 6074 6f72 6368 2e54 656e 736f  obj:`torch.Tenso
-00009f30: 7260 293a 0a20 2020 2020 2020 2020 2020  r`):.           
-00009f40: 2020 2020 204d 6173 6b20 7769 7468 206f       Mask with o
-00009f50: 6e65 7320 696e 6469 6361 7469 6e67 2074  nes indicating t
-00009f60: 6f6b 656e 7320 746f 2061 7474 656e 6420  okens to attend 
-00009f70: 746f 2c20 7a65 726f 7320 666f 7220 746f  to, zeros for to
-00009f80: 6b65 6e73 0a20 2020 2020 2020 2020 2020  kens.           
-00009f90: 2020 2020 2074 6f20 6967 6e6f 7265 2e0a       to ignore..
-00009fa0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
-00009fb0: 745f 7368 6170 6520 283a 6f62 6a3a 6054  t_shape (:obj:`T
-00009fc0: 7570 6c65 5b69 6e74 5d60 293a 0a20 2020  uple[int]`):.   
-00009fd0: 2020 2020 2020 2020 2020 2020 2054 6865               The
-00009fe0: 2073 6861 7065 206f 6620 7468 6520 696e   shape of the in
-00009ff0: 7075 7420 746f 2074 6865 206d 6f64 656c  put to the model
-0000a000: 2e0a 2020 2020 2020 2020 2020 2020 6465  ..            de
-0000a010: 7669 6365 3a20 283a 6f62 6a3a 6074 6f72  vice: (:obj:`tor
-0000a020: 6368 2e64 6576 6963 6560 293a 0a20 2020  ch.device`):.   
-0000a030: 2020 2020 2020 2020 2020 2020 2054 6865               The
-0000a040: 2064 6576 6963 6520 6f66 2074 6865 2069   device of the i
-0000a050: 6e70 7574 2074 6f20 7468 6520 6d6f 6465  nput to the mode
-0000a060: 6c2e 0a0a 2020 2020 2020 2020 5265 7475  l...        Retu
-0000a070: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
-0000a080: 203a 6f62 6a3a 6074 6f72 6368 2e54 656e   :obj:`torch.Ten
-0000a090: 736f 7260 2054 6865 2065 7874 656e 6465  sor` The extende
-0000a0a0: 6420 6174 7465 6e74 696f 6e20 6d61 736b  d attention mask
-0000a0b0: 2c20 7769 7468 2061 2074 6865 2073 616d  , with a the sam
-0000a0c0: 650a 2020 2020 2020 2020 2020 2020 6474  e.            dt
-0000a0d0: 7970 6520 6173 203a 6f62 6a3a 6061 7474  ype as :obj:`att
-0000a0e0: 656e 7469 6f6e 5f6d 6173 6b2e 6474 7970  ention_mask.dtyp
-0000a0f0: 6560 2e0a 2020 2020 2020 2020 2222 220a  e`..        """.
-0000a100: 2020 2020 2020 2020 2320 5765 2063 616e          # We can
-0000a110: 2070 726f 7669 6465 2061 2073 656c 662d   provide a self-
-0000a120: 6174 7465 6e74 696f 6e20 6d61 736b 206f  attention mask o
-0000a130: 6620 6469 6d65 6e73 696f 6e73 205b 6261  f dimensions [ba
-0000a140: 7463 685f 7369 7a65 2c0a 2020 2020 2020  tch_size,.      
-0000a150: 2020 2320 6672 6f6d 5f73 6571 5f6c 656e    # from_seq_len
-0000a160: 6774 682c 2074 6f5f 7365 715f 6c65 6e67  gth, to_seq_leng
-0000a170: 7468 5d20 6f75 7273 656c 7665 7320 696e  th] ourselves in
-0000a180: 2077 6869 6368 2063 6173 6520 7765 206a   which case we j
-0000a190: 7573 7420 6e65 6564 0a20 2020 2020 2020  ust need.       
-0000a1a0: 2023 2074 6f20 6d61 6b65 2069 7420 6272   # to make it br
-0000a1b0: 6f61 6463 6173 7461 626c 6520 746f 2061  oadcastable to a
-0000a1c0: 6c6c 2068 6561 6473 2e0a 2020 2020 2020  ll heads..      
-0000a1d0: 2020 6966 2061 7474 656e 7469 6f6e 5f6d    if attention_m
-0000a1e0: 6173 6b2e 6469 6d28 2920 3d3d 2033 3a0a  ask.dim() == 3:.
-0000a1f0: 2020 2020 2020 2020 2020 2020 6578 7465              exte
-0000a200: 6e64 6564 5f61 7474 656e 7469 6f6e 5f6d  nded_attention_m
-0000a210: 6173 6b20 3d20 6174 7465 6e74 696f 6e5f  ask = attention_
-0000a220: 6d61 736b 5b3a 2c20 4e6f 6e65 2c20 3a2c  mask[:, None, :,
-0000a230: 203a 5d0a 2020 2020 2020 2020 656c 6966   :].        elif
-0000a240: 2061 7474 656e 7469 6f6e 5f6d 6173 6b2e   attention_mask.
-0000a250: 6469 6d28 2920 3d3d 2032 3a0a 2020 2020  dim() == 2:.    
-0000a260: 2020 2020 2020 2020 2320 5072 6f76 6964          # Provid
-0000a270: 6564 2061 2070 6164 6469 6e67 206d 6173  ed a padding mas
-0000a280: 6b20 6f66 2064 696d 656e 7369 6f6e 7320  k of dimensions 
-0000a290: 5b62 6174 6368 5f73 697a 652c 2073 6571  [batch_size, seq
-0000a2a0: 5f6c 656e 6774 685d 0a20 2020 2020 2020  _length].       
-0000a2b0: 2020 2020 2023 202d 2069 6620 7468 6520       # - if the 
-0000a2c0: 6d6f 6465 6c20 6973 2061 2064 6563 6f64  model is a decod
-0000a2d0: 6572 2c20 6170 706c 7920 6120 6361 7573  er, apply a caus
-0000a2e0: 616c 206d 6173 6b20 696e 2061 6464 6974  al mask in addit
-0000a2f0: 696f 6e20 746f 0a20 2020 2020 2020 2020  ion to.         
-0000a300: 2020 2023 2020 2074 6865 2070 6164 6469     #   the paddi
-0000a310: 6e67 206d 6173 6b0a 2020 2020 2020 2020  ng mask.        
-0000a320: 2020 2020 2320 2d20 6966 2074 6865 206d      # - if the m
-0000a330: 6f64 656c 2069 7320 616e 2065 6e63 6f64  odel is an encod
-0000a340: 6572 2c20 6d61 6b65 2074 6865 206d 6173  er, make the mas
-0000a350: 6b20 6272 6f61 6463 6173 7461 626c 6520  k broadcastable 
-0000a360: 746f 0a20 2020 2020 2020 2020 2020 2023  to.            #
-0000a370: 2020 205b 6261 7463 685f 7369 7a65 2c20     [batch_size, 
-0000a380: 6e75 6d5f 6865 6164 732c 2073 6571 5f6c  num_heads, seq_l
-0000a390: 656e 6774 682c 2073 6571 5f6c 656e 6774  ength, seq_lengt
-0000a3a0: 685d 0a20 2020 2020 2020 2020 2020 2069  h].            i
-0000a3b0: 6620 6973 5f64 6563 6f64 6572 3a0a 2020  f is_decoder:.  
-0000a3c0: 2020 2020 2020 2020 2020 2020 2020 6261                ba
-0000a3d0: 7463 685f 7369 7a65 2c20 7365 715f 6c65  tch_size, seq_le
-0000a3e0: 6e67 7468 203d 2069 6e70 7574 5f73 6861  ngth = input_sha
-0000a3f0: 7065 0a20 2020 2020 2020 2020 2020 2020  pe.             
-0000a400: 2020 2073 6571 5f69 6473 203d 2074 6f72     seq_ids = tor
-0000a410: 6368 2e61 7261 6e67 6528 7365 715f 6c65  ch.arange(seq_le
-0000a420: 6e67 7468 2c20 6465 7669 6365 3d64 6576  ngth, device=dev
-0000a430: 6963 6529 0a20 2020 2020 2020 2020 2020  ice).           
-0000a440: 2020 2020 2063 6175 7361 6c5f 6d61 736b       causal_mask
-0000a450: 203d 2073 6571 5f69 6473 5b4e 6f6e 652c   = seq_ids[None,
-0000a460: 204e 6f6e 652c 203a 5d2e 7265 7065 6174   None, :].repeat
-0000a470: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000a480: 2020 2020 2020 6261 7463 685f 7369 7a65        batch_size
-0000a490: 2c20 7365 715f 6c65 6e67 7468 2c20 3129  , seq_length, 1)
-0000a4a0: 203c 3d20 7365 715f 6964 735b 4e6f 6e65   <= seq_ids[None
-0000a4b0: 2c20 3a2c 204e 6f6e 655d 0a20 2020 2020  , :, None].     
-0000a4c0: 2020 2020 2020 2020 2020 2023 2069 6e20             # in 
-0000a4d0: 6361 7365 2070 6173 745f 6b65 795f 7661  case past_key_va
-0000a4e0: 6c75 6573 2061 7265 2075 7365 6420 7765  lues are used we
-0000a4f0: 206e 6565 6420 746f 2061 6464 2061 2070   need to add a p
-0000a500: 7265 6669 7820 6f6e 6573 0a20 2020 2020  refix ones.     
-0000a510: 2020 2020 2020 2020 2020 2023 206d 6173             # mas
-0000a520: 6b20 746f 2074 6865 2063 6175 7361 6c20  k to the causal 
-0000a530: 6d61 736b 2063 6175 7361 6c20 616e 6420  mask causal and 
-0000a540: 6174 7465 6e74 696f 6e20 6d61 736b 7320  attention masks 
-0000a550: 6d75 7374 2068 6176 650a 2020 2020 2020  must have.      
-0000a560: 2020 2020 2020 2020 2020 2320 7361 6d65            # same
-0000a570: 2074 7970 6520 7769 7468 2070 7974 6f72   type with pytor
-0000a580: 6368 2076 6572 7369 6f6e 203c 2031 2e33  ch version < 1.3
-0000a590: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000a5a0: 2063 6175 7361 6c5f 6d61 736b 203d 2063   causal_mask = c
-0000a5b0: 6175 7361 6c5f 6d61 736b 2e74 6f28 6174  ausal_mask.to(at
-0000a5c0: 7465 6e74 696f 6e5f 6d61 736b 2e64 7479  tention_mask.dty
-0000a5d0: 7065 290a 0a20 2020 2020 2020 2020 2020  pe)..           
-0000a5e0: 2020 2020 2069 6620 6361 7573 616c 5f6d       if causal_m
-0000a5f0: 6173 6b2e 7368 6170 655b 315d 203c 2061  ask.shape[1] < a
-0000a600: 7474 656e 7469 6f6e 5f6d 6173 6b2e 7368  ttention_mask.sh
-0000a610: 6170 655b 315d 3a0a 2020 2020 2020 2020  ape[1]:.        
-0000a620: 2020 2020 2020 2020 2020 2020 7072 6566              pref
-0000a630: 6978 5f73 6571 5f6c 656e 203d 2061 7474  ix_seq_len = att
-0000a640: 656e 7469 6f6e 5f6d 6173 6b2e 7368 6170  ention_mask.shap
-0000a650: 655b 0a20 2020 2020 2020 2020 2020 2020  e[.             
-0000a660: 2020 2020 2020 2020 2020 2031 5d20 2d20             1] - 
-0000a670: 6361 7573 616c 5f6d 6173 6b2e 7368 6170  causal_mask.shap
-0000a680: 655b 315d 0a20 2020 2020 2020 2020 2020  e[1].           
-0000a690: 2020 2020 2020 2020 2063 6175 7361 6c5f           causal_
-0000a6a0: 6d61 736b 203d 2074 6f72 6368 2e63 6174  mask = torch.cat
-0000a6b0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000a6c0: 2020 2020 2020 2020 2020 5b0a 2020 2020            [.    
+000072a0: 2020 6f75 7470 7574 5f61 7474 656e 7469    output_attenti
+000072b0: 6f6e 7329 0a0a 2020 2020 2020 2020 2020  ons)..          
+000072c0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+000072d0: 2063 7573 746f 6d5f 666f 7277 6172 640a   custom_forward.
+000072e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000072f0: 206c 6179 6572 5f6f 7574 7075 7473 203d   layer_outputs =
+00007300: 2074 6f72 6368 2e75 7469 6c73 2e63 6865   torch.utils.che
+00007310: 636b 706f 696e 742e 6368 6563 6b70 6f69  ckpoint.checkpoi
+00007320: 6e74 280a 2020 2020 2020 2020 2020 2020  nt(.            
+00007330: 2020 2020 2020 2020 6372 6561 7465 5f63          create_c
+00007340: 7573 746f 6d5f 666f 7277 6172 6428 6c61  ustom_forward(la
+00007350: 7965 725f 6d6f 6475 6c65 292c 0a20 2020  yer_module),.   
+00007360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007370: 2068 6964 6465 6e5f 7374 6174 6573 2c0a   hidden_states,.
+00007380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007390: 2020 2020 6174 7465 6e74 696f 6e5f 6d61      attention_ma
+000073a0: 736b 2c0a 2020 2020 2020 2020 2020 2020  sk,.            
+000073b0: 2020 2020 2020 2020 6c61 7965 725f 6865          layer_he
+000073c0: 6164 5f6d 6173 6b2c 0a20 2020 2020 2020  ad_mask,.       
+000073d0: 2020 2020 2020 2020 2020 2020 2065 6e63               enc
+000073e0: 6f64 6572 5f68 6964 6465 6e5f 7374 6174  oder_hidden_stat
+000073f0: 6573 2c0a 2020 2020 2020 2020 2020 2020  es,.            
+00007400: 2020 2020 2020 2020 656e 636f 6465 725f          encoder_
+00007410: 6174 7465 6e74 696f 6e5f 6d61 736b 2c0a  attention_mask,.
+00007420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007430: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
+00007440: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00007450: 2020 2020 6c61 7965 725f 6f75 7470 7574      layer_output
+00007460: 7320 3d20 6c61 7965 725f 6d6f 6475 6c65  s = layer_module
+00007470: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00007480: 2020 2020 2020 6869 6464 656e 5f73 7461        hidden_sta
+00007490: 7465 732c 0a20 2020 2020 2020 2020 2020  tes,.           
+000074a0: 2020 2020 2020 2020 2061 7474 656e 7469           attenti
+000074b0: 6f6e 5f6d 6173 6b2c 0a20 2020 2020 2020  on_mask,.       
+000074c0: 2020 2020 2020 2020 2020 2020 206c 6179               lay
+000074d0: 6572 5f68 6561 645f 6d61 736b 2c0a 2020  er_head_mask,.  
+000074e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000074f0: 2020 656e 636f 6465 725f 6869 6464 656e    encoder_hidden
+00007500: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
+00007510: 2020 2020 2020 2020 2020 2020 2065 6e63               enc
+00007520: 6f64 6572 5f61 7474 656e 7469 6f6e 5f6d  oder_attention_m
+00007530: 6173 6b2c 0a20 2020 2020 2020 2020 2020  ask,.           
+00007540: 2020 2020 2020 2020 2070 6173 745f 6b65           past_ke
+00007550: 795f 7661 6c75 652c 0a20 2020 2020 2020  y_value,.       
+00007560: 2020 2020 2020 2020 2020 2020 206f 7574               out
+00007570: 7075 745f 6174 7465 6e74 696f 6e73 2c0a  put_attentions,.
+00007580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007590: 290a 0a20 2020 2020 2020 2020 2020 2068  )..            h
+000075a0: 6964 6465 6e5f 7374 6174 6573 203d 206c  idden_states = l
+000075b0: 6179 6572 5f6f 7574 7075 7473 5b30 5d0a  ayer_outputs[0].
+000075c0: 2020 2020 2020 2020 2020 2020 6966 2075              if u
+000075d0: 7365 5f63 6163 6865 3a0a 2020 2020 2020  se_cache:.      
+000075e0: 2020 2020 2020 2020 2020 6e65 7874 5f64            next_d
+000075f0: 6563 6f64 6572 5f63 6163 6865 202b 3d20  ecoder_cache += 
+00007600: 286c 6179 6572 5f6f 7574 7075 7473 5b2d  (layer_outputs[-
+00007610: 315d 2c20 290a 2020 2020 2020 2020 2020  1], ).          
+00007620: 2020 6966 206f 7574 7075 745f 6174 7465    if output_atte
+00007630: 6e74 696f 6e73 3a0a 2020 2020 2020 2020  ntions:.        
+00007640: 2020 2020 2020 2020 616c 6c5f 7365 6c66          all_self
+00007650: 5f61 7474 656e 7469 6f6e 7320 3d20 616c  _attentions = al
+00007660: 6c5f 7365 6c66 5f61 7474 656e 7469 6f6e  l_self_attention
+00007670: 7320 2b20 280a 2020 2020 2020 2020 2020  s + (.          
+00007680: 2020 2020 2020 2020 2020 6c61 7965 725f            layer_
+00007690: 6f75 7470 7574 735b 315d 2c20 290a 0a20  outputs[1], ).. 
+000076a0: 2020 2020 2020 2069 6620 6f75 7470 7574         if output
+000076b0: 5f68 6964 6465 6e5f 7374 6174 6573 3a0a  _hidden_states:.
+000076c0: 2020 2020 2020 2020 2020 2020 616c 6c5f              all_
+000076d0: 6869 6464 656e 5f73 7461 7465 7320 3d20  hidden_states = 
+000076e0: 616c 6c5f 6869 6464 656e 5f73 7461 7465  all_hidden_state
+000076f0: 7320 2b20 2868 6964 6465 6e5f 7374 6174  s + (hidden_stat
+00007700: 6573 2c20 290a 0a20 2020 2020 2020 2069  es, )..        i
+00007710: 6620 6e6f 7420 7265 7475 726e 5f64 6963  f not return_dic
+00007720: 743a 0a20 2020 2020 2020 2020 2020 2072  t:.            r
+00007730: 6574 7572 6e20 7475 706c 6528 7620 666f  eturn tuple(v fo
+00007740: 7220 7620 696e 205b 0a20 2020 2020 2020  r v in [.       
+00007750: 2020 2020 2020 2020 2068 6964 6465 6e5f           hidden_
+00007760: 7374 6174 6573 2c0a 2020 2020 2020 2020  states,.        
+00007770: 2020 2020 2020 2020 6e65 7874 5f64 6563          next_dec
+00007780: 6f64 6572 5f63 6163 6865 2c0a 2020 2020  oder_cache,.    
+00007790: 2020 2020 2020 2020 2020 2020 616c 6c5f              all_
+000077a0: 6869 6464 656e 5f73 7461 7465 732c 0a20  hidden_states,. 
+000077b0: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+000077c0: 6c6c 5f73 656c 665f 6174 7465 6e74 696f  ll_self_attentio
+000077d0: 6e73 2c0a 2020 2020 2020 2020 2020 2020  ns,.            
+000077e0: 2020 2020 616c 6c5f 6372 6f73 735f 6174      all_cross_at
+000077f0: 7465 6e74 696f 6e73 2c0a 2020 2020 2020  tentions,.      
+00007800: 2020 2020 2020 5d20 6966 2076 2069 7320        ] if v is 
+00007810: 6e6f 7420 4e6f 6e65 290a 2020 2020 2020  not None).      
+00007820: 2020 7265 7475 726e 2042 6173 654d 6f64    return BaseMod
+00007830: 656c 4f75 7470 7574 5769 7468 5061 7374  elOutputWithPast
+00007840: 416e 6443 726f 7373 4174 7465 6e74 696f  AndCrossAttentio
+00007850: 6e73 280a 2020 2020 2020 2020 2020 2020  ns(.            
+00007860: 6c61 7374 5f68 6964 6465 6e5f 7374 6174  last_hidden_stat
+00007870: 653d 6869 6464 656e 5f73 7461 7465 732c  e=hidden_states,
+00007880: 0a20 2020 2020 2020 2020 2020 2070 6173  .            pas
+00007890: 745f 6b65 795f 7661 6c75 6573 3d6e 6578  t_key_values=nex
+000078a0: 745f 6465 636f 6465 725f 6361 6368 652c  t_decoder_cache,
+000078b0: 0a20 2020 2020 2020 2020 2020 2068 6964  .            hid
+000078c0: 6465 6e5f 7374 6174 6573 3d61 6c6c 5f68  den_states=all_h
+000078d0: 6964 6465 6e5f 7374 6174 6573 2c0a 2020  idden_states,.  
+000078e0: 2020 2020 2020 2020 2020 6174 7465 6e74            attent
+000078f0: 696f 6e73 3d61 6c6c 5f73 656c 665f 6174  ions=all_self_at
+00007900: 7465 6e74 696f 6e73 2c0a 2020 2020 2020  tentions,.      
+00007910: 2020 2020 2020 6372 6f73 735f 6174 7465        cross_atte
+00007920: 6e74 696f 6e73 3d61 6c6c 5f63 726f 7373  ntions=all_cross
+00007930: 5f61 7474 656e 7469 6f6e 732c 0a20 2020  _attentions,.   
+00007940: 2020 2020 2029 0a0a 0a63 6c61 7373 2042       )...class B
+00007950: 6572 7450 6f6f 6c65 7228 6e6e 2e4d 6f64  ertPooler(nn.Mod
+00007960: 756c 6529 3a0a 0a20 2020 2064 6566 205f  ule):..    def _
+00007970: 5f69 6e69 745f 5f28 7365 6c66 2c20 636f  _init__(self, co
+00007980: 6e66 6967 293a 0a20 2020 2020 2020 2073  nfig):.        s
+00007990: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+000079a0: 290a 2020 2020 2020 2020 7365 6c66 2e64  ).        self.d
+000079b0: 656e 7365 203d 206e 6e2e 4c69 6e65 6172  ense = nn.Linear
+000079c0: 2863 6f6e 6669 672e 6869 6464 656e 5f73  (config.hidden_s
+000079d0: 697a 652c 2063 6f6e 6669 672e 6869 6464  ize, config.hidd
+000079e0: 656e 5f73 697a 6529 0a20 2020 2020 2020  en_size).       
+000079f0: 2073 656c 662e 6163 7469 7661 7469 6f6e   self.activation
+00007a00: 203d 206e 6e2e 5461 6e68 2829 0a0a 2020   = nn.Tanh()..  
+00007a10: 2020 6465 6620 666f 7277 6172 6428 7365    def forward(se
+00007a20: 6c66 2c20 6869 6464 656e 5f73 7461 7465  lf, hidden_state
+00007a30: 7329 3a0a 2020 2020 2020 2020 2320 5765  s):.        # We
+00007a40: 2022 706f 6f6c 2220 7468 6520 6d6f 6465   "pool" the mode
+00007a50: 6c20 6279 2073 696d 706c 7920 7461 6b69  l by simply taki
+00007a60: 6e67 2074 6865 2068 6964 6465 6e20 7374  ng the hidden st
+00007a70: 6174 6520 636f 7272 6573 706f 6e64 696e  ate correspondin
+00007a80: 670a 2020 2020 2020 2020 2320 746f 2074  g.        # to t
+00007a90: 6865 2066 6972 7374 2074 6f6b 656e 2e0a  he first token..
+00007aa0: 2020 2020 2020 2020 6669 7273 745f 746f          first_to
+00007ab0: 6b65 6e5f 7465 6e73 6f72 203d 2068 6964  ken_tensor = hid
+00007ac0: 6465 6e5f 7374 6174 6573 5b3a 2c20 305d  den_states[:, 0]
+00007ad0: 0a20 2020 2020 2020 2070 6f6f 6c65 645f  .        pooled_
+00007ae0: 6f75 7470 7574 203d 2073 656c 662e 6465  output = self.de
+00007af0: 6e73 6528 6669 7273 745f 746f 6b65 6e5f  nse(first_token_
+00007b00: 7465 6e73 6f72 290a 2020 2020 2020 2020  tensor).        
+00007b10: 706f 6f6c 6564 5f6f 7574 7075 7420 3d20  pooled_output = 
+00007b20: 7365 6c66 2e61 6374 6976 6174 696f 6e28  self.activation(
+00007b30: 706f 6f6c 6564 5f6f 7574 7075 7429 0a20  pooled_output). 
+00007b40: 2020 2020 2020 2072 6574 7572 6e20 706f         return po
+00007b50: 6f6c 6564 5f6f 7574 7075 740a 0a0a 636c  oled_output...cl
+00007b60: 6173 7320 4265 7274 5072 6564 6963 7469  ass BertPredicti
+00007b70: 6f6e 4865 6164 5472 616e 7366 6f72 6d28  onHeadTransform(
+00007b80: 6e6e 2e4d 6f64 756c 6529 3a0a 0a20 2020  nn.Module):..   
+00007b90: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
+00007ba0: 6c66 2c20 636f 6e66 6967 293a 0a20 2020  lf, config):.   
+00007bb0: 2020 2020 2073 7570 6572 2829 2e5f 5f69       super().__i
+00007bc0: 6e69 745f 5f28 290a 2020 2020 2020 2020  nit__().        
+00007bd0: 7365 6c66 2e64 656e 7365 203d 206e 6e2e  self.dense = nn.
+00007be0: 4c69 6e65 6172 2863 6f6e 6669 672e 6869  Linear(config.hi
+00007bf0: 6464 656e 5f73 697a 652c 2063 6f6e 6669  dden_size, confi
+00007c00: 672e 6869 6464 656e 5f73 697a 6529 0a20  g.hidden_size). 
+00007c10: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+00007c20: 616e 6365 2863 6f6e 6669 672e 6869 6464  ance(config.hidd
+00007c30: 656e 5f61 6374 2c20 7374 7229 3a0a 2020  en_act, str):.  
+00007c40: 2020 2020 2020 2020 2020 7365 6c66 2e74            self.t
+00007c50: 7261 6e73 666f 726d 5f61 6374 5f66 6e20  ransform_act_fn 
+00007c60: 3d20 4143 5432 464e 5b63 6f6e 6669 672e  = ACT2FN[config.
+00007c70: 6869 6464 656e 5f61 6374 5d0a 2020 2020  hidden_act].    
+00007c80: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00007c90: 2020 2020 2020 7365 6c66 2e74 7261 6e73        self.trans
+00007ca0: 666f 726d 5f61 6374 5f66 6e20 3d20 636f  form_act_fn = co
+00007cb0: 6e66 6967 2e68 6964 6465 6e5f 6163 740a  nfig.hidden_act.
+00007cc0: 2020 2020 2020 2020 7365 6c66 2e4c 6179          self.Lay
+00007cd0: 6572 4e6f 726d 203d 206e 6e2e 4c61 7965  erNorm = nn.Laye
+00007ce0: 724e 6f72 6d28 0a20 2020 2020 2020 2020  rNorm(.         
+00007cf0: 2020 2063 6f6e 6669 672e 6869 6464 656e     config.hidden
+00007d00: 5f73 697a 652c 2065 7073 3d63 6f6e 6669  _size, eps=confi
+00007d10: 672e 6c61 7965 725f 6e6f 726d 5f65 7073  g.layer_norm_eps
+00007d20: 290a 0a20 2020 2064 6566 2066 6f72 7761  )..    def forwa
+00007d30: 7264 2873 656c 662c 2068 6964 6465 6e5f  rd(self, hidden_
+00007d40: 7374 6174 6573 293a 0a20 2020 2020 2020  states):.       
+00007d50: 2068 6964 6465 6e5f 7374 6174 6573 203d   hidden_states =
+00007d60: 2073 656c 662e 6465 6e73 6528 6869 6464   self.dense(hidd
+00007d70: 656e 5f73 7461 7465 7329 0a20 2020 2020  en_states).     
+00007d80: 2020 2068 6964 6465 6e5f 7374 6174 6573     hidden_states
+00007d90: 203d 2073 656c 662e 7472 616e 7366 6f72   = self.transfor
+00007da0: 6d5f 6163 745f 666e 2868 6964 6465 6e5f  m_act_fn(hidden_
+00007db0: 7374 6174 6573 290a 2020 2020 2020 2020  states).        
+00007dc0: 6869 6464 656e 5f73 7461 7465 7320 3d20  hidden_states = 
+00007dd0: 7365 6c66 2e4c 6179 6572 4e6f 726d 2868  self.LayerNorm(h
+00007de0: 6964 6465 6e5f 7374 6174 6573 290a 2020  idden_states).  
+00007df0: 2020 2020 2020 7265 7475 726e 2068 6964        return hid
+00007e00: 6465 6e5f 7374 6174 6573 0a0a 0a63 6c61  den_states...cla
+00007e10: 7373 2042 6572 744c 4d50 7265 6469 6374  ss BertLMPredict
+00007e20: 696f 6e48 6561 6428 6e6e 2e4d 6f64 756c  ionHead(nn.Modul
+00007e30: 6529 3a0a 0a20 2020 2064 6566 205f 5f69  e):..    def __i
+00007e40: 6e69 745f 5f28 7365 6c66 2c20 636f 6e66  nit__(self, conf
+00007e50: 6967 293a 0a20 2020 2020 2020 2073 7570  ig):.        sup
+00007e60: 6572 2829 2e5f 5f69 6e69 745f 5f28 290a  er().__init__().
+00007e70: 2020 2020 2020 2020 7365 6c66 2e74 7261          self.tra
+00007e80: 6e73 666f 726d 203d 2042 6572 7450 7265  nsform = BertPre
+00007e90: 6469 6374 696f 6e48 6561 6454 7261 6e73  dictionHeadTrans
+00007ea0: 666f 726d 2863 6f6e 6669 6729 0a0a 2020  form(config)..  
+00007eb0: 2020 2020 2020 2320 5468 6520 6f75 7470        # The outp
+00007ec0: 7574 2077 6569 6768 7473 2061 7265 2074  ut weights are t
+00007ed0: 6865 2073 616d 6520 6173 2074 6865 2069  he same as the i
+00007ee0: 6e70 7574 2065 6d62 6564 6469 6e67 732c  nput embeddings,
+00007ef0: 2062 7574 2074 6865 7265 2069 730a 2020   but there is.  
+00007f00: 2020 2020 2020 2320 616e 206f 7574 7075        # an outpu
+00007f10: 742d 6f6e 6c79 2062 6961 7320 666f 7220  t-only bias for 
+00007f20: 6561 6368 2074 6f6b 656e 2e0a 2020 2020  each token..    
+00007f30: 2020 2020 7365 6c66 2e64 6563 6f64 6572      self.decoder
+00007f40: 203d 206e 6e2e 4c69 6e65 6172 280a 2020   = nn.Linear(.  
+00007f50: 2020 2020 2020 2020 2020 636f 6e66 6967            config
+00007f60: 2e68 6964 6465 6e5f 7369 7a65 2c20 636f  .hidden_size, co
+00007f70: 6e66 6967 2e76 6f63 6162 5f73 697a 652c  nfig.vocab_size,
+00007f80: 2062 6961 733d 4661 6c73 6529 0a0a 2020   bias=False)..  
+00007f90: 2020 2020 2020 7365 6c66 2e62 6961 7320        self.bias 
+00007fa0: 3d20 6e6e 2e50 6172 616d 6574 6572 2874  = nn.Parameter(t
+00007fb0: 6f72 6368 2e7a 6572 6f73 2863 6f6e 6669  orch.zeros(confi
+00007fc0: 672e 766f 6361 625f 7369 7a65 2929 0a0a  g.vocab_size))..
+00007fd0: 2020 2020 2020 2020 2320 4e65 6564 2061          # Need a
+00007fe0: 206c 696e 6b20 6265 7477 6565 6e20 7468   link between th
+00007ff0: 6520 7477 6f20 7661 7269 6162 6c65 7320  e two variables 
+00008000: 736f 2074 6861 7420 7468 6520 6269 6173  so that the bias
+00008010: 2069 7320 636f 7272 6563 746c 7920 7265   is correctly re
+00008020: 7369 7a65 6420 7769 7468 2060 7265 7369  sized with `resi
+00008030: 7a65 5f74 6f6b 656e 5f65 6d62 6564 6469  ze_token_embeddi
+00008040: 6e67 7360 0a20 2020 2020 2020 2073 656c  ngs`.        sel
+00008050: 662e 6465 636f 6465 722e 6269 6173 203d  f.decoder.bias =
+00008060: 2073 656c 662e 6269 6173 0a0a 2020 2020   self.bias..    
+00008070: 6465 6620 666f 7277 6172 6428 7365 6c66  def forward(self
+00008080: 2c20 6869 6464 656e 5f73 7461 7465 7329  , hidden_states)
+00008090: 3a0a 2020 2020 2020 2020 6869 6464 656e  :.        hidden
+000080a0: 5f73 7461 7465 7320 3d20 7365 6c66 2e74  _states = self.t
+000080b0: 7261 6e73 666f 726d 2868 6964 6465 6e5f  ransform(hidden_
+000080c0: 7374 6174 6573 290a 2020 2020 2020 2020  states).        
+000080d0: 6869 6464 656e 5f73 7461 7465 7320 3d20  hidden_states = 
+000080e0: 7365 6c66 2e64 6563 6f64 6572 2868 6964  self.decoder(hid
+000080f0: 6465 6e5f 7374 6174 6573 290a 2020 2020  den_states).    
+00008100: 2020 2020 7265 7475 726e 2068 6964 6465      return hidde
+00008110: 6e5f 7374 6174 6573 0a0a 0a63 6c61 7373  n_states...class
+00008120: 2042 6572 744f 6e6c 794d 4c4d 4865 6164   BertOnlyMLMHead
+00008130: 286e 6e2e 4d6f 6475 6c65 293a 0a0a 2020  (nn.Module):..  
+00008140: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
+00008150: 656c 662c 2063 6f6e 6669 6729 3a0a 2020  elf, config):.  
+00008160: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
+00008170: 696e 6974 5f5f 2829 0a20 2020 2020 2020  init__().       
+00008180: 2073 656c 662e 7072 6564 6963 7469 6f6e   self.prediction
+00008190: 7320 3d20 4265 7274 4c4d 5072 6564 6963  s = BertLMPredic
+000081a0: 7469 6f6e 4865 6164 2863 6f6e 6669 6729  tionHead(config)
+000081b0: 0a0a 2020 2020 6465 6620 666f 7277 6172  ..    def forwar
+000081c0: 6428 7365 6c66 2c20 7365 7175 656e 6365  d(self, sequence
+000081d0: 5f6f 7574 7075 7429 3a0a 2020 2020 2020  _output):.      
+000081e0: 2020 7072 6564 6963 7469 6f6e 5f73 636f    prediction_sco
+000081f0: 7265 7320 3d20 7365 6c66 2e70 7265 6469  res = self.predi
+00008200: 6374 696f 6e73 2873 6571 7565 6e63 655f  ctions(sequence_
+00008210: 6f75 7470 7574 290a 2020 2020 2020 2020  output).        
+00008220: 7265 7475 726e 2070 7265 6469 6374 696f  return predictio
+00008230: 6e5f 7363 6f72 6573 0a0a 0a63 6c61 7373  n_scores...class
+00008240: 2042 6572 744f 6e6c 794e 5350 4865 6164   BertOnlyNSPHead
+00008250: 286e 6e2e 4d6f 6475 6c65 293a 0a0a 2020  (nn.Module):..  
+00008260: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
+00008270: 656c 662c 2063 6f6e 6669 6729 3a0a 2020  elf, config):.  
+00008280: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
+00008290: 696e 6974 5f5f 2829 0a20 2020 2020 2020  init__().       
+000082a0: 2073 656c 662e 7365 715f 7265 6c61 7469   self.seq_relati
+000082b0: 6f6e 7368 6970 203d 206e 6e2e 4c69 6e65  onship = nn.Line
+000082c0: 6172 2863 6f6e 6669 672e 6869 6464 656e  ar(config.hidden
+000082d0: 5f73 697a 652c 2032 290a 0a20 2020 2064  _size, 2)..    d
+000082e0: 6566 2066 6f72 7761 7264 2873 656c 662c  ef forward(self,
+000082f0: 2070 6f6f 6c65 645f 6f75 7470 7574 293a   pooled_output):
+00008300: 0a20 2020 2020 2020 2073 6571 5f72 656c  .        seq_rel
+00008310: 6174 696f 6e73 6869 705f 7363 6f72 6520  ationship_score 
+00008320: 3d20 7365 6c66 2e73 6571 5f72 656c 6174  = self.seq_relat
+00008330: 696f 6e73 6869 7028 706f 6f6c 6564 5f6f  ionship(pooled_o
+00008340: 7574 7075 7429 0a20 2020 2020 2020 2072  utput).        r
+00008350: 6574 7572 6e20 7365 715f 7265 6c61 7469  eturn seq_relati
+00008360: 6f6e 7368 6970 5f73 636f 7265 0a0a 0a63  onship_score...c
+00008370: 6c61 7373 2042 6572 7450 7265 5472 6169  lass BertPreTrai
+00008380: 6e69 6e67 4865 6164 7328 6e6e 2e4d 6f64  ningHeads(nn.Mod
+00008390: 756c 6529 3a0a 0a20 2020 2064 6566 205f  ule):..    def _
+000083a0: 5f69 6e69 745f 5f28 7365 6c66 2c20 636f  _init__(self, co
+000083b0: 6e66 6967 293a 0a20 2020 2020 2020 2073  nfig):.        s
+000083c0: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+000083d0: 290a 2020 2020 2020 2020 7365 6c66 2e70  ).        self.p
+000083e0: 7265 6469 6374 696f 6e73 203d 2042 6572  redictions = Ber
+000083f0: 744c 4d50 7265 6469 6374 696f 6e48 6561  tLMPredictionHea
+00008400: 6428 636f 6e66 6967 290a 2020 2020 2020  d(config).      
+00008410: 2020 7365 6c66 2e73 6571 5f72 656c 6174    self.seq_relat
+00008420: 696f 6e73 6869 7020 3d20 6e6e 2e4c 696e  ionship = nn.Lin
+00008430: 6561 7228 636f 6e66 6967 2e68 6964 6465  ear(config.hidde
+00008440: 6e5f 7369 7a65 2c20 3229 0a0a 2020 2020  n_size, 2)..    
+00008450: 6465 6620 666f 7277 6172 6428 7365 6c66  def forward(self
+00008460: 2c20 7365 7175 656e 6365 5f6f 7574 7075  , sequence_outpu
+00008470: 742c 2070 6f6f 6c65 645f 6f75 7470 7574  t, pooled_output
+00008480: 293a 0a20 2020 2020 2020 2070 7265 6469  ):.        predi
+00008490: 6374 696f 6e5f 7363 6f72 6573 203d 2073  ction_scores = s
+000084a0: 656c 662e 7072 6564 6963 7469 6f6e 7328  elf.predictions(
+000084b0: 7365 7175 656e 6365 5f6f 7574 7075 7429  sequence_output)
+000084c0: 0a20 2020 2020 2020 2073 6571 5f72 656c  .        seq_rel
+000084d0: 6174 696f 6e73 6869 705f 7363 6f72 6520  ationship_score 
+000084e0: 3d20 7365 6c66 2e73 6571 5f72 656c 6174  = self.seq_relat
+000084f0: 696f 6e73 6869 7028 706f 6f6c 6564 5f6f  ionship(pooled_o
+00008500: 7574 7075 7429 0a20 2020 2020 2020 2072  utput).        r
+00008510: 6574 7572 6e20 7072 6564 6963 7469 6f6e  eturn prediction
+00008520: 5f73 636f 7265 732c 2073 6571 5f72 656c  _scores, seq_rel
+00008530: 6174 696f 6e73 6869 705f 7363 6f72 650a  ationship_score.
+00008540: 0a0a 636c 6173 7320 4265 7274 5072 6554  ..class BertPreT
+00008550: 7261 696e 6564 4d6f 6465 6c28 5072 6554  rainedModel(PreT
+00008560: 7261 696e 6564 4d6f 6465 6c29 3a0a 2020  rainedModel):.  
+00008570: 2020 2222 220a 2020 2020 416e 2061 6273    """.    An abs
+00008580: 7472 6163 7420 636c 6173 7320 746f 2068  tract class to h
+00008590: 616e 646c 6520 7765 6967 6874 7320 696e  andle weights in
+000085a0: 6974 6961 6c69 7a61 7469 6f6e 2061 6e64  itialization and
+000085b0: 2061 2073 696d 706c 6520 696e 7465 7266   a simple interf
+000085c0: 6163 650a 2020 2020 666f 7220 646f 776e  ace.    for down
+000085d0: 6c6f 6164 696e 6720 616e 6420 6c6f 6164  loading and load
+000085e0: 696e 6720 7072 6574 7261 696e 6564 206d  ing pretrained m
+000085f0: 6f64 656c 732e 0a20 2020 2022 2222 0a0a  odels..    """..
+00008600: 2020 2020 636f 6e66 6967 5f63 6c61 7373      config_class
+00008610: 203d 2042 6572 7443 6f6e 6669 670a 2020   = BertConfig.  
+00008620: 2020 6c6f 6164 5f74 665f 7765 6967 6874    load_tf_weight
+00008630: 7320 3d20 6c6f 6164 5f74 665f 7765 6967  s = load_tf_weig
+00008640: 6874 735f 696e 5f62 6572 740a 2020 2020  hts_in_bert.    
+00008650: 6261 7365 5f6d 6f64 656c 5f70 7265 6669  base_model_prefi
+00008660: 7820 3d20 2762 6572 7427 0a20 2020 205f  x = 'bert'.    _
+00008670: 6b65 7973 5f74 6f5f 6967 6e6f 7265 5f6f  keys_to_ignore_o
+00008680: 6e5f 6c6f 6164 5f6d 6973 7369 6e67 203d  n_load_missing =
+00008690: 205b 7227 706f 7369 7469 6f6e 5f69 6473   [r'position_ids
+000086a0: 275d 0a0a 2020 2020 6465 6620 5f69 6e69  ']..    def _ini
+000086b0: 745f 7765 6967 6874 7328 7365 6c66 2c20  t_weights(self, 
+000086c0: 6d6f 6475 6c65 293a 0a20 2020 2020 2020  module):.       
+000086d0: 2022 2222 2049 6e69 7469 616c 697a 6520   """ Initialize 
+000086e0: 7468 6520 7765 6967 6874 7320 2222 220a  the weights """.
+000086f0: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
+00008700: 7461 6e63 6528 6d6f 6475 6c65 2c20 286e  tance(module, (n
+00008710: 6e2e 4c69 6e65 6172 2c20 6e6e 2e45 6d62  n.Linear, nn.Emb
+00008720: 6564 6469 6e67 2929 3a0a 2020 2020 2020  edding)):.      
+00008730: 2020 2020 2020 2320 536c 6967 6874 6c79        # Slightly
+00008740: 2064 6966 6665 7265 6e74 2066 726f 6d20   different from 
+00008750: 7468 6520 5446 2076 6572 7369 6f6e 2077  the TF version w
+00008760: 6869 6368 2075 7365 7320 7472 756e 6361  hich uses trunca
+00008770: 7465 645f 6e6f 726d 616c 2066 6f72 2069  ted_normal for i
+00008780: 6e69 7469 616c 697a 6174 696f 6e0a 2020  nitialization.  
+00008790: 2020 2020 2020 2020 2020 2320 6366 2068            # cf h
+000087a0: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
+000087b0: 6d2f 7079 746f 7263 682f 7079 746f 7263  m/pytorch/pytorc
+000087c0: 682f 7075 6c6c 2f35 3631 370a 2020 2020  h/pull/5617.    
+000087d0: 2020 2020 2020 2020 6d6f 6475 6c65 2e77          module.w
+000087e0: 6569 6768 742e 6461 7461 2e6e 6f72 6d61  eight.data.norma
+000087f0: 6c5f 280a 2020 2020 2020 2020 2020 2020  l_(.            
+00008800: 2020 2020 6d65 616e 3d30 2e30 2c20 7374      mean=0.0, st
+00008810: 643d 7365 6c66 2e63 6f6e 6669 672e 696e  d=self.config.in
+00008820: 6974 6961 6c69 7a65 725f 7261 6e67 6529  itializer_range)
+00008830: 0a20 2020 2020 2020 2065 6c69 6620 6973  .        elif is
+00008840: 696e 7374 616e 6365 286d 6f64 756c 652c  instance(module,
+00008850: 206e 6e2e 4c61 7965 724e 6f72 6d29 3a0a   nn.LayerNorm):.
+00008860: 2020 2020 2020 2020 2020 2020 6d6f 6475              modu
+00008870: 6c65 2e62 6961 732e 6461 7461 2e7a 6572  le.bias.data.zer
+00008880: 6f5f 2829 0a20 2020 2020 2020 2020 2020  o_().           
+00008890: 206d 6f64 756c 652e 7765 6967 6874 2e64   module.weight.d
+000088a0: 6174 612e 6669 6c6c 5f28 312e 3029 0a20  ata.fill_(1.0). 
+000088b0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+000088c0: 616e 6365 286d 6f64 756c 652c 206e 6e2e  ance(module, nn.
+000088d0: 4c69 6e65 6172 2920 616e 6420 6d6f 6475  Linear) and modu
+000088e0: 6c65 2e62 6961 7320 6973 206e 6f74 204e  le.bias is not N
+000088f0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+00008900: 206d 6f64 756c 652e 6269 6173 2e64 6174   module.bias.dat
+00008910: 612e 7a65 726f 5f28 290a 0a0a 4064 6174  a.zero_()...@dat
+00008920: 6163 6c61 7373 0a63 6c61 7373 2042 6572  aclass.class Ber
+00008930: 7446 6f72 5072 6554 7261 696e 696e 674f  tForPreTrainingO
+00008940: 7574 7075 7428 4d6f 6465 6c4f 7574 7075  utput(ModelOutpu
+00008950: 7429 3a0a 2020 2020 2222 220a 2020 2020  t):.    """.    
+00008960: 4f75 7470 7574 2074 7970 6520 6f66 203a  Output type of :
+00008970: 636c 6173 733a 607e 7472 616e 7366 6f72  class:`~transfor
+00008980: 6d65 7273 2e42 6572 7446 6f72 5072 6554  mers.BertForPreT
+00008990: 7261 696e 696e 6760 2e20 4172 6773 3a0a  raining`. Args:.
+000089a0: 2020 2020 2020 2020 6c6f 7373 2028 606f          loss (`o
+000089b0: 7074 696f 6e61 6c60 2c20 7265 7475 726e  ptional`, return
+000089c0: 6564 2077 6865 6e20 6060 6c61 6265 6c73  ed when ``labels
+000089d0: 6060 2069 7320 7072 6f76 6964 6564 2c0a  `` is provided,.
+000089e0: 2020 2020 2020 2020 6060 746f 7263 682e          ``torch.
+000089f0: 466c 6f61 7454 656e 736f 7260 6020 6f66  FloatTensor`` of
+00008a00: 2073 6861 7065 203a 6f62 6a3a 6028 312c   shape :obj:`(1,
+00008a10: 2960 293a 0a20 2020 2020 2020 2020 2020  )`):.           
+00008a20: 2054 6f74 616c 206c 6f73 7320 6173 2074   Total loss as t
+00008a30: 6865 2073 756d 206f 6620 7468 6520 6d61  he sum of the ma
+00008a40: 736b 6564 206c 616e 6775 6167 6520 6d6f  sked language mo
+00008a50: 6465 6c69 6e67 206c 6f73 7320 616e 6420  deling loss and 
+00008a60: 7468 650a 2020 2020 2020 2020 2020 2020  the.            
+00008a70: 6e65 7874 2073 6571 7565 6e63 6520 7072  next sequence pr
+00008a80: 6564 6963 7469 6f6e 2028 636c 6173 7369  ediction (classi
+00008a90: 6669 6361 7469 6f6e 2920 6c6f 7373 2e0a  fication) loss..
+00008aa0: 2020 2020 2020 2020 7072 6564 6963 7469          predicti
+00008ab0: 6f6e 5f6c 6f67 6974 7320 283a 6f62 6a3a  on_logits (:obj:
+00008ac0: 6074 6f72 6368 2e46 6c6f 6174 5465 6e73  `torch.FloatTens
+00008ad0: 6f72 6020 6f66 2073 6861 7065 203a 6f62  or` of shape :ob
+00008ae0: 6a3a 6028 6261 7463 685f 7369 7a65 2c0a  j:`(batch_size,.
+00008af0: 2020 2020 2020 2020 7365 7175 656e 6365          sequence
+00008b00: 5f6c 656e 6774 682c 2063 6f6e 6669 672e  _length, config.
+00008b10: 766f 6361 625f 7369 7a65 2960 293a 0a20  vocab_size)`):. 
+00008b20: 2020 2020 2020 2020 2020 2050 7265 6469             Predi
+00008b30: 6374 696f 6e20 7363 6f72 6573 206f 6620  ction scores of 
+00008b40: 7468 6520 6c61 6e67 7561 6765 206d 6f64  the language mod
+00008b50: 656c 696e 6720 6865 6164 2028 7363 6f72  eling head (scor
+00008b60: 6573 2066 6f72 2065 6163 680a 2020 2020  es for each.    
+00008b70: 2020 2020 2020 2020 766f 6361 6275 6c61          vocabula
+00008b80: 7279 2074 6f6b 656e 2062 6566 6f72 6520  ry token before 
+00008b90: 536f 6674 4d61 7829 2e0a 2020 2020 2020  SoftMax)..      
+00008ba0: 2020 7365 715f 7265 6c61 7469 6f6e 7368    seq_relationsh
+00008bb0: 6970 5f6c 6f67 6974 7320 283a 6f62 6a3a  ip_logits (:obj:
+00008bc0: 6074 6f72 6368 2e46 6c6f 6174 5465 6e73  `torch.FloatTens
+00008bd0: 6f72 6020 6f66 2073 6861 7065 0a20 2020  or` of shape.   
+00008be0: 2020 2020 203a 6f62 6a3a 6028 6261 7463       :obj:`(batc
+00008bf0: 685f 7369 7a65 2c20 3229 6029 3a0a 2020  h_size, 2)`):.  
+00008c00: 2020 2020 2020 2020 2020 5072 6564 6963            Predic
+00008c10: 7469 6f6e 2073 636f 7265 7320 6f66 2074  tion scores of t
+00008c20: 6865 206e 6578 7420 7365 7175 656e 6365  he next sequence
+00008c30: 2070 7265 6469 6374 696f 6e20 2863 6c61   prediction (cla
+00008c40: 7373 6966 6963 6174 696f 6e29 0a20 2020  ssification).   
+00008c50: 2020 2020 2020 2020 2068 6561 6420 2873           head (s
+00008c60: 636f 7265 7320 6f66 2054 7275 652f 4661  cores of True/Fa
+00008c70: 6c73 6520 636f 6e74 696e 7561 7469 6f6e  lse continuation
+00008c80: 2062 6566 6f72 6520 536f 6674 4d61 7829   before SoftMax)
+00008c90: 2e0a 2020 2020 2020 2020 6869 6464 656e  ..        hidden
+00008ca0: 5f73 7461 7465 7320 283a 6f62 6a3a 6074  _states (:obj:`t
+00008cb0: 7570 6c65 2874 6f72 6368 2e46 6c6f 6174  uple(torch.Float
+00008cc0: 5465 6e73 6f72 2960 2c20 606f 7074 696f  Tensor)`, `optio
+00008cd0: 6e61 6c60 2c20 7265 7475 726e 6564 0a20  nal`, returned. 
+00008ce0: 2020 2020 2020 2077 6865 6e20 6060 6f75         when ``ou
+00008cf0: 7470 7574 5f68 6964 6465 6e5f 7374 6174  tput_hidden_stat
+00008d00: 6573 3d54 7275 6560 6020 6973 2070 6173  es=True`` is pas
+00008d10: 7365 6420 6f72 2077 6865 6e0a 2020 2020  sed or when.    
+00008d20: 2020 2020 6060 636f 6e66 6967 2e6f 7574      ``config.out
+00008d30: 7075 745f 6869 6464 656e 5f73 7461 7465  put_hidden_state
+00008d40: 733d 5472 7565 6060 293a 0a20 2020 2020  s=True``):.     
+00008d50: 2020 2020 2020 2054 7570 6c65 206f 6620         Tuple of 
+00008d60: 3a6f 626a 3a60 746f 7263 682e 466c 6f61  :obj:`torch.Floa
+00008d70: 7454 656e 736f 7260 2028 6f6e 6520 666f  tTensor` (one fo
+00008d80: 7220 7468 6520 6f75 7470 7574 206f 6620  r the output of 
+00008d90: 7468 650a 2020 2020 2020 2020 2020 2020  the.            
+00008da0: 656d 6265 6464 696e 6773 202b 206f 6e65  embeddings + one
+00008db0: 2066 6f72 2074 6865 206f 7574 7075 7420   for the output 
+00008dc0: 6f66 2065 6163 6820 6c61 7965 7229 206f  of each layer) o
+00008dd0: 6620 7368 6170 650a 2020 2020 2020 2020  f shape.        
+00008de0: 2020 2020 3a6f 626a 3a60 2862 6174 6368      :obj:`(batch
+00008df0: 5f73 697a 652c 2073 6571 7565 6e63 655f  _size, sequence_
+00008e00: 6c65 6e67 7468 2c20 6869 6464 656e 5f73  length, hidden_s
+00008e10: 697a 6529 602e 2048 6964 6465 6e2d 7374  ize)`. Hidden-st
+00008e20: 6174 6573 206f 660a 2020 2020 2020 2020  ates of.        
+00008e30: 2020 2020 7468 6520 6d6f 6465 6c20 6174      the model at
+00008e40: 2074 6865 206f 7574 7075 7420 6f66 2065   the output of e
+00008e50: 6163 6820 6c61 7965 7220 706c 7573 2074  ach layer plus t
+00008e60: 6865 2069 6e69 7469 616c 2065 6d62 6564  he initial embed
+00008e70: 6469 6e67 0a20 2020 2020 2020 2020 2020  ding.           
+00008e80: 206f 7574 7075 7473 2e0a 2020 2020 2020   outputs..      
+00008e90: 2020 6174 7465 6e74 696f 6e73 2028 3a6f    attentions (:o
+00008ea0: 626a 3a60 7475 706c 6528 746f 7263 682e  bj:`tuple(torch.
+00008eb0: 466c 6f61 7454 656e 736f 7229 602c 2060  FloatTensor)`, `
+00008ec0: 6f70 7469 6f6e 616c 602c 2072 6574 7572  optional`, retur
+00008ed0: 6e65 6420 7768 656e 0a20 2020 2020 2020  ned when.       
+00008ee0: 2060 606f 7574 7075 745f 6174 7465 6e74   ``output_attent
+00008ef0: 696f 6e73 3d54 7275 6560 6020 6973 2070  ions=True`` is p
+00008f00: 6173 7365 6420 6f72 2077 6865 6e0a 2020  assed or when.  
+00008f10: 2020 2020 2020 6060 636f 6e66 6967 2e6f        ``config.o
+00008f20: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
+00008f30: 3d54 7275 6560 6029 3a0a 2020 2020 2020  =True``):.      
+00008f40: 2020 2020 2020 5475 706c 6520 6f66 203a        Tuple of :
+00008f50: 6f62 6a3a 6074 6f72 6368 2e46 6c6f 6174  obj:`torch.Float
+00008f60: 5465 6e73 6f72 6020 286f 6e65 2066 6f72  Tensor` (one for
+00008f70: 2065 6163 6820 6c61 7965 7229 206f 6620   each layer) of 
+00008f80: 7368 6170 650a 2020 2020 2020 2020 2020  shape.          
+00008f90: 2020 3a6f 626a 3a60 2862 6174 6368 5f73    :obj:`(batch_s
+00008fa0: 697a 652c 206e 756d 5f68 6561 6473 2c20  ize, num_heads, 
+00008fb0: 7365 7175 656e 6365 5f6c 656e 6774 682c  sequence_length,
+00008fc0: 2073 6571 7565 6e63 655f 6c65 6e67 7468   sequence_length
+00008fd0: 2960 2e0a 2020 2020 2020 2020 2020 2020  )`..            
+00008fe0: 4174 7465 6e74 696f 6e73 2077 6569 6768  Attentions weigh
+00008ff0: 7473 2061 6674 6572 2074 6865 2061 7474  ts after the att
+00009000: 656e 7469 6f6e 2073 6f66 746d 6178 2c20  ention softmax, 
+00009010: 7573 6564 2074 6f20 636f 6d70 7574 6520  used to compute 
+00009020: 7468 650a 2020 2020 2020 2020 2020 2020  the.            
+00009030: 7765 6967 6874 6564 2061 7665 7261 6765  weighted average
+00009040: 2069 6e20 7468 6520 7365 6c66 2d61 7474   in the self-att
+00009050: 656e 7469 6f6e 2068 6561 6473 2e0a 2020  ention heads..  
+00009060: 2020 2222 220a 0a20 2020 206c 6f73 733a    """..    loss:
+00009070: 204f 7074 696f 6e61 6c5b 746f 7263 682e   Optional[torch.
+00009080: 466c 6f61 7454 656e 736f 725d 203d 204e  FloatTensor] = N
+00009090: 6f6e 650a 2020 2020 7072 6564 6963 7469  one.    predicti
+000090a0: 6f6e 5f6c 6f67 6974 733a 2074 6f72 6368  on_logits: torch
+000090b0: 2e46 6c6f 6174 5465 6e73 6f72 203d 204e  .FloatTensor = N
+000090c0: 6f6e 650a 2020 2020 7365 715f 7265 6c61  one.    seq_rela
+000090d0: 7469 6f6e 7368 6970 5f6c 6f67 6974 733a  tionship_logits:
+000090e0: 2074 6f72 6368 2e46 6c6f 6174 5465 6e73   torch.FloatTens
+000090f0: 6f72 203d 204e 6f6e 650a 2020 2020 6869  or = None.    hi
+00009100: 6464 656e 5f73 7461 7465 733a 204f 7074  dden_states: Opt
+00009110: 696f 6e61 6c5b 5475 706c 655b 746f 7263  ional[Tuple[torc
+00009120: 682e 466c 6f61 7454 656e 736f 725d 5d20  h.FloatTensor]] 
+00009130: 3d20 4e6f 6e65 0a20 2020 2061 7474 656e  = None.    atten
+00009140: 7469 6f6e 733a 204f 7074 696f 6e61 6c5b  tions: Optional[
+00009150: 5475 706c 655b 746f 7263 682e 466c 6f61  Tuple[torch.Floa
+00009160: 7454 656e 736f 725d 5d20 3d20 4e6f 6e65  tTensor]] = None
+00009170: 0a0a 0a63 6c61 7373 2042 6572 744d 6f64  ...class BertMod
+00009180: 656c 2842 6572 7450 7265 5472 6169 6e65  el(BertPreTraine
+00009190: 644d 6f64 656c 293a 0a20 2020 2022 2222  dModel):.    """
+000091a0: 0a20 2020 204e 6f74 6564 2074 6861 7420  .    Noted that 
+000091b0: 7468 6520 6265 7274 206d 6f64 656c 2068  the bert model h
+000091c0: 6572 6520 6973 2073 6c69 6768 746c 7920  ere is slightly 
+000091d0: 7570 6461 7465 6420 6672 6f6d 206f 7269  updated from ori
+000091e0: 6769 6e61 6c20 6265 7274 2c20 736f 2077  ginal bert, so w
+000091f0: 650a 2020 2020 6d61 696e 7469 616e 2074  e.    maintian t
+00009200: 6865 2063 6f64 6520 6865 7265 2069 6e64  he code here ind
+00009210: 6570 656e 6465 6e74 6c79 2e20 5468 6520  ependently. The 
+00009220: 4265 7274 204d 6f64 656c 2074 7261 6e73  Bert Model trans
+00009230: 666f 726d 6572 206f 7574 7075 7474 696e  former outputtin
+00009240: 670a 2020 2020 7261 7720 6869 6464 656e  g.    raw hidden
+00009250: 2d73 7461 7465 7320 7769 7468 6f75 7420  -states without 
+00009260: 616e 7920 7370 6563 6966 6963 2068 6561  any specific hea
+00009270: 6420 6f6e 2074 6f70 2e0a 0a20 2020 2054  d on top...    T
+00009280: 6869 7320 6d6f 6465 6c20 696e 6865 7269  his model inheri
+00009290: 7473 2066 726f 6d20 5b60 5072 6554 7261  ts from [`PreTra
+000092a0: 696e 6564 4d6f 6465 6c60 5d2e 2043 6865  inedModel`]. Che
+000092b0: 636b 2074 6865 2073 7570 6572 636c 6173  ck the superclas
+000092c0: 730a 2020 2020 646f 6375 6d65 6e74 6174  s.    documentat
+000092d0: 696f 6e20 666f 7220 7468 6520 6765 6e65  ion for the gene
+000092e0: 7269 6320 6d65 7468 6f64 7320 7468 6520  ric methods the 
+000092f0: 6c69 6272 6172 7920 696d 706c 656d 656e  library implemen
+00009300: 7473 2066 6f72 2061 6c6c 2069 7473 0a20  ts for all its. 
+00009310: 2020 206d 6f64 656c 2028 7375 6368 2061     model (such a
+00009320: 7320 646f 776e 6c6f 6164 696e 6720 6f72  s downloading or
+00009330: 2073 6176 696e 672c 2072 6573 697a 696e   saving, resizin
+00009340: 6720 7468 6520 696e 7075 7420 656d 6265  g the input embe
+00009350: 6464 696e 6773 2c20 7072 756e 696e 670a  ddings, pruning.
+00009360: 2020 2020 6865 6164 7320 6574 632e 290a      heads etc.).
+00009370: 0a20 2020 2054 6869 7320 6d6f 6465 6c20  .    This model 
+00009380: 6973 2061 6c73 6f20 6120 5079 546f 7263  is also a PyTorc
+00009390: 680a 2020 2020 5b74 6f72 6368 2e6e 6e2e  h.    [torch.nn.
+000093a0: 4d6f 6475 6c65 5d28 6874 7470 733a 2f2f  Module](https://
+000093b0: 7079 746f 7263 682e 6f72 672f 646f 6373  pytorch.org/docs
+000093c0: 2f73 7461 626c 652f 6e6e 2e68 746d 6c23  /stable/nn.html#
+000093d0: 746f 7263 682e 6e6e 2e4d 6f64 756c 6529  torch.nn.Module)
+000093e0: 0a20 2020 2073 7562 636c 6173 732e 2055  .    subclass. U
+000093f0: 7365 2069 7420 6173 2061 2072 6567 756c  se it as a regul
+00009400: 6172 2050 7954 6f72 6368 204d 6f64 756c  ar PyTorch Modul
+00009410: 6520 616e 6420 7265 6665 7220 746f 2074  e and refer to t
+00009420: 6865 2050 7954 6f72 6368 0a20 2020 2064  he PyTorch.    d
+00009430: 6f63 756d 656e 7461 7469 6f6e 2066 6f72  ocumentation for
+00009440: 2061 6c6c 206d 6174 7465 7220 7265 6c61   all matter rela
+00009450: 7465 6420 746f 2067 656e 6572 616c 2075  ted to general u
+00009460: 7361 6765 2061 6e64 2062 6568 6176 696f  sage and behavio
+00009470: 722e 0a0a 2020 2020 5061 7261 6d65 7465  r...    Paramete
+00009480: 7273 3a0a 2020 2020 2020 2020 636f 6e66  rs:.        conf
+00009490: 6967 2028 5b60 4265 7274 436f 6e66 6967  ig ([`BertConfig
+000094a0: 605d 293a 204d 6f64 656c 2063 6f6e 6669  `]): Model confi
+000094b0: 6775 7261 7469 6f6e 2063 6c61 7373 2077  guration class w
+000094c0: 6974 6820 616c 6c20 7468 650a 2020 2020  ith all the.    
+000094d0: 2020 2020 7061 7261 6d65 7465 7273 206f      parameters o
+000094e0: 6620 7468 6520 6d6f 6465 6c2e 0a20 2020  f the model..   
+000094f0: 2020 2020 2020 2020 2049 6e69 7469 616c           Initial
+00009500: 697a 696e 6720 7769 7468 2061 2063 6f6e  izing with a con
+00009510: 6669 6720 6669 6c65 2064 6f65 7320 6e6f  fig file does no
+00009520: 7420 6c6f 6164 2074 6865 2077 6569 6768  t load the weigh
+00009530: 7473 2061 7373 6f63 6961 7465 640a 2020  ts associated.  
+00009540: 2020 2020 2020 2020 2020 7769 7468 2074            with t
+00009550: 6865 206d 6f64 656c 2c20 6f6e 6c79 2074  he model, only t
+00009560: 6865 2063 6f6e 6669 6775 7261 7469 6f6e  he configuration
+00009570: 2e20 4368 6563 6b20 6f75 7420 7468 650a  . Check out the.
+00009580: 2020 2020 2020 2020 2020 2020 5b60 7e50              [`~P
+00009590: 7265 5472 6169 6e65 644d 6f64 656c 2e66  reTrainedModel.f
+000095a0: 726f 6d5f 7072 6574 7261 696e 6564 605d  rom_pretrained`]
+000095b0: 206d 6574 686f 6420 746f 206c 6f61 6420   method to load 
+000095c0: 7468 6520 6d6f 6465 6c0a 2020 2020 2020  the model.      
+000095d0: 2020 2020 2020 7765 6967 6874 732e 0a0a        weights...
+000095e0: 2020 2020 5468 6520 6d6f 6465 6c20 6361      The model ca
+000095f0: 6e20 6265 6861 7665 2061 7320 616e 2065  n behave as an e
+00009600: 6e63 6f64 6572 2028 7769 7468 206f 6e6c  ncoder (with onl
+00009610: 7920 7365 6c66 2d61 7474 656e 7469 6f6e  y self-attention
+00009620: 2920 6173 2077 656c 6c20 6173 2061 0a20  ) as well as a. 
+00009630: 2020 2064 6563 6f64 6572 2c20 696e 2077     decoder, in w
+00009640: 6869 6368 2063 6173 6520 6120 6c61 7965  hich case a laye
+00009650: 7220 6f66 2063 726f 7373 2d61 7474 656e  r of cross-atten
+00009660: 7469 6f6e 2069 7320 6164 6465 6420 6265  tion is added be
+00009670: 7477 6565 6e20 7468 650a 2020 2020 7365  tween the.    se
+00009680: 6c66 2d61 7474 656e 7469 6f6e 206c 6179  lf-attention lay
+00009690: 6572 732c 2066 6f6c 6c6f 7769 6e67 2074  ers, following t
+000096a0: 6865 2061 7263 6869 7465 6374 7572 6520  he architecture 
+000096b0: 6465 7363 7269 6265 6420 696e 205b 4174  described in [At
+000096c0: 7465 6e74 696f 6e20 6973 0a20 2020 2061  tention is.    a
+000096d0: 6c6c 2079 6f75 206e 6565 645d 2868 7474  ll you need](htt
+000096e0: 7073 3a2f 2f61 7278 6976 2e6f 7267 2f61  ps://arxiv.org/a
+000096f0: 6273 2f31 3730 362e 3033 3736 3229 2062  bs/1706.03762) b
+00009700: 7920 4173 6869 7368 2056 6173 7761 6e69  y Ashish Vaswani
+00009710: 2c20 4e6f 616d 0a20 2020 2053 6861 7a65  , Noam.    Shaze
+00009720: 6572 2c20 4e69 6b69 2050 6172 6d61 722c  er, Niki Parmar,
+00009730: 204a 616b 6f62 2055 737a 6b6f 7265 6974   Jakob Uszkoreit
+00009740: 2c20 4c6c 696f 6e20 4a6f 6e65 732c 2041  , Llion Jones, A
+00009750: 6964 616e 204e 2e20 476f 6d65 7a2c 204c  idan N. Gomez, L
+00009760: 756b 6173 7a0a 2020 2020 4b61 6973 6572  ukasz.    Kaiser
+00009770: 2061 6e64 2049 6c6c 6961 2050 6f6c 6f73   and Illia Polos
+00009780: 756b 6869 6e2e 0a0a 2020 2020 546f 2062  ukhin...    To b
+00009790: 6568 6176 6520 6173 2061 6e20 6465 636f  ehave as an deco
+000097a0: 6465 7220 7468 6520 6d6f 6465 6c20 6e65  der the model ne
+000097b0: 6564 7320 746f 2062 6520 696e 6974 6961  eds to be initia
+000097c0: 6c69 7a65 6420 7769 7468 2074 6865 0a20  lized with the. 
+000097d0: 2020 2060 6973 5f64 6563 6f64 6572 6020     `is_decoder` 
+000097e0: 6172 6775 6d65 6e74 206f 6620 7468 6520  argument of the 
+000097f0: 636f 6e66 6967 7572 6174 696f 6e20 7365  configuration se
+00009800: 7420 746f 2060 5472 7565 602e 2054 6f20  t to `True`. To 
+00009810: 6265 2075 7365 6420 696e 2061 0a20 2020  be used in a.   
+00009820: 2053 6571 3253 6571 206d 6f64 656c 2c20   Seq2Seq model, 
+00009830: 7468 6520 6d6f 6465 6c20 6e65 6564 7320  the model needs 
+00009840: 746f 2069 6e69 7469 616c 697a 6564 2077  to initialized w
+00009850: 6974 6820 626f 7468 2060 6973 5f64 6563  ith both `is_dec
+00009860: 6f64 6572 600a 2020 2020 6172 6775 6d65  oder`.    argume
+00009870: 6e74 2061 6e64 2060 6164 645f 6372 6f73  nt and `add_cros
+00009880: 735f 6174 7465 6e74 696f 6e60 2073 6574  s_attention` set
+00009890: 2074 6f20 6054 7275 6560 3b20 616e 2060   to `True`; an `
+000098a0: 656e 636f 6465 725f 6869 6464 656e 5f73  encoder_hidden_s
+000098b0: 7461 7465 7360 0a20 2020 2069 7320 7468  tates`.    is th
+000098c0: 656e 2065 7870 6563 7465 6420 6173 2061  en expected as a
+000098d0: 6e20 696e 7075 7420 746f 2074 6865 2066  n input to the f
+000098e0: 6f72 7761 7264 2070 6173 732e 0a0a 0a20  orward pass.... 
+000098f0: 2020 2022 2222 0a0a 2020 2020 6465 6620     """..    def 
+00009900: 5f5f 696e 6974 5f5f 2873 656c 662c 2063  __init__(self, c
+00009910: 6f6e 6669 672c 2061 6464 5f70 6f6f 6c69  onfig, add_pooli
+00009920: 6e67 5f6c 6179 6572 3d54 7275 6529 3a0a  ng_layer=True):.
+00009930: 2020 2020 2020 2020 7375 7065 7228 292e          super().
+00009940: 5f5f 696e 6974 5f5f 2863 6f6e 6669 6729  __init__(config)
+00009950: 0a20 2020 2020 2020 2073 656c 662e 636f  .        self.co
+00009960: 6e66 6967 203d 2063 6f6e 6669 670a 0a20  nfig = config.. 
+00009970: 2020 2020 2020 2069 6620 636f 6e66 6967         if config
+00009980: 2e67 6973 5f65 6d62 6564 6469 6e67 203d  .gis_embedding =
+00009990: 3d20 303a 0a20 2020 2020 2020 2020 2020  = 0:.           
+000099a0: 2073 656c 662e 656d 6265 6464 696e 6773   self.embeddings
+000099b0: 203d 2042 6572 7445 6d62 6564 6469 6e67   = BertEmbedding
+000099c0: 7328 636f 6e66 6967 290a 2020 2020 2020  s(config).      
+000099d0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+000099e0: 2020 2020 7365 6c66 2e65 6d62 6564 6469      self.embeddi
+000099f0: 6e67 7320 3d20 4769 7345 6d62 6564 6469  ngs = GisEmbeddi
+00009a00: 6e67 7328 636f 6e66 6967 290a 0a20 2020  ngs(config)..   
+00009a10: 2020 2020 2073 656c 662e 656e 636f 6465       self.encode
+00009a20: 7220 3d20 4265 7274 456e 636f 6465 7228  r = BertEncoder(
+00009a30: 636f 6e66 6967 290a 0a20 2020 2020 2020  config)..       
+00009a40: 2073 656c 662e 706f 6f6c 6572 203d 2042   self.pooler = B
+00009a50: 6572 7450 6f6f 6c65 7228 636f 6e66 6967  ertPooler(config
+00009a60: 2920 6966 2061 6464 5f70 6f6f 6c69 6e67  ) if add_pooling
+00009a70: 5f6c 6179 6572 2065 6c73 6520 4e6f 6e65  _layer else None
+00009a80: 0a0a 2020 2020 2020 2020 7365 6c66 2e69  ..        self.i
+00009a90: 6e69 745f 7765 6967 6874 7328 290a 0a20  nit_weights().. 
+00009aa0: 2020 2064 6566 2067 6574 5f69 6e70 7574     def get_input
+00009ab0: 5f65 6d62 6564 6469 6e67 7328 7365 6c66  _embeddings(self
+00009ac0: 293a 0a20 2020 2020 2020 2072 6574 7572  ):.        retur
+00009ad0: 6e20 7365 6c66 2e65 6d62 6564 6469 6e67  n self.embedding
+00009ae0: 732e 776f 7264 5f65 6d62 6564 6469 6e67  s.word_embedding
+00009af0: 730a 0a20 2020 2064 6566 2073 6574 5f69  s..    def set_i
+00009b00: 6e70 7574 5f65 6d62 6564 6469 6e67 7328  nput_embeddings(
+00009b10: 7365 6c66 2c20 7661 6c75 6529 3a0a 2020  self, value):.  
+00009b20: 2020 2020 2020 7365 6c66 2e65 6d62 6564        self.embed
+00009b30: 6469 6e67 732e 776f 7264 5f65 6d62 6564  dings.word_embed
+00009b40: 6469 6e67 7320 3d20 7661 6c75 650a 0a20  dings = value.. 
+00009b50: 2020 2064 6566 205f 7072 756e 655f 6865     def _prune_he
+00009b60: 6164 7328 7365 6c66 2c20 6865 6164 735f  ads(self, heads_
+00009b70: 746f 5f70 7275 6e65 293a 0a20 2020 2020  to_prune):.     
+00009b80: 2020 2022 2222 0a20 2020 2020 2020 2050     """.        P
+00009b90: 7275 6e65 7320 6865 6164 7320 6f66 2074  runes heads of t
+00009ba0: 6865 206d 6f64 656c 2e20 6865 6164 735f  he model. heads_
+00009bb0: 746f 5f70 7275 6e65 3a20 6469 6374 206f  to_prune: dict o
+00009bc0: 6620 7b6c 6179 6572 5f6e 756d 3a20 6c69  f {layer_num: li
+00009bd0: 7374 206f 6620 6865 6164 7320 746f 2070  st of heads to p
+00009be0: 7275 6e65 2069 6e20 7468 6973 206c 6179  rune in this lay
+00009bf0: 6572 7d20 5365 6520 6261 7365 0a20 2020  er} See base.   
+00009c00: 2020 2020 2063 6c61 7373 2050 7265 5472       class PreTr
+00009c10: 6169 6e65 644d 6f64 656c 0a20 2020 2020  ainedModel.     
+00009c20: 2020 2022 2222 0a20 2020 2020 2020 2066     """.        f
+00009c30: 6f72 206c 6179 6572 2c20 6865 6164 7320  or layer, heads 
+00009c40: 696e 2068 6561 6473 5f74 6f5f 7072 756e  in heads_to_prun
+00009c50: 652e 6974 656d 7328 293a 0a20 2020 2020  e.items():.     
+00009c60: 2020 2020 2020 2073 656c 662e 656e 636f         self.enco
+00009c70: 6465 722e 6c61 7965 725b 6c61 7965 725d  der.layer[layer]
+00009c80: 2e61 7474 656e 7469 6f6e 2e70 7275 6e65  .attention.prune
+00009c90: 5f68 6561 6473 2868 6561 6473 290a 0a20  _heads(heads).. 
+00009ca0: 2020 2064 6566 2067 6574 5f65 7874 656e     def get_exten
+00009cb0: 6465 645f 6174 7465 6e74 696f 6e5f 6d61  ded_attention_ma
+00009cc0: 736b 2873 656c 662c 2061 7474 656e 7469  sk(self, attenti
+00009cd0: 6f6e 5f6d 6173 6b3a 2054 656e 736f 722c  on_mask: Tensor,
+00009ce0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009d00: 2020 2020 2069 6e70 7574 5f73 6861 7065       input_shape
+00009d10: 3a20 5475 706c 655b 696e 745d 2c20 6465  : Tuple[int], de
+00009d20: 7669 6365 3a20 6465 7669 6365 2c0a 2020  vice: device,.  
+00009d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009d50: 2020 6973 5f64 6563 6f64 6572 3a20 626f    is_decoder: bo
+00009d60: 6f6c 2920 2d3e 2054 656e 736f 723a 0a20  ol) -> Tensor:. 
+00009d70: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00009d80: 2020 204d 616b 6573 2062 726f 6164 6361     Makes broadca
+00009d90: 7374 6162 6c65 2061 7474 656e 7469 6f6e  stable attention
+00009da0: 2061 6e64 2063 6175 7361 6c20 6d61 736b   and causal mask
+00009db0: 7320 736f 2074 6861 7420 6675 7475 7265  s so that future
+00009dc0: 2061 6e64 206d 6173 6b65 640a 2020 2020   and masked.    
+00009dd0: 2020 2020 746f 6b65 6e73 2061 7265 2069      tokens are i
+00009de0: 676e 6f72 6564 2e0a 0a20 2020 2020 2020  gnored...       
+00009df0: 2041 7267 756d 656e 7473 3a0a 2020 2020   Arguments:.    
+00009e00: 2020 2020 2020 2020 6174 7465 6e74 696f          attentio
+00009e10: 6e5f 6d61 736b 2028 3a6f 626a 3a60 746f  n_mask (:obj:`to
+00009e20: 7263 682e 5465 6e73 6f72 6029 3a0a 2020  rch.Tensor`):.  
+00009e30: 2020 2020 2020 2020 2020 2020 2020 4d61                Ma
+00009e40: 736b 2077 6974 6820 6f6e 6573 2069 6e64  sk with ones ind
+00009e50: 6963 6174 696e 6720 746f 6b65 6e73 2074  icating tokens t
+00009e60: 6f20 6174 7465 6e64 2074 6f2c 207a 6572  o attend to, zer
+00009e70: 6f73 2066 6f72 2074 6f6b 656e 730a 2020  os for tokens.  
+00009e80: 2020 2020 2020 2020 2020 2020 2020 746f                to
+00009e90: 2069 676e 6f72 652e 0a20 2020 2020 2020   ignore..       
+00009ea0: 2020 2020 2069 6e70 7574 5f73 6861 7065       input_shape
+00009eb0: 2028 3a6f 626a 3a60 5475 706c 655b 696e   (:obj:`Tuple[in
+00009ec0: 745d 6029 3a0a 2020 2020 2020 2020 2020  t]`):.          
+00009ed0: 2020 2020 2020 5468 6520 7368 6170 6520        The shape 
+00009ee0: 6f66 2074 6865 2069 6e70 7574 2074 6f20  of the input to 
+00009ef0: 7468 6520 6d6f 6465 6c2e 0a20 2020 2020  the model..     
+00009f00: 2020 2020 2020 2064 6576 6963 653a 2028         device: (
+00009f10: 3a6f 626a 3a60 746f 7263 682e 6465 7669  :obj:`torch.devi
+00009f20: 6365 6029 3a0a 2020 2020 2020 2020 2020  ce`):.          
+00009f30: 2020 2020 2020 5468 6520 6465 7669 6365        The device
+00009f40: 206f 6620 7468 6520 696e 7075 7420 746f   of the input to
+00009f50: 2074 6865 206d 6f64 656c 2e0a 0a20 2020   the model...   
+00009f60: 2020 2020 2052 6574 7572 6e73 3a0a 2020       Returns:.  
+00009f70: 2020 2020 2020 2020 2020 3a6f 626a 3a60            :obj:`
+00009f80: 746f 7263 682e 5465 6e73 6f72 6020 5468  torch.Tensor` Th
+00009f90: 6520 6578 7465 6e64 6564 2061 7474 656e  e extended atten
+00009fa0: 7469 6f6e 206d 6173 6b2c 2077 6974 6820  tion mask, with 
+00009fb0: 6120 7468 6520 7361 6d65 0a20 2020 2020  a the same.     
+00009fc0: 2020 2020 2020 2064 7479 7065 2061 7320         dtype as 
+00009fd0: 3a6f 626a 3a60 6174 7465 6e74 696f 6e5f  :obj:`attention_
+00009fe0: 6d61 736b 2e64 7479 7065 602e 0a20 2020  mask.dtype`..   
+00009ff0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+0000a000: 2023 2057 6520 6361 6e20 7072 6f76 6964   # We can provid
+0000a010: 6520 6120 7365 6c66 2d61 7474 656e 7469  e a self-attenti
+0000a020: 6f6e 206d 6173 6b20 6f66 2064 696d 656e  on mask of dimen
+0000a030: 7369 6f6e 7320 5b62 6174 6368 5f73 697a  sions [batch_siz
+0000a040: 652c 0a20 2020 2020 2020 2023 2066 726f  e,.        # fro
+0000a050: 6d5f 7365 715f 6c65 6e67 7468 2c20 746f  m_seq_length, to
+0000a060: 5f73 6571 5f6c 656e 6774 685d 206f 7572  _seq_length] our
+0000a070: 7365 6c76 6573 2069 6e20 7768 6963 6820  selves in which 
+0000a080: 6361 7365 2077 6520 6a75 7374 206e 6565  case we just nee
+0000a090: 640a 2020 2020 2020 2020 2320 746f 206d  d.        # to m
+0000a0a0: 616b 6520 6974 2062 726f 6164 6361 7374  ake it broadcast
+0000a0b0: 6162 6c65 2074 6f20 616c 6c20 6865 6164  able to all head
+0000a0c0: 732e 0a20 2020 2020 2020 2069 6620 6174  s..        if at
+0000a0d0: 7465 6e74 696f 6e5f 6d61 736b 2e64 696d  tention_mask.dim
+0000a0e0: 2829 203d 3d20 333a 0a20 2020 2020 2020  () == 3:.       
+0000a0f0: 2020 2020 2065 7874 656e 6465 645f 6174       extended_at
+0000a100: 7465 6e74 696f 6e5f 6d61 736b 203d 2061  tention_mask = a
+0000a110: 7474 656e 7469 6f6e 5f6d 6173 6b5b 3a2c  ttention_mask[:,
+0000a120: 204e 6f6e 652c 203a 2c20 3a5d 0a20 2020   None, :, :].   
+0000a130: 2020 2020 2065 6c69 6620 6174 7465 6e74       elif attent
+0000a140: 696f 6e5f 6d61 736b 2e64 696d 2829 203d  ion_mask.dim() =
+0000a150: 3d20 323a 0a20 2020 2020 2020 2020 2020  = 2:.           
+0000a160: 2023 2050 726f 7669 6465 6420 6120 7061   # Provided a pa
+0000a170: 6464 696e 6720 6d61 736b 206f 6620 6469  dding mask of di
+0000a180: 6d65 6e73 696f 6e73 205b 6261 7463 685f  mensions [batch_
+0000a190: 7369 7a65 2c20 7365 715f 6c65 6e67 7468  size, seq_length
+0000a1a0: 5d0a 2020 2020 2020 2020 2020 2020 2320  ].            # 
+0000a1b0: 2d20 6966 2074 6865 206d 6f64 656c 2069  - if the model i
+0000a1c0: 7320 6120 6465 636f 6465 722c 2061 7070  s a decoder, app
+0000a1d0: 6c79 2061 2063 6175 7361 6c20 6d61 736b  ly a causal mask
+0000a1e0: 2069 6e20 6164 6469 7469 6f6e 2074 6f0a   in addition to.
+0000a1f0: 2020 2020 2020 2020 2020 2020 2320 2020              #   
+0000a200: 7468 6520 7061 6464 696e 6720 6d61 736b  the padding mask
+0000a210: 0a20 2020 2020 2020 2020 2020 2023 202d  .            # -
+0000a220: 2069 6620 7468 6520 6d6f 6465 6c20 6973   if the model is
+0000a230: 2061 6e20 656e 636f 6465 722c 206d 616b   an encoder, mak
+0000a240: 6520 7468 6520 6d61 736b 2062 726f 6164  e the mask broad
+0000a250: 6361 7374 6162 6c65 2074 6f0a 2020 2020  castable to.    
+0000a260: 2020 2020 2020 2020 2320 2020 5b62 6174          #   [bat
+0000a270: 6368 5f73 697a 652c 206e 756d 5f68 6561  ch_size, num_hea
+0000a280: 6473 2c20 7365 715f 6c65 6e67 7468 2c20  ds, seq_length, 
+0000a290: 7365 715f 6c65 6e67 7468 5d0a 2020 2020  seq_length].    
+0000a2a0: 2020 2020 2020 2020 6966 2069 735f 6465          if is_de
+0000a2b0: 636f 6465 723a 0a20 2020 2020 2020 2020  coder:.         
+0000a2c0: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
+0000a2d0: 652c 2073 6571 5f6c 656e 6774 6820 3d20  e, seq_length = 
+0000a2e0: 696e 7075 745f 7368 6170 650a 2020 2020  input_shape.    
+0000a2f0: 2020 2020 2020 2020 2020 2020 7365 715f              seq_
+0000a300: 6964 7320 3d20 746f 7263 682e 6172 616e  ids = torch.aran
+0000a310: 6765 2873 6571 5f6c 656e 6774 682c 2064  ge(seq_length, d
+0000a320: 6576 6963 653d 6465 7669 6365 290a 2020  evice=device).  
+0000a330: 2020 2020 2020 2020 2020 2020 2020 6361                ca
+0000a340: 7573 616c 5f6d 6173 6b20 3d20 7365 715f  usal_mask = seq_
+0000a350: 6964 735b 4e6f 6e65 2c20 4e6f 6e65 2c20  ids[None, None, 
+0000a360: 3a5d 2e72 6570 6561 7428 0a20 2020 2020  :].repeat(.     
+0000a370: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+0000a380: 6174 6368 5f73 697a 652c 2073 6571 5f6c  atch_size, seq_l
+0000a390: 656e 6774 682c 2031 2920 3c3d 2073 6571  ength, 1) <= seq
+0000a3a0: 5f69 6473 5b4e 6f6e 652c 203a 2c20 4e6f  _ids[None, :, No
+0000a3b0: 6e65 5d0a 2020 2020 2020 2020 2020 2020  ne].            
+0000a3c0: 2020 2020 2320 696e 2063 6173 6520 7061      # in case pa
+0000a3d0: 7374 5f6b 6579 5f76 616c 7565 7320 6172  st_key_values ar
+0000a3e0: 6520 7573 6564 2077 6520 6e65 6564 2074  e used we need t
+0000a3f0: 6f20 6164 6420 6120 7072 6566 6978 206f  o add a prefix o
+0000a400: 6e65 730a 2020 2020 2020 2020 2020 2020  nes.            
+0000a410: 2020 2020 2320 6d61 736b 2074 6f20 7468      # mask to th
+0000a420: 6520 6361 7573 616c 206d 6173 6b20 6361  e causal mask ca
+0000a430: 7573 616c 2061 6e64 2061 7474 656e 7469  usal and attenti
+0000a440: 6f6e 206d 6173 6b73 206d 7573 7420 6861  on masks must ha
+0000a450: 7665 0a20 2020 2020 2020 2020 2020 2020  ve.             
+0000a460: 2020 2023 2073 616d 6520 7479 7065 2077     # same type w
+0000a470: 6974 6820 7079 746f 7263 6820 7665 7273  ith pytorch vers
+0000a480: 696f 6e20 3c20 312e 330a 2020 2020 2020  ion < 1.3.      
+0000a490: 2020 2020 2020 2020 2020 6361 7573 616c            causal
+0000a4a0: 5f6d 6173 6b20 3d20 6361 7573 616c 5f6d  _mask = causal_m
+0000a4b0: 6173 6b2e 746f 2861 7474 656e 7469 6f6e  ask.to(attention
+0000a4c0: 5f6d 6173 6b2e 6474 7970 6529 0a0a 2020  _mask.dtype)..  
+0000a4d0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000a4e0: 2063 6175 7361 6c5f 6d61 736b 2e73 6861   causal_mask.sha
+0000a4f0: 7065 5b31 5d20 3c20 6174 7465 6e74 696f  pe[1] < attentio
+0000a500: 6e5f 6d61 736b 2e73 6861 7065 5b31 5d3a  n_mask.shape[1]:
+0000a510: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a520: 2020 2020 2070 7265 6669 785f 7365 715f       prefix_seq_
+0000a530: 6c65 6e20 3d20 6174 7465 6e74 696f 6e5f  len = attention_
+0000a540: 6d61 736b 2e73 6861 7065 5b0a 2020 2020  mask.shape[.    
+0000a550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a560: 2020 2020 315d 202d 2063 6175 7361 6c5f      1] - causal_
+0000a570: 6d61 736b 2e73 6861 7065 5b31 5d0a 2020  mask.shape[1].  
+0000a580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a590: 2020 6361 7573 616c 5f6d 6173 6b20 3d20    causal_mask = 
+0000a5a0: 746f 7263 682e 6361 7428 0a20 2020 2020  torch.cat(.     
+0000a5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a5c0: 2020 205b 0a20 2020 2020 2020 2020 2020     [.           
+0000a5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a5e0: 2074 6f72 6368 2e6f 6e65 7328 0a20 2020   torch.ones(.   
+0000a5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a600: 2020 2020 2020 2020 2020 2020 2028 6261               (ba
+0000a610: 7463 685f 7369 7a65 2c20 7365 715f 6c65  tch_size, seq_le
+0000a620: 6e67 7468 2c20 7072 6566 6978 5f73 6571  ngth, prefix_seq
+0000a630: 5f6c 656e 292c 0a20 2020 2020 2020 2020  _len),.         
+0000a640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a650: 2020 2020 2020 2064 6576 6963 653d 6465         device=de
+0000a660: 7669 6365 2c0a 2020 2020 2020 2020 2020  vice,.          
+0000a670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a680: 2020 2020 2020 6474 7970 653d 6361 7573        dtype=caus
+0000a690: 616c 5f6d 6173 6b2e 6474 7970 6529 2c0a  al_mask.dtype),.
+0000a6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a6b0: 2020 2020 2020 2020 2020 2020 6361 7573              caus
+0000a6c0: 616c 5f6d 6173 6b2c 0a20 2020 2020 2020  al_mask,.       
 0000a6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a6e0: 2020 2020 2020 2020 746f 7263 682e 6f6e          torch.on
-0000a6f0: 6573 280a 2020 2020 2020 2020 2020 2020  es(.            
-0000a700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a710: 2020 2020 2862 6174 6368 5f73 697a 652c      (batch_size,
-0000a720: 2073 6571 5f6c 656e 6774 682c 2070 7265   seq_length, pre
-0000a730: 6669 785f 7365 715f 6c65 6e29 2c0a 2020  fix_seq_len),.  
-0000a740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a750: 2020 2020 2020 2020 2020 2020 2020 6465                de
-0000a760: 7669 6365 3d64 6576 6963 652c 0a20 2020  vice=device,.   
+0000a6e0: 205d 2c0a 2020 2020 2020 2020 2020 2020   ],.            
+0000a6f0: 2020 2020 2020 2020 2020 2020 6178 6973              axis
+0000a700: 3d2d 312c 0a20 2020 2020 2020 2020 2020  =-1,.           
+0000a710: 2020 2020 2020 2020 2029 0a0a 2020 2020           )..    
+0000a720: 2020 2020 2020 2020 2020 2020 6578 7465              exte
+0000a730: 6e64 6564 5f61 7474 656e 7469 6f6e 5f6d  nded_attention_m
+0000a740: 6173 6b20 3d20 6361 7573 616c 5f6d 6173  ask = causal_mas
+0000a750: 6b5b 3a2c 0a20 2020 2020 2020 2020 2020  k[:,.           
+0000a760: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0000a770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a780: 2020 2020 2020 2020 2020 2020 2064 7479               dty
-0000a790: 7065 3d63 6175 7361 6c5f 6d61 736b 2e64  pe=causal_mask.d
-0000a7a0: 7479 7065 292c 0a20 2020 2020 2020 2020  type),.         
+0000a780: 2020 2020 2020 2020 2020 204e 6f6e 652c             None,
+0000a790: 203a 2c20 3a5d 202a 2061 7474 656e 7469   :, :] * attenti
+0000a7a0: 6f6e 5f6d 6173 6b5b 3a2c 0a20 2020 2020  on_mask[:,.     
 0000a7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a7c0: 2020 2063 6175 7361 6c5f 6d61 736b 2c0a     causal_mask,.
+0000a7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0000a7d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a7e0: 2020 2020 2020 2020 5d2c 0a20 2020 2020          ],.     
-0000a7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a800: 2020 2061 7869 733d 2d31 2c0a 2020 2020     axis=-1,.    
+0000a7e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a7f0: 2020 2020 2020 2020 2020 2020 2020 4e6f                No
+0000a800: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
 0000a810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a820: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
-0000a830: 2020 2065 7874 656e 6465 645f 6174 7465     extended_atte
-0000a840: 6e74 696f 6e5f 6d61 736b 203d 2063 6175  ntion_mask = cau
-0000a850: 7361 6c5f 6d61 736b 5b3a 2c0a 2020 2020  sal_mask[:,.    
-0000a860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a890: 2020 4e6f 6e65 2c20 3a2c 203a 5d20 2a20    None, :, :] * 
-0000a8a0: 6174 7465 6e74 696f 6e5f 6d61 736b 5b3a  attention_mask[:
-0000a8b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000a8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a8d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a8e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a900: 2020 2020 204e 6f6e 652c 0a20 2020 2020       None,.     
-0000a910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a950: 2020 2020 2020 2020 2020 2020 2020 4e6f                No
-0000a960: 6e65 2c20 3a5d 0a20 2020 2020 2020 2020  ne, :].         
-0000a970: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0000a980: 2020 2020 2020 2020 2065 7874 656e 6465           extende
-0000a990: 645f 6174 7465 6e74 696f 6e5f 6d61 736b  d_attention_mask
-0000a9a0: 203d 2061 7474 656e 7469 6f6e 5f6d 6173   = attention_mas
-0000a9b0: 6b5b 3a2c 204e 6f6e 652c 204e 6f6e 652c  k[:, None, None,
-0000a9c0: 203a 5d0a 2020 2020 2020 2020 656c 7365   :].        else
-0000a9d0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-0000a9e0: 6973 6520 5661 6c75 6545 7272 6f72 280a  ise ValueError(.
-0000a9f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000aa00: 2757 726f 6e67 2073 6861 7065 2066 6f72  'Wrong shape for
-0000aa10: 2069 6e70 7574 5f69 6473 2028 7368 6170   input_ids (shap
-0000aa20: 6520 7b7d 2920 6f72 2061 7474 656e 7469  e {}) or attenti
-0000aa30: 6f6e 5f6d 6173 6b20 2873 6861 7065 207b  on_mask (shape {
-0000aa40: 7d29 270a 2020 2020 2020 2020 2020 2020  })'.            
-0000aa50: 2020 2020 2e66 6f72 6d61 7428 696e 7075      .format(inpu
-0000aa60: 745f 7368 6170 652c 2061 7474 656e 7469  t_shape, attenti
-0000aa70: 6f6e 5f6d 6173 6b2e 7368 6170 6529 290a  on_mask.shape)).
-0000aa80: 0a20 2020 2020 2020 2023 2053 696e 6365  .        # Since
-0000aa90: 2061 7474 656e 7469 6f6e 5f6d 6173 6b20   attention_mask 
-0000aaa0: 6973 2031 2e30 2066 6f72 2070 6f73 6974  is 1.0 for posit
-0000aab0: 696f 6e73 2077 6520 7761 6e74 2074 6f20  ions we want to 
-0000aac0: 6174 7465 6e64 2061 6e64 2030 2e30 0a20  attend and 0.0. 
-0000aad0: 2020 2020 2020 2023 2066 6f72 206d 6173         # for mas
-0000aae0: 6b65 6420 706f 7369 7469 6f6e 732c 2074  ked positions, t
-0000aaf0: 6869 7320 6f70 6572 6174 696f 6e20 7769  his operation wi
-0000ab00: 6c6c 2063 7265 6174 6520 6120 7465 6e73  ll create a tens
-0000ab10: 6f72 2077 6869 6368 2069 7320 302e 300a  or which is 0.0.
-0000ab20: 2020 2020 2020 2020 2320 666f 7220 706f          # for po
-0000ab30: 7369 7469 6f6e 7320 7765 2077 616e 7420  sitions we want 
-0000ab40: 746f 2061 7474 656e 6420 616e 6420 2d31  to attend and -1
-0000ab50: 3030 3030 2e30 2066 6f72 206d 6173 6b65  0000.0 for maske
-0000ab60: 6420 706f 7369 7469 6f6e 732e 0a20 2020  d positions..   
-0000ab70: 2020 2020 2023 2053 696e 6365 2077 6520       # Since we 
-0000ab80: 6172 6520 6164 6469 6e67 2069 7420 746f  are adding it to
-0000ab90: 2074 6865 2072 6177 2073 636f 7265 7320   the raw scores 
-0000aba0: 6265 666f 7265 2074 6865 2073 6f66 746d  before the softm
-0000abb0: 6178 2c20 7468 6973 2069 730a 2020 2020  ax, this is.    
-0000abc0: 2020 2020 2320 6566 6665 6374 6976 656c      # effectivel
-0000abd0: 7920 7468 6520 7361 6d65 2061 7320 7265  y the same as re
-0000abe0: 6d6f 7669 6e67 2074 6865 7365 2065 6e74  moving these ent
-0000abf0: 6972 656c 792e 0a20 2020 2020 2020 2065  irely..        e
-0000ac00: 7874 656e 6465 645f 6174 7465 6e74 696f  xtended_attentio
-0000ac10: 6e5f 6d61 736b 203d 2065 7874 656e 6465  n_mask = extende
-0000ac20: 645f 6174 7465 6e74 696f 6e5f 6d61 736b  d_attention_mask
-0000ac30: 2e74 6f28 0a20 2020 2020 2020 2020 2020  .to(.           
-0000ac40: 2064 7479 7065 3d73 656c 662e 6474 7970   dtype=self.dtyp
-0000ac50: 6529 2020 2320 6670 3136 2063 6f6d 7061  e)  # fp16 compa
-0000ac60: 7469 6269 6c69 7479 0a20 2020 2020 2020  tibility.       
-0000ac70: 2065 7874 656e 6465 645f 6174 7465 6e74   extended_attent
-0000ac80: 696f 6e5f 6d61 736b 203d 2028 312e 3020  ion_mask = (1.0 
-0000ac90: 2d20 6578 7465 6e64 6564 5f61 7474 656e  - extended_atten
-0000aca0: 7469 6f6e 5f6d 6173 6b29 202a 202d 3130  tion_mask) * -10
-0000acb0: 3030 302e 300a 2020 2020 2020 2020 7265  000.0.        re
-0000acc0: 7475 726e 2065 7874 656e 6465 645f 6174  turn extended_at
-0000acd0: 7465 6e74 696f 6e5f 6d61 736b 0a0a 2020  tention_mask..  
-0000ace0: 2020 6465 6620 666f 7277 6172 6428 0a20    def forward(. 
-0000acf0: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-0000ad00: 2020 2020 2069 6e70 7574 5f69 6473 3d4e       input_ids=N
-0000ad10: 6f6e 652c 0a20 2020 2020 2020 2061 7474  one,.        att
-0000ad20: 656e 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65  ention_mask=None
-0000ad30: 2c0a 2020 2020 2020 2020 746f 6b65 6e5f  ,.        token_
-0000ad40: 7479 7065 5f69 6473 3d4e 6f6e 652c 0a20  type_ids=None,. 
-0000ad50: 2020 2020 2020 2070 6f73 6974 696f 6e5f         position_
-0000ad60: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
-0000ad70: 2020 6865 6164 5f6d 6173 6b3d 4e6f 6e65    head_mask=None
-0000ad80: 2c0a 2020 2020 2020 2020 696e 7075 7473  ,.        inputs
-0000ad90: 5f65 6d62 6564 733d 4e6f 6e65 2c0a 2020  _embeds=None,.  
-0000ada0: 2020 2020 2020 656e 636f 6465 725f 656d        encoder_em
-0000adb0: 6265 6473 3d4e 6f6e 652c 0a20 2020 2020  beds=None,.     
-0000adc0: 2020 2065 6e63 6f64 6572 5f68 6964 6465     encoder_hidde
-0000add0: 6e5f 7374 6174 6573 3d4e 6f6e 652c 0a20  n_states=None,. 
-0000ade0: 2020 2020 2020 2065 6e63 6f64 6572 5f61         encoder_a
-0000adf0: 7474 656e 7469 6f6e 5f6d 6173 6b3d 4e6f  ttention_mask=No
-0000ae00: 6e65 2c0a 2020 2020 2020 2020 7061 7374  ne,.        past
-0000ae10: 5f6b 6579 5f76 616c 7565 733d 4e6f 6e65  _key_values=None
-0000ae20: 2c0a 2020 2020 2020 2020 7573 655f 6361  ,.        use_ca
-0000ae30: 6368 653d 4e6f 6e65 2c0a 2020 2020 2020  che=None,.      
-0000ae40: 2020 6f75 7470 7574 5f61 7474 656e 7469    output_attenti
-0000ae50: 6f6e 733d 4e6f 6e65 2c0a 2020 2020 2020  ons=None,.      
-0000ae60: 2020 6f75 7470 7574 5f68 6964 6465 6e5f    output_hidden_
-0000ae70: 7374 6174 6573 3d4e 6f6e 652c 0a20 2020  states=None,.   
-0000ae80: 2020 2020 2072 6574 7572 6e5f 6469 6374       return_dict
-0000ae90: 3d4e 6f6e 652c 0a20 2020 2020 2020 2069  =None,.        i
-0000aea0: 735f 6465 636f 6465 723d 4661 6c73 652c  s_decoder=False,
-0000aeb0: 0a20 2020 2020 2020 206d 6f64 653d 276d  .        mode='m
-0000aec0: 756c 7469 5f6d 6f64 616c 272c 0a20 2020  ulti_modal',.   
-0000aed0: 2020 2020 2072 656c 5f74 7970 655f 6964       rel_type_id
-0000aee0: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
-0000aef0: 6162 736f 6c75 7465 5f70 6f73 6974 696f  absolute_positio
-0000af00: 6e5f 6964 733d 4e6f 6e65 2c0a 2020 2020  n_ids=None,.    
-0000af10: 2020 2020 7265 6c61 7469 7665 5f70 6f73      relative_pos
-0000af20: 6974 696f 6e5f 6964 733d 4e6f 6e65 2c0a  ition_ids=None,.
-0000af30: 2020 2020 2020 2020 7072 6f76 5f69 6473          prov_ids
-0000af40: 3d4e 6f6e 652c 0a20 2020 2020 2020 2063  =None,.        c
-0000af50: 6974 795f 6964 733d 4e6f 6e65 2c0a 2020  ity_ids=None,.  
-0000af60: 2020 2020 2020 6469 7374 5f69 6473 3d4e        dist_ids=N
-0000af70: 6f6e 652c 0a20 2020 2029 3a0a 2020 2020  one,.    ):.    
-0000af80: 2020 2020 7222 2222 0a20 2020 2020 2020      r""".       
-0000af90: 2041 7267 733a 0a20 2020 2020 2020 2069   Args:.        i
-0000afa0: 6e70 7574 5f69 6473 2028 6074 6f72 6368  nput_ids (`torch
-0000afb0: 2e4c 6f6e 6754 656e 736f 7260 206f 6620  .LongTensor` of 
-0000afc0: 7368 6170 6520 6028 2862 6174 6368 5f73  shape `((batch_s
-0000afd0: 697a 652c 2073 6571 7565 6e63 655f 6c65  ize, sequence_le
-0000afe0: 6e67 7468 2960 293a 0a20 2020 2020 2020  ngth)`):.       
-0000aff0: 2020 2020 2049 6e64 6963 6573 206f 6620       Indices of 
-0000b000: 696e 7075 7420 7365 7175 656e 6365 2074  input sequence t
-0000b010: 6f6b 656e 7320 696e 2074 6865 2076 6f63  okens in the voc
-0000b020: 6162 756c 6172 792e 0a0a 2020 2020 2020  abulary...      
-0000b030: 2020 2020 2020 496e 6469 6365 7320 6361        Indices ca
-0000b040: 6e20 6265 206f 6274 6169 6e65 6420 7573  n be obtained us
-0000b050: 696e 6720 5b60 4265 7274 546f 6b65 6e69  ing [`BertTokeni
-0000b060: 7a65 7260 5d2e 2053 6565 0a20 2020 2020  zer`]. See.     
-0000b070: 2020 2020 2020 205b 6050 7265 5472 6169         [`PreTrai
-0000b080: 6e65 6454 6f6b 656e 697a 6572 2e65 6e63  nedTokenizer.enc
-0000b090: 6f64 6560 5d20 616e 6420 5b60 5072 6554  ode`] and [`PreT
-0000b0a0: 7261 696e 6564 546f 6b65 6e69 7a65 722e  rainedTokenizer.
-0000b0b0: 5f5f 6361 6c6c 5f5f 605d 0a20 2020 2020  __call__`].     
-0000b0c0: 2020 2020 2020 2066 6f72 2064 6574 6169         for detai
-0000b0d0: 6c73 2e0a 0a20 2020 2020 2020 2020 2020  ls...           
-0000b0e0: 205b 5768 6174 2061 7265 2069 6e70 7574   [What are input
-0000b0f0: 2049 4473 3f5d 282e 2e2f 676c 6f73 7361   IDs?](../glossa
-0000b100: 7279 2369 6e70 7574 2d69 6473 290a 2020  ry#input-ids).  
-0000b110: 2020 2020 2020 6174 7465 6e74 696f 6e5f        attention_
-0000b120: 6d61 736b 2028 6074 6f72 6368 2e46 6c6f  mask (`torch.Flo
-0000b130: 6174 5465 6e73 6f72 6020 6f66 2073 6861  atTensor` of sha
-0000b140: 7065 2060 2828 6261 7463 685f 7369 7a65  pe `((batch_size
-0000b150: 2c20 7365 7175 656e 6365 5f6c 656e 6774  , sequence_lengt
-0000b160: 6829 602c 202a 6f70 7469 6f6e 616c 2a29  h)`, *optional*)
-0000b170: 3a0a 2020 2020 2020 2020 2020 2020 4d61  :.            Ma
-0000b180: 736b 2074 6f20 6176 6f69 6420 7065 7266  sk to avoid perf
-0000b190: 6f72 6d69 6e67 2061 7474 656e 7469 6f6e  orming attention
-0000b1a0: 206f 6e20 7061 6464 696e 6720 746f 6b65   on padding toke
-0000b1b0: 6e20 696e 6469 6365 732e 204d 6173 6b0a  n indices. Mask.
-0000b1c0: 2020 2020 2020 2020 2020 2020 7661 6c75              valu
-0000b1d0: 6573 2073 656c 6563 7465 6420 696e 2060  es selected in `
-0000b1e0: 5b30 2c20 315d 603a 0a0a 2020 2020 2020  [0, 1]`:..      
-0000b1f0: 2020 2020 2020 2d20 3120 666f 7220 746f        - 1 for to
-0000b200: 6b65 6e73 2074 6861 7420 6172 6520 2a2a  kens that are **
-0000b210: 6e6f 7420 6d61 736b 6564 2a2a 2c0a 2020  not masked**,.  
-0000b220: 2020 2020 2020 2020 2020 2d20 3020 666f            - 0 fo
-0000b230: 7220 746f 6b65 6e73 2074 6861 7420 6172  r tokens that ar
-0000b240: 6520 2a2a 6d61 736b 6564 2a2a 2e0a 0a20  e **masked**... 
-0000b250: 2020 2020 2020 2020 2020 205b 5768 6174             [What
-0000b260: 2061 7265 2061 7474 656e 7469 6f6e 206d   are attention m
-0000b270: 6173 6b73 3f5d 282e 2e2f 676c 6f73 7361  asks?](../glossa
-0000b280: 7279 2361 7474 656e 7469 6f6e 2d6d 6173  ry#attention-mas
-0000b290: 6b29 0a20 2020 2020 2020 2074 6f6b 656e  k).        token
-0000b2a0: 5f74 7970 655f 6964 7320 2860 746f 7263  _type_ids (`torc
-0000b2b0: 682e 4c6f 6e67 5465 6e73 6f72 6020 6f66  h.LongTensor` of
-0000b2c0: 2073 6861 7065 2060 2828 6261 7463 685f   shape `((batch_
-0000b2d0: 7369 7a65 2c20 7365 7175 656e 6365 5f6c  size, sequence_l
-0000b2e0: 656e 6774 6829 602c 202a 6f70 7469 6f6e  ength)`, *option
-0000b2f0: 616c 2a29 3a0a 2020 2020 2020 2020 2020  al*):.          
-0000b300: 2020 5365 676d 656e 7420 746f 6b65 6e20    Segment token 
-0000b310: 696e 6469 6365 7320 746f 2069 6e64 6963  indices to indic
-0000b320: 6174 6520 6669 7273 7420 616e 6420 7365  ate first and se
-0000b330: 636f 6e64 2070 6f72 7469 6f6e 7320 6f66  cond portions of
-0000b340: 2074 6865 0a20 2020 2020 2020 2020 2020   the.           
-0000b350: 2069 6e70 7574 732e 2049 6e64 6963 6573   inputs. Indices
-0000b360: 2061 7265 2073 656c 6563 7465 6420 696e   are selected in
-0000b370: 2060 5b30 2c20 315d 603a 0a0a 2020 2020   `[0, 1]`:..    
-0000b380: 2020 2020 2020 2020 2d20 3020 636f 7272          - 0 corr
-0000b390: 6573 706f 6e64 7320 746f 2061 202a 7365  esponds to a *se
-0000b3a0: 6e74 656e 6365 2041 2a20 746f 6b65 6e2c  ntence A* token,
-0000b3b0: 0a20 2020 2020 2020 2020 2020 202d 2031  .            - 1
-0000b3c0: 2063 6f72 7265 7370 6f6e 6473 2074 6f20   corresponds to 
-0000b3d0: 6120 2a73 656e 7465 6e63 6520 422a 2074  a *sentence B* t
-0000b3e0: 6f6b 656e 2e0a 0a20 2020 2020 2020 2020  oken...         
-0000b3f0: 2020 205b 5768 6174 2061 7265 2074 6f6b     [What are tok
-0000b400: 656e 2074 7970 6520 4944 733f 5d28 2e2e  en type IDs?](..
-0000b410: 2f67 6c6f 7373 6172 7923 746f 6b65 6e2d  /glossary#token-
-0000b420: 7479 7065 2d69 6473 290a 2020 2020 2020  type-ids).      
-0000b430: 2020 706f 7369 7469 6f6e 5f69 6473 2028    position_ids (
-0000b440: 6074 6f72 6368 2e4c 6f6e 6754 656e 736f  `torch.LongTenso
-0000b450: 7260 206f 6620 7368 6170 6520 6028 2862  r` of shape `((b
-0000b460: 6174 6368 5f73 697a 652c 2073 6571 7565  atch_size, seque
-0000b470: 6e63 655f 6c65 6e67 7468 2960 2c20 2a6f  nce_length)`, *o
-0000b480: 7074 696f 6e61 6c2a 293a 0a20 2020 2020  ptional*):.     
-0000b490: 2020 2020 2020 2049 6e64 6963 6573 206f         Indices o
-0000b4a0: 6620 706f 7369 7469 6f6e 7320 6f66 2065  f positions of e
-0000b4b0: 6163 6820 696e 7075 7420 7365 7175 656e  ach input sequen
-0000b4c0: 6365 2074 6f6b 656e 7320 696e 2074 6865  ce tokens in the
-0000b4d0: 2070 6f73 6974 696f 6e0a 2020 2020 2020   position.      
-0000b4e0: 2020 2020 2020 656d 6265 6464 696e 6773        embeddings
-0000b4f0: 2e20 5365 6c65 6374 6564 2069 6e20 7468  . Selected in th
-0000b500: 6520 7261 6e67 6520 605b 302c 0a20 2020  e range `[0,.   
-0000b510: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
-0000b520: 6d61 785f 706f 7369 7469 6f6e 5f65 6d62  max_position_emb
-0000b530: 6564 6469 6e67 7320 2d20 315d 602e 0a0a  eddings - 1]`...
-0000b540: 2020 2020 2020 2020 2020 2020 5b57 6861              [Wha
-0000b550: 7420 6172 6520 706f 7369 7469 6f6e 2049  t are position I
-0000b560: 4473 3f5d 282e 2e2f 676c 6f73 7361 7279  Ds?](../glossary
-0000b570: 2370 6f73 6974 696f 6e2d 6964 7329 0a20  #position-ids). 
-0000b580: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
-0000b590: 2028 6074 6f72 6368 2e46 6c6f 6174 5465   (`torch.FloatTe
-0000b5a0: 6e73 6f72 6020 6f66 2073 6861 7065 2060  nsor` of shape `
-0000b5b0: 286e 756d 5f68 6561 6473 2c29 6020 6f72  (num_heads,)` or
-0000b5c0: 2060 286e 756d 5f6c 6179 6572 732c 0a20   `(num_layers,. 
-0000b5d0: 2020 2020 2020 206e 756d 5f68 6561 6473         num_heads
-0000b5e0: 2960 2c20 2a6f 7074 696f 6e61 6c2a 293a  )`, *optional*):
-0000b5f0: 0a20 2020 2020 2020 2020 2020 204d 6173  .            Mas
-0000b600: 6b20 746f 206e 756c 6c69 6679 2073 656c  k to nullify sel
-0000b610: 6563 7465 6420 6865 6164 7320 6f66 2074  ected heads of t
-0000b620: 6865 2073 656c 662d 6174 7465 6e74 696f  he self-attentio
-0000b630: 6e20 6d6f 6475 6c65 732e 204d 6173 6b0a  n modules. Mask.
-0000b640: 2020 2020 2020 2020 2020 2020 7661 6c75              valu
-0000b650: 6573 2073 656c 6563 7465 6420 696e 2060  es selected in `
-0000b660: 5b30 2c20 315d 603a 0a0a 2020 2020 2020  [0, 1]`:..      
-0000b670: 2020 2020 2020 2d20 3120 696e 6469 6361        - 1 indica
-0000b680: 7465 7320 7468 6520 6865 6164 2069 7320  tes the head is 
-0000b690: 2a2a 6e6f 7420 6d61 736b 6564 2a2a 2c0a  **not masked**,.
-0000b6a0: 2020 2020 2020 2020 2020 2020 2d20 3020              - 0 
-0000b6b0: 696e 6469 6361 7465 7320 7468 6520 6865  indicates the he
-0000b6c0: 6164 2069 7320 2a2a 6d61 736b 6564 2a2a  ad is **masked**
-0000b6d0: 2e0a 0a20 2020 2020 2020 2069 6e70 7574  ...        input
-0000b6e0: 735f 656d 6265 6473 2028 6074 6f72 6368  s_embeds (`torch
-0000b6f0: 2e46 6c6f 6174 5465 6e73 6f72 6020 6f66  .FloatTensor` of
-0000b700: 2073 6861 7065 2060 2828 6261 7463 685f   shape `((batch_
-0000b710: 7369 7a65 2c20 7365 7175 656e 6365 5f6c  size, sequence_l
-0000b720: 656e 6774 682c 2068 6964 6465 6e5f 7369  ength, hidden_si
-0000b730: 7a65 2960 2c0a 2020 2020 2020 2020 2a6f  ze)`,.        *o
-0000b740: 7074 696f 6e61 6c2a 293a 0a20 2020 2020  ptional*):.     
-0000b750: 2020 2020 2020 204f 7074 696f 6e61 6c6c         Optionall
-0000b760: 792c 2069 6e73 7465 6164 206f 6620 7061  y, instead of pa
-0000b770: 7373 696e 6720 6069 6e70 7574 5f69 6473  ssing `input_ids
-0000b780: 6020 796f 7520 6361 6e20 6368 6f6f 7365  ` you can choose
-0000b790: 2074 6f0a 2020 2020 2020 2020 2020 2020   to.            
-0000b7a0: 6469 7265 6374 6c79 2070 6173 7320 616e  directly pass an
-0000b7b0: 2065 6d62 6564 6465 6420 7265 7072 6573   embedded repres
-0000b7c0: 656e 7461 7469 6f6e 2e20 5468 6973 2069  entation. This i
-0000b7d0: 7320 7573 6566 756c 2069 6620 796f 7520  s useful if you 
-0000b7e0: 7761 6e74 0a20 2020 2020 2020 2020 2020  want.           
-0000b7f0: 206d 6f72 6520 636f 6e74 726f 6c20 6f76   more control ov
-0000b800: 6572 2068 6f77 2074 6f20 636f 6e76 6572  er how to conver
-0000b810: 7420 6069 6e70 7574 5f69 6473 6020 696e  t `input_ids` in
-0000b820: 6469 6365 7320 696e 746f 2061 7373 6f63  dices into assoc
-0000b830: 6961 7465 640a 2020 2020 2020 2020 2020  iated.          
-0000b840: 2020 7665 6374 6f72 7320 7468 616e 2074    vectors than t
-0000b850: 6865 206d 6f64 656c 2773 2069 6e74 6572  he model's inter
-0000b860: 6e61 6c20 656d 6265 6464 696e 6720 6c6f  nal embedding lo
-0000b870: 6f6b 7570 206d 6174 7269 782e 0a20 2020  okup matrix..   
-0000b880: 2020 2020 206f 7574 7075 745f 6174 7465       output_atte
-0000b890: 6e74 696f 6e73 2028 6062 6f6f 6c60 2c20  ntions (`bool`, 
-0000b8a0: 2a6f 7074 696f 6e61 6c2a 293a 0a20 2020  *optional*):.   
-0000b8b0: 2020 2020 2020 2020 2057 6865 7468 6572           Whether
-0000b8c0: 206f 7220 6e6f 7420 746f 2072 6574 7572   or not to retur
-0000b8d0: 6e20 7468 6520 6174 7465 6e74 696f 6e73  n the attentions
-0000b8e0: 2074 656e 736f 7273 206f 6620 616c 6c20   tensors of all 
-0000b8f0: 6174 7465 6e74 696f 6e0a 2020 2020 2020  attention.      
-0000b900: 2020 2020 2020 6c61 7965 7273 2e20 5365        layers. Se
-0000b910: 6520 6061 7474 656e 7469 6f6e 7360 2075  e `attentions` u
-0000b920: 6e64 6572 2072 6574 7572 6e65 6420 7465  nder returned te
-0000b930: 6e73 6f72 7320 666f 7220 6d6f 7265 2064  nsors for more d
-0000b940: 6574 6169 6c2e 0a20 2020 2020 2020 206f  etail..        o
-0000b950: 7574 7075 745f 6869 6464 656e 5f73 7461  utput_hidden_sta
-0000b960: 7465 7320 2860 626f 6f6c 602c 202a 6f70  tes (`bool`, *op
-0000b970: 7469 6f6e 616c 2a29 3a0a 2020 2020 2020  tional*):.      
-0000b980: 2020 2020 2020 5768 6574 6865 7220 6f72        Whether or
-0000b990: 206e 6f74 2074 6f20 7265 7475 726e 2074   not to return t
-0000b9a0: 6865 2068 6964 6465 6e20 7374 6174 6573  he hidden states
-0000b9b0: 206f 6620 616c 6c20 6c61 7965 7273 2e20   of all layers. 
-0000b9c0: 5365 650a 2020 2020 2020 2020 2020 2020  See.            
-0000b9d0: 6068 6964 6465 6e5f 7374 6174 6573 6020  `hidden_states` 
-0000b9e0: 756e 6465 7220 7265 7475 726e 6564 2074  under returned t
-0000b9f0: 656e 736f 7273 2066 6f72 206d 6f72 6520  ensors for more 
-0000ba00: 6465 7461 696c 2e0a 2020 2020 2020 2020  detail..        
-0000ba10: 7265 7475 726e 5f64 6963 7420 2860 626f  return_dict (`bo
-0000ba20: 6f6c 602c 202a 6f70 7469 6f6e 616c 2a29  ol`, *optional*)
-0000ba30: 3a0a 2020 2020 2020 2020 2020 2020 5768  :.            Wh
-0000ba40: 6574 6865 7220 6f72 206e 6f74 2074 6f20  ether or not to 
-0000ba50: 7265 7475 726e 2061 205b 607e 6669 6c65  return a [`~file
-0000ba60: 5f75 7469 6c73 2e4d 6f64 656c 4f75 7470  _utils.ModelOutp
-0000ba70: 7574 605d 2069 6e73 7465 6164 206f 6620  ut`] instead of 
-0000ba80: 610a 2020 2020 2020 2020 2020 2020 706c  a.            pl
-0000ba90: 6169 6e20 7475 706c 652e 0a20 2020 2020  ain tuple..     
-0000baa0: 2020 2065 6e63 6f64 6572 5f68 6964 6465     encoder_hidde
-0000bab0: 6e5f 7374 6174 6573 2020 2860 746f 7263  n_states  (`torc
-0000bac0: 682e 466c 6f61 7454 656e 736f 7260 206f  h.FloatTensor` o
-0000bad0: 6620 7368 6170 6520 6028 6261 7463 685f  f shape `(batch_
-0000bae0: 7369 7a65 2c0a 2020 2020 2020 2020 7365  size,.        se
-0000baf0: 7175 656e 6365 5f6c 656e 6774 682c 2068  quence_length, h
-0000bb00: 6964 6465 6e5f 7369 7a65 2960 2c20 2a6f  idden_size)`, *o
-0000bb10: 7074 696f 6e61 6c2a 293a 0a20 2020 2020  ptional*):.     
-0000bb20: 2020 2020 2020 2053 6571 7565 6e63 6520         Sequence 
-0000bb30: 6f66 2068 6964 6465 6e2d 7374 6174 6573  of hidden-states
-0000bb40: 2061 7420 7468 6520 6f75 7470 7574 206f   at the output o
-0000bb50: 6620 7468 6520 6c61 7374 206c 6179 6572  f the last layer
-0000bb60: 206f 6620 7468 650a 2020 2020 2020 2020   of the.        
-0000bb70: 2020 2020 656e 636f 6465 722e 2055 7365      encoder. Use
-0000bb80: 6420 696e 2074 6865 2063 726f 7373 2d61  d in the cross-a
-0000bb90: 7474 656e 7469 6f6e 2069 6620 7468 6520  ttention if the 
-0000bba0: 6d6f 6465 6c20 6973 2063 6f6e 6669 6775  model is configu
-0000bbb0: 7265 6420 6173 2061 0a20 2020 2020 2020  red as a.       
-0000bbc0: 2020 2020 2064 6563 6f64 6572 2e0a 2020       decoder..  
-0000bbd0: 2020 2020 2020 656e 636f 6465 725f 6174        encoder_at
-0000bbe0: 7465 6e74 696f 6e5f 6d61 736b 2028 6074  tention_mask (`t
-0000bbf0: 6f72 6368 2e46 6c6f 6174 5465 6e73 6f72  orch.FloatTensor
-0000bc00: 6020 6f66 2073 6861 7065 2060 2862 6174  ` of shape `(bat
-0000bc10: 6368 5f73 697a 652c 0a20 2020 2020 2020  ch_size,.       
-0000bc20: 2073 6571 7565 6e63 655f 6c65 6e67 7468   sequence_length
-0000bc30: 2960 2c20 2a6f 7074 696f 6e61 6c2a 293a  )`, *optional*):
-0000bc40: 0a20 2020 2020 2020 2020 2020 204d 6173  .            Mas
-0000bc50: 6b20 746f 2061 766f 6964 2070 6572 666f  k to avoid perfo
-0000bc60: 726d 696e 6720 6174 7465 6e74 696f 6e20  rming attention 
-0000bc70: 6f6e 2074 6865 2070 6164 6469 6e67 2074  on the padding t
-0000bc80: 6f6b 656e 2069 6e64 6963 6573 206f 660a  oken indices of.
-0000bc90: 2020 2020 2020 2020 2020 2020 7468 6520              the 
-0000bca0: 656e 636f 6465 7220 696e 7075 742e 2054  encoder input. T
-0000bcb0: 6869 7320 6d61 736b 2069 7320 7573 6564  his mask is used
-0000bcc0: 2069 6e20 7468 6520 6372 6f73 732d 6174   in the cross-at
-0000bcd0: 7465 6e74 696f 6e20 6966 2074 6865 0a20  tention if the. 
-0000bce0: 2020 2020 2020 2020 2020 206d 6f64 656c             model
-0000bcf0: 2069 7320 636f 6e66 6967 7572 6564 2061   is configured a
-0000bd00: 7320 6120 6465 636f 6465 722e 204d 6173  s a decoder. Mas
-0000bd10: 6b20 7661 6c75 6573 2073 656c 6563 7465  k values selecte
-0000bd20: 6420 696e 2060 5b30 2c20 315d 603a 0a0a  d in `[0, 1]`:..
-0000bd30: 2020 2020 2020 2020 2020 2020 2d20 3120              - 1 
-0000bd40: 666f 7220 746f 6b65 6e73 2074 6861 7420  for tokens that 
-0000bd50: 6172 6520 2a2a 6e6f 7420 6d61 736b 6564  are **not masked
-0000bd60: 2a2a 2c0a 2020 2020 2020 2020 2020 2020  **,.            
-0000bd70: 2d20 3020 666f 7220 746f 6b65 6e73 2074  - 0 for tokens t
-0000bd80: 6861 7420 6172 6520 2a2a 6d61 736b 6564  hat are **masked
-0000bd90: 2a2a 2e0a 2020 2020 2020 2020 7061 7374  **..        past
-0000bda0: 5f6b 6579 5f76 616c 7565 7320 2860 7475  _key_values (`tu
-0000bdb0: 706c 6528 7475 706c 6528 746f 7263 682e  ple(tuple(torch.
-0000bdc0: 466c 6f61 7454 656e 736f 7229 2960 206f  FloatTensor))` o
-0000bdd0: 6620 6c65 6e67 7468 0a20 2020 2020 2020  f length.       
-0000bde0: 2060 636f 6e66 6967 2e6e 5f6c 6179 6572   `config.n_layer
-0000bdf0: 7360 2077 6974 6820 6561 6368 2074 7570  s` with each tup
-0000be00: 6c65 2068 6176 696e 6720 3420 7465 6e73  le having 4 tens
-0000be10: 6f72 7320 6f66 2073 6861 7065 0a20 2020  ors of shape.   
-0000be20: 2020 2020 2060 2862 6174 6368 5f73 697a       `(batch_siz
-0000be30: 652c 206e 756d 5f68 6561 6473 2c20 7365  e, num_heads, se
-0000be40: 7175 656e 6365 5f6c 656e 6774 6820 2d20  quence_length - 
-0000be50: 312c 2065 6d62 6564 5f73 697a 655f 7065  1, embed_size_pe
-0000be60: 725f 6865 6164 2960 293a 0a20 2020 2020  r_head)`):.     
-0000be70: 2020 2020 2020 2043 6f6e 7461 696e 7320         Contains 
-0000be80: 7072 6563 6f6d 7075 7465 6420 6b65 7920  precomputed key 
-0000be90: 616e 6420 7661 6c75 6520 6869 6464 656e  and value hidden
-0000bea0: 2073 7461 7465 7320 6f66 2074 6865 2061   states of the a
-0000beb0: 7474 656e 7469 6f6e 0a20 2020 2020 2020  ttention.       
-0000bec0: 2020 2020 2062 6c6f 636b 732e 2043 616e       blocks. Can
-0000bed0: 2062 6520 7573 6564 2074 6f20 7370 6565   be used to spee
-0000bee0: 6420 7570 2064 6563 6f64 696e 672e 0a0a  d up decoding...
-0000bef0: 2020 2020 2020 2020 2020 2020 4966 2060              If `
-0000bf00: 7061 7374 5f6b 6579 5f76 616c 7565 7360  past_key_values`
-0000bf10: 2061 7265 2075 7365 642c 2074 6865 2075   are used, the u
-0000bf20: 7365 7220 6361 6e20 6f70 7469 6f6e 616c  ser can optional
-0000bf30: 6c79 2069 6e70 7574 206f 6e6c 790a 2020  ly input only.  
-0000bf40: 2020 2020 2020 2020 2020 7468 6520 6c61            the la
-0000bf50: 7374 2060 6465 636f 6465 725f 696e 7075  st `decoder_inpu
-0000bf60: 745f 6964 7360 2028 7468 6f73 6520 7468  t_ids` (those th
-0000bf70: 6174 2064 6f6e 2774 2068 6176 6520 7468  at don't have th
-0000bf80: 6569 7220 7061 7374 206b 6579 0a20 2020  eir past key.   
-0000bf90: 2020 2020 2020 2020 2076 616c 7565 2073           value s
-0000bfa0: 7461 7465 7320 6769 7665 6e20 746f 2074  tates given to t
-0000bfb0: 6869 7320 6d6f 6465 6c29 206f 6620 7368  his model) of sh
-0000bfc0: 6170 6520 6028 6261 7463 685f 7369 7a65  ape `(batch_size
-0000bfd0: 2c20 3129 6020 696e 7374 6561 640a 2020  , 1)` instead.  
-0000bfe0: 2020 2020 2020 2020 2020 6f66 2061 6c6c            of all
-0000bff0: 2060 6465 636f 6465 725f 696e 7075 745f   `decoder_input_
-0000c000: 6964 7360 206f 6620 7368 6170 6520 6028  ids` of shape `(
-0000c010: 6261 7463 685f 7369 7a65 2c20 7365 7175  batch_size, sequ
-0000c020: 656e 6365 5f6c 656e 6774 6829 602e 0a20  ence_length)`.. 
-0000c030: 2020 2020 2020 2075 7365 5f63 6163 6865         use_cache
-0000c040: 2028 6062 6f6f 6c60 2c20 2a6f 7074 696f   (`bool`, *optio
-0000c050: 6e61 6c2a 293a 0a20 2020 2020 2020 2020  nal*):.         
-0000c060: 2020 2049 6620 7365 7420 746f 2060 5472     If set to `Tr
-0000c070: 7565 602c 2060 7061 7374 5f6b 6579 5f76  ue`, `past_key_v
-0000c080: 616c 7565 7360 206b 6579 2076 616c 7565  alues` key value
-0000c090: 2073 7461 7465 7320 6172 6520 7265 7475   states are retu
-0000c0a0: 726e 6564 0a20 2020 2020 2020 2020 2020  rned.           
-0000c0b0: 2061 6e64 2063 616e 2062 6520 7573 6564   and can be used
-0000c0c0: 2074 6f20 7370 6565 6420 7570 2064 6563   to speed up dec
-0000c0d0: 6f64 696e 6720 2873 6565 2060 7061 7374  oding (see `past
-0000c0e0: 5f6b 6579 5f76 616c 7565 7360 292e 0a20  _key_values`).. 
-0000c0f0: 2020 2020 2020 204f 7468 6572 7320 282a         Others (*
-0000c100: 2a6b 7761 7267 7329 0a20 2020 2020 2020  *kwargs).       
-0000c110: 2020 2020 2073 6f6d 6520 6164 6469 7469       some additi
-0000c120: 6f6e 616c 2070 6172 616d 6574 6572 7320  onal parameters 
-0000c130: 6d69 6768 7420 7061 7373 6564 2069 6e20  might passed in 
-0000c140: 6672 6f6d 2075 7073 7472 6561 6d20 7069  from upstream pi
-0000c150: 7065 6c69 6e65 2c0a 2020 2020 2020 2020  peline,.        
-0000c160: 2020 2020 7768 6963 6820 6e6f 7420 696e      which not in
-0000c170: 666c 7565 6e63 6520 7468 6520 7265 7375  fluence the resu
-0000c180: 6c74 732e 0a20 2020 2020 2020 2022 2222  lts..        """
-0000c190: 0a0a 2020 2020 2020 2020 6f75 7470 7574  ..        output
-0000c1a0: 5f61 7474 656e 7469 6f6e 7320 3d20 6f75  _attentions = ou
-0000c1b0: 7470 7574 5f61 7474 656e 7469 6f6e 7320  tput_attentions 
-0000c1c0: 6966 206f 7574 7075 745f 6174 7465 6e74  if output_attent
-0000c1d0: 696f 6e73 2069 7320 6e6f 7420 4e6f 6e65  ions is not None
-0000c1e0: 2065 6c73 6520 7365 6c66 2e63 6f6e 6669   else self.confi
-0000c1f0: 672e 6f75 7470 7574 5f61 7474 656e 7469  g.output_attenti
-0000c200: 6f6e 730a 2020 2020 2020 2020 6f75 7470  ons.        outp
-0000c210: 7574 5f68 6964 6465 6e5f 7374 6174 6573  ut_hidden_states
-0000c220: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
-0000c230: 206f 7574 7075 745f 6869 6464 656e 5f73   output_hidden_s
-0000c240: 7461 7465 7320 6966 206f 7574 7075 745f  tates if output_
-0000c250: 6869 6464 656e 5f73 7461 7465 7320 6973  hidden_states is
-0000c260: 206e 6f74 204e 6f6e 6520 656c 7365 0a20   not None else. 
-0000c270: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0000c280: 636f 6e66 6967 2e6f 7574 7075 745f 6869  config.output_hi
-0000c290: 6464 656e 5f73 7461 7465 7329 0a20 2020  dden_states).   
-0000c2a0: 2020 2020 2072 6574 7572 6e5f 6469 6374       return_dict
-0000c2b0: 203d 2072 6574 7572 6e5f 6469 6374 2069   = return_dict i
-0000c2c0: 6620 7265 7475 726e 5f64 6963 7420 6973  f return_dict is
-0000c2d0: 206e 6f74 204e 6f6e 6520 656c 7365 2073   not None else s
-0000c2e0: 656c 662e 636f 6e66 6967 2e75 7365 5f72  elf.config.use_r
-0000c2f0: 6574 7572 6e5f 6469 6374 0a0a 2020 2020  eturn_dict..    
-0000c300: 2020 2020 6966 2069 735f 6465 636f 6465      if is_decode
-0000c310: 723a 0a20 2020 2020 2020 2020 2020 2075  r:.            u
-0000c320: 7365 5f63 6163 6865 203d 2075 7365 5f63  se_cache = use_c
-0000c330: 6163 6865 2069 6620 7573 655f 6361 6368  ache if use_cach
-0000c340: 6520 6973 206e 6f74 204e 6f6e 6520 656c  e is not None el
-0000c350: 7365 2073 656c 662e 636f 6e66 6967 2e75  se self.config.u
-0000c360: 7365 5f63 6163 6865 0a20 2020 2020 2020  se_cache.       
-0000c370: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-0000c380: 2020 2075 7365 5f63 6163 6865 203d 2046     use_cache = F
-0000c390: 616c 7365 0a0a 2020 2020 2020 2020 6966  alse..        if
-0000c3a0: 2069 6e70 7574 5f69 6473 2069 7320 6e6f   input_ids is no
-0000c3b0: 7420 4e6f 6e65 2061 6e64 2069 6e70 7574  t None and input
-0000c3c0: 735f 656d 6265 6473 2069 7320 6e6f 7420  s_embeds is not 
-0000c3d0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-0000c3e0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-0000c3f0: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
-0000c400: 2020 2020 2759 6f75 2063 616e 6e6f 7420      'You cannot 
-0000c410: 7370 6563 6966 7920 626f 7468 2069 6e70  specify both inp
-0000c420: 7574 5f69 6473 2061 6e64 2069 6e70 7574  ut_ids and input
-0000c430: 735f 656d 6265 6473 2061 7420 7468 6520  s_embeds at the 
-0000c440: 7361 6d65 2074 696d 6527 0a20 2020 2020  same time'.     
-0000c450: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-0000c460: 2065 6c69 6620 696e 7075 745f 6964 7320   elif input_ids 
-0000c470: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-0000c480: 2020 2020 2020 2020 2069 6e70 7574 5f73           input_s
-0000c490: 6861 7065 203d 2069 6e70 7574 5f69 6473  hape = input_ids
-0000c4a0: 2e73 697a 6528 290a 2020 2020 2020 2020  .size().        
-0000c4b0: 2020 2020 6261 7463 685f 7369 7a65 2c20      batch_size, 
-0000c4c0: 7365 715f 6c65 6e67 7468 203d 2069 6e70  seq_length = inp
-0000c4d0: 7574 5f73 6861 7065 0a20 2020 2020 2020  ut_shape.       
-0000c4e0: 2020 2020 2064 6576 6963 6520 3d20 696e       device = in
-0000c4f0: 7075 745f 6964 732e 6465 7669 6365 0a20  put_ids.device. 
-0000c500: 2020 2020 2020 2065 6c69 6620 696e 7075         elif inpu
-0000c510: 7473 5f65 6d62 6564 7320 6973 206e 6f74  ts_embeds is not
-0000c520: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-0000c530: 2020 2069 6e70 7574 5f73 6861 7065 203d     input_shape =
-0000c540: 2069 6e70 7574 735f 656d 6265 6473 2e73   inputs_embeds.s
-0000c550: 697a 6528 295b 3a2d 315d 0a20 2020 2020  ize()[:-1].     
-0000c560: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
-0000c570: 652c 2073 6571 5f6c 656e 6774 6820 3d20  e, seq_length = 
-0000c580: 696e 7075 745f 7368 6170 650a 2020 2020  input_shape.    
-0000c590: 2020 2020 2020 2020 6465 7669 6365 203d          device =
-0000c5a0: 2069 6e70 7574 735f 656d 6265 6473 2e64   inputs_embeds.d
-0000c5b0: 6576 6963 650a 2020 2020 2020 2020 656c  evice.        el
-0000c5c0: 6966 2065 6e63 6f64 6572 5f65 6d62 6564  if encoder_embed
-0000c5d0: 7320 6973 206e 6f74 204e 6f6e 653a 0a20  s is not None:. 
-0000c5e0: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-0000c5f0: 5f73 6861 7065 203d 2065 6e63 6f64 6572  _shape = encoder
-0000c600: 5f65 6d62 6564 732e 7369 7a65 2829 5b3a  _embeds.size()[:
-0000c610: 2d31 5d0a 2020 2020 2020 2020 2020 2020  -1].            
-0000c620: 6261 7463 685f 7369 7a65 2c20 7365 715f  batch_size, seq_
-0000c630: 6c65 6e67 7468 203d 2069 6e70 7574 5f73  length = input_s
-0000c640: 6861 7065 0a20 2020 2020 2020 2020 2020  hape.           
-0000c650: 2064 6576 6963 6520 3d20 656e 636f 6465   device = encode
-0000c660: 725f 656d 6265 6473 2e64 6576 6963 650a  r_embeds.device.
-0000c670: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0000c680: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-0000c690: 5661 6c75 6545 7272 6f72 280a 2020 2020  ValueError(.    
-0000c6a0: 2020 2020 2020 2020 2020 2020 2759 6f75              'You
-0000c6b0: 2068 6176 6520 746f 2073 7065 6369 6679   have to specify
-0000c6c0: 2065 6974 6865 7220 696e 7075 745f 6964   either input_id
-0000c6d0: 7320 6f72 2069 6e70 7574 735f 656d 6265  s or inputs_embe
-0000c6e0: 6473 206f 7220 656e 636f 6465 725f 656d  ds or encoder_em
-0000c6f0: 6265 6473 270a 2020 2020 2020 2020 2020  beds'.          
-0000c700: 2020 290a 0a20 2020 2020 2020 2023 2070    )..        # p
-0000c710: 6173 745f 6b65 795f 7661 6c75 6573 5f6c  ast_key_values_l
-0000c720: 656e 6774 680a 2020 2020 2020 2020 7061  ength.        pa
-0000c730: 7374 5f6b 6579 5f76 616c 7565 735f 6c65  st_key_values_le
-0000c740: 6e67 7468 203d 2070 6173 745f 6b65 795f  ngth = past_key_
-0000c750: 7661 6c75 6573 5b30 5d5b 305d 2e73 6861  values[0][0].sha
-0000c760: 7065 5b0a 2020 2020 2020 2020 2020 2020  pe[.            
-0000c770: 325d 2069 6620 7061 7374 5f6b 6579 5f76  2] if past_key_v
-0000c780: 616c 7565 7320 6973 206e 6f74 204e 6f6e  alues is not Non
-0000c790: 6520 656c 7365 2030 0a0a 2020 2020 2020  e else 0..      
-0000c7a0: 2020 6966 2061 7474 656e 7469 6f6e 5f6d    if attention_m
-0000c7b0: 6173 6b20 6973 204e 6f6e 653a 0a20 2020  ask is None:.   
-0000c7c0: 2020 2020 2020 2020 2061 7474 656e 7469           attenti
-0000c7d0: 6f6e 5f6d 6173 6b20 3d20 746f 7263 682e  on_mask = torch.
-0000c7e0: 6f6e 6573 280a 2020 2020 2020 2020 2020  ones(.          
-0000c7f0: 2020 2020 2020 2828 6261 7463 685f 7369        ((batch_si
-0000c800: 7a65 2c20 7365 715f 6c65 6e67 7468 202b  ze, seq_length +
-0000c810: 2070 6173 745f 6b65 795f 7661 6c75 6573   past_key_values
-0000c820: 5f6c 656e 6774 6829 292c 0a20 2020 2020  _length)),.     
-0000c830: 2020 2020 2020 2020 2020 2064 6576 6963             devic
-0000c840: 653d 6465 7669 6365 290a 2020 2020 2020  e=device).      
-0000c850: 2020 6966 2074 6f6b 656e 5f74 7970 655f    if token_type_
-0000c860: 6964 7320 6973 204e 6f6e 653a 0a20 2020  ids is None:.   
-0000c870: 2020 2020 2020 2020 2074 6f6b 656e 5f74           token_t
-0000c880: 7970 655f 6964 7320 3d20 746f 7263 682e  ype_ids = torch.
-0000c890: 7a65 726f 7328 0a20 2020 2020 2020 2020  zeros(.         
-0000c8a0: 2020 2020 2020 2069 6e70 7574 5f73 6861         input_sha
-0000c8b0: 7065 2c20 6474 7970 653d 746f 7263 682e  pe, dtype=torch.
-0000c8c0: 6c6f 6e67 2c20 6465 7669 6365 3d64 6576  long, device=dev
-0000c8d0: 6963 6529 0a0a 2020 2020 2020 2020 2320  ice)..        # 
-0000c8e0: 5765 2063 616e 2070 726f 7669 6465 2061  We can provide a
-0000c8f0: 2073 656c 662d 6174 7465 6e74 696f 6e20   self-attention 
-0000c900: 6d61 736b 206f 6620 6469 6d65 6e73 696f  mask of dimensio
-0000c910: 6e73 205b 6261 7463 685f 7369 7a65 2c0a  ns [batch_size,.
-0000c920: 2020 2020 2020 2020 2320 6672 6f6d 5f73          # from_s
-0000c930: 6571 5f6c 656e 6774 682c 2074 6f5f 7365  eq_length, to_se
-0000c940: 715f 6c65 6e67 7468 5d20 6f75 7273 656c  q_length] oursel
-0000c950: 7665 7320 696e 2077 6869 6368 2063 6173  ves in which cas
-0000c960: 6520 7765 206a 7573 7420 6e65 6564 0a20  e we just need. 
-0000c970: 2020 2020 2020 2023 2074 6f20 6d61 6b65         # to make
-0000c980: 2069 7420 6272 6f61 6463 6173 7461 626c   it broadcastabl
-0000c990: 6520 746f 2061 6c6c 2068 6561 6473 2e0a  e to all heads..
-0000c9a0: 2020 2020 2020 2020 6578 7465 6e64 6564          extended
-0000c9b0: 5f61 7474 656e 7469 6f6e 5f6d 6173 6b3a  _attention_mask:
-0000c9c0: 2074 6f72 6368 2e54 656e 736f 7220 3d20   torch.Tensor = 
-0000c9d0: 7365 6c66 2e67 6574 5f65 7874 656e 6465  self.get_extende
-0000c9e0: 645f 6174 7465 6e74 696f 6e5f 6d61 736b  d_attention_mask
-0000c9f0: 280a 2020 2020 2020 2020 2020 2020 6174  (.            at
-0000ca00: 7465 6e74 696f 6e5f 6d61 736b 2c20 696e  tention_mask, in
-0000ca10: 7075 745f 7368 6170 652c 2064 6576 6963  put_shape, devic
-0000ca20: 652c 2069 735f 6465 636f 6465 7229 0a0a  e, is_decoder)..
-0000ca30: 2020 2020 2020 2020 2320 4966 2061 2032          # If a 2
-0000ca40: 4420 6f72 2033 4420 6174 7465 6e74 696f  D or 3D attentio
-0000ca50: 6e20 6d61 736b 2069 7320 7072 6f76 6964  n mask is provid
-0000ca60: 6564 2066 6f72 2074 6865 2063 726f 7373  ed for the cross
-0000ca70: 2d61 7474 656e 7469 6f6e 2077 650a 2020  -attention we.  
-0000ca80: 2020 2020 2020 2320 6e65 6564 2074 6f20        # need to 
-0000ca90: 6d61 6b65 2062 726f 6164 6361 7374 6162  make broadcastab
-0000caa0: 6c65 2074 6f20 5b62 6174 6368 5f73 697a  le to [batch_siz
-0000cab0: 652c 206e 756d 5f68 6561 6473 2c20 7365  e, num_heads, se
-0000cac0: 715f 6c65 6e67 7468 2c0a 2020 2020 2020  q_length,.      
-0000cad0: 2020 2320 7365 715f 6c65 6e67 7468 5d0a    # seq_length].
-0000cae0: 2020 2020 2020 2020 6966 2065 6e63 6f64          if encod
-0000caf0: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
-0000cb00: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-0000cb10: 2020 2020 2020 2020 2020 6966 2074 7970            if typ
-0000cb20: 6528 656e 636f 6465 725f 6869 6464 656e  e(encoder_hidden
-0000cb30: 5f73 7461 7465 7329 203d 3d20 6c69 7374  _states) == list
-0000cb40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000cb50: 2020 656e 636f 6465 725f 6261 7463 685f    encoder_batch_
-0000cb60: 7369 7a65 2c20 656e 636f 6465 725f 7365  size, encoder_se
-0000cb70: 7175 656e 6365 5f6c 656e 6774 682c 205f  quence_length, _
-0000cb80: 203d 2065 6e63 6f64 6572 5f68 6964 6465   = encoder_hidde
-0000cb90: 6e5f 7374 6174 6573 5b0a 2020 2020 2020  n_states[.      
-0000cba0: 2020 2020 2020 2020 2020 2020 2020 305d                0]
-0000cbb0: 2e73 697a 6528 290a 2020 2020 2020 2020  .size().        
-0000cbc0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0000cbd0: 2020 2020 2020 2020 2020 656e 636f 6465            encode
-0000cbe0: 725f 6261 7463 685f 7369 7a65 2c20 656e  r_batch_size, en
-0000cbf0: 636f 6465 725f 7365 7175 656e 6365 5f6c  coder_sequence_l
-0000cc00: 656e 6774 682c 205f 203d 2065 6e63 6f64  ength, _ = encod
-0000cc10: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
-0000cc20: 2e73 697a 6528 0a20 2020 2020 2020 2020  .size(.         
-0000cc30: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-0000cc40: 2020 2020 2065 6e63 6f64 6572 5f68 6964       encoder_hid
-0000cc50: 6465 6e5f 7368 6170 6520 3d20 2865 6e63  den_shape = (enc
-0000cc60: 6f64 6572 5f62 6174 6368 5f73 697a 652c  oder_batch_size,
-0000cc70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000cc80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cc90: 2020 2020 2065 6e63 6f64 6572 5f73 6571       encoder_seq
-0000cca0: 7565 6e63 655f 6c65 6e67 7468 290a 0a20  uence_length).. 
-0000ccb0: 2020 2020 2020 2020 2020 2069 6620 7479             if ty
-0000ccc0: 7065 2865 6e63 6f64 6572 5f61 7474 656e  pe(encoder_atten
-0000ccd0: 7469 6f6e 5f6d 6173 6b29 203d 3d20 6c69  tion_mask) == li
-0000cce0: 7374 3a0a 2020 2020 2020 2020 2020 2020  st:.            
-0000ccf0: 2020 2020 656e 636f 6465 725f 6578 7465      encoder_exte
-0000cd00: 6e64 6564 5f61 7474 656e 7469 6f6e 5f6d  nded_attention_m
-0000cd10: 6173 6b20 3d20 5b0a 2020 2020 2020 2020  ask = [.        
-0000cd20: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0000cd30: 2e69 6e76 6572 745f 6174 7465 6e74 696f  .invert_attentio
-0000cd40: 6e5f 6d61 736b 286d 6173 6b29 0a20 2020  n_mask(mask).   
-0000cd50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cd60: 2066 6f72 206d 6173 6b20 696e 2065 6e63   for mask in enc
-0000cd70: 6f64 6572 5f61 7474 656e 7469 6f6e 5f6d  oder_attention_m
-0000cd80: 6173 6b0a 2020 2020 2020 2020 2020 2020  ask.            
-0000cd90: 2020 2020 5d0a 2020 2020 2020 2020 2020      ].          
-0000cda0: 2020 656c 6966 2065 6e63 6f64 6572 5f61    elif encoder_a
-0000cdb0: 7474 656e 7469 6f6e 5f6d 6173 6b20 6973  ttention_mask is
-0000cdc0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-0000cdd0: 2020 2020 2020 2065 6e63 6f64 6572 5f61         encoder_a
-0000cde0: 7474 656e 7469 6f6e 5f6d 6173 6b20 3d20  ttention_mask = 
-0000cdf0: 746f 7263 682e 6f6e 6573 280a 2020 2020  torch.ones(.    
-0000ce00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ce10: 656e 636f 6465 725f 6869 6464 656e 5f73  encoder_hidden_s
-0000ce20: 6861 7065 2c20 6465 7669 6365 3d64 6576  hape, device=dev
-0000ce30: 6963 6529 0a20 2020 2020 2020 2020 2020  ice).           
-0000ce40: 2020 2020 2065 6e63 6f64 6572 5f65 7874       encoder_ext
-0000ce50: 656e 6465 645f 6174 7465 6e74 696f 6e5f  ended_attention_
-0000ce60: 6d61 736b 203d 2073 656c 662e 696e 7665  mask = self.inve
-0000ce70: 7274 5f61 7474 656e 7469 6f6e 5f6d 6173  rt_attention_mas
-0000ce80: 6b28 0a20 2020 2020 2020 2020 2020 2020  k(.             
-0000ce90: 2020 2020 2020 2065 6e63 6f64 6572 5f61         encoder_a
-0000cea0: 7474 656e 7469 6f6e 5f6d 6173 6b29 0a20  ttention_mask). 
-0000ceb0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0000cec0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ced0: 2065 6e63 6f64 6572 5f65 7874 656e 6465   encoder_extende
-0000cee0: 645f 6174 7465 6e74 696f 6e5f 6d61 736b  d_attention_mask
-0000cef0: 203d 2073 656c 662e 696e 7665 7274 5f61   = self.invert_a
-0000cf00: 7474 656e 7469 6f6e 5f6d 6173 6b28 0a20  ttention_mask(. 
-0000cf10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cf20: 2020 2065 6e63 6f64 6572 5f61 7474 656e     encoder_atten
-0000cf30: 7469 6f6e 5f6d 6173 6b29 0a20 2020 2020  tion_mask).     
-0000cf40: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0000cf50: 2020 2020 2065 6e63 6f64 6572 5f65 7874       encoder_ext
-0000cf60: 656e 6465 645f 6174 7465 6e74 696f 6e5f  ended_attention_
-0000cf70: 6d61 736b 203d 204e 6f6e 650a 0a20 2020  mask = None..   
-0000cf80: 2020 2020 2023 2050 7265 7061 7265 2068       # Prepare h
-0000cf90: 6561 6420 6d61 736b 2069 6620 6e65 6564  ead mask if need
-0000cfa0: 6564 0a20 2020 2020 2020 2023 2031 2e30  ed.        # 1.0
-0000cfb0: 2069 6e20 6865 6164 5f6d 6173 6b20 696e   in head_mask in
-0000cfc0: 6469 6361 7465 2077 6520 6b65 6570 2074  dicate we keep t
-0000cfd0: 6865 2068 6561 640a 2020 2020 2020 2020  he head.        
-0000cfe0: 2320 6174 7465 6e74 696f 6e5f 7072 6f62  # attention_prob
-0000cff0: 7320 6861 7320 7368 6170 6520 6273 7a20  s has shape bsz 
-0000d000: 7820 6e5f 6865 6164 7320 7820 4e20 7820  x n_heads x N x 
-0000d010: 4e0a 2020 2020 2020 2020 2320 696e 7075  N.        # inpu
-0000d020: 7420 6865 6164 5f6d 6173 6b20 6861 7320  t head_mask has 
-0000d030: 7368 6170 6520 5b6e 756d 5f68 6561 6473  shape [num_heads
-0000d040: 5d20 6f72 205b 6e75 6d5f 6869 6464 656e  ] or [num_hidden
-0000d050: 5f6c 6179 6572 7320 7820 6e75 6d5f 6865  _layers x num_he
-0000d060: 6164 735d 0a20 2020 2020 2020 2023 2061  ads].        # a
-0000d070: 6e64 2068 6561 645f 6d61 736b 2069 7320  nd head_mask is 
-0000d080: 636f 6e76 6572 7465 6420 746f 2073 6861  converted to sha
-0000d090: 7065 205b 6e75 6d5f 6869 6464 656e 5f6c  pe [num_hidden_l
-0000d0a0: 6179 6572 7320 7820 6261 7463 6820 7820  ayers x batch x 
-0000d0b0: 6e75 6d5f 6865 6164 7320 7820 7365 715f  num_heads x seq_
-0000d0c0: 6c65 6e67 7468 2078 2073 6571 5f6c 656e  length x seq_len
-0000d0d0: 6774 685d 0a20 2020 2020 2020 2068 6561  gth].        hea
-0000d0e0: 645f 6d61 736b 203d 2073 656c 662e 6765  d_mask = self.ge
-0000d0f0: 745f 6865 6164 5f6d 6173 6b28 6865 6164  t_head_mask(head
-0000d100: 5f6d 6173 6b2c 0a20 2020 2020 2020 2020  _mask,.         
-0000d110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d120: 2020 2020 2020 2020 2020 2020 2020 7365                se
-0000d130: 6c66 2e63 6f6e 6669 672e 6e75 6d5f 6869  lf.config.num_hi
-0000d140: 6464 656e 5f6c 6179 6572 7329 0a0a 2020  dden_layers)..  
-0000d150: 2020 2020 2020 6966 2065 6e63 6f64 6572        if encoder
-0000d160: 5f65 6d62 6564 7320 6973 204e 6f6e 653a  _embeds is None:
-0000d170: 0a20 2020 2020 2020 2020 2020 2065 6d62  .            emb
-0000d180: 6564 6469 6e67 5f6f 7574 7075 7420 3d20  edding_output = 
-0000d190: 7365 6c66 2e65 6d62 6564 6469 6e67 7328  self.embeddings(
-0000d1a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d1b0: 2069 6e70 7574 5f69 6473 3d69 6e70 7574   input_ids=input
-0000d1c0: 5f69 6473 2c0a 2020 2020 2020 2020 2020  _ids,.          
-0000d1d0: 2020 2020 2020 706f 7369 7469 6f6e 5f69        position_i
-0000d1e0: 6473 3d70 6f73 6974 696f 6e5f 6964 732c  ds=position_ids,
-0000d1f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d200: 2074 6f6b 656e 5f74 7970 655f 6964 733d   token_type_ids=
-0000d210: 746f 6b65 6e5f 7479 7065 5f69 6473 2c0a  token_type_ids,.
-0000d220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d230: 696e 7075 7473 5f65 6d62 6564 733d 696e  inputs_embeds=in
-0000d240: 7075 7473 5f65 6d62 6564 732c 0a20 2020  puts_embeds,.   
-0000d250: 2020 2020 2020 2020 2020 2020 2070 6173               pas
-0000d260: 745f 6b65 795f 7661 6c75 6573 5f6c 656e  t_key_values_len
-0000d270: 6774 683d 7061 7374 5f6b 6579 5f76 616c  gth=past_key_val
-0000d280: 7565 735f 6c65 6e67 7468 2c0a 2020 2020  ues_length,.    
-0000d290: 2020 2020 2020 2020 2020 2020 7265 6c5f              rel_
-0000d2a0: 7479 7065 5f69 6473 3d72 656c 5f74 7970  type_ids=rel_typ
-0000d2b0: 655f 6964 732c 0a20 2020 2020 2020 2020  e_ids,.         
-0000d2c0: 2020 2020 2020 2061 6273 6f6c 7574 655f         absolute_
-0000d2d0: 706f 7369 7469 6f6e 5f69 6473 3d61 6273  position_ids=abs
-0000d2e0: 6f6c 7574 655f 706f 7369 7469 6f6e 5f69  olute_position_i
-0000d2f0: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
-0000d300: 2020 2020 7265 6c61 7469 7665 5f70 6f73      relative_pos
-0000d310: 6974 696f 6e5f 6964 733d 7265 6c61 7469  ition_ids=relati
-0000d320: 7665 5f70 6f73 6974 696f 6e5f 6964 732c  ve_position_ids,
-0000d330: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d340: 2070 726f 765f 6964 733d 7072 6f76 5f69   prov_ids=prov_i
-0000d350: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
-0000d360: 2020 2020 6369 7479 5f69 6473 3d63 6974      city_ids=cit
-0000d370: 795f 6964 732c 0a20 2020 2020 2020 2020  y_ids,.         
-0000d380: 2020 2020 2020 2064 6973 745f 6964 733d         dist_ids=
-0000d390: 6469 7374 5f69 6473 2c0a 2020 2020 2020  dist_ids,.      
-0000d3a0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
-0000d3b0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0000d3c0: 2020 656d 6265 6464 696e 675f 6f75 7470    embedding_outp
-0000d3d0: 7574 203d 2065 6e63 6f64 6572 5f65 6d62  ut = encoder_emb
-0000d3e0: 6564 730a 0a20 2020 2020 2020 2065 6e63  eds..        enc
-0000d3f0: 6f64 6572 5f6f 7574 7075 7473 203d 2073  oder_outputs = s
-0000d400: 656c 662e 656e 636f 6465 7228 0a20 2020  elf.encoder(.   
-0000d410: 2020 2020 2020 2020 2065 6d62 6564 6469           embeddi
-0000d420: 6e67 5f6f 7574 7075 742c 0a20 2020 2020  ng_output,.     
-0000d430: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
-0000d440: 5f6d 6173 6b3d 6578 7465 6e64 6564 5f61  _mask=extended_a
-0000d450: 7474 656e 7469 6f6e 5f6d 6173 6b2c 0a20  ttention_mask,. 
-0000d460: 2020 2020 2020 2020 2020 2068 6561 645f             head_
-0000d470: 6d61 736b 3d68 6561 645f 6d61 736b 2c0a  mask=head_mask,.
-0000d480: 2020 2020 2020 2020 2020 2020 656e 636f              enco
-0000d490: 6465 725f 6869 6464 656e 5f73 7461 7465  der_hidden_state
-0000d4a0: 733d 656e 636f 6465 725f 6869 6464 656e  s=encoder_hidden
-0000d4b0: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
-0000d4c0: 2020 2020 2065 6e63 6f64 6572 5f61 7474       encoder_att
-0000d4d0: 656e 7469 6f6e 5f6d 6173 6b3d 656e 636f  ention_mask=enco
-0000d4e0: 6465 725f 6578 7465 6e64 6564 5f61 7474  der_extended_att
-0000d4f0: 656e 7469 6f6e 5f6d 6173 6b2c 0a20 2020  ention_mask,.   
-0000d500: 2020 2020 2020 2020 2070 6173 745f 6b65           past_ke
-0000d510: 795f 7661 6c75 6573 3d70 6173 745f 6b65  y_values=past_ke
-0000d520: 795f 7661 6c75 6573 2c0a 2020 2020 2020  y_values,.      
-0000d530: 2020 2020 2020 7573 655f 6361 6368 653d        use_cache=
-0000d540: 7573 655f 6361 6368 652c 0a20 2020 2020  use_cache,.     
-0000d550: 2020 2020 2020 206f 7574 7075 745f 6174         output_at
-0000d560: 7465 6e74 696f 6e73 3d6f 7574 7075 745f  tentions=output_
-0000d570: 6174 7465 6e74 696f 6e73 2c0a 2020 2020  attentions,.    
-0000d580: 2020 2020 2020 2020 6f75 7470 7574 5f68          output_h
-0000d590: 6964 6465 6e5f 7374 6174 6573 3d6f 7574  idden_states=out
-0000d5a0: 7075 745f 6869 6464 656e 5f73 7461 7465  put_hidden_state
-0000d5b0: 732c 0a20 2020 2020 2020 2020 2020 2072  s,.            r
-0000d5c0: 6574 7572 6e5f 6469 6374 3d72 6574 7572  eturn_dict=retur
-0000d5d0: 6e5f 6469 6374 2c0a 2020 2020 2020 2020  n_dict,.        
-0000d5e0: 2020 2020 6d6f 6465 3d6d 6f64 652c 0a20      mode=mode,. 
-0000d5f0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-0000d600: 2073 6571 7565 6e63 655f 6f75 7470 7574   sequence_output
-0000d610: 203d 2065 6e63 6f64 6572 5f6f 7574 7075   = encoder_outpu
-0000d620: 7473 5b30 5d0a 2020 2020 2020 2020 706f  ts[0].        po
-0000d630: 6f6c 6564 5f6f 7574 7075 7420 3d20 7365  oled_output = se
-0000d640: 6c66 2e70 6f6f 6c65 7228 0a20 2020 2020  lf.pooler(.     
-0000d650: 2020 2020 2020 2073 6571 7565 6e63 655f         sequence_
-0000d660: 6f75 7470 7574 2920 6966 2073 656c 662e  output) if self.
-0000d670: 706f 6f6c 6572 2069 7320 6e6f 7420 4e6f  pooler is not No
-0000d680: 6e65 2065 6c73 6520 4e6f 6e65 0a0a 2020  ne else None..  
-0000d690: 2020 2020 2020 6966 206e 6f74 2072 6574        if not ret
-0000d6a0: 7572 6e5f 6469 6374 3a0a 2020 2020 2020  urn_dict:.      
-0000d6b0: 2020 2020 2020 7265 7475 726e 2028 7365        return (se
-0000d6c0: 7175 656e 6365 5f6f 7574 7075 742c 2070  quence_output, p
-0000d6d0: 6f6f 6c65 645f 6f75 7470 7574 2920 2b20  ooled_output) + 
-0000d6e0: 656e 636f 6465 725f 6f75 7470 7574 735b  encoder_outputs[
-0000d6f0: 313a 5d0a 0a20 2020 2020 2020 2072 6574  1:]..        ret
-0000d700: 7572 6e20 4261 7365 4d6f 6465 6c4f 7574  urn BaseModelOut
-0000d710: 7075 7457 6974 6850 6f6f 6c69 6e67 416e  putWithPoolingAn
-0000d720: 6443 726f 7373 4174 7465 6e74 696f 6e73  dCrossAttentions
-0000d730: 280a 2020 2020 2020 2020 2020 2020 6c61  (.            la
-0000d740: 7374 5f68 6964 6465 6e5f 7374 6174 653d  st_hidden_state=
-0000d750: 7365 7175 656e 6365 5f6f 7574 7075 742c  sequence_output,
-0000d760: 0a20 2020 2020 2020 2020 2020 2070 6f6f  .            poo
-0000d770: 6c65 725f 6f75 7470 7574 3d70 6f6f 6c65  ler_output=poole
-0000d780: 645f 6f75 7470 7574 2c0a 2020 2020 2020  d_output,.      
-0000d790: 2020 2020 2020 7061 7374 5f6b 6579 5f76        past_key_v
-0000d7a0: 616c 7565 733d 656e 636f 6465 725f 6f75  alues=encoder_ou
-0000d7b0: 7470 7574 732e 7061 7374 5f6b 6579 5f76  tputs.past_key_v
-0000d7c0: 616c 7565 732c 0a20 2020 2020 2020 2020  alues,.         
-0000d7d0: 2020 2068 6964 6465 6e5f 7374 6174 6573     hidden_states
-0000d7e0: 3d65 6e63 6f64 6572 5f6f 7574 7075 7473  =encoder_outputs
-0000d7f0: 2e68 6964 6465 6e5f 7374 6174 6573 2c0a  .hidden_states,.
-0000d800: 2020 2020 2020 2020 2020 2020 6174 7465              atte
-0000d810: 6e74 696f 6e73 3d65 6e63 6f64 6572 5f6f  ntions=encoder_o
-0000d820: 7574 7075 7473 2e61 7474 656e 7469 6f6e  utputs.attention
-0000d830: 732c 0a20 2020 2020 2020 2020 2020 2063  s,.            c
-0000d840: 726f 7373 5f61 7474 656e 7469 6f6e 733d  ross_attentions=
-0000d850: 656e 636f 6465 725f 6f75 7470 7574 732e  encoder_outputs.
-0000d860: 6372 6f73 735f 6174 7465 6e74 696f 6e73  cross_attentions
-0000d870: 2c0a 2020 2020 2020 2020 290a 0a0a 636c  ,.        )...cl
-0000d880: 6173 7320 4265 7274 466f 7250 7265 5472  ass BertForPreTr
-0000d890: 6169 6e69 6e67 2842 6572 7450 7265 5472  aining(BertPreTr
-0000d8a0: 6169 6e65 644d 6f64 656c 293a 0a0a 2020  ainedModel):..  
-0000d8b0: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-0000d8c0: 656c 662c 2063 6f6e 6669 6729 3a0a 2020  elf, config):.  
-0000d8d0: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
-0000d8e0: 696e 6974 5f5f 2863 6f6e 6669 6729 0a0a  init__(config)..
-0000d8f0: 2020 2020 2020 2020 7365 6c66 2e62 6572          self.ber
-0000d900: 7420 3d20 4265 7274 4d6f 6465 6c28 636f  t = BertModel(co
-0000d910: 6e66 6967 290a 2020 2020 2020 2020 7365  nfig).        se
-0000d920: 6c66 2e63 6c73 203d 2042 6572 7450 7265  lf.cls = BertPre
-0000d930: 5472 6169 6e69 6e67 4865 6164 7328 636f  TrainingHeads(co
-0000d940: 6e66 6967 290a 0a20 2020 2020 2020 2073  nfig)..        s
-0000d950: 656c 662e 696e 6974 5f77 6569 6768 7473  elf.init_weights
-0000d960: 2829 0a0a 2020 2020 6465 6620 6765 745f  ()..    def get_
-0000d970: 6f75 7470 7574 5f65 6d62 6564 6469 6e67  output_embedding
-0000d980: 7328 7365 6c66 293a 0a20 2020 2020 2020  s(self):.       
-0000d990: 2072 6574 7572 6e20 7365 6c66 2e63 6c73   return self.cls
-0000d9a0: 2e70 7265 6469 6374 696f 6e73 2e64 6563  .predictions.dec
-0000d9b0: 6f64 6572 0a0a 2020 2020 6465 6620 7365  oder..    def se
-0000d9c0: 745f 6f75 7470 7574 5f65 6d62 6564 6469  t_output_embeddi
-0000d9d0: 6e67 7328 7365 6c66 2c20 6e65 775f 656d  ngs(self, new_em
-0000d9e0: 6265 6464 696e 6773 293a 0a20 2020 2020  beddings):.     
-0000d9f0: 2020 2073 656c 662e 636c 732e 7072 6564     self.cls.pred
-0000da00: 6963 7469 6f6e 732e 6465 636f 6465 7220  ictions.decoder 
-0000da10: 3d20 6e65 775f 656d 6265 6464 696e 6773  = new_embeddings
-0000da20: 0a0a 2020 2020 6465 6620 666f 7277 6172  ..    def forwar
-0000da30: 6428 0a20 2020 2020 2020 2073 656c 662c  d(.        self,
-0000da40: 0a20 2020 2020 2020 2069 6e70 7574 5f69  .        input_i
-0000da50: 6473 3d4e 6f6e 652c 0a20 2020 2020 2020  ds=None,.       
-0000da60: 2061 7474 656e 7469 6f6e 5f6d 6173 6b3d   attention_mask=
-0000da70: 4e6f 6e65 2c0a 2020 2020 2020 2020 746f  None,.        to
-0000da80: 6b65 6e5f 7479 7065 5f69 6473 3d4e 6f6e  ken_type_ids=Non
-0000da90: 652c 0a20 2020 2020 2020 2070 6f73 6974  e,.        posit
-0000daa0: 696f 6e5f 6964 733d 4e6f 6e65 2c0a 2020  ion_ids=None,.  
-0000dab0: 2020 2020 2020 6865 6164 5f6d 6173 6b3d        head_mask=
-0000dac0: 4e6f 6e65 2c0a 2020 2020 2020 2020 696e  None,.        in
-0000dad0: 7075 7473 5f65 6d62 6564 733d 4e6f 6e65  puts_embeds=None
-0000dae0: 2c0a 2020 2020 2020 2020 6c61 6265 6c73  ,.        labels
-0000daf0: 3d4e 6f6e 652c 0a20 2020 2020 2020 206e  =None,.        n
-0000db00: 6578 745f 7365 6e74 656e 6365 5f6c 6162  ext_sentence_lab
-0000db10: 656c 3d4e 6f6e 652c 0a20 2020 2020 2020  el=None,.       
-0000db20: 206f 7574 7075 745f 6174 7465 6e74 696f   output_attentio
-0000db30: 6e73 3d4e 6f6e 652c 0a20 2020 2020 2020  ns=None,.       
-0000db40: 206f 7574 7075 745f 6869 6464 656e 5f73   output_hidden_s
-0000db50: 7461 7465 733d 4e6f 6e65 2c0a 2020 2020  tates=None,.    
-0000db60: 2020 2020 7265 7475 726e 5f64 6963 743d      return_dict=
-0000db70: 4e6f 6e65 2c0a 2020 2020 293a 0a20 2020  None,.    ):.   
-0000db80: 2020 2020 2072 2222 220a 2020 2020 2020       r""".      
-0000db90: 2020 6c61 6265 6c73 2028 3a6f 626a 3a60    labels (:obj:`
-0000dba0: 746f 7263 682e 4c6f 6e67 5465 6e73 6f72  torch.LongTensor
-0000dbb0: 6020 6f66 2073 6861 7065 2060 6028 6261  ` of shape ``(ba
-0000dbc0: 7463 685f 7369 7a65 2c20 7365 7175 656e  tch_size, sequen
-0000dbd0: 6365 5f6c 656e 6774 6829 6060 2c20 606f  ce_length)``, `o
-0000dbe0: 7074 696f 6e61 6c60 293a 0a20 2020 2020  ptional`):.     
-0000dbf0: 2020 2020 2020 204c 6162 656c 7320 666f         Labels fo
-0000dc00: 7220 636f 6d70 7574 696e 6720 7468 6520  r computing the 
-0000dc10: 6d61 736b 6564 206c 616e 6775 6167 6520  masked language 
-0000dc20: 6d6f 6465 6c69 6e67 206c 6f73 732e 2049  modeling loss. I
-0000dc30: 6e64 6963 6573 2073 686f 756c 6420 6265  ndices should be
-0000dc40: 2069 6e20 6060 5b2d 3130 302c 2030 2c20   in ``[-100, 0, 
-0000dc50: 2e2e 2e2c 0a20 2020 2020 2020 2020 2020  ...,.           
-0000dc60: 2063 6f6e 6669 672e 766f 6361 625f 7369   config.vocab_si
-0000dc70: 7a65 5d60 6020 2873 6565 2060 6069 6e70  ze]`` (see ``inp
-0000dc80: 7574 5f69 6473 6060 2064 6f63 7374 7269  ut_ids`` docstri
-0000dc90: 6e67 2920 546f 6b65 6e73 2077 6974 6820  ng) Tokens with 
-0000dca0: 696e 6469 6365 7320 7365 7420 746f 2060  indices set to `
-0000dcb0: 602d 3130 3060 6020 6172 6520 6967 6e6f  `-100`` are igno
-0000dcc0: 7265 640a 2020 2020 2020 2020 2020 2020  red.            
-0000dcd0: 286d 6173 6b65 6429 2c20 7468 6520 6c6f  (masked), the lo
-0000dce0: 7373 2069 7320 6f6e 6c79 2063 6f6d 7075  ss is only compu
-0000dcf0: 7465 6420 666f 7220 7468 6520 746f 6b65  ted for the toke
-0000dd00: 6e73 2077 6974 6820 6c61 6265 6c73 2069  ns with labels i
-0000dd10: 6e20 6060 5b30 2c20 2e2e 2e2c 2063 6f6e  n ``[0, ..., con
-0000dd20: 6669 672e 766f 6361 625f 7369 7a65 5d60  fig.vocab_size]`
-0000dd30: 600a 2020 2020 2020 2020 6e65 7874 5f73  `.        next_s
-0000dd40: 656e 7465 6e63 655f 6c61 6265 6c20 2860  entence_label (`
-0000dd50: 6074 6f72 6368 2e4c 6f6e 6754 656e 736f  `torch.LongTenso
-0000dd60: 7260 6020 6f66 2073 6861 7065 2060 6028  r`` of shape ``(
-0000dd70: 6261 7463 685f 7369 7a65 2c29 6060 2c20  batch_size,)``, 
-0000dd80: 606f 7074 696f 6e61 6c60 293a 0a20 2020  `optional`):.   
-0000dd90: 2020 2020 2020 2020 204c 6162 656c 7320           Labels 
-0000dda0: 666f 7220 636f 6d70 7574 696e 6720 7468  for computing th
-0000ddb0: 6520 6e65 7874 2073 6571 7565 6e63 6520  e next sequence 
-0000ddc0: 7072 6564 6963 7469 6f6e 2028 636c 6173  prediction (clas
-0000ddd0: 7369 6669 6361 7469 6f6e 2920 6c6f 7373  sification) loss
-0000dde0: 2e20 496e 7075 7420 7368 6f75 6c64 2062  . Input should b
-0000ddf0: 6520 6120 7365 7175 656e 6365 2070 6169  e a sequence pai
-0000de00: 720a 2020 2020 2020 2020 2020 2020 2873  r.            (s
-0000de10: 6565 203a 6f62 6a3a 6069 6e70 7574 5f69  ee :obj:`input_i
-0000de20: 6473 6020 646f 6373 7472 696e 6729 2049  ds` docstring) I
-0000de30: 6e64 6963 6573 2073 686f 756c 6420 6265  ndices should be
-0000de40: 2069 6e20 6060 5b30 2c20 315d 6060 3a0a   in ``[0, 1]``:.
-0000de50: 2020 2020 2020 2020 2020 2020 2d20 3020              - 0 
-0000de60: 696e 6469 6361 7465 7320 7365 7175 656e  indicates sequen
-0000de70: 6365 2042 2069 7320 6120 636f 6e74 696e  ce B is a contin
-0000de80: 7561 7469 6f6e 206f 6620 7365 7175 656e  uation of sequen
-0000de90: 6365 2041 2c0a 2020 2020 2020 2020 2020  ce A,.          
-0000dea0: 2020 2d20 3120 696e 6469 6361 7465 7320    - 1 indicates 
-0000deb0: 7365 7175 656e 6365 2042 2069 7320 6120  sequence B is a 
-0000dec0: 7261 6e64 6f6d 2073 6571 7565 6e63 652e  random sequence.
-0000ded0: 0a20 2020 2020 2020 206b 7761 7267 7320  .        kwargs 
-0000dee0: 283a 6f62 6a3a 6044 6963 745b 7374 722c  (:obj:`Dict[str,
-0000def0: 2061 6e79 5d60 2c20 6f70 7469 6f6e 616c   any]`, optional
-0000df00: 2c20 6465 6661 756c 7473 2074 6f20 607b  , defaults to `{
-0000df10: 7d60 293a 0a20 2020 2020 2020 2020 2020  }`):.           
-0000df20: 2055 7365 6420 746f 2068 6964 6520 6c65   Used to hide le
-0000df30: 6761 6379 2061 7267 756d 656e 7473 2074  gacy arguments t
-0000df40: 6861 7420 6861 7665 2062 6565 6e20 6465  hat have been de
-0000df50: 7072 6563 6174 6564 2e0a 2020 2020 2020  precated..      
-0000df60: 2020 5265 7475 726e 733a 0a20 2020 2020    Returns:.     
-0000df70: 2020 2045 7861 6d70 6c65 3a0a 2020 2020     Example:.    
-0000df80: 2020 2020 2020 2020 3e3e 3e20 6672 6f6d          >>> from
-0000df90: 2074 7261 6e73 666f 726d 6572 7320 696d   transformers im
-0000dfa0: 706f 7274 2042 6572 7454 6f6b 656e 697a  port BertTokeniz
-0000dfb0: 6572 2c20 4265 7274 466f 7250 7265 5472  er, BertForPreTr
-0000dfc0: 6169 6e69 6e67 0a20 2020 2020 2020 2020  aining.         
-0000dfd0: 2020 203e 3e3e 2069 6d70 6f72 7420 746f     >>> import to
-0000dfe0: 7263 680a 2020 2020 2020 2020 2020 2020  rch.            
-0000dff0: 3e3e 3e20 746f 6b65 6e69 7a65 7220 3d20  >>> tokenizer = 
-0000e000: 4265 7274 546f 6b65 6e69 7a65 722e 6672  BertTokenizer.fr
-0000e010: 6f6d 5f70 7265 7472 6169 6e65 6428 2762  om_pretrained('b
-0000e020: 6572 742d 6261 7365 2d75 6e63 6173 6564  ert-base-uncased
-0000e030: 2729 0a20 2020 2020 2020 2020 2020 203e  ').            >
-0000e040: 3e3e 206d 6f64 656c 203d 2042 6572 7446  >> model = BertF
-0000e050: 6f72 5072 6554 7261 696e 696e 672e 6672  orPreTraining.fr
-0000e060: 6f6d 5f70 7265 7472 6169 6e65 6428 2762  om_pretrained('b
-0000e070: 6572 742d 6261 7365 2d75 6e63 6173 6564  ert-base-uncased
-0000e080: 2729 0a20 2020 2020 2020 2020 2020 203e  ').            >
-0000e090: 3e3e 2069 6e70 7574 7320 3d20 746f 6b65  >> inputs = toke
-0000e0a0: 6e69 7a65 7228 2248 656c 6c6f 2c20 6d79  nizer("Hello, my
-0000e0b0: 2064 6f67 2069 7320 6375 7465 222c 2072   dog is cute", r
-0000e0c0: 6574 7572 6e5f 7465 6e73 6f72 733d 2270  eturn_tensors="p
-0000e0d0: 7422 290a 2020 2020 2020 2020 2020 2020  t").            
-0000e0e0: 3e3e 3e20 6f75 7470 7574 7320 3d20 6d6f  >>> outputs = mo
-0000e0f0: 6465 6c28 2a2a 696e 7075 7473 290a 2020  del(**inputs).  
-0000e100: 2020 2020 2020 2020 2020 3e3e 3e20 7072            >>> pr
-0000e110: 6564 6963 7469 6f6e 5f6c 6f67 6974 7320  ediction_logits 
-0000e120: 3d20 6f75 7470 7574 732e 7072 6564 6963  = outputs.predic
-0000e130: 7469 6f6e 5f6c 6f67 6974 730a 2020 2020  tion_logits.    
-0000e140: 2020 2020 2020 2020 3e3e 3e20 7365 715f          >>> seq_
-0000e150: 7265 6c61 7469 6f6e 7368 6970 5f6c 6f67  relationship_log
-0000e160: 6974 7320 3d20 6f75 7470 7574 732e 7365  its = outputs.se
-0000e170: 715f 7265 6c61 7469 6f6e 7368 6970 5f6c  q_relationship_l
-0000e180: 6f67 6974 730a 2020 2020 2020 2020 2222  ogits.        ""
-0000e190: 220a 2020 2020 2020 2020 7265 7475 726e  ".        return
-0000e1a0: 5f64 6963 7420 3d20 7265 7475 726e 5f64  _dict = return_d
-0000e1b0: 6963 7420 6966 2072 6574 7572 6e5f 6469  ict if return_di
-0000e1c0: 6374 2069 7320 6e6f 7420 4e6f 6e65 2065  ct is not None e
-0000e1d0: 6c73 6520 7365 6c66 2e63 6f6e 6669 672e  lse self.config.
-0000e1e0: 7573 655f 7265 7475 726e 5f64 6963 740a  use_return_dict.
-0000e1f0: 0a20 2020 2020 2020 206f 7574 7075 7473  .        outputs
-0000e200: 203d 2073 656c 662e 6265 7274 280a 2020   = self.bert(.  
-0000e210: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-0000e220: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
-0000e230: 2061 7474 656e 7469 6f6e 5f6d 6173 6b3d   attention_mask=
-0000e240: 6174 7465 6e74 696f 6e5f 6d61 736b 2c0a  attention_mask,.
-0000e250: 2020 2020 2020 2020 2020 2020 746f 6b65              toke
-0000e260: 6e5f 7479 7065 5f69 6473 3d74 6f6b 656e  n_type_ids=token
-0000e270: 5f74 7970 655f 6964 732c 0a20 2020 2020  _type_ids,.     
-0000e280: 2020 2020 2020 2070 6f73 6974 696f 6e5f         position_
-0000e290: 6964 733d 706f 7369 7469 6f6e 5f69 6473  ids=position_ids
-0000e2a0: 2c0a 2020 2020 2020 2020 2020 2020 6865  ,.            he
-0000e2b0: 6164 5f6d 6173 6b3d 6865 6164 5f6d 6173  ad_mask=head_mas
-0000e2c0: 6b2c 0a20 2020 2020 2020 2020 2020 2069  k,.            i
-0000e2d0: 6e70 7574 735f 656d 6265 6473 3d69 6e70  nputs_embeds=inp
-0000e2e0: 7574 735f 656d 6265 6473 2c0a 2020 2020  uts_embeds,.    
-0000e2f0: 2020 2020 2020 2020 6f75 7470 7574 5f61          output_a
-0000e300: 7474 656e 7469 6f6e 733d 6f75 7470 7574  ttentions=output
-0000e310: 5f61 7474 656e 7469 6f6e 732c 0a20 2020  _attentions,.   
-0000e320: 2020 2020 2020 2020 206f 7574 7075 745f           output_
-0000e330: 6869 6464 656e 5f73 7461 7465 733d 6f75  hidden_states=ou
-0000e340: 7470 7574 5f68 6964 6465 6e5f 7374 6174  tput_hidden_stat
-0000e350: 6573 2c0a 2020 2020 2020 2020 2020 2020  es,.            
-0000e360: 7265 7475 726e 5f64 6963 743d 7265 7475  return_dict=retu
-0000e370: 726e 5f64 6963 742c 0a20 2020 2020 2020  rn_dict,.       
-0000e380: 2029 0a0a 2020 2020 2020 2020 7365 7175   )..        sequ
-0000e390: 656e 6365 5f6f 7574 7075 742c 2070 6f6f  ence_output, poo
-0000e3a0: 6c65 645f 6f75 7470 7574 203d 206f 7574  led_output = out
-0000e3b0: 7075 7473 5b3a 325d 0a20 2020 2020 2020  puts[:2].       
-0000e3c0: 2070 7265 6469 6374 696f 6e5f 7363 6f72   prediction_scor
-0000e3d0: 6573 2c20 7365 715f 7265 6c61 7469 6f6e  es, seq_relation
-0000e3e0: 7368 6970 5f73 636f 7265 203d 2073 656c  ship_score = sel
-0000e3f0: 662e 636c 7328 0a20 2020 2020 2020 2020  f.cls(.         
-0000e400: 2020 2073 6571 7565 6e63 655f 6f75 7470     sequence_outp
-0000e410: 7574 2c20 706f 6f6c 6564 5f6f 7574 7075  ut, pooled_outpu
-0000e420: 7429 0a0a 2020 2020 2020 2020 746f 7461  t)..        tota
-0000e430: 6c5f 6c6f 7373 203d 204e 6f6e 650a 2020  l_loss = None.  
-0000e440: 2020 2020 2020 6966 206c 6162 656c 7320        if labels 
-0000e450: 6973 206e 6f74 204e 6f6e 6520 616e 6420  is not None and 
-0000e460: 6e65 7874 5f73 656e 7465 6e63 655f 6c61  next_sentence_la
-0000e470: 6265 6c20 6973 206e 6f74 204e 6f6e 653a  bel is not None:
-0000e480: 0a20 2020 2020 2020 2020 2020 206c 6f73  .            los
-0000e490: 735f 6663 7420 3d20 4372 6f73 7345 6e74  s_fct = CrossEnt
-0000e4a0: 726f 7079 4c6f 7373 2829 0a20 2020 2020  ropyLoss().     
-0000e4b0: 2020 2020 2020 206d 6173 6b65 645f 6c6d         masked_lm
-0000e4c0: 5f6c 6f73 7320 3d20 6c6f 7373 5f66 6374  _loss = loss_fct
-0000e4d0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000e4e0: 2020 7072 6564 6963 7469 6f6e 5f73 636f    prediction_sco
-0000e4f0: 7265 732e 7669 6577 282d 312c 2073 656c  res.view(-1, sel
-0000e500: 662e 636f 6e66 6967 2e76 6f63 6162 5f73  f.config.vocab_s
-0000e510: 697a 6529 2c0a 2020 2020 2020 2020 2020  ize),.          
-0000e520: 2020 2020 2020 6c61 6265 6c73 2e76 6965        labels.vie
-0000e530: 7728 2d31 2929 0a20 2020 2020 2020 2020  w(-1)).         
-0000e540: 2020 206e 6578 745f 7365 6e74 656e 6365     next_sentence
-0000e550: 5f6c 6f73 7320 3d20 6c6f 7373 5f66 6374  _loss = loss_fct
-0000e560: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000e570: 2020 7365 715f 7265 6c61 7469 6f6e 7368    seq_relationsh
-0000e580: 6970 5f73 636f 7265 2e76 6965 7728 2d31  ip_score.view(-1
-0000e590: 2c20 3229 2c0a 2020 2020 2020 2020 2020  , 2),.          
-0000e5a0: 2020 2020 2020 6e65 7874 5f73 656e 7465        next_sente
-0000e5b0: 6e63 655f 6c61 6265 6c2e 7669 6577 282d  nce_label.view(-
-0000e5c0: 3129 290a 2020 2020 2020 2020 2020 2020  1)).            
-0000e5d0: 746f 7461 6c5f 6c6f 7373 203d 206d 6173  total_loss = mas
-0000e5e0: 6b65 645f 6c6d 5f6c 6f73 7320 2b20 6e65  ked_lm_loss + ne
-0000e5f0: 7874 5f73 656e 7465 6e63 655f 6c6f 7373  xt_sentence_loss
-0000e600: 0a0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
-0000e610: 2072 6574 7572 6e5f 6469 6374 3a0a 2020   return_dict:.  
-0000e620: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-0000e630: 203d 2028 7072 6564 6963 7469 6f6e 5f73   = (prediction_s
-0000e640: 636f 7265 732c 2073 6571 5f72 656c 6174  cores, seq_relat
-0000e650: 696f 6e73 6869 705f 7363 6f72 6529 202b  ionship_score) +
-0000e660: 206f 7574 7075 7473 5b32 3a5d 0a20 2020   outputs[2:].   
-0000e670: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0000e680: 2828 746f 7461 6c5f 6c6f 7373 2c20 290a  ((total_loss, ).
-0000e690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e6a0: 2020 2020 2b20 6f75 7470 7574 2920 6966      + output) if
-0000e6b0: 2074 6f74 616c 5f6c 6f73 7320 6973 206e   total_loss is n
-0000e6c0: 6f74 204e 6f6e 6520 656c 7365 206f 7574  ot None else out
-0000e6d0: 7075 740a 0a20 2020 2020 2020 2072 6574  put..        ret
-0000e6e0: 7572 6e20 4265 7274 466f 7250 7265 5472  urn BertForPreTr
-0000e6f0: 6169 6e69 6e67 4f75 7470 7574 280a 2020  ainingOutput(.  
-0000e700: 2020 2020 2020 2020 2020 6c6f 7373 3d74            loss=t
-0000e710: 6f74 616c 5f6c 6f73 732c 0a20 2020 2020  otal_loss,.     
-0000e720: 2020 2020 2020 2070 7265 6469 6374 696f         predictio
-0000e730: 6e5f 6c6f 6769 7473 3d70 7265 6469 6374  n_logits=predict
-0000e740: 696f 6e5f 7363 6f72 6573 2c0a 2020 2020  ion_scores,.    
-0000e750: 2020 2020 2020 2020 7365 715f 7265 6c61          seq_rela
-0000e760: 7469 6f6e 7368 6970 5f6c 6f67 6974 733d  tionship_logits=
-0000e770: 7365 715f 7265 6c61 7469 6f6e 7368 6970  seq_relationship
-0000e780: 5f73 636f 7265 2c0a 2020 2020 2020 2020  _score,.        
-0000e790: 2020 2020 6869 6464 656e 5f73 7461 7465      hidden_state
-0000e7a0: 733d 6f75 7470 7574 732e 6869 6464 656e  s=outputs.hidden
-0000e7b0: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
-0000e7c0: 2020 2020 2061 7474 656e 7469 6f6e 733d       attentions=
-0000e7d0: 6f75 7470 7574 732e 6174 7465 6e74 696f  outputs.attentio
-0000e7e0: 6e73 2c0a 2020 2020 2020 2020 290a 0a0a  ns,.        )...
-0000e7f0: 636c 6173 7320 4265 7274 4c4d 4865 6164  class BertLMHead
-0000e800: 4d6f 6465 6c28 4265 7274 5072 6554 7261  Model(BertPreTra
-0000e810: 696e 6564 4d6f 6465 6c29 3a0a 0a20 2020  inedModel):..   
-0000e820: 205f 6b65 7973 5f74 6f5f 6967 6e6f 7265   _keys_to_ignore
-0000e830: 5f6f 6e5f 6c6f 6164 5f75 6e65 7870 6563  _on_load_unexpec
-0000e840: 7465 6420 3d20 5b72 2770 6f6f 6c65 7227  ted = [r'pooler'
-0000e850: 5d0a 2020 2020 5f6b 6579 735f 746f 5f69  ].    _keys_to_i
-0000e860: 676e 6f72 655f 6f6e 5f6c 6f61 645f 6d69  gnore_on_load_mi
-0000e870: 7373 696e 6720 3d20 5b0a 2020 2020 2020  ssing = [.      
-0000e880: 2020 7227 706f 7369 7469 6f6e 5f69 6473    r'position_ids
-0000e890: 272c 2072 2770 7265 6469 6374 696f 6e73  ', r'predictions
-0000e8a0: 2e64 6563 6f64 6572 2e62 6961 7327 0a20  .decoder.bias'. 
-0000e8b0: 2020 205d 0a0a 2020 2020 6465 6620 5f5f     ]..    def __
-0000e8c0: 696e 6974 5f5f 2873 656c 662c 2063 6f6e  init__(self, con
-0000e8d0: 6669 6729 3a0a 2020 2020 2020 2020 7375  fig):.        su
-0000e8e0: 7065 7228 292e 5f5f 696e 6974 5f5f 2863  per().__init__(c
-0000e8f0: 6f6e 6669 6729 0a0a 2020 2020 2020 2020  onfig)..        
-0000e900: 7365 6c66 2e62 6572 7420 3d20 4265 7274  self.bert = Bert
-0000e910: 4d6f 6465 6c28 636f 6e66 6967 2c20 6164  Model(config, ad
-0000e920: 645f 706f 6f6c 696e 675f 6c61 7965 723d  d_pooling_layer=
-0000e930: 4661 6c73 6529 0a20 2020 2020 2020 2073  False).        s
-0000e940: 656c 662e 636c 7320 3d20 4265 7274 4f6e  elf.cls = BertOn
-0000e950: 6c79 4d4c 4d48 6561 6428 636f 6e66 6967  lyMLMHead(config
-0000e960: 290a 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-0000e970: 696e 6974 5f77 6569 6768 7473 2829 0a0a  init_weights()..
-0000e980: 2020 2020 6465 6620 6765 745f 6f75 7470      def get_outp
-0000e990: 7574 5f65 6d62 6564 6469 6e67 7328 7365  ut_embeddings(se
-0000e9a0: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
-0000e9b0: 7572 6e20 7365 6c66 2e63 6c73 2e70 7265  urn self.cls.pre
-0000e9c0: 6469 6374 696f 6e73 2e64 6563 6f64 6572  dictions.decoder
-0000e9d0: 0a0a 2020 2020 6465 6620 7365 745f 6f75  ..    def set_ou
-0000e9e0: 7470 7574 5f65 6d62 6564 6469 6e67 7328  tput_embeddings(
-0000e9f0: 7365 6c66 2c20 6e65 775f 656d 6265 6464  self, new_embedd
-0000ea00: 696e 6773 293a 0a20 2020 2020 2020 2073  ings):.        s
-0000ea10: 656c 662e 636c 732e 7072 6564 6963 7469  elf.cls.predicti
-0000ea20: 6f6e 732e 6465 636f 6465 7220 3d20 6e65  ons.decoder = ne
-0000ea30: 775f 656d 6265 6464 696e 6773 0a0a 2020  w_embeddings..  
-0000ea40: 2020 6465 6620 666f 7277 6172 6428 0a20    def forward(. 
-0000ea50: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-0000ea60: 2020 2020 2069 6e70 7574 5f69 6473 3d4e       input_ids=N
-0000ea70: 6f6e 652c 0a20 2020 2020 2020 2061 7474  one,.        att
-0000ea80: 656e 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65  ention_mask=None
-0000ea90: 2c0a 2020 2020 2020 2020 746f 6b65 6e5f  ,.        token_
-0000eaa0: 7479 7065 5f69 6473 3d4e 6f6e 652c 0a20  type_ids=None,. 
-0000eab0: 2020 2020 2020 2070 6f73 6974 696f 6e5f         position_
-0000eac0: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
-0000ead0: 2020 6865 6164 5f6d 6173 6b3d 4e6f 6e65    head_mask=None
-0000eae0: 2c0a 2020 2020 2020 2020 696e 7075 7473  ,.        inputs
-0000eaf0: 5f65 6d62 6564 733d 4e6f 6e65 2c0a 2020  _embeds=None,.  
-0000eb00: 2020 2020 2020 656e 636f 6465 725f 6869        encoder_hi
-0000eb10: 6464 656e 5f73 7461 7465 733d 4e6f 6e65  dden_states=None
-0000eb20: 2c0a 2020 2020 2020 2020 656e 636f 6465  ,.        encode
-0000eb30: 725f 6174 7465 6e74 696f 6e5f 6d61 736b  r_attention_mask
-0000eb40: 3d4e 6f6e 652c 0a20 2020 2020 2020 206c  =None,.        l
-0000eb50: 6162 656c 733d 4e6f 6e65 2c0a 2020 2020  abels=None,.    
-0000eb60: 2020 2020 7061 7374 5f6b 6579 5f76 616c      past_key_val
-0000eb70: 7565 733d 4e6f 6e65 2c0a 2020 2020 2020  ues=None,.      
-0000eb80: 2020 7573 655f 6361 6368 653d 4e6f 6e65    use_cache=None
-0000eb90: 2c0a 2020 2020 2020 2020 6f75 7470 7574  ,.        output
-0000eba0: 5f61 7474 656e 7469 6f6e 733d 4e6f 6e65  _attentions=None
-0000ebb0: 2c0a 2020 2020 2020 2020 6f75 7470 7574  ,.        output
-0000ebc0: 5f68 6964 6465 6e5f 7374 6174 6573 3d4e  _hidden_states=N
-0000ebd0: 6f6e 652c 0a20 2020 2020 2020 2072 6574  one,.        ret
-0000ebe0: 7572 6e5f 6469 6374 3d4e 6f6e 652c 0a20  urn_dict=None,. 
-0000ebf0: 2020 2020 2020 2069 735f 6465 636f 6465         is_decode
-0000ec00: 723d 5472 7565 2c0a 2020 2020 2020 2020  r=True,.        
-0000ec10: 7265 6475 6374 696f 6e3d 276d 6561 6e27  reduction='mean'
-0000ec20: 2c0a 2020 2020 2020 2020 6d6f 6465 3d27  ,.        mode='
-0000ec30: 6d75 6c74 695f 6d6f 6461 6c27 2c0a 2020  multi_modal',.  
-0000ec40: 2020 2020 2020 736f 6674 5f6c 6162 656c        soft_label
-0000ec50: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
-0000ec60: 616c 7068 613d 302c 0a20 2020 2020 2020  alpha=0,.       
-0000ec70: 2072 6574 7572 6e5f 6c6f 6769 7473 3d46   return_logits=F
-0000ec80: 616c 7365 2c0a 2020 2020 293a 0a20 2020  alse,.    ):.   
-0000ec90: 2020 2020 2072 2222 220a 2020 2020 2020       r""".      
-0000eca0: 2020 656e 636f 6465 725f 6869 6464 656e    encoder_hidden
-0000ecb0: 5f73 7461 7465 7320 2028 3a6f 626a 3a60  _states  (:obj:`
-0000ecc0: 746f 7263 682e 466c 6f61 7454 656e 736f  torch.FloatTenso
-0000ecd0: 7260 206f 6620 7368 6170 650a 2020 2020  r` of shape.    
-0000ece0: 2020 2020 3a6f 626a 3a60 2862 6174 6368      :obj:`(batch
-0000ecf0: 5f73 697a 652c 2073 6571 7565 6e63 655f  _size, sequence_
-0000ed00: 6c65 6e67 7468 2c20 6869 6464 656e 5f73  length, hidden_s
-0000ed10: 697a 6529 602c 2060 6f70 7469 6f6e 616c  ize)`, `optional
-0000ed20: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
-0000ed30: 5365 7175 656e 6365 206f 6620 6869 6464  Sequence of hidd
-0000ed40: 656e 2d73 7461 7465 7320 6174 2074 6865  en-states at the
-0000ed50: 206f 7574 7075 7420 6f66 2074 6865 206c   output of the l
-0000ed60: 6173 7420 6c61 7965 7220 6f66 2074 6865  ast layer of the
-0000ed70: 0a20 2020 2020 2020 2020 2020 2065 6e63  .            enc
-0000ed80: 6f64 6572 2e20 5573 6564 2069 6e20 7468  oder. Used in th
-0000ed90: 6520 6372 6f73 732d 6174 7465 6e74 696f  e cross-attentio
-0000eda0: 6e20 6966 2074 6865 206d 6f64 656c 2069  n if the model i
-0000edb0: 7320 636f 6e66 6967 7572 6564 2061 7320  s configured as 
-0000edc0: 610a 2020 2020 2020 2020 2020 2020 6465  a.            de
-0000edd0: 636f 6465 722e 0a20 2020 2020 2020 2065  coder..        e
-0000ede0: 6e63 6f64 6572 5f61 7474 656e 7469 6f6e  ncoder_attention
-0000edf0: 5f6d 6173 6b20 283a 6f62 6a3a 6074 6f72  _mask (:obj:`tor
-0000ee00: 6368 2e46 6c6f 6174 5465 6e73 6f72 6020  ch.FloatTensor` 
-0000ee10: 6f66 2073 6861 7065 0a20 2020 2020 2020  of shape.       
-0000ee20: 203a 6f62 6a3a 6028 6261 7463 685f 7369   :obj:`(batch_si
-0000ee30: 7a65 2c20 7365 7175 656e 6365 5f6c 656e  ze, sequence_len
-0000ee40: 6774 6829 602c 2060 6f70 7469 6f6e 616c  gth)`, `optional
-0000ee50: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
-0000ee60: 4d61 736b 2074 6f20 6176 6f69 6420 7065  Mask to avoid pe
-0000ee70: 7266 6f72 6d69 6e67 2061 7474 656e 7469  rforming attenti
-0000ee80: 6f6e 206f 6e20 7468 6520 7061 6464 696e  on on the paddin
-0000ee90: 6720 746f 6b65 6e20 696e 6469 6365 7320  g token indices 
-0000eea0: 6f66 0a20 2020 2020 2020 2020 2020 2074  of.            t
-0000eeb0: 6865 2065 6e63 6f64 6572 2069 6e70 7574  he encoder input
-0000eec0: 2e20 5468 6973 206d 6173 6b20 6973 2075  . This mask is u
-0000eed0: 7365 6420 696e 2074 6865 2063 726f 7373  sed in the cross
-0000eee0: 2d61 7474 656e 7469 6f6e 2069 6620 7468  -attention if th
-0000eef0: 650a 2020 2020 2020 2020 2020 2020 6d6f  e.            mo
-0000ef00: 6465 6c20 6973 2063 6f6e 6669 6775 7265  del is configure
-0000ef10: 6420 6173 2061 2064 6563 6f64 6572 2e20  d as a decoder. 
-0000ef20: 4d61 736b 2076 616c 7565 7320 7365 6c65  Mask values sele
-0000ef30: 6374 6564 2069 6e20 6060 5b30 2c0a 2020  cted in ``[0,.  
-0000ef40: 2020 2020 2020 2020 2020 315d 6060 3a20            1]``: 
-0000ef50: 2d20 3120 666f 7220 746f 6b65 6e73 2074  - 1 for tokens t
-0000ef60: 6861 7420 6172 6520 2a2a 6e6f 7420 6d61  hat are **not ma
-0000ef70: 736b 6564 2a2a 2c20 2d20 3020 666f 7220  sked**, - 0 for 
-0000ef80: 746f 6b65 6e73 2074 6861 740a 2020 2020  tokens that.    
-0000ef90: 2020 2020 2020 2020 6172 6520 2a2a 6d61          are **ma
-0000efa0: 736b 6564 2a2a 2e0a 2020 2020 2020 2020  sked**..        
-0000efb0: 6c61 6265 6c73 2028 3a6f 626a 3a60 746f  labels (:obj:`to
-0000efc0: 7263 682e 4c6f 6e67 5465 6e73 6f72 6020  rch.LongTensor` 
-0000efd0: 6f66 2073 6861 7065 203a 6f62 6a3a 6028  of shape :obj:`(
-0000efe0: 6261 7463 685f 7369 7a65 2c0a 2020 2020  batch_size,.    
-0000eff0: 2020 2020 7365 7175 656e 6365 5f6c 656e      sequence_len
-0000f000: 6774 6829 602c 2060 6f70 7469 6f6e 616c  gth)`, `optional
-0000f010: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
-0000f020: 4c61 6265 6c73 2066 6f72 2063 6f6d 7075  Labels for compu
-0000f030: 7469 6e67 2074 6865 206c 6566 742d 746f  ting the left-to
-0000f040: 2d72 6967 6874 206c 616e 6775 6167 6520  -right language 
-0000f050: 6d6f 6465 6c69 6e67 206c 6f73 7320 286e  modeling loss (n
-0000f060: 6578 740a 2020 2020 2020 2020 2020 2020  ext.            
-0000f070: 776f 7264 2070 7265 6469 6374 696f 6e29  word prediction)
-0000f080: 2e20 496e 6469 6365 7320 7368 6f75 6c64  . Indices should
-0000f090: 2062 6520 696e 2060 605b 2d31 3030 2c20   be in ``[-100, 
-0000f0a0: 302c 202e 2e2e 2c0a 2020 2020 2020 2020  0, ...,.        
-0000f0b0: 2020 2020 636f 6e66 6967 2e76 6f63 6162      config.vocab
-0000f0c0: 5f73 697a 655d 6060 2028 7365 6520 6060  _size]`` (see ``
-0000f0d0: 696e 7075 745f 6964 7360 6020 646f 6373  input_ids`` docs
-0000f0e0: 7472 696e 6729 2054 6f6b 656e 7320 7769  tring) Tokens wi
-0000f0f0: 7468 0a20 2020 2020 2020 2020 2020 2069  th.            i
-0000f100: 6e64 6963 6573 2073 6574 2074 6f20 6060  ndices set to ``
-0000f110: 2d31 3030 6060 2061 7265 2069 676e 6f72  -100`` are ignor
-0000f120: 6564 2028 6d61 736b 6564 292c 2074 6865  ed (masked), the
-0000f130: 206c 6f73 7320 6973 206f 6e6c 790a 2020   loss is only.  
-0000f140: 2020 2020 2020 2020 2020 636f 6d70 7574            comput
-0000f150: 6564 2066 6f72 2074 6865 2074 6f6b 656e  ed for the token
-0000f160: 7320 7769 7468 206c 6162 656c 7320 6e20  s with labels n 
-0000f170: 6060 5b30 2c20 2e2e 2e2c 0a20 2020 2020  ``[0, ...,.     
-0000f180: 2020 2020 2020 2063 6f6e 6669 672e 766f         config.vo
-0000f190: 6361 625f 7369 7a65 5d60 600a 2020 2020  cab_size]``.    
-0000f1a0: 2020 2020 7061 7374 5f6b 6579 5f76 616c      past_key_val
-0000f1b0: 7565 7320 283a 6f62 6a3a 6074 7570 6c65  ues (:obj:`tuple
-0000f1c0: 2874 7570 6c65 2874 6f72 6368 2e46 6c6f  (tuple(torch.Flo
-0000f1d0: 6174 5465 6e73 6f72 2929 6020 6f66 206c  atTensor))` of l
-0000f1e0: 656e 6774 680a 2020 2020 2020 2020 3a6f  ength.        :o
-0000f1f0: 626a 3a60 636f 6e66 6967 2e6e 5f6c 6179  bj:`config.n_lay
-0000f200: 6572 7360 2077 6974 6820 6561 6368 2074  ers` with each t
-0000f210: 7570 6c65 2068 6176 696e 6720 3420 7465  uple having 4 te
-0000f220: 6e73 6f72 7320 6f66 2073 6861 7065 0a20  nsors of shape. 
-0000f230: 2020 2020 2020 203a 6f62 6a3a 6028 6261         :obj:`(ba
-0000f240: 7463 685f 7369 7a65 2c20 6e75 6d5f 6865  tch_size, num_he
-0000f250: 6164 732c 2073 6571 7565 6e63 655f 6c65  ads, sequence_le
-0000f260: 6e67 7468 202d 2031 2c0a 2020 2020 2020  ngth - 1,.      
-0000f270: 2020 656d 6265 645f 7369 7a65 5f70 6572    embed_size_per
-0000f280: 5f68 6561 6429 6029 3a0a 2020 2020 2020  _head)`):.      
-0000f290: 2020 2020 2020 436f 6e74 6169 6e73 2070        Contains p
-0000f2a0: 7265 636f 6d70 7574 6564 206b 6579 2061  recomputed key a
-0000f2b0: 6e64 2076 616c 7565 2068 6964 6465 6e20  nd value hidden 
-0000f2c0: 7374 6174 6573 206f 6620 7468 6520 6174  states of the at
-0000f2d0: 7465 6e74 696f 6e0a 2020 2020 2020 2020  tention.        
-0000f2e0: 2020 2020 626c 6f63 6b73 2e20 4361 6e20      blocks. Can 
-0000f2f0: 6265 2075 7365 6420 746f 2073 7065 6564  be used to speed
-0000f300: 2075 7020 6465 636f 6469 6e67 2e20 4966   up decoding. If
-0000f310: 203a 6f62 6a3a 6070 6173 745f 6b65 795f   :obj:`past_key_
-0000f320: 7661 6c75 6573 600a 2020 2020 2020 2020  values`.        
-0000f330: 2020 2020 6172 6520 7573 6564 2c20 7468      are used, th
-0000f340: 6520 7573 6572 2063 616e 206f 7074 696f  e user can optio
-0000f350: 6e61 6c6c 7920 696e 7075 7420 6f6e 6c79  nally input only
-0000f360: 2074 6865 206c 6173 740a 2020 2020 2020   the last.      
-0000f370: 2020 2020 2020 3a6f 626a 3a60 6465 636f        :obj:`deco
-0000f380: 6465 725f 696e 7075 745f 6964 7360 2028  der_input_ids` (
-0000f390: 7468 6f73 6520 7468 6174 2064 6f6e 2774  those that don't
-0000f3a0: 2068 6176 6520 7468 6569 7220 7061 7374   have their past
-0000f3b0: 206b 6579 2076 616c 7565 0a20 2020 2020   key value.     
-0000f3c0: 2020 2020 2020 2073 7461 7465 7320 6769         states gi
-0000f3d0: 7665 6e20 746f 2074 6869 7320 6d6f 6465  ven to this mode
-0000f3e0: 6c29 206f 6620 7368 6170 6520 3a6f 626a  l) of shape :obj
-0000f3f0: 3a60 2862 6174 6368 5f73 697a 652c 2031  :`(batch_size, 1
-0000f400: 2960 2069 6e73 7465 6164 0a20 2020 2020  )` instead.     
-0000f410: 2020 2020 2020 206f 6620 616c 6c20 3a6f         of all :o
-0000f420: 626a 3a60 6465 636f 6465 725f 696e 7075  bj:`decoder_inpu
-0000f430: 745f 6964 7360 206f 6620 7368 6170 6520  t_ids` of shape 
-0000f440: 3a6f 626a 3a60 2862 6174 6368 5f73 697a  :obj:`(batch_siz
-0000f450: 652c 0a20 2020 2020 2020 2020 2020 2073  e,.            s
-0000f460: 6571 7565 6e63 655f 6c65 6e67 7468 2960  equence_length)`
-0000f470: 2e0a 2020 2020 2020 2020 7573 655f 6361  ..        use_ca
-0000f480: 6368 6520 283a 6f62 6a3a 6062 6f6f 6c60  che (:obj:`bool`
-0000f490: 2c20 606f 7074 696f 6e61 6c60 293a 0a20  , `optional`):. 
-0000f4a0: 2020 2020 2020 2020 2020 2049 6620 7365             If se
-0000f4b0: 7420 746f 203a 6f62 6a3a 6054 7275 6560  t to :obj:`True`
-0000f4c0: 2c20 3a6f 626a 3a60 7061 7374 5f6b 6579  , :obj:`past_key
-0000f4d0: 5f76 616c 7565 7360 206b 6579 2076 616c  _values` key val
-0000f4e0: 7565 2073 7461 7465 7320 6172 650a 2020  ue states are.  
-0000f4f0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0000f500: 6564 2061 6e64 2063 616e 2062 6520 7573  ed and can be us
-0000f510: 6564 2074 6f20 7370 6565 6420 7570 2064  ed to speed up d
-0000f520: 6563 6f64 696e 6720 2873 6565 0a20 2020  ecoding (see.   
-0000f530: 2020 2020 2020 2020 203a 6f62 6a3a 6070           :obj:`p
-0000f540: 6173 745f 6b65 795f 7661 6c75 6573 6029  ast_key_values`)
-0000f550: 2e0a 0a20 2020 2020 2020 2052 6574 7572  ...        Retur
-0000f560: 6e73 3a0a 0a20 2020 2020 2020 2045 7861  ns:..        Exa
-0000f570: 6d70 6c65 3a0a 2020 2020 2020 2020 2020  mple:.          
-0000f580: 2020 3e3e 3e20 6672 6f6d 2074 7261 6e73    >>> from trans
-0000f590: 666f 726d 6572 7320 696d 706f 7274 2042  formers import B
-0000f5a0: 6572 7454 6f6b 656e 697a 6572 2c20 4265  ertTokenizer, Be
-0000f5b0: 7274 4c4d 4865 6164 4d6f 6465 6c2c 2042  rtLMHeadModel, B
-0000f5c0: 6572 7443 6f6e 6669 670a 2020 2020 2020  ertConfig.      
-0000f5d0: 2020 2020 2020 3e3e 3e20 696d 706f 7274        >>> import
-0000f5e0: 2074 6f72 6368 0a20 2020 2020 2020 2020   torch.         
-0000f5f0: 2020 203e 3e3e 2074 6f6b 656e 697a 6572     >>> tokenizer
-0000f600: 203d 2042 6572 7454 6f6b 656e 697a 6572   = BertTokenizer
-0000f610: 2e66 726f 6d5f 7072 6574 7261 696e 6564  .from_pretrained
-0000f620: 2827 6265 7274 2d62 6173 652d 6361 7365  ('bert-base-case
-0000f630: 6427 290a 2020 2020 2020 2020 2020 2020  d').            
-0000f640: 3e3e 3e20 636f 6e66 6967 203d 2042 6572  >>> config = Ber
-0000f650: 7443 6f6e 6669 672e 6672 6f6d 5f70 7265  tConfig.from_pre
-0000f660: 7472 6169 6e65 6428 2262 6572 742d 6261  trained("bert-ba
-0000f670: 7365 2d63 6173 6564 2229 0a20 2020 2020  se-cased").     
-0000f680: 2020 2020 2020 203e 3e3e 206d 6f64 656c         >>> model
-0000f690: 203d 2042 6572 744c 4d48 6561 644d 6f64   = BertLMHeadMod
-0000f6a0: 656c 2e66 726f 6d5f 7072 6574 7261 696e  el.from_pretrain
-0000f6b0: 6564 2827 6265 7274 2d62 6173 652d 6361  ed('bert-base-ca
-0000f6c0: 7365 6427 2c20 636f 6e66 6967 3d63 6f6e  sed', config=con
-0000f6d0: 6669 6729 0a20 2020 2020 2020 2020 2020  fig).           
-0000f6e0: 203e 3e3e 2069 6e70 7574 7320 3d20 746f   >>> inputs = to
-0000f6f0: 6b65 6e69 7a65 7228 2248 656c 6c6f 2c20  kenizer("Hello, 
-0000f700: 6d79 2064 6f67 2069 7320 6375 7465 222c  my dog is cute",
-0000f710: 2072 6574 7572 6e5f 7465 6e73 6f72 733d   return_tensors=
-0000f720: 2270 7422 290a 2020 2020 2020 2020 2020  "pt").          
-0000f730: 2020 3e3e 3e20 6f75 7470 7574 7320 3d20    >>> outputs = 
-0000f740: 6d6f 6465 6c28 2a2a 696e 7075 7473 290a  model(**inputs).
-0000f750: 2020 2020 2020 2020 2020 2020 3e3e 3e20              >>> 
-0000f760: 7072 6564 6963 7469 6f6e 5f6c 6f67 6974  prediction_logit
-0000f770: 7320 3d20 6f75 7470 7574 732e 6c6f 6769  s = outputs.logi
-0000f780: 7473 0a20 2020 2020 2020 2022 2222 0a20  ts.        """. 
-0000f790: 2020 2020 2020 2072 6574 7572 6e5f 6469         return_di
-0000f7a0: 6374 203d 2072 6574 7572 6e5f 6469 6374  ct = return_dict
-0000f7b0: 2069 6620 7265 7475 726e 5f64 6963 7420   if return_dict 
-0000f7c0: 6973 206e 6f74 204e 6f6e 6520 656c 7365  is not None else
-0000f7d0: 2073 656c 662e 636f 6e66 6967 2e75 7365   self.config.use
-0000f7e0: 5f72 6574 7572 6e5f 6469 6374 0a20 2020  _return_dict.   
-0000f7f0: 2020 2020 2069 6620 6c61 6265 6c73 2069       if labels i
-0000f800: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
-0000f810: 2020 2020 2020 2020 7573 655f 6361 6368          use_cach
-0000f820: 6520 3d20 4661 6c73 650a 0a20 2020 2020  e = False..     
-0000f830: 2020 206f 7574 7075 7473 203d 2073 656c     outputs = sel
-0000f840: 662e 6265 7274 280a 2020 2020 2020 2020  f.bert(.        
-0000f850: 2020 2020 696e 7075 745f 6964 732c 0a20      input_ids,. 
-0000f860: 2020 2020 2020 2020 2020 2061 7474 656e             atten
-0000f870: 7469 6f6e 5f6d 6173 6b3d 6174 7465 6e74  tion_mask=attent
-0000f880: 696f 6e5f 6d61 736b 2c0a 2020 2020 2020  ion_mask,.      
-0000f890: 2020 2020 2020 746f 6b65 6e5f 7479 7065        token_type
-0000f8a0: 5f69 6473 3d74 6f6b 656e 5f74 7970 655f  _ids=token_type_
-0000f8b0: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
-0000f8c0: 2070 6f73 6974 696f 6e5f 6964 733d 706f   position_ids=po
-0000f8d0: 7369 7469 6f6e 5f69 6473 2c0a 2020 2020  sition_ids,.    
-0000f8e0: 2020 2020 2020 2020 6865 6164 5f6d 6173          head_mas
-0000f8f0: 6b3d 6865 6164 5f6d 6173 6b2c 0a20 2020  k=head_mask,.   
-0000f900: 2020 2020 2020 2020 2069 6e70 7574 735f           inputs_
-0000f910: 656d 6265 6473 3d69 6e70 7574 735f 656d  embeds=inputs_em
-0000f920: 6265 6473 2c0a 2020 2020 2020 2020 2020  beds,.          
-0000f930: 2020 656e 636f 6465 725f 6869 6464 656e    encoder_hidden
-0000f940: 5f73 7461 7465 733d 656e 636f 6465 725f  _states=encoder_
-0000f950: 6869 6464 656e 5f73 7461 7465 732c 0a20  hidden_states,. 
-0000f960: 2020 2020 2020 2020 2020 2065 6e63 6f64             encod
-0000f970: 6572 5f61 7474 656e 7469 6f6e 5f6d 6173  er_attention_mas
-0000f980: 6b3d 656e 636f 6465 725f 6174 7465 6e74  k=encoder_attent
-0000f990: 696f 6e5f 6d61 736b 2c0a 2020 2020 2020  ion_mask,.      
-0000f9a0: 2020 2020 2020 7061 7374 5f6b 6579 5f76        past_key_v
-0000f9b0: 616c 7565 733d 7061 7374 5f6b 6579 5f76  alues=past_key_v
-0000f9c0: 616c 7565 732c 0a20 2020 2020 2020 2020  alues,.         
-0000f9d0: 2020 2075 7365 5f63 6163 6865 3d75 7365     use_cache=use
-0000f9e0: 5f63 6163 6865 2c0a 2020 2020 2020 2020  _cache,.        
-0000f9f0: 2020 2020 6f75 7470 7574 5f61 7474 656e      output_atten
-0000fa00: 7469 6f6e 733d 6f75 7470 7574 5f61 7474  tions=output_att
-0000fa10: 656e 7469 6f6e 732c 0a20 2020 2020 2020  entions,.       
-0000fa20: 2020 2020 206f 7574 7075 745f 6869 6464       output_hidd
-0000fa30: 656e 5f73 7461 7465 733d 6f75 7470 7574  en_states=output
-0000fa40: 5f68 6964 6465 6e5f 7374 6174 6573 2c0a  _hidden_states,.
-0000fa50: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0000fa60: 726e 5f64 6963 743d 7265 7475 726e 5f64  rn_dict=return_d
-0000fa70: 6963 742c 0a20 2020 2020 2020 2020 2020  ict,.           
-0000fa80: 2069 735f 6465 636f 6465 723d 6973 5f64   is_decoder=is_d
-0000fa90: 6563 6f64 6572 2c0a 2020 2020 2020 2020  ecoder,.        
-0000faa0: 2020 2020 6d6f 6465 3d6d 6f64 652c 0a20      mode=mode,. 
-0000fab0: 2020 2020 2020 2029 0a0a 2020 2020 2020         )..      
-0000fac0: 2020 7365 7175 656e 6365 5f6f 7574 7075    sequence_outpu
-0000fad0: 7420 3d20 6f75 7470 7574 735b 305d 0a20  t = outputs[0]. 
-0000fae0: 2020 2020 2020 2070 7265 6469 6374 696f         predictio
-0000faf0: 6e5f 7363 6f72 6573 203d 2073 656c 662e  n_scores = self.
-0000fb00: 636c 7328 7365 7175 656e 6365 5f6f 7574  cls(sequence_out
-0000fb10: 7075 7429 0a0a 2020 2020 2020 2020 6966  put)..        if
-0000fb20: 2072 6574 7572 6e5f 6c6f 6769 7473 3a0a   return_logits:.
-0000fb30: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0000fb40: 726e 2070 7265 6469 6374 696f 6e5f 7363  rn prediction_sc
-0000fb50: 6f72 6573 5b3a 2c20 3a2d 312c 203a 5d2e  ores[:, :-1, :].
-0000fb60: 636f 6e74 6967 756f 7573 2829 0a0a 2020  contiguous()..  
-0000fb70: 2020 2020 2020 6c6d 5f6c 6f73 7320 3d20        lm_loss = 
-0000fb80: 4e6f 6e65 0a20 2020 2020 2020 2069 6620  None.        if 
-0000fb90: 6c61 6265 6c73 2069 7320 6e6f 7420 4e6f  labels is not No
-0000fba0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-0000fbb0: 2320 7765 2061 7265 2064 6f69 6e67 206e  # we are doing n
-0000fbc0: 6578 742d 746f 6b65 6e20 7072 6564 6963  ext-token predic
-0000fbd0: 7469 6f6e 3b20 7368 6966 7420 7072 6564  tion; shift pred
-0000fbe0: 6963 7469 6f6e 2073 636f 7265 7320 616e  iction scores an
-0000fbf0: 6420 696e 7075 7420 6964 7320 6279 206f  d input ids by o
-0000fc00: 6e65 0a20 2020 2020 2020 2020 2020 2073  ne.            s
-0000fc10: 6869 6674 6564 5f70 7265 6469 6374 696f  hifted_predictio
-0000fc20: 6e5f 7363 6f72 6573 203d 2070 7265 6469  n_scores = predi
-0000fc30: 6374 696f 6e5f 7363 6f72 6573 5b3a 2c20  ction_scores[:, 
-0000fc40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000fc50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fc70: 2020 2020 2020 2020 2020 2020 2d31 2c20              -1, 
-0000fc80: 3a5d 2e63 6f6e 7469 6775 6f75 7328 290a  :].contiguous().
-0000fc90: 2020 2020 2020 2020 2020 2020 6c61 6265              labe
-0000fca0: 6c73 203d 206c 6162 656c 735b 3a2c 2031  ls = labels[:, 1
-0000fcb0: 3a5d 2e63 6f6e 7469 6775 6f75 7328 290a  :].contiguous().
-0000fcc0: 2020 2020 2020 2020 2020 2020 6c6f 7373              loss
-0000fcd0: 5f66 6374 203d 2043 726f 7373 456e 7472  _fct = CrossEntr
-0000fce0: 6f70 794c 6f73 7328 7265 6475 6374 696f  opyLoss(reductio
-0000fcf0: 6e3d 7265 6475 6374 696f 6e29 0a20 2020  n=reduction).   
-0000fd00: 2020 2020 2020 2020 206c 6d5f 6c6f 7373           lm_loss
-0000fd10: 203d 206c 6f73 735f 6663 7428 0a20 2020   = loss_fct(.   
-0000fd20: 2020 2020 2020 2020 2020 2020 2073 6869               shi
-0000fd30: 6674 6564 5f70 7265 6469 6374 696f 6e5f  fted_prediction_
-0000fd40: 7363 6f72 6573 2e76 6965 7728 2d31 2c20  scores.view(-1, 
-0000fd50: 7365 6c66 2e63 6f6e 6669 672e 766f 6361  self.config.voca
-0000fd60: 625f 7369 7a65 292c 0a20 2020 2020 2020  b_size),.       
-0000fd70: 2020 2020 2020 2020 206c 6162 656c 732e           labels.
-0000fd80: 7669 6577 282d 3129 290a 2020 2020 2020  view(-1)).      
-0000fd90: 2020 2020 2020 6c6d 5f6c 6f73 7320 3d20        lm_loss = 
-0000fda0: 6c6d 5f6c 6f73 732e 7669 6577 2870 7265  lm_loss.view(pre
-0000fdb0: 6469 6374 696f 6e5f 7363 6f72 6573 2e73  diction_scores.s
-0000fdc0: 697a 6528 3029 2c20 2d31 292e 7375 6d28  ize(0), -1).sum(
-0000fdd0: 3129 0a0a 2020 2020 2020 2020 6966 2073  1)..        if s
-0000fde0: 6f66 745f 6c61 6265 6c73 2069 7320 6e6f  oft_labels is no
-0000fdf0: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-0000fe00: 2020 2020 6c6f 7373 5f64 6973 7469 6c6c      loss_distill
-0000fe10: 203d 202d 746f 7263 682e 7375 6d28 0a20   = -torch.sum(. 
-0000fe20: 2020 2020 2020 2020 2020 2020 2020 2046                 F
-0000fe30: 2e6c 6f67 5f73 6f66 746d 6178 2873 6869  .log_softmax(shi
-0000fe40: 6674 6564 5f70 7265 6469 6374 696f 6e5f  fted_prediction_
-0000fe50: 7363 6f72 6573 2c20 6469 6d3d 2d31 2920  scores, dim=-1) 
-0000fe60: 2a20 736f 6674 5f6c 6162 656c 732c 0a20  * soft_labels,. 
-0000fe70: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-0000fe80: 696d 3d2d 3129 0a20 2020 2020 2020 2020  im=-1).         
-0000fe90: 2020 206c 6f73 735f 6469 7374 696c 6c20     loss_distill 
-0000fea0: 3d20 286c 6f73 735f 6469 7374 696c 6c20  = (loss_distill 
-0000feb0: 2a20 286c 6162 656c 7320 213d 202d 3130  * (labels != -10
-0000fec0: 3029 292e 7375 6d28 3129 0a20 2020 2020  0)).sum(1).     
-0000fed0: 2020 2020 2020 206c 6d5f 6c6f 7373 203d         lm_loss =
-0000fee0: 2028 3120 2d20 616c 7068 6129 202a 206c   (1 - alpha) * l
-0000fef0: 6d5f 6c6f 7373 202b 2061 6c70 6861 202a  m_loss + alpha *
-0000ff00: 206c 6f73 735f 6469 7374 696c 6c0a 0a20   loss_distill.. 
-0000ff10: 2020 2020 2020 2069 6620 6e6f 7420 7265         if not re
-0000ff20: 7475 726e 5f64 6963 743a 0a20 2020 2020  turn_dict:.     
-0000ff30: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0000ff40: 2870 7265 6469 6374 696f 6e5f 7363 6f72  (prediction_scor
-0000ff50: 6573 2c20 2920 2b20 6f75 7470 7574 735b  es, ) + outputs[
-0000ff60: 323a 5d0a 2020 2020 2020 2020 2020 2020  2:].            
-0000ff70: 7265 7475 726e 2028 286c 6d5f 6c6f 7373  return ((lm_loss
-0000ff80: 2c20 2920 2b20 6f75 7470 7574 2920 6966  , ) + output) if
-0000ff90: 206c 6d5f 6c6f 7373 2069 7320 6e6f 7420   lm_loss is not 
-0000ffa0: 4e6f 6e65 2065 6c73 6520 6f75 7470 7574  None else output
-0000ffb0: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-0000ffc0: 2043 6175 7361 6c4c 4d4f 7574 7075 7457   CausalLMOutputW
-0000ffd0: 6974 6843 726f 7373 4174 7465 6e74 696f  ithCrossAttentio
-0000ffe0: 6e73 280a 2020 2020 2020 2020 2020 2020  ns(.            
-0000fff0: 6c6f 7373 3d6c 6d5f 6c6f 7373 2c0a 2020  loss=lm_loss,.  
-00010000: 2020 2020 2020 2020 2020 6c6f 6769 7473            logits
-00010010: 3d70 7265 6469 6374 696f 6e5f 7363 6f72  =prediction_scor
-00010020: 6573 2c0a 2020 2020 2020 2020 2020 2020  es,.            
-00010030: 7061 7374 5f6b 6579 5f76 616c 7565 733d  past_key_values=
-00010040: 6f75 7470 7574 732e 7061 7374 5f6b 6579  outputs.past_key
-00010050: 5f76 616c 7565 732c 0a20 2020 2020 2020  _values,.       
-00010060: 2020 2020 2068 6964 6465 6e5f 7374 6174       hidden_stat
-00010070: 6573 3d6f 7574 7075 7473 2e68 6964 6465  es=outputs.hidde
-00010080: 6e5f 7374 6174 6573 2c0a 2020 2020 2020  n_states,.      
-00010090: 2020 2020 2020 6174 7465 6e74 696f 6e73        attentions
-000100a0: 3d6f 7574 7075 7473 2e61 7474 656e 7469  =outputs.attenti
-000100b0: 6f6e 732c 0a20 2020 2020 2020 2020 2020  ons,.           
-000100c0: 2063 726f 7373 5f61 7474 656e 7469 6f6e   cross_attention
-000100d0: 733d 6f75 7470 7574 732e 6372 6f73 735f  s=outputs.cross_
-000100e0: 6174 7465 6e74 696f 6e73 2c0a 2020 2020  attentions,.    
-000100f0: 2020 2020 290a 0a20 2020 2064 6566 2070      )..    def p
-00010100: 7265 7061 7265 5f69 6e70 7574 735f 666f  repare_inputs_fo
-00010110: 725f 6765 6e65 7261 7469 6f6e 2873 656c  r_generation(sel
-00010120: 662c 0a20 2020 2020 2020 2020 2020 2020  f,.             
-00010130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010140: 2020 2020 2020 2020 2069 6e70 7574 5f69           input_i
-00010150: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
-00010160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010170: 2020 2020 2020 2020 2020 7061 7374 3d4e            past=N
-00010180: 6f6e 652c 0a20 2020 2020 2020 2020 2020  one,.           
-00010190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000101a0: 2020 2020 2020 2020 2020 2061 7474 656e             atten
-000101b0: 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65 2c0a  tion_mask=None,.
-000101c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000101d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000101e0: 2020 2020 2020 2a2a 6d6f 6465 6c5f 6b77        **model_kw
-000101f0: 6172 6773 293a 0a20 2020 2020 2020 2069  args):.        i
-00010200: 6e70 7574 5f73 6861 7065 203d 2069 6e70  nput_shape = inp
-00010210: 7574 5f69 6473 2e73 6861 7065 0a20 2020  ut_ids.shape.   
-00010220: 2020 2020 2023 2069 6620 6d6f 6465 6c20       # if model 
-00010230: 6973 2075 7365 6420 6173 2061 2064 6563  is used as a dec
-00010240: 6f64 6572 2069 6e20 656e 636f 6465 722d  oder in encoder-
-00010250: 6465 636f 6465 7220 6d6f 6465 6c2c 2074  decoder model, t
-00010260: 6865 2064 6563 6f64 6572 2061 7474 656e  he decoder atten
-00010270: 7469 6f6e 206d 6173 6b20 6973 2063 7265  tion mask is cre
-00010280: 6174 6564 206f 6e20 7468 6520 666c 790a  ated on the fly.
-00010290: 2020 2020 2020 2020 6966 2061 7474 656e          if atten
-000102a0: 7469 6f6e 5f6d 6173 6b20 6973 204e 6f6e  tion_mask is Non
-000102b0: 653a 0a20 2020 2020 2020 2020 2020 2061  e:.            a
-000102c0: 7474 656e 7469 6f6e 5f6d 6173 6b20 3d20  ttention_mask = 
-000102d0: 696e 7075 745f 6964 732e 6e65 775f 6f6e  input_ids.new_on
-000102e0: 6573 2869 6e70 7574 5f73 6861 7065 290a  es(input_shape).
-000102f0: 0a20 2020 2020 2020 2023 2063 7574 2064  .        # cut d
-00010300: 6563 6f64 6572 5f69 6e70 7574 5f69 6473  ecoder_input_ids
-00010310: 2069 6620 7061 7374 2069 7320 7573 6564   if past is used
-00010320: 0a20 2020 2020 2020 2069 6620 7061 7374  .        if past
-00010330: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-00010340: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00010350: 6964 7320 3d20 696e 7075 745f 6964 735b  ids = input_ids[
-00010360: 3a2c 202d 313a 5d0a 0a20 2020 2020 2020  :, -1:]..       
-00010370: 2072 6574 7572 6e20 7b0a 2020 2020 2020   return {.      
-00010380: 2020 2020 2020 2769 6e70 7574 5f69 6473        'input_ids
-00010390: 273a 0a20 2020 2020 2020 2020 2020 2069  ':.            i
-000103a0: 6e70 7574 5f69 6473 2c0a 2020 2020 2020  nput_ids,.      
-000103b0: 2020 2020 2020 2761 7474 656e 7469 6f6e        'attention
-000103c0: 5f6d 6173 6b27 3a0a 2020 2020 2020 2020  _mask':.        
-000103d0: 2020 2020 6174 7465 6e74 696f 6e5f 6d61      attention_ma
-000103e0: 736b 2c0a 2020 2020 2020 2020 2020 2020  sk,.            
-000103f0: 2770 6173 745f 6b65 795f 7661 6c75 6573  'past_key_values
-00010400: 273a 0a20 2020 2020 2020 2020 2020 2070  ':.            p
-00010410: 6173 742c 0a20 2020 2020 2020 2020 2020  ast,.           
-00010420: 2027 656e 636f 6465 725f 6869 6464 656e   'encoder_hidden
-00010430: 5f73 7461 7465 7327 3a0a 2020 2020 2020  _states':.      
-00010440: 2020 2020 2020 6d6f 6465 6c5f 6b77 6172        model_kwar
-00010450: 6773 2e67 6574 2827 656e 636f 6465 725f  gs.get('encoder_
-00010460: 6869 6464 656e 5f73 7461 7465 7327 2c20  hidden_states', 
-00010470: 4e6f 6e65 292c 0a20 2020 2020 2020 2020  None),.         
-00010480: 2020 2027 656e 636f 6465 725f 6174 7465     'encoder_atte
-00010490: 6e74 696f 6e5f 6d61 736b 273a 0a20 2020  ntion_mask':.   
-000104a0: 2020 2020 2020 2020 206d 6f64 656c 5f6b           model_k
-000104b0: 7761 7267 732e 6765 7428 2765 6e63 6f64  wargs.get('encod
-000104c0: 6572 5f61 7474 656e 7469 6f6e 5f6d 6173  er_attention_mas
-000104d0: 6b27 2c20 4e6f 6e65 292c 0a20 2020 2020  k', None),.     
-000104e0: 2020 2020 2020 2027 6973 5f64 6563 6f64         'is_decod
-000104f0: 6572 273a 0a20 2020 2020 2020 2020 2020  er':.           
-00010500: 2054 7275 652c 0a20 2020 2020 2020 207d   True,.        }
-00010510: 0a0a 2020 2020 6465 6620 5f72 656f 7264  ..    def _reord
-00010520: 6572 5f63 6163 6865 2873 656c 662c 2070  er_cache(self, p
-00010530: 6173 742c 2062 6561 6d5f 6964 7829 3a0a  ast, beam_idx):.
-00010540: 2020 2020 2020 2020 7265 6f72 6465 7265          reordere
-00010550: 645f 7061 7374 203d 2028 290a 2020 2020  d_past = ().    
-00010560: 2020 2020 666f 7220 6c61 7965 725f 7061      for layer_pa
-00010570: 7374 2069 6e20 7061 7374 3a0a 2020 2020  st in past:.    
-00010580: 2020 2020 2020 2020 7265 6f72 6465 7265          reordere
-00010590: 645f 7061 7374 202b 3d20 2874 7570 6c65  d_past += (tuple
-000105a0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-000105b0: 2020 7061 7374 5f73 7461 7465 2e69 6e64    past_state.ind
-000105c0: 6578 5f73 656c 6563 7428 302c 2062 6561  ex_select(0, bea
-000105d0: 6d5f 6964 7829 0a20 2020 2020 2020 2020  m_idx).         
-000105e0: 2020 2020 2020 2066 6f72 2070 6173 745f         for past_
-000105f0: 7374 6174 6520 696e 206c 6179 6572 5f70  state in layer_p
-00010600: 6173 7429 2c20 290a 2020 2020 2020 2020  ast), ).        
-00010610: 7265 7475 726e 2072 656f 7264 6572 6564  return reordered
-00010620: 5f70 6173 740a 0a0a 636c 6173 7320 4769  _past...class Gi
-00010630: 7342 6572 744c 4d50 7265 6469 6374 696f  sBertLMPredictio
-00010640: 6e48 6561 6428 6e6e 2e4d 6f64 756c 6529  nHead(nn.Module)
-00010650: 3a0a 0a20 2020 2064 6566 205f 5f69 6e69  :..    def __ini
-00010660: 745f 5f28 7365 6c66 2c20 636f 6e66 6967  t__(self, config
-00010670: 2c20 766f 6361 625f 7369 7a65 293a 0a20  , vocab_size):. 
-00010680: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-00010690: 5f69 6e69 745f 5f28 290a 2020 2020 2020  _init__().      
-000106a0: 2020 7365 6c66 2e74 7261 6e73 666f 726d    self.transform
-000106b0: 203d 2042 6572 7450 7265 6469 6374 696f   = BertPredictio
-000106c0: 6e48 6561 6454 7261 6e73 666f 726d 2863  nHeadTransform(c
-000106d0: 6f6e 6669 6729 0a0a 2020 2020 2020 2020  onfig)..        
-000106e0: 2320 5468 6520 6f75 7470 7574 2077 6569  # The output wei
-000106f0: 6768 7473 2061 7265 2074 6865 2073 616d  ghts are the sam
-00010700: 6520 6173 2074 6865 2069 6e70 7574 2065  e as the input e
-00010710: 6d62 6564 6469 6e67 732c 2062 7574 2074  mbeddings, but t
-00010720: 6865 7265 2069 730a 2020 2020 2020 2020  here is.        
-00010730: 2320 616e 206f 7574 7075 742d 6f6e 6c79  # an output-only
-00010740: 2062 6961 7320 666f 7220 6561 6368 2074   bias for each t
-00010750: 6f6b 656e 2e0a 2020 2020 2020 2020 7365  oken..        se
-00010760: 6c66 2e64 6563 6f64 6572 203d 206e 6e2e  lf.decoder = nn.
-00010770: 4c69 6e65 6172 2863 6f6e 6669 672e 6869  Linear(config.hi
-00010780: 6464 656e 5f73 697a 652c 2076 6f63 6162  dden_size, vocab
-00010790: 5f73 697a 652c 2062 6961 733d 4661 6c73  _size, bias=Fals
-000107a0: 6529 0a0a 2020 2020 2020 2020 7365 6c66  e)..        self
-000107b0: 2e62 6961 7320 3d20 6e6e 2e50 6172 616d  .bias = nn.Param
-000107c0: 6574 6572 2874 6f72 6368 2e7a 6572 6f73  eter(torch.zeros
-000107d0: 2876 6f63 6162 5f73 697a 6529 290a 0a20  (vocab_size)).. 
-000107e0: 2020 2020 2020 2023 204e 6565 6420 6120         # Need a 
-000107f0: 6c69 6e6b 2062 6574 7765 656e 2074 6865  link between the
-00010800: 2074 776f 2076 6172 6961 626c 6573 2073   two variables s
-00010810: 6f20 7468 6174 2074 6865 2062 6961 7320  o that the bias 
-00010820: 6973 2063 6f72 7265 6374 6c79 2072 6573  is correctly res
-00010830: 697a 6564 2077 6974 6820 6072 6573 697a  ized with `resiz
-00010840: 655f 746f 6b65 6e5f 656d 6265 6464 696e  e_token_embeddin
-00010850: 6773 600a 2020 2020 2020 2020 7365 6c66  gs`.        self
-00010860: 2e64 6563 6f64 6572 2e62 6961 7320 3d20  .decoder.bias = 
-00010870: 7365 6c66 2e62 6961 730a 0a20 2020 2064  self.bias..    d
-00010880: 6566 2066 6f72 7761 7264 2873 656c 662c  ef forward(self,
-00010890: 2068 6964 6465 6e5f 7374 6174 6573 293a   hidden_states):
-000108a0: 0a20 2020 2020 2020 2068 6964 6465 6e5f  .        hidden_
-000108b0: 7374 6174 6573 203d 2073 656c 662e 7472  states = self.tr
-000108c0: 616e 7366 6f72 6d28 6869 6464 656e 5f73  ansform(hidden_s
-000108d0: 7461 7465 7329 0a20 2020 2020 2020 2068  tates).        h
-000108e0: 6964 6465 6e5f 7374 6174 6573 203d 2073  idden_states = s
-000108f0: 656c 662e 6465 636f 6465 7228 6869 6464  elf.decoder(hidd
-00010900: 656e 5f73 7461 7465 7329 0a20 2020 2020  en_states).     
-00010910: 2020 2072 6574 7572 6e20 6869 6464 656e     return hidden
-00010920: 5f73 7461 7465 730a 0a0a 636c 6173 7320  _states...class 
-00010930: 4265 7274 466f 7247 6973 4d61 736b 6564  BertForGisMasked
-00010940: 4c4d 2842 6572 7450 7265 5472 6169 6e65  LM(BertPreTraine
-00010950: 644d 6f64 656c 293a 0a0a 2020 2020 5f6b  dModel):..    _k
-00010960: 6579 735f 746f 5f69 676e 6f72 655f 6f6e  eys_to_ignore_on
-00010970: 5f6c 6f61 645f 756e 6578 7065 6374 6564  _load_unexpected
-00010980: 203d 205b 7227 706f 6f6c 6572 275d 0a20   = [r'pooler']. 
-00010990: 2020 205f 6b65 7973 5f74 6f5f 6967 6e6f     _keys_to_igno
-000109a0: 7265 5f6f 6e5f 6c6f 6164 5f6d 6973 7369  re_on_load_missi
-000109b0: 6e67 203d 205b 0a20 2020 2020 2020 2072  ng = [.        r
-000109c0: 2770 6f73 6974 696f 6e5f 6964 7327 2c20  'position_ids', 
-000109d0: 7227 7072 6564 6963 7469 6f6e 732e 6465  r'predictions.de
-000109e0: 636f 6465 722e 6269 6173 270a 2020 2020  coder.bias'.    
-000109f0: 5d0a 0a20 2020 2064 6566 205f 5f69 6e69  ]..    def __ini
-00010a00: 745f 5f28 7365 6c66 2c20 636f 6e66 6967  t__(self, config
-00010a10: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
-00010a20: 2829 2e5f 5f69 6e69 745f 5f28 636f 6e66  ().__init__(conf
-00010a30: 6967 290a 2020 2020 2020 2020 7365 6c66  ig).        self
-00010a40: 2e62 6572 7420 3d20 4265 7274 4d6f 6465  .bert = BertMode
-00010a50: 6c28 636f 6e66 6967 2c20 6164 645f 706f  l(config, add_po
-00010a60: 6f6c 696e 675f 6c61 7965 723d 4661 6c73  oling_layer=Fals
-00010a70: 6529 0a20 2020 2020 2020 2073 656c 662e  e).        self.
-00010a80: 636c 735f 6765 6f6d 5f69 6420 3d20 4769  cls_geom_id = Gi
-00010a90: 7342 6572 744c 4d50 7265 6469 6374 696f  sBertLMPredictio
-00010aa0: 6e48 6561 6428 636f 6e66 6967 2c20 636f  nHead(config, co
-00010ab0: 6e66 6967 2e76 6f63 6162 5f73 697a 6529  nfig.vocab_size)
-00010ac0: 0a20 2020 2020 2020 2073 656c 662e 636c  .        self.cl
-00010ad0: 735f 6765 6f6d 5f74 7970 6520 3d20 4769  s_geom_type = Gi
-00010ae0: 7342 6572 744c 4d50 7265 6469 6374 696f  sBertLMPredictio
-00010af0: 6e48 6561 6428 636f 6e66 6967 2c0a 2020  nHead(config,.  
-00010b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b30: 2020 2063 6f6e 6669 672e 7479 7065 5f76     config.type_v
-00010b40: 6f63 6162 5f73 697a 6529 0a20 2020 2020  ocab_size).     
-00010b50: 2020 2073 656c 662e 636c 735f 7265 6c5f     self.cls_rel_
-00010b60: 7479 7065 203d 2047 6973 4265 7274 4c4d  type = GisBertLM
-00010b70: 5072 6564 6963 7469 6f6e 4865 6164 2863  PredictionHead(c
-00010b80: 6f6e 6669 672c 0a20 2020 2020 2020 2020  onfig,.         
-00010b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010bb0: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
-00010bc0: 672e 7265 6c5f 7479 7065 5f76 6f63 6162  g.rel_type_vocab
-00010bd0: 5f73 697a 6529 0a20 2020 2020 2020 2073  _size).        s
-00010be0: 656c 662e 636c 735f 6162 736f 6c75 7465  elf.cls_absolute
-00010bf0: 5f70 6f73 6974 696f 6e5f 7831 203d 2047  _position_x1 = G
-00010c00: 6973 4265 7274 4c4d 5072 6564 6963 7469  isBertLMPredicti
-00010c10: 6f6e 4865 6164 280a 2020 2020 2020 2020  onHead(.        
-00010c20: 2020 2020 636f 6e66 6967 2c20 636f 6e66      config, conf
-00010c30: 6967 2e61 6273 6f6c 7574 655f 785f 766f  ig.absolute_x_vo
-00010c40: 6361 625f 7369 7a65 290a 2020 2020 2020  cab_size).      
-00010c50: 2020 7365 6c66 2e63 6c73 5f61 6273 6f6c    self.cls_absol
-00010c60: 7574 655f 706f 7369 7469 6f6e 5f78 3220  ute_position_x2 
-00010c70: 3d20 4769 7342 6572 744c 4d50 7265 6469  = GisBertLMPredi
-00010c80: 6374 696f 6e48 6561 6428 0a20 2020 2020  ctionHead(.     
-00010c90: 2020 2020 2020 2063 6f6e 6669 672c 2063         config, c
-00010ca0: 6f6e 6669 672e 6162 736f 6c75 7465 5f78  onfig.absolute_x
-00010cb0: 5f76 6f63 6162 5f73 697a 6529 0a20 2020  _vocab_size).   
-00010cc0: 2020 2020 2073 656c 662e 636c 735f 6162       self.cls_ab
-00010cd0: 736f 6c75 7465 5f70 6f73 6974 696f 6e5f  solute_position_
-00010ce0: 7931 203d 2047 6973 4265 7274 4c4d 5072  y1 = GisBertLMPr
-00010cf0: 6564 6963 7469 6f6e 4865 6164 280a 2020  edictionHead(.  
-00010d00: 2020 2020 2020 2020 2020 636f 6e66 6967            config
-00010d10: 2c20 636f 6e66 6967 2e61 6273 6f6c 7574  , config.absolut
-00010d20: 655f 795f 766f 6361 625f 7369 7a65 290a  e_y_vocab_size).
-00010d30: 2020 2020 2020 2020 7365 6c66 2e63 6c73          self.cls
-00010d40: 5f61 6273 6f6c 7574 655f 706f 7369 7469  _absolute_positi
-00010d50: 6f6e 5f79 3220 3d20 4769 7342 6572 744c  on_y2 = GisBertL
-00010d60: 4d50 7265 6469 6374 696f 6e48 6561 6428  MPredictionHead(
-00010d70: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
-00010d80: 6669 672c 2063 6f6e 6669 672e 6162 736f  fig, config.abso
-00010d90: 6c75 7465 5f79 5f76 6f63 6162 5f73 697a  lute_y_vocab_siz
-00010da0: 6529 0a20 2020 2020 2020 2073 656c 662e  e).        self.
-00010db0: 636c 735f 7265 6c61 7469 7665 5f70 6f73  cls_relative_pos
-00010dc0: 6974 696f 6e5f 7831 203d 2047 6973 4265  ition_x1 = GisBe
-00010dd0: 7274 4c4d 5072 6564 6963 7469 6f6e 4865  rtLMPredictionHe
-00010de0: 6164 280a 2020 2020 2020 2020 2020 2020  ad(.            
-00010df0: 636f 6e66 6967 2c20 636f 6e66 6967 2e72  config, config.r
-00010e00: 656c 6174 6976 655f 785f 766f 6361 625f  elative_x_vocab_
-00010e10: 7369 7a65 290a 2020 2020 2020 2020 7365  size).        se
-00010e20: 6c66 2e63 6c73 5f72 656c 6174 6976 655f  lf.cls_relative_
-00010e30: 706f 7369 7469 6f6e 5f78 3220 3d20 4769  position_x2 = Gi
-00010e40: 7342 6572 744c 4d50 7265 6469 6374 696f  sBertLMPredictio
-00010e50: 6e48 6561 6428 0a20 2020 2020 2020 2020  nHead(.         
-00010e60: 2020 2063 6f6e 6669 672c 2063 6f6e 6669     config, confi
-00010e70: 672e 7265 6c61 7469 7665 5f78 5f76 6f63  g.relative_x_voc
-00010e80: 6162 5f73 697a 6529 0a20 2020 2020 2020  ab_size).       
-00010e90: 2073 656c 662e 636c 735f 7265 6c61 7469   self.cls_relati
-00010ea0: 7665 5f70 6f73 6974 696f 6e5f 7931 203d  ve_position_y1 =
-00010eb0: 2047 6973 4265 7274 4c4d 5072 6564 6963   GisBertLMPredic
-00010ec0: 7469 6f6e 4865 6164 280a 2020 2020 2020  tionHead(.      
-00010ed0: 2020 2020 2020 636f 6e66 6967 2c20 636f        config, co
-00010ee0: 6e66 6967 2e72 656c 6174 6976 655f 795f  nfig.relative_y_
-00010ef0: 766f 6361 625f 7369 7a65 290a 2020 2020  vocab_size).    
-00010f00: 2020 2020 7365 6c66 2e63 6c73 5f72 656c      self.cls_rel
-00010f10: 6174 6976 655f 706f 7369 7469 6f6e 5f79  ative_position_y
-00010f20: 3220 3d20 4769 7342 6572 744c 4d50 7265  2 = GisBertLMPre
-00010f30: 6469 6374 696f 6e48 6561 6428 0a20 2020  dictionHead(.   
-00010f40: 2020 2020 2020 2020 2063 6f6e 6669 672c           config,
-00010f50: 2063 6f6e 6669 672e 7265 6c61 7469 7665   config.relative
-00010f60: 5f79 5f76 6f63 6162 5f73 697a 6529 0a20  _y_vocab_size). 
-00010f70: 2020 2020 2020 2073 656c 662e 636f 6e66         self.conf
-00010f80: 6967 203d 2063 6f6e 6669 670a 0a20 2020  ig = config..   
-00010f90: 2020 2020 2073 656c 662e 696e 6974 5f77       self.init_w
-00010fa0: 6569 6768 7473 2829 0a0a 2020 2020 6465  eights()..    de
-00010fb0: 6620 666f 7277 6172 6428 0a20 2020 2020  f forward(.     
-00010fc0: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
-00010fd0: 2069 6e70 7574 5f69 6473 3d4e 6f6e 652c   input_ids=None,
-00010fe0: 0a20 2020 2020 2020 2061 7474 656e 7469  .        attenti
-00010ff0: 6f6e 5f6d 6173 6b3d 4e6f 6e65 2c0a 2020  on_mask=None,.  
-00011000: 2020 2020 2020 746f 6b65 6e5f 7479 7065        token_type
-00011010: 5f69 6473 3d4e 6f6e 652c 0a20 2020 2020  _ids=None,.     
-00011020: 2020 2070 6f73 6974 696f 6e5f 6964 733d     position_ids=
-00011030: 4e6f 6e65 2c0a 2020 2020 2020 2020 6865  None,.        he
-00011040: 6164 5f6d 6173 6b3d 4e6f 6e65 2c0a 2020  ad_mask=None,.  
-00011050: 2020 2020 2020 696e 7075 7473 5f65 6d62        inputs_emb
-00011060: 6564 733d 4e6f 6e65 2c0a 2020 2020 2020  eds=None,.      
-00011070: 2020 656e 636f 6465 725f 656d 6265 6473    encoder_embeds
-00011080: 3d4e 6f6e 652c 0a20 2020 2020 2020 2065  =None,.        e
-00011090: 6e63 6f64 6572 5f68 6964 6465 6e5f 7374  ncoder_hidden_st
-000110a0: 6174 6573 3d4e 6f6e 652c 0a20 2020 2020  ates=None,.     
-000110b0: 2020 2065 6e63 6f64 6572 5f61 7474 656e     encoder_atten
-000110c0: 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65 2c0a  tion_mask=None,.
-000110d0: 2020 2020 2020 2020 6c61 6265 6c73 3d4e          labels=N
-000110e0: 6f6e 652c 0a20 2020 2020 2020 206f 7574  one,.        out
-000110f0: 7075 745f 6174 7465 6e74 696f 6e73 3d4e  put_attentions=N
-00011100: 6f6e 652c 0a20 2020 2020 2020 206f 7574  one,.        out
-00011110: 7075 745f 6869 6464 656e 5f73 7461 7465  put_hidden_state
-00011120: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
-00011130: 7265 7475 726e 5f64 6963 743d 4e6f 6e65  return_dict=None
-00011140: 2c0a 2020 2020 2020 2020 6973 5f64 6563  ,.        is_dec
-00011150: 6f64 6572 3d46 616c 7365 2c0a 2020 2020  oder=False,.    
-00011160: 2020 2020 6d6f 6465 3d27 6d75 6c74 695f      mode='multi_
-00011170: 6d6f 6461 6c27 2c0a 2020 2020 2020 2020  modal',.        
-00011180: 736f 6674 5f6c 6162 656c 733d 4e6f 6e65  soft_labels=None
-00011190: 2c0a 2020 2020 2020 2020 616c 7068 613d  ,.        alpha=
-000111a0: 302c 0a20 2020 2020 2020 2072 6574 7572  0,.        retur
-000111b0: 6e5f 6c6f 6769 7473 3d46 616c 7365 2c0a  n_logits=False,.
-000111c0: 2020 2020 2020 2020 7265 6c5f 7479 7065          rel_type
-000111d0: 5f69 6473 3d4e 6f6e 652c 0a20 2020 2020  _ids=None,.     
-000111e0: 2020 2061 6273 6f6c 7574 655f 706f 7369     absolute_posi
-000111f0: 7469 6f6e 5f69 6473 3d4e 6f6e 652c 0a20  tion_ids=None,. 
-00011200: 2020 2020 2020 2072 656c 6174 6976 655f         relative_
-00011210: 706f 7369 7469 6f6e 5f69 6473 3d4e 6f6e  position_ids=Non
-00011220: 652c 0a20 2020 2020 2020 2074 6f6b 656e  e,.        token
-00011230: 5f74 7970 655f 6964 735f 6c61 6265 6c3d  _type_ids_label=
-00011240: 4e6f 6e65 2c0a 2020 2020 2020 2020 7265  None,.        re
-00011250: 6c5f 7479 7065 5f69 6473 5f6c 6162 656c  l_type_ids_label
-00011260: 3d4e 6f6e 652c 0a20 2020 2020 2020 2061  =None,.        a
-00011270: 6273 6f6c 7574 655f 706f 7369 7469 6f6e  bsolute_position
-00011280: 5f69 6473 5f6c 6162 656c 3d4e 6f6e 652c  _ids_label=None,
-00011290: 0a20 2020 2020 2020 2072 656c 6174 6976  .        relativ
-000112a0: 655f 706f 7369 7469 6f6e 5f69 6473 5f6c  e_position_ids_l
-000112b0: 6162 656c 3d4e 6f6e 652c 0a20 2020 2029  abel=None,.    )
-000112c0: 3a0a 2020 2020 2020 2020 7222 2222 0a20  :.        r""". 
-000112d0: 2020 2020 2020 206c 6162 656c 7320 283a         labels (:
-000112e0: 6f62 6a3a 6074 6f72 6368 2e4c 6f6e 6754  obj:`torch.LongT
-000112f0: 656e 736f 7260 206f 6620 7368 6170 6520  ensor` of shape 
-00011300: 3a6f 626a 3a60 2862 6174 6368 5f73 697a  :obj:`(batch_siz
-00011310: 652c 0a20 2020 2020 2020 2073 6571 7565  e,.        seque
-00011320: 6e63 655f 6c65 6e67 7468 2960 2c20 606f  nce_length)`, `o
-00011330: 7074 696f 6e61 6c60 293a 0a20 2020 2020  ptional`):.     
-00011340: 2020 2020 2020 204c 6162 656c 7320 666f         Labels fo
-00011350: 7220 636f 6d70 7574 696e 6720 7468 6520  r computing the 
-00011360: 6d61 736b 6564 206c 616e 6775 6167 6520  masked language 
-00011370: 6d6f 6465 6c69 6e67 206c 6f73 732e 2049  modeling loss. I
-00011380: 6e64 6963 6573 0a20 2020 2020 2020 2020  ndices.         
-00011390: 2020 2073 686f 756c 6420 6265 2069 6e20     should be in 
-000113a0: 6060 5b2d 3130 302c 2030 2c20 2e2e 2e2c  ``[-100, 0, ...,
-000113b0: 2063 6f6e 6669 672e 766f 6361 625f 7369   config.vocab_si
-000113c0: 7a65 5d60 6020 2873 6565 0a20 2020 2020  ze]`` (see.     
-000113d0: 2020 2020 2020 2060 6069 6e70 7574 5f69         ``input_i
-000113e0: 6473 6060 2064 6f63 7374 7269 6e67 2920  ds`` docstring) 
-000113f0: 546f 6b65 6e73 2077 6974 6820 696e 6469  Tokens with indi
-00011400: 6365 7320 7365 7420 746f 2060 602d 3130  ces set to ``-10
-00011410: 3060 6020 6172 650a 2020 2020 2020 2020  0`` are.        
-00011420: 2020 2020 6967 6e6f 7265 6420 286d 6173      ignored (mas
-00011430: 6b65 6429 2c20 7468 6520 6c6f 7373 2069  ked), the loss i
-00011440: 7320 6f6e 6c79 2063 6f6d 7075 7465 6420  s only computed 
-00011450: 666f 7220 7468 6520 746f 6b65 6e73 2077  for the tokens w
-00011460: 6974 680a 2020 2020 2020 2020 2020 2020  ith.            
-00011470: 6c61 6265 6c73 2069 6e20 6060 5b30 2c20  labels in ``[0, 
-00011480: 2e2e 2e2c 2063 6f6e 6669 672e 766f 6361  ..., config.voca
-00011490: 625f 7369 7a65 5d60 600a 2020 2020 2020  b_size]``.      
-000114a0: 2020 2222 220a 0a20 2020 2020 2020 2072    """..        r
-000114b0: 6574 7572 6e5f 6469 6374 203d 2072 6574  eturn_dict = ret
-000114c0: 7572 6e5f 6469 6374 2069 6620 7265 7475  urn_dict if retu
-000114d0: 726e 5f64 6963 7420 6973 206e 6f74 204e  rn_dict is not N
-000114e0: 6f6e 6520 656c 7365 2073 656c 662e 636f  one else self.co
-000114f0: 6e66 6967 2e75 7365 5f72 6574 7572 6e5f  nfig.use_return_
-00011500: 6469 6374 0a0a 2020 2020 2020 2020 6f75  dict..        ou
-00011510: 7470 7574 7320 3d20 7365 6c66 2e62 6572  tputs = self.ber
-00011520: 7428 0a20 2020 2020 2020 2020 2020 2069  t(.            i
-00011530: 6e70 7574 5f69 6473 2c0a 2020 2020 2020  nput_ids,.      
-00011540: 2020 2020 2020 6174 7465 6e74 696f 6e5f        attention_
-00011550: 6d61 736b 3d61 7474 656e 7469 6f6e 5f6d  mask=attention_m
-00011560: 6173 6b2c 0a20 2020 2020 2020 2020 2020  ask,.           
-00011570: 2074 6f6b 656e 5f74 7970 655f 6964 733d   token_type_ids=
-00011580: 746f 6b65 6e5f 7479 7065 5f69 6473 2c0a  token_type_ids,.
-00011590: 2020 2020 2020 2020 2020 2020 706f 7369              posi
-000115a0: 7469 6f6e 5f69 6473 3d70 6f73 6974 696f  tion_ids=positio
-000115b0: 6e5f 6964 732c 0a20 2020 2020 2020 2020  n_ids,.         
-000115c0: 2020 2068 6561 645f 6d61 736b 3d68 6561     head_mask=hea
-000115d0: 645f 6d61 736b 2c0a 2020 2020 2020 2020  d_mask,.        
-000115e0: 2020 2020 696e 7075 7473 5f65 6d62 6564      inputs_embed
-000115f0: 733d 696e 7075 7473 5f65 6d62 6564 732c  s=inputs_embeds,
-00011600: 0a20 2020 2020 2020 2020 2020 2065 6e63  .            enc
-00011610: 6f64 6572 5f65 6d62 6564 733d 656e 636f  oder_embeds=enco
-00011620: 6465 725f 656d 6265 6473 2c0a 2020 2020  der_embeds,.    
-00011630: 2020 2020 2020 2020 656e 636f 6465 725f          encoder_
-00011640: 6869 6464 656e 5f73 7461 7465 733d 656e  hidden_states=en
-00011650: 636f 6465 725f 6869 6464 656e 5f73 7461  coder_hidden_sta
-00011660: 7465 732c 0a20 2020 2020 2020 2020 2020  tes,.           
-00011670: 2065 6e63 6f64 6572 5f61 7474 656e 7469   encoder_attenti
-00011680: 6f6e 5f6d 6173 6b3d 656e 636f 6465 725f  on_mask=encoder_
-00011690: 6174 7465 6e74 696f 6e5f 6d61 736b 2c0a  attention_mask,.
-000116a0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-000116b0: 7574 5f61 7474 656e 7469 6f6e 733d 6f75  ut_attentions=ou
-000116c0: 7470 7574 5f61 7474 656e 7469 6f6e 732c  tput_attentions,
-000116d0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-000116e0: 7075 745f 6869 6464 656e 5f73 7461 7465  put_hidden_state
-000116f0: 733d 6f75 7470 7574 5f68 6964 6465 6e5f  s=output_hidden_
-00011700: 7374 6174 6573 2c0a 2020 2020 2020 2020  states,.        
-00011710: 2020 2020 7265 7475 726e 5f64 6963 743d      return_dict=
-00011720: 7265 7475 726e 5f64 6963 742c 0a20 2020  return_dict,.   
-00011730: 2020 2020 2020 2020 2069 735f 6465 636f           is_deco
-00011740: 6465 723d 6973 5f64 6563 6f64 6572 2c0a  der=is_decoder,.
-00011750: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
-00011760: 3d6d 6f64 652c 0a20 2020 2020 2020 2020  =mode,.         
-00011770: 2020 2072 656c 5f74 7970 655f 6964 733d     rel_type_ids=
-00011780: 7265 6c5f 7479 7065 5f69 6473 2c0a 2020  rel_type_ids,.  
-00011790: 2020 2020 2020 2020 2020 6162 736f 6c75            absolu
-000117a0: 7465 5f70 6f73 6974 696f 6e5f 6964 733d  te_position_ids=
-000117b0: 6162 736f 6c75 7465 5f70 6f73 6974 696f  absolute_positio
-000117c0: 6e5f 6964 732c 0a20 2020 2020 2020 2020  n_ids,.         
-000117d0: 2020 2072 656c 6174 6976 655f 706f 7369     relative_posi
-000117e0: 7469 6f6e 5f69 6473 3d72 656c 6174 6976  tion_ids=relativ
-000117f0: 655f 706f 7369 7469 6f6e 5f69 6473 2c0a  e_position_ids,.
-00011800: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
-00011810: 2020 2073 6571 7565 6e63 655f 6f75 7470     sequence_outp
-00011820: 7574 203d 206f 7574 7075 7473 5b30 5d0a  ut = outputs[0].
-00011830: 0a20 2020 2020 2020 2070 7265 6469 6374  .        predict
-00011840: 696f 6e5f 7363 6f72 6573 203d 2073 656c  ion_scores = sel
-00011850: 662e 636c 735f 6765 6f6d 5f69 6428 7365  f.cls_geom_id(se
-00011860: 7175 656e 6365 5f6f 7574 7075 7429 0a20  quence_output). 
-00011870: 2020 2020 2020 206c 6f73 735f 6663 7420         loss_fct 
-00011880: 3d20 4372 6f73 7345 6e74 726f 7079 4c6f  = CrossEntropyLo
-00011890: 7373 2829 2020 2320 2d31 3030 2069 6e64  ss()  # -100 ind
-000118a0: 6578 203d 2070 6164 6469 6e67 2074 6f6b  ex = padding tok
-000118b0: 656e 0a20 2020 2020 2020 206d 6173 6b65  en.        maske
-000118c0: 645f 6c6d 5f6c 6f73 7320 3d20 6c6f 7373  d_lm_loss = loss
-000118d0: 5f66 6374 280a 2020 2020 2020 2020 2020  _fct(.          
-000118e0: 2020 7072 6564 6963 7469 6f6e 5f73 636f    prediction_sco
-000118f0: 7265 732e 7669 6577 282d 312c 2073 656c  res.view(-1, sel
-00011900: 662e 636f 6e66 6967 2e76 6f63 6162 5f73  f.config.vocab_s
-00011910: 697a 6529 2c0a 2020 2020 2020 2020 2020  ize),.          
-00011920: 2020 6c61 6265 6c73 2e76 6965 7728 2d31    labels.view(-1
-00011930: 2929 0a0a 2020 2020 2020 2020 706f 7369  ))..        posi
-00011940: 7469 6f6e 735f 636c 7320 3d20 5b0a 2020  tions_cls = [.  
-00011950: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
-00011960: 6c73 5f67 656f 6d5f 7479 7065 2c20 7365  ls_geom_type, se
-00011970: 6c66 2e63 6c73 5f72 656c 5f74 7970 652c  lf.cls_rel_type,
-00011980: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00011990: 662e 636c 735f 6162 736f 6c75 7465 5f70  f.cls_absolute_p
-000119a0: 6f73 6974 696f 6e5f 7831 2c20 7365 6c66  osition_x1, self
-000119b0: 2e63 6c73 5f61 6273 6f6c 7574 655f 706f  .cls_absolute_po
-000119c0: 7369 7469 6f6e 5f78 322c 0a20 2020 2020  sition_x2,.     
-000119d0: 2020 2020 2020 2073 656c 662e 636c 735f         self.cls_
-000119e0: 6162 736f 6c75 7465 5f70 6f73 6974 696f  absolute_positio
-000119f0: 6e5f 7931 2c20 7365 6c66 2e63 6c73 5f61  n_y1, self.cls_a
-00011a00: 6273 6f6c 7574 655f 706f 7369 7469 6f6e  bsolute_position
-00011a10: 5f79 322c 0a20 2020 2020 2020 2020 2020  _y2,.           
-00011a20: 2073 656c 662e 636c 735f 7265 6c61 7469   self.cls_relati
-00011a30: 7665 5f70 6f73 6974 696f 6e5f 7831 2c20  ve_position_x1, 
-00011a40: 7365 6c66 2e63 6c73 5f72 656c 6174 6976  self.cls_relativ
-00011a50: 655f 706f 7369 7469 6f6e 5f78 322c 0a20  e_position_x2,. 
-00011a60: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00011a70: 636c 735f 7265 6c61 7469 7665 5f70 6f73  cls_relative_pos
-00011a80: 6974 696f 6e5f 7931 2c20 7365 6c66 2e63  ition_y1, self.c
-00011a90: 6c73 5f72 656c 6174 6976 655f 706f 7369  ls_relative_posi
-00011aa0: 7469 6f6e 5f79 320a 2020 2020 2020 2020  tion_y2.        
-00011ab0: 5d0a 2020 2020 2020 2020 706f 7369 7469  ].        positi
-00011ac0: 6f6e 735f 6c61 6265 6c20 3d20 5b0a 2020  ons_label = [.  
-00011ad0: 2020 2020 2020 2020 2020 746f 6b65 6e5f            token_
-00011ae0: 7479 7065 5f69 6473 5f6c 6162 656c 2c20  type_ids_label, 
-00011af0: 7265 6c5f 7479 7065 5f69 6473 5f6c 6162  rel_type_ids_lab
-00011b00: 656c 2c0a 2020 2020 2020 2020 2020 2020  el,.            
-00011b10: 6162 736f 6c75 7465 5f70 6f73 6974 696f  absolute_positio
-00011b20: 6e5f 6964 735f 6c61 6265 6c5b 3a2c 203a  n_ids_label[:, :
-00011b30: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00011b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011b50: 2020 2020 2020 2020 2020 305d 2c20 6162            0], ab
-00011b60: 736f 6c75 7465 5f70 6f73 6974 696f 6e5f  solute_position_
-00011b70: 6964 735f 6c61 6265 6c5b 3a2c 203a 2c0a  ids_label[:, :,.
-00011b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011bc0: 2020 2020 2020 2020 325d 2c0a 2020 2020          2],.    
-00011bd0: 2020 2020 2020 2020 6162 736f 6c75 7465          absolute
-00011be0: 5f70 6f73 6974 696f 6e5f 6964 735f 6c61  _position_ids_la
-00011bf0: 6265 6c5b 3a2c 203a 2c0a 2020 2020 2020  bel[:, :,.      
-00011c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a830: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a850: 2020 2020 2020 204e 6f6e 652c 203a 5d0a         None, :].
+0000a860: 2020 2020 2020 2020 2020 2020 656c 7365              else
+0000a870: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000a880: 2020 6578 7465 6e64 6564 5f61 7474 656e    extended_atten
+0000a890: 7469 6f6e 5f6d 6173 6b20 3d20 6174 7465  tion_mask = atte
+0000a8a0: 6e74 696f 6e5f 6d61 736b 5b3a 2c20 4e6f  ntion_mask[:, No
+0000a8b0: 6e65 2c20 4e6f 6e65 2c20 3a5d 0a20 2020  ne, None, :].   
+0000a8c0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0000a8d0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+0000a8e0: 7565 4572 726f 7228 0a20 2020 2020 2020  ueError(.       
+0000a8f0: 2020 2020 2020 2020 2027 5772 6f6e 6720           'Wrong 
+0000a900: 7368 6170 6520 666f 7220 696e 7075 745f  shape for input_
+0000a910: 6964 7320 2873 6861 7065 207b 7d29 206f  ids (shape {}) o
+0000a920: 7220 6174 7465 6e74 696f 6e5f 6d61 736b  r attention_mask
+0000a930: 2028 7368 6170 6520 7b7d 2927 0a20 2020   (shape {})'.   
+0000a940: 2020 2020 2020 2020 2020 2020 202e 666f               .fo
+0000a950: 726d 6174 2869 6e70 7574 5f73 6861 7065  rmat(input_shape
+0000a960: 2c20 6174 7465 6e74 696f 6e5f 6d61 736b  , attention_mask
+0000a970: 2e73 6861 7065 2929 0a0a 2020 2020 2020  .shape))..      
+0000a980: 2020 2320 5369 6e63 6520 6174 7465 6e74    # Since attent
+0000a990: 696f 6e5f 6d61 736b 2069 7320 312e 3020  ion_mask is 1.0 
+0000a9a0: 666f 7220 706f 7369 7469 6f6e 7320 7765  for positions we
+0000a9b0: 2077 616e 7420 746f 2061 7474 656e 6420   want to attend 
+0000a9c0: 616e 6420 302e 300a 2020 2020 2020 2020  and 0.0.        
+0000a9d0: 2320 666f 7220 6d61 736b 6564 2070 6f73  # for masked pos
+0000a9e0: 6974 696f 6e73 2c20 7468 6973 206f 7065  itions, this ope
+0000a9f0: 7261 7469 6f6e 2077 696c 6c20 6372 6561  ration will crea
+0000aa00: 7465 2061 2074 656e 736f 7220 7768 6963  te a tensor whic
+0000aa10: 6820 6973 2030 2e30 0a20 2020 2020 2020  h is 0.0.       
+0000aa20: 2023 2066 6f72 2070 6f73 6974 696f 6e73   # for positions
+0000aa30: 2077 6520 7761 6e74 2074 6f20 6174 7465   we want to atte
+0000aa40: 6e64 2061 6e64 202d 3130 3030 302e 3020  nd and -10000.0 
+0000aa50: 666f 7220 6d61 736b 6564 2070 6f73 6974  for masked posit
+0000aa60: 696f 6e73 2e0a 2020 2020 2020 2020 2320  ions..        # 
+0000aa70: 5369 6e63 6520 7765 2061 7265 2061 6464  Since we are add
+0000aa80: 696e 6720 6974 2074 6f20 7468 6520 7261  ing it to the ra
+0000aa90: 7720 7363 6f72 6573 2062 6566 6f72 6520  w scores before 
+0000aaa0: 7468 6520 736f 6674 6d61 782c 2074 6869  the softmax, thi
+0000aab0: 7320 6973 0a20 2020 2020 2020 2023 2065  s is.        # e
+0000aac0: 6666 6563 7469 7665 6c79 2074 6865 2073  ffectively the s
+0000aad0: 616d 6520 6173 2072 656d 6f76 696e 6720  ame as removing 
+0000aae0: 7468 6573 6520 656e 7469 7265 6c79 2e0a  these entirely..
+0000aaf0: 2020 2020 2020 2020 6578 7465 6e64 6564          extended
+0000ab00: 5f61 7474 656e 7469 6f6e 5f6d 6173 6b20  _attention_mask 
+0000ab10: 3d20 6578 7465 6e64 6564 5f61 7474 656e  = extended_atten
+0000ab20: 7469 6f6e 5f6d 6173 6b2e 746f 280a 2020  tion_mask.to(.  
+0000ab30: 2020 2020 2020 2020 2020 6474 7970 653d            dtype=
+0000ab40: 7365 6c66 2e64 7479 7065 2920 2023 2066  self.dtype)  # f
+0000ab50: 7031 3620 636f 6d70 6174 6962 696c 6974  p16 compatibilit
+0000ab60: 790a 2020 2020 2020 2020 6578 7465 6e64  y.        extend
+0000ab70: 6564 5f61 7474 656e 7469 6f6e 5f6d 6173  ed_attention_mas
+0000ab80: 6b20 3d20 2831 2e30 202d 2065 7874 656e  k = (1.0 - exten
+0000ab90: 6465 645f 6174 7465 6e74 696f 6e5f 6d61  ded_attention_ma
+0000aba0: 736b 2920 2a20 2d31 3030 3030 2e30 0a20  sk) * -10000.0. 
+0000abb0: 2020 2020 2020 2072 6574 7572 6e20 6578         return ex
+0000abc0: 7465 6e64 6564 5f61 7474 656e 7469 6f6e  tended_attention
+0000abd0: 5f6d 6173 6b0a 0a20 2020 2064 6566 2066  _mask..    def f
+0000abe0: 6f72 7761 7264 280a 2020 2020 2020 2020  orward(.        
+0000abf0: 7365 6c66 2c0a 2020 2020 2020 2020 696e  self,.        in
+0000ac00: 7075 745f 6964 733d 4e6f 6e65 2c0a 2020  put_ids=None,.  
+0000ac10: 2020 2020 2020 6174 7465 6e74 696f 6e5f        attention_
+0000ac20: 6d61 736b 3d4e 6f6e 652c 0a20 2020 2020  mask=None,.     
+0000ac30: 2020 2074 6f6b 656e 5f74 7970 655f 6964     token_type_id
+0000ac40: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
+0000ac50: 706f 7369 7469 6f6e 5f69 6473 3d4e 6f6e  position_ids=Non
+0000ac60: 652c 0a20 2020 2020 2020 2068 6561 645f  e,.        head_
+0000ac70: 6d61 736b 3d4e 6f6e 652c 0a20 2020 2020  mask=None,.     
+0000ac80: 2020 2069 6e70 7574 735f 656d 6265 6473     inputs_embeds
+0000ac90: 3d4e 6f6e 652c 0a20 2020 2020 2020 2065  =None,.        e
+0000aca0: 6e63 6f64 6572 5f65 6d62 6564 733d 4e6f  ncoder_embeds=No
+0000acb0: 6e65 2c0a 2020 2020 2020 2020 656e 636f  ne,.        enco
+0000acc0: 6465 725f 6869 6464 656e 5f73 7461 7465  der_hidden_state
+0000acd0: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
+0000ace0: 656e 636f 6465 725f 6174 7465 6e74 696f  encoder_attentio
+0000acf0: 6e5f 6d61 736b 3d4e 6f6e 652c 0a20 2020  n_mask=None,.   
+0000ad00: 2020 2020 2070 6173 745f 6b65 795f 7661       past_key_va
+0000ad10: 6c75 6573 3d4e 6f6e 652c 0a20 2020 2020  lues=None,.     
+0000ad20: 2020 2075 7365 5f63 6163 6865 3d4e 6f6e     use_cache=Non
+0000ad30: 652c 0a20 2020 2020 2020 206f 7574 7075  e,.        outpu
+0000ad40: 745f 6174 7465 6e74 696f 6e73 3d4e 6f6e  t_attentions=Non
+0000ad50: 652c 0a20 2020 2020 2020 206f 7574 7075  e,.        outpu
+0000ad60: 745f 6869 6464 656e 5f73 7461 7465 733d  t_hidden_states=
+0000ad70: 4e6f 6e65 2c0a 2020 2020 2020 2020 7265  None,.        re
+0000ad80: 7475 726e 5f64 6963 743d 4e6f 6e65 2c0a  turn_dict=None,.
+0000ad90: 2020 2020 2020 2020 6973 5f64 6563 6f64          is_decod
+0000ada0: 6572 3d46 616c 7365 2c0a 2020 2020 2020  er=False,.      
+0000adb0: 2020 6d6f 6465 3d27 6d75 6c74 695f 6d6f    mode='multi_mo
+0000adc0: 6461 6c27 2c0a 2020 2020 2020 2020 7265  dal',.        re
+0000add0: 6c5f 7479 7065 5f69 6473 3d4e 6f6e 652c  l_type_ids=None,
+0000ade0: 0a20 2020 2020 2020 2061 6273 6f6c 7574  .        absolut
+0000adf0: 655f 706f 7369 7469 6f6e 5f69 6473 3d4e  e_position_ids=N
+0000ae00: 6f6e 652c 0a20 2020 2020 2020 2072 656c  one,.        rel
+0000ae10: 6174 6976 655f 706f 7369 7469 6f6e 5f69  ative_position_i
+0000ae20: 6473 3d4e 6f6e 652c 0a20 2020 2020 2020  ds=None,.       
+0000ae30: 2070 726f 765f 6964 733d 4e6f 6e65 2c0a   prov_ids=None,.
+0000ae40: 2020 2020 2020 2020 6369 7479 5f69 6473          city_ids
+0000ae50: 3d4e 6f6e 652c 0a20 2020 2020 2020 2064  =None,.        d
+0000ae60: 6973 745f 6964 733d 4e6f 6e65 2c0a 2020  ist_ids=None,.  
+0000ae70: 2020 293a 0a20 2020 2020 2020 2072 2222    ):.        r""
+0000ae80: 220a 2020 2020 2020 2020 4172 6773 3a0a  ".        Args:.
+0000ae90: 2020 2020 2020 2020 696e 7075 745f 6964          input_id
+0000aea0: 7320 2860 746f 7263 682e 4c6f 6e67 5465  s (`torch.LongTe
+0000aeb0: 6e73 6f72 6020 6f66 2073 6861 7065 2060  nsor` of shape `
+0000aec0: 2828 6261 7463 685f 7369 7a65 2c20 7365  ((batch_size, se
+0000aed0: 7175 656e 6365 5f6c 656e 6774 6829 6029  quence_length)`)
+0000aee0: 3a0a 2020 2020 2020 2020 2020 2020 496e  :.            In
+0000aef0: 6469 6365 7320 6f66 2069 6e70 7574 2073  dices of input s
+0000af00: 6571 7565 6e63 6520 746f 6b65 6e73 2069  equence tokens i
+0000af10: 6e20 7468 6520 766f 6361 6275 6c61 7279  n the vocabulary
+0000af20: 2e0a 0a20 2020 2020 2020 2020 2020 2049  ...            I
+0000af30: 6e64 6963 6573 2063 616e 2062 6520 6f62  ndices can be ob
+0000af40: 7461 696e 6564 2075 7369 6e67 205b 6042  tained using [`B
+0000af50: 6572 7454 6f6b 656e 697a 6572 605d 2e20  ertTokenizer`]. 
+0000af60: 5365 650a 2020 2020 2020 2020 2020 2020  See.            
+0000af70: 5b60 5072 6554 7261 696e 6564 546f 6b65  [`PreTrainedToke
+0000af80: 6e69 7a65 722e 656e 636f 6465 605d 2061  nizer.encode`] a
+0000af90: 6e64 205b 6050 7265 5472 6169 6e65 6454  nd [`PreTrainedT
+0000afa0: 6f6b 656e 697a 6572 2e5f 5f63 616c 6c5f  okenizer.__call_
+0000afb0: 5f60 5d0a 2020 2020 2020 2020 2020 2020  _`].            
+0000afc0: 666f 7220 6465 7461 696c 732e 0a0a 2020  for details...  
+0000afd0: 2020 2020 2020 2020 2020 5b57 6861 7420            [What 
+0000afe0: 6172 6520 696e 7075 7420 4944 733f 5d28  are input IDs?](
+0000aff0: 2e2e 2f67 6c6f 7373 6172 7923 696e 7075  ../glossary#inpu
+0000b000: 742d 6964 7329 0a20 2020 2020 2020 2061  t-ids).        a
+0000b010: 7474 656e 7469 6f6e 5f6d 6173 6b20 2860  ttention_mask (`
+0000b020: 746f 7263 682e 466c 6f61 7454 656e 736f  torch.FloatTenso
+0000b030: 7260 206f 6620 7368 6170 6520 6028 2862  r` of shape `((b
+0000b040: 6174 6368 5f73 697a 652c 2073 6571 7565  atch_size, seque
+0000b050: 6e63 655f 6c65 6e67 7468 2960 2c20 2a6f  nce_length)`, *o
+0000b060: 7074 696f 6e61 6c2a 293a 0a20 2020 2020  ptional*):.     
+0000b070: 2020 2020 2020 204d 6173 6b20 746f 2061         Mask to a
+0000b080: 766f 6964 2070 6572 666f 726d 696e 6720  void performing 
+0000b090: 6174 7465 6e74 696f 6e20 6f6e 2070 6164  attention on pad
+0000b0a0: 6469 6e67 2074 6f6b 656e 2069 6e64 6963  ding token indic
+0000b0b0: 6573 2e20 4d61 736b 0a20 2020 2020 2020  es. Mask.       
+0000b0c0: 2020 2020 2076 616c 7565 7320 7365 6c65       values sele
+0000b0d0: 6374 6564 2069 6e20 605b 302c 2031 5d60  cted in `[0, 1]`
+0000b0e0: 3a0a 0a20 2020 2020 2020 2020 2020 202d  :..            -
+0000b0f0: 2031 2066 6f72 2074 6f6b 656e 7320 7468   1 for tokens th
+0000b100: 6174 2061 7265 202a 2a6e 6f74 206d 6173  at are **not mas
+0000b110: 6b65 642a 2a2c 0a20 2020 2020 2020 2020  ked**,.         
+0000b120: 2020 202d 2030 2066 6f72 2074 6f6b 656e     - 0 for token
+0000b130: 7320 7468 6174 2061 7265 202a 2a6d 6173  s that are **mas
+0000b140: 6b65 642a 2a2e 0a0a 2020 2020 2020 2020  ked**...        
+0000b150: 2020 2020 5b57 6861 7420 6172 6520 6174      [What are at
+0000b160: 7465 6e74 696f 6e20 6d61 736b 733f 5d28  tention masks?](
+0000b170: 2e2e 2f67 6c6f 7373 6172 7923 6174 7465  ../glossary#atte
+0000b180: 6e74 696f 6e2d 6d61 736b 290a 2020 2020  ntion-mask).    
+0000b190: 2020 2020 746f 6b65 6e5f 7479 7065 5f69      token_type_i
+0000b1a0: 6473 2028 6074 6f72 6368 2e4c 6f6e 6754  ds (`torch.LongT
+0000b1b0: 656e 736f 7260 206f 6620 7368 6170 6520  ensor` of shape 
+0000b1c0: 6028 2862 6174 6368 5f73 697a 652c 2073  `((batch_size, s
+0000b1d0: 6571 7565 6e63 655f 6c65 6e67 7468 2960  equence_length)`
+0000b1e0: 2c20 2a6f 7074 696f 6e61 6c2a 293a 0a20  , *optional*):. 
+0000b1f0: 2020 2020 2020 2020 2020 2053 6567 6d65             Segme
+0000b200: 6e74 2074 6f6b 656e 2069 6e64 6963 6573  nt token indices
+0000b210: 2074 6f20 696e 6469 6361 7465 2066 6972   to indicate fir
+0000b220: 7374 2061 6e64 2073 6563 6f6e 6420 706f  st and second po
+0000b230: 7274 696f 6e73 206f 6620 7468 650a 2020  rtions of the.  
+0000b240: 2020 2020 2020 2020 2020 696e 7075 7473            inputs
+0000b250: 2e20 496e 6469 6365 7320 6172 6520 7365  . Indices are se
+0000b260: 6c65 6374 6564 2069 6e20 605b 302c 2031  lected in `[0, 1
+0000b270: 5d60 3a0a 0a20 2020 2020 2020 2020 2020  ]`:..           
+0000b280: 202d 2030 2063 6f72 7265 7370 6f6e 6473   - 0 corresponds
+0000b290: 2074 6f20 6120 2a73 656e 7465 6e63 6520   to a *sentence 
+0000b2a0: 412a 2074 6f6b 656e 2c0a 2020 2020 2020  A* token,.      
+0000b2b0: 2020 2020 2020 2d20 3120 636f 7272 6573        - 1 corres
+0000b2c0: 706f 6e64 7320 746f 2061 202a 7365 6e74  ponds to a *sent
+0000b2d0: 656e 6365 2042 2a20 746f 6b65 6e2e 0a0a  ence B* token...
+0000b2e0: 2020 2020 2020 2020 2020 2020 5b57 6861              [Wha
+0000b2f0: 7420 6172 6520 746f 6b65 6e20 7479 7065  t are token type
+0000b300: 2049 4473 3f5d 282e 2e2f 676c 6f73 7361   IDs?](../glossa
+0000b310: 7279 2374 6f6b 656e 2d74 7970 652d 6964  ry#token-type-id
+0000b320: 7329 0a20 2020 2020 2020 2070 6f73 6974  s).        posit
+0000b330: 696f 6e5f 6964 7320 2860 746f 7263 682e  ion_ids (`torch.
+0000b340: 4c6f 6e67 5465 6e73 6f72 6020 6f66 2073  LongTensor` of s
+0000b350: 6861 7065 2060 2828 6261 7463 685f 7369  hape `((batch_si
+0000b360: 7a65 2c20 7365 7175 656e 6365 5f6c 656e  ze, sequence_len
+0000b370: 6774 6829 602c 202a 6f70 7469 6f6e 616c  gth)`, *optional
+0000b380: 2a29 3a0a 2020 2020 2020 2020 2020 2020  *):.            
+0000b390: 496e 6469 6365 7320 6f66 2070 6f73 6974  Indices of posit
+0000b3a0: 696f 6e73 206f 6620 6561 6368 2069 6e70  ions of each inp
+0000b3b0: 7574 2073 6571 7565 6e63 6520 746f 6b65  ut sequence toke
+0000b3c0: 6e73 2069 6e20 7468 6520 706f 7369 7469  ns in the positi
+0000b3d0: 6f6e 0a20 2020 2020 2020 2020 2020 2065  on.            e
+0000b3e0: 6d62 6564 6469 6e67 732e 2053 656c 6563  mbeddings. Selec
+0000b3f0: 7465 6420 696e 2074 6865 2072 616e 6765  ted in the range
+0000b400: 2060 5b30 2c0a 2020 2020 2020 2020 2020   `[0,.          
+0000b410: 2020 636f 6e66 6967 2e6d 6178 5f70 6f73    config.max_pos
+0000b420: 6974 696f 6e5f 656d 6265 6464 696e 6773  ition_embeddings
+0000b430: 202d 2031 5d60 2e0a 0a20 2020 2020 2020   - 1]`...       
+0000b440: 2020 2020 205b 5768 6174 2061 7265 2070       [What are p
+0000b450: 6f73 6974 696f 6e20 4944 733f 5d28 2e2e  osition IDs?](..
+0000b460: 2f67 6c6f 7373 6172 7923 706f 7369 7469  /glossary#positi
+0000b470: 6f6e 2d69 6473 290a 2020 2020 2020 2020  on-ids).        
+0000b480: 6865 6164 5f6d 6173 6b20 2860 746f 7263  head_mask (`torc
+0000b490: 682e 466c 6f61 7454 656e 736f 7260 206f  h.FloatTensor` o
+0000b4a0: 6620 7368 6170 6520 6028 6e75 6d5f 6865  f shape `(num_he
+0000b4b0: 6164 732c 2960 206f 7220 6028 6e75 6d5f  ads,)` or `(num_
+0000b4c0: 6c61 7965 7273 2c0a 2020 2020 2020 2020  layers,.        
+0000b4d0: 6e75 6d5f 6865 6164 7329 602c 202a 6f70  num_heads)`, *op
+0000b4e0: 7469 6f6e 616c 2a29 3a0a 2020 2020 2020  tional*):.      
+0000b4f0: 2020 2020 2020 4d61 736b 2074 6f20 6e75        Mask to nu
+0000b500: 6c6c 6966 7920 7365 6c65 6374 6564 2068  llify selected h
+0000b510: 6561 6473 206f 6620 7468 6520 7365 6c66  eads of the self
+0000b520: 2d61 7474 656e 7469 6f6e 206d 6f64 756c  -attention modul
+0000b530: 6573 2e20 4d61 736b 0a20 2020 2020 2020  es. Mask.       
+0000b540: 2020 2020 2076 616c 7565 7320 7365 6c65       values sele
+0000b550: 6374 6564 2069 6e20 605b 302c 2031 5d60  cted in `[0, 1]`
+0000b560: 3a0a 0a20 2020 2020 2020 2020 2020 202d  :..            -
+0000b570: 2031 2069 6e64 6963 6174 6573 2074 6865   1 indicates the
+0000b580: 2068 6561 6420 6973 202a 2a6e 6f74 206d   head is **not m
+0000b590: 6173 6b65 642a 2a2c 0a20 2020 2020 2020  asked**,.       
+0000b5a0: 2020 2020 202d 2030 2069 6e64 6963 6174       - 0 indicat
+0000b5b0: 6573 2074 6865 2068 6561 6420 6973 202a  es the head is *
+0000b5c0: 2a6d 6173 6b65 642a 2a2e 0a0a 2020 2020  *masked**...    
+0000b5d0: 2020 2020 696e 7075 7473 5f65 6d62 6564      inputs_embed
+0000b5e0: 7320 2860 746f 7263 682e 466c 6f61 7454  s (`torch.FloatT
+0000b5f0: 656e 736f 7260 206f 6620 7368 6170 6520  ensor` of shape 
+0000b600: 6028 2862 6174 6368 5f73 697a 652c 2073  `((batch_size, s
+0000b610: 6571 7565 6e63 655f 6c65 6e67 7468 2c20  equence_length, 
+0000b620: 6869 6464 656e 5f73 697a 6529 602c 0a20  hidden_size)`,. 
+0000b630: 2020 2020 2020 202a 6f70 7469 6f6e 616c         *optional
+0000b640: 2a29 3a0a 2020 2020 2020 2020 2020 2020  *):.            
+0000b650: 4f70 7469 6f6e 616c 6c79 2c20 696e 7374  Optionally, inst
+0000b660: 6561 6420 6f66 2070 6173 7369 6e67 2060  ead of passing `
+0000b670: 696e 7075 745f 6964 7360 2079 6f75 2063  input_ids` you c
+0000b680: 616e 2063 686f 6f73 6520 746f 0a20 2020  an choose to.   
+0000b690: 2020 2020 2020 2020 2064 6972 6563 746c           directl
+0000b6a0: 7920 7061 7373 2061 6e20 656d 6265 6464  y pass an embedd
+0000b6b0: 6564 2072 6570 7265 7365 6e74 6174 696f  ed representatio
+0000b6c0: 6e2e 2054 6869 7320 6973 2075 7365 6675  n. This is usefu
+0000b6d0: 6c20 6966 2079 6f75 2077 616e 740a 2020  l if you want.  
+0000b6e0: 2020 2020 2020 2020 2020 6d6f 7265 2063            more c
+0000b6f0: 6f6e 7472 6f6c 206f 7665 7220 686f 7720  ontrol over how 
+0000b700: 746f 2063 6f6e 7665 7274 2060 696e 7075  to convert `inpu
+0000b710: 745f 6964 7360 2069 6e64 6963 6573 2069  t_ids` indices i
+0000b720: 6e74 6f20 6173 736f 6369 6174 6564 0a20  nto associated. 
+0000b730: 2020 2020 2020 2020 2020 2076 6563 746f             vecto
+0000b740: 7273 2074 6861 6e20 7468 6520 6d6f 6465  rs than the mode
+0000b750: 6c27 7320 696e 7465 726e 616c 2065 6d62  l's internal emb
+0000b760: 6564 6469 6e67 206c 6f6f 6b75 7020 6d61  edding lookup ma
+0000b770: 7472 6978 2e0a 2020 2020 2020 2020 6f75  trix..        ou
+0000b780: 7470 7574 5f61 7474 656e 7469 6f6e 7320  tput_attentions 
+0000b790: 2860 626f 6f6c 602c 202a 6f70 7469 6f6e  (`bool`, *option
+0000b7a0: 616c 2a29 3a0a 2020 2020 2020 2020 2020  al*):.          
+0000b7b0: 2020 5768 6574 6865 7220 6f72 206e 6f74    Whether or not
+0000b7c0: 2074 6f20 7265 7475 726e 2074 6865 2061   to return the a
+0000b7d0: 7474 656e 7469 6f6e 7320 7465 6e73 6f72  ttentions tensor
+0000b7e0: 7320 6f66 2061 6c6c 2061 7474 656e 7469  s of all attenti
+0000b7f0: 6f6e 0a20 2020 2020 2020 2020 2020 206c  on.            l
+0000b800: 6179 6572 732e 2053 6565 2060 6174 7465  ayers. See `atte
+0000b810: 6e74 696f 6e73 6020 756e 6465 7220 7265  ntions` under re
+0000b820: 7475 726e 6564 2074 656e 736f 7273 2066  turned tensors f
+0000b830: 6f72 206d 6f72 6520 6465 7461 696c 2e0a  or more detail..
+0000b840: 2020 2020 2020 2020 6f75 7470 7574 5f68          output_h
+0000b850: 6964 6465 6e5f 7374 6174 6573 2028 6062  idden_states (`b
+0000b860: 6f6f 6c60 2c20 2a6f 7074 696f 6e61 6c2a  ool`, *optional*
+0000b870: 293a 0a20 2020 2020 2020 2020 2020 2057  ):.            W
+0000b880: 6865 7468 6572 206f 7220 6e6f 7420 746f  hether or not to
+0000b890: 2072 6574 7572 6e20 7468 6520 6869 6464   return the hidd
+0000b8a0: 656e 2073 7461 7465 7320 6f66 2061 6c6c  en states of all
+0000b8b0: 206c 6179 6572 732e 2053 6565 0a20 2020   layers. See.   
+0000b8c0: 2020 2020 2020 2020 2060 6869 6464 656e           `hidden
+0000b8d0: 5f73 7461 7465 7360 2075 6e64 6572 2072  _states` under r
+0000b8e0: 6574 7572 6e65 6420 7465 6e73 6f72 7320  eturned tensors 
+0000b8f0: 666f 7220 6d6f 7265 2064 6574 6169 6c2e  for more detail.
+0000b900: 0a20 2020 2020 2020 2072 6574 7572 6e5f  .        return_
+0000b910: 6469 6374 2028 6062 6f6f 6c60 2c20 2a6f  dict (`bool`, *o
+0000b920: 7074 696f 6e61 6c2a 293a 0a20 2020 2020  ptional*):.     
+0000b930: 2020 2020 2020 2057 6865 7468 6572 206f         Whether o
+0000b940: 7220 6e6f 7420 746f 2072 6574 7572 6e20  r not to return 
+0000b950: 6120 5b60 7e66 696c 655f 7574 696c 732e  a [`~file_utils.
+0000b960: 4d6f 6465 6c4f 7574 7075 7460 5d20 696e  ModelOutput`] in
+0000b970: 7374 6561 6420 6f66 2061 0a20 2020 2020  stead of a.     
+0000b980: 2020 2020 2020 2070 6c61 696e 2074 7570         plain tup
+0000b990: 6c65 2e0a 2020 2020 2020 2020 656e 636f  le..        enco
+0000b9a0: 6465 725f 6869 6464 656e 5f73 7461 7465  der_hidden_state
+0000b9b0: 7320 2028 6074 6f72 6368 2e46 6c6f 6174  s  (`torch.Float
+0000b9c0: 5465 6e73 6f72 6020 6f66 2073 6861 7065  Tensor` of shape
+0000b9d0: 2060 2862 6174 6368 5f73 697a 652c 0a20   `(batch_size,. 
+0000b9e0: 2020 2020 2020 2073 6571 7565 6e63 655f         sequence_
+0000b9f0: 6c65 6e67 7468 2c20 6869 6464 656e 5f73  length, hidden_s
+0000ba00: 697a 6529 602c 202a 6f70 7469 6f6e 616c  ize)`, *optional
+0000ba10: 2a29 3a0a 2020 2020 2020 2020 2020 2020  *):.            
+0000ba20: 5365 7175 656e 6365 206f 6620 6869 6464  Sequence of hidd
+0000ba30: 656e 2d73 7461 7465 7320 6174 2074 6865  en-states at the
+0000ba40: 206f 7574 7075 7420 6f66 2074 6865 206c   output of the l
+0000ba50: 6173 7420 6c61 7965 7220 6f66 2074 6865  ast layer of the
+0000ba60: 0a20 2020 2020 2020 2020 2020 2065 6e63  .            enc
+0000ba70: 6f64 6572 2e20 5573 6564 2069 6e20 7468  oder. Used in th
+0000ba80: 6520 6372 6f73 732d 6174 7465 6e74 696f  e cross-attentio
+0000ba90: 6e20 6966 2074 6865 206d 6f64 656c 2069  n if the model i
+0000baa0: 7320 636f 6e66 6967 7572 6564 2061 7320  s configured as 
+0000bab0: 610a 2020 2020 2020 2020 2020 2020 6465  a.            de
+0000bac0: 636f 6465 722e 0a20 2020 2020 2020 2065  coder..        e
+0000bad0: 6e63 6f64 6572 5f61 7474 656e 7469 6f6e  ncoder_attention
+0000bae0: 5f6d 6173 6b20 2860 746f 7263 682e 466c  _mask (`torch.Fl
+0000baf0: 6f61 7454 656e 736f 7260 206f 6620 7368  oatTensor` of sh
+0000bb00: 6170 6520 6028 6261 7463 685f 7369 7a65  ape `(batch_size
+0000bb10: 2c0a 2020 2020 2020 2020 7365 7175 656e  ,.        sequen
+0000bb20: 6365 5f6c 656e 6774 6829 602c 202a 6f70  ce_length)`, *op
+0000bb30: 7469 6f6e 616c 2a29 3a0a 2020 2020 2020  tional*):.      
+0000bb40: 2020 2020 2020 4d61 736b 2074 6f20 6176        Mask to av
+0000bb50: 6f69 6420 7065 7266 6f72 6d69 6e67 2061  oid performing a
+0000bb60: 7474 656e 7469 6f6e 206f 6e20 7468 6520  ttention on the 
+0000bb70: 7061 6464 696e 6720 746f 6b65 6e20 696e  padding token in
+0000bb80: 6469 6365 7320 6f66 0a20 2020 2020 2020  dices of.       
+0000bb90: 2020 2020 2074 6865 2065 6e63 6f64 6572       the encoder
+0000bba0: 2069 6e70 7574 2e20 5468 6973 206d 6173   input. This mas
+0000bbb0: 6b20 6973 2075 7365 6420 696e 2074 6865  k is used in the
+0000bbc0: 2063 726f 7373 2d61 7474 656e 7469 6f6e   cross-attention
+0000bbd0: 2069 6620 7468 650a 2020 2020 2020 2020   if the.        
+0000bbe0: 2020 2020 6d6f 6465 6c20 6973 2063 6f6e      model is con
+0000bbf0: 6669 6775 7265 6420 6173 2061 2064 6563  figured as a dec
+0000bc00: 6f64 6572 2e20 4d61 736b 2076 616c 7565  oder. Mask value
+0000bc10: 7320 7365 6c65 6374 6564 2069 6e20 605b  s selected in `[
+0000bc20: 302c 2031 5d60 3a0a 0a20 2020 2020 2020  0, 1]`:..       
+0000bc30: 2020 2020 202d 2031 2066 6f72 2074 6f6b       - 1 for tok
+0000bc40: 656e 7320 7468 6174 2061 7265 202a 2a6e  ens that are **n
+0000bc50: 6f74 206d 6173 6b65 642a 2a2c 0a20 2020  ot masked**,.   
+0000bc60: 2020 2020 2020 2020 202d 2030 2066 6f72           - 0 for
+0000bc70: 2074 6f6b 656e 7320 7468 6174 2061 7265   tokens that are
+0000bc80: 202a 2a6d 6173 6b65 642a 2a2e 0a20 2020   **masked**..   
+0000bc90: 2020 2020 2070 6173 745f 6b65 795f 7661       past_key_va
+0000bca0: 6c75 6573 2028 6074 7570 6c65 2874 7570  lues (`tuple(tup
+0000bcb0: 6c65 2874 6f72 6368 2e46 6c6f 6174 5465  le(torch.FloatTe
+0000bcc0: 6e73 6f72 2929 6020 6f66 206c 656e 6774  nsor))` of lengt
+0000bcd0: 680a 2020 2020 2020 2020 6063 6f6e 6669  h.        `confi
+0000bce0: 672e 6e5f 6c61 7965 7273 6020 7769 7468  g.n_layers` with
+0000bcf0: 2065 6163 6820 7475 706c 6520 6861 7669   each tuple havi
+0000bd00: 6e67 2034 2074 656e 736f 7273 206f 6620  ng 4 tensors of 
+0000bd10: 7368 6170 650a 2020 2020 2020 2020 6028  shape.        `(
+0000bd20: 6261 7463 685f 7369 7a65 2c20 6e75 6d5f  batch_size, num_
+0000bd30: 6865 6164 732c 2073 6571 7565 6e63 655f  heads, sequence_
+0000bd40: 6c65 6e67 7468 202d 2031 2c20 656d 6265  length - 1, embe
+0000bd50: 645f 7369 7a65 5f70 6572 5f68 6561 6429  d_size_per_head)
+0000bd60: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
+0000bd70: 436f 6e74 6169 6e73 2070 7265 636f 6d70  Contains precomp
+0000bd80: 7574 6564 206b 6579 2061 6e64 2076 616c  uted key and val
+0000bd90: 7565 2068 6964 6465 6e20 7374 6174 6573  ue hidden states
+0000bda0: 206f 6620 7468 6520 6174 7465 6e74 696f   of the attentio
+0000bdb0: 6e0a 2020 2020 2020 2020 2020 2020 626c  n.            bl
+0000bdc0: 6f63 6b73 2e20 4361 6e20 6265 2075 7365  ocks. Can be use
+0000bdd0: 6420 746f 2073 7065 6564 2075 7020 6465  d to speed up de
+0000bde0: 636f 6469 6e67 2e0a 0a20 2020 2020 2020  coding...       
+0000bdf0: 2020 2020 2049 6620 6070 6173 745f 6b65       If `past_ke
+0000be00: 795f 7661 6c75 6573 6020 6172 6520 7573  y_values` are us
+0000be10: 6564 2c20 7468 6520 7573 6572 2063 616e  ed, the user can
+0000be20: 206f 7074 696f 6e61 6c6c 7920 696e 7075   optionally inpu
+0000be30: 7420 6f6e 6c79 0a20 2020 2020 2020 2020  t only.         
+0000be40: 2020 2074 6865 206c 6173 7420 6064 6563     the last `dec
+0000be50: 6f64 6572 5f69 6e70 7574 5f69 6473 6020  oder_input_ids` 
+0000be60: 2874 686f 7365 2074 6861 7420 646f 6e27  (those that don'
+0000be70: 7420 6861 7665 2074 6865 6972 2070 6173  t have their pas
+0000be80: 7420 6b65 790a 2020 2020 2020 2020 2020  t key.          
+0000be90: 2020 7661 6c75 6520 7374 6174 6573 2067    value states g
+0000bea0: 6976 656e 2074 6f20 7468 6973 206d 6f64  iven to this mod
+0000beb0: 656c 2920 6f66 2073 6861 7065 2060 2862  el) of shape `(b
+0000bec0: 6174 6368 5f73 697a 652c 2031 2960 2069  atch_size, 1)` i
+0000bed0: 6e73 7465 6164 0a20 2020 2020 2020 2020  nstead.         
+0000bee0: 2020 206f 6620 616c 6c20 6064 6563 6f64     of all `decod
+0000bef0: 6572 5f69 6e70 7574 5f69 6473 6020 6f66  er_input_ids` of
+0000bf00: 2073 6861 7065 2060 2862 6174 6368 5f73   shape `(batch_s
+0000bf10: 697a 652c 2073 6571 7565 6e63 655f 6c65  ize, sequence_le
+0000bf20: 6e67 7468 2960 2e0a 2020 2020 2020 2020  ngth)`..        
+0000bf30: 7573 655f 6361 6368 6520 2860 626f 6f6c  use_cache (`bool
+0000bf40: 602c 202a 6f70 7469 6f6e 616c 2a29 3a0a  `, *optional*):.
+0000bf50: 2020 2020 2020 2020 2020 2020 4966 2073              If s
+0000bf60: 6574 2074 6f20 6054 7275 6560 2c20 6070  et to `True`, `p
+0000bf70: 6173 745f 6b65 795f 7661 6c75 6573 6020  ast_key_values` 
+0000bf80: 6b65 7920 7661 6c75 6520 7374 6174 6573  key value states
+0000bf90: 2061 7265 2072 6574 7572 6e65 640a 2020   are returned.  
+0000bfa0: 2020 2020 2020 2020 2020 616e 6420 6361            and ca
+0000bfb0: 6e20 6265 2075 7365 6420 746f 2073 7065  n be used to spe
+0000bfc0: 6564 2075 7020 6465 636f 6469 6e67 2028  ed up decoding (
+0000bfd0: 7365 6520 6070 6173 745f 6b65 795f 7661  see `past_key_va
+0000bfe0: 6c75 6573 6029 2e0a 2020 2020 2020 2020  lues`)..        
+0000bff0: 4f74 6865 7273 2028 2a2a 6b77 6172 6773  Others (**kwargs
+0000c000: 290a 2020 2020 2020 2020 2020 2020 736f  ).            so
+0000c010: 6d65 2061 6464 6974 696f 6e61 6c20 7061  me additional pa
+0000c020: 7261 6d65 7465 7273 206d 6967 6874 2070  rameters might p
+0000c030: 6173 7365 6420 696e 2066 726f 6d20 7570  assed in from up
+0000c040: 7374 7265 616d 2070 6970 656c 696e 652c  stream pipeline,
+0000c050: 0a20 2020 2020 2020 2020 2020 2077 6869  .            whi
+0000c060: 6368 206e 6f74 2069 6e66 6c75 656e 6365  ch not influence
+0000c070: 2074 6865 2072 6573 756c 7473 2e0a 2020   the results..  
+0000c080: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
+0000c090: 2020 206f 7574 7075 745f 6174 7465 6e74     output_attent
+0000c0a0: 696f 6e73 203d 206f 7574 7075 745f 6174  ions = output_at
+0000c0b0: 7465 6e74 696f 6e73 2069 6620 6f75 7470  tentions if outp
+0000c0c0: 7574 5f61 7474 656e 7469 6f6e 7320 6973  ut_attentions is
+0000c0d0: 206e 6f74 204e 6f6e 6520 656c 7365 2073   not None else s
+0000c0e0: 656c 662e 636f 6e66 6967 2e6f 7574 7075  elf.config.outpu
+0000c0f0: 745f 6174 7465 6e74 696f 6e73 0a20 2020  t_attentions.   
+0000c100: 2020 2020 206f 7574 7075 745f 6869 6464       output_hidd
+0000c110: 656e 5f73 7461 7465 7320 3d20 280a 2020  en_states = (.  
+0000c120: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+0000c130: 5f68 6964 6465 6e5f 7374 6174 6573 2069  _hidden_states i
+0000c140: 6620 6f75 7470 7574 5f68 6964 6465 6e5f  f output_hidden_
+0000c150: 7374 6174 6573 2069 7320 6e6f 7420 4e6f  states is not No
+0000c160: 6e65 2065 6c73 650a 2020 2020 2020 2020  ne else.        
+0000c170: 2020 2020 7365 6c66 2e63 6f6e 6669 672e      self.config.
+0000c180: 6f75 7470 7574 5f68 6964 6465 6e5f 7374  output_hidden_st
+0000c190: 6174 6573 290a 2020 2020 2020 2020 7265  ates).        re
+0000c1a0: 7475 726e 5f64 6963 7420 3d20 7265 7475  turn_dict = retu
+0000c1b0: 726e 5f64 6963 7420 6966 2072 6574 7572  rn_dict if retur
+0000c1c0: 6e5f 6469 6374 2069 7320 6e6f 7420 4e6f  n_dict is not No
+0000c1d0: 6e65 2065 6c73 6520 7365 6c66 2e63 6f6e  ne else self.con
+0000c1e0: 6669 672e 7573 655f 7265 7475 726e 5f64  fig.use_return_d
+0000c1f0: 6963 740a 0a20 2020 2020 2020 2069 6620  ict..        if 
+0000c200: 6973 5f64 6563 6f64 6572 3a0a 2020 2020  is_decoder:.    
+0000c210: 2020 2020 2020 2020 7573 655f 6361 6368          use_cach
+0000c220: 6520 3d20 7573 655f 6361 6368 6520 6966  e = use_cache if
+0000c230: 2075 7365 5f63 6163 6865 2069 7320 6e6f   use_cache is no
+0000c240: 7420 4e6f 6e65 2065 6c73 6520 7365 6c66  t None else self
+0000c250: 2e63 6f6e 6669 672e 7573 655f 6361 6368  .config.use_cach
+0000c260: 650a 2020 2020 2020 2020 656c 7365 3a0a  e.        else:.
+0000c270: 2020 2020 2020 2020 2020 2020 7573 655f              use_
+0000c280: 6361 6368 6520 3d20 4661 6c73 650a 0a20  cache = False.. 
+0000c290: 2020 2020 2020 2069 6620 696e 7075 745f         if input_
+0000c2a0: 6964 7320 6973 206e 6f74 204e 6f6e 6520  ids is not None 
+0000c2b0: 616e 6420 696e 7075 7473 5f65 6d62 6564  and inputs_embed
+0000c2c0: 7320 6973 206e 6f74 204e 6f6e 653a 0a20  s is not None:. 
+0000c2d0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000c2e0: 2056 616c 7565 4572 726f 7228 0a20 2020   ValueError(.   
+0000c2f0: 2020 2020 2020 2020 2020 2020 2027 596f               'Yo
+0000c300: 7520 6361 6e6e 6f74 2073 7065 6369 6679  u cannot specify
+0000c310: 2062 6f74 6820 696e 7075 745f 6964 7320   both input_ids 
+0000c320: 616e 6420 696e 7075 7473 5f65 6d62 6564  and inputs_embed
+0000c330: 7320 6174 2074 6865 2073 616d 6520 7469  s at the same ti
+0000c340: 6d65 270a 2020 2020 2020 2020 2020 2020  me'.            
+0000c350: 290a 2020 2020 2020 2020 656c 6966 2069  ).        elif i
+0000c360: 6e70 7574 5f69 6473 2069 7320 6e6f 7420  nput_ids is not 
+0000c370: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+0000c380: 2020 696e 7075 745f 7368 6170 6520 3d20    input_shape = 
+0000c390: 696e 7075 745f 6964 732e 7369 7a65 2829  input_ids.size()
+0000c3a0: 0a20 2020 2020 2020 2020 2020 2062 6174  .            bat
+0000c3b0: 6368 5f73 697a 652c 2073 6571 5f6c 656e  ch_size, seq_len
+0000c3c0: 6774 6820 3d20 696e 7075 745f 7368 6170  gth = input_shap
+0000c3d0: 650a 2020 2020 2020 2020 2020 2020 6465  e.            de
+0000c3e0: 7669 6365 203d 2069 6e70 7574 5f69 6473  vice = input_ids
+0000c3f0: 2e64 6576 6963 650a 2020 2020 2020 2020  .device.        
+0000c400: 656c 6966 2069 6e70 7574 735f 656d 6265  elif inputs_embe
+0000c410: 6473 2069 7320 6e6f 7420 4e6f 6e65 3a0a  ds is not None:.
+0000c420: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+0000c430: 745f 7368 6170 6520 3d20 696e 7075 7473  t_shape = inputs
+0000c440: 5f65 6d62 6564 732e 7369 7a65 2829 5b3a  _embeds.size()[:
+0000c450: 2d31 5d0a 2020 2020 2020 2020 2020 2020  -1].            
+0000c460: 6261 7463 685f 7369 7a65 2c20 7365 715f  batch_size, seq_
+0000c470: 6c65 6e67 7468 203d 2069 6e70 7574 5f73  length = input_s
+0000c480: 6861 7065 0a20 2020 2020 2020 2020 2020  hape.           
+0000c490: 2064 6576 6963 6520 3d20 696e 7075 7473   device = inputs
+0000c4a0: 5f65 6d62 6564 732e 6465 7669 6365 0a20  _embeds.device. 
+0000c4b0: 2020 2020 2020 2065 6c69 6620 656e 636f         elif enco
+0000c4c0: 6465 725f 656d 6265 6473 2069 7320 6e6f  der_embeds is no
+0000c4d0: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+0000c4e0: 2020 2020 696e 7075 745f 7368 6170 6520      input_shape 
+0000c4f0: 3d20 656e 636f 6465 725f 656d 6265 6473  = encoder_embeds
+0000c500: 2e73 697a 6528 295b 3a2d 315d 0a20 2020  .size()[:-1].   
+0000c510: 2020 2020 2020 2020 2062 6174 6368 5f73           batch_s
+0000c520: 697a 652c 2073 6571 5f6c 656e 6774 6820  ize, seq_length 
+0000c530: 3d20 696e 7075 745f 7368 6170 650a 2020  = input_shape.  
+0000c540: 2020 2020 2020 2020 2020 6465 7669 6365            device
+0000c550: 203d 2065 6e63 6f64 6572 5f65 6d62 6564   = encoder_embed
+0000c560: 732e 6465 7669 6365 0a20 2020 2020 2020  s.device.       
+0000c570: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0000c580: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+0000c590: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
+0000c5a0: 2020 2020 2027 596f 7520 6861 7665 2074       'You have t
+0000c5b0: 6f20 7370 6563 6966 7920 6569 7468 6572  o specify either
+0000c5c0: 2069 6e70 7574 5f69 6473 206f 7220 696e   input_ids or in
+0000c5d0: 7075 7473 5f65 6d62 6564 7320 6f72 2065  puts_embeds or e
+0000c5e0: 6e63 6f64 6572 5f65 6d62 6564 7327 0a20  ncoder_embeds'. 
+0000c5f0: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
+0000c600: 2020 2020 2020 2320 7061 7374 5f6b 6579        # past_key
+0000c610: 5f76 616c 7565 735f 6c65 6e67 7468 0a20  _values_length. 
+0000c620: 2020 2020 2020 2070 6173 745f 6b65 795f         past_key_
+0000c630: 7661 6c75 6573 5f6c 656e 6774 6820 3d20  values_length = 
+0000c640: 7061 7374 5f6b 6579 5f76 616c 7565 735b  past_key_values[
+0000c650: 305d 5b30 5d2e 7368 6170 655b 0a20 2020  0][0].shape[.   
+0000c660: 2020 2020 2020 2020 2032 5d20 6966 2070           2] if p
+0000c670: 6173 745f 6b65 795f 7661 6c75 6573 2069  ast_key_values i
+0000c680: 7320 6e6f 7420 4e6f 6e65 2065 6c73 6520  s not None else 
+0000c690: 300a 0a20 2020 2020 2020 2069 6620 6174  0..        if at
+0000c6a0: 7465 6e74 696f 6e5f 6d61 736b 2069 7320  tention_mask is 
+0000c6b0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+0000c6c0: 2020 6174 7465 6e74 696f 6e5f 6d61 736b    attention_mask
+0000c6d0: 203d 2074 6f72 6368 2e6f 6e65 7328 0a20   = torch.ones(. 
+0000c6e0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+0000c6f0: 2862 6174 6368 5f73 697a 652c 2073 6571  (batch_size, seq
+0000c700: 5f6c 656e 6774 6820 2b20 7061 7374 5f6b  _length + past_k
+0000c710: 6579 5f76 616c 7565 735f 6c65 6e67 7468  ey_values_length
+0000c720: 2929 2c0a 2020 2020 2020 2020 2020 2020  )),.            
+0000c730: 2020 2020 6465 7669 6365 3d64 6576 6963      device=devic
+0000c740: 6529 0a20 2020 2020 2020 2069 6620 746f  e).        if to
+0000c750: 6b65 6e5f 7479 7065 5f69 6473 2069 7320  ken_type_ids is 
+0000c760: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+0000c770: 2020 746f 6b65 6e5f 7479 7065 5f69 6473    token_type_ids
+0000c780: 203d 2074 6f72 6368 2e7a 6572 6f73 280a   = torch.zeros(.
+0000c790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c7a0: 696e 7075 745f 7368 6170 652c 2064 7479  input_shape, dty
+0000c7b0: 7065 3d74 6f72 6368 2e6c 6f6e 672c 2064  pe=torch.long, d
+0000c7c0: 6576 6963 653d 6465 7669 6365 290a 0a20  evice=device).. 
+0000c7d0: 2020 2020 2020 2023 2057 6520 6361 6e20         # We can 
+0000c7e0: 7072 6f76 6964 6520 6120 7365 6c66 2d61  provide a self-a
+0000c7f0: 7474 656e 7469 6f6e 206d 6173 6b20 6f66  ttention mask of
+0000c800: 2064 696d 656e 7369 6f6e 7320 5b62 6174   dimensions [bat
+0000c810: 6368 5f73 697a 652c 0a20 2020 2020 2020  ch_size,.       
+0000c820: 2023 2066 726f 6d5f 7365 715f 6c65 6e67   # from_seq_leng
+0000c830: 7468 2c20 746f 5f73 6571 5f6c 656e 6774  th, to_seq_lengt
+0000c840: 685d 206f 7572 7365 6c76 6573 2069 6e20  h] ourselves in 
+0000c850: 7768 6963 6820 6361 7365 2077 6520 6a75  which case we ju
+0000c860: 7374 206e 6565 640a 2020 2020 2020 2020  st need.        
+0000c870: 2320 746f 206d 616b 6520 6974 2062 726f  # to make it bro
+0000c880: 6164 6361 7374 6162 6c65 2074 6f20 616c  adcastable to al
+0000c890: 6c20 6865 6164 732e 0a20 2020 2020 2020  l heads..       
+0000c8a0: 2065 7874 656e 6465 645f 6174 7465 6e74   extended_attent
+0000c8b0: 696f 6e5f 6d61 736b 3a20 746f 7263 682e  ion_mask: torch.
+0000c8c0: 5465 6e73 6f72 203d 2073 656c 662e 6765  Tensor = self.ge
+0000c8d0: 745f 6578 7465 6e64 6564 5f61 7474 656e  t_extended_atten
+0000c8e0: 7469 6f6e 5f6d 6173 6b28 0a20 2020 2020  tion_mask(.     
+0000c8f0: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
+0000c900: 5f6d 6173 6b2c 2069 6e70 7574 5f73 6861  _mask, input_sha
+0000c910: 7065 2c20 6465 7669 6365 2c20 6973 5f64  pe, device, is_d
+0000c920: 6563 6f64 6572 290a 0a20 2020 2020 2020  ecoder)..       
+0000c930: 2023 2049 6620 6120 3244 206f 7220 3344   # If a 2D or 3D
+0000c940: 2061 7474 656e 7469 6f6e 206d 6173 6b20   attention mask 
+0000c950: 6973 2070 726f 7669 6465 6420 666f 7220  is provided for 
+0000c960: 7468 6520 6372 6f73 732d 6174 7465 6e74  the cross-attent
+0000c970: 696f 6e20 7765 0a20 2020 2020 2020 2023  ion we.        #
+0000c980: 206e 6565 6420 746f 206d 616b 6520 6272   need to make br
+0000c990: 6f61 6463 6173 7461 626c 6520 746f 205b  oadcastable to [
+0000c9a0: 6261 7463 685f 7369 7a65 2c20 6e75 6d5f  batch_size, num_
+0000c9b0: 6865 6164 732c 2073 6571 5f6c 656e 6774  heads, seq_lengt
+0000c9c0: 682c 0a20 2020 2020 2020 2023 2073 6571  h,.        # seq
+0000c9d0: 5f6c 656e 6774 685d 0a20 2020 2020 2020  _length].       
+0000c9e0: 2069 6620 656e 636f 6465 725f 6869 6464   if encoder_hidd
+0000c9f0: 656e 5f73 7461 7465 7320 6973 206e 6f74  en_states is not
+0000ca00: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+0000ca10: 2020 2069 6620 7479 7065 2865 6e63 6f64     if type(encod
+0000ca20: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
+0000ca30: 2920 3d3d 206c 6973 743a 0a20 2020 2020  ) == list:.     
+0000ca40: 2020 2020 2020 2020 2020 2065 6e63 6f64             encod
+0000ca50: 6572 5f62 6174 6368 5f73 697a 652c 2065  er_batch_size, e
+0000ca60: 6e63 6f64 6572 5f73 6571 7565 6e63 655f  ncoder_sequence_
+0000ca70: 6c65 6e67 7468 2c20 5f20 3d20 656e 636f  length, _ = enco
+0000ca80: 6465 725f 6869 6464 656e 5f73 7461 7465  der_hidden_state
+0000ca90: 735b 0a20 2020 2020 2020 2020 2020 2020  s[.             
+0000caa0: 2020 2020 2020 2030 5d2e 7369 7a65 2829         0].size()
+0000cab0: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
+0000cac0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+0000cad0: 2020 2065 6e63 6f64 6572 5f62 6174 6368     encoder_batch
+0000cae0: 5f73 697a 652c 2065 6e63 6f64 6572 5f73  _size, encoder_s
+0000caf0: 6571 7565 6e63 655f 6c65 6e67 7468 2c20  equence_length, 
+0000cb00: 5f20 3d20 656e 636f 6465 725f 6869 6464  _ = encoder_hidd
+0000cb10: 656e 5f73 7461 7465 732e 7369 7a65 280a  en_states.size(.
+0000cb20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cb30: 290a 2020 2020 2020 2020 2020 2020 656e  ).            en
+0000cb40: 636f 6465 725f 6869 6464 656e 5f73 6861  coder_hidden_sha
+0000cb50: 7065 203d 2028 656e 636f 6465 725f 6261  pe = (encoder_ba
+0000cb60: 7463 685f 7369 7a65 2c0a 2020 2020 2020  tch_size,.      
+0000cb70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cb80: 2020 2020 2020 2020 2020 2020 2020 656e                en
+0000cb90: 636f 6465 725f 7365 7175 656e 6365 5f6c  coder_sequence_l
+0000cba0: 656e 6774 6829 0a0a 2020 2020 2020 2020  ength)..        
+0000cbb0: 2020 2020 6966 2074 7970 6528 656e 636f      if type(enco
+0000cbc0: 6465 725f 6174 7465 6e74 696f 6e5f 6d61  der_attention_ma
+0000cbd0: 736b 2920 3d3d 206c 6973 743a 0a20 2020  sk) == list:.   
+0000cbe0: 2020 2020 2020 2020 2020 2020 2065 6e63               enc
+0000cbf0: 6f64 6572 5f65 7874 656e 6465 645f 6174  oder_extended_at
+0000cc00: 7465 6e74 696f 6e5f 6d61 736b 203d 205b  tention_mask = [
+0000cc10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000cc20: 2020 2020 2073 656c 662e 696e 7665 7274       self.invert
+0000cc30: 5f61 7474 656e 7469 6f6e 5f6d 6173 6b28  _attention_mask(
+0000cc40: 6d61 736b 290a 2020 2020 2020 2020 2020  mask).          
+0000cc50: 2020 2020 2020 2020 2020 666f 7220 6d61            for ma
+0000cc60: 736b 2069 6e20 656e 636f 6465 725f 6174  sk in encoder_at
+0000cc70: 7465 6e74 696f 6e5f 6d61 736b 0a20 2020  tention_mask.   
+0000cc80: 2020 2020 2020 2020 2020 2020 205d 0a20               ]. 
+0000cc90: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+0000cca0: 656e 636f 6465 725f 6174 7465 6e74 696f  encoder_attentio
+0000ccb0: 6e5f 6d61 736b 2069 7320 4e6f 6e65 3a0a  n_mask is None:.
+0000ccc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ccd0: 656e 636f 6465 725f 6174 7465 6e74 696f  encoder_attentio
+0000cce0: 6e5f 6d61 736b 203d 2074 6f72 6368 2e6f  n_mask = torch.o
+0000ccf0: 6e65 7328 0a20 2020 2020 2020 2020 2020  nes(.           
+0000cd00: 2020 2020 2020 2020 2065 6e63 6f64 6572           encoder
+0000cd10: 5f68 6964 6465 6e5f 7368 6170 652c 2064  _hidden_shape, d
+0000cd20: 6576 6963 653d 6465 7669 6365 290a 2020  evice=device).  
+0000cd30: 2020 2020 2020 2020 2020 2020 2020 656e                en
+0000cd40: 636f 6465 725f 6578 7465 6e64 6564 5f61  coder_extended_a
+0000cd50: 7474 656e 7469 6f6e 5f6d 6173 6b20 3d20  ttention_mask = 
+0000cd60: 7365 6c66 2e69 6e76 6572 745f 6174 7465  self.invert_atte
+0000cd70: 6e74 696f 6e5f 6d61 736b 280a 2020 2020  ntion_mask(.    
+0000cd80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd90: 656e 636f 6465 725f 6174 7465 6e74 696f  encoder_attentio
+0000cda0: 6e5f 6d61 736b 290a 2020 2020 2020 2020  n_mask).        
+0000cdb0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+0000cdc0: 2020 2020 2020 2020 2020 656e 636f 6465            encode
+0000cdd0: 725f 6578 7465 6e64 6564 5f61 7474 656e  r_extended_atten
+0000cde0: 7469 6f6e 5f6d 6173 6b20 3d20 7365 6c66  tion_mask = self
+0000cdf0: 2e69 6e76 6572 745f 6174 7465 6e74 696f  .invert_attentio
+0000ce00: 6e5f 6d61 736b 280a 2020 2020 2020 2020  n_mask(.        
+0000ce10: 2020 2020 2020 2020 2020 2020 656e 636f              enco
+0000ce20: 6465 725f 6174 7465 6e74 696f 6e5f 6d61  der_attention_ma
+0000ce30: 736b 290a 2020 2020 2020 2020 656c 7365  sk).        else
+0000ce40: 3a0a 2020 2020 2020 2020 2020 2020 656e  :.            en
+0000ce50: 636f 6465 725f 6578 7465 6e64 6564 5f61  coder_extended_a
+0000ce60: 7474 656e 7469 6f6e 5f6d 6173 6b20 3d20  ttention_mask = 
+0000ce70: 4e6f 6e65 0a0a 2020 2020 2020 2020 2320  None..        # 
+0000ce80: 5072 6570 6172 6520 6865 6164 206d 6173  Prepare head mas
+0000ce90: 6b20 6966 206e 6565 6465 640a 2020 2020  k if needed.    
+0000cea0: 2020 2020 2320 312e 3020 696e 2068 6561      # 1.0 in hea
+0000ceb0: 645f 6d61 736b 2069 6e64 6963 6174 6520  d_mask indicate 
+0000cec0: 7765 206b 6565 7020 7468 6520 6865 6164  we keep the head
+0000ced0: 0a20 2020 2020 2020 2023 2061 7474 656e  .        # atten
+0000cee0: 7469 6f6e 5f70 726f 6273 2068 6173 2073  tion_probs has s
+0000cef0: 6861 7065 2062 737a 2078 206e 5f68 6561  hape bsz x n_hea
+0000cf00: 6473 2078 204e 2078 204e 0a20 2020 2020  ds x N x N.     
+0000cf10: 2020 2023 2069 6e70 7574 2068 6561 645f     # input head_
+0000cf20: 6d61 736b 2068 6173 2073 6861 7065 205b  mask has shape [
+0000cf30: 6e75 6d5f 6865 6164 735d 206f 7220 5b6e  num_heads] or [n
+0000cf40: 756d 5f68 6964 6465 6e5f 6c61 7965 7273  um_hidden_layers
+0000cf50: 2078 206e 756d 5f68 6561 6473 5d0a 2020   x num_heads].  
+0000cf60: 2020 2020 2020 2320 616e 6420 6865 6164        # and head
+0000cf70: 5f6d 6173 6b20 6973 2063 6f6e 7665 7274  _mask is convert
+0000cf80: 6564 2074 6f20 7368 6170 6520 5b6e 756d  ed to shape [num
+0000cf90: 5f68 6964 6465 6e5f 6c61 7965 7273 2078  _hidden_layers x
+0000cfa0: 2062 6174 6368 2078 206e 756d 5f68 6561   batch x num_hea
+0000cfb0: 6473 2078 2073 6571 5f6c 656e 6774 6820  ds x seq_length 
+0000cfc0: 7820 7365 715f 6c65 6e67 7468 5d0a 2020  x seq_length].  
+0000cfd0: 2020 2020 2020 6865 6164 5f6d 6173 6b20        head_mask 
+0000cfe0: 3d20 7365 6c66 2e67 6574 5f68 6561 645f  = self.get_head_
+0000cff0: 6d61 736b 2868 6561 645f 6d61 736b 2c0a  mask(head_mask,.
+0000d000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d020: 2020 2020 2020 2073 656c 662e 636f 6e66         self.conf
+0000d030: 6967 2e6e 756d 5f68 6964 6465 6e5f 6c61  ig.num_hidden_la
+0000d040: 7965 7273 290a 0a20 2020 2020 2020 2069  yers)..        i
+0000d050: 6620 656e 636f 6465 725f 656d 6265 6473  f encoder_embeds
+0000d060: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+0000d070: 2020 2020 2020 656d 6265 6464 696e 675f        embedding_
+0000d080: 6f75 7470 7574 203d 2073 656c 662e 656d  output = self.em
+0000d090: 6265 6464 696e 6773 280a 2020 2020 2020  beddings(.      
+0000d0a0: 2020 2020 2020 2020 2020 696e 7075 745f            input_
+0000d0b0: 6964 733d 696e 7075 745f 6964 732c 0a20  ids=input_ids,. 
+0000d0c0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0000d0d0: 6f73 6974 696f 6e5f 6964 733d 706f 7369  osition_ids=posi
+0000d0e0: 7469 6f6e 5f69 6473 2c0a 2020 2020 2020  tion_ids,.      
+0000d0f0: 2020 2020 2020 2020 2020 746f 6b65 6e5f            token_
+0000d100: 7479 7065 5f69 6473 3d74 6f6b 656e 5f74  type_ids=token_t
+0000d110: 7970 655f 6964 732c 0a20 2020 2020 2020  ype_ids,.       
+0000d120: 2020 2020 2020 2020 2069 6e70 7574 735f           inputs_
+0000d130: 656d 6265 6473 3d69 6e70 7574 735f 656d  embeds=inputs_em
+0000d140: 6265 6473 2c0a 2020 2020 2020 2020 2020  beds,.          
+0000d150: 2020 2020 2020 7061 7374 5f6b 6579 5f76        past_key_v
+0000d160: 616c 7565 735f 6c65 6e67 7468 3d70 6173  alues_length=pas
+0000d170: 745f 6b65 795f 7661 6c75 6573 5f6c 656e  t_key_values_len
+0000d180: 6774 682c 0a20 2020 2020 2020 2020 2020  gth,.           
+0000d190: 2020 2020 2072 656c 5f74 7970 655f 6964       rel_type_id
+0000d1a0: 733d 7265 6c5f 7479 7065 5f69 6473 2c0a  s=rel_type_ids,.
+0000d1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d1c0: 6162 736f 6c75 7465 5f70 6f73 6974 696f  absolute_positio
+0000d1d0: 6e5f 6964 733d 6162 736f 6c75 7465 5f70  n_ids=absolute_p
+0000d1e0: 6f73 6974 696f 6e5f 6964 732c 0a20 2020  osition_ids,.   
+0000d1f0: 2020 2020 2020 2020 2020 2020 2072 656c               rel
+0000d200: 6174 6976 655f 706f 7369 7469 6f6e 5f69  ative_position_i
+0000d210: 6473 3d72 656c 6174 6976 655f 706f 7369  ds=relative_posi
+0000d220: 7469 6f6e 5f69 6473 2c0a 2020 2020 2020  tion_ids,.      
+0000d230: 2020 2020 2020 2020 2020 7072 6f76 5f69            prov_i
+0000d240: 6473 3d70 726f 765f 6964 732c 0a20 2020  ds=prov_ids,.   
+0000d250: 2020 2020 2020 2020 2020 2020 2063 6974               cit
+0000d260: 795f 6964 733d 6369 7479 5f69 6473 2c0a  y_ids=city_ids,.
+0000d270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d280: 6469 7374 5f69 6473 3d64 6973 745f 6964  dist_ids=dist_id
+0000d290: 732c 0a20 2020 2020 2020 2020 2020 2029  s,.            )
+0000d2a0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+0000d2b0: 2020 2020 2020 2020 2020 2065 6d62 6564             embed
+0000d2c0: 6469 6e67 5f6f 7574 7075 7420 3d20 656e  ding_output = en
+0000d2d0: 636f 6465 725f 656d 6265 6473 0a0a 2020  coder_embeds..  
+0000d2e0: 2020 2020 2020 656e 636f 6465 725f 6f75        encoder_ou
+0000d2f0: 7470 7574 7320 3d20 7365 6c66 2e65 6e63  tputs = self.enc
+0000d300: 6f64 6572 280a 2020 2020 2020 2020 2020  oder(.          
+0000d310: 2020 656d 6265 6464 696e 675f 6f75 7470    embedding_outp
+0000d320: 7574 2c0a 2020 2020 2020 2020 2020 2020  ut,.            
+0000d330: 6174 7465 6e74 696f 6e5f 6d61 736b 3d65  attention_mask=e
+0000d340: 7874 656e 6465 645f 6174 7465 6e74 696f  xtended_attentio
+0000d350: 6e5f 6d61 736b 2c0a 2020 2020 2020 2020  n_mask,.        
+0000d360: 2020 2020 6865 6164 5f6d 6173 6b3d 6865      head_mask=he
+0000d370: 6164 5f6d 6173 6b2c 0a20 2020 2020 2020  ad_mask,.       
+0000d380: 2020 2020 2065 6e63 6f64 6572 5f68 6964       encoder_hid
+0000d390: 6465 6e5f 7374 6174 6573 3d65 6e63 6f64  den_states=encod
+0000d3a0: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
+0000d3b0: 2c0a 2020 2020 2020 2020 2020 2020 656e  ,.            en
+0000d3c0: 636f 6465 725f 6174 7465 6e74 696f 6e5f  coder_attention_
+0000d3d0: 6d61 736b 3d65 6e63 6f64 6572 5f65 7874  mask=encoder_ext
+0000d3e0: 656e 6465 645f 6174 7465 6e74 696f 6e5f  ended_attention_
+0000d3f0: 6d61 736b 2c0a 2020 2020 2020 2020 2020  mask,.          
+0000d400: 2020 7061 7374 5f6b 6579 5f76 616c 7565    past_key_value
+0000d410: 733d 7061 7374 5f6b 6579 5f76 616c 7565  s=past_key_value
+0000d420: 732c 0a20 2020 2020 2020 2020 2020 2075  s,.            u
+0000d430: 7365 5f63 6163 6865 3d75 7365 5f63 6163  se_cache=use_cac
+0000d440: 6865 2c0a 2020 2020 2020 2020 2020 2020  he,.            
+0000d450: 6f75 7470 7574 5f61 7474 656e 7469 6f6e  output_attention
+0000d460: 733d 6f75 7470 7574 5f61 7474 656e 7469  s=output_attenti
+0000d470: 6f6e 732c 0a20 2020 2020 2020 2020 2020  ons,.           
+0000d480: 206f 7574 7075 745f 6869 6464 656e 5f73   output_hidden_s
+0000d490: 7461 7465 733d 6f75 7470 7574 5f68 6964  tates=output_hid
+0000d4a0: 6465 6e5f 7374 6174 6573 2c0a 2020 2020  den_states,.    
+0000d4b0: 2020 2020 2020 2020 7265 7475 726e 5f64          return_d
+0000d4c0: 6963 743d 7265 7475 726e 5f64 6963 742c  ict=return_dict,
+0000d4d0: 0a20 2020 2020 2020 2020 2020 206d 6f64  .            mod
+0000d4e0: 653d 6d6f 6465 2c0a 2020 2020 2020 2020  e=mode,.        
+0000d4f0: 290a 2020 2020 2020 2020 7365 7175 656e  ).        sequen
+0000d500: 6365 5f6f 7574 7075 7420 3d20 656e 636f  ce_output = enco
+0000d510: 6465 725f 6f75 7470 7574 735b 305d 0a20  der_outputs[0]. 
+0000d520: 2020 2020 2020 2070 6f6f 6c65 645f 6f75         pooled_ou
+0000d530: 7470 7574 203d 2073 656c 662e 706f 6f6c  tput = self.pool
+0000d540: 6572 280a 2020 2020 2020 2020 2020 2020  er(.            
+0000d550: 7365 7175 656e 6365 5f6f 7574 7075 7429  sequence_output)
+0000d560: 2069 6620 7365 6c66 2e70 6f6f 6c65 7220   if self.pooler 
+0000d570: 6973 206e 6f74 204e 6f6e 6520 656c 7365  is not None else
+0000d580: 204e 6f6e 650a 0a20 2020 2020 2020 2069   None..        i
+0000d590: 6620 6e6f 7420 7265 7475 726e 5f64 6963  f not return_dic
+0000d5a0: 743a 0a20 2020 2020 2020 2020 2020 2072  t:.            r
+0000d5b0: 6574 7572 6e20 2873 6571 7565 6e63 655f  eturn (sequence_
+0000d5c0: 6f75 7470 7574 2c20 706f 6f6c 6564 5f6f  output, pooled_o
+0000d5d0: 7574 7075 7429 202b 2065 6e63 6f64 6572  utput) + encoder
+0000d5e0: 5f6f 7574 7075 7473 5b31 3a5d 0a0a 2020  _outputs[1:]..  
+0000d5f0: 2020 2020 2020 7265 7475 726e 2042 6173        return Bas
+0000d600: 654d 6f64 656c 4f75 7470 7574 5769 7468  eModelOutputWith
+0000d610: 506f 6f6c 696e 6741 6e64 4372 6f73 7341  PoolingAndCrossA
+0000d620: 7474 656e 7469 6f6e 7328 0a20 2020 2020  ttentions(.     
+0000d630: 2020 2020 2020 206c 6173 745f 6869 6464         last_hidd
+0000d640: 656e 5f73 7461 7465 3d73 6571 7565 6e63  en_state=sequenc
+0000d650: 655f 6f75 7470 7574 2c0a 2020 2020 2020  e_output,.      
+0000d660: 2020 2020 2020 706f 6f6c 6572 5f6f 7574        pooler_out
+0000d670: 7075 743d 706f 6f6c 6564 5f6f 7574 7075  put=pooled_outpu
+0000d680: 742c 0a20 2020 2020 2020 2020 2020 2070  t,.            p
+0000d690: 6173 745f 6b65 795f 7661 6c75 6573 3d65  ast_key_values=e
+0000d6a0: 6e63 6f64 6572 5f6f 7574 7075 7473 2e70  ncoder_outputs.p
+0000d6b0: 6173 745f 6b65 795f 7661 6c75 6573 2c0a  ast_key_values,.
+0000d6c0: 2020 2020 2020 2020 2020 2020 6869 6464              hidd
+0000d6d0: 656e 5f73 7461 7465 733d 656e 636f 6465  en_states=encode
+0000d6e0: 725f 6f75 7470 7574 732e 6869 6464 656e  r_outputs.hidden
+0000d6f0: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
+0000d700: 2020 2020 2061 7474 656e 7469 6f6e 733d       attentions=
+0000d710: 656e 636f 6465 725f 6f75 7470 7574 732e  encoder_outputs.
+0000d720: 6174 7465 6e74 696f 6e73 2c0a 2020 2020  attentions,.    
+0000d730: 2020 2020 2020 2020 6372 6f73 735f 6174          cross_at
+0000d740: 7465 6e74 696f 6e73 3d65 6e63 6f64 6572  tentions=encoder
+0000d750: 5f6f 7574 7075 7473 2e63 726f 7373 5f61  _outputs.cross_a
+0000d760: 7474 656e 7469 6f6e 732c 0a20 2020 2020  ttentions,.     
+0000d770: 2020 2029 0a0a 0a63 6c61 7373 2042 6572     )...class Ber
+0000d780: 7446 6f72 5072 6554 7261 696e 696e 6728  tForPreTraining(
+0000d790: 4265 7274 5072 6554 7261 696e 6564 4d6f  BertPreTrainedMo
+0000d7a0: 6465 6c29 3a0a 0a20 2020 2064 6566 205f  del):..    def _
+0000d7b0: 5f69 6e69 745f 5f28 7365 6c66 2c20 636f  _init__(self, co
+0000d7c0: 6e66 6967 293a 0a20 2020 2020 2020 2073  nfig):.        s
+0000d7d0: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+0000d7e0: 636f 6e66 6967 290a 0a20 2020 2020 2020  config)..       
+0000d7f0: 2073 656c 662e 6265 7274 203d 2042 6572   self.bert = Ber
+0000d800: 744d 6f64 656c 2863 6f6e 6669 6729 0a20  tModel(config). 
+0000d810: 2020 2020 2020 2073 656c 662e 636c 7320         self.cls 
+0000d820: 3d20 4265 7274 5072 6554 7261 696e 696e  = BertPreTrainin
+0000d830: 6748 6561 6473 2863 6f6e 6669 6729 0a0a  gHeads(config)..
+0000d840: 2020 2020 2020 2020 7365 6c66 2e69 6e69          self.ini
+0000d850: 745f 7765 6967 6874 7328 290a 0a20 2020  t_weights()..   
+0000d860: 2064 6566 2067 6574 5f6f 7574 7075 745f   def get_output_
+0000d870: 656d 6265 6464 696e 6773 2873 656c 6629  embeddings(self)
+0000d880: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
+0000d890: 2073 656c 662e 636c 732e 7072 6564 6963   self.cls.predic
+0000d8a0: 7469 6f6e 732e 6465 636f 6465 720a 0a20  tions.decoder.. 
+0000d8b0: 2020 2064 6566 2073 6574 5f6f 7574 7075     def set_outpu
+0000d8c0: 745f 656d 6265 6464 696e 6773 2873 656c  t_embeddings(sel
+0000d8d0: 662c 206e 6577 5f65 6d62 6564 6469 6e67  f, new_embedding
+0000d8e0: 7329 3a0a 2020 2020 2020 2020 7365 6c66  s):.        self
+0000d8f0: 2e63 6c73 2e70 7265 6469 6374 696f 6e73  .cls.predictions
+0000d900: 2e64 6563 6f64 6572 203d 206e 6577 5f65  .decoder = new_e
+0000d910: 6d62 6564 6469 6e67 730a 0a20 2020 2064  mbeddings..    d
+0000d920: 6566 2066 6f72 7761 7264 280a 2020 2020  ef forward(.    
+0000d930: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+0000d940: 2020 696e 7075 745f 6964 733d 4e6f 6e65    input_ids=None
+0000d950: 2c0a 2020 2020 2020 2020 6174 7465 6e74  ,.        attent
+0000d960: 696f 6e5f 6d61 736b 3d4e 6f6e 652c 0a20  ion_mask=None,. 
+0000d970: 2020 2020 2020 2074 6f6b 656e 5f74 7970         token_typ
+0000d980: 655f 6964 733d 4e6f 6e65 2c0a 2020 2020  e_ids=None,.    
+0000d990: 2020 2020 706f 7369 7469 6f6e 5f69 6473      position_ids
+0000d9a0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2068  =None,.        h
+0000d9b0: 6561 645f 6d61 736b 3d4e 6f6e 652c 0a20  ead_mask=None,. 
+0000d9c0: 2020 2020 2020 2069 6e70 7574 735f 656d         inputs_em
+0000d9d0: 6265 6473 3d4e 6f6e 652c 0a20 2020 2020  beds=None,.     
+0000d9e0: 2020 206c 6162 656c 733d 4e6f 6e65 2c0a     labels=None,.
+0000d9f0: 2020 2020 2020 2020 6e65 7874 5f73 656e          next_sen
+0000da00: 7465 6e63 655f 6c61 6265 6c3d 4e6f 6e65  tence_label=None
+0000da10: 2c0a 2020 2020 2020 2020 6f75 7470 7574  ,.        output
+0000da20: 5f61 7474 656e 7469 6f6e 733d 4e6f 6e65  _attentions=None
+0000da30: 2c0a 2020 2020 2020 2020 6f75 7470 7574  ,.        output
+0000da40: 5f68 6964 6465 6e5f 7374 6174 6573 3d4e  _hidden_states=N
+0000da50: 6f6e 652c 0a20 2020 2020 2020 2072 6574  one,.        ret
+0000da60: 7572 6e5f 6469 6374 3d4e 6f6e 652c 0a20  urn_dict=None,. 
+0000da70: 2020 2029 3a0a 2020 2020 2020 2020 7222     ):.        r"
+0000da80: 2222 0a20 2020 2020 2020 206c 6162 656c  "".        label
+0000da90: 7320 283a 6f62 6a3a 6074 6f72 6368 2e4c  s (:obj:`torch.L
+0000daa0: 6f6e 6754 656e 736f 7260 206f 6620 7368  ongTensor` of sh
+0000dab0: 6170 6520 6060 2862 6174 6368 5f73 697a  ape ``(batch_siz
+0000dac0: 652c 2073 6571 7565 6e63 655f 6c65 6e67  e, sequence_leng
+0000dad0: 7468 2960 602c 2060 6f70 7469 6f6e 616c  th)``, `optional
+0000dae0: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
+0000daf0: 4c61 6265 6c73 2066 6f72 2063 6f6d 7075  Labels for compu
+0000db00: 7469 6e67 2074 6865 206d 6173 6b65 6420  ting the masked 
+0000db10: 6c61 6e67 7561 6765 206d 6f64 656c 696e  language modelin
+0000db20: 6720 6c6f 7373 2e20 496e 6469 6365 7320  g loss. Indices 
+0000db30: 7368 6f75 6c64 2062 6520 696e 2060 605b  should be in ``[
+0000db40: 2d31 3030 2c20 302c 202e 2e2e 2c0a 2020  -100, 0, ...,.  
+0000db50: 2020 2020 2020 2020 2020 636f 6e66 6967            config
+0000db60: 2e76 6f63 6162 5f73 697a 655d 6060 2028  .vocab_size]`` (
+0000db70: 7365 6520 6060 696e 7075 745f 6964 7360  see ``input_ids`
+0000db80: 6020 646f 6373 7472 696e 6729 2054 6f6b  ` docstring) Tok
+0000db90: 656e 7320 7769 7468 2069 6e64 6963 6573  ens with indices
+0000dba0: 2073 6574 2074 6f20 6060 2d31 3030 6060   set to ``-100``
+0000dbb0: 2061 7265 2069 676e 6f72 6564 0a20 2020   are ignored.   
+0000dbc0: 2020 2020 2020 2020 2028 6d61 736b 6564           (masked
+0000dbd0: 292c 2074 6865 206c 6f73 7320 6973 206f  ), the loss is o
+0000dbe0: 6e6c 7920 636f 6d70 7574 6564 2066 6f72  nly computed for
+0000dbf0: 2074 6865 2074 6f6b 656e 7320 7769 7468   the tokens with
+0000dc00: 206c 6162 656c 7320 696e 2060 605b 302c   labels in ``[0,
+0000dc10: 202e 2e2e 2c20 636f 6e66 6967 2e76 6f63   ..., config.voc
+0000dc20: 6162 5f73 697a 655d 6060 0a20 2020 2020  ab_size]``.     
+0000dc30: 2020 206e 6578 745f 7365 6e74 656e 6365     next_sentence
+0000dc40: 5f6c 6162 656c 2028 6060 746f 7263 682e  _label (``torch.
+0000dc50: 4c6f 6e67 5465 6e73 6f72 6060 206f 6620  LongTensor`` of 
+0000dc60: 7368 6170 6520 6060 2862 6174 6368 5f73  shape ``(batch_s
+0000dc70: 697a 652c 2960 602c 2060 6f70 7469 6f6e  ize,)``, `option
+0000dc80: 616c 6029 3a0a 2020 2020 2020 2020 2020  al`):.          
+0000dc90: 2020 4c61 6265 6c73 2066 6f72 2063 6f6d    Labels for com
+0000dca0: 7075 7469 6e67 2074 6865 206e 6578 7420  puting the next 
+0000dcb0: 7365 7175 656e 6365 2070 7265 6469 6374  sequence predict
+0000dcc0: 696f 6e20 2863 6c61 7373 6966 6963 6174  ion (classificat
+0000dcd0: 696f 6e29 206c 6f73 732e 2049 6e70 7574  ion) loss. Input
+0000dce0: 2073 686f 756c 6420 6265 2061 2073 6571   should be a seq
+0000dcf0: 7565 6e63 6520 7061 6972 0a20 2020 2020  uence pair.     
+0000dd00: 2020 2020 2020 2028 7365 6520 3a6f 626a         (see :obj
+0000dd10: 3a60 696e 7075 745f 6964 7360 2064 6f63  :`input_ids` doc
+0000dd20: 7374 7269 6e67 2920 496e 6469 6365 7320  string) Indices 
+0000dd30: 7368 6f75 6c64 2062 6520 696e 2060 605b  should be in ``[
+0000dd40: 302c 2031 5d60 603a 0a20 2020 2020 2020  0, 1]``:.       
+0000dd50: 2020 2020 202d 2030 2069 6e64 6963 6174       - 0 indicat
+0000dd60: 6573 2073 6571 7565 6e63 6520 4220 6973  es sequence B is
+0000dd70: 2061 2063 6f6e 7469 6e75 6174 696f 6e20   a continuation 
+0000dd80: 6f66 2073 6571 7565 6e63 6520 412c 0a20  of sequence A,. 
+0000dd90: 2020 2020 2020 2020 2020 202d 2031 2069             - 1 i
+0000dda0: 6e64 6963 6174 6573 2073 6571 7565 6e63  ndicates sequenc
+0000ddb0: 6520 4220 6973 2061 2072 616e 646f 6d20  e B is a random 
+0000ddc0: 7365 7175 656e 6365 2e0a 2020 2020 2020  sequence..      
+0000ddd0: 2020 6b77 6172 6773 2028 3a6f 626a 3a60    kwargs (:obj:`
+0000dde0: 4469 6374 5b73 7472 2c20 616e 795d 602c  Dict[str, any]`,
+0000ddf0: 206f 7074 696f 6e61 6c2c 2064 6566 6175   optional, defau
+0000de00: 6c74 7320 746f 2060 7b7d 6029 3a0a 2020  lts to `{}`):.  
+0000de10: 2020 2020 2020 2020 2020 5573 6564 2074            Used t
+0000de20: 6f20 6869 6465 206c 6567 6163 7920 6172  o hide legacy ar
+0000de30: 6775 6d65 6e74 7320 7468 6174 2068 6176  guments that hav
+0000de40: 6520 6265 656e 2064 6570 7265 6361 7465  e been deprecate
+0000de50: 642e 0a20 2020 2020 2020 2052 6574 7572  d..        Retur
+0000de60: 6e73 3a0a 2020 2020 2020 2020 4578 616d  ns:.        Exam
+0000de70: 706c 653a 0a20 2020 2020 2020 2020 2020  ple:.           
+0000de80: 203e 3e3e 2066 726f 6d20 7472 616e 7366   >>> from transf
+0000de90: 6f72 6d65 7273 2069 6d70 6f72 7420 4265  ormers import Be
+0000dea0: 7274 546f 6b65 6e69 7a65 722c 2042 6572  rtTokenizer, Ber
+0000deb0: 7446 6f72 5072 6554 7261 696e 696e 670a  tForPreTraining.
+0000dec0: 2020 2020 2020 2020 2020 2020 3e3e 3e20              >>> 
+0000ded0: 696d 706f 7274 2074 6f72 6368 0a20 2020  import torch.   
+0000dee0: 2020 2020 2020 2020 203e 3e3e 2074 6f6b           >>> tok
+0000def0: 656e 697a 6572 203d 2042 6572 7454 6f6b  enizer = BertTok
+0000df00: 656e 697a 6572 2e66 726f 6d5f 7072 6574  enizer.from_pret
+0000df10: 7261 696e 6564 2827 6265 7274 2d62 6173  rained('bert-bas
+0000df20: 652d 756e 6361 7365 6427 290a 2020 2020  e-uncased').    
+0000df30: 2020 2020 2020 2020 3e3e 3e20 6d6f 6465          >>> mode
+0000df40: 6c20 3d20 4265 7274 466f 7250 7265 5472  l = BertForPreTr
+0000df50: 6169 6e69 6e67 2e66 726f 6d5f 7072 6574  aining.from_pret
+0000df60: 7261 696e 6564 2827 6265 7274 2d62 6173  rained('bert-bas
+0000df70: 652d 756e 6361 7365 6427 290a 2020 2020  e-uncased').    
+0000df80: 2020 2020 2020 2020 3e3e 3e20 696e 7075          >>> inpu
+0000df90: 7473 203d 2074 6f6b 656e 697a 6572 2822  ts = tokenizer("
+0000dfa0: 4865 6c6c 6f2c 206d 7920 646f 6720 6973  Hello, my dog is
+0000dfb0: 2063 7574 6522 2c20 7265 7475 726e 5f74   cute", return_t
+0000dfc0: 656e 736f 7273 3d22 7074 2229 0a20 2020  ensors="pt").   
+0000dfd0: 2020 2020 2020 2020 203e 3e3e 206f 7574           >>> out
+0000dfe0: 7075 7473 203d 206d 6f64 656c 282a 2a69  puts = model(**i
+0000dff0: 6e70 7574 7329 0a20 2020 2020 2020 2020  nputs).         
+0000e000: 2020 203e 3e3e 2070 7265 6469 6374 696f     >>> predictio
+0000e010: 6e5f 6c6f 6769 7473 203d 206f 7574 7075  n_logits = outpu
+0000e020: 7473 2e70 7265 6469 6374 696f 6e5f 6c6f  ts.prediction_lo
+0000e030: 6769 7473 0a20 2020 2020 2020 2020 2020  gits.           
+0000e040: 203e 3e3e 2073 6571 5f72 656c 6174 696f   >>> seq_relatio
+0000e050: 6e73 6869 705f 6c6f 6769 7473 203d 206f  nship_logits = o
+0000e060: 7574 7075 7473 2e73 6571 5f72 656c 6174  utputs.seq_relat
+0000e070: 696f 6e73 6869 705f 6c6f 6769 7473 0a20  ionship_logits. 
+0000e080: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+0000e090: 2020 2072 6574 7572 6e5f 6469 6374 203d     return_dict =
+0000e0a0: 2072 6574 7572 6e5f 6469 6374 2069 6620   return_dict if 
+0000e0b0: 7265 7475 726e 5f64 6963 7420 6973 206e  return_dict is n
+0000e0c0: 6f74 204e 6f6e 6520 656c 7365 2073 656c  ot None else sel
+0000e0d0: 662e 636f 6e66 6967 2e75 7365 5f72 6574  f.config.use_ret
+0000e0e0: 7572 6e5f 6469 6374 0a0a 2020 2020 2020  urn_dict..      
+0000e0f0: 2020 6f75 7470 7574 7320 3d20 7365 6c66    outputs = self
+0000e100: 2e62 6572 7428 0a20 2020 2020 2020 2020  .bert(.         
+0000e110: 2020 2069 6e70 7574 5f69 6473 2c0a 2020     input_ids,.  
+0000e120: 2020 2020 2020 2020 2020 6174 7465 6e74            attent
+0000e130: 696f 6e5f 6d61 736b 3d61 7474 656e 7469  ion_mask=attenti
+0000e140: 6f6e 5f6d 6173 6b2c 0a20 2020 2020 2020  on_mask,.       
+0000e150: 2020 2020 2074 6f6b 656e 5f74 7970 655f       token_type_
+0000e160: 6964 733d 746f 6b65 6e5f 7479 7065 5f69  ids=token_type_i
+0000e170: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
+0000e180: 706f 7369 7469 6f6e 5f69 6473 3d70 6f73  position_ids=pos
+0000e190: 6974 696f 6e5f 6964 732c 0a20 2020 2020  ition_ids,.     
+0000e1a0: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
+0000e1b0: 3d68 6561 645f 6d61 736b 2c0a 2020 2020  =head_mask,.    
+0000e1c0: 2020 2020 2020 2020 696e 7075 7473 5f65          inputs_e
+0000e1d0: 6d62 6564 733d 696e 7075 7473 5f65 6d62  mbeds=inputs_emb
+0000e1e0: 6564 732c 0a20 2020 2020 2020 2020 2020  eds,.           
+0000e1f0: 206f 7574 7075 745f 6174 7465 6e74 696f   output_attentio
+0000e200: 6e73 3d6f 7574 7075 745f 6174 7465 6e74  ns=output_attent
+0000e210: 696f 6e73 2c0a 2020 2020 2020 2020 2020  ions,.          
+0000e220: 2020 6f75 7470 7574 5f68 6964 6465 6e5f    output_hidden_
+0000e230: 7374 6174 6573 3d6f 7574 7075 745f 6869  states=output_hi
+0000e240: 6464 656e 5f73 7461 7465 732c 0a20 2020  dden_states,.   
+0000e250: 2020 2020 2020 2020 2072 6574 7572 6e5f           return_
+0000e260: 6469 6374 3d72 6574 7572 6e5f 6469 6374  dict=return_dict
+0000e270: 2c0a 2020 2020 2020 2020 290a 0a20 2020  ,.        )..   
+0000e280: 2020 2020 2073 6571 7565 6e63 655f 6f75       sequence_ou
+0000e290: 7470 7574 2c20 706f 6f6c 6564 5f6f 7574  tput, pooled_out
+0000e2a0: 7075 7420 3d20 6f75 7470 7574 735b 3a32  put = outputs[:2
+0000e2b0: 5d0a 2020 2020 2020 2020 7072 6564 6963  ].        predic
+0000e2c0: 7469 6f6e 5f73 636f 7265 732c 2073 6571  tion_scores, seq
+0000e2d0: 5f72 656c 6174 696f 6e73 6869 705f 7363  _relationship_sc
+0000e2e0: 6f72 6520 3d20 7365 6c66 2e63 6c73 280a  ore = self.cls(.
+0000e2f0: 2020 2020 2020 2020 2020 2020 7365 7175              sequ
+0000e300: 656e 6365 5f6f 7574 7075 742c 2070 6f6f  ence_output, poo
+0000e310: 6c65 645f 6f75 7470 7574 290a 0a20 2020  led_output)..   
+0000e320: 2020 2020 2074 6f74 616c 5f6c 6f73 7320       total_loss 
+0000e330: 3d20 4e6f 6e65 0a20 2020 2020 2020 2069  = None.        i
+0000e340: 6620 6c61 6265 6c73 2069 7320 6e6f 7420  f labels is not 
+0000e350: 4e6f 6e65 2061 6e64 206e 6578 745f 7365  None and next_se
+0000e360: 6e74 656e 6365 5f6c 6162 656c 2069 7320  ntence_label is 
+0000e370: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+0000e380: 2020 2020 2020 6c6f 7373 5f66 6374 203d        loss_fct =
+0000e390: 2043 726f 7373 456e 7472 6f70 794c 6f73   CrossEntropyLos
+0000e3a0: 7328 290a 2020 2020 2020 2020 2020 2020  s().            
+0000e3b0: 6d61 736b 6564 5f6c 6d5f 6c6f 7373 203d  masked_lm_loss =
+0000e3c0: 206c 6f73 735f 6663 7428 0a20 2020 2020   loss_fct(.     
+0000e3d0: 2020 2020 2020 2020 2020 2070 7265 6469             predi
+0000e3e0: 6374 696f 6e5f 7363 6f72 6573 2e76 6965  ction_scores.vie
+0000e3f0: 7728 2d31 2c20 7365 6c66 2e63 6f6e 6669  w(-1, self.confi
+0000e400: 672e 766f 6361 625f 7369 7a65 292c 0a20  g.vocab_size),. 
+0000e410: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+0000e420: 6162 656c 732e 7669 6577 282d 3129 290a  abels.view(-1)).
+0000e430: 2020 2020 2020 2020 2020 2020 6e65 7874              next
+0000e440: 5f73 656e 7465 6e63 655f 6c6f 7373 203d  _sentence_loss =
+0000e450: 206c 6f73 735f 6663 7428 0a20 2020 2020   loss_fct(.     
+0000e460: 2020 2020 2020 2020 2020 2073 6571 5f72             seq_r
+0000e470: 656c 6174 696f 6e73 6869 705f 7363 6f72  elationship_scor
+0000e480: 652e 7669 6577 282d 312c 2032 292c 0a20  e.view(-1, 2),. 
+0000e490: 2020 2020 2020 2020 2020 2020 2020 206e                 n
+0000e4a0: 6578 745f 7365 6e74 656e 6365 5f6c 6162  ext_sentence_lab
+0000e4b0: 656c 2e76 6965 7728 2d31 2929 0a20 2020  el.view(-1)).   
+0000e4c0: 2020 2020 2020 2020 2074 6f74 616c 5f6c           total_l
+0000e4d0: 6f73 7320 3d20 6d61 736b 6564 5f6c 6d5f  oss = masked_lm_
+0000e4e0: 6c6f 7373 202b 206e 6578 745f 7365 6e74  loss + next_sent
+0000e4f0: 656e 6365 5f6c 6f73 730a 0a20 2020 2020  ence_loss..     
+0000e500: 2020 2069 6620 6e6f 7420 7265 7475 726e     if not return
+0000e510: 5f64 6963 743a 0a20 2020 2020 2020 2020  _dict:.         
+0000e520: 2020 206f 7574 7075 7420 3d20 2870 7265     output = (pre
+0000e530: 6469 6374 696f 6e5f 7363 6f72 6573 2c20  diction_scores, 
+0000e540: 7365 715f 7265 6c61 7469 6f6e 7368 6970  seq_relationship
+0000e550: 5f73 636f 7265 2920 2b20 6f75 7470 7574  _score) + output
+0000e560: 735b 323a 5d0a 2020 2020 2020 2020 2020  s[2:].          
+0000e570: 2020 7265 7475 726e 2028 2874 6f74 616c    return ((total
+0000e580: 5f6c 6f73 732c 2029 0a20 2020 2020 2020  _loss, ).       
+0000e590: 2020 2020 2020 2020 2020 2020 202b 206f               + o
+0000e5a0: 7574 7075 7429 2069 6620 746f 7461 6c5f  utput) if total_
+0000e5b0: 6c6f 7373 2069 7320 6e6f 7420 4e6f 6e65  loss is not None
+0000e5c0: 2065 6c73 6520 6f75 7470 7574 0a0a 2020   else output..  
+0000e5d0: 2020 2020 2020 7265 7475 726e 2042 6572        return Ber
+0000e5e0: 7446 6f72 5072 6554 7261 696e 696e 674f  tForPreTrainingO
+0000e5f0: 7574 7075 7428 0a20 2020 2020 2020 2020  utput(.         
+0000e600: 2020 206c 6f73 733d 746f 7461 6c5f 6c6f     loss=total_lo
+0000e610: 7373 2c0a 2020 2020 2020 2020 2020 2020  ss,.            
+0000e620: 7072 6564 6963 7469 6f6e 5f6c 6f67 6974  prediction_logit
+0000e630: 733d 7072 6564 6963 7469 6f6e 5f73 636f  s=prediction_sco
+0000e640: 7265 732c 0a20 2020 2020 2020 2020 2020  res,.           
+0000e650: 2073 6571 5f72 656c 6174 696f 6e73 6869   seq_relationshi
+0000e660: 705f 6c6f 6769 7473 3d73 6571 5f72 656c  p_logits=seq_rel
+0000e670: 6174 696f 6e73 6869 705f 7363 6f72 652c  ationship_score,
+0000e680: 0a20 2020 2020 2020 2020 2020 2068 6964  .            hid
+0000e690: 6465 6e5f 7374 6174 6573 3d6f 7574 7075  den_states=outpu
+0000e6a0: 7473 2e68 6964 6465 6e5f 7374 6174 6573  ts.hidden_states
+0000e6b0: 2c0a 2020 2020 2020 2020 2020 2020 6174  ,.            at
+0000e6c0: 7465 6e74 696f 6e73 3d6f 7574 7075 7473  tentions=outputs
+0000e6d0: 2e61 7474 656e 7469 6f6e 732c 0a20 2020  .attentions,.   
+0000e6e0: 2020 2020 2029 0a0a 0a63 6c61 7373 2042       )...class B
+0000e6f0: 6572 744c 4d48 6561 644d 6f64 656c 2842  ertLMHeadModel(B
+0000e700: 6572 7450 7265 5472 6169 6e65 644d 6f64  ertPreTrainedMod
+0000e710: 656c 293a 0a0a 2020 2020 5f6b 6579 735f  el):..    _keys_
+0000e720: 746f 5f69 676e 6f72 655f 6f6e 5f6c 6f61  to_ignore_on_loa
+0000e730: 645f 756e 6578 7065 6374 6564 203d 205b  d_unexpected = [
+0000e740: 7227 706f 6f6c 6572 275d 0a20 2020 205f  r'pooler'].    _
+0000e750: 6b65 7973 5f74 6f5f 6967 6e6f 7265 5f6f  keys_to_ignore_o
+0000e760: 6e5f 6c6f 6164 5f6d 6973 7369 6e67 203d  n_load_missing =
+0000e770: 205b 0a20 2020 2020 2020 2072 2770 6f73   [.        r'pos
+0000e780: 6974 696f 6e5f 6964 7327 2c20 7227 7072  ition_ids', r'pr
+0000e790: 6564 6963 7469 6f6e 732e 6465 636f 6465  edictions.decode
+0000e7a0: 722e 6269 6173 270a 2020 2020 5d0a 0a20  r.bias'.    ].. 
+0000e7b0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+0000e7c0: 7365 6c66 2c20 636f 6e66 6967 293a 0a20  self, config):. 
+0000e7d0: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
+0000e7e0: 5f69 6e69 745f 5f28 636f 6e66 6967 290a  _init__(config).
+0000e7f0: 0a20 2020 2020 2020 2073 656c 662e 6265  .        self.be
+0000e800: 7274 203d 2042 6572 744d 6f64 656c 2863  rt = BertModel(c
+0000e810: 6f6e 6669 672c 2061 6464 5f70 6f6f 6c69  onfig, add_pooli
+0000e820: 6e67 5f6c 6179 6572 3d46 616c 7365 290a  ng_layer=False).
+0000e830: 2020 2020 2020 2020 7365 6c66 2e63 6c73          self.cls
+0000e840: 203d 2042 6572 744f 6e6c 794d 4c4d 4865   = BertOnlyMLMHe
+0000e850: 6164 2863 6f6e 6669 6729 0a0a 2020 2020  ad(config)..    
+0000e860: 2020 2020 7365 6c66 2e69 6e69 745f 7765      self.init_we
+0000e870: 6967 6874 7328 290a 0a20 2020 2064 6566  ights()..    def
+0000e880: 2067 6574 5f6f 7574 7075 745f 656d 6265   get_output_embe
+0000e890: 6464 696e 6773 2873 656c 6629 3a0a 2020  ddings(self):.  
+0000e8a0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+0000e8b0: 662e 636c 732e 7072 6564 6963 7469 6f6e  f.cls.prediction
+0000e8c0: 732e 6465 636f 6465 720a 0a20 2020 2064  s.decoder..    d
+0000e8d0: 6566 2073 6574 5f6f 7574 7075 745f 656d  ef set_output_em
+0000e8e0: 6265 6464 696e 6773 2873 656c 662c 206e  beddings(self, n
+0000e8f0: 6577 5f65 6d62 6564 6469 6e67 7329 3a0a  ew_embeddings):.
+0000e900: 2020 2020 2020 2020 7365 6c66 2e63 6c73          self.cls
+0000e910: 2e70 7265 6469 6374 696f 6e73 2e64 6563  .predictions.dec
+0000e920: 6f64 6572 203d 206e 6577 5f65 6d62 6564  oder = new_embed
+0000e930: 6469 6e67 730a 0a20 2020 2064 6566 2066  dings..    def f
+0000e940: 6f72 7761 7264 280a 2020 2020 2020 2020  orward(.        
+0000e950: 7365 6c66 2c0a 2020 2020 2020 2020 696e  self,.        in
+0000e960: 7075 745f 6964 733d 4e6f 6e65 2c0a 2020  put_ids=None,.  
+0000e970: 2020 2020 2020 6174 7465 6e74 696f 6e5f        attention_
+0000e980: 6d61 736b 3d4e 6f6e 652c 0a20 2020 2020  mask=None,.     
+0000e990: 2020 2074 6f6b 656e 5f74 7970 655f 6964     token_type_id
+0000e9a0: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
+0000e9b0: 706f 7369 7469 6f6e 5f69 6473 3d4e 6f6e  position_ids=Non
+0000e9c0: 652c 0a20 2020 2020 2020 2068 6561 645f  e,.        head_
+0000e9d0: 6d61 736b 3d4e 6f6e 652c 0a20 2020 2020  mask=None,.     
+0000e9e0: 2020 2069 6e70 7574 735f 656d 6265 6473     inputs_embeds
+0000e9f0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2065  =None,.        e
+0000ea00: 6e63 6f64 6572 5f68 6964 6465 6e5f 7374  ncoder_hidden_st
+0000ea10: 6174 6573 3d4e 6f6e 652c 0a20 2020 2020  ates=None,.     
+0000ea20: 2020 2065 6e63 6f64 6572 5f61 7474 656e     encoder_atten
+0000ea30: 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65 2c0a  tion_mask=None,.
+0000ea40: 2020 2020 2020 2020 6c61 6265 6c73 3d4e          labels=N
+0000ea50: 6f6e 652c 0a20 2020 2020 2020 2070 6173  one,.        pas
+0000ea60: 745f 6b65 795f 7661 6c75 6573 3d4e 6f6e  t_key_values=Non
+0000ea70: 652c 0a20 2020 2020 2020 2075 7365 5f63  e,.        use_c
+0000ea80: 6163 6865 3d4e 6f6e 652c 0a20 2020 2020  ache=None,.     
+0000ea90: 2020 206f 7574 7075 745f 6174 7465 6e74     output_attent
+0000eaa0: 696f 6e73 3d4e 6f6e 652c 0a20 2020 2020  ions=None,.     
+0000eab0: 2020 206f 7574 7075 745f 6869 6464 656e     output_hidden
+0000eac0: 5f73 7461 7465 733d 4e6f 6e65 2c0a 2020  _states=None,.  
+0000ead0: 2020 2020 2020 7265 7475 726e 5f64 6963        return_dic
+0000eae0: 743d 4e6f 6e65 2c0a 2020 2020 2020 2020  t=None,.        
+0000eaf0: 6973 5f64 6563 6f64 6572 3d54 7275 652c  is_decoder=True,
+0000eb00: 0a20 2020 2020 2020 2072 6564 7563 7469  .        reducti
+0000eb10: 6f6e 3d27 6d65 616e 272c 0a20 2020 2020  on='mean',.     
+0000eb20: 2020 206d 6f64 653d 276d 756c 7469 5f6d     mode='multi_m
+0000eb30: 6f64 616c 272c 0a20 2020 2020 2020 2073  odal',.        s
+0000eb40: 6f66 745f 6c61 6265 6c73 3d4e 6f6e 652c  oft_labels=None,
+0000eb50: 0a20 2020 2020 2020 2061 6c70 6861 3d30  .        alpha=0
+0000eb60: 2c0a 2020 2020 2020 2020 7265 7475 726e  ,.        return
+0000eb70: 5f6c 6f67 6974 733d 4661 6c73 652c 0a20  _logits=False,. 
+0000eb80: 2020 2029 3a0a 2020 2020 2020 2020 7222     ):.        r"
+0000eb90: 2222 0a20 2020 2020 2020 2065 6e63 6f64  "".        encod
+0000eba0: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
+0000ebb0: 2020 283a 6f62 6a3a 6074 6f72 6368 2e46    (:obj:`torch.F
+0000ebc0: 6c6f 6174 5465 6e73 6f72 6020 6f66 2073  loatTensor` of s
+0000ebd0: 6861 7065 0a20 2020 2020 2020 203a 6f62  hape.        :ob
+0000ebe0: 6a3a 6028 6261 7463 685f 7369 7a65 2c20  j:`(batch_size, 
+0000ebf0: 7365 7175 656e 6365 5f6c 656e 6774 682c  sequence_length,
+0000ec00: 2068 6964 6465 6e5f 7369 7a65 2960 2c20   hidden_size)`, 
+0000ec10: 606f 7074 696f 6e61 6c60 293a 0a20 2020  `optional`):.   
+0000ec20: 2020 2020 2020 2020 2053 6571 7565 6e63           Sequenc
+0000ec30: 6520 6f66 2068 6964 6465 6e2d 7374 6174  e of hidden-stat
+0000ec40: 6573 2061 7420 7468 6520 6f75 7470 7574  es at the output
+0000ec50: 206f 6620 7468 6520 6c61 7374 206c 6179   of the last lay
+0000ec60: 6572 206f 6620 7468 650a 2020 2020 2020  er of the.      
+0000ec70: 2020 2020 2020 656e 636f 6465 722e 2055        encoder. U
+0000ec80: 7365 6420 696e 2074 6865 2063 726f 7373  sed in the cross
+0000ec90: 2d61 7474 656e 7469 6f6e 2069 6620 7468  -attention if th
+0000eca0: 6520 6d6f 6465 6c20 6973 2063 6f6e 6669  e model is confi
+0000ecb0: 6775 7265 6420 6173 2061 0a20 2020 2020  gured as a.     
+0000ecc0: 2020 2020 2020 2064 6563 6f64 6572 2e0a         decoder..
+0000ecd0: 2020 2020 2020 2020 656e 636f 6465 725f          encoder_
+0000ece0: 6174 7465 6e74 696f 6e5f 6d61 736b 2028  attention_mask (
+0000ecf0: 3a6f 626a 3a60 746f 7263 682e 466c 6f61  :obj:`torch.Floa
+0000ed00: 7454 656e 736f 7260 206f 6620 7368 6170  tTensor` of shap
+0000ed10: 650a 2020 2020 2020 2020 3a6f 626a 3a60  e.        :obj:`
+0000ed20: 2862 6174 6368 5f73 697a 652c 2073 6571  (batch_size, seq
+0000ed30: 7565 6e63 655f 6c65 6e67 7468 2960 2c20  uence_length)`, 
+0000ed40: 606f 7074 696f 6e61 6c60 293a 0a20 2020  `optional`):.   
+0000ed50: 2020 2020 2020 2020 204d 6173 6b20 746f           Mask to
+0000ed60: 2061 766f 6964 2070 6572 666f 726d 696e   avoid performin
+0000ed70: 6720 6174 7465 6e74 696f 6e20 6f6e 2074  g attention on t
+0000ed80: 6865 2070 6164 6469 6e67 2074 6f6b 656e  he padding token
+0000ed90: 2069 6e64 6963 6573 206f 660a 2020 2020   indices of.    
+0000eda0: 2020 2020 2020 2020 7468 6520 656e 636f          the enco
+0000edb0: 6465 7220 696e 7075 742e 2054 6869 7320  der input. This 
+0000edc0: 6d61 736b 2069 7320 7573 6564 2069 6e20  mask is used in 
+0000edd0: 7468 6520 6372 6f73 732d 6174 7465 6e74  the cross-attent
+0000ede0: 696f 6e20 6966 2074 6865 0a20 2020 2020  ion if the.     
+0000edf0: 2020 2020 2020 206d 6f64 656c 2069 7320         model is 
+0000ee00: 636f 6e66 6967 7572 6564 2061 7320 6120  configured as a 
+0000ee10: 6465 636f 6465 722e 204d 6173 6b20 7661  decoder. Mask va
+0000ee20: 6c75 6573 2073 656c 6563 7465 6420 696e  lues selected in
+0000ee30: 2060 605b 302c 0a20 2020 2020 2020 2020   ``[0,.         
+0000ee40: 2020 2031 5d60 603a 202d 2031 2066 6f72     1]``: - 1 for
+0000ee50: 2074 6f6b 656e 7320 7468 6174 2061 7265   tokens that are
+0000ee60: 202a 2a6e 6f74 206d 6173 6b65 642a 2a2c   **not masked**,
+0000ee70: 202d 2030 2066 6f72 2074 6f6b 656e 7320   - 0 for tokens 
+0000ee80: 7468 6174 0a20 2020 2020 2020 2020 2020  that.           
+0000ee90: 2061 7265 202a 2a6d 6173 6b65 642a 2a2e   are **masked**.
+0000eea0: 0a20 2020 2020 2020 206c 6162 656c 7320  .        labels 
+0000eeb0: 283a 6f62 6a3a 6074 6f72 6368 2e4c 6f6e  (:obj:`torch.Lon
+0000eec0: 6754 656e 736f 7260 206f 6620 7368 6170  gTensor` of shap
+0000eed0: 6520 3a6f 626a 3a60 2862 6174 6368 5f73  e :obj:`(batch_s
+0000eee0: 697a 652c 0a20 2020 2020 2020 2073 6571  ize,.        seq
+0000eef0: 7565 6e63 655f 6c65 6e67 7468 2960 2c20  uence_length)`, 
+0000ef00: 606f 7074 696f 6e61 6c60 293a 0a20 2020  `optional`):.   
+0000ef10: 2020 2020 2020 2020 204c 6162 656c 7320           Labels 
+0000ef20: 666f 7220 636f 6d70 7574 696e 6720 7468  for computing th
+0000ef30: 6520 6c65 6674 2d74 6f2d 7269 6768 7420  e left-to-right 
+0000ef40: 6c61 6e67 7561 6765 206d 6f64 656c 696e  language modelin
+0000ef50: 6720 6c6f 7373 2028 6e65 7874 0a20 2020  g loss (next.   
+0000ef60: 2020 2020 2020 2020 2077 6f72 6420 7072           word pr
+0000ef70: 6564 6963 7469 6f6e 292e 2049 6e64 6963  ediction). Indic
+0000ef80: 6573 2073 686f 756c 6420 6265 2069 6e20  es should be in 
+0000ef90: 6060 5b2d 3130 302c 2030 2c20 2e2e 2e2c  ``[-100, 0, ...,
+0000efa0: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
+0000efb0: 6669 672e 766f 6361 625f 7369 7a65 5d60  fig.vocab_size]`
+0000efc0: 6020 2873 6565 2060 6069 6e70 7574 5f69  ` (see ``input_i
+0000efd0: 6473 6060 2064 6f63 7374 7269 6e67 2920  ds`` docstring) 
+0000efe0: 546f 6b65 6e73 2077 6974 680a 2020 2020  Tokens with.    
+0000eff0: 2020 2020 2020 2020 696e 6469 6365 7320          indices 
+0000f000: 7365 7420 746f 2060 602d 3130 3060 6020  set to ``-100`` 
+0000f010: 6172 6520 6967 6e6f 7265 6420 286d 6173  are ignored (mas
+0000f020: 6b65 6429 2c20 7468 6520 6c6f 7373 2069  ked), the loss i
+0000f030: 7320 6f6e 6c79 0a20 2020 2020 2020 2020  s only.         
+0000f040: 2020 2063 6f6d 7075 7465 6420 666f 7220     computed for 
+0000f050: 7468 6520 746f 6b65 6e73 2077 6974 6820  the tokens with 
+0000f060: 6c61 6265 6c73 206e 2060 605b 302c 202e  labels n ``[0, .
+0000f070: 2e2e 2c0a 2020 2020 2020 2020 2020 2020  ..,.            
+0000f080: 636f 6e66 6967 2e76 6f63 6162 5f73 697a  config.vocab_siz
+0000f090: 655d 6060 0a20 2020 2020 2020 2070 6173  e]``.        pas
+0000f0a0: 745f 6b65 795f 7661 6c75 6573 2028 3a6f  t_key_values (:o
+0000f0b0: 626a 3a60 7475 706c 6528 7475 706c 6528  bj:`tuple(tuple(
+0000f0c0: 746f 7263 682e 466c 6f61 7454 656e 736f  torch.FloatTenso
+0000f0d0: 7229 2960 206f 6620 6c65 6e67 7468 0a20  r))` of length. 
+0000f0e0: 2020 2020 2020 203a 6f62 6a3a 6063 6f6e         :obj:`con
+0000f0f0: 6669 672e 6e5f 6c61 7965 7273 6020 7769  fig.n_layers` wi
+0000f100: 7468 2065 6163 6820 7475 706c 6520 6861  th each tuple ha
+0000f110: 7669 6e67 2034 2074 656e 736f 7273 206f  ving 4 tensors o
+0000f120: 6620 7368 6170 650a 2020 2020 2020 2020  f shape.        
+0000f130: 3a6f 626a 3a60 2862 6174 6368 5f73 697a  :obj:`(batch_siz
+0000f140: 652c 206e 756d 5f68 6561 6473 2c20 7365  e, num_heads, se
+0000f150: 7175 656e 6365 5f6c 656e 6774 6820 2d20  quence_length - 
+0000f160: 312c 0a20 2020 2020 2020 2065 6d62 6564  1,.        embed
+0000f170: 5f73 697a 655f 7065 725f 6865 6164 2960  _size_per_head)`
+0000f180: 293a 0a20 2020 2020 2020 2020 2020 2043  ):.            C
+0000f190: 6f6e 7461 696e 7320 7072 6563 6f6d 7075  ontains precompu
+0000f1a0: 7465 6420 6b65 7920 616e 6420 7661 6c75  ted key and valu
+0000f1b0: 6520 6869 6464 656e 2073 7461 7465 7320  e hidden states 
+0000f1c0: 6f66 2074 6865 2061 7474 656e 7469 6f6e  of the attention
+0000f1d0: 0a20 2020 2020 2020 2020 2020 2062 6c6f  .            blo
+0000f1e0: 636b 732e 2043 616e 2062 6520 7573 6564  cks. Can be used
+0000f1f0: 2074 6f20 7370 6565 6420 7570 2064 6563   to speed up dec
+0000f200: 6f64 696e 672e 2049 6620 3a6f 626a 3a60  oding. If :obj:`
+0000f210: 7061 7374 5f6b 6579 5f76 616c 7565 7360  past_key_values`
+0000f220: 0a20 2020 2020 2020 2020 2020 2061 7265  .            are
+0000f230: 2075 7365 642c 2074 6865 2075 7365 7220   used, the user 
+0000f240: 6361 6e20 6f70 7469 6f6e 616c 6c79 2069  can optionally i
+0000f250: 6e70 7574 206f 6e6c 7920 7468 6520 6c61  nput only the la
+0000f260: 7374 0a20 2020 2020 2020 2020 2020 203a  st.            :
+0000f270: 6f62 6a3a 6064 6563 6f64 6572 5f69 6e70  obj:`decoder_inp
+0000f280: 7574 5f69 6473 6020 2874 686f 7365 2074  ut_ids` (those t
+0000f290: 6861 7420 646f 6e27 7420 6861 7665 2074  hat don't have t
+0000f2a0: 6865 6972 2070 6173 7420 6b65 7920 7661  heir past key va
+0000f2b0: 6c75 650a 2020 2020 2020 2020 2020 2020  lue.            
+0000f2c0: 7374 6174 6573 2067 6976 656e 2074 6f20  states given to 
+0000f2d0: 7468 6973 206d 6f64 656c 2920 6f66 2073  this model) of s
+0000f2e0: 6861 7065 203a 6f62 6a3a 6028 6261 7463  hape :obj:`(batc
+0000f2f0: 685f 7369 7a65 2c20 3129 6020 696e 7374  h_size, 1)` inst
+0000f300: 6561 640a 2020 2020 2020 2020 2020 2020  ead.            
+0000f310: 6f66 2061 6c6c 203a 6f62 6a3a 6064 6563  of all :obj:`dec
+0000f320: 6f64 6572 5f69 6e70 7574 5f69 6473 6020  oder_input_ids` 
+0000f330: 6f66 2073 6861 7065 203a 6f62 6a3a 6028  of shape :obj:`(
+0000f340: 6261 7463 685f 7369 7a65 2c0a 2020 2020  batch_size,.    
+0000f350: 2020 2020 2020 2020 7365 7175 656e 6365          sequence
+0000f360: 5f6c 656e 6774 6829 602e 0a20 2020 2020  _length)`..     
+0000f370: 2020 2075 7365 5f63 6163 6865 2028 3a6f     use_cache (:o
+0000f380: 626a 3a60 626f 6f6c 602c 2060 6f70 7469  bj:`bool`, `opti
+0000f390: 6f6e 616c 6029 3a0a 2020 2020 2020 2020  onal`):.        
+0000f3a0: 2020 2020 4966 2073 6574 2074 6f20 3a6f      If set to :o
+0000f3b0: 626a 3a60 5472 7565 602c 203a 6f62 6a3a  bj:`True`, :obj:
+0000f3c0: 6070 6173 745f 6b65 795f 7661 6c75 6573  `past_key_values
+0000f3d0: 6020 6b65 7920 7661 6c75 6520 7374 6174  ` key value stat
+0000f3e0: 6573 2061 7265 0a20 2020 2020 2020 2020  es are.         
+0000f3f0: 2020 2072 6574 7572 6e65 6420 616e 6420     returned and 
+0000f400: 6361 6e20 6265 2075 7365 6420 746f 2073  can be used to s
+0000f410: 7065 6564 2075 7020 6465 636f 6469 6e67  peed up decoding
+0000f420: 2028 7365 650a 2020 2020 2020 2020 2020   (see.          
+0000f430: 2020 3a6f 626a 3a60 7061 7374 5f6b 6579    :obj:`past_key
+0000f440: 5f76 616c 7565 7360 292e 0a0a 2020 2020  _values`)...    
+0000f450: 2020 2020 5265 7475 726e 733a 0a0a 2020      Returns:..  
+0000f460: 2020 2020 2020 4578 616d 706c 653a 0a20        Example:. 
+0000f470: 2020 2020 2020 2020 2020 203e 3e3e 2066             >>> f
+0000f480: 726f 6d20 7472 616e 7366 6f72 6d65 7273  rom transformers
+0000f490: 2069 6d70 6f72 7420 4265 7274 546f 6b65   import BertToke
+0000f4a0: 6e69 7a65 722c 2042 6572 744c 4d48 6561  nizer, BertLMHea
+0000f4b0: 644d 6f64 656c 2c20 4265 7274 436f 6e66  dModel, BertConf
+0000f4c0: 6967 0a20 2020 2020 2020 2020 2020 203e  ig.            >
+0000f4d0: 3e3e 2069 6d70 6f72 7420 746f 7263 680a  >> import torch.
+0000f4e0: 2020 2020 2020 2020 2020 2020 3e3e 3e20              >>> 
+0000f4f0: 746f 6b65 6e69 7a65 7220 3d20 4265 7274  tokenizer = Bert
+0000f500: 546f 6b65 6e69 7a65 722e 6672 6f6d 5f70  Tokenizer.from_p
+0000f510: 7265 7472 6169 6e65 6428 2762 6572 742d  retrained('bert-
+0000f520: 6261 7365 2d63 6173 6564 2729 0a20 2020  base-cased').   
+0000f530: 2020 2020 2020 2020 203e 3e3e 2063 6f6e           >>> con
+0000f540: 6669 6720 3d20 4265 7274 436f 6e66 6967  fig = BertConfig
+0000f550: 2e66 726f 6d5f 7072 6574 7261 696e 6564  .from_pretrained
+0000f560: 2822 6265 7274 2d62 6173 652d 6361 7365  ("bert-base-case
+0000f570: 6422 290a 2020 2020 2020 2020 2020 2020  d").            
+0000f580: 3e3e 3e20 6d6f 6465 6c20 3d20 4265 7274  >>> model = Bert
+0000f590: 4c4d 4865 6164 4d6f 6465 6c2e 6672 6f6d  LMHeadModel.from
+0000f5a0: 5f70 7265 7472 6169 6e65 6428 2762 6572  _pretrained('ber
+0000f5b0: 742d 6261 7365 2d63 6173 6564 272c 2063  t-base-cased', c
+0000f5c0: 6f6e 6669 673d 636f 6e66 6967 290a 2020  onfig=config).  
+0000f5d0: 2020 2020 2020 2020 2020 3e3e 3e20 696e            >>> in
+0000f5e0: 7075 7473 203d 2074 6f6b 656e 697a 6572  puts = tokenizer
+0000f5f0: 2822 4865 6c6c 6f2c 206d 7920 646f 6720  ("Hello, my dog 
+0000f600: 6973 2063 7574 6522 2c20 7265 7475 726e  is cute", return
+0000f610: 5f74 656e 736f 7273 3d22 7074 2229 0a20  _tensors="pt"). 
+0000f620: 2020 2020 2020 2020 2020 203e 3e3e 206f             >>> o
+0000f630: 7574 7075 7473 203d 206d 6f64 656c 282a  utputs = model(*
+0000f640: 2a69 6e70 7574 7329 0a20 2020 2020 2020  *inputs).       
+0000f650: 2020 2020 203e 3e3e 2070 7265 6469 6374       >>> predict
+0000f660: 696f 6e5f 6c6f 6769 7473 203d 206f 7574  ion_logits = out
+0000f670: 7075 7473 2e6c 6f67 6974 730a 2020 2020  puts.logits.    
+0000f680: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0000f690: 7265 7475 726e 5f64 6963 7420 3d20 7265  return_dict = re
+0000f6a0: 7475 726e 5f64 6963 7420 6966 2072 6574  turn_dict if ret
+0000f6b0: 7572 6e5f 6469 6374 2069 7320 6e6f 7420  urn_dict is not 
+0000f6c0: 4e6f 6e65 2065 6c73 6520 7365 6c66 2e63  None else self.c
+0000f6d0: 6f6e 6669 672e 7573 655f 7265 7475 726e  onfig.use_return
+0000f6e0: 5f64 6963 740a 2020 2020 2020 2020 6966  _dict.        if
+0000f6f0: 206c 6162 656c 7320 6973 206e 6f74 204e   labels is not N
+0000f700: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+0000f710: 2075 7365 5f63 6163 6865 203d 2046 616c   use_cache = Fal
+0000f720: 7365 0a0a 2020 2020 2020 2020 6f75 7470  se..        outp
+0000f730: 7574 7320 3d20 7365 6c66 2e62 6572 7428  uts = self.bert(
+0000f740: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
+0000f750: 7574 5f69 6473 2c0a 2020 2020 2020 2020  ut_ids,.        
+0000f760: 2020 2020 6174 7465 6e74 696f 6e5f 6d61      attention_ma
+0000f770: 736b 3d61 7474 656e 7469 6f6e 5f6d 6173  sk=attention_mas
+0000f780: 6b2c 0a20 2020 2020 2020 2020 2020 2074  k,.            t
+0000f790: 6f6b 656e 5f74 7970 655f 6964 733d 746f  oken_type_ids=to
+0000f7a0: 6b65 6e5f 7479 7065 5f69 6473 2c0a 2020  ken_type_ids,.  
+0000f7b0: 2020 2020 2020 2020 2020 706f 7369 7469            positi
+0000f7c0: 6f6e 5f69 6473 3d70 6f73 6974 696f 6e5f  on_ids=position_
+0000f7d0: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
+0000f7e0: 2068 6561 645f 6d61 736b 3d68 6561 645f   head_mask=head_
+0000f7f0: 6d61 736b 2c0a 2020 2020 2020 2020 2020  mask,.          
+0000f800: 2020 696e 7075 7473 5f65 6d62 6564 733d    inputs_embeds=
+0000f810: 696e 7075 7473 5f65 6d62 6564 732c 0a20  inputs_embeds,. 
+0000f820: 2020 2020 2020 2020 2020 2065 6e63 6f64             encod
+0000f830: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
+0000f840: 3d65 6e63 6f64 6572 5f68 6964 6465 6e5f  =encoder_hidden_
+0000f850: 7374 6174 6573 2c0a 2020 2020 2020 2020  states,.        
+0000f860: 2020 2020 656e 636f 6465 725f 6174 7465      encoder_atte
+0000f870: 6e74 696f 6e5f 6d61 736b 3d65 6e63 6f64  ntion_mask=encod
+0000f880: 6572 5f61 7474 656e 7469 6f6e 5f6d 6173  er_attention_mas
+0000f890: 6b2c 0a20 2020 2020 2020 2020 2020 2070  k,.            p
+0000f8a0: 6173 745f 6b65 795f 7661 6c75 6573 3d70  ast_key_values=p
+0000f8b0: 6173 745f 6b65 795f 7661 6c75 6573 2c0a  ast_key_values,.
+0000f8c0: 2020 2020 2020 2020 2020 2020 7573 655f              use_
+0000f8d0: 6361 6368 653d 7573 655f 6361 6368 652c  cache=use_cache,
+0000f8e0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0000f8f0: 7075 745f 6174 7465 6e74 696f 6e73 3d6f  put_attentions=o
+0000f900: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
+0000f910: 2c0a 2020 2020 2020 2020 2020 2020 6f75  ,.            ou
+0000f920: 7470 7574 5f68 6964 6465 6e5f 7374 6174  tput_hidden_stat
+0000f930: 6573 3d6f 7574 7075 745f 6869 6464 656e  es=output_hidden
+0000f940: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
+0000f950: 2020 2020 2072 6574 7572 6e5f 6469 6374       return_dict
+0000f960: 3d72 6574 7572 6e5f 6469 6374 2c0a 2020  =return_dict,.  
+0000f970: 2020 2020 2020 2020 2020 6973 5f64 6563            is_dec
+0000f980: 6f64 6572 3d69 735f 6465 636f 6465 722c  oder=is_decoder,
+0000f990: 0a20 2020 2020 2020 2020 2020 206d 6f64  .            mod
+0000f9a0: 653d 6d6f 6465 2c0a 2020 2020 2020 2020  e=mode,.        
+0000f9b0: 290a 0a20 2020 2020 2020 2073 6571 7565  )..        seque
+0000f9c0: 6e63 655f 6f75 7470 7574 203d 206f 7574  nce_output = out
+0000f9d0: 7075 7473 5b30 5d0a 2020 2020 2020 2020  puts[0].        
+0000f9e0: 7072 6564 6963 7469 6f6e 5f73 636f 7265  prediction_score
+0000f9f0: 7320 3d20 7365 6c66 2e63 6c73 2873 6571  s = self.cls(seq
+0000fa00: 7565 6e63 655f 6f75 7470 7574 290a 0a20  uence_output).. 
+0000fa10: 2020 2020 2020 2069 6620 7265 7475 726e         if return
+0000fa20: 5f6c 6f67 6974 733a 0a20 2020 2020 2020  _logits:.       
+0000fa30: 2020 2020 2072 6574 7572 6e20 7072 6564       return pred
+0000fa40: 6963 7469 6f6e 5f73 636f 7265 735b 3a2c  iction_scores[:,
+0000fa50: 203a 2d31 2c20 3a5d 2e63 6f6e 7469 6775   :-1, :].contigu
+0000fa60: 6f75 7328 290a 0a20 2020 2020 2020 206c  ous()..        l
+0000fa70: 6d5f 6c6f 7373 203d 204e 6f6e 650a 2020  m_loss = None.  
+0000fa80: 2020 2020 2020 6966 206c 6162 656c 7320        if labels 
+0000fa90: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+0000faa0: 2020 2020 2020 2020 2023 2077 6520 6172           # we ar
+0000fab0: 6520 646f 696e 6720 6e65 7874 2d74 6f6b  e doing next-tok
+0000fac0: 656e 2070 7265 6469 6374 696f 6e3b 2073  en prediction; s
+0000fad0: 6869 6674 2070 7265 6469 6374 696f 6e20  hift prediction 
+0000fae0: 7363 6f72 6573 2061 6e64 2069 6e70 7574  scores and input
+0000faf0: 2069 6473 2062 7920 6f6e 650a 2020 2020   ids by one.    
+0000fb00: 2020 2020 2020 2020 7368 6966 7465 645f          shifted_
+0000fb10: 7072 6564 6963 7469 6f6e 5f73 636f 7265  prediction_score
+0000fb20: 7320 3d20 7072 6564 6963 7469 6f6e 5f73  s = prediction_s
+0000fb30: 636f 7265 735b 3a2c 203a 0a20 2020 2020  cores[:, :.     
+0000fb40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb70: 2020 2020 202d 312c 203a 5d2e 636f 6e74       -1, :].cont
+0000fb80: 6967 756f 7573 2829 0a20 2020 2020 2020  iguous().       
+0000fb90: 2020 2020 206c 6162 656c 7320 3d20 6c61       labels = la
+0000fba0: 6265 6c73 5b3a 2c20 313a 5d2e 636f 6e74  bels[:, 1:].cont
+0000fbb0: 6967 756f 7573 2829 0a20 2020 2020 2020  iguous().       
+0000fbc0: 2020 2020 206c 6f73 735f 6663 7420 3d20       loss_fct = 
+0000fbd0: 4372 6f73 7345 6e74 726f 7079 4c6f 7373  CrossEntropyLoss
+0000fbe0: 2872 6564 7563 7469 6f6e 3d72 6564 7563  (reduction=reduc
+0000fbf0: 7469 6f6e 290a 2020 2020 2020 2020 2020  tion).          
+0000fc00: 2020 6c6d 5f6c 6f73 7320 3d20 6c6f 7373    lm_loss = loss
+0000fc10: 5f66 6374 280a 2020 2020 2020 2020 2020  _fct(.          
+0000fc20: 2020 2020 2020 7368 6966 7465 645f 7072        shifted_pr
+0000fc30: 6564 6963 7469 6f6e 5f73 636f 7265 732e  ediction_scores.
+0000fc40: 7669 6577 282d 312c 2073 656c 662e 636f  view(-1, self.co
+0000fc50: 6e66 6967 2e76 6f63 6162 5f73 697a 6529  nfig.vocab_size)
+0000fc60: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000fc70: 2020 6c61 6265 6c73 2e76 6965 7728 2d31    labels.view(-1
+0000fc80: 2929 0a20 2020 2020 2020 2020 2020 206c  )).            l
+0000fc90: 6d5f 6c6f 7373 203d 206c 6d5f 6c6f 7373  m_loss = lm_loss
+0000fca0: 2e76 6965 7728 7072 6564 6963 7469 6f6e  .view(prediction
+0000fcb0: 5f73 636f 7265 732e 7369 7a65 2830 292c  _scores.size(0),
+0000fcc0: 202d 3129 2e73 756d 2831 290a 0a20 2020   -1).sum(1)..   
+0000fcd0: 2020 2020 2069 6620 736f 6674 5f6c 6162       if soft_lab
+0000fce0: 656c 7320 6973 206e 6f74 204e 6f6e 653a  els is not None:
+0000fcf0: 0a20 2020 2020 2020 2020 2020 206c 6f73  .            los
+0000fd00: 735f 6469 7374 696c 6c20 3d20 2d74 6f72  s_distill = -tor
+0000fd10: 6368 2e73 756d 280a 2020 2020 2020 2020  ch.sum(.        
+0000fd20: 2020 2020 2020 2020 462e 6c6f 675f 736f          F.log_so
+0000fd30: 6674 6d61 7828 7368 6966 7465 645f 7072  ftmax(shifted_pr
+0000fd40: 6564 6963 7469 6f6e 5f73 636f 7265 732c  ediction_scores,
+0000fd50: 2064 696d 3d2d 3129 202a 2073 6f66 745f   dim=-1) * soft_
+0000fd60: 6c61 6265 6c73 2c0a 2020 2020 2020 2020  labels,.        
+0000fd70: 2020 2020 2020 2020 6469 6d3d 2d31 290a          dim=-1).
+0000fd80: 2020 2020 2020 2020 2020 2020 6c6f 7373              loss
+0000fd90: 5f64 6973 7469 6c6c 203d 2028 6c6f 7373  _distill = (loss
+0000fda0: 5f64 6973 7469 6c6c 202a 2028 6c61 6265  _distill * (labe
+0000fdb0: 6c73 2021 3d20 2d31 3030 2929 2e73 756d  ls != -100)).sum
+0000fdc0: 2831 290a 2020 2020 2020 2020 2020 2020  (1).            
+0000fdd0: 6c6d 5f6c 6f73 7320 3d20 2831 202d 2061  lm_loss = (1 - a
+0000fde0: 6c70 6861 2920 2a20 6c6d 5f6c 6f73 7320  lpha) * lm_loss 
+0000fdf0: 2b20 616c 7068 6120 2a20 6c6f 7373 5f64  + alpha * loss_d
+0000fe00: 6973 7469 6c6c 0a0a 2020 2020 2020 2020  istill..        
+0000fe10: 6966 206e 6f74 2072 6574 7572 6e5f 6469  if not return_di
+0000fe20: 6374 3a0a 2020 2020 2020 2020 2020 2020  ct:.            
+0000fe30: 6f75 7470 7574 203d 2028 7072 6564 6963  output = (predic
+0000fe40: 7469 6f6e 5f73 636f 7265 732c 2029 202b  tion_scores, ) +
+0000fe50: 206f 7574 7075 7473 5b32 3a5d 0a20 2020   outputs[2:].   
+0000fe60: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0000fe70: 2828 6c6d 5f6c 6f73 732c 2029 202b 206f  ((lm_loss, ) + o
+0000fe80: 7574 7075 7429 2069 6620 6c6d 5f6c 6f73  utput) if lm_los
+0000fe90: 7320 6973 206e 6f74 204e 6f6e 6520 656c  s is not None el
+0000fea0: 7365 206f 7574 7075 740a 0a20 2020 2020  se output..     
+0000feb0: 2020 2072 6574 7572 6e20 4361 7573 616c     return Causal
+0000fec0: 4c4d 4f75 7470 7574 5769 7468 4372 6f73  LMOutputWithCros
+0000fed0: 7341 7474 656e 7469 6f6e 7328 0a20 2020  sAttentions(.   
+0000fee0: 2020 2020 2020 2020 206c 6f73 733d 6c6d           loss=lm
+0000fef0: 5f6c 6f73 732c 0a20 2020 2020 2020 2020  _loss,.         
+0000ff00: 2020 206c 6f67 6974 733d 7072 6564 6963     logits=predic
+0000ff10: 7469 6f6e 5f73 636f 7265 732c 0a20 2020  tion_scores,.   
+0000ff20: 2020 2020 2020 2020 2070 6173 745f 6b65           past_ke
+0000ff30: 795f 7661 6c75 6573 3d6f 7574 7075 7473  y_values=outputs
+0000ff40: 2e70 6173 745f 6b65 795f 7661 6c75 6573  .past_key_values
+0000ff50: 2c0a 2020 2020 2020 2020 2020 2020 6869  ,.            hi
+0000ff60: 6464 656e 5f73 7461 7465 733d 6f75 7470  dden_states=outp
+0000ff70: 7574 732e 6869 6464 656e 5f73 7461 7465  uts.hidden_state
+0000ff80: 732c 0a20 2020 2020 2020 2020 2020 2061  s,.            a
+0000ff90: 7474 656e 7469 6f6e 733d 6f75 7470 7574  ttentions=output
+0000ffa0: 732e 6174 7465 6e74 696f 6e73 2c0a 2020  s.attentions,.  
+0000ffb0: 2020 2020 2020 2020 2020 6372 6f73 735f            cross_
+0000ffc0: 6174 7465 6e74 696f 6e73 3d6f 7574 7075  attentions=outpu
+0000ffd0: 7473 2e63 726f 7373 5f61 7474 656e 7469  ts.cross_attenti
+0000ffe0: 6f6e 732c 0a20 2020 2020 2020 2029 0a0a  ons,.        )..
+0000fff0: 2020 2020 6465 6620 7072 6570 6172 655f      def prepare_
+00010000: 696e 7075 7473 5f66 6f72 5f67 656e 6572  inputs_for_gener
+00010010: 6174 696f 6e28 7365 6c66 2c0a 2020 2020  ation(self,.    
+00010020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010040: 2020 696e 7075 745f 6964 732c 0a20 2020    input_ids,.   
+00010050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010070: 2020 2070 6173 743d 4e6f 6e65 2c0a 2020     past=None,.  
+00010080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000100a0: 2020 2020 6174 7465 6e74 696f 6e5f 6d61      attention_ma
+000100b0: 736b 3d4e 6f6e 652c 0a20 2020 2020 2020  sk=None,.       
+000100c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000100d0: 2020 2020 2020 2020 2020 2020 2020 202a                 *
+000100e0: 2a6d 6f64 656c 5f6b 7761 7267 7329 3a0a  *model_kwargs):.
+000100f0: 2020 2020 2020 2020 696e 7075 745f 7368          input_sh
+00010100: 6170 6520 3d20 696e 7075 745f 6964 732e  ape = input_ids.
+00010110: 7368 6170 650a 2020 2020 2020 2020 2320  shape.        # 
+00010120: 6966 206d 6f64 656c 2069 7320 7573 6564  if model is used
+00010130: 2061 7320 6120 6465 636f 6465 7220 696e   as a decoder in
+00010140: 2065 6e63 6f64 6572 2d64 6563 6f64 6572   encoder-decoder
+00010150: 206d 6f64 656c 2c20 7468 6520 6465 636f   model, the deco
+00010160: 6465 7220 6174 7465 6e74 696f 6e20 6d61  der attention ma
+00010170: 736b 2069 7320 6372 6561 7465 6420 6f6e  sk is created on
+00010180: 2074 6865 2066 6c79 0a20 2020 2020 2020   the fly.       
+00010190: 2069 6620 6174 7465 6e74 696f 6e5f 6d61   if attention_ma
+000101a0: 736b 2069 7320 4e6f 6e65 3a0a 2020 2020  sk is None:.    
+000101b0: 2020 2020 2020 2020 6174 7465 6e74 696f          attentio
+000101c0: 6e5f 6d61 736b 203d 2069 6e70 7574 5f69  n_mask = input_i
+000101d0: 6473 2e6e 6577 5f6f 6e65 7328 696e 7075  ds.new_ones(inpu
+000101e0: 745f 7368 6170 6529 0a0a 2020 2020 2020  t_shape)..      
+000101f0: 2020 2320 6375 7420 6465 636f 6465 725f    # cut decoder_
+00010200: 696e 7075 745f 6964 7320 6966 2070 6173  input_ids if pas
+00010210: 7420 6973 2075 7365 640a 2020 2020 2020  t is used.      
+00010220: 2020 6966 2070 6173 7420 6973 206e 6f74    if past is not
+00010230: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00010240: 2020 2069 6e70 7574 5f69 6473 203d 2069     input_ids = i
+00010250: 6e70 7574 5f69 6473 5b3a 2c20 2d31 3a5d  nput_ids[:, -1:]
+00010260: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00010270: 207b 0a20 2020 2020 2020 2020 2020 2027   {.            '
+00010280: 696e 7075 745f 6964 7327 3a0a 2020 2020  input_ids':.    
+00010290: 2020 2020 2020 2020 696e 7075 745f 6964          input_id
+000102a0: 732c 0a20 2020 2020 2020 2020 2020 2027  s,.            '
+000102b0: 6174 7465 6e74 696f 6e5f 6d61 736b 273a  attention_mask':
+000102c0: 0a20 2020 2020 2020 2020 2020 2061 7474  .            att
+000102d0: 656e 7469 6f6e 5f6d 6173 6b2c 0a20 2020  ention_mask,.   
+000102e0: 2020 2020 2020 2020 2027 7061 7374 5f6b           'past_k
+000102f0: 6579 5f76 616c 7565 7327 3a0a 2020 2020  ey_values':.    
+00010300: 2020 2020 2020 2020 7061 7374 2c0a 2020          past,.  
+00010310: 2020 2020 2020 2020 2020 2765 6e63 6f64            'encod
+00010320: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
+00010330: 273a 0a20 2020 2020 2020 2020 2020 206d  ':.            m
+00010340: 6f64 656c 5f6b 7761 7267 732e 6765 7428  odel_kwargs.get(
+00010350: 2765 6e63 6f64 6572 5f68 6964 6465 6e5f  'encoder_hidden_
+00010360: 7374 6174 6573 272c 204e 6f6e 6529 2c0a  states', None),.
+00010370: 2020 2020 2020 2020 2020 2020 2765 6e63              'enc
+00010380: 6f64 6572 5f61 7474 656e 7469 6f6e 5f6d  oder_attention_m
+00010390: 6173 6b27 3a0a 2020 2020 2020 2020 2020  ask':.          
+000103a0: 2020 6d6f 6465 6c5f 6b77 6172 6773 2e67    model_kwargs.g
+000103b0: 6574 2827 656e 636f 6465 725f 6174 7465  et('encoder_atte
+000103c0: 6e74 696f 6e5f 6d61 736b 272c 204e 6f6e  ntion_mask', Non
+000103d0: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
+000103e0: 2769 735f 6465 636f 6465 7227 3a0a 2020  'is_decoder':.  
+000103f0: 2020 2020 2020 2020 2020 5472 7565 2c0a            True,.
+00010400: 2020 2020 2020 2020 7d0a 0a20 2020 2064          }..    d
+00010410: 6566 205f 7265 6f72 6465 725f 6361 6368  ef _reorder_cach
+00010420: 6528 7365 6c66 2c20 7061 7374 2c20 6265  e(self, past, be
+00010430: 616d 5f69 6478 293a 0a20 2020 2020 2020  am_idx):.       
+00010440: 2072 656f 7264 6572 6564 5f70 6173 7420   reordered_past 
+00010450: 3d20 2829 0a20 2020 2020 2020 2066 6f72  = ().        for
+00010460: 206c 6179 6572 5f70 6173 7420 696e 2070   layer_past in p
+00010470: 6173 743a 0a20 2020 2020 2020 2020 2020  ast:.           
+00010480: 2072 656f 7264 6572 6564 5f70 6173 7420   reordered_past 
+00010490: 2b3d 2028 7475 706c 6528 0a20 2020 2020  += (tuple(.     
+000104a0: 2020 2020 2020 2020 2020 2070 6173 745f             past_
+000104b0: 7374 6174 652e 696e 6465 785f 7365 6c65  state.index_sele
+000104c0: 6374 2830 2c20 6265 616d 5f69 6478 290a  ct(0, beam_idx).
+000104d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000104e0: 666f 7220 7061 7374 5f73 7461 7465 2069  for past_state i
+000104f0: 6e20 6c61 7965 725f 7061 7374 292c 2029  n layer_past), )
+00010500: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00010510: 7265 6f72 6465 7265 645f 7061 7374 0a0a  reordered_past..
+00010520: 0a63 6c61 7373 2047 6973 4265 7274 4c4d  .class GisBertLM
+00010530: 5072 6564 6963 7469 6f6e 4865 6164 286e  PredictionHead(n
+00010540: 6e2e 4d6f 6475 6c65 293a 0a0a 2020 2020  n.Module):..    
+00010550: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00010560: 662c 2063 6f6e 6669 672c 2076 6f63 6162  f, config, vocab
+00010570: 5f73 697a 6529 3a0a 2020 2020 2020 2020  _size):.        
+00010580: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
+00010590: 2829 0a20 2020 2020 2020 2073 656c 662e  ().        self.
+000105a0: 7472 616e 7366 6f72 6d20 3d20 4265 7274  transform = Bert
+000105b0: 5072 6564 6963 7469 6f6e 4865 6164 5472  PredictionHeadTr
+000105c0: 616e 7366 6f72 6d28 636f 6e66 6967 290a  ansform(config).
+000105d0: 0a20 2020 2020 2020 2023 2054 6865 206f  .        # The o
+000105e0: 7574 7075 7420 7765 6967 6874 7320 6172  utput weights ar
+000105f0: 6520 7468 6520 7361 6d65 2061 7320 7468  e the same as th
+00010600: 6520 696e 7075 7420 656d 6265 6464 696e  e input embeddin
+00010610: 6773 2c20 6275 7420 7468 6572 6520 6973  gs, but there is
+00010620: 0a20 2020 2020 2020 2023 2061 6e20 6f75  .        # an ou
+00010630: 7470 7574 2d6f 6e6c 7920 6269 6173 2066  tput-only bias f
+00010640: 6f72 2065 6163 6820 746f 6b65 6e2e 0a20  or each token.. 
+00010650: 2020 2020 2020 2073 656c 662e 6465 636f         self.deco
+00010660: 6465 7220 3d20 6e6e 2e4c 696e 6561 7228  der = nn.Linear(
+00010670: 636f 6e66 6967 2e68 6964 6465 6e5f 7369  config.hidden_si
+00010680: 7a65 2c20 766f 6361 625f 7369 7a65 2c20  ze, vocab_size, 
+00010690: 6269 6173 3d46 616c 7365 290a 0a20 2020  bias=False)..   
+000106a0: 2020 2020 2073 656c 662e 6269 6173 203d       self.bias =
+000106b0: 206e 6e2e 5061 7261 6d65 7465 7228 746f   nn.Parameter(to
+000106c0: 7263 682e 7a65 726f 7328 766f 6361 625f  rch.zeros(vocab_
+000106d0: 7369 7a65 2929 0a0a 2020 2020 2020 2020  size))..        
+000106e0: 2320 4e65 6564 2061 206c 696e 6b20 6265  # Need a link be
+000106f0: 7477 6565 6e20 7468 6520 7477 6f20 7661  tween the two va
+00010700: 7269 6162 6c65 7320 736f 2074 6861 7420  riables so that 
+00010710: 7468 6520 6269 6173 2069 7320 636f 7272  the bias is corr
+00010720: 6563 746c 7920 7265 7369 7a65 6420 7769  ectly resized wi
+00010730: 7468 2060 7265 7369 7a65 5f74 6f6b 656e  th `resize_token
+00010740: 5f65 6d62 6564 6469 6e67 7360 0a20 2020  _embeddings`.   
+00010750: 2020 2020 2073 656c 662e 6465 636f 6465       self.decode
+00010760: 722e 6269 6173 203d 2073 656c 662e 6269  r.bias = self.bi
+00010770: 6173 0a0a 2020 2020 6465 6620 666f 7277  as..    def forw
+00010780: 6172 6428 7365 6c66 2c20 6869 6464 656e  ard(self, hidden
+00010790: 5f73 7461 7465 7329 3a0a 2020 2020 2020  _states):.      
+000107a0: 2020 6869 6464 656e 5f73 7461 7465 7320    hidden_states 
+000107b0: 3d20 7365 6c66 2e74 7261 6e73 666f 726d  = self.transform
+000107c0: 2868 6964 6465 6e5f 7374 6174 6573 290a  (hidden_states).
+000107d0: 2020 2020 2020 2020 6869 6464 656e 5f73          hidden_s
+000107e0: 7461 7465 7320 3d20 7365 6c66 2e64 6563  tates = self.dec
+000107f0: 6f64 6572 2868 6964 6465 6e5f 7374 6174  oder(hidden_stat
+00010800: 6573 290a 2020 2020 2020 2020 7265 7475  es).        retu
+00010810: 726e 2068 6964 6465 6e5f 7374 6174 6573  rn hidden_states
+00010820: 0a0a 0a63 6c61 7373 2042 6572 7446 6f72  ...class BertFor
+00010830: 4769 734d 6173 6b65 644c 4d28 4265 7274  GisMaskedLM(Bert
+00010840: 5072 6554 7261 696e 6564 4d6f 6465 6c29  PreTrainedModel)
+00010850: 3a0a 0a20 2020 205f 6b65 7973 5f74 6f5f  :..    _keys_to_
+00010860: 6967 6e6f 7265 5f6f 6e5f 6c6f 6164 5f75  ignore_on_load_u
+00010870: 6e65 7870 6563 7465 6420 3d20 5b72 2770  nexpected = [r'p
+00010880: 6f6f 6c65 7227 5d0a 2020 2020 5f6b 6579  ooler'].    _key
+00010890: 735f 746f 5f69 676e 6f72 655f 6f6e 5f6c  s_to_ignore_on_l
+000108a0: 6f61 645f 6d69 7373 696e 6720 3d20 5b0a  oad_missing = [.
+000108b0: 2020 2020 2020 2020 7227 706f 7369 7469          r'positi
+000108c0: 6f6e 5f69 6473 272c 2072 2770 7265 6469  on_ids', r'predi
+000108d0: 6374 696f 6e73 2e64 6563 6f64 6572 2e62  ctions.decoder.b
+000108e0: 6961 7327 0a20 2020 205d 0a0a 2020 2020  ias'.    ]..    
+000108f0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00010900: 662c 2063 6f6e 6669 6729 3a0a 2020 2020  f, config):.    
+00010910: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
+00010920: 6974 5f5f 2863 6f6e 6669 6729 0a20 2020  it__(config).   
+00010930: 2020 2020 2073 656c 662e 6265 7274 203d       self.bert =
+00010940: 2042 6572 744d 6f64 656c 2863 6f6e 6669   BertModel(confi
+00010950: 672c 2061 6464 5f70 6f6f 6c69 6e67 5f6c  g, add_pooling_l
+00010960: 6179 6572 3d46 616c 7365 290a 2020 2020  ayer=False).    
+00010970: 2020 2020 7365 6c66 2e63 6c73 5f67 656f      self.cls_geo
+00010980: 6d5f 6964 203d 2047 6973 4265 7274 4c4d  m_id = GisBertLM
+00010990: 5072 6564 6963 7469 6f6e 4865 6164 2863  PredictionHead(c
+000109a0: 6f6e 6669 672c 2063 6f6e 6669 672e 766f  onfig, config.vo
+000109b0: 6361 625f 7369 7a65 290a 2020 2020 2020  cab_size).      
+000109c0: 2020 7365 6c66 2e63 6c73 5f67 656f 6d5f    self.cls_geom_
+000109d0: 7479 7065 203d 2047 6973 4265 7274 4c4d  type = GisBertLM
+000109e0: 5072 6564 6963 7469 6f6e 4865 6164 2863  PredictionHead(c
+000109f0: 6f6e 6669 672c 0a20 2020 2020 2020 2020  onfig,.         
+00010a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010a20: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+00010a30: 6967 2e74 7970 655f 766f 6361 625f 7369  ig.type_vocab_si
+00010a40: 7a65 290a 2020 2020 2020 2020 7365 6c66  ze).        self
+00010a50: 2e63 6c73 5f72 656c 5f74 7970 6520 3d20  .cls_rel_type = 
+00010a60: 4769 7342 6572 744c 4d50 7265 6469 6374  GisBertLMPredict
+00010a70: 696f 6e48 6561 6428 636f 6e66 6967 2c0a  ionHead(config,.
+00010a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010ab0: 2020 2020 636f 6e66 6967 2e72 656c 5f74      config.rel_t
+00010ac0: 7970 655f 766f 6361 625f 7369 7a65 290a  ype_vocab_size).
+00010ad0: 2020 2020 2020 2020 7365 6c66 2e63 6c73          self.cls
+00010ae0: 5f61 6273 6f6c 7574 655f 706f 7369 7469  _absolute_positi
+00010af0: 6f6e 5f78 3120 3d20 4769 7342 6572 744c  on_x1 = GisBertL
+00010b00: 4d50 7265 6469 6374 696f 6e48 6561 6428  MPredictionHead(
+00010b10: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
+00010b20: 6669 672c 2063 6f6e 6669 672e 6162 736f  fig, config.abso
+00010b30: 6c75 7465 5f78 5f76 6f63 6162 5f73 697a  lute_x_vocab_siz
+00010b40: 6529 0a20 2020 2020 2020 2073 656c 662e  e).        self.
+00010b50: 636c 735f 6162 736f 6c75 7465 5f70 6f73  cls_absolute_pos
+00010b60: 6974 696f 6e5f 7832 203d 2047 6973 4265  ition_x2 = GisBe
+00010b70: 7274 4c4d 5072 6564 6963 7469 6f6e 4865  rtLMPredictionHe
+00010b80: 6164 280a 2020 2020 2020 2020 2020 2020  ad(.            
+00010b90: 636f 6e66 6967 2c20 636f 6e66 6967 2e61  config, config.a
+00010ba0: 6273 6f6c 7574 655f 785f 766f 6361 625f  bsolute_x_vocab_
+00010bb0: 7369 7a65 290a 2020 2020 2020 2020 7365  size).        se
+00010bc0: 6c66 2e63 6c73 5f61 6273 6f6c 7574 655f  lf.cls_absolute_
+00010bd0: 706f 7369 7469 6f6e 5f79 3120 3d20 4769  position_y1 = Gi
+00010be0: 7342 6572 744c 4d50 7265 6469 6374 696f  sBertLMPredictio
+00010bf0: 6e48 6561 6428 0a20 2020 2020 2020 2020  nHead(.         
+00010c00: 2020 2063 6f6e 6669 672c 2063 6f6e 6669     config, confi
+00010c10: 672e 6162 736f 6c75 7465 5f79 5f76 6f63  g.absolute_y_voc
+00010c20: 6162 5f73 697a 6529 0a20 2020 2020 2020  ab_size).       
+00010c30: 2073 656c 662e 636c 735f 6162 736f 6c75   self.cls_absolu
+00010c40: 7465 5f70 6f73 6974 696f 6e5f 7932 203d  te_position_y2 =
+00010c50: 2047 6973 4265 7274 4c4d 5072 6564 6963   GisBertLMPredic
+00010c60: 7469 6f6e 4865 6164 280a 2020 2020 2020  tionHead(.      
+00010c70: 2020 2020 2020 636f 6e66 6967 2c20 636f        config, co
+00010c80: 6e66 6967 2e61 6273 6f6c 7574 655f 795f  nfig.absolute_y_
+00010c90: 766f 6361 625f 7369 7a65 290a 2020 2020  vocab_size).    
+00010ca0: 2020 2020 7365 6c66 2e63 6c73 5f72 656c      self.cls_rel
+00010cb0: 6174 6976 655f 706f 7369 7469 6f6e 5f78  ative_position_x
+00010cc0: 3120 3d20 4769 7342 6572 744c 4d50 7265  1 = GisBertLMPre
+00010cd0: 6469 6374 696f 6e48 6561 6428 0a20 2020  dictionHead(.   
+00010ce0: 2020 2020 2020 2020 2063 6f6e 6669 672c           config,
+00010cf0: 2063 6f6e 6669 672e 7265 6c61 7469 7665   config.relative
+00010d00: 5f78 5f76 6f63 6162 5f73 697a 6529 0a20  _x_vocab_size). 
+00010d10: 2020 2020 2020 2073 656c 662e 636c 735f         self.cls_
+00010d20: 7265 6c61 7469 7665 5f70 6f73 6974 696f  relative_positio
+00010d30: 6e5f 7832 203d 2047 6973 4265 7274 4c4d  n_x2 = GisBertLM
+00010d40: 5072 6564 6963 7469 6f6e 4865 6164 280a  PredictionHead(.
+00010d50: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+00010d60: 6967 2c20 636f 6e66 6967 2e72 656c 6174  ig, config.relat
+00010d70: 6976 655f 785f 766f 6361 625f 7369 7a65  ive_x_vocab_size
+00010d80: 290a 2020 2020 2020 2020 7365 6c66 2e63  ).        self.c
+00010d90: 6c73 5f72 656c 6174 6976 655f 706f 7369  ls_relative_posi
+00010da0: 7469 6f6e 5f79 3120 3d20 4769 7342 6572  tion_y1 = GisBer
+00010db0: 744c 4d50 7265 6469 6374 696f 6e48 6561  tLMPredictionHea
+00010dc0: 6428 0a20 2020 2020 2020 2020 2020 2063  d(.            c
+00010dd0: 6f6e 6669 672c 2063 6f6e 6669 672e 7265  onfig, config.re
+00010de0: 6c61 7469 7665 5f79 5f76 6f63 6162 5f73  lative_y_vocab_s
+00010df0: 697a 6529 0a20 2020 2020 2020 2073 656c  ize).        sel
+00010e00: 662e 636c 735f 7265 6c61 7469 7665 5f70  f.cls_relative_p
+00010e10: 6f73 6974 696f 6e5f 7932 203d 2047 6973  osition_y2 = Gis
+00010e20: 4265 7274 4c4d 5072 6564 6963 7469 6f6e  BertLMPrediction
+00010e30: 4865 6164 280a 2020 2020 2020 2020 2020  Head(.          
+00010e40: 2020 636f 6e66 6967 2c20 636f 6e66 6967    config, config
+00010e50: 2e72 656c 6174 6976 655f 795f 766f 6361  .relative_y_voca
+00010e60: 625f 7369 7a65 290a 2020 2020 2020 2020  b_size).        
+00010e70: 7365 6c66 2e63 6f6e 6669 6720 3d20 636f  self.config = co
+00010e80: 6e66 6967 0a0a 2020 2020 2020 2020 7365  nfig..        se
+00010e90: 6c66 2e69 6e69 745f 7765 6967 6874 7328  lf.init_weights(
+00010ea0: 290a 0a20 2020 2064 6566 2066 6f72 7761  )..    def forwa
+00010eb0: 7264 280a 2020 2020 2020 2020 7365 6c66  rd(.        self
+00010ec0: 2c0a 2020 2020 2020 2020 696e 7075 745f  ,.        input_
+00010ed0: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
+00010ee0: 2020 6174 7465 6e74 696f 6e5f 6d61 736b    attention_mask
+00010ef0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2074  =None,.        t
+00010f00: 6f6b 656e 5f74 7970 655f 6964 733d 4e6f  oken_type_ids=No
+00010f10: 6e65 2c0a 2020 2020 2020 2020 706f 7369  ne,.        posi
+00010f20: 7469 6f6e 5f69 6473 3d4e 6f6e 652c 0a20  tion_ids=None,. 
+00010f30: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
+00010f40: 3d4e 6f6e 652c 0a20 2020 2020 2020 2069  =None,.        i
+00010f50: 6e70 7574 735f 656d 6265 6473 3d4e 6f6e  nputs_embeds=Non
+00010f60: 652c 0a20 2020 2020 2020 2065 6e63 6f64  e,.        encod
+00010f70: 6572 5f65 6d62 6564 733d 4e6f 6e65 2c0a  er_embeds=None,.
+00010f80: 2020 2020 2020 2020 656e 636f 6465 725f          encoder_
+00010f90: 6869 6464 656e 5f73 7461 7465 733d 4e6f  hidden_states=No
+00010fa0: 6e65 2c0a 2020 2020 2020 2020 656e 636f  ne,.        enco
+00010fb0: 6465 725f 6174 7465 6e74 696f 6e5f 6d61  der_attention_ma
+00010fc0: 736b 3d4e 6f6e 652c 0a20 2020 2020 2020  sk=None,.       
+00010fd0: 206c 6162 656c 733d 4e6f 6e65 2c0a 2020   labels=None,.  
+00010fe0: 2020 2020 2020 6f75 7470 7574 5f61 7474        output_att
+00010ff0: 656e 7469 6f6e 733d 4e6f 6e65 2c0a 2020  entions=None,.  
+00011000: 2020 2020 2020 6f75 7470 7574 5f68 6964        output_hid
+00011010: 6465 6e5f 7374 6174 6573 3d4e 6f6e 652c  den_states=None,
+00011020: 0a20 2020 2020 2020 2072 6574 7572 6e5f  .        return_
+00011030: 6469 6374 3d4e 6f6e 652c 0a20 2020 2020  dict=None,.     
+00011040: 2020 2069 735f 6465 636f 6465 723d 4661     is_decoder=Fa
+00011050: 6c73 652c 0a20 2020 2020 2020 206d 6f64  lse,.        mod
+00011060: 653d 276d 756c 7469 5f6d 6f64 616c 272c  e='multi_modal',
+00011070: 0a20 2020 2020 2020 2073 6f66 745f 6c61  .        soft_la
+00011080: 6265 6c73 3d4e 6f6e 652c 0a20 2020 2020  bels=None,.     
+00011090: 2020 2061 6c70 6861 3d30 2c0a 2020 2020     alpha=0,.    
+000110a0: 2020 2020 7265 7475 726e 5f6c 6f67 6974      return_logit
+000110b0: 733d 4661 6c73 652c 0a20 2020 2020 2020  s=False,.       
+000110c0: 2072 656c 5f74 7970 655f 6964 733d 4e6f   rel_type_ids=No
+000110d0: 6e65 2c0a 2020 2020 2020 2020 6162 736f  ne,.        abso
+000110e0: 6c75 7465 5f70 6f73 6974 696f 6e5f 6964  lute_position_id
+000110f0: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
+00011100: 7265 6c61 7469 7665 5f70 6f73 6974 696f  relative_positio
+00011110: 6e5f 6964 733d 4e6f 6e65 2c0a 2020 2020  n_ids=None,.    
+00011120: 2020 2020 746f 6b65 6e5f 7479 7065 5f69      token_type_i
+00011130: 6473 5f6c 6162 656c 3d4e 6f6e 652c 0a20  ds_label=None,. 
+00011140: 2020 2020 2020 2072 656c 5f74 7970 655f         rel_type_
+00011150: 6964 735f 6c61 6265 6c3d 4e6f 6e65 2c0a  ids_label=None,.
+00011160: 2020 2020 2020 2020 6162 736f 6c75 7465          absolute
+00011170: 5f70 6f73 6974 696f 6e5f 6964 735f 6c61  _position_ids_la
+00011180: 6265 6c3d 4e6f 6e65 2c0a 2020 2020 2020  bel=None,.      
+00011190: 2020 7265 6c61 7469 7665 5f70 6f73 6974    relative_posit
+000111a0: 696f 6e5f 6964 735f 6c61 6265 6c3d 4e6f  ion_ids_label=No
+000111b0: 6e65 2c0a 2020 2020 293a 0a20 2020 2020  ne,.    ):.     
+000111c0: 2020 2072 2222 220a 2020 2020 2020 2020     r""".        
+000111d0: 6c61 6265 6c73 2028 3a6f 626a 3a60 746f  labels (:obj:`to
+000111e0: 7263 682e 4c6f 6e67 5465 6e73 6f72 6020  rch.LongTensor` 
+000111f0: 6f66 2073 6861 7065 203a 6f62 6a3a 6028  of shape :obj:`(
+00011200: 6261 7463 685f 7369 7a65 2c0a 2020 2020  batch_size,.    
+00011210: 2020 2020 7365 7175 656e 6365 5f6c 656e      sequence_len
+00011220: 6774 6829 602c 2060 6f70 7469 6f6e 616c  gth)`, `optional
+00011230: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
+00011240: 4c61 6265 6c73 2066 6f72 2063 6f6d 7075  Labels for compu
+00011250: 7469 6e67 2074 6865 206d 6173 6b65 6420  ting the masked 
+00011260: 6c61 6e67 7561 6765 206d 6f64 656c 696e  language modelin
+00011270: 6720 6c6f 7373 2e20 496e 6469 6365 730a  g loss. Indices.
+00011280: 2020 2020 2020 2020 2020 2020 7368 6f75              shou
+00011290: 6c64 2062 6520 696e 2060 605b 2d31 3030  ld be in ``[-100
+000112a0: 2c20 302c 202e 2e2e 2c20 636f 6e66 6967  , 0, ..., config
+000112b0: 2e76 6f63 6162 5f73 697a 655d 6060 2028  .vocab_size]`` (
+000112c0: 7365 650a 2020 2020 2020 2020 2020 2020  see.            
+000112d0: 6060 696e 7075 745f 6964 7360 6020 646f  ``input_ids`` do
+000112e0: 6373 7472 696e 6729 2054 6f6b 656e 7320  cstring) Tokens 
+000112f0: 7769 7468 2069 6e64 6963 6573 2073 6574  with indices set
+00011300: 2074 6f20 6060 2d31 3030 6060 2061 7265   to ``-100`` are
+00011310: 0a20 2020 2020 2020 2020 2020 2069 676e  .            ign
+00011320: 6f72 6564 2028 6d61 736b 6564 292c 2074  ored (masked), t
+00011330: 6865 206c 6f73 7320 6973 206f 6e6c 7920  he loss is only 
+00011340: 636f 6d70 7574 6564 2066 6f72 2074 6865  computed for the
+00011350: 2074 6f6b 656e 7320 7769 7468 0a20 2020   tokens with.   
+00011360: 2020 2020 2020 2020 206c 6162 656c 7320           labels 
+00011370: 696e 2060 605b 302c 202e 2e2e 2c20 636f  in ``[0, ..., co
+00011380: 6e66 6967 2e76 6f63 6162 5f73 697a 655d  nfig.vocab_size]
+00011390: 6060 0a20 2020 2020 2020 2022 2222 0a0a  ``.        """..
+000113a0: 2020 2020 2020 2020 7265 7475 726e 5f64          return_d
+000113b0: 6963 7420 3d20 7265 7475 726e 5f64 6963  ict = return_dic
+000113c0: 7420 6966 2072 6574 7572 6e5f 6469 6374  t if return_dict
+000113d0: 2069 7320 6e6f 7420 4e6f 6e65 2065 6c73   is not None els
+000113e0: 6520 7365 6c66 2e63 6f6e 6669 672e 7573  e self.config.us
+000113f0: 655f 7265 7475 726e 5f64 6963 740a 0a20  e_return_dict.. 
+00011400: 2020 2020 2020 206f 7574 7075 7473 203d         outputs =
+00011410: 2073 656c 662e 6265 7274 280a 2020 2020   self.bert(.    
+00011420: 2020 2020 2020 2020 696e 7075 745f 6964          input_id
+00011430: 732c 0a20 2020 2020 2020 2020 2020 2061  s,.            a
+00011440: 7474 656e 7469 6f6e 5f6d 6173 6b3d 6174  ttention_mask=at
+00011450: 7465 6e74 696f 6e5f 6d61 736b 2c0a 2020  tention_mask,.  
+00011460: 2020 2020 2020 2020 2020 746f 6b65 6e5f            token_
+00011470: 7479 7065 5f69 6473 3d74 6f6b 656e 5f74  type_ids=token_t
+00011480: 7970 655f 6964 732c 0a20 2020 2020 2020  ype_ids,.       
+00011490: 2020 2020 2070 6f73 6974 696f 6e5f 6964       position_id
+000114a0: 733d 706f 7369 7469 6f6e 5f69 6473 2c0a  s=position_ids,.
+000114b0: 2020 2020 2020 2020 2020 2020 6865 6164              head
+000114c0: 5f6d 6173 6b3d 6865 6164 5f6d 6173 6b2c  _mask=head_mask,
+000114d0: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
+000114e0: 7574 735f 656d 6265 6473 3d69 6e70 7574  uts_embeds=input
+000114f0: 735f 656d 6265 6473 2c0a 2020 2020 2020  s_embeds,.      
+00011500: 2020 2020 2020 656e 636f 6465 725f 656d        encoder_em
+00011510: 6265 6473 3d65 6e63 6f64 6572 5f65 6d62  beds=encoder_emb
+00011520: 6564 732c 0a20 2020 2020 2020 2020 2020  eds,.           
+00011530: 2065 6e63 6f64 6572 5f68 6964 6465 6e5f   encoder_hidden_
+00011540: 7374 6174 6573 3d65 6e63 6f64 6572 5f68  states=encoder_h
+00011550: 6964 6465 6e5f 7374 6174 6573 2c0a 2020  idden_states,.  
+00011560: 2020 2020 2020 2020 2020 656e 636f 6465            encode
+00011570: 725f 6174 7465 6e74 696f 6e5f 6d61 736b  r_attention_mask
+00011580: 3d65 6e63 6f64 6572 5f61 7474 656e 7469  =encoder_attenti
+00011590: 6f6e 5f6d 6173 6b2c 0a20 2020 2020 2020  on_mask,.       
+000115a0: 2020 2020 206f 7574 7075 745f 6174 7465       output_atte
+000115b0: 6e74 696f 6e73 3d6f 7574 7075 745f 6174  ntions=output_at
+000115c0: 7465 6e74 696f 6e73 2c0a 2020 2020 2020  tentions,.      
+000115d0: 2020 2020 2020 6f75 7470 7574 5f68 6964        output_hid
+000115e0: 6465 6e5f 7374 6174 6573 3d6f 7574 7075  den_states=outpu
+000115f0: 745f 6869 6464 656e 5f73 7461 7465 732c  t_hidden_states,
+00011600: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00011610: 7572 6e5f 6469 6374 3d72 6574 7572 6e5f  urn_dict=return_
+00011620: 6469 6374 2c0a 2020 2020 2020 2020 2020  dict,.          
+00011630: 2020 6973 5f64 6563 6f64 6572 3d69 735f    is_decoder=is_
+00011640: 6465 636f 6465 722c 0a20 2020 2020 2020  decoder,.       
+00011650: 2020 2020 206d 6f64 653d 6d6f 6465 2c0a       mode=mode,.
+00011660: 2020 2020 2020 2020 2020 2020 7265 6c5f              rel_
+00011670: 7479 7065 5f69 6473 3d72 656c 5f74 7970  type_ids=rel_typ
+00011680: 655f 6964 732c 0a20 2020 2020 2020 2020  e_ids,.         
+00011690: 2020 2061 6273 6f6c 7574 655f 706f 7369     absolute_posi
+000116a0: 7469 6f6e 5f69 6473 3d61 6273 6f6c 7574  tion_ids=absolut
+000116b0: 655f 706f 7369 7469 6f6e 5f69 6473 2c0a  e_position_ids,.
+000116c0: 2020 2020 2020 2020 2020 2020 7265 6c61              rela
+000116d0: 7469 7665 5f70 6f73 6974 696f 6e5f 6964  tive_position_id
+000116e0: 733d 7265 6c61 7469 7665 5f70 6f73 6974  s=relative_posit
+000116f0: 696f 6e5f 6964 732c 0a20 2020 2020 2020  ion_ids,.       
+00011700: 2029 0a0a 2020 2020 2020 2020 7365 7175   )..        sequ
+00011710: 656e 6365 5f6f 7574 7075 7420 3d20 6f75  ence_output = ou
+00011720: 7470 7574 735b 305d 0a0a 2020 2020 2020  tputs[0]..      
+00011730: 2020 7072 6564 6963 7469 6f6e 5f73 636f    prediction_sco
+00011740: 7265 7320 3d20 7365 6c66 2e63 6c73 5f67  res = self.cls_g
+00011750: 656f 6d5f 6964 2873 6571 7565 6e63 655f  eom_id(sequence_
+00011760: 6f75 7470 7574 290a 2020 2020 2020 2020  output).        
+00011770: 6c6f 7373 5f66 6374 203d 2043 726f 7373  loss_fct = Cross
+00011780: 456e 7472 6f70 794c 6f73 7328 2920 2023  EntropyLoss()  #
+00011790: 202d 3130 3020 696e 6465 7820 3d20 7061   -100 index = pa
+000117a0: 6464 696e 6720 746f 6b65 6e0a 2020 2020  dding token.    
+000117b0: 2020 2020 6d61 736b 6564 5f6c 6d5f 6c6f      masked_lm_lo
+000117c0: 7373 203d 206c 6f73 735f 6663 7428 0a20  ss = loss_fct(. 
+000117d0: 2020 2020 2020 2020 2020 2070 7265 6469             predi
+000117e0: 6374 696f 6e5f 7363 6f72 6573 2e76 6965  ction_scores.vie
+000117f0: 7728 2d31 2c20 7365 6c66 2e63 6f6e 6669  w(-1, self.confi
+00011800: 672e 766f 6361 625f 7369 7a65 292c 0a20  g.vocab_size),. 
+00011810: 2020 2020 2020 2020 2020 206c 6162 656c             label
+00011820: 732e 7669 6577 282d 3129 290a 0a20 2020  s.view(-1))..   
+00011830: 2020 2020 2070 6f73 6974 696f 6e73 5f63       positions_c
+00011840: 6c73 203d 205b 0a20 2020 2020 2020 2020  ls = [.         
+00011850: 2020 2073 656c 662e 636c 735f 6765 6f6d     self.cls_geom
+00011860: 5f74 7970 652c 2073 656c 662e 636c 735f  _type, self.cls_
+00011870: 7265 6c5f 7479 7065 2c0a 2020 2020 2020  rel_type,.      
+00011880: 2020 2020 2020 7365 6c66 2e63 6c73 5f61        self.cls_a
+00011890: 6273 6f6c 7574 655f 706f 7369 7469 6f6e  bsolute_position
+000118a0: 5f78 312c 2073 656c 662e 636c 735f 6162  _x1, self.cls_ab
+000118b0: 736f 6c75 7465 5f70 6f73 6974 696f 6e5f  solute_position_
+000118c0: 7832 2c0a 2020 2020 2020 2020 2020 2020  x2,.            
+000118d0: 7365 6c66 2e63 6c73 5f61 6273 6f6c 7574  self.cls_absolut
+000118e0: 655f 706f 7369 7469 6f6e 5f79 312c 2073  e_position_y1, s
+000118f0: 656c 662e 636c 735f 6162 736f 6c75 7465  elf.cls_absolute
+00011900: 5f70 6f73 6974 696f 6e5f 7932 2c0a 2020  _position_y2,.  
+00011910: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
+00011920: 6c73 5f72 656c 6174 6976 655f 706f 7369  ls_relative_posi
+00011930: 7469 6f6e 5f78 312c 2073 656c 662e 636c  tion_x1, self.cl
+00011940: 735f 7265 6c61 7469 7665 5f70 6f73 6974  s_relative_posit
+00011950: 696f 6e5f 7832 2c0a 2020 2020 2020 2020  ion_x2,.        
+00011960: 2020 2020 7365 6c66 2e63 6c73 5f72 656c      self.cls_rel
+00011970: 6174 6976 655f 706f 7369 7469 6f6e 5f79  ative_position_y
+00011980: 312c 2073 656c 662e 636c 735f 7265 6c61  1, self.cls_rela
+00011990: 7469 7665 5f70 6f73 6974 696f 6e5f 7932  tive_position_y2
+000119a0: 0a20 2020 2020 2020 205d 0a20 2020 2020  .        ].     
+000119b0: 2020 2070 6f73 6974 696f 6e73 5f6c 6162     positions_lab
+000119c0: 656c 203d 205b 0a20 2020 2020 2020 2020  el = [.         
+000119d0: 2020 2074 6f6b 656e 5f74 7970 655f 6964     token_type_id
+000119e0: 735f 6c61 6265 6c2c 2072 656c 5f74 7970  s_label, rel_typ
+000119f0: 655f 6964 735f 6c61 6265 6c2c 0a20 2020  e_ids_label,.   
+00011a00: 2020 2020 2020 2020 2061 6273 6f6c 7574           absolut
+00011a10: 655f 706f 7369 7469 6f6e 5f69 6473 5f6c  e_position_ids_l
+00011a20: 6162 656c 5b3a 2c20 3a2c 0a20 2020 2020  abel[:, :,.     
+00011a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011a50: 2020 2030 5d2c 2061 6273 6f6c 7574 655f     0], absolute_
+00011a60: 706f 7369 7469 6f6e 5f69 6473 5f6c 6162  position_ids_lab
+00011a70: 656c 5b3a 2c20 3a2c 0a20 2020 2020 2020  el[:, :,.       
+00011a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ac0: 2032 5d2c 0a20 2020 2020 2020 2020 2020   2],.           
+00011ad0: 2061 6273 6f6c 7574 655f 706f 7369 7469   absolute_positi
+00011ae0: 6f6e 5f69 6473 5f6c 6162 656c 5b3a 2c20  on_ids_label[:, 
+00011af0: 3a2c 0a20 2020 2020 2020 2020 2020 2020  :,.             
+00011b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b10: 2020 2020 2020 2020 2020 2031 5d2c 2061             1], a
+00011b20: 6273 6f6c 7574 655f 706f 7369 7469 6f6e  bsolute_position
+00011b30: 5f69 6473 5f6c 6162 656c 5b3a 2c20 3a2c  _ids_label[:, :,
+00011b40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b80: 2020 2020 2020 2020 2033 5d2c 0a20 2020           3],.   
+00011b90: 2020 2020 2020 2020 2072 656c 6174 6976           relativ
+00011ba0: 655f 706f 7369 7469 6f6e 5f69 6473 5f6c  e_position_ids_l
+00011bb0: 6162 656c 5b3a 2c20 3a2c 0a20 2020 2020  abel[:, :,.     
+00011bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011be0: 2020 2030 5d2c 2072 656c 6174 6976 655f     0], relative_
+00011bf0: 706f 7369 7469 6f6e 5f69 6473 5f6c 6162  position_ids_lab
+00011c00: 656c 5b3a 2c20 3a2c 0a20 2020 2020 2020  el[:, :,.       
 00011c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c20: 2020 315d 2c20 6162 736f 6c75 7465 5f70    1], absolute_p
-00011c30: 6f73 6974 696f 6e5f 6964 735f 6c61 6265  osition_ids_labe
-00011c40: 6c5b 3a2c 203a 2c0a 2020 2020 2020 2020  l[:, :,.        
-00011c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c90: 335d 2c0a 2020 2020 2020 2020 2020 2020  3],.            
-00011ca0: 7265 6c61 7469 7665 5f70 6f73 6974 696f  relative_positio
-00011cb0: 6e5f 6964 735f 6c61 6265 6c5b 3a2c 203a  n_ids_label[:, :
-00011cc0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00011cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ce0: 2020 2020 2020 2020 2020 305d 2c20 7265            0], re
-00011cf0: 6c61 7469 7665 5f70 6f73 6974 696f 6e5f  lative_position_
-00011d00: 6964 735f 6c61 6265 6c5b 3a2c 203a 2c0a  ids_label[:, :,.
-00011d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011d50: 2020 2020 2020 2020 325d 2c0a 2020 2020          2],.    
-00011d60: 2020 2020 2020 2020 7265 6c61 7469 7665          relative
-00011d70: 5f70 6f73 6974 696f 6e5f 6964 735f 6c61  _position_ids_la
-00011d80: 6265 6c5b 3a2c 203a 2c0a 2020 2020 2020  bel[:, :,.      
-00011d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011db0: 2020 315d 2c20 7265 6c61 7469 7665 5f70    1], relative_p
-00011dc0: 6f73 6974 696f 6e5f 6964 735f 6c61 6265  osition_ids_labe
-00011dd0: 6c5b 3a2c 203a 2c0a 2020 2020 2020 2020  l[:, :,.        
-00011de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011e20: 335d 0a20 2020 2020 2020 205d 0a20 2020  3].        ].   
-00011e30: 2020 2020 2070 6f73 6974 696f 6e73 5f73       positions_s
-00011e40: 697a 6520 3d20 5b0a 2020 2020 2020 2020  ize = [.        
-00011e50: 2020 2020 7365 6c66 2e63 6f6e 6669 672e      self.config.
-00011e60: 7479 7065 5f76 6f63 6162 5f73 697a 652c  type_vocab_size,
-00011e70: 2073 656c 662e 636f 6e66 6967 2e72 656c   self.config.rel
-00011e80: 5f74 7970 655f 766f 6361 625f 7369 7a65  _type_vocab_size
-00011e90: 2c0a 2020 2020 2020 2020 2020 2020 7365  ,.            se
-00011ea0: 6c66 2e63 6f6e 6669 672e 6162 736f 6c75  lf.config.absolu
-00011eb0: 7465 5f78 5f76 6f63 6162 5f73 697a 652c  te_x_vocab_size,
-00011ec0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00011ed0: 662e 636f 6e66 6967 2e61 6273 6f6c 7574  f.config.absolut
-00011ee0: 655f 785f 766f 6361 625f 7369 7a65 2c0a  e_x_vocab_size,.
-00011ef0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00011f00: 2e63 6f6e 6669 672e 6162 736f 6c75 7465  .config.absolute
-00011f10: 5f79 5f76 6f63 6162 5f73 697a 652c 0a20  _y_vocab_size,. 
-00011f20: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00011f30: 636f 6e66 6967 2e61 6273 6f6c 7574 655f  config.absolute_
-00011f40: 795f 766f 6361 625f 7369 7a65 2c0a 2020  y_vocab_size,.  
-00011f50: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
-00011f60: 6f6e 6669 672e 7265 6c61 7469 7665 5f78  onfig.relative_x
-00011f70: 5f76 6f63 6162 5f73 697a 652c 0a20 2020  _vocab_size,.   
-00011f80: 2020 2020 2020 2020 2073 656c 662e 636f           self.co
-00011f90: 6e66 6967 2e72 656c 6174 6976 655f 785f  nfig.relative_x_
-00011fa0: 766f 6361 625f 7369 7a65 2c0a 2020 2020  vocab_size,.    
-00011fb0: 2020 2020 2020 2020 7365 6c66 2e63 6f6e          self.con
-00011fc0: 6669 672e 7265 6c61 7469 7665 5f79 5f76  fig.relative_y_v
-00011fd0: 6f63 6162 5f73 697a 652c 0a20 2020 2020  ocab_size,.     
-00011fe0: 2020 2020 2020 2073 656c 662e 636f 6e66         self.conf
-00011ff0: 6967 2e72 656c 6174 6976 655f 795f 766f  ig.relative_y_vo
-00012000: 6361 625f 7369 7a65 0a20 2020 2020 2020  cab_size.       
-00012010: 205d 0a20 2020 2020 2020 2066 6f72 206d   ].        for m
-00012020: 7963 6c73 2c20 6d79 6c61 6265 6c73 2c20  ycls, mylabels, 
-00012030: 6d79 7369 7a65 2069 6e20 7a69 7028 706f  mysize in zip(po
-00012040: 7369 7469 6f6e 735f 636c 732c 2070 6f73  sitions_cls, pos
-00012050: 6974 696f 6e73 5f6c 6162 656c 2c0a 2020  itions_label,.  
-00012060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012080: 2020 2020 2020 2020 2070 6f73 6974 696f           positio
-00012090: 6e73 5f73 697a 6529 3a0a 2020 2020 2020  ns_size):.      
-000120a0: 2020 2020 2020 6966 206d 796c 6162 656c        if mylabel
-000120b0: 7320 6973 206e 6f74 204e 6f6e 653a 0a20  s is not None:. 
-000120c0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-000120d0: 7970 7265 6469 6374 696f 6e5f 7363 6f72  yprediction_scor
-000120e0: 6573 203d 206d 7963 6c73 2873 6571 7565  es = mycls(seque
-000120f0: 6e63 655f 6f75 7470 7574 290a 2020 2020  nce_output).    
-00012100: 2020 2020 2020 2020 2020 2020 6d61 736b              mask
-00012110: 6564 5f6c 6d5f 6c6f 7373 202b 3d20 6c6f  ed_lm_loss += lo
-00012120: 7373 5f66 6374 280a 2020 2020 2020 2020  ss_fct(.        
-00012130: 2020 2020 2020 2020 2020 2020 6d79 7072              mypr
-00012140: 6564 6963 7469 6f6e 5f73 636f 7265 732e  ediction_scores.
-00012150: 7669 6577 282d 312c 206d 7973 697a 6529  view(-1, mysize)
-00012160: 2c20 6d79 6c61 6265 6c73 2e76 6965 7728  , mylabels.view(
-00012170: 2d31 2929 0a0a 2020 2020 2020 2020 6966  -1))..        if
-00012180: 206e 6f74 2072 6574 7572 6e5f 6469 6374   not return_dict
-00012190: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
-000121a0: 7470 7574 203d 2028 7072 6564 6963 7469  tput = (predicti
-000121b0: 6f6e 5f73 636f 7265 732c 2029 202b 206f  on_scores, ) + o
-000121c0: 7574 7075 7473 5b32 3a5d 0a20 2020 2020  utputs[2:].     
-000121d0: 2020 2020 2020 2072 6574 7572 6e20 2828         return ((
-000121e0: 6d61 736b 6564 5f6c 6d5f 6c6f 7373 2c20  masked_lm_loss, 
-000121f0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00012200: 2020 2020 2020 2b20 6f75 7470 7574 2920        + output) 
-00012210: 6966 206d 6173 6b65 645f 6c6d 5f6c 6f73  if masked_lm_los
-00012220: 7320 6973 206e 6f74 204e 6f6e 6520 656c  s is not None el
-00012230: 7365 206f 7574 7075 740a 0a20 2020 2020  se output..     
-00012240: 2020 2072 6574 7572 6e20 4d61 736b 6564     return Masked
-00012250: 4c4d 4f75 7470 7574 280a 2020 2020 2020  LMOutput(.      
-00012260: 2020 2020 2020 6c6f 7373 3d6d 6173 6b65        loss=maske
-00012270: 645f 6c6d 5f6c 6f73 732c 0a20 2020 2020  d_lm_loss,.     
-00012280: 2020 2020 2020 206c 6f67 6974 733d 7072         logits=pr
-00012290: 6564 6963 7469 6f6e 5f73 636f 7265 732c  ediction_scores,
-000122a0: 0a20 2020 2020 2020 2020 2020 2068 6964  .            hid
-000122b0: 6465 6e5f 7374 6174 6573 3d6f 7574 7075  den_states=outpu
-000122c0: 7473 2e68 6964 6465 6e5f 7374 6174 6573  ts.hidden_states
-000122d0: 2c0a 2020 2020 2020 2020 2020 2020 6174  ,.            at
-000122e0: 7465 6e74 696f 6e73 3d6f 7574 7075 7473  tentions=outputs
-000122f0: 2e61 7474 656e 7469 6f6e 732c 0a20 2020  .attentions,.   
-00012300: 2020 2020 2029 0a0a 2020 2020 6465 6620       )..    def 
-00012310: 7072 6570 6172 655f 696e 7075 7473 5f66  prepare_inputs_f
-00012320: 6f72 5f67 656e 6572 6174 696f 6e28 7365  or_generation(se
-00012330: 6c66 2c0a 2020 2020 2020 2020 2020 2020  lf,.            
-00012340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012350: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00012360: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
-00012370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012380: 2020 2020 2020 2020 2020 2061 7474 656e             atten
-00012390: 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65 2c0a  tion_mask=None,.
-000123a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000123b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000123c0: 2020 2020 2020 2a2a 6d6f 6465 6c5f 6b77        **model_kw
-000123d0: 6172 6773 293a 0a20 2020 2020 2020 2069  args):.        i
-000123e0: 6e70 7574 5f73 6861 7065 203d 2069 6e70  nput_shape = inp
-000123f0: 7574 5f69 6473 2e73 6861 7065 0a20 2020  ut_ids.shape.   
-00012400: 2020 2020 2065 6666 6563 7469 7665 5f62       effective_b
-00012410: 6174 6368 5f73 697a 6520 3d20 696e 7075  atch_size = inpu
-00012420: 745f 7368 6170 655b 305d 0a0a 2020 2020  t_shape[0]..    
-00012430: 2020 2020 2320 2061 6464 2061 2064 756d      #  add a dum
-00012440: 6d79 2074 6f6b 656e 0a20 2020 2020 2020  my token.       
-00012450: 2061 7373 6572 7420 7365 6c66 2e63 6f6e   assert self.con
-00012460: 6669 672e 7061 645f 746f 6b65 6e5f 6964  fig.pad_token_id
-00012470: 2069 7320 6e6f 7420 4e6f 6e65 2c20 2754   is not None, 'T
-00012480: 6865 2050 4144 2074 6f6b 656e 2073 686f  he PAD token sho
-00012490: 756c 6420 6265 2064 6566 696e 6564 2066  uld be defined f
-000124a0: 6f72 2067 656e 6572 6174 696f 6e27 0a20  or generation'. 
-000124b0: 2020 2020 2020 2070 6164 6469 6e67 5f6d         padding_m
-000124c0: 6173 6b20 3d20 6174 7465 6e74 696f 6e5f  ask = attention_
-000124d0: 6d61 736b 2e6e 6577 5f7a 6572 6f73 2828  mask.new_zeros((
-000124e0: 6174 7465 6e74 696f 6e5f 6d61 736b 2e73  attention_mask.s
-000124f0: 6861 7065 5b30 5d2c 2031 2929 0a20 2020  hape[0], 1)).   
-00012500: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
-00012510: 6173 6b20 3d20 746f 7263 682e 6361 7428  ask = torch.cat(
-00012520: 5b61 7474 656e 7469 6f6e 5f6d 6173 6b2c  [attention_mask,
-00012530: 2070 6164 6469 6e67 5f6d 6173 6b5d 2c20   padding_mask], 
-00012540: 6469 6d3d 2d31 290a 2020 2020 2020 2020  dim=-1).        
-00012550: 6475 6d6d 795f 746f 6b65 6e20 3d20 746f  dummy_token = to
-00012560: 7263 682e 6675 6c6c 2828 6566 6665 6374  rch.full((effect
-00012570: 6976 655f 6261 7463 685f 7369 7a65 2c20  ive_batch_size, 
-00012580: 3129 2c0a 2020 2020 2020 2020 2020 2020  1),.            
-00012590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000125a0: 2020 2020 2073 656c 662e 636f 6e66 6967       self.config
-000125b0: 2e70 6164 5f74 6f6b 656e 5f69 642c 0a20  .pad_token_id,. 
-000125c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000125d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000125e0: 6474 7970 653d 746f 7263 682e 6c6f 6e67  dtype=torch.long
-000125f0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00012600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012610: 2020 2064 6576 6963 653d 696e 7075 745f     device=input_
-00012620: 6964 732e 6465 7669 6365 290a 2020 2020  ids.device).    
-00012630: 2020 2020 696e 7075 745f 6964 7320 3d20      input_ids = 
-00012640: 746f 7263 682e 6361 7428 5b69 6e70 7574  torch.cat([input
-00012650: 5f69 6473 2c20 6475 6d6d 795f 746f 6b65  _ids, dummy_toke
-00012660: 6e5d 2c20 6469 6d3d 3129 0a0a 2020 2020  n], dim=1)..    
-00012670: 2020 2020 7265 7475 726e 207b 2769 6e70      return {'inp
-00012680: 7574 5f69 6473 273a 2069 6e70 7574 5f69  ut_ids': input_i
-00012690: 6473 2c20 2761 7474 656e 7469 6f6e 5f6d  ds, 'attention_m
-000126a0: 6173 6b27 3a20 6174 7465 6e74 696f 6e5f  ask': attention_
-000126b0: 6d61 736b 7d0a 0a0a 636c 6173 7320 4265  mask}...class Be
-000126c0: 7274 466f 724d 6173 6b65 644c 4d28 4265  rtForMaskedLM(Be
-000126d0: 7274 5072 6554 7261 696e 6564 4d6f 6465  rtPreTrainedMode
-000126e0: 6c29 3a0a 0a20 2020 205f 6b65 7973 5f74  l):..    _keys_t
-000126f0: 6f5f 6967 6e6f 7265 5f6f 6e5f 6c6f 6164  o_ignore_on_load
-00012700: 5f75 6e65 7870 6563 7465 6420 3d20 5b72  _unexpected = [r
-00012710: 2770 6f6f 6c65 7227 5d0a 2020 2020 5f6b  'pooler'].    _k
-00012720: 6579 735f 746f 5f69 676e 6f72 655f 6f6e  eys_to_ignore_on
-00012730: 5f6c 6f61 645f 6d69 7373 696e 6720 3d20  _load_missing = 
-00012740: 5b0a 2020 2020 2020 2020 7227 706f 7369  [.        r'posi
-00012750: 7469 6f6e 5f69 6473 272c 2072 2770 7265  tion_ids', r'pre
-00012760: 6469 6374 696f 6e73 2e64 6563 6f64 6572  dictions.decoder
-00012770: 2e62 6961 7327 0a20 2020 205d 0a0a 2020  .bias'.    ]..  
-00012780: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-00012790: 656c 662c 2063 6f6e 6669 6729 3a0a 2020  elf, config):.  
-000127a0: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
-000127b0: 696e 6974 5f5f 2863 6f6e 6669 6729 0a0a  init__(config)..
-000127c0: 2020 2020 2020 2020 7365 6c66 2e62 6572          self.ber
-000127d0: 7420 3d20 4265 7274 4d6f 6465 6c28 636f  t = BertModel(co
-000127e0: 6e66 6967 2c20 6164 645f 706f 6f6c 696e  nfig, add_poolin
-000127f0: 675f 6c61 7965 723d 4661 6c73 6529 0a20  g_layer=False). 
-00012800: 2020 2020 2020 2073 656c 662e 636c 7320         self.cls 
-00012810: 3d20 4265 7274 4f6e 6c79 4d4c 4d48 6561  = BertOnlyMLMHea
-00012820: 6428 636f 6e66 6967 290a 0a20 2020 2020  d(config)..     
-00012830: 2020 2073 656c 662e 696e 6974 5f77 6569     self.init_wei
-00012840: 6768 7473 2829 0a0a 2020 2020 6465 6620  ghts()..    def 
-00012850: 6765 745f 6f75 7470 7574 5f65 6d62 6564  get_output_embed
-00012860: 6469 6e67 7328 7365 6c66 293a 0a20 2020  dings(self):.   
-00012870: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00012880: 2e63 6c73 2e70 7265 6469 6374 696f 6e73  .cls.predictions
-00012890: 2e64 6563 6f64 6572 0a0a 2020 2020 6465  .decoder..    de
-000128a0: 6620 7365 745f 6f75 7470 7574 5f65 6d62  f set_output_emb
-000128b0: 6564 6469 6e67 7328 7365 6c66 2c20 6e65  eddings(self, ne
-000128c0: 775f 656d 6265 6464 696e 6773 293a 0a20  w_embeddings):. 
-000128d0: 2020 2020 2020 2073 656c 662e 636c 732e         self.cls.
-000128e0: 7072 6564 6963 7469 6f6e 732e 6465 636f  predictions.deco
-000128f0: 6465 7220 3d20 6e65 775f 656d 6265 6464  der = new_embedd
-00012900: 696e 6773 0a0a 2020 2020 6465 6620 666f  ings..    def fo
-00012910: 7277 6172 6428 0a20 2020 2020 2020 2073  rward(.        s
-00012920: 656c 662c 0a20 2020 2020 2020 2069 6e70  elf,.        inp
-00012930: 7574 5f69 6473 3d4e 6f6e 652c 0a20 2020  ut_ids=None,.   
-00012940: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
-00012950: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
-00012960: 2020 746f 6b65 6e5f 7479 7065 5f69 6473    token_type_ids
-00012970: 3d4e 6f6e 652c 0a20 2020 2020 2020 2070  =None,.        p
-00012980: 6f73 6974 696f 6e5f 6964 733d 4e6f 6e65  osition_ids=None
-00012990: 2c0a 2020 2020 2020 2020 6865 6164 5f6d  ,.        head_m
-000129a0: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
-000129b0: 2020 696e 7075 7473 5f65 6d62 6564 733d    inputs_embeds=
-000129c0: 4e6f 6e65 2c0a 2020 2020 2020 2020 656e  None,.        en
-000129d0: 636f 6465 725f 656d 6265 6473 3d4e 6f6e  coder_embeds=Non
-000129e0: 652c 0a20 2020 2020 2020 2065 6e63 6f64  e,.        encod
-000129f0: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
-00012a00: 3d4e 6f6e 652c 0a20 2020 2020 2020 2065  =None,.        e
-00012a10: 6e63 6f64 6572 5f61 7474 656e 7469 6f6e  ncoder_attention
-00012a20: 5f6d 6173 6b3d 4e6f 6e65 2c0a 2020 2020  _mask=None,.    
-00012a30: 2020 2020 6c61 6265 6c73 3d4e 6f6e 652c      labels=None,
-00012a40: 0a20 2020 2020 2020 206f 7574 7075 745f  .        output_
-00012a50: 6174 7465 6e74 696f 6e73 3d4e 6f6e 652c  attentions=None,
-00012a60: 0a20 2020 2020 2020 206f 7574 7075 745f  .        output_
-00012a70: 6869 6464 656e 5f73 7461 7465 733d 4e6f  hidden_states=No
-00012a80: 6e65 2c0a 2020 2020 2020 2020 7265 7475  ne,.        retu
-00012a90: 726e 5f64 6963 743d 4e6f 6e65 2c0a 2020  rn_dict=None,.  
-00012aa0: 2020 2020 2020 6973 5f64 6563 6f64 6572        is_decoder
-00012ab0: 3d46 616c 7365 2c0a 2020 2020 2020 2020  =False,.        
-00012ac0: 6d6f 6465 3d27 6d75 6c74 695f 6d6f 6461  mode='multi_moda
-00012ad0: 6c27 2c0a 2020 2020 2020 2020 736f 6674  l',.        soft
-00012ae0: 5f6c 6162 656c 733d 4e6f 6e65 2c0a 2020  _labels=None,.  
-00012af0: 2020 2020 2020 616c 7068 613d 302c 0a20        alpha=0,. 
-00012b00: 2020 2020 2020 2072 6574 7572 6e5f 6c6f         return_lo
-00012b10: 6769 7473 3d46 616c 7365 2c0a 2020 2020  gits=False,.    
-00012b20: 2020 2020 7265 6c5f 7479 7065 5f69 6473      rel_type_ids
-00012b30: 3d4e 6f6e 652c 0a20 2020 2020 2020 2061  =None,.        a
-00012b40: 6273 6f6c 7574 655f 706f 7369 7469 6f6e  bsolute_position
-00012b50: 5f69 6473 3d4e 6f6e 652c 0a20 2020 2020  _ids=None,.     
-00012b60: 2020 2072 656c 6174 6976 655f 706f 7369     relative_posi
-00012b70: 7469 6f6e 5f69 6473 3d4e 6f6e 652c 0a20  tion_ids=None,. 
-00012b80: 2020 2029 3a0a 2020 2020 2020 2020 7222     ):.        r"
-00012b90: 2222 0a20 2020 2020 2020 206c 6162 656c  "".        label
-00012ba0: 7320 283a 6f62 6a3a 6074 6f72 6368 2e4c  s (:obj:`torch.L
-00012bb0: 6f6e 6754 656e 736f 7260 206f 6620 7368  ongTensor` of sh
-00012bc0: 6170 6520 3a6f 626a 3a60 2862 6174 6368  ape :obj:`(batch
-00012bd0: 5f73 697a 652c 2073 6571 7565 6e63 655f  _size, sequence_
-00012be0: 6c65 6e67 7468 2960 2c20 606f 7074 696f  length)`, `optio
-00012bf0: 6e61 6c60 293a 0a20 2020 2020 2020 2020  nal`):.         
-00012c00: 2020 204c 6162 656c 7320 666f 7220 636f     Labels for co
-00012c10: 6d70 7574 696e 6720 7468 6520 6d61 736b  mputing the mask
-00012c20: 6564 206c 616e 6775 6167 6520 6d6f 6465  ed language mode
-00012c30: 6c69 6e67 206c 6f73 732e 2049 6e64 6963  ling loss. Indic
-00012c40: 6573 2073 686f 756c 6420 6265 2069 6e20  es should be in 
-00012c50: 6060 5b2d 3130 302c 2030 2c20 2e2e 2e2c  ``[-100, 0, ...,
-00012c60: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
-00012c70: 6669 672e 766f 6361 625f 7369 7a65 5d60  fig.vocab_size]`
-00012c80: 6020 2873 6565 2060 6069 6e70 7574 5f69  ` (see ``input_i
-00012c90: 6473 6060 2064 6f63 7374 7269 6e67 2920  ds`` docstring) 
-00012ca0: 546f 6b65 6e73 2077 6974 6820 696e 6469  Tokens with indi
-00012cb0: 6365 7320 7365 7420 746f 2060 602d 3130  ces set to ``-10
-00012cc0: 3060 6020 6172 6520 6967 6e6f 7265 640a  0`` are ignored.
-00012cd0: 2020 2020 2020 2020 2020 2020 286d 6173              (mas
-00012ce0: 6b65 6429 2c20 7468 6520 6c6f 7373 2069  ked), the loss i
-00012cf0: 7320 6f6e 6c79 2063 6f6d 7075 7465 6420  s only computed 
-00012d00: 666f 7220 7468 6520 746f 6b65 6e73 2077  for the tokens w
-00012d10: 6974 6820 6c61 6265 6c73 2069 6e20 6060  ith labels in ``
-00012d20: 5b30 2c20 2e2e 2e2c 2063 6f6e 6669 672e  [0, ..., config.
-00012d30: 766f 6361 625f 7369 7a65 5d60 600a 2020  vocab_size]``.  
-00012d40: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
-00012d50: 2020 2072 6574 7572 6e5f 6469 6374 203d     return_dict =
-00012d60: 2072 6574 7572 6e5f 6469 6374 2069 6620   return_dict if 
-00012d70: 7265 7475 726e 5f64 6963 7420 6973 206e  return_dict is n
-00012d80: 6f74 204e 6f6e 6520 656c 7365 2073 656c  ot None else sel
-00012d90: 662e 636f 6e66 6967 2e75 7365 5f72 6574  f.config.use_ret
-00012da0: 7572 6e5f 6469 6374 0a0a 2020 2020 2020  urn_dict..      
-00012db0: 2020 6f75 7470 7574 7320 3d20 7365 6c66    outputs = self
-00012dc0: 2e62 6572 7428 0a20 2020 2020 2020 2020  .bert(.         
-00012dd0: 2020 2069 6e70 7574 5f69 6473 2c0a 2020     input_ids,.  
-00012de0: 2020 2020 2020 2020 2020 6174 7465 6e74            attent
-00012df0: 696f 6e5f 6d61 736b 3d61 7474 656e 7469  ion_mask=attenti
-00012e00: 6f6e 5f6d 6173 6b2c 0a20 2020 2020 2020  on_mask,.       
-00012e10: 2020 2020 2074 6f6b 656e 5f74 7970 655f       token_type_
-00012e20: 6964 733d 746f 6b65 6e5f 7479 7065 5f69  ids=token_type_i
-00012e30: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
-00012e40: 706f 7369 7469 6f6e 5f69 6473 3d70 6f73  position_ids=pos
-00012e50: 6974 696f 6e5f 6964 732c 0a20 2020 2020  ition_ids,.     
-00012e60: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
-00012e70: 3d68 6561 645f 6d61 736b 2c0a 2020 2020  =head_mask,.    
-00012e80: 2020 2020 2020 2020 696e 7075 7473 5f65          inputs_e
-00012e90: 6d62 6564 733d 696e 7075 7473 5f65 6d62  mbeds=inputs_emb
-00012ea0: 6564 732c 0a20 2020 2020 2020 2020 2020  eds,.           
-00012eb0: 2065 6e63 6f64 6572 5f65 6d62 6564 733d   encoder_embeds=
-00012ec0: 656e 636f 6465 725f 656d 6265 6473 2c0a  encoder_embeds,.
-00012ed0: 2020 2020 2020 2020 2020 2020 656e 636f              enco
-00012ee0: 6465 725f 6869 6464 656e 5f73 7461 7465  der_hidden_state
-00012ef0: 733d 656e 636f 6465 725f 6869 6464 656e  s=encoder_hidden
-00012f00: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
-00012f10: 2020 2020 2065 6e63 6f64 6572 5f61 7474       encoder_att
-00012f20: 656e 7469 6f6e 5f6d 6173 6b3d 656e 636f  ention_mask=enco
-00012f30: 6465 725f 6174 7465 6e74 696f 6e5f 6d61  der_attention_ma
-00012f40: 736b 2c0a 2020 2020 2020 2020 2020 2020  sk,.            
-00012f50: 6f75 7470 7574 5f61 7474 656e 7469 6f6e  output_attention
-00012f60: 733d 6f75 7470 7574 5f61 7474 656e 7469  s=output_attenti
-00012f70: 6f6e 732c 0a20 2020 2020 2020 2020 2020  ons,.           
-00012f80: 206f 7574 7075 745f 6869 6464 656e 5f73   output_hidden_s
-00012f90: 7461 7465 733d 6f75 7470 7574 5f68 6964  tates=output_hid
-00012fa0: 6465 6e5f 7374 6174 6573 2c0a 2020 2020  den_states,.    
-00012fb0: 2020 2020 2020 2020 7265 7475 726e 5f64          return_d
-00012fc0: 6963 743d 7265 7475 726e 5f64 6963 742c  ict=return_dict,
-00012fd0: 0a20 2020 2020 2020 2020 2020 2069 735f  .            is_
-00012fe0: 6465 636f 6465 723d 6973 5f64 6563 6f64  decoder=is_decod
-00012ff0: 6572 2c0a 2020 2020 2020 2020 2020 2020  er,.            
-00013000: 6d6f 6465 3d6d 6f64 652c 0a20 2020 2020  mode=mode,.     
-00013010: 2020 2020 2020 2072 656c 5f74 7970 655f         rel_type_
-00013020: 6964 733d 7265 6c5f 7479 7065 5f69 6473  ids=rel_type_ids
-00013030: 2c0a 2020 2020 2020 2020 2020 2020 6162  ,.            ab
-00013040: 736f 6c75 7465 5f70 6f73 6974 696f 6e5f  solute_position_
-00013050: 6964 733d 6162 736f 6c75 7465 5f70 6f73  ids=absolute_pos
-00013060: 6974 696f 6e5f 6964 732c 0a20 2020 2020  ition_ids,.     
-00013070: 2020 2020 2020 2072 656c 6174 6976 655f         relative_
-00013080: 706f 7369 7469 6f6e 5f69 6473 3d72 656c  position_ids=rel
-00013090: 6174 6976 655f 706f 7369 7469 6f6e 5f69  ative_position_i
-000130a0: 6473 2c0a 2020 2020 2020 2020 290a 0a20  ds,.        ).. 
-000130b0: 2020 2020 2020 2073 6571 7565 6e63 655f         sequence_
-000130c0: 6f75 7470 7574 203d 206f 7574 7075 7473  output = outputs
-000130d0: 5b30 5d0a 2020 2020 2020 2020 7072 6564  [0].        pred
-000130e0: 6963 7469 6f6e 5f73 636f 7265 7320 3d20  iction_scores = 
-000130f0: 7365 6c66 2e63 6c73 2873 6571 7565 6e63  self.cls(sequenc
-00013100: 655f 6f75 7470 7574 290a 0a20 2020 2020  e_output)..     
-00013110: 2020 2069 6620 7265 7475 726e 5f6c 6f67     if return_log
-00013120: 6974 733a 0a20 2020 2020 2020 2020 2020  its:.           
-00013130: 2072 6574 7572 6e20 7072 6564 6963 7469   return predicti
-00013140: 6f6e 5f73 636f 7265 730a 0a20 2020 2020  on_scores..     
-00013150: 2020 206d 6173 6b65 645f 6c6d 5f6c 6f73     masked_lm_los
-00013160: 7320 3d20 4e6f 6e65 0a20 2020 2020 2020  s = None.       
-00013170: 2069 6620 6c61 6265 6c73 2069 7320 6e6f   if labels is no
-00013180: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-00013190: 2020 2020 6c6f 7373 5f66 6374 203d 2043      loss_fct = C
-000131a0: 726f 7373 456e 7472 6f70 794c 6f73 7328  rossEntropyLoss(
-000131b0: 2920 2023 202d 3130 3020 696e 6465 7820  )  # -100 index 
-000131c0: 3d20 7061 6464 696e 6720 746f 6b65 6e0a  = padding token.
-000131d0: 2020 2020 2020 2020 2020 2020 6d61 736b              mask
-000131e0: 6564 5f6c 6d5f 6c6f 7373 203d 206c 6f73  ed_lm_loss = los
-000131f0: 735f 6663 7428 0a20 2020 2020 2020 2020  s_fct(.         
-00013200: 2020 2020 2020 2070 7265 6469 6374 696f         predictio
-00013210: 6e5f 7363 6f72 6573 2e76 6965 7728 2d31  n_scores.view(-1
-00013220: 2c20 7365 6c66 2e63 6f6e 6669 672e 766f  , self.config.vo
-00013230: 6361 625f 7369 7a65 292c 0a20 2020 2020  cab_size),.     
-00013240: 2020 2020 2020 2020 2020 206c 6162 656c             label
-00013250: 732e 7669 6577 282d 3129 290a 0a20 2020  s.view(-1))..   
-00013260: 2020 2020 2069 6620 736f 6674 5f6c 6162       if soft_lab
-00013270: 656c 7320 6973 206e 6f74 204e 6f6e 653a  els is not None:
-00013280: 0a20 2020 2020 2020 2020 2020 206c 6f73  .            los
-00013290: 735f 6469 7374 696c 6c20 3d20 2d74 6f72  s_distill = -tor
-000132a0: 6368 2e73 756d 280a 2020 2020 2020 2020  ch.sum(.        
-000132b0: 2020 2020 2020 2020 462e 6c6f 675f 736f          F.log_so
-000132c0: 6674 6d61 7828 7072 6564 6963 7469 6f6e  ftmax(prediction
-000132d0: 5f73 636f 7265 732c 2064 696d 3d2d 3129  _scores, dim=-1)
-000132e0: 202a 2073 6f66 745f 6c61 6265 6c73 2c20   * soft_labels, 
-000132f0: 6469 6d3d 2d31 290a 2020 2020 2020 2020  dim=-1).        
-00013300: 2020 2020 6c6f 7373 5f64 6973 7469 6c6c      loss_distill
-00013310: 203d 206c 6f73 735f 6469 7374 696c 6c5b   = loss_distill[
-00013320: 6c61 6265 6c73 2021 3d20 2d31 3030 5d2e  labels != -100].
-00013330: 6d65 616e 2829 0a20 2020 2020 2020 2020  mean().         
-00013340: 2020 206d 6173 6b65 645f 6c6d 5f6c 6f73     masked_lm_los
-00013350: 7320 3d20 2831 0a20 2020 2020 2020 2020  s = (1.         
-00013360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013370: 2020 2020 202d 2061 6c70 6861 2920 2a20       - alpha) * 
-00013380: 6d61 736b 6564 5f6c 6d5f 6c6f 7373 202b  masked_lm_loss +
-00013390: 2061 6c70 6861 202a 206c 6f73 735f 6469   alpha * loss_di
-000133a0: 7374 696c 6c0a 0a20 2020 2020 2020 2069  still..        i
-000133b0: 6620 6e6f 7420 7265 7475 726e 5f64 6963  f not return_dic
-000133c0: 743a 0a20 2020 2020 2020 2020 2020 206f  t:.            o
-000133d0: 7574 7075 7420 3d20 2870 7265 6469 6374  utput = (predict
-000133e0: 696f 6e5f 7363 6f72 6573 2c20 2920 2b20  ion_scores, ) + 
-000133f0: 6f75 7470 7574 735b 323a 5d0a 2020 2020  outputs[2:].    
-00013400: 2020 2020 2020 2020 7265 7475 726e 2028          return (
-00013410: 286d 6173 6b65 645f 6c6d 5f6c 6f73 732c  (masked_lm_loss,
-00013420: 2029 0a20 2020 2020 2020 2020 2020 2020   ).             
-00013430: 2020 2020 2020 202b 206f 7574 7075 7429         + output)
-00013440: 2069 6620 6d61 736b 6564 5f6c 6d5f 6c6f   if masked_lm_lo
-00013450: 7373 2069 7320 6e6f 7420 4e6f 6e65 2065  ss is not None e
-00013460: 6c73 6520 6f75 7470 7574 0a0a 2020 2020  lse output..    
-00013470: 2020 2020 7265 7475 726e 204d 6173 6b65      return Maske
-00013480: 644c 4d4f 7574 7075 7428 0a20 2020 2020  dLMOutput(.     
-00013490: 2020 2020 2020 206c 6f73 733d 6d61 736b         loss=mask
-000134a0: 6564 5f6c 6d5f 6c6f 7373 2c0a 2020 2020  ed_lm_loss,.    
-000134b0: 2020 2020 2020 2020 6c6f 6769 7473 3d70          logits=p
-000134c0: 7265 6469 6374 696f 6e5f 7363 6f72 6573  rediction_scores
-000134d0: 2c0a 2020 2020 2020 2020 2020 2020 6869  ,.            hi
-000134e0: 6464 656e 5f73 7461 7465 733d 6f75 7470  dden_states=outp
-000134f0: 7574 732e 6869 6464 656e 5f73 7461 7465  uts.hidden_state
-00013500: 732c 0a20 2020 2020 2020 2020 2020 2061  s,.            a
-00013510: 7474 656e 7469 6f6e 733d 6f75 7470 7574  ttentions=output
-00013520: 732e 6174 7465 6e74 696f 6e73 2c0a 2020  s.attentions,.  
-00013530: 2020 2020 2020 290a 0a20 2020 2064 6566        )..    def
-00013540: 2070 7265 7061 7265 5f69 6e70 7574 735f   prepare_inputs_
-00013550: 666f 725f 6765 6e65 7261 7469 6f6e 2873  for_generation(s
-00013560: 656c 662c 0a20 2020 2020 2020 2020 2020  elf,.           
-00013570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013580: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00013590: 5f69 6473 2c0a 2020 2020 2020 2020 2020  _ids,.          
-000135a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000135b0: 2020 2020 2020 2020 2020 2020 6174 7465              atte
-000135c0: 6e74 696f 6e5f 6d61 736b 3d4e 6f6e 652c  ntion_mask=None,
-000135d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000135e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000135f0: 2020 2020 2020 202a 2a6d 6f64 656c 5f6b         **model_k
-00013600: 7761 7267 7329 3a0a 2020 2020 2020 2020  wargs):.        
-00013610: 696e 7075 745f 7368 6170 6520 3d20 696e  input_shape = in
-00013620: 7075 745f 6964 732e 7368 6170 650a 2020  put_ids.shape.  
-00013630: 2020 2020 2020 6566 6665 6374 6976 655f        effective_
-00013640: 6261 7463 685f 7369 7a65 203d 2069 6e70  batch_size = inp
-00013650: 7574 5f73 6861 7065 5b30 5d0a 0a20 2020  ut_shape[0]..   
-00013660: 2020 2020 2023 2020 6164 6420 6120 6475       #  add a du
-00013670: 6d6d 7920 746f 6b65 6e0a 2020 2020 2020  mmy token.      
-00013680: 2020 6173 7365 7274 2073 656c 662e 636f    assert self.co
-00013690: 6e66 6967 2e70 6164 5f74 6f6b 656e 5f69  nfig.pad_token_i
-000136a0: 6420 6973 206e 6f74 204e 6f6e 652c 2027  d is not None, '
-000136b0: 5468 6520 5041 4420 746f 6b65 6e20 7368  The PAD token sh
-000136c0: 6f75 6c64 2062 6520 6465 6669 6e65 6420  ould be defined 
-000136d0: 666f 7220 6765 6e65 7261 7469 6f6e 270a  for generation'.
-000136e0: 0a20 2020 2020 2020 2070 6164 6469 6e67  .        padding
-000136f0: 5f6d 6173 6b20 3d20 6174 7465 6e74 696f  _mask = attentio
-00013700: 6e5f 6d61 736b 2e6e 6577 5f7a 6572 6f73  n_mask.new_zeros
-00013710: 2828 6174 7465 6e74 696f 6e5f 6d61 736b  ((attention_mask
-00013720: 2e73 6861 7065 5b30 5d2c 2031 2929 0a20  .shape[0], 1)). 
-00013730: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
-00013740: 5f6d 6173 6b20 3d20 746f 7263 682e 6361  _mask = torch.ca
-00013750: 7428 5b61 7474 656e 7469 6f6e 5f6d 6173  t([attention_mas
-00013760: 6b2c 2070 6164 6469 6e67 5f6d 6173 6b5d  k, padding_mask]
-00013770: 2c20 6469 6d3d 2d31 290a 2020 2020 2020  , dim=-1).      
-00013780: 2020 6475 6d6d 795f 746f 6b65 6e20 3d20    dummy_token = 
-00013790: 746f 7263 682e 6675 6c6c 2828 6566 6665  torch.full((effe
-000137a0: 6374 6976 655f 6261 7463 685f 7369 7a65  ctive_batch_size
-000137b0: 2c20 3129 2c0a 2020 2020 2020 2020 2020  , 1),.          
-000137c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000137d0: 2020 2020 2020 2073 656c 662e 636f 6e66         self.conf
-000137e0: 6967 2e70 6164 5f74 6f6b 656e 5f69 642c  ig.pad_token_id,
-000137f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00013800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013810: 2020 6474 7970 653d 746f 7263 682e 6c6f    dtype=torch.lo
-00013820: 6e67 2c0a 2020 2020 2020 2020 2020 2020  ng,.            
-00013830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013840: 2020 2020 2064 6576 6963 653d 696e 7075       device=inpu
-00013850: 745f 6964 732e 6465 7669 6365 290a 2020  t_ids.device).  
-00013860: 2020 2020 2020 696e 7075 745f 6964 7320        input_ids 
-00013870: 3d20 746f 7263 682e 6361 7428 5b69 6e70  = torch.cat([inp
-00013880: 7574 5f69 6473 2c20 6475 6d6d 795f 746f  ut_ids, dummy_to
-00013890: 6b65 6e5d 2c20 6469 6d3d 3129 0a0a 2020  ken], dim=1)..  
-000138a0: 2020 2020 2020 7265 7475 726e 207b 2769        return {'i
-000138b0: 6e70 7574 5f69 6473 273a 2069 6e70 7574  nput_ids': input
-000138c0: 5f69 6473 2c20 2761 7474 656e 7469 6f6e  _ids, 'attention
-000138d0: 5f6d 6173 6b27 3a20 6174 7465 6e74 696f  _mask': attentio
-000138e0: 6e5f 6d61 736b 7d0a 0a0a 636c 6173 7320  n_mask}...class 
-000138f0: 4265 7274 466f 724e 6578 7453 656e 7465  BertForNextSente
-00013900: 6e63 6550 7265 6469 6374 696f 6e28 4265  ncePrediction(Be
-00013910: 7274 5072 6554 7261 696e 6564 4d6f 6465  rtPreTrainedMode
-00013920: 6c29 3a0a 0a20 2020 2064 6566 205f 5f69  l):..    def __i
-00013930: 6e69 745f 5f28 7365 6c66 2c20 636f 6e66  nit__(self, conf
-00013940: 6967 293a 0a20 2020 2020 2020 2073 7570  ig):.        sup
-00013950: 6572 2829 2e5f 5f69 6e69 745f 5f28 636f  er().__init__(co
-00013960: 6e66 6967 290a 0a20 2020 2020 2020 2073  nfig)..        s
-00013970: 656c 662e 6265 7274 203d 2042 6572 744d  elf.bert = BertM
-00013980: 6f64 656c 2863 6f6e 6669 6729 0a20 2020  odel(config).   
-00013990: 2020 2020 2073 656c 662e 636c 7320 3d20       self.cls = 
-000139a0: 4265 7274 4f6e 6c79 4e53 5048 6561 6428  BertOnlyNSPHead(
-000139b0: 636f 6e66 6967 290a 0a20 2020 2020 2020  config)..       
-000139c0: 2073 656c 662e 696e 6974 5f77 6569 6768   self.init_weigh
-000139d0: 7473 2829 0a0a 2020 2020 6465 6620 666f  ts()..    def fo
-000139e0: 7277 6172 6428 7365 6c66 2c0a 2020 2020  rward(self,.    
-000139f0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
-00013a00: 745f 6964 733d 4e6f 6e65 2c0a 2020 2020  t_ids=None,.    
-00013a10: 2020 2020 2020 2020 2020 2020 6174 7465              atte
-00013a20: 6e74 696f 6e5f 6d61 736b 3d4e 6f6e 652c  ntion_mask=None,
-00013a30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00013a40: 2074 6f6b 656e 5f74 7970 655f 6964 733d   token_type_ids=
-00013a50: 4e6f 6e65 2c0a 2020 2020 2020 2020 2020  None,.          
-00013a60: 2020 2020 2020 706f 7369 7469 6f6e 5f69        position_i
-00013a70: 6473 3d4e 6f6e 652c 0a20 2020 2020 2020  ds=None,.       
-00013a80: 2020 2020 2020 2020 2068 6561 645f 6d61           head_ma
-00013a90: 736b 3d4e 6f6e 652c 0a20 2020 2020 2020  sk=None,.       
-00013aa0: 2020 2020 2020 2020 2069 6e70 7574 735f           inputs_
-00013ab0: 656d 6265 6473 3d4e 6f6e 652c 0a20 2020  embeds=None,.   
-00013ac0: 2020 2020 2020 2020 2020 2020 206c 6162               lab
-00013ad0: 656c 733d 4e6f 6e65 2c0a 2020 2020 2020  els=None,.      
-00013ae0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00013af0: 5f61 7474 656e 7469 6f6e 733d 4e6f 6e65  _attentions=None
-00013b00: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00013b10: 2020 6f75 7470 7574 5f68 6964 6465 6e5f    output_hidden_
-00013b20: 7374 6174 6573 3d4e 6f6e 652c 0a20 2020  states=None,.   
-00013b30: 2020 2020 2020 2020 2020 2020 2072 6574               ret
-00013b40: 7572 6e5f 6469 6374 3d4e 6f6e 652c 0a20  urn_dict=None,. 
-00013b50: 2020 2020 2020 2020 2020 2020 2020 202a                 *
-00013b60: 2a6b 7761 7267 7329 3a0a 2020 2020 2020  *kwargs):.      
-00013b70: 2020 7222 2222 0a20 2020 2020 2020 206c    r""".        l
-00013b80: 6162 656c 7320 283a 6f62 6a3a 6074 6f72  abels (:obj:`tor
-00013b90: 6368 2e4c 6f6e 6754 656e 736f 7260 206f  ch.LongTensor` o
-00013ba0: 6620 7368 6170 6520 3a6f 626a 3a60 2862  f shape :obj:`(b
-00013bb0: 6174 6368 5f73 697a 652c 2960 2c20 606f  atch_size,)`, `o
-00013bc0: 7074 696f 6e61 6c60 293a 0a20 2020 2020  ptional`):.     
-00013bd0: 2020 2020 2020 204c 6162 656c 7320 666f         Labels fo
-00013be0: 7220 636f 6d70 7574 696e 6720 7468 6520  r computing the 
-00013bf0: 6e65 7874 2073 6571 7565 6ec3 a563 6520  next sequen..ce 
-00013c00: 7072 6564 6963 7469 6f6e 2028 636c 6173  prediction (clas
-00013c10: 7369 6669 6361 7469 6f6e 2920 6c6f 7373  sification) loss
-00013c20: 2e20 496e 7075 7420 7368 6f75 6c64 2062  . Input should b
-00013c30: 6520 6120 7365 7175 656e 6365 2070 6169  e a sequence pai
-00013c40: 720a 2020 2020 2020 2020 2020 2020 2873  r.            (s
-00013c50: 6565 2060 6069 6e70 7574 5f69 6473 6060  ee ``input_ids``
-00013c60: 2064 6f63 7374 7269 6e67 292e 2049 6e64   docstring). Ind
-00013c70: 6963 6573 2073 686f 756c 6420 6265 2069  ices should be i
-00013c80: 6e20 6060 5b30 2c20 315d 6060 3a0a 2020  n ``[0, 1]``:.  
-00013c90: 2020 2020 2020 2020 2020 2d20 3020 696e            - 0 in
-00013ca0: 6469 6361 7465 7320 7365 7175 656e 6365  dicates sequence
-00013cb0: 2042 2069 7320 6120 636f 6e74 696e 7561   B is a continua
-00013cc0: 7469 6f6e 206f 6620 7365 7175 656e 6365  tion of sequence
-00013cd0: 2041 2c0a 2020 2020 2020 2020 2020 2020   A,.            
-00013ce0: 2d20 3120 696e 6469 6361 7465 7320 7365  - 1 indicates se
-00013cf0: 7175 656e 6365 2042 2069 7320 6120 7261  quence B is a ra
-00013d00: 6e64 6f6d 2073 6571 7565 6e63 652e 0a20  ndom sequence.. 
-00013d10: 2020 2020 2020 2052 6574 7572 6e73 3a0a         Returns:.
-00013d20: 0a20 2020 2020 2020 2045 7861 6d70 6c65  .        Example
-00013d30: 3a0a 2020 2020 2020 2020 2020 2020 3e3e  :.            >>
-00013d40: 3e20 6672 6f6d 2074 7261 6e73 666f 726d  > from transform
-00013d50: 6572 7320 696d 706f 7274 2042 6572 7454  ers import BertT
-00013d60: 6f6b 656e 697a 6572 2c20 4265 7274 466f  okenizer, BertFo
-00013d70: 724e 6578 7453 656e 7465 6e63 6550 7265  rNextSentencePre
-00013d80: 6469 6374 696f 6e0a 2020 2020 2020 2020  diction.        
-00013d90: 2020 2020 3e3e 3e20 696d 706f 7274 2074      >>> import t
-00013da0: 6f72 6368 0a20 2020 2020 2020 2020 2020  orch.           
-00013db0: 203e 3e3e 2074 6f6b 656e 697a 6572 203d   >>> tokenizer =
-00013dc0: 2042 6572 7454 6f6b 656e 697a 6572 2e66   BertTokenizer.f
-00013dd0: 726f 6d5f 7072 6574 7261 696e 6564 2827  rom_pretrained('
-00013de0: 6265 7274 2d62 6173 652d 756e 6361 7365  bert-base-uncase
-00013df0: 6427 290a 2020 2020 2020 2020 2020 2020  d').            
-00013e00: 3e3e 3e20 6d6f 6465 6c20 3d20 4265 7274  >>> model = Bert
-00013e10: 466f 724e 6578 7453 656e 7465 6e63 6550  ForNextSentenceP
-00013e20: 7265 6469 6374 696f 6e2e 6672 6f6d 5f70  rediction.from_p
-00013e30: 7265 7472 6169 6e65 6428 2762 6572 742d  retrained('bert-
-00013e40: 6261 7365 2d75 6e63 6173 6564 2729 0a20  base-uncased'). 
-00013e50: 2020 2020 2020 2020 2020 203e 3e3e 2070             >>> p
-00013e60: 726f 6d70 7420 3d20 2249 6e20 4974 616c  rompt = "In Ital
-00013e70: 792c 2070 697a 7a61 2073 6572 7665 6420  y, pizza served 
-00013e80: 696e 2066 6f72 6d61 6c20 7365 7474 696e  in formal settin
-00013e90: 6773 2c20 7375 6368 2061 7320 6174 2061  gs, such as at a
-00013ea0: 2072 6573 7461 7572 616e 742c 2069 7320   restaurant, is 
-00013eb0: 7072 6573 656e 7465 6420 756e 736c 6963  presented unslic
-00013ec0: 6564 2e22 0a20 2020 2020 2020 2020 2020  ed.".           
-00013ed0: 203e 3e3e 206e 6578 745f 7365 6e74 656e   >>> next_senten
-00013ee0: 6365 203d 2022 5468 6520 736b 7920 6973  ce = "The sky is
-00013ef0: 2062 6c75 6520 6475 6520 746f 2074 6865   blue due to the
-00013f00: 2073 686f 7274 6572 2077 6176 656c 656e   shorter wavelen
-00013f10: 6774 6820 6f66 2062 6c75 6520 6c69 6768  gth of blue ligh
-00013f20: 742e 220a 2020 2020 2020 2020 2020 2020  t.".            
-00013f30: 3e3e 3e20 656e 636f 6469 6e67 203d 2074  >>> encoding = t
-00013f40: 6f6b 656e 697a 6572 2870 726f 6d70 742c  okenizer(prompt,
-00013f50: 206e 6578 745f 7365 6e74 656e 6365 2c20   next_sentence, 
-00013f60: 7265 7475 726e 5f74 656e 736f 7273 3d27  return_tensors='
-00013f70: 7074 2729 0a20 2020 2020 2020 2020 2020  pt').           
-00013f80: 203e 3e3e 206f 7574 7075 7473 203d 206d   >>> outputs = m
-00013f90: 6f64 656c 282a 2a65 6e63 6f64 696e 672c  odel(**encoding,
-00013fa0: 206c 6162 656c 733d 746f 7263 682e 4c6f   labels=torch.Lo
-00013fb0: 6e67 5465 6e73 6f72 285b 315d 2929 0a20  ngTensor([1])). 
-00013fc0: 2020 2020 2020 2020 2020 203e 3e3e 206c             >>> l
-00013fd0: 6f67 6974 7320 3d20 6f75 7470 7574 732e  ogits = outputs.
-00013fe0: 6c6f 6769 7473 0a20 2020 2020 2020 2020  logits.         
-00013ff0: 2020 203e 3e3e 2061 7373 6572 7420 6c6f     >>> assert lo
-00014000: 6769 7473 5b30 2c20 305d 203c 206c 6f67  gits[0, 0] < log
-00014010: 6974 735b 302c 2031 5d20 2320 6e65 7874  its[0, 1] # next
-00014020: 2073 656e 7465 6e63 6520 7761 7320 7261   sentence was ra
-00014030: 6e64 6f6d 0a20 2020 2020 2020 2022 2222  ndom.        """
-00014040: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00014050: 5f64 6963 7420 3d20 7265 7475 726e 5f64  _dict = return_d
-00014060: 6963 7420 6966 2072 6574 7572 6e5f 6469  ict if return_di
-00014070: 6374 2069 7320 6e6f 7420 4e6f 6e65 2065  ct is not None e
-00014080: 6c73 6520 7365 6c66 2e63 6f6e 6669 672e  lse self.config.
-00014090: 7573 655f 7265 7475 726e 5f64 6963 740a  use_return_dict.
-000140a0: 0a20 2020 2020 2020 206f 7574 7075 7473  .        outputs
-000140b0: 203d 2073 656c 662e 6265 7274 280a 2020   = self.bert(.  
-000140c0: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-000140d0: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
-000140e0: 2061 7474 656e 7469 6f6e 5f6d 6173 6b3d   attention_mask=
-000140f0: 6174 7465 6e74 696f 6e5f 6d61 736b 2c0a  attention_mask,.
-00014100: 2020 2020 2020 2020 2020 2020 746f 6b65              toke
-00014110: 6e5f 7479 7065 5f69 6473 3d74 6f6b 656e  n_type_ids=token
-00014120: 5f74 7970 655f 6964 732c 0a20 2020 2020  _type_ids,.     
-00014130: 2020 2020 2020 2070 6f73 6974 696f 6e5f         position_
-00014140: 6964 733d 706f 7369 7469 6f6e 5f69 6473  ids=position_ids
-00014150: 2c0a 2020 2020 2020 2020 2020 2020 6865  ,.            he
-00014160: 6164 5f6d 6173 6b3d 6865 6164 5f6d 6173  ad_mask=head_mas
-00014170: 6b2c 0a20 2020 2020 2020 2020 2020 2069  k,.            i
-00014180: 6e70 7574 735f 656d 6265 6473 3d69 6e70  nputs_embeds=inp
-00014190: 7574 735f 656d 6265 6473 2c0a 2020 2020  uts_embeds,.    
-000141a0: 2020 2020 2020 2020 6f75 7470 7574 5f61          output_a
-000141b0: 7474 656e 7469 6f6e 733d 6f75 7470 7574  ttentions=output
-000141c0: 5f61 7474 656e 7469 6f6e 732c 0a20 2020  _attentions,.   
-000141d0: 2020 2020 2020 2020 206f 7574 7075 745f           output_
-000141e0: 6869 6464 656e 5f73 7461 7465 733d 6f75  hidden_states=ou
-000141f0: 7470 7574 5f68 6964 6465 6e5f 7374 6174  tput_hidden_stat
-00014200: 6573 2c0a 2020 2020 2020 2020 2020 2020  es,.            
-00014210: 7265 7475 726e 5f64 6963 743d 7265 7475  return_dict=retu
-00014220: 726e 5f64 6963 742c 0a20 2020 2020 2020  rn_dict,.       
-00014230: 2029 0a0a 2020 2020 2020 2020 706f 6f6c   )..        pool
-00014240: 6564 5f6f 7574 7075 7420 3d20 6f75 7470  ed_output = outp
-00014250: 7574 735b 315d 0a0a 2020 2020 2020 2020  uts[1]..        
-00014260: 7365 715f 7265 6c61 7469 6f6e 7368 6970  seq_relationship
-00014270: 5f73 636f 7265 7320 3d20 7365 6c66 2e63  _scores = self.c
-00014280: 6c73 2870 6f6f 6c65 645f 6f75 7470 7574  ls(pooled_output
-00014290: 290a 0a20 2020 2020 2020 206e 6578 745f  )..        next_
-000142a0: 7365 6e74 656e 6365 5f6c 6f73 7320 3d20  sentence_loss = 
-000142b0: 4e6f 6e65 0a20 2020 2020 2020 2069 6620  None.        if 
-000142c0: 6c61 6265 6c73 2069 7320 6e6f 7420 4e6f  labels is not No
-000142d0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-000142e0: 6c6f 7373 5f66 6374 203d 2043 726f 7373  loss_fct = Cross
-000142f0: 456e 7472 6f70 794c 6f73 7328 290a 2020  EntropyLoss().  
-00014300: 2020 2020 2020 2020 2020 6e65 7874 5f73            next_s
-00014310: 656e 7465 6e63 655f 6c6f 7373 203d 206c  entence_loss = l
-00014320: 6f73 735f 6663 7428 0a20 2020 2020 2020  oss_fct(.       
-00014330: 2020 2020 2020 2020 2073 6571 5f72 656c           seq_rel
-00014340: 6174 696f 6e73 6869 705f 7363 6f72 6573  ationship_scores
-00014350: 2e76 6965 7728 2d31 2c20 3229 2c20 6c61  .view(-1, 2), la
-00014360: 6265 6c73 2e76 6965 7728 2d31 2929 0a0a  bels.view(-1))..
-00014370: 2020 2020 2020 2020 6966 206e 6f74 2072          if not r
-00014380: 6574 7572 6e5f 6469 6374 3a0a 2020 2020  eturn_dict:.    
-00014390: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-000143a0: 2028 7365 715f 7265 6c61 7469 6f6e 7368   (seq_relationsh
-000143b0: 6970 5f73 636f 7265 732c 2029 202b 206f  ip_scores, ) + o
-000143c0: 7574 7075 7473 5b32 3a5d 0a20 2020 2020  utputs[2:].     
-000143d0: 2020 2020 2020 2072 6574 7572 6e20 2828         return ((
-000143e0: 6e65 7874 5f73 656e 7465 6e63 655f 6c6f  next_sentence_lo
-000143f0: 7373 2c20 290a 2020 2020 2020 2020 2020  ss, ).          
-00014400: 2020 2020 2020 2020 2020 2b20 6f75 7470            + outp
-00014410: 7574 2920 6966 206e 6578 745f 7365 6e74  ut) if next_sent
-00014420: 656e 6365 5f6c 6f73 7320 6973 206e 6f74  ence_loss is not
-00014430: 204e 6f6e 6520 656c 7365 206f 7574 7075   None else outpu
-00014440: 740a 0a20 2020 2020 2020 2072 6574 7572  t..        retur
-00014450: 6e20 4e65 7874 5365 6e74 656e 6365 5072  n NextSentencePr
-00014460: 6564 6963 746f 724f 7574 7075 7428 0a20  edictorOutput(. 
-00014470: 2020 2020 2020 2020 2020 206c 6f73 733d             loss=
-00014480: 6e65 7874 5f73 656e 7465 6e63 655f 6c6f  next_sentence_lo
-00014490: 7373 2c0a 2020 2020 2020 2020 2020 2020  ss,.            
-000144a0: 6c6f 6769 7473 3d73 6571 5f72 656c 6174  logits=seq_relat
-000144b0: 696f 6e73 6869 705f 7363 6f72 6573 2c0a  ionship_scores,.
-000144c0: 2020 2020 2020 2020 2020 2020 6869 6464              hidd
-000144d0: 656e 5f73 7461 7465 733d 6f75 7470 7574  en_states=output
-000144e0: 732e 6869 6464 656e 5f73 7461 7465 732c  s.hidden_states,
-000144f0: 0a20 2020 2020 2020 2020 2020 2061 7474  .            att
-00014500: 656e 7469 6f6e 733d 6f75 7470 7574 732e  entions=outputs.
-00014510: 6174 7465 6e74 696f 6e73 2c0a 2020 2020  attentions,.    
-00014520: 2020 2020 290a 0a0a 636c 6173 7320 4265      )...class Be
-00014530: 7274 466f 7253 6571 7565 6e63 6543 6c61  rtForSequenceCla
-00014540: 7373 6966 6963 6174 696f 6e28 4265 7274  ssification(Bert
-00014550: 5072 6554 7261 696e 6564 4d6f 6465 6c29  PreTrainedModel)
-00014560: 3a0a 0a20 2020 2064 6566 205f 5f69 6e69  :..    def __ini
-00014570: 745f 5f28 7365 6c66 2c20 636f 6e66 6967  t__(self, config
-00014580: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
-00014590: 2829 2e5f 5f69 6e69 745f 5f28 636f 6e66  ().__init__(conf
-000145a0: 6967 290a 2020 2020 2020 2020 7365 6c66  ig).        self
-000145b0: 2e6e 756d 5f6c 6162 656c 7320 3d20 636f  .num_labels = co
-000145c0: 6e66 6967 2e6e 756d 5f6c 6162 656c 730a  nfig.num_labels.
-000145d0: 0a20 2020 2020 2020 2073 656c 662e 6265  .        self.be
-000145e0: 7274 203d 2042 6572 744d 6f64 656c 2863  rt = BertModel(c
-000145f0: 6f6e 6669 6729 0a20 2020 2020 2020 2073  onfig).        s
-00014600: 656c 662e 6472 6f70 6f75 7420 3d20 6e6e  elf.dropout = nn
-00014610: 2e44 726f 706f 7574 2863 6f6e 6669 672e  .Dropout(config.
-00014620: 6869 6464 656e 5f64 726f 706f 7574 5f70  hidden_dropout_p
-00014630: 726f 6229 0a20 2020 2020 2020 2073 656c  rob).        sel
-00014640: 662e 636c 6173 7369 6669 6572 203d 206e  f.classifier = n
-00014650: 6e2e 4c69 6e65 6172 2863 6f6e 6669 672e  n.Linear(config.
-00014660: 6869 6464 656e 5f73 697a 652c 2063 6f6e  hidden_size, con
-00014670: 6669 672e 6e75 6d5f 6c61 6265 6c73 290a  fig.num_labels).
-00014680: 0a20 2020 2020 2020 2073 656c 662e 696e  .        self.in
-00014690: 6974 5f77 6569 6768 7473 2829 0a0a 2020  it_weights()..  
-000146a0: 2020 6465 6620 666f 7277 6172 6428 0a20    def forward(. 
-000146b0: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-000146c0: 2020 2020 2069 6e70 7574 5f69 6473 3d4e       input_ids=N
-000146d0: 6f6e 652c 0a20 2020 2020 2020 2061 7474  one,.        att
-000146e0: 656e 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65  ention_mask=None
-000146f0: 2c0a 2020 2020 2020 2020 746f 6b65 6e5f  ,.        token_
-00014700: 7479 7065 5f69 6473 3d4e 6f6e 652c 0a20  type_ids=None,. 
-00014710: 2020 2020 2020 2070 6f73 6974 696f 6e5f         position_
-00014720: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
-00014730: 2020 6865 6164 5f6d 6173 6b3d 4e6f 6e65    head_mask=None
-00014740: 2c0a 2020 2020 2020 2020 696e 7075 7473  ,.        inputs
-00014750: 5f65 6d62 6564 733d 4e6f 6e65 2c0a 2020  _embeds=None,.  
-00014760: 2020 2020 2020 6c61 6265 6c73 3d4e 6f6e        labels=Non
-00014770: 652c 0a20 2020 2020 2020 206f 7574 7075  e,.        outpu
-00014780: 745f 6174 7465 6e74 696f 6e73 3d4e 6f6e  t_attentions=Non
-00014790: 652c 0a20 2020 2020 2020 206f 7574 7075  e,.        outpu
-000147a0: 745f 6869 6464 656e 5f73 7461 7465 733d  t_hidden_states=
-000147b0: 4e6f 6e65 2c0a 2020 2020 2020 2020 7265  None,.        re
-000147c0: 7475 726e 5f64 6963 743d 4e6f 6e65 2c0a  turn_dict=None,.
-000147d0: 2020 2020 293a 0a20 2020 2020 2020 2072      ):.        r
-000147e0: 2222 220a 2020 2020 2020 2020 6c61 6265  """.        labe
-000147f0: 6c73 2028 3a6f 626a 3a60 746f 7263 682e  ls (:obj:`torch.
-00014800: 4c6f 6e67 5465 6e73 6f72 6020 6f66 2073  LongTensor` of s
-00014810: 6861 7065 203a 6f62 6a3a 6028 6261 7463  hape :obj:`(batc
-00014820: 685f 7369 7a65 2c29 602c 2060 6f70 7469  h_size,)`, `opti
-00014830: 6f6e 616c 6029 3a0a 2020 2020 2020 2020  onal`):.        
-00014840: 2020 2020 4c61 6265 6c73 2066 6f72 2063      Labels for c
-00014850: 6f6d 7075 7469 6e67 2074 6865 2073 6571  omputing the seq
-00014860: 7565 6e63 6520 636c 6173 7369 6669 6361  uence classifica
-00014870: 7469 6f6e 2f72 6567 7265 7373 696f 6e20  tion/regression 
-00014880: 6c6f 7373 2e20 496e 6469 6365 7320 7368  loss. Indices sh
-00014890: 6f75 6c64 2062 6520 696e 203a 6f62 6a3a  ould be in :obj:
-000148a0: 605b 302c 202e 2e2e 2c0a 2020 2020 2020  `[0, ...,.      
-000148b0: 2020 2020 2020 636f 6e66 6967 2e6e 756d        config.num
-000148c0: 5f6c 6162 656c 7320 2d20 315d 602e 2049  _labels - 1]`. I
-000148d0: 6620 3a6f 626a 3a60 636f 6e66 6967 2e6e  f :obj:`config.n
-000148e0: 756d 5f6c 6162 656c 7320 3d3d 2031 6020  um_labels == 1` 
-000148f0: 6120 7265 6772 6573 7369 6f6e 206c 6f73  a regression los
-00014900: 7320 6973 2063 6f6d 7075 7465 6420 284d  s is computed (M
-00014910: 6561 6e2d 5371 7561 7265 206c 6f73 7329  ean-Square loss)
-00014920: 2c0a 2020 2020 2020 2020 2020 2020 4966  ,.            If
-00014930: 203a 6f62 6a3a 6063 6f6e 6669 672e 6e75   :obj:`config.nu
-00014940: 6d5f 6c61 6265 6c73 203e 2031 6020 6120  m_labels > 1` a 
-00014950: 636c 6173 7369 6669 6361 7469 6f6e 206c  classification l
-00014960: 6f73 7320 6973 2063 6f6d 7075 7465 6420  oss is computed 
-00014970: 2843 726f 7373 2d45 6e74 726f 7079 292e  (Cross-Entropy).
-00014980: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00014990: 2020 2020 2072 6574 7572 6e5f 6469 6374       return_dict
-000149a0: 203d 2072 6574 7572 6e5f 6469 6374 2069   = return_dict i
-000149b0: 6620 7265 7475 726e 5f64 6963 7420 6973  f return_dict is
-000149c0: 206e 6f74 204e 6f6e 6520 656c 7365 2073   not None else s
-000149d0: 656c 662e 636f 6e66 6967 2e75 7365 5f72  elf.config.use_r
-000149e0: 6574 7572 6e5f 6469 6374 0a0a 2020 2020  eturn_dict..    
-000149f0: 2020 2020 6f75 7470 7574 7320 3d20 7365      outputs = se
-00014a00: 6c66 2e62 6572 7428 0a20 2020 2020 2020  lf.bert(.       
-00014a10: 2020 2020 2069 6e70 7574 5f69 6473 2c0a       input_ids,.
-00014a20: 2020 2020 2020 2020 2020 2020 6174 7465              atte
-00014a30: 6e74 696f 6e5f 6d61 736b 3d61 7474 656e  ntion_mask=atten
-00014a40: 7469 6f6e 5f6d 6173 6b2c 0a20 2020 2020  tion_mask,.     
-00014a50: 2020 2020 2020 2074 6f6b 656e 5f74 7970         token_typ
-00014a60: 655f 6964 733d 746f 6b65 6e5f 7479 7065  e_ids=token_type
-00014a70: 5f69 6473 2c0a 2020 2020 2020 2020 2020  _ids,.          
-00014a80: 2020 706f 7369 7469 6f6e 5f69 6473 3d70    position_ids=p
-00014a90: 6f73 6974 696f 6e5f 6964 732c 0a20 2020  osition_ids,.   
-00014aa0: 2020 2020 2020 2020 2068 6561 645f 6d61           head_ma
-00014ab0: 736b 3d68 6561 645f 6d61 736b 2c0a 2020  sk=head_mask,.  
-00014ac0: 2020 2020 2020 2020 2020 696e 7075 7473            inputs
-00014ad0: 5f65 6d62 6564 733d 696e 7075 7473 5f65  _embeds=inputs_e
-00014ae0: 6d62 6564 732c 0a20 2020 2020 2020 2020  mbeds,.         
-00014af0: 2020 206f 7574 7075 745f 6174 7465 6e74     output_attent
-00014b00: 696f 6e73 3d6f 7574 7075 745f 6174 7465  ions=output_atte
-00014b10: 6e74 696f 6e73 2c0a 2020 2020 2020 2020  ntions,.        
-00014b20: 2020 2020 6f75 7470 7574 5f68 6964 6465      output_hidde
-00014b30: 6e5f 7374 6174 6573 3d6f 7574 7075 745f  n_states=output_
-00014b40: 6869 6464 656e 5f73 7461 7465 732c 0a20  hidden_states,. 
-00014b50: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00014b60: 6e5f 6469 6374 3d72 6574 7572 6e5f 6469  n_dict=return_di
-00014b70: 6374 2c0a 2020 2020 2020 2020 290a 0a20  ct,.        ).. 
-00014b80: 2020 2020 2020 2070 6f6f 6c65 645f 6f75         pooled_ou
-00014b90: 7470 7574 203d 206f 7574 7075 7473 5b31  tput = outputs[1
-00014ba0: 5d0a 0a20 2020 2020 2020 2070 6f6f 6c65  ]..        poole
-00014bb0: 645f 6f75 7470 7574 203d 2073 656c 662e  d_output = self.
-00014bc0: 6472 6f70 6f75 7428 706f 6f6c 6564 5f6f  dropout(pooled_o
-00014bd0: 7574 7075 7429 0a20 2020 2020 2020 206c  utput).        l
-00014be0: 6f67 6974 7320 3d20 7365 6c66 2e63 6c61  ogits = self.cla
-00014bf0: 7373 6966 6965 7228 706f 6f6c 6564 5f6f  ssifier(pooled_o
-00014c00: 7574 7075 7429 0a0a 2020 2020 2020 2020  utput)..        
-00014c10: 6c6f 7373 203d 204e 6f6e 650a 2020 2020  loss = None.    
-00014c20: 2020 2020 6966 206c 6162 656c 7320 6973      if labels is
-00014c30: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
-00014c40: 2020 2020 2020 2069 6620 7365 6c66 2e6e         if self.n
-00014c50: 756d 5f6c 6162 656c 7320 3d3d 2031 3a0a  um_labels == 1:.
-00014c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014c70: 2320 2057 6520 6172 6520 646f 696e 6720  #  We are doing 
-00014c80: 7265 6772 6573 7369 6f6e 0a20 2020 2020  regression.     
-00014c90: 2020 2020 2020 2020 2020 206c 6f73 735f             loss_
-00014ca0: 6663 7420 3d20 4d53 454c 6f73 7328 290a  fct = MSELoss().
-00014cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014cc0: 6c6f 7373 203d 206c 6f73 735f 6663 7428  loss = loss_fct(
-00014cd0: 6c6f 6769 7473 2e76 6965 7728 2d31 292c  logits.view(-1),
-00014ce0: 206c 6162 656c 732e 7669 6577 282d 3129   labels.view(-1)
-00014cf0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-00014d00: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00014d10: 2020 2020 6c6f 7373 5f66 6374 203d 2043      loss_fct = C
-00014d20: 726f 7373 456e 7472 6f70 794c 6f73 7328  rossEntropyLoss(
-00014d30: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00014d40: 2020 6c6f 7373 203d 206c 6f73 735f 6663    loss = loss_fc
-00014d50: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-00014d60: 2020 2020 2020 206c 6f67 6974 732e 7669         logits.vi
-00014d70: 6577 282d 312c 2073 656c 662e 6e75 6d5f  ew(-1, self.num_
-00014d80: 6c61 6265 6c73 292c 206c 6162 656c 732e  labels), labels.
-00014d90: 7669 6577 282d 3129 290a 0a20 2020 2020  view(-1))..     
-00014da0: 2020 2069 6620 6e6f 7420 7265 7475 726e     if not return
-00014db0: 5f64 6963 743a 0a20 2020 2020 2020 2020  _dict:.         
-00014dc0: 2020 206f 7574 7075 7420 3d20 286c 6f67     output = (log
-00014dd0: 6974 732c 2029 202b 206f 7574 7075 7473  its, ) + outputs
-00014de0: 5b32 3a5d 0a20 2020 2020 2020 2020 2020  [2:].           
-00014df0: 2072 6574 7572 6e20 2828 6c6f 7373 2c20   return ((loss, 
-00014e00: 2920 2b20 6f75 7470 7574 2920 6966 206c  ) + output) if l
-00014e10: 6f73 7320 6973 206e 6f74 204e 6f6e 6520  oss is not None 
-00014e20: 656c 7365 206f 7574 7075 740a 0a20 2020  else output..   
-00014e30: 2020 2020 2072 6574 7572 6e20 5365 7175       return Sequ
-00014e40: 656e 6365 436c 6173 7369 6669 6572 4f75  enceClassifierOu
-00014e50: 7470 7574 280a 2020 2020 2020 2020 2020  tput(.          
-00014e60: 2020 6c6f 7373 3d6c 6f73 732c 0a20 2020    loss=loss,.   
-00014e70: 2020 2020 2020 2020 206c 6f67 6974 733d           logits=
-00014e80: 6c6f 6769 7473 2c0a 2020 2020 2020 2020  logits,.        
-00014e90: 2020 2020 6869 6464 656e 5f73 7461 7465      hidden_state
-00014ea0: 733d 6f75 7470 7574 732e 6869 6464 656e  s=outputs.hidden
-00014eb0: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
-00014ec0: 2020 2020 2061 7474 656e 7469 6f6e 733d       attentions=
-00014ed0: 6f75 7470 7574 732e 6174 7465 6e74 696f  outputs.attentio
-00014ee0: 6e73 2c0a 2020 2020 2020 2020 290a 0a0a  ns,.        )...
-00014ef0: 636c 6173 7320 4265 7274 466f 724d 756c  class BertForMul
-00014f00: 7469 706c 6543 686f 6963 6528 4265 7274  tipleChoice(Bert
-00014f10: 5072 6554 7261 696e 6564 4d6f 6465 6c29  PreTrainedModel)
-00014f20: 3a0a 0a20 2020 2064 6566 205f 5f69 6e69  :..    def __ini
-00014f30: 745f 5f28 7365 6c66 2c20 636f 6e66 6967  t__(self, config
-00014f40: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
-00014f50: 2829 2e5f 5f69 6e69 745f 5f28 636f 6e66  ().__init__(conf
-00014f60: 6967 290a 0a20 2020 2020 2020 2073 656c  ig)..        sel
-00014f70: 662e 6265 7274 203d 2042 6572 744d 6f64  f.bert = BertMod
-00014f80: 656c 2863 6f6e 6669 6729 0a20 2020 2020  el(config).     
-00014f90: 2020 2073 656c 662e 6472 6f70 6f75 7420     self.dropout 
-00014fa0: 3d20 6e6e 2e44 726f 706f 7574 2863 6f6e  = nn.Dropout(con
-00014fb0: 6669 672e 6869 6464 656e 5f64 726f 706f  fig.hidden_dropo
-00014fc0: 7574 5f70 726f 6229 0a20 2020 2020 2020  ut_prob).       
-00014fd0: 2073 656c 662e 636c 6173 7369 6669 6572   self.classifier
-00014fe0: 203d 206e 6e2e 4c69 6e65 6172 2863 6f6e   = nn.Linear(con
-00014ff0: 6669 672e 6869 6464 656e 5f73 697a 652c  fig.hidden_size,
-00015000: 2031 290a 0a20 2020 2020 2020 2073 656c   1)..        sel
-00015010: 662e 696e 6974 5f77 6569 6768 7473 2829  f.init_weights()
-00015020: 0a0a 2020 2020 6465 6620 666f 7277 6172  ..    def forwar
-00015030: 6428 0a20 2020 2020 2020 2073 656c 662c  d(.        self,
-00015040: 0a20 2020 2020 2020 2069 6e70 7574 5f69  .        input_i
-00015050: 6473 3d4e 6f6e 652c 0a20 2020 2020 2020  ds=None,.       
-00015060: 2061 7474 656e 7469 6f6e 5f6d 6173 6b3d   attention_mask=
-00015070: 4e6f 6e65 2c0a 2020 2020 2020 2020 746f  None,.        to
-00015080: 6b65 6e5f 7479 7065 5f69 6473 3d4e 6f6e  ken_type_ids=Non
-00015090: 652c 0a20 2020 2020 2020 2070 6f73 6974  e,.        posit
-000150a0: 696f 6e5f 6964 733d 4e6f 6e65 2c0a 2020  ion_ids=None,.  
-000150b0: 2020 2020 2020 6865 6164 5f6d 6173 6b3d        head_mask=
-000150c0: 4e6f 6e65 2c0a 2020 2020 2020 2020 696e  None,.        in
-000150d0: 7075 7473 5f65 6d62 6564 733d 4e6f 6e65  puts_embeds=None
-000150e0: 2c0a 2020 2020 2020 2020 6c61 6265 6c73  ,.        labels
-000150f0: 3d4e 6f6e 652c 0a20 2020 2020 2020 206f  =None,.        o
-00015100: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
-00015110: 3d4e 6f6e 652c 0a20 2020 2020 2020 206f  =None,.        o
-00015120: 7574 7075 745f 6869 6464 656e 5f73 7461  utput_hidden_sta
-00015130: 7465 733d 4e6f 6e65 2c0a 2020 2020 2020  tes=None,.      
-00015140: 2020 7265 7475 726e 5f64 6963 743d 4e6f    return_dict=No
-00015150: 6e65 2c0a 2020 2020 293a 0a20 2020 2020  ne,.    ):.     
-00015160: 2020 2072 2222 220a 2020 2020 2020 2020     r""".        
-00015170: 6c61 6265 6c73 2028 3a6f 626a 3a60 746f  labels (:obj:`to
-00015180: 7263 682e 4c6f 6e67 5465 6e73 6f72 6020  rch.LongTensor` 
-00015190: 6f66 2073 6861 7065 203a 6f62 6a3a 6028  of shape :obj:`(
-000151a0: 6261 7463 685f 7369 7a65 2c29 602c 0a20  batch_size,)`,. 
-000151b0: 2020 2020 2020 2060 6f70 7469 6f6e 616c         `optional
-000151c0: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
-000151d0: 4c61 6265 6c73 2066 6f72 2063 6f6d 7075  Labels for compu
-000151e0: 7469 6e67 2074 6865 206d 756c 7469 706c  ting the multipl
-000151f0: 6520 6368 6f69 6365 2063 6c61 7373 6966  e choice classif
-00015200: 6963 6174 696f 6e20 6c6f 7373 2e0a 2020  ication loss..  
-00015210: 2020 2020 2020 2020 2020 496e 6469 6365            Indice
-00015220: 7320 7368 6f75 6c64 2062 6520 696e 2060  s should be in `
-00015230: 605b 302c 202e 2e2e 2c20 6e75 6d5f 6368  `[0, ..., num_ch
-00015240: 6f69 6365 732d 315d 6060 2077 6865 7265  oices-1]`` where
-00015250: 0a20 2020 2020 2020 2020 2020 203a 6f62  .            :ob
-00015260: 6a3a 606e 756d 5f63 686f 6963 6573 6020  j:`num_choices` 
-00015270: 6973 2074 6865 2073 697a 6520 6f66 2074  is the size of t
-00015280: 6865 2073 6563 6f6e 6420 6469 6d65 6e73  he second dimens
-00015290: 696f 6e20 6f66 2074 6865 2069 6e70 7574  ion of the input
-000152a0: 0a20 2020 2020 2020 2020 2020 2074 656e  .            ten
-000152b0: 736f 7273 2e20 2853 6565 203a 6f62 6a3a  sors. (See :obj:
-000152c0: 6069 6e70 7574 5f69 6473 6020 6162 6f76  `input_ids` abov
-000152d0: 6529 0a20 2020 2020 2020 2022 2222 0a20  e).        """. 
-000152e0: 2020 2020 2020 2072 6574 7572 6e5f 6469         return_di
-000152f0: 6374 203d 2072 6574 7572 6e5f 6469 6374  ct = return_dict
-00015300: 2069 6620 7265 7475 726e 5f64 6963 7420   if return_dict 
-00015310: 6973 206e 6f74 204e 6f6e 6520 656c 7365  is not None else
-00015320: 2073 656c 662e 636f 6e66 6967 2e75 7365   self.config.use
-00015330: 5f72 6574 7572 6e5f 6469 6374 0a20 2020  _return_dict.   
-00015340: 2020 2020 206e 756d 5f63 686f 6963 6573       num_choices
-00015350: 203d 2069 6e70 7574 5f69 6473 2e73 6861   = input_ids.sha
-00015360: 7065 5b0a 2020 2020 2020 2020 2020 2020  pe[.            
-00015370: 315d 2069 6620 696e 7075 745f 6964 7320  1] if input_ids 
-00015380: 6973 206e 6f74 204e 6f6e 6520 656c 7365  is not None else
-00015390: 2069 6e70 7574 735f 656d 6265 6473 2e73   inputs_embeds.s
-000153a0: 6861 7065 5b31 5d0a 0a20 2020 2020 2020  hape[1]..       
-000153b0: 2069 6e70 7574 5f69 6473 203d 2069 6e70   input_ids = inp
-000153c0: 7574 5f69 6473 2e76 6965 7728 0a20 2020  ut_ids.view(.   
-000153d0: 2020 2020 2020 2020 202d 312c 2069 6e70           -1, inp
-000153e0: 7574 5f69 6473 2e73 697a 6528 2d31 2929  ut_ids.size(-1))
-000153f0: 2069 6620 696e 7075 745f 6964 7320 6973   if input_ids is
-00015400: 206e 6f74 204e 6f6e 6520 656c 7365 204e   not None else N
-00015410: 6f6e 650a 2020 2020 2020 2020 6174 7465  one.        atte
-00015420: 6e74 696f 6e5f 6d61 736b 203d 2061 7474  ntion_mask = att
-00015430: 656e 7469 6f6e 5f6d 6173 6b2e 7669 6577  ention_mask.view
-00015440: 280a 2020 2020 2020 2020 2020 2020 2d31  (.            -1
-00015450: 2c0a 2020 2020 2020 2020 2020 2020 6174  ,.            at
-00015460: 7465 6e74 696f 6e5f 6d61 736b 2e73 697a  tention_mask.siz
-00015470: 6528 2d31 2929 2069 6620 6174 7465 6e74  e(-1)) if attent
-00015480: 696f 6e5f 6d61 736b 2069 7320 6e6f 7420  ion_mask is not 
-00015490: 4e6f 6e65 2065 6c73 6520 4e6f 6e65 0a20  None else None. 
-000154a0: 2020 2020 2020 2074 6f6b 656e 5f74 7970         token_typ
-000154b0: 655f 6964 7320 3d20 746f 6b65 6e5f 7479  e_ids = token_ty
-000154c0: 7065 5f69 6473 2e76 6965 7728 0a20 2020  pe_ids.view(.   
-000154d0: 2020 2020 2020 2020 202d 312c 0a20 2020           -1,.   
-000154e0: 2020 2020 2020 2020 2074 6f6b 656e 5f74           token_t
-000154f0: 7970 655f 6964 732e 7369 7a65 282d 3129  ype_ids.size(-1)
-00015500: 2920 6966 2074 6f6b 656e 5f74 7970 655f  ) if token_type_
-00015510: 6964 7320 6973 206e 6f74 204e 6f6e 6520  ids is not None 
-00015520: 656c 7365 204e 6f6e 650a 2020 2020 2020  else None.      
-00015530: 2020 706f 7369 7469 6f6e 5f69 6473 203d    position_ids =
-00015540: 2070 6f73 6974 696f 6e5f 6964 732e 7669   position_ids.vi
-00015550: 6577 280a 2020 2020 2020 2020 2020 2020  ew(.            
-00015560: 2d31 2c20 706f 7369 7469 6f6e 5f69 6473  -1, position_ids
-00015570: 2e73 697a 6528 2d31 2929 2069 6620 706f  .size(-1)) if po
-00015580: 7369 7469 6f6e 5f69 6473 2069 7320 6e6f  sition_ids is no
-00015590: 7420 4e6f 6e65 2065 6c73 6520 4e6f 6e65  t None else None
-000155a0: 0a20 2020 2020 2020 2069 6e70 7574 735f  .        inputs_
-000155b0: 656d 6265 6473 203d 2028 0a20 2020 2020  embeds = (.     
-000155c0: 2020 2020 2020 2069 6e70 7574 735f 656d         inputs_em
-000155d0: 6265 6473 2e76 6965 7728 2d31 2c20 696e  beds.view(-1, in
-000155e0: 7075 7473 5f65 6d62 6564 732e 7369 7a65  puts_embeds.size
-000155f0: 282d 3229 2c0a 2020 2020 2020 2020 2020  (-2),.          
-00015600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015610: 2020 2020 2069 6e70 7574 735f 656d 6265       inputs_embe
-00015620: 6473 2e73 697a 6528 2d31 2929 0a20 2020  ds.size(-1)).   
-00015630: 2020 2020 2020 2020 2069 6620 696e 7075           if inpu
-00015640: 7473 5f65 6d62 6564 7320 6973 206e 6f74  ts_embeds is not
-00015650: 204e 6f6e 6520 656c 7365 204e 6f6e 6529   None else None)
-00015660: 0a0a 2020 2020 2020 2020 6f75 7470 7574  ..        output
-00015670: 7320 3d20 7365 6c66 2e62 6572 7428 0a20  s = self.bert(. 
-00015680: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00015690: 5f69 6473 2c0a 2020 2020 2020 2020 2020  _ids,.          
-000156a0: 2020 6174 7465 6e74 696f 6e5f 6d61 736b    attention_mask
-000156b0: 3d61 7474 656e 7469 6f6e 5f6d 6173 6b2c  =attention_mask,
-000156c0: 0a20 2020 2020 2020 2020 2020 2074 6f6b  .            tok
-000156d0: 656e 5f74 7970 655f 6964 733d 746f 6b65  en_type_ids=toke
-000156e0: 6e5f 7479 7065 5f69 6473 2c0a 2020 2020  n_type_ids,.    
-000156f0: 2020 2020 2020 2020 706f 7369 7469 6f6e          position
-00015700: 5f69 6473 3d70 6f73 6974 696f 6e5f 6964  _ids=position_id
-00015710: 732c 0a20 2020 2020 2020 2020 2020 2068  s,.            h
-00015720: 6561 645f 6d61 736b 3d68 6561 645f 6d61  ead_mask=head_ma
-00015730: 736b 2c0a 2020 2020 2020 2020 2020 2020  sk,.            
-00015740: 696e 7075 7473 5f65 6d62 6564 733d 696e  inputs_embeds=in
-00015750: 7075 7473 5f65 6d62 6564 732c 0a20 2020  puts_embeds,.   
-00015760: 2020 2020 2020 2020 206f 7574 7075 745f           output_
-00015770: 6174 7465 6e74 696f 6e73 3d6f 7574 7075  attentions=outpu
-00015780: 745f 6174 7465 6e74 696f 6e73 2c0a 2020  t_attentions,.  
-00015790: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-000157a0: 5f68 6964 6465 6e5f 7374 6174 6573 3d6f  _hidden_states=o
-000157b0: 7574 7075 745f 6869 6464 656e 5f73 7461  utput_hidden_sta
-000157c0: 7465 732c 0a20 2020 2020 2020 2020 2020  tes,.           
-000157d0: 2072 6574 7572 6e5f 6469 6374 3d72 6574   return_dict=ret
-000157e0: 7572 6e5f 6469 6374 2c0a 2020 2020 2020  urn_dict,.      
-000157f0: 2020 290a 0a20 2020 2020 2020 2070 6f6f    )..        poo
-00015800: 6c65 645f 6f75 7470 7574 203d 206f 7574  led_output = out
-00015810: 7075 7473 5b31 5d0a 0a20 2020 2020 2020  puts[1]..       
-00015820: 2070 6f6f 6c65 645f 6f75 7470 7574 203d   pooled_output =
-00015830: 2073 656c 662e 6472 6f70 6f75 7428 706f   self.dropout(po
-00015840: 6f6c 6564 5f6f 7574 7075 7429 0a20 2020  oled_output).   
-00015850: 2020 2020 206c 6f67 6974 7320 3d20 7365       logits = se
-00015860: 6c66 2e63 6c61 7373 6966 6965 7228 706f  lf.classifier(po
-00015870: 6f6c 6564 5f6f 7574 7075 7429 0a20 2020  oled_output).   
-00015880: 2020 2020 2072 6573 6861 7065 645f 6c6f       reshaped_lo
-00015890: 6769 7473 203d 206c 6f67 6974 732e 7669  gits = logits.vi
-000158a0: 6577 282d 312c 206e 756d 5f63 686f 6963  ew(-1, num_choic
-000158b0: 6573 290a 0a20 2020 2020 2020 206c 6f73  es)..        los
-000158c0: 7320 3d20 4e6f 6e65 0a20 2020 2020 2020  s = None.       
-000158d0: 2069 6620 6c61 6265 6c73 2069 7320 6e6f   if labels is no
-000158e0: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-000158f0: 2020 2020 6c6f 7373 5f66 6374 203d 2043      loss_fct = C
-00015900: 726f 7373 456e 7472 6f70 794c 6f73 7328  rossEntropyLoss(
-00015910: 290a 2020 2020 2020 2020 2020 2020 6c6f  ).            lo
-00015920: 7373 203d 206c 6f73 735f 6663 7428 7265  ss = loss_fct(re
-00015930: 7368 6170 6564 5f6c 6f67 6974 732c 206c  shaped_logits, l
-00015940: 6162 656c 7329 0a0a 2020 2020 2020 2020  abels)..        
-00015950: 6966 206e 6f74 2072 6574 7572 6e5f 6469  if not return_di
-00015960: 6374 3a0a 2020 2020 2020 2020 2020 2020  ct:.            
-00015970: 6f75 7470 7574 203d 2028 7265 7368 6170  output = (reshap
-00015980: 6564 5f6c 6f67 6974 732c 2029 202b 206f  ed_logits, ) + o
-00015990: 7574 7075 7473 5b32 3a5d 0a20 2020 2020  utputs[2:].     
-000159a0: 2020 2020 2020 2072 6574 7572 6e20 2828         return ((
-000159b0: 6c6f 7373 2c20 2920 2b20 6f75 7470 7574  loss, ) + output
-000159c0: 2920 6966 206c 6f73 7320 6973 206e 6f74  ) if loss is not
-000159d0: 204e 6f6e 6520 656c 7365 206f 7574 7075   None else outpu
-000159e0: 740a 0a20 2020 2020 2020 2072 6574 7572  t..        retur
-000159f0: 6e20 4d75 6c74 6970 6c65 4368 6f69 6365  n MultipleChoice
-00015a00: 4d6f 6465 6c4f 7574 7075 7428 0a20 2020  ModelOutput(.   
-00015a10: 2020 2020 2020 2020 206c 6f73 733d 6c6f           loss=lo
-00015a20: 7373 2c0a 2020 2020 2020 2020 2020 2020  ss,.            
-00015a30: 6c6f 6769 7473 3d72 6573 6861 7065 645f  logits=reshaped_
-00015a40: 6c6f 6769 7473 2c0a 2020 2020 2020 2020  logits,.        
-00015a50: 2020 2020 6869 6464 656e 5f73 7461 7465      hidden_state
-00015a60: 733d 6f75 7470 7574 732e 6869 6464 656e  s=outputs.hidden
-00015a70: 5f73 7461 7465 732c 0a20 2020 2020 2020  _states,.       
-00015a80: 2020 2020 2061 7474 656e 7469 6f6e 733d       attentions=
-00015a90: 6f75 7470 7574 732e 6174 7465 6e74 696f  outputs.attentio
-00015aa0: 6e73 2c0a 2020 2020 2020 2020 290a 0a0a  ns,.        )...
-00015ab0: 636c 6173 7320 4265 7274 466f 7254 6f6b  class BertForTok
-00015ac0: 656e 436c 6173 7369 6669 6361 7469 6f6e  enClassification
-00015ad0: 2842 6572 7450 7265 5472 6169 6e65 644d  (BertPreTrainedM
-00015ae0: 6f64 656c 293a 0a0a 2020 2020 5f6b 6579  odel):..    _key
-00015af0: 735f 746f 5f69 676e 6f72 655f 6f6e 5f6c  s_to_ignore_on_l
-00015b00: 6f61 645f 756e 6578 7065 6374 6564 203d  oad_unexpected =
-00015b10: 205b 7227 706f 6f6c 6572 275d 0a0a 2020   [r'pooler']..  
-00015b20: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-00015b30: 656c 662c 2063 6f6e 6669 6729 3a0a 2020  elf, config):.  
-00015b40: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
-00015b50: 696e 6974 5f5f 2863 6f6e 6669 6729 0a20  init__(config). 
-00015b60: 2020 2020 2020 2073 656c 662e 6e75 6d5f         self.num_
-00015b70: 6c61 6265 6c73 203d 2063 6f6e 6669 672e  labels = config.
-00015b80: 6e75 6d5f 6c61 6265 6c73 0a0a 2020 2020  num_labels..    
-00015b90: 2020 2020 7365 6c66 2e62 6572 7420 3d20      self.bert = 
-00015ba0: 4265 7274 4d6f 6465 6c28 636f 6e66 6967  BertModel(config
-00015bb0: 2c20 6164 645f 706f 6f6c 696e 675f 6c61  , add_pooling_la
-00015bc0: 7965 723d 4661 6c73 6529 0a20 2020 2020  yer=False).     
-00015bd0: 2020 2073 656c 662e 6472 6f70 6f75 7420     self.dropout 
-00015be0: 3d20 6e6e 2e44 726f 706f 7574 2863 6f6e  = nn.Dropout(con
-00015bf0: 6669 672e 6869 6464 656e 5f64 726f 706f  fig.hidden_dropo
-00015c00: 7574 5f70 726f 6229 0a20 2020 2020 2020  ut_prob).       
-00015c10: 2073 656c 662e 636c 6173 7369 6669 6572   self.classifier
-00015c20: 203d 206e 6e2e 4c69 6e65 6172 2863 6f6e   = nn.Linear(con
-00015c30: 6669 672e 6869 6464 656e 5f73 697a 652c  fig.hidden_size,
-00015c40: 2063 6f6e 6669 672e 6e75 6d5f 6c61 6265   config.num_labe
-00015c50: 6c73 290a 0a20 2020 2020 2020 2073 656c  ls)..        sel
-00015c60: 662e 696e 6974 5f77 6569 6768 7473 2829  f.init_weights()
-00015c70: 0a0a 2020 2020 6465 6620 666f 7277 6172  ..    def forwar
-00015c80: 6428 0a20 2020 2020 2020 2073 656c 662c  d(.        self,
-00015c90: 0a20 2020 2020 2020 2069 6e70 7574 5f69  .        input_i
-00015ca0: 6473 3d4e 6f6e 652c 0a20 2020 2020 2020  ds=None,.       
-00015cb0: 2061 7474 656e 7469 6f6e 5f6d 6173 6b3d   attention_mask=
-00015cc0: 4e6f 6e65 2c0a 2020 2020 2020 2020 746f  None,.        to
-00015cd0: 6b65 6e5f 7479 7065 5f69 6473 3d4e 6f6e  ken_type_ids=Non
-00015ce0: 652c 0a20 2020 2020 2020 2070 6f73 6974  e,.        posit
-00015cf0: 696f 6e5f 6964 733d 4e6f 6e65 2c0a 2020  ion_ids=None,.  
-00015d00: 2020 2020 2020 6865 6164 5f6d 6173 6b3d        head_mask=
-00015d10: 4e6f 6e65 2c0a 2020 2020 2020 2020 696e  None,.        in
-00015d20: 7075 7473 5f65 6d62 6564 733d 4e6f 6e65  puts_embeds=None
-00015d30: 2c0a 2020 2020 2020 2020 6c61 6265 6c73  ,.        labels
-00015d40: 3d4e 6f6e 652c 0a20 2020 2020 2020 206f  =None,.        o
-00015d50: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
-00015d60: 3d4e 6f6e 652c 0a20 2020 2020 2020 206f  =None,.        o
-00015d70: 7574 7075 745f 6869 6464 656e 5f73 7461  utput_hidden_sta
-00015d80: 7465 733d 4e6f 6e65 2c0a 2020 2020 2020  tes=None,.      
-00015d90: 2020 7265 7475 726e 5f64 6963 743d 4e6f    return_dict=No
-00015da0: 6e65 2c0a 2020 2020 293a 0a20 2020 2020  ne,.    ):.     
-00015db0: 2020 2072 2222 220a 2020 2020 2020 2020     r""".        
-00015dc0: 6c61 6265 6c73 2028 3a6f 626a 3a60 746f  labels (:obj:`to
-00015dd0: 7263 682e 4c6f 6e67 5465 6e73 6f72 6020  rch.LongTensor` 
-00015de0: 6f66 2073 6861 7065 203a 6f62 6a3a 6028  of shape :obj:`(
-00015df0: 6261 7463 685f 7369 7a65 2c0a 2020 2020  batch_size,.    
-00015e00: 2020 2020 7365 7175 656e 6365 5f6c 656e      sequence_len
-00015e10: 6774 6829 602c 2060 6f70 7469 6f6e 616c  gth)`, `optional
-00015e20: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
-00015e30: 4c61 6265 6c73 2066 6f72 2063 6f6d 7075  Labels for compu
-00015e40: 7469 6e67 2074 6865 2074 6f6b 656e 2063  ting the token c
-00015e50: 6c61 7373 6966 6963 6174 696f 6e20 6c6f  lassification lo
-00015e60: 7373 2e20 496e 6469 6365 7320 7368 6f75  ss. Indices shou
-00015e70: 6c64 0a20 2020 2020 2020 2020 2020 2062  ld.            b
-00015e80: 6520 696e 2060 605b 302c 202e 2e2e 2c20  e in ``[0, ..., 
-00015e90: 636f 6e66 6967 2e6e 756d 5f6c 6162 656c  config.num_label
-00015ea0: 7320 2d20 315d 6060 2e0a 2020 2020 2020  s - 1]``..      
-00015eb0: 2020 2222 220a 2020 2020 2020 2020 7265    """.        re
-00015ec0: 7475 726e 5f64 6963 7420 3d20 7265 7475  turn_dict = retu
-00015ed0: 726e 5f64 6963 7420 6966 2072 6574 7572  rn_dict if retur
-00015ee0: 6e5f 6469 6374 2069 7320 6e6f 7420 4e6f  n_dict is not No
-00015ef0: 6e65 2065 6c73 6520 7365 6c66 2e63 6f6e  ne else self.con
-00015f00: 6669 672e 7573 655f 7265 7475 726e 5f64  fig.use_return_d
-00015f10: 6963 740a 0a20 2020 2020 2020 206f 7574  ict..        out
-00015f20: 7075 7473 203d 2073 656c 662e 6265 7274  puts = self.bert
-00015f30: 280a 2020 2020 2020 2020 2020 2020 696e  (.            in
-00015f40: 7075 745f 6964 732c 0a20 2020 2020 2020  put_ids,.       
-00015f50: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
-00015f60: 6173 6b3d 6174 7465 6e74 696f 6e5f 6d61  ask=attention_ma
-00015f70: 736b 2c0a 2020 2020 2020 2020 2020 2020  sk,.            
-00015f80: 746f 6b65 6e5f 7479 7065 5f69 6473 3d74  token_type_ids=t
-00015f90: 6f6b 656e 5f74 7970 655f 6964 732c 0a20  oken_type_ids,. 
-00015fa0: 2020 2020 2020 2020 2020 2070 6f73 6974             posit
-00015fb0: 696f 6e5f 6964 733d 706f 7369 7469 6f6e  ion_ids=position
-00015fc0: 5f69 6473 2c0a 2020 2020 2020 2020 2020  _ids,.          
-00015fd0: 2020 6865 6164 5f6d 6173 6b3d 6865 6164    head_mask=head
-00015fe0: 5f6d 6173 6b2c 0a20 2020 2020 2020 2020  _mask,.         
-00015ff0: 2020 2069 6e70 7574 735f 656d 6265 6473     inputs_embeds
-00016000: 3d69 6e70 7574 735f 656d 6265 6473 2c0a  =inputs_embeds,.
-00016010: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00016020: 7574 5f61 7474 656e 7469 6f6e 733d 6f75  ut_attentions=ou
-00016030: 7470 7574 5f61 7474 656e 7469 6f6e 732c  tput_attentions,
-00016040: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00016050: 7075 745f 6869 6464 656e 5f73 7461 7465  put_hidden_state
-00016060: 733d 6f75 7470 7574 5f68 6964 6465 6e5f  s=output_hidden_
-00016070: 7374 6174 6573 2c0a 2020 2020 2020 2020  states,.        
-00016080: 2020 2020 7265 7475 726e 5f64 6963 743d      return_dict=
-00016090: 7265 7475 726e 5f64 6963 742c 0a20 2020  return_dict,.   
-000160a0: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
-000160b0: 7365 7175 656e 6365 5f6f 7574 7075 7420  sequence_output 
-000160c0: 3d20 6f75 7470 7574 735b 305d 0a0a 2020  = outputs[0]..  
-000160d0: 2020 2020 2020 7365 7175 656e 6365 5f6f        sequence_o
-000160e0: 7574 7075 7420 3d20 7365 6c66 2e64 726f  utput = self.dro
-000160f0: 706f 7574 2873 6571 7565 6e63 655f 6f75  pout(sequence_ou
-00016100: 7470 7574 290a 2020 2020 2020 2020 6c6f  tput).        lo
-00016110: 6769 7473 203d 2073 656c 662e 636c 6173  gits = self.clas
-00016120: 7369 6669 6572 2873 6571 7565 6e63 655f  sifier(sequence_
-00016130: 6f75 7470 7574 290a 0a20 2020 2020 2020  output)..       
-00016140: 206c 6f73 7320 3d20 4e6f 6e65 0a20 2020   loss = None.   
-00016150: 2020 2020 2069 6620 6c61 6265 6c73 2069       if labels i
-00016160: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
-00016170: 2020 2020 2020 2020 6c6f 7373 5f66 6374          loss_fct
-00016180: 203d 2043 726f 7373 456e 7472 6f70 794c   = CrossEntropyL
-00016190: 6f73 7328 290a 2020 2020 2020 2020 2020  oss().          
-000161a0: 2020 2320 4f6e 6c79 206b 6565 7020 6163    # Only keep ac
-000161b0: 7469 7665 2070 6172 7473 206f 6620 7468  tive parts of th
-000161c0: 6520 6c6f 7373 0a20 2020 2020 2020 2020  e loss.         
-000161d0: 2020 2069 6620 6174 7465 6e74 696f 6e5f     if attention_
-000161e0: 6d61 736b 2069 7320 6e6f 7420 4e6f 6e65  mask is not None
-000161f0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00016200: 2020 6163 7469 7665 5f6c 6f73 7320 3d20    active_loss = 
-00016210: 6174 7465 6e74 696f 6e5f 6d61 736b 2e76  attention_mask.v
-00016220: 6965 7728 2d31 2920 3d3d 2031 0a20 2020  iew(-1) == 1.   
-00016230: 2020 2020 2020 2020 2020 2020 2061 6374               act
-00016240: 6976 655f 6c6f 6769 7473 203d 206c 6f67  ive_logits = log
-00016250: 6974 732e 7669 6577 282d 312c 2073 656c  its.view(-1, sel
-00016260: 662e 6e75 6d5f 6c61 6265 6c73 290a 2020  f.num_labels).  
-00016270: 2020 2020 2020 2020 2020 2020 2020 6163                ac
-00016280: 7469 7665 5f6c 6162 656c 7320 3d20 746f  tive_labels = to
-00016290: 7263 682e 7768 6572 6528 0a20 2020 2020  rch.where(.     
-000162a0: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-000162b0: 6374 6976 655f 6c6f 7373 2c20 6c61 6265  ctive_loss, labe
-000162c0: 6c73 2e76 6965 7728 2d31 292c 0a20 2020  ls.view(-1),.   
-000162d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000162e0: 2074 6f72 6368 2e74 656e 736f 7228 6c6f   torch.tensor(lo
-000162f0: 7373 5f66 6374 2e69 676e 6f72 655f 696e  ss_fct.ignore_in
-00016300: 6465 7829 2e74 7970 655f 6173 286c 6162  dex).type_as(lab
-00016310: 656c 7329 290a 2020 2020 2020 2020 2020  els)).          
-00016320: 2020 2020 2020 6c6f 7373 203d 206c 6f73        loss = los
-00016330: 735f 6663 7428 6163 7469 7665 5f6c 6f67  s_fct(active_log
-00016340: 6974 732c 2061 6374 6976 655f 6c61 6265  its, active_labe
-00016350: 6c73 290a 2020 2020 2020 2020 2020 2020  ls).            
-00016360: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00016370: 2020 2020 2020 6c6f 7373 203d 206c 6f73        loss = los
-00016380: 735f 6663 7428 0a20 2020 2020 2020 2020  s_fct(.         
-00016390: 2020 2020 2020 2020 2020 206c 6f67 6974             logit
-000163a0: 732e 7669 6577 282d 312c 2073 656c 662e  s.view(-1, self.
-000163b0: 6e75 6d5f 6c61 6265 6c73 292c 206c 6162  num_labels), lab
-000163c0: 656c 732e 7669 6577 282d 3129 290a 0a20  els.view(-1)).. 
-000163d0: 2020 2020 2020 2069 6620 6e6f 7420 7265         if not re
-000163e0: 7475 726e 5f64 6963 743a 0a20 2020 2020  turn_dict:.     
-000163f0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00016400: 286c 6f67 6974 732c 2029 202b 206f 7574  (logits, ) + out
-00016410: 7075 7473 5b32 3a5d 0a20 2020 2020 2020  puts[2:].       
-00016420: 2020 2020 2072 6574 7572 6e20 2828 6c6f       return ((lo
-00016430: 7373 2c20 2920 2b20 6f75 7470 7574 2920  ss, ) + output) 
-00016440: 6966 206c 6f73 7320 6973 206e 6f74 204e  if loss is not N
-00016450: 6f6e 6520 656c 7365 206f 7574 7075 740a  one else output.
-00016460: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00016470: 546f 6b65 6e43 6c61 7373 6966 6965 724f  TokenClassifierO
-00016480: 7574 7075 7428 0a20 2020 2020 2020 2020  utput(.         
-00016490: 2020 206c 6f73 733d 6c6f 7373 2c0a 2020     loss=loss,.  
-000164a0: 2020 2020 2020 2020 2020 6c6f 6769 7473            logits
-000164b0: 3d6c 6f67 6974 732c 0a20 2020 2020 2020  =logits,.       
-000164c0: 2020 2020 2068 6964 6465 6e5f 7374 6174       hidden_stat
-000164d0: 6573 3d6f 7574 7075 7473 2e68 6964 6465  es=outputs.hidde
-000164e0: 6e5f 7374 6174 6573 2c0a 2020 2020 2020  n_states,.      
-000164f0: 2020 2020 2020 6174 7465 6e74 696f 6e73        attentions
-00016500: 3d6f 7574 7075 7473 2e61 7474 656e 7469  =outputs.attenti
-00016510: 6f6e 732c 0a20 2020 2020 2020 2029 0a0a  ons,.        )..
-00016520: 0a63 6c61 7373 2042 6572 7446 6f72 5175  .class BertForQu
-00016530: 6573 7469 6f6e 416e 7377 6572 696e 6728  estionAnswering(
-00016540: 4265 7274 5072 6554 7261 696e 6564 4d6f  BertPreTrainedMo
-00016550: 6465 6c29 3a0a 0a20 2020 205f 6b65 7973  del):..    _keys
-00016560: 5f74 6f5f 6967 6e6f 7265 5f6f 6e5f 6c6f  _to_ignore_on_lo
-00016570: 6164 5f75 6e65 7870 6563 7465 6420 3d20  ad_unexpected = 
-00016580: 5b72 2770 6f6f 6c65 7227 5d0a 0a20 2020  [r'pooler']..   
-00016590: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
-000165a0: 6c66 2c20 636f 6e66 6967 293a 0a20 2020  lf, config):.   
-000165b0: 2020 2020 2073 7570 6572 2829 2e5f 5f69       super().__i
-000165c0: 6e69 745f 5f28 636f 6e66 6967 290a 2020  nit__(config).  
-000165d0: 2020 2020 2020 7365 6c66 2e6e 756d 5f6c        self.num_l
-000165e0: 6162 656c 7320 3d20 636f 6e66 6967 2e6e  abels = config.n
-000165f0: 756d 5f6c 6162 656c 730a 0a20 2020 2020  um_labels..     
-00016600: 2020 2073 656c 662e 6265 7274 203d 2042     self.bert = B
-00016610: 6572 744d 6f64 656c 2863 6f6e 6669 672c  ertModel(config,
-00016620: 2061 6464 5f70 6f6f 6c69 6e67 5f6c 6179   add_pooling_lay
-00016630: 6572 3d46 616c 7365 290a 2020 2020 2020  er=False).      
-00016640: 2020 7365 6c66 2e71 615f 6f75 7470 7574    self.qa_output
-00016650: 7320 3d20 6e6e 2e4c 696e 6561 7228 636f  s = nn.Linear(co
-00016660: 6e66 6967 2e68 6964 6465 6e5f 7369 7a65  nfig.hidden_size
-00016670: 2c20 636f 6e66 6967 2e6e 756d 5f6c 6162  , config.num_lab
-00016680: 656c 7329 0a0a 2020 2020 2020 2020 7365  els)..        se
-00016690: 6c66 2e69 6e69 745f 7765 6967 6874 7328  lf.init_weights(
-000166a0: 290a 0a20 2020 2064 6566 2066 6f72 7761  )..    def forwa
-000166b0: 7264 280a 2020 2020 2020 2020 7365 6c66  rd(.        self
-000166c0: 2c0a 2020 2020 2020 2020 696e 7075 745f  ,.        input_
-000166d0: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
-000166e0: 2020 6174 7465 6e74 696f 6e5f 6d61 736b    attention_mask
-000166f0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2074  =None,.        t
-00016700: 6f6b 656e 5f74 7970 655f 6964 733d 4e6f  oken_type_ids=No
-00016710: 6e65 2c0a 2020 2020 2020 2020 706f 7369  ne,.        posi
-00016720: 7469 6f6e 5f69 6473 3d4e 6f6e 652c 0a20  tion_ids=None,. 
-00016730: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
-00016740: 3d4e 6f6e 652c 0a20 2020 2020 2020 2069  =None,.        i
-00016750: 6e70 7574 735f 656d 6265 6473 3d4e 6f6e  nputs_embeds=Non
-00016760: 652c 0a20 2020 2020 2020 2073 7461 7274  e,.        start
-00016770: 5f70 6f73 6974 696f 6e73 3d4e 6f6e 652c  _positions=None,
-00016780: 0a20 2020 2020 2020 2065 6e64 5f70 6f73  .        end_pos
-00016790: 6974 696f 6e73 3d4e 6f6e 652c 0a20 2020  itions=None,.   
-000167a0: 2020 2020 206f 7574 7075 745f 6174 7465       output_atte
-000167b0: 6e74 696f 6e73 3d4e 6f6e 652c 0a20 2020  ntions=None,.   
-000167c0: 2020 2020 206f 7574 7075 745f 6869 6464       output_hidd
-000167d0: 656e 5f73 7461 7465 733d 4e6f 6e65 2c0a  en_states=None,.
-000167e0: 2020 2020 2020 2020 7265 7475 726e 5f64          return_d
-000167f0: 6963 743d 4e6f 6e65 2c0a 2020 2020 293a  ict=None,.    ):
-00016800: 0a20 2020 2020 2020 2072 2222 220a 2020  .        r""".  
-00016810: 2020 2020 2020 7374 6172 745f 706f 7369        start_posi
-00016820: 7469 6f6e 7320 283a 6f62 6a3a 6074 6f72  tions (:obj:`tor
-00016830: 6368 2e4c 6f6e 6754 656e 736f 7260 206f  ch.LongTensor` o
-00016840: 6620 7368 6170 6520 3a6f 626a 3a60 2862  f shape :obj:`(b
-00016850: 6174 6368 5f73 697a 652c 2960 2c0a 2020  atch_size,)`,.  
-00016860: 2020 2020 2020 606f 7074 696f 6e61 6c60        `optional`
-00016870: 293a 0a20 2020 2020 2020 2020 2020 204c  ):.            L
-00016880: 6162 656c 7320 666f 7220 706f 7369 7469  abels for positi
-00016890: 6f6e 2028 696e 6465 7829 206f 6620 7468  on (index) of th
-000168a0: 6520 7374 6172 7420 6f66 2074 6865 206c  e start of the l
-000168b0: 6162 656c 6c65 6420 7370 616e 2066 6f72  abelled span for
-000168c0: 0a20 2020 2020 2020 2020 2020 2063 6f6d  .            com
-000168d0: 7075 7469 6e67 2074 6865 2074 6f6b 656e  puting the token
-000168e0: 2063 6c61 7373 6966 6963 6174 696f 6e20   classification 
-000168f0: 6c6f 7373 2e20 506f 7369 7469 6f6e 7320  loss. Positions 
-00016900: 6172 6520 636c 616d 7065 6420 746f 0a20  are clamped to. 
-00016910: 2020 2020 2020 2020 2020 2074 6865 206c             the l
-00016920: 656e 6774 6820 6f66 2074 6865 2073 6571  ength of the seq
-00016930: 7565 6e63 6520 283a 6f62 6a3a 6073 6571  uence (:obj:`seq
-00016940: 7565 6e63 655f 6c65 6e67 7468 6029 2e20  uence_length`). 
-00016950: 506f 7369 7469 6f6e 0a20 2020 2020 2020  Position.       
-00016960: 2020 2020 206f 7574 7369 6465 206f 6620       outside of 
-00016970: 7468 6520 7365 7175 656e 6365 2061 7265  the sequence are
-00016980: 206e 6f74 2074 616b 656e 2069 6e74 6f20   not taken into 
-00016990: 6163 636f 756e 7420 666f 7220 636f 6d70  account for comp
-000169a0: 7574 696e 6720 7468 650a 2020 2020 2020  uting the.      
-000169b0: 2020 2020 2020 6c6f 7373 2e0a 2020 2020        loss..    
-000169c0: 2020 2020 656e 645f 706f 7369 7469 6f6e      end_position
-000169d0: 7320 283a 6f62 6a3a 6074 6f72 6368 2e4c  s (:obj:`torch.L
-000169e0: 6f6e 6754 656e 736f 7260 206f 6620 7368  ongTensor` of sh
-000169f0: 6170 6520 3a6f 626a 3a60 2862 6174 6368  ape :obj:`(batch
-00016a00: 5f73 697a 652c 2960 2c0a 2020 2020 2020  _size,)`,.      
-00016a10: 2020 606f 7074 696f 6e61 6c60 293a 0a20    `optional`):. 
-00016a20: 2020 2020 2020 2020 2020 204c 6162 656c             Label
-00016a30: 7320 666f 7220 706f 7369 7469 6f6e 2028  s for position (
-00016a40: 696e 6465 7829 206f 6620 7468 6520 656e  index) of the en
-00016a50: 6420 6f66 2074 6865 206c 6162 656c 6c65  d of the labelle
-00016a60: 6420 7370 616e 2066 6f72 0a20 2020 2020  d span for.     
-00016a70: 2020 2020 2020 2063 6f6d 7075 7469 6e67         computing
-00016a80: 2074 6865 2074 6f6b 656e 2063 6c61 7373   the token class
-00016a90: 6966 6963 6174 696f 6e20 6c6f 7373 2e20  ification loss. 
-00016aa0: 506f 7369 7469 6f6e 7320 6172 6520 636c  Positions are cl
-00016ab0: 616d 7065 6420 746f 0a20 2020 2020 2020  amped to.       
-00016ac0: 2020 2020 2074 6865 206c 656e 6774 6820       the length 
-00016ad0: 6f66 2074 6865 2073 6571 7565 6e63 6520  of the sequence 
-00016ae0: 283a 6f62 6a3a 6073 6571 7565 6e63 655f  (:obj:`sequence_
-00016af0: 6c65 6e67 7468 6029 2e20 506f 7369 7469  length`). Positi
-00016b00: 6f6e 0a20 2020 2020 2020 2020 2020 206f  on.            o
-00016b10: 7574 7369 6465 206f 6620 7468 6520 7365  utside of the se
-00016b20: 7175 656e 6365 2061 7265 206e 6f74 2074  quence are not t
-00016b30: 616b 656e 2069 6e74 6f20 6163 636f 756e  aken into accoun
-00016b40: 7420 666f 7220 636f 6d70 7574 696e 6720  t for computing 
-00016b50: 7468 650a 2020 2020 2020 2020 2020 2020  the.            
-00016b60: 6c6f 7373 2e0a 2020 2020 2020 2020 2222  loss..        ""
-00016b70: 220a 2020 2020 2020 2020 7265 7475 726e  ".        return
-00016b80: 5f64 6963 7420 3d20 7265 7475 726e 5f64  _dict = return_d
-00016b90: 6963 7420 6966 2072 6574 7572 6e5f 6469  ict if return_di
-00016ba0: 6374 2069 7320 6e6f 7420 4e6f 6e65 2065  ct is not None e
-00016bb0: 6c73 6520 7365 6c66 2e63 6f6e 6669 672e  lse self.config.
-00016bc0: 7573 655f 7265 7475 726e 5f64 6963 740a  use_return_dict.
-00016bd0: 0a20 2020 2020 2020 206f 7574 7075 7473  .        outputs
-00016be0: 203d 2073 656c 662e 6265 7274 280a 2020   = self.bert(.  
-00016bf0: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00016c00: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
-00016c10: 2061 7474 656e 7469 6f6e 5f6d 6173 6b3d   attention_mask=
-00016c20: 6174 7465 6e74 696f 6e5f 6d61 736b 2c0a  attention_mask,.
-00016c30: 2020 2020 2020 2020 2020 2020 746f 6b65              toke
-00016c40: 6e5f 7479 7065 5f69 6473 3d74 6f6b 656e  n_type_ids=token
-00016c50: 5f74 7970 655f 6964 732c 0a20 2020 2020  _type_ids,.     
-00016c60: 2020 2020 2020 2070 6f73 6974 696f 6e5f         position_
-00016c70: 6964 733d 706f 7369 7469 6f6e 5f69 6473  ids=position_ids
-00016c80: 2c0a 2020 2020 2020 2020 2020 2020 6865  ,.            he
-00016c90: 6164 5f6d 6173 6b3d 6865 6164 5f6d 6173  ad_mask=head_mas
-00016ca0: 6b2c 0a20 2020 2020 2020 2020 2020 2069  k,.            i
-00016cb0: 6e70 7574 735f 656d 6265 6473 3d69 6e70  nputs_embeds=inp
-00016cc0: 7574 735f 656d 6265 6473 2c0a 2020 2020  uts_embeds,.    
-00016cd0: 2020 2020 2020 2020 6f75 7470 7574 5f61          output_a
-00016ce0: 7474 656e 7469 6f6e 733d 6f75 7470 7574  ttentions=output
-00016cf0: 5f61 7474 656e 7469 6f6e 732c 0a20 2020  _attentions,.   
-00016d00: 2020 2020 2020 2020 206f 7574 7075 745f           output_
-00016d10: 6869 6464 656e 5f73 7461 7465 733d 6f75  hidden_states=ou
-00016d20: 7470 7574 5f68 6964 6465 6e5f 7374 6174  tput_hidden_stat
-00016d30: 6573 2c0a 2020 2020 2020 2020 2020 2020  es,.            
-00016d40: 7265 7475 726e 5f64 6963 743d 7265 7475  return_dict=retu
-00016d50: 726e 5f64 6963 742c 0a20 2020 2020 2020  rn_dict,.       
-00016d60: 2029 0a0a 2020 2020 2020 2020 7365 7175   )..        sequ
-00016d70: 656e 6365 5f6f 7574 7075 7420 3d20 6f75  ence_output = ou
-00016d80: 7470 7574 735b 305d 0a0a 2020 2020 2020  tputs[0]..      
-00016d90: 2020 6c6f 6769 7473 203d 2073 656c 662e    logits = self.
-00016da0: 7161 5f6f 7574 7075 7473 2873 6571 7565  qa_outputs(seque
-00016db0: 6e63 655f 6f75 7470 7574 290a 2020 2020  nce_output).    
-00016dc0: 2020 2020 7374 6172 745f 6c6f 6769 7473      start_logits
-00016dd0: 2c20 656e 645f 6c6f 6769 7473 203d 206c  , end_logits = l
-00016de0: 6f67 6974 732e 7370 6c69 7428 312c 2064  ogits.split(1, d
-00016df0: 696d 3d2d 3129 0a20 2020 2020 2020 2073  im=-1).        s
-00016e00: 7461 7274 5f6c 6f67 6974 7320 3d20 7374  tart_logits = st
-00016e10: 6172 745f 6c6f 6769 7473 2e73 7175 6565  art_logits.squee
-00016e20: 7a65 282d 3129 0a20 2020 2020 2020 2065  ze(-1).        e
-00016e30: 6e64 5f6c 6f67 6974 7320 3d20 656e 645f  nd_logits = end_
-00016e40: 6c6f 6769 7473 2e73 7175 6565 7a65 282d  logits.squeeze(-
-00016e50: 3129 0a0a 2020 2020 2020 2020 746f 7461  1)..        tota
-00016e60: 6c5f 6c6f 7373 203d 204e 6f6e 650a 2020  l_loss = None.  
-00016e70: 2020 2020 2020 6966 2073 7461 7274 5f70        if start_p
-00016e80: 6f73 6974 696f 6e73 2069 7320 6e6f 7420  ositions is not 
-00016e90: 4e6f 6e65 2061 6e64 2065 6e64 5f70 6f73  None and end_pos
-00016ea0: 6974 696f 6e73 2069 7320 6e6f 7420 4e6f  itions is not No
-00016eb0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00016ec0: 2320 4966 2077 6520 6172 6520 6f6e 206d  # If we are on m
-00016ed0: 756c 7469 2d47 5055 2c20 7370 6c69 7420  ulti-GPU, split 
-00016ee0: 6164 6420 6120 6469 6d65 6e73 696f 6e0a  add a dimension.
-00016ef0: 2020 2020 2020 2020 2020 2020 6966 206c              if l
-00016f00: 656e 2873 7461 7274 5f70 6f73 6974 696f  en(start_positio
-00016f10: 6e73 2e73 697a 6528 2929 203e 2031 3a0a  ns.size()) > 1:.
-00016f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016f30: 7374 6172 745f 706f 7369 7469 6f6e 7320  start_positions 
-00016f40: 3d20 7374 6172 745f 706f 7369 7469 6f6e  = start_position
-00016f50: 732e 7371 7565 657a 6528 2d31 290a 2020  s.squeeze(-1).  
-00016f60: 2020 2020 2020 2020 2020 6966 206c 656e            if len
-00016f70: 2865 6e64 5f70 6f73 6974 696f 6e73 2e73  (end_positions.s
-00016f80: 697a 6528 2929 203e 2031 3a0a 2020 2020  ize()) > 1:.    
-00016f90: 2020 2020 2020 2020 2020 2020 656e 645f              end_
-00016fa0: 706f 7369 7469 6f6e 7320 3d20 656e 645f  positions = end_
-00016fb0: 706f 7369 7469 6f6e 732e 7371 7565 657a  positions.squeez
-00016fc0: 6528 2d31 290a 2020 2020 2020 2020 2020  e(-1).          
-00016fd0: 2020 2320 736f 6d65 7469 6d65 7320 7468    # sometimes th
-00016fe0: 6520 7374 6172 742f 656e 6420 706f 7369  e start/end posi
-00016ff0: 7469 6f6e 7320 6172 6520 6f75 7473 6964  tions are outsid
-00017000: 6520 6f75 7220 6d6f 6465 6c20 696e 7075  e our model inpu
-00017010: 7473 2c20 7765 2069 676e 6f72 6520 7468  ts, we ignore th
-00017020: 6573 6520 7465 726d 730a 2020 2020 2020  ese terms.      
-00017030: 2020 2020 2020 6967 6e6f 7265 645f 696e        ignored_in
-00017040: 6465 7820 3d20 7374 6172 745f 6c6f 6769  dex = start_logi
-00017050: 7473 2e73 697a 6528 3129 0a20 2020 2020  ts.size(1).     
-00017060: 2020 2020 2020 2073 7461 7274 5f70 6f73         start_pos
-00017070: 6974 696f 6e73 2e63 6c61 6d70 5f28 302c  itions.clamp_(0,
-00017080: 2069 676e 6f72 6564 5f69 6e64 6578 290a   ignored_index).
-00017090: 2020 2020 2020 2020 2020 2020 656e 645f              end_
-000170a0: 706f 7369 7469 6f6e 732e 636c 616d 705f  positions.clamp_
-000170b0: 2830 2c20 6967 6e6f 7265 645f 696e 6465  (0, ignored_inde
-000170c0: 7829 0a0a 2020 2020 2020 2020 2020 2020  x)..            
-000170d0: 6c6f 7373 5f66 6374 203d 2043 726f 7373  loss_fct = Cross
-000170e0: 456e 7472 6f70 794c 6f73 7328 6967 6e6f  EntropyLoss(igno
-000170f0: 7265 5f69 6e64 6578 3d69 676e 6f72 6564  re_index=ignored
-00017100: 5f69 6e64 6578 290a 2020 2020 2020 2020  _index).        
-00017110: 2020 2020 7374 6172 745f 6c6f 7373 203d      start_loss =
-00017120: 206c 6f73 735f 6663 7428 7374 6172 745f   loss_fct(start_
-00017130: 6c6f 6769 7473 2c20 7374 6172 745f 706f  logits, start_po
-00017140: 7369 7469 6f6e 7329 0a20 2020 2020 2020  sitions).       
-00017150: 2020 2020 2065 6e64 5f6c 6f73 7320 3d20       end_loss = 
-00017160: 6c6f 7373 5f66 6374 2865 6e64 5f6c 6f67  loss_fct(end_log
-00017170: 6974 732c 2065 6e64 5f70 6f73 6974 696f  its, end_positio
-00017180: 6e73 290a 2020 2020 2020 2020 2020 2020  ns).            
-00017190: 746f 7461 6c5f 6c6f 7373 203d 2028 7374  total_loss = (st
-000171a0: 6172 745f 6c6f 7373 202b 2065 6e64 5f6c  art_loss + end_l
-000171b0: 6f73 7329 202f 2032 0a0a 2020 2020 2020  oss) / 2..      
-000171c0: 2020 6966 206e 6f74 2072 6574 7572 6e5f    if not return_
-000171d0: 6469 6374 3a0a 2020 2020 2020 2020 2020  dict:.          
-000171e0: 2020 6f75 7470 7574 203d 2028 7374 6172    output = (star
-000171f0: 745f 6c6f 6769 7473 2c20 656e 645f 6c6f  t_logits, end_lo
-00017200: 6769 7473 2920 2b20 6f75 7470 7574 735b  gits) + outputs[
-00017210: 323a 5d0a 2020 2020 2020 2020 2020 2020  2:].            
-00017220: 7265 7475 726e 2028 2874 6f74 616c 5f6c  return ((total_l
-00017230: 6f73 732c 2029 0a20 2020 2020 2020 2020  oss, ).         
-00017240: 2020 2020 2020 2020 2020 202b 206f 7574             + out
-00017250: 7075 7429 2069 6620 746f 7461 6c5f 6c6f  put) if total_lo
-00017260: 7373 2069 7320 6e6f 7420 4e6f 6e65 2065  ss is not None e
-00017270: 6c73 6520 6f75 7470 7574 0a0a 2020 2020  lse output..    
-00017280: 2020 2020 7265 7475 726e 2051 7565 7374      return Quest
-00017290: 696f 6e41 6e73 7765 7269 6e67 4d6f 6465  ionAnsweringMode
-000172a0: 6c4f 7574 7075 7428 0a20 2020 2020 2020  lOutput(.       
-000172b0: 2020 2020 206c 6f73 733d 746f 7461 6c5f       loss=total_
-000172c0: 6c6f 7373 2c0a 2020 2020 2020 2020 2020  loss,.          
-000172d0: 2020 7374 6172 745f 6c6f 6769 7473 3d73    start_logits=s
-000172e0: 7461 7274 5f6c 6f67 6974 732c 0a20 2020  tart_logits,.   
-000172f0: 2020 2020 2020 2020 2065 6e64 5f6c 6f67           end_log
-00017300: 6974 733d 656e 645f 6c6f 6769 7473 2c0a  its=end_logits,.
-00017310: 2020 2020 2020 2020 2020 2020 6869 6464              hidd
-00017320: 656e 5f73 7461 7465 733d 6f75 7470 7574  en_states=output
-00017330: 732e 6869 6464 656e 5f73 7461 7465 732c  s.hidden_states,
-00017340: 0a20 2020 2020 2020 2020 2020 2061 7474  .            att
-00017350: 656e 7469 6f6e 733d 6f75 7470 7574 732e  entions=outputs.
-00017360: 6174 7465 6e74 696f 6e73 2c0a 2020 2020  attentions,.    
-00017370: 2020 2020 290a 0a0a 636c 6173 7320 4d47      )...class MG
-00017380: 656f 5072 6554 7261 696e 6564 4d6f 6465  eoPreTrainedMode
-00017390: 6c28 546f 7263 684d 6f64 656c 2c20 5072  l(TorchModel, Pr
-000173a0: 6554 7261 696e 6564 4d6f 6465 6c29 3a0a  eTrainedModel):.
-000173b0: 2020 2020 2222 220a 2020 2020 416e 2061      """.    An a
-000173c0: 6273 7472 6163 7420 636c 6173 7320 746f  bstract class to
-000173d0: 2068 616e 646c 6520 7765 6967 6874 7320   handle weights 
-000173e0: 696e 6974 6961 6c69 7a61 7469 6f6e 2061  initialization a
-000173f0: 6e64 2061 2073 696d 706c 6520 696e 7465  nd a simple inte
-00017400: 7266 6163 650a 2020 2020 666f 7220 646f  rface.    for do
-00017410: 776e 6c6f 6164 696e 6720 616e 6420 6c6f  wnloading and lo
-00017420: 6164 696e 6720 7072 6574 7261 696e 6564  ading pretrained
-00017430: 206d 6f64 656c 732e 0a20 2020 2022 2222   models..    """
-00017440: 0a0a 2020 2020 636f 6e66 6967 5f63 6c61  ..    config_cla
-00017450: 7373 203d 2042 6572 7443 6f6e 6669 670a  ss = BertConfig.
-00017460: 2020 2020 6261 7365 5f6d 6f64 656c 5f70      base_model_p
-00017470: 7265 6669 7820 3d20 2762 6572 7427 0a20  refix = 'bert'. 
-00017480: 2020 2073 7570 706f 7274 735f 6772 6164     supports_grad
-00017490: 6965 6e74 5f63 6865 636b 706f 696e 7469  ient_checkpointi
-000174a0: 6e67 203d 2054 7275 650a 2020 2020 5f6b  ng = True.    _k
-000174b0: 6579 735f 746f 5f69 676e 6f72 655f 6f6e  eys_to_ignore_on
-000174c0: 5f6c 6f61 645f 6d69 7373 696e 6720 3d20  _load_missing = 
-000174d0: 5b72 2770 6f73 6974 696f 6e5f 6964 7327  [r'position_ids'
-000174e0: 5d0a 0a20 2020 2064 6566 205f 5f69 6e69  ]..    def __ini
-000174f0: 745f 5f28 7365 6c66 2c20 636f 6e66 6967  t__(self, config
-00017500: 2c20 2a2a 6b77 6172 6773 293a 0a20 2020  , **kwargs):.   
-00017510: 2020 2020 2073 7570 6572 2829 2e5f 5f69       super().__i
-00017520: 6e69 745f 5f28 636f 6e66 6967 2e6e 616d  nit__(config.nam
-00017530: 655f 6f72 5f70 6174 682c 202a 2a6b 7761  e_or_path, **kwa
-00017540: 7267 7329 0a20 2020 2020 2020 2073 7570  rgs).        sup
-00017550: 6572 284d 6f64 656c 2c20 7365 6c66 292e  er(Model, self).
-00017560: 5f5f 696e 6974 5f5f 2863 6f6e 6669 6729  __init__(config)
-00017570: 0a0a 2020 2020 6465 6620 5f69 6e69 745f  ..    def _init_
-00017580: 7765 6967 6874 7328 7365 6c66 2c20 6d6f  weights(self, mo
-00017590: 6475 6c65 293a 0a20 2020 2020 2020 2022  dule):.        "
-000175a0: 2222 496e 6974 6961 6c69 7a65 2074 6865  ""Initialize the
-000175b0: 2077 6569 6768 7473 2222 220a 2020 2020   weights""".    
-000175c0: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
-000175d0: 6528 6d6f 6475 6c65 2c20 6e6e 2e4c 696e  e(module, nn.Lin
-000175e0: 6561 7229 3a0a 2020 2020 2020 2020 2020  ear):.          
-000175f0: 2020 2320 536c 6967 6874 6c79 2064 6966    # Slightly dif
-00017600: 6665 7265 6e74 2066 726f 6d20 7468 6520  ferent from the 
-00017610: 5446 2076 6572 7369 6f6e 2077 6869 6368  TF version which
-00017620: 2075 7365 7320 7472 756e 6361 7465 645f   uses truncated_
-00017630: 6e6f 726d 616c 2066 6f72 2069 6e69 7469  normal for initi
-00017640: 616c 697a 6174 696f 6e0a 2020 2020 2020  alization.      
-00017650: 2020 2020 2020 2320 6366 2068 7474 7073        # cf https
-00017660: 3a2f 2f67 6974 6875 622e 636f 6d2f 7079  ://github.com/py
-00017670: 746f 7263 682f 7079 746f 7263 682f 7075  torch/pytorch/pu
-00017680: 6c6c 2f35 3631 370a 2020 2020 2020 2020  ll/5617.        
-00017690: 2020 2020 6d6f 6475 6c65 2e77 6569 6768      module.weigh
-000176a0: 742e 6461 7461 2e6e 6f72 6d61 6c5f 280a  t.data.normal_(.
-000176b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000176c0: 6d65 616e 3d30 2e30 2c20 7374 643d 7365  mean=0.0, std=se
-000176d0: 6c66 2e63 6f6e 6669 672e 696e 6974 6961  lf.config.initia
-000176e0: 6c69 7a65 725f 7261 6e67 6529 0a20 2020  lizer_range).   
-000176f0: 2020 2020 2020 2020 2069 6620 6d6f 6475           if modu
-00017700: 6c65 2e62 6961 7320 6973 206e 6f74 204e  le.bias is not N
-00017710: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-00017720: 2020 2020 206d 6f64 756c 652e 6269 6173       module.bias
-00017730: 2e64 6174 612e 7a65 726f 5f28 290a 2020  .data.zero_().  
-00017740: 2020 2020 2020 656c 6966 2069 7369 6e73        elif isins
-00017750: 7461 6e63 6528 6d6f 6475 6c65 2c20 6e6e  tance(module, nn
-00017760: 2e45 6d62 6564 6469 6e67 293a 0a20 2020  .Embedding):.   
-00017770: 2020 2020 2020 2020 206d 6f64 756c 652e           module.
-00017780: 7765 6967 6874 2e64 6174 612e 6e6f 726d  weight.data.norm
-00017790: 616c 5f28 0a20 2020 2020 2020 2020 2020  al_(.           
-000177a0: 2020 2020 206d 6561 6e3d 302e 302c 2073       mean=0.0, s
-000177b0: 7464 3d73 656c 662e 636f 6e66 6967 2e69  td=self.config.i
-000177c0: 6e69 7469 616c 697a 6572 5f72 616e 6765  nitializer_range
-000177d0: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-000177e0: 206d 6f64 756c 652e 7061 6464 696e 675f   module.padding_
-000177f0: 6964 7820 6973 206e 6f74 204e 6f6e 653a  idx is not None:
-00017800: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017810: 206d 6f64 756c 652e 7765 6967 6874 2e64   module.weight.d
-00017820: 6174 615b 6d6f 6475 6c65 2e70 6164 6469  ata[module.paddi
-00017830: 6e67 5f69 6478 5d2e 7a65 726f 5f28 290a  ng_idx].zero_().
-00017840: 2020 2020 2020 2020 656c 6966 2069 7369          elif isi
-00017850: 6e73 7461 6e63 6528 6d6f 6475 6c65 2c20  nstance(module, 
-00017860: 6e6e 2e4c 6179 6572 4e6f 726d 293a 0a20  nn.LayerNorm):. 
-00017870: 2020 2020 2020 2020 2020 206d 6f64 756c             modul
-00017880: 652e 6269 6173 2e64 6174 612e 7a65 726f  e.bias.data.zero
-00017890: 5f28 290a 2020 2020 2020 2020 2020 2020  _().            
-000178a0: 6d6f 6475 6c65 2e77 6569 6768 742e 6461  module.weight.da
-000178b0: 7461 2e66 696c 6c5f 2831 2e30 290a 0a20  ta.fill_(1.0).. 
-000178c0: 2020 2064 6566 205f 7365 745f 6772 6164     def _set_grad
-000178d0: 6965 6e74 5f63 6865 636b 706f 696e 7469  ient_checkpointi
-000178e0: 6e67 2873 656c 662c 206d 6f64 756c 652c  ng(self, module,
-000178f0: 2076 616c 7565 3d46 616c 7365 293a 0a20   value=False):. 
-00017900: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-00017910: 616e 6365 286d 6f64 756c 652c 2042 6572  ance(module, Ber
-00017920: 7445 6e63 6f64 6572 293a 0a20 2020 2020  tEncoder):.     
-00017930: 2020 2020 2020 206d 6f64 756c 652e 6772         module.gr
-00017940: 6164 6965 6e74 5f63 6865 636b 706f 696e  adient_checkpoin
-00017950: 7469 6e67 203d 2076 616c 7565 0a0a 2020  ting = value..  
-00017960: 2020 4063 6c61 7373 6d65 7468 6f64 0a20    @classmethod. 
-00017970: 2020 2064 6566 205f 696e 7374 616e 7469     def _instanti
-00017980: 6174 6528 636c 732c 202a 2a6b 7761 7267  ate(cls, **kwarg
-00017990: 7329 3a0a 2020 2020 2020 2020 2222 2249  s):.        """I
-000179a0: 6e73 7461 6e74 6961 7465 2074 6865 206d  nstantiate the m
-000179b0: 6f64 656c 2e0a 0a20 2020 2020 2020 2041  odel...        A
-000179c0: 7267 733a 0a20 2020 2020 2020 2020 2020  rgs:.           
-000179d0: 206b 7761 7267 733a 2049 6e70 7574 2061   kwargs: Input a
-000179e0: 7267 732e 0a20 2020 2020 2020 2020 2020  rgs..           
-000179f0: 2020 2020 2020 2020 206d 6f64 656c 5f64           model_d
-00017a00: 6972 3a20 5468 6520 6d6f 6465 6c20 6469  ir: The model di
-00017a10: 7220 7573 6564 2074 6f20 6c6f 6164 2074  r used to load t
-00017a20: 6865 2063 6865 636b 706f 696e 7420 616e  he checkpoint an
-00017a30: 6420 7468 650a 2020 2020 2020 2020 2020  d the.          
-00017a40: 2020 2020 2020 2020 2020 6c61 6265 6c20            label 
-00017a50: 696e 666f 726d 6174 696f 6e2e 206e 756d  information. num
-00017a60: 5f6c 6162 656c 733a 2041 6e20 6f70 7469  _labels: An opti
-00017a70: 6f6e 616c 2061 7267 2074 6f20 7465 6c6c  onal arg to tell
-00017a80: 2074 6865 0a20 2020 2020 2020 2020 2020   the.           
-00017a90: 2020 2020 2020 2020 206d 6f64 656c 2068           model h
-00017aa0: 6f77 206d 616e 7920 636c 6173 7365 7320  ow many classes 
-00017ab0: 746f 2069 6e69 7469 616c 697a 652e 0a20  to initialize.. 
-00017ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ae0: 2020 204d 6574 686f 6420 7769 6c6c 2063     Method will c
-00017af0: 616c 6c20 7574 696c 732e 7061 7273 655f  all utils.parse_
-00017b00: 6c61 6265 6c5f 6d61 7070 696e 670a 2020  label_mapping.  
-00017b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b30: 2020 6966 206e 756d 5f6c 6162 656c 7320    if num_labels 
-00017b40: 6e6f 7420 7375 7070 6c69 6564 2e20 4966  not supplied. If
-00017b50: 206e 756d 5f6c 6162 656c 7320 6973 0a20   num_labels is. 
-00017b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b80: 2020 206e 6f74 2066 6f75 6e64 2c20 7468     not found, th
-00017b90: 6520 6d6f 6465 6c20 7769 6c6c 2075 7365  e model will use
-00017ba0: 2074 6865 2064 6566 6175 6c74 0a20 2020   the default.   
-00017bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017bd0: 2073 6574 7469 6e67 2028 3220 636c 6173   setting (2 clas
-00017be0: 7365 7329 2e0a 0a20 2020 2020 2020 2052  ses)...        R
-00017bf0: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
-00017c00: 2020 2020 5468 6520 6c6f 6164 6564 206d      The loaded m
-00017c10: 6f64 656c 2c20 7768 6963 6820 6973 2069  odel, which is i
-00017c20: 6e69 7469 616c 697a 6564 2062 790a 2020  nitialized by.  
-00017c30: 2020 2020 2020 2020 2020 7472 616e 7366            transf
-00017c40: 6f72 6d65 7273 2e50 7265 5472 6169 6e65  ormers.PreTraine
-00017c50: 644d 6f64 656c 2e66 726f 6d5f 7072 6574  dModel.from_pret
-00017c60: 7261 696e 6564 0a20 2020 2020 2020 2022  rained.        "
-00017c70: 2222 0a0a 2020 2020 2020 2020 6d6f 6465  ""..        mode
-00017c80: 6c5f 6469 7220 3d20 6b77 6172 6773 2e70  l_dir = kwargs.p
-00017c90: 6f70 2827 6d6f 6465 6c5f 6469 7227 2c20  op('model_dir', 
-00017ca0: 4e6f 6e65 290a 2020 2020 2020 2020 6366  None).        cf
-00017cb0: 6720 3d20 6b77 6172 6773 2e70 6f70 2827  g = kwargs.pop('
-00017cc0: 6366 6727 2c20 4e6f 6e65 290a 2020 2020  cfg', None).    
-00017cd0: 2020 2020 6d6f 6465 6c5f 6172 6773 203d      model_args =
-00017ce0: 2070 6172 7365 5f6c 6162 656c 735f 696e   parse_labels_in
-00017cf0: 5f6f 7264 6572 286d 6f64 656c 5f64 6972  _order(model_dir
-00017d00: 2c20 6366 672c 202a 2a6b 7761 7267 7329  , cfg, **kwargs)
-00017d10: 0a20 2020 2020 2020 2069 6620 6d6f 6465  .        if mode
-00017d20: 6c5f 6469 7220 6973 204e 6f6e 653a 0a20  l_dir is None:. 
-00017d30: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
-00017d40: 6720 3d20 4265 7274 436f 6e66 6967 282a  g = BertConfig(*
-00017d50: 2a6d 6f64 656c 5f61 7267 7329 0a20 2020  *model_args).   
-00017d60: 2020 2020 2020 2020 206d 6f64 656c 203d           model =
-00017d70: 2063 6c73 2863 6f6e 6669 6729 0a20 2020   cls(config).   
-00017d80: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00017d90: 2020 2020 2020 206d 6f64 656c 203d 2073         model = s
-00017da0: 7570 6572 284d 6f64 656c 2c20 636c 7329  uper(Model, cls)
-00017db0: 2e66 726f 6d5f 7072 6574 7261 696e 6564  .from_pretrained
-00017dc0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00017dd0: 2020 7072 6574 7261 696e 6564 5f6d 6f64    pretrained_mod
-00017de0: 656c 5f6e 616d 655f 6f72 5f70 6174 683d  el_name_or_path=
-00017df0: 6d6f 6465 6c5f 6469 722c 202a 2a6d 6f64  model_dir, **mod
-00017e00: 656c 5f61 7267 7329 0a20 2020 2020 2020  el_args).       
-00017e10: 206d 6f64 656c 2e6d 6f64 656c 5f64 6972   model.model_dir
-00017e20: 203d 206d 6f64 656c 5f64 6972 0a20 2020   = model_dir.   
-00017e30: 2020 2020 2072 6574 7572 6e20 6d6f 6465       return mode
-00017e40: 6c0a 0a0a 404d 4f44 454c 532e 7265 6769  l...@MODELS.regi
-00017e50: 7374 6572 5f6d 6f64 756c 6528 5461 736b  ster_module(Task
-00017e60: 732e 6261 636b 626f 6e65 2c20 6d6f 6475  s.backbone, modu
-00017e70: 6c65 5f6e 616d 653d 4d6f 6465 6c73 2e6d  le_name=Models.m
-00017e80: 6765 6f29 0a63 6c61 7373 204d 4765 6f28  geo).class MGeo(
-00017e90: 4d47 656f 5072 6554 7261 696e 6564 4d6f  MGeoPreTrainedMo
-00017ea0: 6465 6c29 3a0a 0a20 2020 2064 6566 205f  del):..    def _
-00017eb0: 5f69 6e69 745f 5f28 7365 6c66 2c0a 2020  _init__(self,.  
-00017ec0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00017ed0: 6f6e 6669 673a 2042 6572 7443 6f6e 6669  onfig: BertConfi
-00017ee0: 672c 0a20 2020 2020 2020 2020 2020 2020  g,.             
-00017ef0: 2020 2020 6669 6e65 7475 6e65 5f6d 6f64      finetune_mod
-00017f00: 653a 2073 7472 203d 2027 7369 6e67 6c65  e: str = 'single
-00017f10: 2d6d 6f64 616c 272c 0a20 2020 2020 2020  -modal',.       
-00017f20: 2020 2020 2020 2020 2020 6769 735f 6e75            gis_nu
-00017f30: 6d3a 2069 6e74 203d 2031 2c0a 2020 2020  m: int = 1,.    
-00017f40: 2020 2020 2020 2020 2020 2020 2061 6464               add
-00017f50: 5f70 6f6f 6c69 6e67 5f6c 6179 6572 3d46  _pooling_layer=F
-00017f60: 616c 7365 2c0a 2020 2020 2020 2020 2020  alse,.          
-00017f70: 2020 2020 2020 202a 2a6b 7761 7267 7329         **kwargs)
-00017f80: 3a0a 2020 2020 2020 2020 7375 7065 7228  :.        super(
-00017f90: 292e 5f5f 696e 6974 5f5f 2863 6f6e 6669  ).__init__(confi
-00017fa0: 6729 0a0a 2020 2020 2020 2020 7365 6c66  g)..        self
-00017fb0: 2e66 696e 6574 756e 655f 6d6f 6465 203d  .finetune_mode =
-00017fc0: 2066 696e 6574 756e 655f 6d6f 6465 0a0a   finetune_mode..
-00017fd0: 2020 2020 2020 2020 7365 6c66 2e63 6f6e          self.con
-00017fe0: 6669 6720 3d20 636f 6e66 6967 0a20 2020  fig = config.   
-00017ff0: 2020 2020 2073 656c 662e 7465 7874 5f65       self.text_e
-00018000: 6e63 6f64 6572 203d 2042 6572 744d 6f64  ncoder = BertMod
-00018010: 656c 280a 2020 2020 2020 2020 2020 2020  el(.            
-00018020: 636f 6e66 6967 2c20 6164 645f 706f 6f6c  config, add_pool
-00018030: 696e 675f 6c61 7965 723d 6164 645f 706f  ing_layer=add_po
-00018040: 6f6c 696e 675f 6c61 7965 7229 0a0a 2020  oling_layer)..  
-00018050: 2020 2020 2020 6966 2073 656c 662e 6669        if self.fi
-00018060: 6e65 7475 6e65 5f6d 6f64 6520 3d3d 2027  netune_mode == '
-00018070: 6d75 6c74 692d 6d6f 6461 6c27 3a0a 2020  multi-modal':.  
-00018080: 2020 2020 2020 2020 2020 6769 735f 636f            gis_co
-00018090: 6e66 6967 203d 2042 6572 7443 6f6e 6669  nfig = BertConfi
-000180a0: 672e 6672 6f6d 5f64 6963 7428 636f 6e66  g.from_dict(conf
-000180b0: 6967 2e67 6973 5f65 6e63 6f64 6572 290a  ig.gis_encoder).
-000180c0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000180d0: 2e67 6973 5f65 6e63 6f64 6572 203d 2042  .gis_encoder = B
-000180e0: 6572 744d 6f64 656c 2867 6973 5f63 6f6e  ertModel(gis_con
-000180f0: 6669 672c 2061 6464 5f70 6f6f 6c69 6e67  fig, add_pooling
-00018100: 5f6c 6179 6572 3d46 616c 7365 290a 2020  _layer=False).  
-00018110: 2020 2020 2020 2020 2020 666f 7220 7061            for pa
-00018120: 7261 6d20 696e 2073 656c 662e 6769 735f  ram in self.gis_
-00018130: 656e 636f 6465 722e 7061 7261 6d65 7465  encoder.paramete
-00018140: 7273 2829 3a0a 2020 2020 2020 2020 2020  rs():.          
-00018150: 2020 2020 2020 7061 7261 6d2e 7265 7175        param.requ
-00018160: 6972 6573 5f67 7261 6420 3d20 4661 6c73  ires_grad = Fals
-00018170: 650a 2020 2020 2020 2020 2020 2020 7365  e.            se
-00018180: 6c66 2e67 6973 3274 6578 7420 3d20 6e6e  lf.gis2text = nn
-00018190: 2e4c 696e 6561 7228 6769 735f 636f 6e66  .Linear(gis_conf
-000181a0: 6967 2e68 6964 6465 6e5f 7369 7a65 2c0a  ig.hidden_size,.
-000181b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000181c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000181d0: 2020 2020 2020 7365 6c66 2e63 6f6e 6669        self.confi
-000181e0: 672e 6869 6464 656e 5f73 697a 6529 0a20  g.hidden_size). 
-000181f0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00018200: 6769 735f 7479 7065 203d 206e 6e2e 456d  gis_type = nn.Em
-00018210: 6265 6464 696e 6728 6769 735f 6e75 6d2c  bedding(gis_num,
-00018220: 2067 6973 5f63 6f6e 6669 672e 6869 6464   gis_config.hidd
-00018230: 656e 5f73 697a 6529 0a0a 2020 2020 2020  en_size)..      
-00018240: 2020 7365 6c66 2e69 6e69 745f 7765 6967    self.init_weig
-00018250: 6874 7328 290a 0a20 2020 2064 6566 2066  hts()..    def f
-00018260: 6f72 7761 7264 2873 656c 662c 0a20 2020  orward(self,.   
-00018270: 2020 2020 2020 2020 2020 2020 2069 6e70               inp
-00018280: 7574 5f69 6473 3d4e 6f6e 652c 0a20 2020  ut_ids=None,.   
-00018290: 2020 2020 2020 2020 2020 2020 2061 7474               att
-000182a0: 656e 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65  ention_mask=None
-000182b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000182c0: 2020 746f 6b65 6e5f 7479 7065 5f69 6473    token_type_ids
-000182d0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2020  =None,.         
-000182e0: 2020 2020 2020 2070 6f73 6974 696f 6e5f         position_
-000182f0: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
-00018300: 2020 2020 2020 2020 2020 6865 6164 5f6d            head_m
-00018310: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
-00018320: 2020 2020 2020 2020 2020 696e 7075 7473            inputs
-00018330: 5f65 6d62 6564 733d 4e6f 6e65 2c0a 2020  _embeds=None,.  
-00018340: 2020 2020 2020 2020 2020 2020 2020 656e                en
-00018350: 636f 6465 725f 656d 6265 6473 3d4e 6f6e  coder_embeds=Non
-00018360: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-00018370: 2020 2065 6e63 6f64 6572 5f68 6964 6465     encoder_hidde
-00018380: 6e5f 7374 6174 6573 3d4e 6f6e 652c 0a20  n_states=None,. 
-00018390: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-000183a0: 6e63 6f64 6572 5f61 7474 656e 7469 6f6e  ncoder_attention
-000183b0: 5f6d 6173 6b3d 4e6f 6e65 2c0a 2020 2020  _mask=None,.    
-000183c0: 2020 2020 2020 2020 2020 2020 7061 7374              past
-000183d0: 5f6b 6579 5f76 616c 7565 733d 4e6f 6e65  _key_values=None
-000183e0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000183f0: 2020 7573 655f 6361 6368 653d 4e6f 6e65    use_cache=None
-00018400: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00018410: 2020 6f75 7470 7574 5f61 7474 656e 7469    output_attenti
-00018420: 6f6e 733d 4e6f 6e65 2c0a 2020 2020 2020  ons=None,.      
-00018430: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00018440: 5f68 6964 6465 6e5f 7374 6174 6573 3d4e  _hidden_states=N
-00018450: 6f6e 652c 0a20 2020 2020 2020 2020 2020  one,.           
-00018460: 2020 2020 2072 6574 7572 6e5f 6469 6374       return_dict
-00018470: 3d4e 6f6e 652c 0a20 2020 2020 2020 2020  =None,.         
-00018480: 2020 2020 2020 2069 735f 6465 636f 6465         is_decode
-00018490: 723d 4661 6c73 652c 0a20 2020 2020 2020  r=False,.       
-000184a0: 2020 2020 2020 2020 206d 6f64 653d 2773           mode='s
-000184b0: 696e 676c 652d 6d6f 6461 6c27 2c0a 2020  ingle-modal',.  
-000184c0: 2020 2020 2020 2020 2020 2020 2020 6769                gi
-000184d0: 735f 6c69 7374 3d4e 6f6e 652c 0a20 2020  s_list=None,.   
-000184e0: 2020 2020 2020 2020 2020 2020 2067 6973               gis
-000184f0: 5f74 703d 4e6f 6e65 2c0a 2020 2020 2020  _tp=None,.      
-00018500: 2020 2020 2020 2020 2020 7573 655f 746f            use_to
-00018510: 6b65 6e5f 7479 7065 3d46 616c 7365 293a  ken_type=False):
-00018520: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-00018530: 2e66 696e 6574 756e 655f 6d6f 6465 203d  .finetune_mode =
-00018540: 3d20 276d 756c 7469 2d6d 6f64 616c 2720  = 'multi-modal' 
-00018550: 616e 6420 6769 735f 6c69 7374 2069 7320  and gis_list is 
-00018560: 6e6f 7420 4e6f 6e65 2061 6e64 206c 656e  not None and len
-00018570: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00018580: 2020 6769 735f 6c69 7374 2920 3e20 303a    gis_list) > 0:
-00018590: 0a20 2020 2020 2020 2020 2020 2067 6973  .            gis
-000185a0: 5f65 6d62 7320 3d20 5b5d 0a20 2020 2020  _embs = [].     
-000185b0: 2020 2020 2020 2067 6973 5f61 7474 7320         gis_atts 
-000185c0: 3d20 5b5d 0a20 2020 2020 2020 2020 2020  = [].           
-000185d0: 2066 6f72 2067 6973 2069 6e20 6769 735f   for gis in gis_
-000185e0: 6c69 7374 3a0a 2020 2020 2020 2020 2020  list:.          
-000185f0: 2020 2020 2020 6769 735f 656d 6273 2e61        gis_embs.a
-00018600: 7070 656e 6428 0a20 2020 2020 2020 2020  ppend(.         
-00018610: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00018620: 6769 735f 656e 636f 6465 7228 7265 7475  gis_encoder(retu
-00018630: 726e 5f64 6963 743d 5472 7565 2c20 6d6f  rn_dict=True, mo
-00018640: 6465 3d27 7465 7874 272c 0a20 2020 2020  de='text',.     
-00018650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018670: 2a2a 6769 7329 2e6c 6173 745f 6869 6464  **gis).last_hidd
-00018680: 656e 5f73 7461 7465 290a 2020 2020 2020  en_state).      
-00018690: 2020 2020 2020 2020 2020 6769 735f 6174            gis_at
-000186a0: 7473 2e61 7070 656e 6428 6769 735b 2761  ts.append(gis['a
-000186b0: 7474 656e 7469 6f6e 5f6d 6173 6b27 5d29  ttention_mask'])
-000186c0: 0a20 2020 2020 2020 2069 6620 7573 655f  .        if use_
-000186d0: 746f 6b65 6e5f 7479 7065 3a0a 2020 2020  token_type:.    
-000186e0: 2020 2020 2020 2020 656d 6265 6464 696e          embeddin
-000186f0: 675f 6f75 7470 7574 203d 2073 656c 662e  g_output = self.
-00018700: 7465 7874 5f65 6e63 6f64 6572 2e65 6d62  text_encoder.emb
-00018710: 6564 6469 6e67 7328 0a20 2020 2020 2020  eddings(.       
-00018720: 2020 2020 2020 2020 2069 6e70 7574 5f69           input_i
-00018730: 6473 3d69 6e70 7574 5f69 6473 2c0a 2020  ds=input_ids,.  
-00018740: 2020 2020 2020 2020 2020 2020 2020 706f                po
-00018750: 7369 7469 6f6e 5f69 6473 3d70 6f73 6974  sition_ids=posit
-00018760: 696f 6e5f 6964 732c 0a20 2020 2020 2020  ion_ids,.       
-00018770: 2020 2020 2020 2020 2074 6f6b 656e 5f74           token_t
-00018780: 7970 655f 6964 733d 746f 6b65 6e5f 7479  ype_ids=token_ty
-00018790: 7065 5f69 6473 2c0a 2020 2020 2020 2020  pe_ids,.        
-000187a0: 2020 2020 290a 2020 2020 2020 2020 656c      ).        el
-000187b0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-000187c0: 656d 6265 6464 696e 675f 6f75 7470 7574  embedding_output
-000187d0: 203d 2073 656c 662e 7465 7874 5f65 6e63   = self.text_enc
-000187e0: 6f64 6572 2e65 6d62 6564 6469 6e67 7328  oder.embeddings(
-000187f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018800: 2069 6e70 7574 5f69 6473 3d69 6e70 7574   input_ids=input
-00018810: 5f69 6473 2c20 290a 0a20 2020 2020 2020  _ids, )..       
-00018820: 2069 6620 7365 6c66 2e66 696e 6574 756e   if self.finetun
-00018830: 655f 6d6f 6465 203d 3d20 276d 756c 7469  e_mode == 'multi
-00018840: 2d6d 6f64 616c 2720 616e 6420 6769 735f  -modal' and gis_
-00018850: 6c69 7374 2069 7320 6e6f 7420 4e6f 6e65  list is not None
-00018860: 2061 6e64 206c 656e 280a 2020 2020 2020   and len(.      
-00018870: 2020 2020 2020 2020 2020 6769 735f 6c69            gis_li
-00018880: 7374 2920 3e20 303a 0a20 2020 2020 2020  st) > 0:.       
-00018890: 2020 2020 2065 6d62 7320 3d20 5b65 6d62       embs = [emb
-000188a0: 6564 6469 6e67 5f6f 7574 7075 745d 0a20  edding_output]. 
-000188b0: 2020 2020 2020 2020 2020 2061 7474 7320             atts 
-000188c0: 3d20 5b61 7474 656e 7469 6f6e 5f6d 6173  = [attention_mas
-000188d0: 6b5d 0a20 2020 2020 2020 2020 2020 2074  k].            t
-000188e0: 705f 656d 6220 3d20 5b73 656c 662e 6769  p_emb = [self.gi
-000188f0: 735f 7479 7065 2867 7470 2920 666f 7220  s_type(gtp) for 
-00018900: 6774 7020 696e 2067 6973 5f74 705d 0a20  gtp in gis_tp]. 
-00018910: 2020 2020 2020 2020 2020 2066 6f72 2067             for g
-00018920: 652c 2067 612c 2067 7420 696e 207a 6970  e, ga, gt in zip
-00018930: 2867 6973 5f65 6d62 732c 2067 6973 5f61  (gis_embs, gis_a
-00018940: 7474 732c 2074 705f 656d 6229 3a0a 2020  tts, tp_emb):.  
-00018950: 2020 2020 2020 2020 2020 2020 2020 656d                em
-00018960: 6273 2e61 7070 656e 6428 7365 6c66 2e67  bs.append(self.g
-00018970: 6973 3274 6578 7428 6765 202b 2067 7429  is2text(ge + gt)
-00018980: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00018990: 2020 6174 7473 2e61 7070 656e 6428 6761    atts.append(ga
-000189a0: 290a 2020 2020 2020 2020 2020 2020 6d65  ).            me
-000189b0: 7267 655f 656d 6220 3d20 746f 7263 682e  rge_emb = torch.
-000189c0: 6361 7428 656d 6273 2c20 6469 6d3d 3129  cat(embs, dim=1)
-000189d0: 0a20 2020 2020 2020 2020 2020 206d 6572  .            mer
-000189e0: 6765 5f61 7474 656e 7469 6f6e 203d 2074  ge_attention = t
-000189f0: 6f72 6368 2e63 6174 2861 7474 732c 2064  orch.cat(atts, d
-00018a00: 696d 3d2d 3129 0a20 2020 2020 2020 2065  im=-1).        e
-00018a10: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00018a20: 206d 6572 6765 5f65 6d62 203d 2065 6d62   merge_emb = emb
-00018a30: 6564 6469 6e67 5f6f 7574 7075 740a 2020  edding_output.  
-00018a40: 2020 2020 2020 2020 2020 6d65 7267 655f            merge_
-00018a50: 6174 7465 6e74 696f 6e20 3d20 6174 7465  attention = atte
-00018a60: 6e74 696f 6e5f 6d61 736b 0a20 2020 2020  ntion_mask.     
-00018a70: 2020 2065 6e63 6f64 6572 5f6f 7574 7075     encoder_outpu
-00018a80: 7473 203d 2073 656c 662e 7465 7874 5f65  ts = self.text_e
-00018a90: 6e63 6f64 6572 280a 2020 2020 2020 2020  ncoder(.        
-00018aa0: 2020 2020 6174 7465 6e74 696f 6e5f 6d61      attention_ma
-00018ab0: 736b 3d6d 6572 6765 5f61 7474 656e 7469  sk=merge_attenti
-00018ac0: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
-00018ad0: 656e 636f 6465 725f 656d 6265 6473 3d6d  encoder_embeds=m
-00018ae0: 6572 6765 5f65 6d62 2c0a 2020 2020 2020  erge_emb,.      
-00018af0: 2020 2020 2020 6f75 7470 7574 5f61 7474        output_att
-00018b00: 656e 7469 6f6e 733d 6f75 7470 7574 5f61  entions=output_a
-00018b10: 7474 656e 7469 6f6e 732c 0a20 2020 2020  ttentions,.     
-00018b20: 2020 2020 2020 206f 7574 7075 745f 6869         output_hi
-00018b30: 6464 656e 5f73 7461 7465 733d 6f75 7470  dden_states=outp
-00018b40: 7574 5f68 6964 6465 6e5f 7374 6174 6573  ut_hidden_states
-00018b50: 2c0a 2020 2020 2020 2020 2020 2020 7265  ,.            re
-00018b60: 7475 726e 5f64 6963 743d 7265 7475 726e  turn_dict=return
-00018b70: 5f64 6963 742c 0a20 2020 2020 2020 2020  _dict,.         
-00018b80: 2020 206d 6f64 653d 2774 6578 7427 290a     mode='text').
-00018b90: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00018ba0: 7265 7475 726e 5f64 6963 743a 0a20 2020  return_dict:.   
-00018bb0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00018bc0: 656e 636f 6465 725f 6f75 7470 7574 730a  encoder_outputs.
-00018bd0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00018be0: 4174 7465 6e74 696f 6e42 6163 6b62 6f6e  AttentionBackbon
-00018bf0: 654d 6f64 656c 4f75 7470 7574 280a 2020  eModelOutput(.  
-00018c00: 2020 2020 2020 2020 2020 6c61 7374 5f68            last_h
-00018c10: 6964 6465 6e5f 7374 6174 653d 656e 636f  idden_state=enco
-00018c20: 6465 725f 6f75 7470 7574 732e 6c61 7374  der_outputs.last
-00018c30: 5f68 6964 6465 6e5f 7374 6174 652c 0a20  _hidden_state,. 
-00018c40: 2020 2020 2020 2020 2020 2070 6f6f 6c65             poole
-00018c50: 725f 6f75 7470 7574 3d65 6e63 6f64 6572  r_output=encoder
-00018c60: 5f6f 7574 7075 7473 2e70 6f6f 6c65 725f  _outputs.pooler_
-00018c70: 6f75 7470 7574 2c0a 2020 2020 2020 2020  output,.        
-00018c80: 2020 2020 7061 7374 5f6b 6579 5f76 616c      past_key_val
-00018c90: 7565 733d 656e 636f 6465 725f 6f75 7470  ues=encoder_outp
-00018ca0: 7574 732e 7061 7374 5f6b 6579 5f76 616c  uts.past_key_val
-00018cb0: 7565 732c 0a20 2020 2020 2020 2020 2020  ues,.           
-00018cc0: 2068 6964 6465 6e5f 7374 6174 6573 3d65   hidden_states=e
-00018cd0: 6e63 6f64 6572 5f6f 7574 7075 7473 2e68  ncoder_outputs.h
-00018ce0: 6964 6465 6e5f 7374 6174 6573 2c0a 2020  idden_states,.  
-00018cf0: 2020 2020 2020 2020 2020 6174 7465 6e74            attent
-00018d00: 696f 6e73 3d65 6e63 6f64 6572 5f6f 7574  ions=encoder_out
-00018d10: 7075 7473 2e61 7474 656e 7469 6f6e 732c  puts.attentions,
-00018d20: 0a20 2020 2020 2020 2020 2020 2063 726f  .            cro
-00018d30: 7373 5f61 7474 656e 7469 6f6e 733d 656e  ss_attentions=en
-00018d40: 636f 6465 725f 6f75 7470 7574 732e 6372  coder_outputs.cr
-00018d50: 6f73 735f 6174 7465 6e74 696f 6e73 2c0a  oss_attentions,.
-00018d60: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00018d70: 2020 7265 7475 726e 206f 7574 7075 740a    return output.
-00018d80: 0a20 2020 2064 6566 2065 7874 7261 6374  .    def extract
-00018d90: 5f73 6571 7565 6e63 655f 6f75 7470 7574  _sequence_output
-00018da0: 7328 7365 6c66 2c20 6f75 7470 7574 7329  s(self, outputs)
-00018db0: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
-00018dc0: 206f 7574 7075 7473 5b27 6c61 7374 5f68   outputs['last_h
-00018dd0: 6964 6465 6e5f 7374 6174 6527 5d0a 0a20  idden_state'].. 
-00018de0: 2020 2064 6566 2065 7874 7261 6374 5f70     def extract_p
-00018df0: 6f6f 6c65 645f 6f75 7470 7574 7328 7365  ooled_outputs(se
-00018e00: 6c66 2c20 6f75 7470 7574 7329 3a0a 2020  lf, outputs):.  
-00018e10: 2020 2020 2020 7265 7475 726e 206f 7574        return out
-00018e20: 7075 7473 5b27 706f 6f6c 6572 5f6f 7574  puts['pooler_out
-00018e30: 7075 7427 5d0a                           put'].
+00011c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011c50: 2032 5d2c 0a20 2020 2020 2020 2020 2020   2],.           
+00011c60: 2072 656c 6174 6976 655f 706f 7369 7469   relative_positi
+00011c70: 6f6e 5f69 6473 5f6c 6162 656c 5b3a 2c20  on_ids_label[:, 
+00011c80: 3a2c 0a20 2020 2020 2020 2020 2020 2020  :,.             
+00011c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ca0: 2020 2020 2020 2020 2020 2031 5d2c 2072             1], r
+00011cb0: 656c 6174 6976 655f 706f 7369 7469 6f6e  elative_position
+00011cc0: 5f69 6473 5f6c 6162 656c 5b3a 2c20 3a2c  _ids_label[:, :,
+00011cd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011d10: 2020 2020 2020 2020 2033 5d0a 2020 2020           3].    
+00011d20: 2020 2020 5d0a 2020 2020 2020 2020 706f      ].        po
+00011d30: 7369 7469 6f6e 735f 7369 7a65 203d 205b  sitions_size = [
+00011d40: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00011d50: 662e 636f 6e66 6967 2e74 7970 655f 766f  f.config.type_vo
+00011d60: 6361 625f 7369 7a65 2c20 7365 6c66 2e63  cab_size, self.c
+00011d70: 6f6e 6669 672e 7265 6c5f 7479 7065 5f76  onfig.rel_type_v
+00011d80: 6f63 6162 5f73 697a 652c 0a20 2020 2020  ocab_size,.     
+00011d90: 2020 2020 2020 2073 656c 662e 636f 6e66         self.conf
+00011da0: 6967 2e61 6273 6f6c 7574 655f 785f 766f  ig.absolute_x_vo
+00011db0: 6361 625f 7369 7a65 2c0a 2020 2020 2020  cab_size,.      
+00011dc0: 2020 2020 2020 7365 6c66 2e63 6f6e 6669        self.confi
+00011dd0: 672e 6162 736f 6c75 7465 5f78 5f76 6f63  g.absolute_x_voc
+00011de0: 6162 5f73 697a 652c 0a20 2020 2020 2020  ab_size,.       
+00011df0: 2020 2020 2073 656c 662e 636f 6e66 6967       self.config
+00011e00: 2e61 6273 6f6c 7574 655f 795f 766f 6361  .absolute_y_voca
+00011e10: 625f 7369 7a65 2c0a 2020 2020 2020 2020  b_size,.        
+00011e20: 2020 2020 7365 6c66 2e63 6f6e 6669 672e      self.config.
+00011e30: 6162 736f 6c75 7465 5f79 5f76 6f63 6162  absolute_y_vocab
+00011e40: 5f73 697a 652c 0a20 2020 2020 2020 2020  _size,.         
+00011e50: 2020 2073 656c 662e 636f 6e66 6967 2e72     self.config.r
+00011e60: 656c 6174 6976 655f 785f 766f 6361 625f  elative_x_vocab_
+00011e70: 7369 7a65 2c0a 2020 2020 2020 2020 2020  size,.          
+00011e80: 2020 7365 6c66 2e63 6f6e 6669 672e 7265    self.config.re
+00011e90: 6c61 7469 7665 5f78 5f76 6f63 6162 5f73  lative_x_vocab_s
+00011ea0: 697a 652c 0a20 2020 2020 2020 2020 2020  ize,.           
+00011eb0: 2073 656c 662e 636f 6e66 6967 2e72 656c   self.config.rel
+00011ec0: 6174 6976 655f 795f 766f 6361 625f 7369  ative_y_vocab_si
+00011ed0: 7a65 2c0a 2020 2020 2020 2020 2020 2020  ze,.            
+00011ee0: 7365 6c66 2e63 6f6e 6669 672e 7265 6c61  self.config.rela
+00011ef0: 7469 7665 5f79 5f76 6f63 6162 5f73 697a  tive_y_vocab_siz
+00011f00: 650a 2020 2020 2020 2020 5d0a 2020 2020  e.        ].    
+00011f10: 2020 2020 666f 7220 6d79 636c 732c 206d      for mycls, m
+00011f20: 796c 6162 656c 732c 206d 7973 697a 6520  ylabels, mysize 
+00011f30: 696e 207a 6970 2870 6f73 6974 696f 6e73  in zip(positions
+00011f40: 5f63 6c73 2c20 706f 7369 7469 6f6e 735f  _cls, positions_
+00011f50: 6c61 6265 6c2c 0a20 2020 2020 2020 2020  label,.         
+00011f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f80: 2020 706f 7369 7469 6f6e 735f 7369 7a65    positions_size
+00011f90: 293a 0a20 2020 2020 2020 2020 2020 2069  ):.            i
+00011fa0: 6620 6d79 6c61 6265 6c73 2069 7320 6e6f  f mylabels is no
+00011fb0: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+00011fc0: 2020 2020 2020 2020 6d79 7072 6564 6963          mypredic
+00011fd0: 7469 6f6e 5f73 636f 7265 7320 3d20 6d79  tion_scores = my
+00011fe0: 636c 7328 7365 7175 656e 6365 5f6f 7574  cls(sequence_out
+00011ff0: 7075 7429 0a20 2020 2020 2020 2020 2020  put).           
+00012000: 2020 2020 206d 6173 6b65 645f 6c6d 5f6c       masked_lm_l
+00012010: 6f73 7320 2b3d 206c 6f73 735f 6663 7428  oss += loss_fct(
+00012020: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012030: 2020 2020 206d 7970 7265 6469 6374 696f       mypredictio
+00012040: 6e5f 7363 6f72 6573 2e76 6965 7728 2d31  n_scores.view(-1
+00012050: 2c20 6d79 7369 7a65 292c 206d 796c 6162  , mysize), mylab
+00012060: 656c 732e 7669 6577 282d 3129 290a 0a20  els.view(-1)).. 
+00012070: 2020 2020 2020 2069 6620 6e6f 7420 7265         if not re
+00012080: 7475 726e 5f64 6963 743a 0a20 2020 2020  turn_dict:.     
+00012090: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+000120a0: 2870 7265 6469 6374 696f 6e5f 7363 6f72  (prediction_scor
+000120b0: 6573 2c20 2920 2b20 6f75 7470 7574 735b  es, ) + outputs[
+000120c0: 323a 5d0a 2020 2020 2020 2020 2020 2020  2:].            
+000120d0: 7265 7475 726e 2028 286d 6173 6b65 645f  return ((masked_
+000120e0: 6c6d 5f6c 6f73 732c 2029 0a20 2020 2020  lm_loss, ).     
+000120f0: 2020 2020 2020 2020 2020 2020 2020 202b                 +
+00012100: 206f 7574 7075 7429 2069 6620 6d61 736b   output) if mask
+00012110: 6564 5f6c 6d5f 6c6f 7373 2069 7320 6e6f  ed_lm_loss is no
+00012120: 7420 4e6f 6e65 2065 6c73 6520 6f75 7470  t None else outp
+00012130: 7574 0a0a 2020 2020 2020 2020 7265 7475  ut..        retu
+00012140: 726e 204d 6173 6b65 644c 4d4f 7574 7075  rn MaskedLMOutpu
+00012150: 7428 0a20 2020 2020 2020 2020 2020 206c  t(.            l
+00012160: 6f73 733d 6d61 736b 6564 5f6c 6d5f 6c6f  oss=masked_lm_lo
+00012170: 7373 2c0a 2020 2020 2020 2020 2020 2020  ss,.            
+00012180: 6c6f 6769 7473 3d70 7265 6469 6374 696f  logits=predictio
+00012190: 6e5f 7363 6f72 6573 2c0a 2020 2020 2020  n_scores,.      
+000121a0: 2020 2020 2020 6869 6464 656e 5f73 7461        hidden_sta
+000121b0: 7465 733d 6f75 7470 7574 732e 6869 6464  tes=outputs.hidd
+000121c0: 656e 5f73 7461 7465 732c 0a20 2020 2020  en_states,.     
+000121d0: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
+000121e0: 733d 6f75 7470 7574 732e 6174 7465 6e74  s=outputs.attent
+000121f0: 696f 6e73 2c0a 2020 2020 2020 2020 290a  ions,.        ).
+00012200: 0a20 2020 2064 6566 2070 7265 7061 7265  .    def prepare
+00012210: 5f69 6e70 7574 735f 666f 725f 6765 6e65  _inputs_for_gene
+00012220: 7261 7469 6f6e 2873 656c 662c 0a20 2020  ration(self,.   
+00012230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012250: 2020 2069 6e70 7574 5f69 6473 2c0a 2020     input_ids,.  
+00012260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012280: 2020 2020 6174 7465 6e74 696f 6e5f 6d61      attention_ma
+00012290: 736b 3d4e 6f6e 652c 0a20 2020 2020 2020  sk=None,.       
+000122a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000122b0: 2020 2020 2020 2020 2020 2020 2020 202a                 *
+000122c0: 2a6d 6f64 656c 5f6b 7761 7267 7329 3a0a  *model_kwargs):.
+000122d0: 2020 2020 2020 2020 696e 7075 745f 7368          input_sh
+000122e0: 6170 6520 3d20 696e 7075 745f 6964 732e  ape = input_ids.
+000122f0: 7368 6170 650a 2020 2020 2020 2020 6566  shape.        ef
+00012300: 6665 6374 6976 655f 6261 7463 685f 7369  fective_batch_si
+00012310: 7a65 203d 2069 6e70 7574 5f73 6861 7065  ze = input_shape
+00012320: 5b30 5d0a 0a20 2020 2020 2020 2023 2020  [0]..        #  
+00012330: 6164 6420 6120 6475 6d6d 7920 746f 6b65  add a dummy toke
+00012340: 6e0a 2020 2020 2020 2020 6173 7365 7274  n.        assert
+00012350: 2073 656c 662e 636f 6e66 6967 2e70 6164   self.config.pad
+00012360: 5f74 6f6b 656e 5f69 6420 6973 206e 6f74  _token_id is not
+00012370: 204e 6f6e 652c 2027 5468 6520 5041 4420   None, 'The PAD 
+00012380: 746f 6b65 6e20 7368 6f75 6c64 2062 6520  token should be 
+00012390: 6465 6669 6e65 6420 666f 7220 6765 6e65  defined for gene
+000123a0: 7261 7469 6f6e 270a 2020 2020 2020 2020  ration'.        
+000123b0: 7061 6464 696e 675f 6d61 736b 203d 2061  padding_mask = a
+000123c0: 7474 656e 7469 6f6e 5f6d 6173 6b2e 6e65  ttention_mask.ne
+000123d0: 775f 7a65 726f 7328 2861 7474 656e 7469  w_zeros((attenti
+000123e0: 6f6e 5f6d 6173 6b2e 7368 6170 655b 305d  on_mask.shape[0]
+000123f0: 2c20 3129 290a 2020 2020 2020 2020 6174  , 1)).        at
+00012400: 7465 6e74 696f 6e5f 6d61 736b 203d 2074  tention_mask = t
+00012410: 6f72 6368 2e63 6174 285b 6174 7465 6e74  orch.cat([attent
+00012420: 696f 6e5f 6d61 736b 2c20 7061 6464 696e  ion_mask, paddin
+00012430: 675f 6d61 736b 5d2c 2064 696d 3d2d 3129  g_mask], dim=-1)
+00012440: 0a20 2020 2020 2020 2064 756d 6d79 5f74  .        dummy_t
+00012450: 6f6b 656e 203d 2074 6f72 6368 2e66 756c  oken = torch.ful
+00012460: 6c28 2865 6666 6563 7469 7665 5f62 6174  l((effective_bat
+00012470: 6368 5f73 697a 652c 2031 292c 0a20 2020  ch_size, 1),.   
+00012480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012490: 2020 2020 2020 2020 2020 2020 2020 7365                se
+000124a0: 6c66 2e63 6f6e 6669 672e 7061 645f 746f  lf.config.pad_to
+000124b0: 6b65 6e5f 6964 2c0a 2020 2020 2020 2020  ken_id,.        
+000124c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000124d0: 2020 2020 2020 2020 2064 7479 7065 3d74           dtype=t
+000124e0: 6f72 6368 2e6c 6f6e 672c 0a20 2020 2020  orch.long,.     
+000124f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012500: 2020 2020 2020 2020 2020 2020 6465 7669              devi
+00012510: 6365 3d69 6e70 7574 5f69 6473 2e64 6576  ce=input_ids.dev
+00012520: 6963 6529 0a20 2020 2020 2020 2069 6e70  ice).        inp
+00012530: 7574 5f69 6473 203d 2074 6f72 6368 2e63  ut_ids = torch.c
+00012540: 6174 285b 696e 7075 745f 6964 732c 2064  at([input_ids, d
+00012550: 756d 6d79 5f74 6f6b 656e 5d2c 2064 696d  ummy_token], dim
+00012560: 3d31 290a 0a20 2020 2020 2020 2072 6574  =1)..        ret
+00012570: 7572 6e20 7b27 696e 7075 745f 6964 7327  urn {'input_ids'
+00012580: 3a20 696e 7075 745f 6964 732c 2027 6174  : input_ids, 'at
+00012590: 7465 6e74 696f 6e5f 6d61 736b 273a 2061  tention_mask': a
+000125a0: 7474 656e 7469 6f6e 5f6d 6173 6b7d 0a0a  ttention_mask}..
+000125b0: 0a63 6c61 7373 2042 6572 7446 6f72 4d61  .class BertForMa
+000125c0: 736b 6564 4c4d 2842 6572 7450 7265 5472  skedLM(BertPreTr
+000125d0: 6169 6e65 644d 6f64 656c 293a 0a0a 2020  ainedModel):..  
+000125e0: 2020 5f6b 6579 735f 746f 5f69 676e 6f72    _keys_to_ignor
+000125f0: 655f 6f6e 5f6c 6f61 645f 756e 6578 7065  e_on_load_unexpe
+00012600: 6374 6564 203d 205b 7227 706f 6f6c 6572  cted = [r'pooler
+00012610: 275d 0a20 2020 205f 6b65 7973 5f74 6f5f  '].    _keys_to_
+00012620: 6967 6e6f 7265 5f6f 6e5f 6c6f 6164 5f6d  ignore_on_load_m
+00012630: 6973 7369 6e67 203d 205b 0a20 2020 2020  issing = [.     
+00012640: 2020 2072 2770 6f73 6974 696f 6e5f 6964     r'position_id
+00012650: 7327 2c20 7227 7072 6564 6963 7469 6f6e  s', r'prediction
+00012660: 732e 6465 636f 6465 722e 6269 6173 270a  s.decoder.bias'.
+00012670: 2020 2020 5d0a 0a20 2020 2064 6566 205f      ]..    def _
+00012680: 5f69 6e69 745f 5f28 7365 6c66 2c20 636f  _init__(self, co
+00012690: 6e66 6967 293a 0a20 2020 2020 2020 2073  nfig):.        s
+000126a0: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+000126b0: 636f 6e66 6967 290a 0a20 2020 2020 2020  config)..       
+000126c0: 2073 656c 662e 6265 7274 203d 2042 6572   self.bert = Ber
+000126d0: 744d 6f64 656c 2863 6f6e 6669 672c 2061  tModel(config, a
+000126e0: 6464 5f70 6f6f 6c69 6e67 5f6c 6179 6572  dd_pooling_layer
+000126f0: 3d46 616c 7365 290a 2020 2020 2020 2020  =False).        
+00012700: 7365 6c66 2e63 6c73 203d 2042 6572 744f  self.cls = BertO
+00012710: 6e6c 794d 4c4d 4865 6164 2863 6f6e 6669  nlyMLMHead(confi
+00012720: 6729 0a0a 2020 2020 2020 2020 7365 6c66  g)..        self
+00012730: 2e69 6e69 745f 7765 6967 6874 7328 290a  .init_weights().
+00012740: 0a20 2020 2064 6566 2067 6574 5f6f 7574  .    def get_out
+00012750: 7075 745f 656d 6265 6464 696e 6773 2873  put_embeddings(s
+00012760: 656c 6629 3a0a 2020 2020 2020 2020 7265  elf):.        re
+00012770: 7475 726e 2073 656c 662e 636c 732e 7072  turn self.cls.pr
+00012780: 6564 6963 7469 6f6e 732e 6465 636f 6465  edictions.decode
+00012790: 720a 0a20 2020 2064 6566 2073 6574 5f6f  r..    def set_o
+000127a0: 7574 7075 745f 656d 6265 6464 696e 6773  utput_embeddings
+000127b0: 2873 656c 662c 206e 6577 5f65 6d62 6564  (self, new_embed
+000127c0: 6469 6e67 7329 3a0a 2020 2020 2020 2020  dings):.        
+000127d0: 7365 6c66 2e63 6c73 2e70 7265 6469 6374  self.cls.predict
+000127e0: 696f 6e73 2e64 6563 6f64 6572 203d 206e  ions.decoder = n
+000127f0: 6577 5f65 6d62 6564 6469 6e67 730a 0a20  ew_embeddings.. 
+00012800: 2020 2064 6566 2066 6f72 7761 7264 280a     def forward(.
+00012810: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00012820: 2020 2020 2020 696e 7075 745f 6964 733d        input_ids=
+00012830: 4e6f 6e65 2c0a 2020 2020 2020 2020 6174  None,.        at
+00012840: 7465 6e74 696f 6e5f 6d61 736b 3d4e 6f6e  tention_mask=Non
+00012850: 652c 0a20 2020 2020 2020 2074 6f6b 656e  e,.        token
+00012860: 5f74 7970 655f 6964 733d 4e6f 6e65 2c0a  _type_ids=None,.
+00012870: 2020 2020 2020 2020 706f 7369 7469 6f6e          position
+00012880: 5f69 6473 3d4e 6f6e 652c 0a20 2020 2020  _ids=None,.     
+00012890: 2020 2068 6561 645f 6d61 736b 3d4e 6f6e     head_mask=Non
+000128a0: 652c 0a20 2020 2020 2020 2069 6e70 7574  e,.        input
+000128b0: 735f 656d 6265 6473 3d4e 6f6e 652c 0a20  s_embeds=None,. 
+000128c0: 2020 2020 2020 2065 6e63 6f64 6572 5f65         encoder_e
+000128d0: 6d62 6564 733d 4e6f 6e65 2c0a 2020 2020  mbeds=None,.    
+000128e0: 2020 2020 656e 636f 6465 725f 6869 6464      encoder_hidd
+000128f0: 656e 5f73 7461 7465 733d 4e6f 6e65 2c0a  en_states=None,.
+00012900: 2020 2020 2020 2020 656e 636f 6465 725f          encoder_
+00012910: 6174 7465 6e74 696f 6e5f 6d61 736b 3d4e  attention_mask=N
+00012920: 6f6e 652c 0a20 2020 2020 2020 206c 6162  one,.        lab
+00012930: 656c 733d 4e6f 6e65 2c0a 2020 2020 2020  els=None,.      
+00012940: 2020 6f75 7470 7574 5f61 7474 656e 7469    output_attenti
+00012950: 6f6e 733d 4e6f 6e65 2c0a 2020 2020 2020  ons=None,.      
+00012960: 2020 6f75 7470 7574 5f68 6964 6465 6e5f    output_hidden_
+00012970: 7374 6174 6573 3d4e 6f6e 652c 0a20 2020  states=None,.   
+00012980: 2020 2020 2072 6574 7572 6e5f 6469 6374       return_dict
+00012990: 3d4e 6f6e 652c 0a20 2020 2020 2020 2069  =None,.        i
+000129a0: 735f 6465 636f 6465 723d 4661 6c73 652c  s_decoder=False,
+000129b0: 0a20 2020 2020 2020 206d 6f64 653d 276d  .        mode='m
+000129c0: 756c 7469 5f6d 6f64 616c 272c 0a20 2020  ulti_modal',.   
+000129d0: 2020 2020 2073 6f66 745f 6c61 6265 6c73       soft_labels
+000129e0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2061  =None,.        a
+000129f0: 6c70 6861 3d30 2c0a 2020 2020 2020 2020  lpha=0,.        
+00012a00: 7265 7475 726e 5f6c 6f67 6974 733d 4661  return_logits=Fa
+00012a10: 6c73 652c 0a20 2020 2020 2020 2072 656c  lse,.        rel
+00012a20: 5f74 7970 655f 6964 733d 4e6f 6e65 2c0a  _type_ids=None,.
+00012a30: 2020 2020 2020 2020 6162 736f 6c75 7465          absolute
+00012a40: 5f70 6f73 6974 696f 6e5f 6964 733d 4e6f  _position_ids=No
+00012a50: 6e65 2c0a 2020 2020 2020 2020 7265 6c61  ne,.        rela
+00012a60: 7469 7665 5f70 6f73 6974 696f 6e5f 6964  tive_position_id
+00012a70: 733d 4e6f 6e65 2c0a 2020 2020 293a 0a20  s=None,.    ):. 
+00012a80: 2020 2020 2020 2072 2222 220a 2020 2020         r""".    
+00012a90: 2020 2020 6c61 6265 6c73 2028 3a6f 626a      labels (:obj
+00012aa0: 3a60 746f 7263 682e 4c6f 6e67 5465 6e73  :`torch.LongTens
+00012ab0: 6f72 6020 6f66 2073 6861 7065 203a 6f62  or` of shape :ob
+00012ac0: 6a3a 6028 6261 7463 685f 7369 7a65 2c20  j:`(batch_size, 
+00012ad0: 7365 7175 656e 6365 5f6c 656e 6774 6829  sequence_length)
+00012ae0: 602c 2060 6f70 7469 6f6e 616c 6029 3a0a  `, `optional`):.
+00012af0: 2020 2020 2020 2020 2020 2020 4c61 6265              Labe
+00012b00: 6c73 2066 6f72 2063 6f6d 7075 7469 6e67  ls for computing
+00012b10: 2074 6865 206d 6173 6b65 6420 6c61 6e67   the masked lang
+00012b20: 7561 6765 206d 6f64 656c 696e 6720 6c6f  uage modeling lo
+00012b30: 7373 2e20 496e 6469 6365 7320 7368 6f75  ss. Indices shou
+00012b40: 6c64 2062 6520 696e 2060 605b 2d31 3030  ld be in ``[-100
+00012b50: 2c20 302c 202e 2e2e 2c0a 2020 2020 2020  , 0, ...,.      
+00012b60: 2020 2020 2020 636f 6e66 6967 2e76 6f63        config.voc
+00012b70: 6162 5f73 697a 655d 6060 2028 7365 6520  ab_size]`` (see 
+00012b80: 6060 696e 7075 745f 6964 7360 6020 646f  ``input_ids`` do
+00012b90: 6373 7472 696e 6729 2054 6f6b 656e 7320  cstring) Tokens 
+00012ba0: 7769 7468 2069 6e64 6963 6573 2073 6574  with indices set
+00012bb0: 2074 6f20 6060 2d31 3030 6060 2061 7265   to ``-100`` are
+00012bc0: 2069 676e 6f72 6564 0a20 2020 2020 2020   ignored.       
+00012bd0: 2020 2020 2028 6d61 736b 6564 292c 2074       (masked), t
+00012be0: 6865 206c 6f73 7320 6973 206f 6e6c 7920  he loss is only 
+00012bf0: 636f 6d70 7574 6564 2066 6f72 2074 6865  computed for the
+00012c00: 2074 6f6b 656e 7320 7769 7468 206c 6162   tokens with lab
+00012c10: 656c 7320 696e 2060 605b 302c 202e 2e2e  els in ``[0, ...
+00012c20: 2c20 636f 6e66 6967 2e76 6f63 6162 5f73  , config.vocab_s
+00012c30: 697a 655d 6060 0a20 2020 2020 2020 2022  ize]``.        "
+00012c40: 2222 0a0a 2020 2020 2020 2020 7265 7475  ""..        retu
+00012c50: 726e 5f64 6963 7420 3d20 7265 7475 726e  rn_dict = return
+00012c60: 5f64 6963 7420 6966 2072 6574 7572 6e5f  _dict if return_
+00012c70: 6469 6374 2069 7320 6e6f 7420 4e6f 6e65  dict is not None
+00012c80: 2065 6c73 6520 7365 6c66 2e63 6f6e 6669   else self.confi
+00012c90: 672e 7573 655f 7265 7475 726e 5f64 6963  g.use_return_dic
+00012ca0: 740a 0a20 2020 2020 2020 206f 7574 7075  t..        outpu
+00012cb0: 7473 203d 2073 656c 662e 6265 7274 280a  ts = self.bert(.
+00012cc0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00012cd0: 745f 6964 732c 0a20 2020 2020 2020 2020  t_ids,.         
+00012ce0: 2020 2061 7474 656e 7469 6f6e 5f6d 6173     attention_mas
+00012cf0: 6b3d 6174 7465 6e74 696f 6e5f 6d61 736b  k=attention_mask
+00012d00: 2c0a 2020 2020 2020 2020 2020 2020 746f  ,.            to
+00012d10: 6b65 6e5f 7479 7065 5f69 6473 3d74 6f6b  ken_type_ids=tok
+00012d20: 656e 5f74 7970 655f 6964 732c 0a20 2020  en_type_ids,.   
+00012d30: 2020 2020 2020 2020 2070 6f73 6974 696f           positio
+00012d40: 6e5f 6964 733d 706f 7369 7469 6f6e 5f69  n_ids=position_i
+00012d50: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
+00012d60: 6865 6164 5f6d 6173 6b3d 6865 6164 5f6d  head_mask=head_m
+00012d70: 6173 6b2c 0a20 2020 2020 2020 2020 2020  ask,.           
+00012d80: 2069 6e70 7574 735f 656d 6265 6473 3d69   inputs_embeds=i
+00012d90: 6e70 7574 735f 656d 6265 6473 2c0a 2020  nputs_embeds,.  
+00012da0: 2020 2020 2020 2020 2020 656e 636f 6465            encode
+00012db0: 725f 656d 6265 6473 3d65 6e63 6f64 6572  r_embeds=encoder
+00012dc0: 5f65 6d62 6564 732c 0a20 2020 2020 2020  _embeds,.       
+00012dd0: 2020 2020 2065 6e63 6f64 6572 5f68 6964       encoder_hid
+00012de0: 6465 6e5f 7374 6174 6573 3d65 6e63 6f64  den_states=encod
+00012df0: 6572 5f68 6964 6465 6e5f 7374 6174 6573  er_hidden_states
+00012e00: 2c0a 2020 2020 2020 2020 2020 2020 656e  ,.            en
+00012e10: 636f 6465 725f 6174 7465 6e74 696f 6e5f  coder_attention_
+00012e20: 6d61 736b 3d65 6e63 6f64 6572 5f61 7474  mask=encoder_att
+00012e30: 656e 7469 6f6e 5f6d 6173 6b2c 0a20 2020  ention_mask,.   
+00012e40: 2020 2020 2020 2020 206f 7574 7075 745f           output_
+00012e50: 6174 7465 6e74 696f 6e73 3d6f 7574 7075  attentions=outpu
+00012e60: 745f 6174 7465 6e74 696f 6e73 2c0a 2020  t_attentions,.  
+00012e70: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00012e80: 5f68 6964 6465 6e5f 7374 6174 6573 3d6f  _hidden_states=o
+00012e90: 7574 7075 745f 6869 6464 656e 5f73 7461  utput_hidden_sta
+00012ea0: 7465 732c 0a20 2020 2020 2020 2020 2020  tes,.           
+00012eb0: 2072 6574 7572 6e5f 6469 6374 3d72 6574   return_dict=ret
+00012ec0: 7572 6e5f 6469 6374 2c0a 2020 2020 2020  urn_dict,.      
+00012ed0: 2020 2020 2020 6973 5f64 6563 6f64 6572        is_decoder
+00012ee0: 3d69 735f 6465 636f 6465 722c 0a20 2020  =is_decoder,.   
+00012ef0: 2020 2020 2020 2020 206d 6f64 653d 6d6f           mode=mo
+00012f00: 6465 2c0a 2020 2020 2020 2020 2020 2020  de,.            
+00012f10: 7265 6c5f 7479 7065 5f69 6473 3d72 656c  rel_type_ids=rel
+00012f20: 5f74 7970 655f 6964 732c 0a20 2020 2020  _type_ids,.     
+00012f30: 2020 2020 2020 2061 6273 6f6c 7574 655f         absolute_
+00012f40: 706f 7369 7469 6f6e 5f69 6473 3d61 6273  position_ids=abs
+00012f50: 6f6c 7574 655f 706f 7369 7469 6f6e 5f69  olute_position_i
+00012f60: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
+00012f70: 7265 6c61 7469 7665 5f70 6f73 6974 696f  relative_positio
+00012f80: 6e5f 6964 733d 7265 6c61 7469 7665 5f70  n_ids=relative_p
+00012f90: 6f73 6974 696f 6e5f 6964 732c 0a20 2020  osition_ids,.   
+00012fa0: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
+00012fb0: 7365 7175 656e 6365 5f6f 7574 7075 7420  sequence_output 
+00012fc0: 3d20 6f75 7470 7574 735b 305d 0a20 2020  = outputs[0].   
+00012fd0: 2020 2020 2070 7265 6469 6374 696f 6e5f       prediction_
+00012fe0: 7363 6f72 6573 203d 2073 656c 662e 636c  scores = self.cl
+00012ff0: 7328 7365 7175 656e 6365 5f6f 7574 7075  s(sequence_outpu
+00013000: 7429 0a0a 2020 2020 2020 2020 6966 2072  t)..        if r
+00013010: 6574 7572 6e5f 6c6f 6769 7473 3a0a 2020  eturn_logits:.  
+00013020: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00013030: 2070 7265 6469 6374 696f 6e5f 7363 6f72   prediction_scor
+00013040: 6573 0a0a 2020 2020 2020 2020 6d61 736b  es..        mask
+00013050: 6564 5f6c 6d5f 6c6f 7373 203d 204e 6f6e  ed_lm_loss = Non
+00013060: 650a 2020 2020 2020 2020 6966 206c 6162  e.        if lab
+00013070: 656c 7320 6973 206e 6f74 204e 6f6e 653a  els is not None:
+00013080: 0a20 2020 2020 2020 2020 2020 206c 6f73  .            los
+00013090: 735f 6663 7420 3d20 4372 6f73 7345 6e74  s_fct = CrossEnt
+000130a0: 726f 7079 4c6f 7373 2829 2020 2320 2d31  ropyLoss()  # -1
+000130b0: 3030 2069 6e64 6578 203d 2070 6164 6469  00 index = paddi
+000130c0: 6e67 2074 6f6b 656e 0a20 2020 2020 2020  ng token.       
+000130d0: 2020 2020 206d 6173 6b65 645f 6c6d 5f6c       masked_lm_l
+000130e0: 6f73 7320 3d20 6c6f 7373 5f66 6374 280a  oss = loss_fct(.
+000130f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013100: 7072 6564 6963 7469 6f6e 5f73 636f 7265  prediction_score
+00013110: 732e 7669 6577 282d 312c 2073 656c 662e  s.view(-1, self.
+00013120: 636f 6e66 6967 2e76 6f63 6162 5f73 697a  config.vocab_siz
+00013130: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
+00013140: 2020 2020 6c61 6265 6c73 2e76 6965 7728      labels.view(
+00013150: 2d31 2929 0a0a 2020 2020 2020 2020 6966  -1))..        if
+00013160: 2073 6f66 745f 6c61 6265 6c73 2069 7320   soft_labels is 
+00013170: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00013180: 2020 2020 2020 6c6f 7373 5f64 6973 7469        loss_disti
+00013190: 6c6c 203d 202d 746f 7263 682e 7375 6d28  ll = -torch.sum(
+000131a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000131b0: 2046 2e6c 6f67 5f73 6f66 746d 6178 2870   F.log_softmax(p
+000131c0: 7265 6469 6374 696f 6e5f 7363 6f72 6573  rediction_scores
+000131d0: 2c20 6469 6d3d 2d31 2920 2a20 736f 6674  , dim=-1) * soft
+000131e0: 5f6c 6162 656c 732c 2064 696d 3d2d 3129  _labels, dim=-1)
+000131f0: 0a20 2020 2020 2020 2020 2020 206c 6f73  .            los
+00013200: 735f 6469 7374 696c 6c20 3d20 6c6f 7373  s_distill = loss
+00013210: 5f64 6973 7469 6c6c 5b6c 6162 656c 7320  _distill[labels 
+00013220: 213d 202d 3130 305d 2e6d 6561 6e28 290a  != -100].mean().
+00013230: 2020 2020 2020 2020 2020 2020 6d61 736b              mask
+00013240: 6564 5f6c 6d5f 6c6f 7373 203d 2028 310a  ed_lm_loss = (1.
+00013250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013260: 2020 2020 2020 2020 2020 2020 2020 2d20                - 
+00013270: 616c 7068 6129 202a 206d 6173 6b65 645f  alpha) * masked_
+00013280: 6c6d 5f6c 6f73 7320 2b20 616c 7068 6120  lm_loss + alpha 
+00013290: 2a20 6c6f 7373 5f64 6973 7469 6c6c 0a0a  * loss_distill..
+000132a0: 2020 2020 2020 2020 6966 206e 6f74 2072          if not r
+000132b0: 6574 7572 6e5f 6469 6374 3a0a 2020 2020  eturn_dict:.    
+000132c0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000132d0: 2028 7072 6564 6963 7469 6f6e 5f73 636f   (prediction_sco
+000132e0: 7265 732c 2029 202b 206f 7574 7075 7473  res, ) + outputs
+000132f0: 5b32 3a5d 0a20 2020 2020 2020 2020 2020  [2:].           
+00013300: 2072 6574 7572 6e20 2828 6d61 736b 6564   return ((masked
+00013310: 5f6c 6d5f 6c6f 7373 2c20 290a 2020 2020  _lm_loss, ).    
+00013320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013330: 2b20 6f75 7470 7574 2920 6966 206d 6173  + output) if mas
+00013340: 6b65 645f 6c6d 5f6c 6f73 7320 6973 206e  ked_lm_loss is n
+00013350: 6f74 204e 6f6e 6520 656c 7365 206f 7574  ot None else out
+00013360: 7075 740a 0a20 2020 2020 2020 2072 6574  put..        ret
+00013370: 7572 6e20 4d61 736b 6564 4c4d 4f75 7470  urn MaskedLMOutp
+00013380: 7574 280a 2020 2020 2020 2020 2020 2020  ut(.            
+00013390: 6c6f 7373 3d6d 6173 6b65 645f 6c6d 5f6c  loss=masked_lm_l
+000133a0: 6f73 732c 0a20 2020 2020 2020 2020 2020  oss,.           
+000133b0: 206c 6f67 6974 733d 7072 6564 6963 7469   logits=predicti
+000133c0: 6f6e 5f73 636f 7265 732c 0a20 2020 2020  on_scores,.     
+000133d0: 2020 2020 2020 2068 6964 6465 6e5f 7374         hidden_st
+000133e0: 6174 6573 3d6f 7574 7075 7473 2e68 6964  ates=outputs.hid
+000133f0: 6465 6e5f 7374 6174 6573 2c0a 2020 2020  den_states,.    
+00013400: 2020 2020 2020 2020 6174 7465 6e74 696f          attentio
+00013410: 6e73 3d6f 7574 7075 7473 2e61 7474 656e  ns=outputs.atten
+00013420: 7469 6f6e 732c 0a20 2020 2020 2020 2029  tions,.        )
+00013430: 0a0a 2020 2020 6465 6620 7072 6570 6172  ..    def prepar
+00013440: 655f 696e 7075 7473 5f66 6f72 5f67 656e  e_inputs_for_gen
+00013450: 6572 6174 696f 6e28 7365 6c66 2c0a 2020  eration(self,.  
+00013460: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013480: 2020 2020 696e 7075 745f 6964 732c 0a20      input_ids,. 
+00013490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000134a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000134b0: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
+000134c0: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
+000134d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000134e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000134f0: 2a2a 6d6f 6465 6c5f 6b77 6172 6773 293a  **model_kwargs):
+00013500: 0a20 2020 2020 2020 2069 6e70 7574 5f73  .        input_s
+00013510: 6861 7065 203d 2069 6e70 7574 5f69 6473  hape = input_ids
+00013520: 2e73 6861 7065 0a20 2020 2020 2020 2065  .shape.        e
+00013530: 6666 6563 7469 7665 5f62 6174 6368 5f73  ffective_batch_s
+00013540: 697a 6520 3d20 696e 7075 745f 7368 6170  ize = input_shap
+00013550: 655b 305d 0a0a 2020 2020 2020 2020 2320  e[0]..        # 
+00013560: 2061 6464 2061 2064 756d 6d79 2074 6f6b   add a dummy tok
+00013570: 656e 0a20 2020 2020 2020 2061 7373 6572  en.        asser
+00013580: 7420 7365 6c66 2e63 6f6e 6669 672e 7061  t self.config.pa
+00013590: 645f 746f 6b65 6e5f 6964 2069 7320 6e6f  d_token_id is no
+000135a0: 7420 4e6f 6e65 2c20 2754 6865 2050 4144  t None, 'The PAD
+000135b0: 2074 6f6b 656e 2073 686f 756c 6420 6265   token should be
+000135c0: 2064 6566 696e 6564 2066 6f72 2067 656e   defined for gen
+000135d0: 6572 6174 696f 6e27 0a0a 2020 2020 2020  eration'..      
+000135e0: 2020 7061 6464 696e 675f 6d61 736b 203d    padding_mask =
+000135f0: 2061 7474 656e 7469 6f6e 5f6d 6173 6b2e   attention_mask.
+00013600: 6e65 775f 7a65 726f 7328 2861 7474 656e  new_zeros((atten
+00013610: 7469 6f6e 5f6d 6173 6b2e 7368 6170 655b  tion_mask.shape[
+00013620: 305d 2c20 3129 290a 2020 2020 2020 2020  0], 1)).        
+00013630: 6174 7465 6e74 696f 6e5f 6d61 736b 203d  attention_mask =
+00013640: 2074 6f72 6368 2e63 6174 285b 6174 7465   torch.cat([atte
+00013650: 6e74 696f 6e5f 6d61 736b 2c20 7061 6464  ntion_mask, padd
+00013660: 696e 675f 6d61 736b 5d2c 2064 696d 3d2d  ing_mask], dim=-
+00013670: 3129 0a20 2020 2020 2020 2064 756d 6d79  1).        dummy
+00013680: 5f74 6f6b 656e 203d 2074 6f72 6368 2e66  _token = torch.f
+00013690: 756c 6c28 2865 6666 6563 7469 7665 5f62  ull((effective_b
+000136a0: 6174 6368 5f73 697a 652c 2031 292c 0a20  atch_size, 1),. 
+000136b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000136c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000136d0: 7365 6c66 2e63 6f6e 6669 672e 7061 645f  self.config.pad_
+000136e0: 746f 6b65 6e5f 6964 2c0a 2020 2020 2020  token_id,.      
+000136f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013700: 2020 2020 2020 2020 2020 2064 7479 7065             dtype
+00013710: 3d74 6f72 6368 2e6c 6f6e 672c 0a20 2020  =torch.long,.   
+00013720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013730: 2020 2020 2020 2020 2020 2020 2020 6465                de
+00013740: 7669 6365 3d69 6e70 7574 5f69 6473 2e64  vice=input_ids.d
+00013750: 6576 6963 6529 0a20 2020 2020 2020 2069  evice).        i
+00013760: 6e70 7574 5f69 6473 203d 2074 6f72 6368  nput_ids = torch
+00013770: 2e63 6174 285b 696e 7075 745f 6964 732c  .cat([input_ids,
+00013780: 2064 756d 6d79 5f74 6f6b 656e 5d2c 2064   dummy_token], d
+00013790: 696d 3d31 290a 0a20 2020 2020 2020 2072  im=1)..        r
+000137a0: 6574 7572 6e20 7b27 696e 7075 745f 6964  eturn {'input_id
+000137b0: 7327 3a20 696e 7075 745f 6964 732c 2027  s': input_ids, '
+000137c0: 6174 7465 6e74 696f 6e5f 6d61 736b 273a  attention_mask':
+000137d0: 2061 7474 656e 7469 6f6e 5f6d 6173 6b7d   attention_mask}
+000137e0: 0a0a 0a63 6c61 7373 2042 6572 7446 6f72  ...class BertFor
+000137f0: 4e65 7874 5365 6e74 656e 6365 5072 6564  NextSentencePred
+00013800: 6963 7469 6f6e 2842 6572 7450 7265 5472  iction(BertPreTr
+00013810: 6169 6e65 644d 6f64 656c 293a 0a0a 2020  ainedModel):..  
+00013820: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
+00013830: 656c 662c 2063 6f6e 6669 6729 3a0a 2020  elf, config):.  
+00013840: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
+00013850: 696e 6974 5f5f 2863 6f6e 6669 6729 0a0a  init__(config)..
+00013860: 2020 2020 2020 2020 7365 6c66 2e62 6572          self.ber
+00013870: 7420 3d20 4265 7274 4d6f 6465 6c28 636f  t = BertModel(co
+00013880: 6e66 6967 290a 2020 2020 2020 2020 7365  nfig).        se
+00013890: 6c66 2e63 6c73 203d 2042 6572 744f 6e6c  lf.cls = BertOnl
+000138a0: 794e 5350 4865 6164 2863 6f6e 6669 6729  yNSPHead(config)
+000138b0: 0a0a 2020 2020 2020 2020 7365 6c66 2e69  ..        self.i
+000138c0: 6e69 745f 7765 6967 6874 7328 290a 0a20  nit_weights().. 
+000138d0: 2020 2064 6566 2066 6f72 7761 7264 2873     def forward(s
+000138e0: 656c 662c 0a20 2020 2020 2020 2020 2020  elf,.           
+000138f0: 2020 2020 2069 6e70 7574 5f69 6473 3d4e       input_ids=N
+00013900: 6f6e 652c 0a20 2020 2020 2020 2020 2020  one,.           
+00013910: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
+00013920: 6173 6b3d 4e6f 6e65 2c0a 2020 2020 2020  ask=None,.      
+00013930: 2020 2020 2020 2020 2020 746f 6b65 6e5f            token_
+00013940: 7479 7065 5f69 6473 3d4e 6f6e 652c 0a20  type_ids=None,. 
+00013950: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00013960: 6f73 6974 696f 6e5f 6964 733d 4e6f 6e65  osition_ids=None
+00013970: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00013980: 2020 6865 6164 5f6d 6173 6b3d 4e6f 6e65    head_mask=None
+00013990: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000139a0: 2020 696e 7075 7473 5f65 6d62 6564 733d    inputs_embeds=
+000139b0: 4e6f 6e65 2c0a 2020 2020 2020 2020 2020  None,.          
+000139c0: 2020 2020 2020 6c61 6265 6c73 3d4e 6f6e        labels=Non
+000139d0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+000139e0: 2020 206f 7574 7075 745f 6174 7465 6e74     output_attent
+000139f0: 696f 6e73 3d4e 6f6e 652c 0a20 2020 2020  ions=None,.     
+00013a00: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+00013a10: 745f 6869 6464 656e 5f73 7461 7465 733d  t_hidden_states=
+00013a20: 4e6f 6e65 2c0a 2020 2020 2020 2020 2020  None,.          
+00013a30: 2020 2020 2020 7265 7475 726e 5f64 6963        return_dic
+00013a40: 743d 4e6f 6e65 2c0a 2020 2020 2020 2020  t=None,.        
+00013a50: 2020 2020 2020 2020 2a2a 6b77 6172 6773          **kwargs
+00013a60: 293a 0a20 2020 2020 2020 2072 2222 220a  ):.        r""".
+00013a70: 2020 2020 2020 2020 6c61 6265 6c73 2028          labels (
+00013a80: 3a6f 626a 3a60 746f 7263 682e 4c6f 6e67  :obj:`torch.Long
+00013a90: 5465 6e73 6f72 6020 6f66 2073 6861 7065  Tensor` of shape
+00013aa0: 203a 6f62 6a3a 6028 6261 7463 685f 7369   :obj:`(batch_si
+00013ab0: 7a65 2c29 602c 2060 6f70 7469 6f6e 616c  ze,)`, `optional
+00013ac0: 6029 3a0a 2020 2020 2020 2020 2020 2020  `):.            
+00013ad0: 4c61 6265 6c73 2066 6f72 2063 6f6d 7075  Labels for compu
+00013ae0: 7469 6e67 2074 6865 206e 6578 7420 7365  ting the next se
+00013af0: 7175 656e c3a5 6365 2070 7265 6469 6374  quen..ce predict
+00013b00: 696f 6e20 2863 6c61 7373 6966 6963 6174  ion (classificat
+00013b10: 696f 6e29 206c 6f73 732e 2049 6e70 7574  ion) loss. Input
+00013b20: 2073 686f 756c 6420 6265 2061 2073 6571   should be a seq
+00013b30: 7565 6e63 6520 7061 6972 0a20 2020 2020  uence pair.     
+00013b40: 2020 2020 2020 2028 7365 6520 6060 696e         (see ``in
+00013b50: 7075 745f 6964 7360 6020 646f 6373 7472  put_ids`` docstr
+00013b60: 696e 6729 2e20 496e 6469 6365 7320 7368  ing). Indices sh
+00013b70: 6f75 6c64 2062 6520 696e 2060 605b 302c  ould be in ``[0,
+00013b80: 2031 5d60 603a 0a20 2020 2020 2020 2020   1]``:.         
+00013b90: 2020 202d 2030 2069 6e64 6963 6174 6573     - 0 indicates
+00013ba0: 2073 6571 7565 6e63 6520 4220 6973 2061   sequence B is a
+00013bb0: 2063 6f6e 7469 6e75 6174 696f 6e20 6f66   continuation of
+00013bc0: 2073 6571 7565 6e63 6520 412c 0a20 2020   sequence A,.   
+00013bd0: 2020 2020 2020 2020 202d 2031 2069 6e64           - 1 ind
+00013be0: 6963 6174 6573 2073 6571 7565 6e63 6520  icates sequence 
+00013bf0: 4220 6973 2061 2072 616e 646f 6d20 7365  B is a random se
+00013c00: 7175 656e 6365 2e0a 2020 2020 2020 2020  quence..        
+00013c10: 5265 7475 726e 733a 0a0a 2020 2020 2020  Returns:..      
+00013c20: 2020 4578 616d 706c 653a 0a20 2020 2020    Example:.     
+00013c30: 2020 2020 2020 203e 3e3e 2066 726f 6d20         >>> from 
+00013c40: 7472 616e 7366 6f72 6d65 7273 2069 6d70  transformers imp
+00013c50: 6f72 7420 4265 7274 546f 6b65 6e69 7a65  ort BertTokenize
+00013c60: 722c 2042 6572 7446 6f72 4e65 7874 5365  r, BertForNextSe
+00013c70: 6e74 656e 6365 5072 6564 6963 7469 6f6e  ntencePrediction
+00013c80: 0a20 2020 2020 2020 2020 2020 203e 3e3e  .            >>>
+00013c90: 2069 6d70 6f72 7420 746f 7263 680a 2020   import torch.  
+00013ca0: 2020 2020 2020 2020 2020 3e3e 3e20 746f            >>> to
+00013cb0: 6b65 6e69 7a65 7220 3d20 4265 7274 546f  kenizer = BertTo
+00013cc0: 6b65 6e69 7a65 722e 6672 6f6d 5f70 7265  kenizer.from_pre
+00013cd0: 7472 6169 6e65 6428 2762 6572 742d 6261  trained('bert-ba
+00013ce0: 7365 2d75 6e63 6173 6564 2729 0a20 2020  se-uncased').   
+00013cf0: 2020 2020 2020 2020 203e 3e3e 206d 6f64           >>> mod
+00013d00: 656c 203d 2042 6572 7446 6f72 4e65 7874  el = BertForNext
+00013d10: 5365 6e74 656e 6365 5072 6564 6963 7469  SentencePredicti
+00013d20: 6f6e 2e66 726f 6d5f 7072 6574 7261 696e  on.from_pretrain
+00013d30: 6564 2827 6265 7274 2d62 6173 652d 756e  ed('bert-base-un
+00013d40: 6361 7365 6427 290a 2020 2020 2020 2020  cased').        
+00013d50: 2020 2020 3e3e 3e20 7072 6f6d 7074 203d      >>> prompt =
+00013d60: 2022 496e 2049 7461 6c79 2c20 7069 7a7a   "In Italy, pizz
+00013d70: 6120 7365 7276 6564 2069 6e20 666f 726d  a served in form
+00013d80: 616c 2073 6574 7469 6e67 732c 2073 7563  al settings, suc
+00013d90: 6820 6173 2061 7420 6120 7265 7374 6175  h as at a restau
+00013da0: 7261 6e74 2c20 6973 2070 7265 7365 6e74  rant, is present
+00013db0: 6564 2075 6e73 6c69 6365 642e 220a 2020  ed unsliced.".  
+00013dc0: 2020 2020 2020 2020 2020 3e3e 3e20 6e65            >>> ne
+00013dd0: 7874 5f73 656e 7465 6e63 6520 3d20 2254  xt_sentence = "T
+00013de0: 6865 2073 6b79 2069 7320 626c 7565 2064  he sky is blue d
+00013df0: 7565 2074 6f20 7468 6520 7368 6f72 7465  ue to the shorte
+00013e00: 7220 7761 7665 6c65 6e67 7468 206f 6620  r wavelength of 
+00013e10: 626c 7565 206c 6967 6874 2e22 0a20 2020  blue light.".   
+00013e20: 2020 2020 2020 2020 203e 3e3e 2065 6e63           >>> enc
+00013e30: 6f64 696e 6720 3d20 746f 6b65 6e69 7a65  oding = tokenize
+00013e40: 7228 7072 6f6d 7074 2c20 6e65 7874 5f73  r(prompt, next_s
+00013e50: 656e 7465 6e63 652c 2072 6574 7572 6e5f  entence, return_
+00013e60: 7465 6e73 6f72 733d 2770 7427 290a 2020  tensors='pt').  
+00013e70: 2020 2020 2020 2020 2020 3e3e 3e20 6f75            >>> ou
+00013e80: 7470 7574 7320 3d20 6d6f 6465 6c28 2a2a  tputs = model(**
+00013e90: 656e 636f 6469 6e67 2c20 6c61 6265 6c73  encoding, labels
+00013ea0: 3d74 6f72 6368 2e4c 6f6e 6754 656e 736f  =torch.LongTenso
+00013eb0: 7228 5b31 5d29 290a 2020 2020 2020 2020  r([1])).        
+00013ec0: 2020 2020 3e3e 3e20 6c6f 6769 7473 203d      >>> logits =
+00013ed0: 206f 7574 7075 7473 2e6c 6f67 6974 730a   outputs.logits.
+00013ee0: 2020 2020 2020 2020 2020 2020 3e3e 3e20              >>> 
+00013ef0: 6173 7365 7274 206c 6f67 6974 735b 302c  assert logits[0,
+00013f00: 2030 5d20 3c20 6c6f 6769 7473 5b30 2c20   0] < logits[0, 
+00013f10: 315d 2023 206e 6578 7420 7365 6e74 656e  1] # next senten
+00013f20: 6365 2077 6173 2072 616e 646f 6d0a 2020  ce was random.  
+00013f30: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
+00013f40: 2020 2072 6574 7572 6e5f 6469 6374 203d     return_dict =
+00013f50: 2072 6574 7572 6e5f 6469 6374 2069 6620   return_dict if 
+00013f60: 7265 7475 726e 5f64 6963 7420 6973 206e  return_dict is n
+00013f70: 6f74 204e 6f6e 6520 656c 7365 2073 656c  ot None else sel
+00013f80: 662e 636f 6e66 6967 2e75 7365 5f72 6574  f.config.use_ret
+00013f90: 7572 6e5f 6469 6374 0a0a 2020 2020 2020  urn_dict..      
+00013fa0: 2020 6f75 7470 7574 7320 3d20 7365 6c66    outputs = self
+00013fb0: 2e62 6572 7428 0a20 2020 2020 2020 2020  .bert(.         
+00013fc0: 2020 2069 6e70 7574 5f69 6473 2c0a 2020     input_ids,.  
+00013fd0: 2020 2020 2020 2020 2020 6174 7465 6e74            attent
+00013fe0: 696f 6e5f 6d61 736b 3d61 7474 656e 7469  ion_mask=attenti
+00013ff0: 6f6e 5f6d 6173 6b2c 0a20 2020 2020 2020  on_mask,.       
+00014000: 2020 2020 2074 6f6b 656e 5f74 7970 655f       token_type_
+00014010: 6964 733d 746f 6b65 6e5f 7479 7065 5f69  ids=token_type_i
+00014020: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
+00014030: 706f 7369 7469 6f6e 5f69 6473 3d70 6f73  position_ids=pos
+00014040: 6974 696f 6e5f 6964 732c 0a20 2020 2020  ition_ids,.     
+00014050: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
+00014060: 3d68 6561 645f 6d61 736b 2c0a 2020 2020  =head_mask,.    
+00014070: 2020 2020 2020 2020 696e 7075 7473 5f65          inputs_e
+00014080: 6d62 6564 733d 696e 7075 7473 5f65 6d62  mbeds=inputs_emb
+00014090: 6564 732c 0a20 2020 2020 2020 2020 2020  eds,.           
+000140a0: 206f 7574 7075 745f 6174 7465 6e74 696f   output_attentio
+000140b0: 6e73 3d6f 7574 7075 745f 6174 7465 6e74  ns=output_attent
+000140c0: 696f 6e73 2c0a 2020 2020 2020 2020 2020  ions,.          
+000140d0: 2020 6f75 7470 7574 5f68 6964 6465 6e5f    output_hidden_
+000140e0: 7374 6174 6573 3d6f 7574 7075 745f 6869  states=output_hi
+000140f0: 6464 656e 5f73 7461 7465 732c 0a20 2020  dden_states,.   
+00014100: 2020 2020 2020 2020 2072 6574 7572 6e5f           return_
+00014110: 6469 6374 3d72 6574 7572 6e5f 6469 6374  dict=return_dict
+00014120: 2c0a 2020 2020 2020 2020 290a 0a20 2020  ,.        )..   
+00014130: 2020 2020 2070 6f6f 6c65 645f 6f75 7470       pooled_outp
+00014140: 7574 203d 206f 7574 7075 7473 5b31 5d0a  ut = outputs[1].
+00014150: 0a20 2020 2020 2020 2073 6571 5f72 656c  .        seq_rel
+00014160: 6174 696f 6e73 6869 705f 7363 6f72 6573  ationship_scores
+00014170: 203d 2073 656c 662e 636c 7328 706f 6f6c   = self.cls(pool
+00014180: 6564 5f6f 7574 7075 7429 0a0a 2020 2020  ed_output)..    
+00014190: 2020 2020 6e65 7874 5f73 656e 7465 6e63      next_sentenc
+000141a0: 655f 6c6f 7373 203d 204e 6f6e 650a 2020  e_loss = None.  
+000141b0: 2020 2020 2020 6966 206c 6162 656c 7320        if labels 
+000141c0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+000141d0: 2020 2020 2020 2020 206c 6f73 735f 6663           loss_fc
+000141e0: 7420 3d20 4372 6f73 7345 6e74 726f 7079  t = CrossEntropy
+000141f0: 4c6f 7373 2829 0a20 2020 2020 2020 2020  Loss().         
+00014200: 2020 206e 6578 745f 7365 6e74 656e 6365     next_sentence
+00014210: 5f6c 6f73 7320 3d20 6c6f 7373 5f66 6374  _loss = loss_fct
+00014220: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00014230: 2020 7365 715f 7265 6c61 7469 6f6e 7368    seq_relationsh
+00014240: 6970 5f73 636f 7265 732e 7669 6577 282d  ip_scores.view(-
+00014250: 312c 2032 292c 206c 6162 656c 732e 7669  1, 2), labels.vi
+00014260: 6577 282d 3129 290a 0a20 2020 2020 2020  ew(-1))..       
+00014270: 2069 6620 6e6f 7420 7265 7475 726e 5f64   if not return_d
+00014280: 6963 743a 0a20 2020 2020 2020 2020 2020  ict:.           
+00014290: 206f 7574 7075 7420 3d20 2873 6571 5f72   output = (seq_r
+000142a0: 656c 6174 696f 6e73 6869 705f 7363 6f72  elationship_scor
+000142b0: 6573 2c20 2920 2b20 6f75 7470 7574 735b  es, ) + outputs[
+000142c0: 323a 5d0a 2020 2020 2020 2020 2020 2020  2:].            
+000142d0: 7265 7475 726e 2028 286e 6578 745f 7365  return ((next_se
+000142e0: 6e74 656e 6365 5f6c 6f73 732c 2029 0a20  ntence_loss, ). 
+000142f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014300: 2020 202b 206f 7574 7075 7429 2069 6620     + output) if 
+00014310: 6e65 7874 5f73 656e 7465 6e63 655f 6c6f  next_sentence_lo
+00014320: 7373 2069 7320 6e6f 7420 4e6f 6e65 2065  ss is not None e
+00014330: 6c73 6520 6f75 7470 7574 0a0a 2020 2020  lse output..    
+00014340: 2020 2020 7265 7475 726e 204e 6578 7453      return NextS
+00014350: 656e 7465 6e63 6550 7265 6469 6374 6f72  entencePredictor
+00014360: 4f75 7470 7574 280a 2020 2020 2020 2020  Output(.        
+00014370: 2020 2020 6c6f 7373 3d6e 6578 745f 7365      loss=next_se
+00014380: 6e74 656e 6365 5f6c 6f73 732c 0a20 2020  ntence_loss,.   
+00014390: 2020 2020 2020 2020 206c 6f67 6974 733d           logits=
+000143a0: 7365 715f 7265 6c61 7469 6f6e 7368 6970  seq_relationship
+000143b0: 5f73 636f 7265 732c 0a20 2020 2020 2020  _scores,.       
+000143c0: 2020 2020 2068 6964 6465 6e5f 7374 6174       hidden_stat
+000143d0: 6573 3d6f 7574 7075 7473 2e68 6964 6465  es=outputs.hidde
+000143e0: 6e5f 7374 6174 6573 2c0a 2020 2020 2020  n_states,.      
+000143f0: 2020 2020 2020 6174 7465 6e74 696f 6e73        attentions
+00014400: 3d6f 7574 7075 7473 2e61 7474 656e 7469  =outputs.attenti
+00014410: 6f6e 732c 0a20 2020 2020 2020 2029 0a0a  ons,.        )..
+00014420: 0a63 6c61 7373 2042 6572 7446 6f72 5365  .class BertForSe
+00014430: 7175 656e 6365 436c 6173 7369 6669 6361  quenceClassifica
+00014440: 7469 6f6e 2842 6572 7450 7265 5472 6169  tion(BertPreTrai
+00014450: 6e65 644d 6f64 656c 293a 0a0a 2020 2020  nedModel):..    
+00014460: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00014470: 662c 2063 6f6e 6669 6729 3a0a 2020 2020  f, config):.    
+00014480: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
+00014490: 6974 5f5f 2863 6f6e 6669 6729 0a20 2020  it__(config).   
+000144a0: 2020 2020 2073 656c 662e 6e75 6d5f 6c61       self.num_la
+000144b0: 6265 6c73 203d 2063 6f6e 6669 672e 6e75  bels = config.nu
+000144c0: 6d5f 6c61 6265 6c73 0a0a 2020 2020 2020  m_labels..      
+000144d0: 2020 7365 6c66 2e62 6572 7420 3d20 4265    self.bert = Be
+000144e0: 7274 4d6f 6465 6c28 636f 6e66 6967 290a  rtModel(config).
+000144f0: 2020 2020 2020 2020 7365 6c66 2e64 726f          self.dro
+00014500: 706f 7574 203d 206e 6e2e 4472 6f70 6f75  pout = nn.Dropou
+00014510: 7428 636f 6e66 6967 2e68 6964 6465 6e5f  t(config.hidden_
+00014520: 6472 6f70 6f75 745f 7072 6f62 290a 2020  dropout_prob).  
+00014530: 2020 2020 2020 7365 6c66 2e63 6c61 7373        self.class
+00014540: 6966 6965 7220 3d20 6e6e 2e4c 696e 6561  ifier = nn.Linea
+00014550: 7228 636f 6e66 6967 2e68 6964 6465 6e5f  r(config.hidden_
+00014560: 7369 7a65 2c20 636f 6e66 6967 2e6e 756d  size, config.num
+00014570: 5f6c 6162 656c 7329 0a0a 2020 2020 2020  _labels)..      
+00014580: 2020 7365 6c66 2e69 6e69 745f 7765 6967    self.init_weig
+00014590: 6874 7328 290a 0a20 2020 2064 6566 2066  hts()..    def f
+000145a0: 6f72 7761 7264 280a 2020 2020 2020 2020  orward(.        
+000145b0: 7365 6c66 2c0a 2020 2020 2020 2020 696e  self,.        in
+000145c0: 7075 745f 6964 733d 4e6f 6e65 2c0a 2020  put_ids=None,.  
+000145d0: 2020 2020 2020 6174 7465 6e74 696f 6e5f        attention_
+000145e0: 6d61 736b 3d4e 6f6e 652c 0a20 2020 2020  mask=None,.     
+000145f0: 2020 2074 6f6b 656e 5f74 7970 655f 6964     token_type_id
+00014600: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
+00014610: 706f 7369 7469 6f6e 5f69 6473 3d4e 6f6e  position_ids=Non
+00014620: 652c 0a20 2020 2020 2020 2068 6561 645f  e,.        head_
+00014630: 6d61 736b 3d4e 6f6e 652c 0a20 2020 2020  mask=None,.     
+00014640: 2020 2069 6e70 7574 735f 656d 6265 6473     inputs_embeds
+00014650: 3d4e 6f6e 652c 0a20 2020 2020 2020 206c  =None,.        l
+00014660: 6162 656c 733d 4e6f 6e65 2c0a 2020 2020  abels=None,.    
+00014670: 2020 2020 6f75 7470 7574 5f61 7474 656e      output_atten
+00014680: 7469 6f6e 733d 4e6f 6e65 2c0a 2020 2020  tions=None,.    
+00014690: 2020 2020 6f75 7470 7574 5f68 6964 6465      output_hidde
+000146a0: 6e5f 7374 6174 6573 3d4e 6f6e 652c 0a20  n_states=None,. 
+000146b0: 2020 2020 2020 2072 6574 7572 6e5f 6469         return_di
+000146c0: 6374 3d4e 6f6e 652c 0a20 2020 2029 3a0a  ct=None,.    ):.
+000146d0: 2020 2020 2020 2020 7222 2222 0a20 2020          r""".   
+000146e0: 2020 2020 206c 6162 656c 7320 283a 6f62       labels (:ob
+000146f0: 6a3a 6074 6f72 6368 2e4c 6f6e 6754 656e  j:`torch.LongTen
+00014700: 736f 7260 206f 6620 7368 6170 6520 3a6f  sor` of shape :o
+00014710: 626a 3a60 2862 6174 6368 5f73 697a 652c  bj:`(batch_size,
+00014720: 2960 2c20 606f 7074 696f 6e61 6c60 293a  )`, `optional`):
+00014730: 0a20 2020 2020 2020 2020 2020 204c 6162  .            Lab
+00014740: 656c 7320 666f 7220 636f 6d70 7574 696e  els for computin
+00014750: 6720 7468 6520 7365 7175 656e 6365 2063  g the sequence c
+00014760: 6c61 7373 6966 6963 6174 696f 6e2f 7265  lassification/re
+00014770: 6772 6573 7369 6f6e 206c 6f73 732e 2049  gression loss. I
+00014780: 6e64 6963 6573 2073 686f 756c 6420 6265  ndices should be
+00014790: 2069 6e20 3a6f 626a 3a60 5b30 2c20 2e2e   in :obj:`[0, ..
+000147a0: 2e2c 0a20 2020 2020 2020 2020 2020 2063  .,.            c
+000147b0: 6f6e 6669 672e 6e75 6d5f 6c61 6265 6c73  onfig.num_labels
+000147c0: 202d 2031 5d60 2e20 4966 203a 6f62 6a3a   - 1]`. If :obj:
+000147d0: 6063 6f6e 6669 672e 6e75 6d5f 6c61 6265  `config.num_labe
+000147e0: 6c73 203d 3d20 3160 2061 2072 6567 7265  ls == 1` a regre
+000147f0: 7373 696f 6e20 6c6f 7373 2069 7320 636f  ssion loss is co
+00014800: 6d70 7574 6564 2028 4d65 616e 2d53 7175  mputed (Mean-Squ
+00014810: 6172 6520 6c6f 7373 292c 0a20 2020 2020  are loss),.     
+00014820: 2020 2020 2020 2049 6620 3a6f 626a 3a60         If :obj:`
+00014830: 636f 6e66 6967 2e6e 756d 5f6c 6162 656c  config.num_label
+00014840: 7320 3e20 3160 2061 2063 6c61 7373 6966  s > 1` a classif
+00014850: 6963 6174 696f 6e20 6c6f 7373 2069 7320  ication loss is 
+00014860: 636f 6d70 7574 6564 2028 4372 6f73 732d  computed (Cross-
+00014870: 456e 7472 6f70 7929 2e0a 2020 2020 2020  Entropy)..      
+00014880: 2020 2222 220a 2020 2020 2020 2020 7265    """.        re
+00014890: 7475 726e 5f64 6963 7420 3d20 7265 7475  turn_dict = retu
+000148a0: 726e 5f64 6963 7420 6966 2072 6574 7572  rn_dict if retur
+000148b0: 6e5f 6469 6374 2069 7320 6e6f 7420 4e6f  n_dict is not No
+000148c0: 6e65 2065 6c73 6520 7365 6c66 2e63 6f6e  ne else self.con
+000148d0: 6669 672e 7573 655f 7265 7475 726e 5f64  fig.use_return_d
+000148e0: 6963 740a 0a20 2020 2020 2020 206f 7574  ict..        out
+000148f0: 7075 7473 203d 2073 656c 662e 6265 7274  puts = self.bert
+00014900: 280a 2020 2020 2020 2020 2020 2020 696e  (.            in
+00014910: 7075 745f 6964 732c 0a20 2020 2020 2020  put_ids,.       
+00014920: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
+00014930: 6173 6b3d 6174 7465 6e74 696f 6e5f 6d61  ask=attention_ma
+00014940: 736b 2c0a 2020 2020 2020 2020 2020 2020  sk,.            
+00014950: 746f 6b65 6e5f 7479 7065 5f69 6473 3d74  token_type_ids=t
+00014960: 6f6b 656e 5f74 7970 655f 6964 732c 0a20  oken_type_ids,. 
+00014970: 2020 2020 2020 2020 2020 2070 6f73 6974             posit
+00014980: 696f 6e5f 6964 733d 706f 7369 7469 6f6e  ion_ids=position
+00014990: 5f69 6473 2c0a 2020 2020 2020 2020 2020  _ids,.          
+000149a0: 2020 6865 6164 5f6d 6173 6b3d 6865 6164    head_mask=head
+000149b0: 5f6d 6173 6b2c 0a20 2020 2020 2020 2020  _mask,.         
+000149c0: 2020 2069 6e70 7574 735f 656d 6265 6473     inputs_embeds
+000149d0: 3d69 6e70 7574 735f 656d 6265 6473 2c0a  =inputs_embeds,.
+000149e0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+000149f0: 7574 5f61 7474 656e 7469 6f6e 733d 6f75  ut_attentions=ou
+00014a00: 7470 7574 5f61 7474 656e 7469 6f6e 732c  tput_attentions,
+00014a10: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00014a20: 7075 745f 6869 6464 656e 5f73 7461 7465  put_hidden_state
+00014a30: 733d 6f75 7470 7574 5f68 6964 6465 6e5f  s=output_hidden_
+00014a40: 7374 6174 6573 2c0a 2020 2020 2020 2020  states,.        
+00014a50: 2020 2020 7265 7475 726e 5f64 6963 743d      return_dict=
+00014a60: 7265 7475 726e 5f64 6963 742c 0a20 2020  return_dict,.   
+00014a70: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
+00014a80: 706f 6f6c 6564 5f6f 7574 7075 7420 3d20  pooled_output = 
+00014a90: 6f75 7470 7574 735b 315d 0a0a 2020 2020  outputs[1]..    
+00014aa0: 2020 2020 706f 6f6c 6564 5f6f 7574 7075      pooled_outpu
+00014ab0: 7420 3d20 7365 6c66 2e64 726f 706f 7574  t = self.dropout
+00014ac0: 2870 6f6f 6c65 645f 6f75 7470 7574 290a  (pooled_output).
+00014ad0: 2020 2020 2020 2020 6c6f 6769 7473 203d          logits =
+00014ae0: 2073 656c 662e 636c 6173 7369 6669 6572   self.classifier
+00014af0: 2870 6f6f 6c65 645f 6f75 7470 7574 290a  (pooled_output).
+00014b00: 0a20 2020 2020 2020 206c 6f73 7320 3d20  .        loss = 
+00014b10: 4e6f 6e65 0a20 2020 2020 2020 2069 6620  None.        if 
+00014b20: 6c61 6265 6c73 2069 7320 6e6f 7420 4e6f  labels is not No
+00014b30: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00014b40: 6966 2073 656c 662e 6e75 6d5f 6c61 6265  if self.num_labe
+00014b50: 6c73 203d 3d20 313a 0a20 2020 2020 2020  ls == 1:.       
+00014b60: 2020 2020 2020 2020 2023 2020 5765 2061           #  We a
+00014b70: 7265 2064 6f69 6e67 2072 6567 7265 7373  re doing regress
+00014b80: 696f 6e0a 2020 2020 2020 2020 2020 2020  ion.            
+00014b90: 2020 2020 6c6f 7373 5f66 6374 203d 204d      loss_fct = M
+00014ba0: 5345 4c6f 7373 2829 0a20 2020 2020 2020  SELoss().       
+00014bb0: 2020 2020 2020 2020 206c 6f73 7320 3d20           loss = 
+00014bc0: 6c6f 7373 5f66 6374 286c 6f67 6974 732e  loss_fct(logits.
+00014bd0: 7669 6577 282d 3129 2c20 6c61 6265 6c73  view(-1), labels
+00014be0: 2e76 6965 7728 2d31 2929 0a20 2020 2020  .view(-1)).     
+00014bf0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00014c00: 2020 2020 2020 2020 2020 2020 206c 6f73               los
+00014c10: 735f 6663 7420 3d20 4372 6f73 7345 6e74  s_fct = CrossEnt
+00014c20: 726f 7079 4c6f 7373 2829 0a20 2020 2020  ropyLoss().     
+00014c30: 2020 2020 2020 2020 2020 206c 6f73 7320             loss 
+00014c40: 3d20 6c6f 7373 5f66 6374 280a 2020 2020  = loss_fct(.    
+00014c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014c60: 6c6f 6769 7473 2e76 6965 7728 2d31 2c20  logits.view(-1, 
+00014c70: 7365 6c66 2e6e 756d 5f6c 6162 656c 7329  self.num_labels)
+00014c80: 2c20 6c61 6265 6c73 2e76 6965 7728 2d31  , labels.view(-1
+00014c90: 2929 0a0a 2020 2020 2020 2020 6966 206e  ))..        if n
+00014ca0: 6f74 2072 6574 7572 6e5f 6469 6374 3a0a  ot return_dict:.
+00014cb0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+00014cc0: 7574 203d 2028 6c6f 6769 7473 2c20 2920  ut = (logits, ) 
+00014cd0: 2b20 6f75 7470 7574 735b 323a 5d0a 2020  + outputs[2:].  
+00014ce0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00014cf0: 2028 286c 6f73 732c 2029 202b 206f 7574   ((loss, ) + out
+00014d00: 7075 7429 2069 6620 6c6f 7373 2069 7320  put) if loss is 
+00014d10: 6e6f 7420 4e6f 6e65 2065 6c73 6520 6f75  not None else ou
+00014d20: 7470 7574 0a0a 2020 2020 2020 2020 7265  tput..        re
+00014d30: 7475 726e 2053 6571 7565 6e63 6543 6c61  turn SequenceCla
+00014d40: 7373 6966 6965 724f 7574 7075 7428 0a20  ssifierOutput(. 
+00014d50: 2020 2020 2020 2020 2020 206c 6f73 733d             loss=
+00014d60: 6c6f 7373 2c0a 2020 2020 2020 2020 2020  loss,.          
+00014d70: 2020 6c6f 6769 7473 3d6c 6f67 6974 732c    logits=logits,
+00014d80: 0a20 2020 2020 2020 2020 2020 2068 6964  .            hid
+00014d90: 6465 6e5f 7374 6174 6573 3d6f 7574 7075  den_states=outpu
+00014da0: 7473 2e68 6964 6465 6e5f 7374 6174 6573  ts.hidden_states
+00014db0: 2c0a 2020 2020 2020 2020 2020 2020 6174  ,.            at
+00014dc0: 7465 6e74 696f 6e73 3d6f 7574 7075 7473  tentions=outputs
+00014dd0: 2e61 7474 656e 7469 6f6e 732c 0a20 2020  .attentions,.   
+00014de0: 2020 2020 2029 0a0a 0a63 6c61 7373 2042       )...class B
+00014df0: 6572 7446 6f72 4d75 6c74 6970 6c65 4368  ertForMultipleCh
+00014e00: 6f69 6365 2842 6572 7450 7265 5472 6169  oice(BertPreTrai
+00014e10: 6e65 644d 6f64 656c 293a 0a0a 2020 2020  nedModel):..    
+00014e20: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00014e30: 662c 2063 6f6e 6669 6729 3a0a 2020 2020  f, config):.    
+00014e40: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
+00014e50: 6974 5f5f 2863 6f6e 6669 6729 0a0a 2020  it__(config)..  
+00014e60: 2020 2020 2020 7365 6c66 2e62 6572 7420        self.bert 
+00014e70: 3d20 4265 7274 4d6f 6465 6c28 636f 6e66  = BertModel(conf
+00014e80: 6967 290a 2020 2020 2020 2020 7365 6c66  ig).        self
+00014e90: 2e64 726f 706f 7574 203d 206e 6e2e 4472  .dropout = nn.Dr
+00014ea0: 6f70 6f75 7428 636f 6e66 6967 2e68 6964  opout(config.hid
+00014eb0: 6465 6e5f 6472 6f70 6f75 745f 7072 6f62  den_dropout_prob
+00014ec0: 290a 2020 2020 2020 2020 7365 6c66 2e63  ).        self.c
+00014ed0: 6c61 7373 6966 6965 7220 3d20 6e6e 2e4c  lassifier = nn.L
+00014ee0: 696e 6561 7228 636f 6e66 6967 2e68 6964  inear(config.hid
+00014ef0: 6465 6e5f 7369 7a65 2c20 3129 0a0a 2020  den_size, 1)..  
+00014f00: 2020 2020 2020 7365 6c66 2e69 6e69 745f        self.init_
+00014f10: 7765 6967 6874 7328 290a 0a20 2020 2064  weights()..    d
+00014f20: 6566 2066 6f72 7761 7264 280a 2020 2020  ef forward(.    
+00014f30: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+00014f40: 2020 696e 7075 745f 6964 733d 4e6f 6e65    input_ids=None
+00014f50: 2c0a 2020 2020 2020 2020 6174 7465 6e74  ,.        attent
+00014f60: 696f 6e5f 6d61 736b 3d4e 6f6e 652c 0a20  ion_mask=None,. 
+00014f70: 2020 2020 2020 2074 6f6b 656e 5f74 7970         token_typ
+00014f80: 655f 6964 733d 4e6f 6e65 2c0a 2020 2020  e_ids=None,.    
+00014f90: 2020 2020 706f 7369 7469 6f6e 5f69 6473      position_ids
+00014fa0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2068  =None,.        h
+00014fb0: 6561 645f 6d61 736b 3d4e 6f6e 652c 0a20  ead_mask=None,. 
+00014fc0: 2020 2020 2020 2069 6e70 7574 735f 656d         inputs_em
+00014fd0: 6265 6473 3d4e 6f6e 652c 0a20 2020 2020  beds=None,.     
+00014fe0: 2020 206c 6162 656c 733d 4e6f 6e65 2c0a     labels=None,.
+00014ff0: 2020 2020 2020 2020 6f75 7470 7574 5f61          output_a
+00015000: 7474 656e 7469 6f6e 733d 4e6f 6e65 2c0a  ttentions=None,.
+00015010: 2020 2020 2020 2020 6f75 7470 7574 5f68          output_h
+00015020: 6964 6465 6e5f 7374 6174 6573 3d4e 6f6e  idden_states=Non
+00015030: 652c 0a20 2020 2020 2020 2072 6574 7572  e,.        retur
+00015040: 6e5f 6469 6374 3d4e 6f6e 652c 0a20 2020  n_dict=None,.   
+00015050: 2029 3a0a 2020 2020 2020 2020 7222 2222   ):.        r"""
+00015060: 0a20 2020 2020 2020 206c 6162 656c 7320  .        labels 
+00015070: 283a 6f62 6a3a 6074 6f72 6368 2e4c 6f6e  (:obj:`torch.Lon
+00015080: 6754 656e 736f 7260 206f 6620 7368 6170  gTensor` of shap
+00015090: 6520 3a6f 626a 3a60 2862 6174 6368 5f73  e :obj:`(batch_s
+000150a0: 697a 652c 2960 2c0a 2020 2020 2020 2020  ize,)`,.        
+000150b0: 606f 7074 696f 6e61 6c60 293a 0a20 2020  `optional`):.   
+000150c0: 2020 2020 2020 2020 204c 6162 656c 7320           Labels 
+000150d0: 666f 7220 636f 6d70 7574 696e 6720 7468  for computing th
+000150e0: 6520 6d75 6c74 6970 6c65 2063 686f 6963  e multiple choic
+000150f0: 6520 636c 6173 7369 6669 6361 7469 6f6e  e classification
+00015100: 206c 6f73 732e 0a20 2020 2020 2020 2020   loss..         
+00015110: 2020 2049 6e64 6963 6573 2073 686f 756c     Indices shoul
+00015120: 6420 6265 2069 6e20 6060 5b30 2c20 2e2e  d be in ``[0, ..
+00015130: 2e2c 206e 756d 5f63 686f 6963 6573 2d31  ., num_choices-1
+00015140: 5d60 6020 7768 6572 650a 2020 2020 2020  ]`` where.      
+00015150: 2020 2020 2020 3a6f 626a 3a60 6e75 6d5f        :obj:`num_
+00015160: 6368 6f69 6365 7360 2069 7320 7468 6520  choices` is the 
+00015170: 7369 7a65 206f 6620 7468 6520 7365 636f  size of the seco
+00015180: 6e64 2064 696d 656e 7369 6f6e 206f 6620  nd dimension of 
+00015190: 7468 6520 696e 7075 740a 2020 2020 2020  the input.      
+000151a0: 2020 2020 2020 7465 6e73 6f72 732e 2028        tensors. (
+000151b0: 5365 6520 3a6f 626a 3a60 696e 7075 745f  See :obj:`input_
+000151c0: 6964 7360 2061 626f 7665 290a 2020 2020  ids` above).    
+000151d0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+000151e0: 7265 7475 726e 5f64 6963 7420 3d20 7265  return_dict = re
+000151f0: 7475 726e 5f64 6963 7420 6966 2072 6574  turn_dict if ret
+00015200: 7572 6e5f 6469 6374 2069 7320 6e6f 7420  urn_dict is not 
+00015210: 4e6f 6e65 2065 6c73 6520 7365 6c66 2e63  None else self.c
+00015220: 6f6e 6669 672e 7573 655f 7265 7475 726e  onfig.use_return
+00015230: 5f64 6963 740a 2020 2020 2020 2020 6e75  _dict.        nu
+00015240: 6d5f 6368 6f69 6365 7320 3d20 696e 7075  m_choices = inpu
+00015250: 745f 6964 732e 7368 6170 655b 0a20 2020  t_ids.shape[.   
+00015260: 2020 2020 2020 2020 2031 5d20 6966 2069           1] if i
+00015270: 6e70 7574 5f69 6473 2069 7320 6e6f 7420  nput_ids is not 
+00015280: 4e6f 6e65 2065 6c73 6520 696e 7075 7473  None else inputs
+00015290: 5f65 6d62 6564 732e 7368 6170 655b 315d  _embeds.shape[1]
+000152a0: 0a0a 2020 2020 2020 2020 696e 7075 745f  ..        input_
+000152b0: 6964 7320 3d20 696e 7075 745f 6964 732e  ids = input_ids.
+000152c0: 7669 6577 280a 2020 2020 2020 2020 2020  view(.          
+000152d0: 2020 2d31 2c20 696e 7075 745f 6964 732e    -1, input_ids.
+000152e0: 7369 7a65 282d 3129 2920 6966 2069 6e70  size(-1)) if inp
+000152f0: 7574 5f69 6473 2069 7320 6e6f 7420 4e6f  ut_ids is not No
+00015300: 6e65 2065 6c73 6520 4e6f 6e65 0a20 2020  ne else None.   
+00015310: 2020 2020 2061 7474 656e 7469 6f6e 5f6d       attention_m
+00015320: 6173 6b20 3d20 6174 7465 6e74 696f 6e5f  ask = attention_
+00015330: 6d61 736b 2e76 6965 7728 0a20 2020 2020  mask.view(.     
+00015340: 2020 2020 2020 202d 312c 0a20 2020 2020         -1,.     
+00015350: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
+00015360: 5f6d 6173 6b2e 7369 7a65 282d 3129 2920  _mask.size(-1)) 
+00015370: 6966 2061 7474 656e 7469 6f6e 5f6d 6173  if attention_mas
+00015380: 6b20 6973 206e 6f74 204e 6f6e 6520 656c  k is not None el
+00015390: 7365 204e 6f6e 650a 2020 2020 2020 2020  se None.        
+000153a0: 746f 6b65 6e5f 7479 7065 5f69 6473 203d  token_type_ids =
+000153b0: 2074 6f6b 656e 5f74 7970 655f 6964 732e   token_type_ids.
+000153c0: 7669 6577 280a 2020 2020 2020 2020 2020  view(.          
+000153d0: 2020 2d31 2c0a 2020 2020 2020 2020 2020    -1,.          
+000153e0: 2020 746f 6b65 6e5f 7479 7065 5f69 6473    token_type_ids
+000153f0: 2e73 697a 6528 2d31 2929 2069 6620 746f  .size(-1)) if to
+00015400: 6b65 6e5f 7479 7065 5f69 6473 2069 7320  ken_type_ids is 
+00015410: 6e6f 7420 4e6f 6e65 2065 6c73 6520 4e6f  not None else No
+00015420: 6e65 0a20 2020 2020 2020 2070 6f73 6974  ne.        posit
+00015430: 696f 6e5f 6964 7320 3d20 706f 7369 7469  ion_ids = positi
+00015440: 6f6e 5f69 6473 2e76 6965 7728 0a20 2020  on_ids.view(.   
+00015450: 2020 2020 2020 2020 202d 312c 2070 6f73           -1, pos
+00015460: 6974 696f 6e5f 6964 732e 7369 7a65 282d  ition_ids.size(-
+00015470: 3129 2920 6966 2070 6f73 6974 696f 6e5f  1)) if position_
+00015480: 6964 7320 6973 206e 6f74 204e 6f6e 6520  ids is not None 
+00015490: 656c 7365 204e 6f6e 650a 2020 2020 2020  else None.      
+000154a0: 2020 696e 7075 7473 5f65 6d62 6564 7320    inputs_embeds 
+000154b0: 3d20 280a 2020 2020 2020 2020 2020 2020  = (.            
+000154c0: 696e 7075 7473 5f65 6d62 6564 732e 7669  inputs_embeds.vi
+000154d0: 6577 282d 312c 2069 6e70 7574 735f 656d  ew(-1, inputs_em
+000154e0: 6265 6473 2e73 697a 6528 2d32 292c 0a20  beds.size(-2),. 
+000154f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015500: 2020 2020 2020 2020 2020 2020 2020 696e                in
+00015510: 7075 7473 5f65 6d62 6564 732e 7369 7a65  puts_embeds.size
+00015520: 282d 3129 290a 2020 2020 2020 2020 2020  (-1)).          
+00015530: 2020 6966 2069 6e70 7574 735f 656d 6265    if inputs_embe
+00015540: 6473 2069 7320 6e6f 7420 4e6f 6e65 2065  ds is not None e
+00015550: 6c73 6520 4e6f 6e65 290a 0a20 2020 2020  lse None)..     
+00015560: 2020 206f 7574 7075 7473 203d 2073 656c     outputs = sel
+00015570: 662e 6265 7274 280a 2020 2020 2020 2020  f.bert(.        
+00015580: 2020 2020 696e 7075 745f 6964 732c 0a20      input_ids,. 
+00015590: 2020 2020 2020 2020 2020 2061 7474 656e             atten
+000155a0: 7469 6f6e 5f6d 6173 6b3d 6174 7465 6e74  tion_mask=attent
+000155b0: 696f 6e5f 6d61 736b 2c0a 2020 2020 2020  ion_mask,.      
+000155c0: 2020 2020 2020 746f 6b65 6e5f 7479 7065        token_type
+000155d0: 5f69 6473 3d74 6f6b 656e 5f74 7970 655f  _ids=token_type_
+000155e0: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
+000155f0: 2070 6f73 6974 696f 6e5f 6964 733d 706f   position_ids=po
+00015600: 7369 7469 6f6e 5f69 6473 2c0a 2020 2020  sition_ids,.    
+00015610: 2020 2020 2020 2020 6865 6164 5f6d 6173          head_mas
+00015620: 6b3d 6865 6164 5f6d 6173 6b2c 0a20 2020  k=head_mask,.   
+00015630: 2020 2020 2020 2020 2069 6e70 7574 735f           inputs_
+00015640: 656d 6265 6473 3d69 6e70 7574 735f 656d  embeds=inputs_em
+00015650: 6265 6473 2c0a 2020 2020 2020 2020 2020  beds,.          
+00015660: 2020 6f75 7470 7574 5f61 7474 656e 7469    output_attenti
+00015670: 6f6e 733d 6f75 7470 7574 5f61 7474 656e  ons=output_atten
+00015680: 7469 6f6e 732c 0a20 2020 2020 2020 2020  tions,.         
+00015690: 2020 206f 7574 7075 745f 6869 6464 656e     output_hidden
+000156a0: 5f73 7461 7465 733d 6f75 7470 7574 5f68  _states=output_h
+000156b0: 6964 6465 6e5f 7374 6174 6573 2c0a 2020  idden_states,.  
+000156c0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+000156d0: 5f64 6963 743d 7265 7475 726e 5f64 6963  _dict=return_dic
+000156e0: 742c 0a20 2020 2020 2020 2029 0a0a 2020  t,.        )..  
+000156f0: 2020 2020 2020 706f 6f6c 6564 5f6f 7574        pooled_out
+00015700: 7075 7420 3d20 6f75 7470 7574 735b 315d  put = outputs[1]
+00015710: 0a0a 2020 2020 2020 2020 706f 6f6c 6564  ..        pooled
+00015720: 5f6f 7574 7075 7420 3d20 7365 6c66 2e64  _output = self.d
+00015730: 726f 706f 7574 2870 6f6f 6c65 645f 6f75  ropout(pooled_ou
+00015740: 7470 7574 290a 2020 2020 2020 2020 6c6f  tput).        lo
+00015750: 6769 7473 203d 2073 656c 662e 636c 6173  gits = self.clas
+00015760: 7369 6669 6572 2870 6f6f 6c65 645f 6f75  sifier(pooled_ou
+00015770: 7470 7574 290a 2020 2020 2020 2020 7265  tput).        re
+00015780: 7368 6170 6564 5f6c 6f67 6974 7320 3d20  shaped_logits = 
+00015790: 6c6f 6769 7473 2e76 6965 7728 2d31 2c20  logits.view(-1, 
+000157a0: 6e75 6d5f 6368 6f69 6365 7329 0a0a 2020  num_choices)..  
+000157b0: 2020 2020 2020 6c6f 7373 203d 204e 6f6e        loss = Non
+000157c0: 650a 2020 2020 2020 2020 6966 206c 6162  e.        if lab
+000157d0: 656c 7320 6973 206e 6f74 204e 6f6e 653a  els is not None:
+000157e0: 0a20 2020 2020 2020 2020 2020 206c 6f73  .            los
+000157f0: 735f 6663 7420 3d20 4372 6f73 7345 6e74  s_fct = CrossEnt
+00015800: 726f 7079 4c6f 7373 2829 0a20 2020 2020  ropyLoss().     
+00015810: 2020 2020 2020 206c 6f73 7320 3d20 6c6f         loss = lo
+00015820: 7373 5f66 6374 2872 6573 6861 7065 645f  ss_fct(reshaped_
+00015830: 6c6f 6769 7473 2c20 6c61 6265 6c73 290a  logits, labels).
+00015840: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
+00015850: 7265 7475 726e 5f64 6963 743a 0a20 2020  return_dict:.   
+00015860: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00015870: 3d20 2872 6573 6861 7065 645f 6c6f 6769  = (reshaped_logi
+00015880: 7473 2c20 2920 2b20 6f75 7470 7574 735b  ts, ) + outputs[
+00015890: 323a 5d0a 2020 2020 2020 2020 2020 2020  2:].            
+000158a0: 7265 7475 726e 2028 286c 6f73 732c 2029  return ((loss, )
+000158b0: 202b 206f 7574 7075 7429 2069 6620 6c6f   + output) if lo
+000158c0: 7373 2069 7320 6e6f 7420 4e6f 6e65 2065  ss is not None e
+000158d0: 6c73 6520 6f75 7470 7574 0a0a 2020 2020  lse output..    
+000158e0: 2020 2020 7265 7475 726e 204d 756c 7469      return Multi
+000158f0: 706c 6543 686f 6963 654d 6f64 656c 4f75  pleChoiceModelOu
+00015900: 7470 7574 280a 2020 2020 2020 2020 2020  tput(.          
+00015910: 2020 6c6f 7373 3d6c 6f73 732c 0a20 2020    loss=loss,.   
+00015920: 2020 2020 2020 2020 206c 6f67 6974 733d           logits=
+00015930: 7265 7368 6170 6564 5f6c 6f67 6974 732c  reshaped_logits,
+00015940: 0a20 2020 2020 2020 2020 2020 2068 6964  .            hid
+00015950: 6465 6e5f 7374 6174 6573 3d6f 7574 7075  den_states=outpu
+00015960: 7473 2e68 6964 6465 6e5f 7374 6174 6573  ts.hidden_states
+00015970: 2c0a 2020 2020 2020 2020 2020 2020 6174  ,.            at
+00015980: 7465 6e74 696f 6e73 3d6f 7574 7075 7473  tentions=outputs
+00015990: 2e61 7474 656e 7469 6f6e 732c 0a20 2020  .attentions,.   
+000159a0: 2020 2020 2029 0a0a 0a63 6c61 7373 2042       )...class B
+000159b0: 6572 7446 6f72 546f 6b65 6e43 6c61 7373  ertForTokenClass
+000159c0: 6966 6963 6174 696f 6e28 4265 7274 5072  ification(BertPr
+000159d0: 6554 7261 696e 6564 4d6f 6465 6c29 3a0a  eTrainedModel):.
+000159e0: 0a20 2020 205f 6b65 7973 5f74 6f5f 6967  .    _keys_to_ig
+000159f0: 6e6f 7265 5f6f 6e5f 6c6f 6164 5f75 6e65  nore_on_load_une
+00015a00: 7870 6563 7465 6420 3d20 5b72 2770 6f6f  xpected = [r'poo
+00015a10: 6c65 7227 5d0a 0a20 2020 2064 6566 205f  ler']..    def _
+00015a20: 5f69 6e69 745f 5f28 7365 6c66 2c20 636f  _init__(self, co
+00015a30: 6e66 6967 293a 0a20 2020 2020 2020 2073  nfig):.        s
+00015a40: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+00015a50: 636f 6e66 6967 290a 2020 2020 2020 2020  config).        
+00015a60: 7365 6c66 2e6e 756d 5f6c 6162 656c 7320  self.num_labels 
+00015a70: 3d20 636f 6e66 6967 2e6e 756d 5f6c 6162  = config.num_lab
+00015a80: 656c 730a 0a20 2020 2020 2020 2073 656c  els..        sel
+00015a90: 662e 6265 7274 203d 2042 6572 744d 6f64  f.bert = BertMod
+00015aa0: 656c 2863 6f6e 6669 672c 2061 6464 5f70  el(config, add_p
+00015ab0: 6f6f 6c69 6e67 5f6c 6179 6572 3d46 616c  ooling_layer=Fal
+00015ac0: 7365 290a 2020 2020 2020 2020 7365 6c66  se).        self
+00015ad0: 2e64 726f 706f 7574 203d 206e 6e2e 4472  .dropout = nn.Dr
+00015ae0: 6f70 6f75 7428 636f 6e66 6967 2e68 6964  opout(config.hid
+00015af0: 6465 6e5f 6472 6f70 6f75 745f 7072 6f62  den_dropout_prob
+00015b00: 290a 2020 2020 2020 2020 7365 6c66 2e63  ).        self.c
+00015b10: 6c61 7373 6966 6965 7220 3d20 6e6e 2e4c  lassifier = nn.L
+00015b20: 696e 6561 7228 636f 6e66 6967 2e68 6964  inear(config.hid
+00015b30: 6465 6e5f 7369 7a65 2c20 636f 6e66 6967  den_size, config
+00015b40: 2e6e 756d 5f6c 6162 656c 7329 0a0a 2020  .num_labels)..  
+00015b50: 2020 2020 2020 7365 6c66 2e69 6e69 745f        self.init_
+00015b60: 7765 6967 6874 7328 290a 0a20 2020 2064  weights()..    d
+00015b70: 6566 2066 6f72 7761 7264 280a 2020 2020  ef forward(.    
+00015b80: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+00015b90: 2020 696e 7075 745f 6964 733d 4e6f 6e65    input_ids=None
+00015ba0: 2c0a 2020 2020 2020 2020 6174 7465 6e74  ,.        attent
+00015bb0: 696f 6e5f 6d61 736b 3d4e 6f6e 652c 0a20  ion_mask=None,. 
+00015bc0: 2020 2020 2020 2074 6f6b 656e 5f74 7970         token_typ
+00015bd0: 655f 6964 733d 4e6f 6e65 2c0a 2020 2020  e_ids=None,.    
+00015be0: 2020 2020 706f 7369 7469 6f6e 5f69 6473      position_ids
+00015bf0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2068  =None,.        h
+00015c00: 6561 645f 6d61 736b 3d4e 6f6e 652c 0a20  ead_mask=None,. 
+00015c10: 2020 2020 2020 2069 6e70 7574 735f 656d         inputs_em
+00015c20: 6265 6473 3d4e 6f6e 652c 0a20 2020 2020  beds=None,.     
+00015c30: 2020 206c 6162 656c 733d 4e6f 6e65 2c0a     labels=None,.
+00015c40: 2020 2020 2020 2020 6f75 7470 7574 5f61          output_a
+00015c50: 7474 656e 7469 6f6e 733d 4e6f 6e65 2c0a  ttentions=None,.
+00015c60: 2020 2020 2020 2020 6f75 7470 7574 5f68          output_h
+00015c70: 6964 6465 6e5f 7374 6174 6573 3d4e 6f6e  idden_states=Non
+00015c80: 652c 0a20 2020 2020 2020 2072 6574 7572  e,.        retur
+00015c90: 6e5f 6469 6374 3d4e 6f6e 652c 0a20 2020  n_dict=None,.   
+00015ca0: 2029 3a0a 2020 2020 2020 2020 7222 2222   ):.        r"""
+00015cb0: 0a20 2020 2020 2020 206c 6162 656c 7320  .        labels 
+00015cc0: 283a 6f62 6a3a 6074 6f72 6368 2e4c 6f6e  (:obj:`torch.Lon
+00015cd0: 6754 656e 736f 7260 206f 6620 7368 6170  gTensor` of shap
+00015ce0: 6520 3a6f 626a 3a60 2862 6174 6368 5f73  e :obj:`(batch_s
+00015cf0: 697a 652c 0a20 2020 2020 2020 2073 6571  ize,.        seq
+00015d00: 7565 6e63 655f 6c65 6e67 7468 2960 2c20  uence_length)`, 
+00015d10: 606f 7074 696f 6e61 6c60 293a 0a20 2020  `optional`):.   
+00015d20: 2020 2020 2020 2020 204c 6162 656c 7320           Labels 
+00015d30: 666f 7220 636f 6d70 7574 696e 6720 7468  for computing th
+00015d40: 6520 746f 6b65 6e20 636c 6173 7369 6669  e token classifi
+00015d50: 6361 7469 6f6e 206c 6f73 732e 2049 6e64  cation loss. Ind
+00015d60: 6963 6573 2073 686f 756c 640a 2020 2020  ices should.    
+00015d70: 2020 2020 2020 2020 6265 2069 6e20 6060          be in ``
+00015d80: 5b30 2c20 2e2e 2e2c 2063 6f6e 6669 672e  [0, ..., config.
+00015d90: 6e75 6d5f 6c61 6265 6c73 202d 2031 5d60  num_labels - 1]`
+00015da0: 602e 0a20 2020 2020 2020 2022 2222 0a20  `..        """. 
+00015db0: 2020 2020 2020 2072 6574 7572 6e5f 6469         return_di
+00015dc0: 6374 203d 2072 6574 7572 6e5f 6469 6374  ct = return_dict
+00015dd0: 2069 6620 7265 7475 726e 5f64 6963 7420   if return_dict 
+00015de0: 6973 206e 6f74 204e 6f6e 6520 656c 7365  is not None else
+00015df0: 2073 656c 662e 636f 6e66 6967 2e75 7365   self.config.use
+00015e00: 5f72 6574 7572 6e5f 6469 6374 0a0a 2020  _return_dict..  
+00015e10: 2020 2020 2020 6f75 7470 7574 7320 3d20        outputs = 
+00015e20: 7365 6c66 2e62 6572 7428 0a20 2020 2020  self.bert(.     
+00015e30: 2020 2020 2020 2069 6e70 7574 5f69 6473         input_ids
+00015e40: 2c0a 2020 2020 2020 2020 2020 2020 6174  ,.            at
+00015e50: 7465 6e74 696f 6e5f 6d61 736b 3d61 7474  tention_mask=att
+00015e60: 656e 7469 6f6e 5f6d 6173 6b2c 0a20 2020  ention_mask,.   
+00015e70: 2020 2020 2020 2020 2074 6f6b 656e 5f74           token_t
+00015e80: 7970 655f 6964 733d 746f 6b65 6e5f 7479  ype_ids=token_ty
+00015e90: 7065 5f69 6473 2c0a 2020 2020 2020 2020  pe_ids,.        
+00015ea0: 2020 2020 706f 7369 7469 6f6e 5f69 6473      position_ids
+00015eb0: 3d70 6f73 6974 696f 6e5f 6964 732c 0a20  =position_ids,. 
+00015ec0: 2020 2020 2020 2020 2020 2068 6561 645f             head_
+00015ed0: 6d61 736b 3d68 6561 645f 6d61 736b 2c0a  mask=head_mask,.
+00015ee0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00015ef0: 7473 5f65 6d62 6564 733d 696e 7075 7473  ts_embeds=inputs
+00015f00: 5f65 6d62 6564 732c 0a20 2020 2020 2020  _embeds,.       
+00015f10: 2020 2020 206f 7574 7075 745f 6174 7465       output_atte
+00015f20: 6e74 696f 6e73 3d6f 7574 7075 745f 6174  ntions=output_at
+00015f30: 7465 6e74 696f 6e73 2c0a 2020 2020 2020  tentions,.      
+00015f40: 2020 2020 2020 6f75 7470 7574 5f68 6964        output_hid
+00015f50: 6465 6e5f 7374 6174 6573 3d6f 7574 7075  den_states=outpu
+00015f60: 745f 6869 6464 656e 5f73 7461 7465 732c  t_hidden_states,
+00015f70: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00015f80: 7572 6e5f 6469 6374 3d72 6574 7572 6e5f  urn_dict=return_
+00015f90: 6469 6374 2c0a 2020 2020 2020 2020 290a  dict,.        ).
+00015fa0: 0a20 2020 2020 2020 2073 6571 7565 6e63  .        sequenc
+00015fb0: 655f 6f75 7470 7574 203d 206f 7574 7075  e_output = outpu
+00015fc0: 7473 5b30 5d0a 0a20 2020 2020 2020 2073  ts[0]..        s
+00015fd0: 6571 7565 6e63 655f 6f75 7470 7574 203d  equence_output =
+00015fe0: 2073 656c 662e 6472 6f70 6f75 7428 7365   self.dropout(se
+00015ff0: 7175 656e 6365 5f6f 7574 7075 7429 0a20  quence_output). 
+00016000: 2020 2020 2020 206c 6f67 6974 7320 3d20         logits = 
+00016010: 7365 6c66 2e63 6c61 7373 6966 6965 7228  self.classifier(
+00016020: 7365 7175 656e 6365 5f6f 7574 7075 7429  sequence_output)
+00016030: 0a0a 2020 2020 2020 2020 6c6f 7373 203d  ..        loss =
+00016040: 204e 6f6e 650a 2020 2020 2020 2020 6966   None.        if
+00016050: 206c 6162 656c 7320 6973 206e 6f74 204e   labels is not N
+00016060: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+00016070: 206c 6f73 735f 6663 7420 3d20 4372 6f73   loss_fct = Cros
+00016080: 7345 6e74 726f 7079 4c6f 7373 2829 0a20  sEntropyLoss(). 
+00016090: 2020 2020 2020 2020 2020 2023 204f 6e6c             # Onl
+000160a0: 7920 6b65 6570 2061 6374 6976 6520 7061  y keep active pa
+000160b0: 7274 7320 6f66 2074 6865 206c 6f73 730a  rts of the loss.
+000160c0: 2020 2020 2020 2020 2020 2020 6966 2061              if a
+000160d0: 7474 656e 7469 6f6e 5f6d 6173 6b20 6973  ttention_mask is
+000160e0: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+000160f0: 2020 2020 2020 2020 2020 2061 6374 6976             activ
+00016100: 655f 6c6f 7373 203d 2061 7474 656e 7469  e_loss = attenti
+00016110: 6f6e 5f6d 6173 6b2e 7669 6577 282d 3129  on_mask.view(-1)
+00016120: 203d 3d20 310a 2020 2020 2020 2020 2020   == 1.          
+00016130: 2020 2020 2020 6163 7469 7665 5f6c 6f67        active_log
+00016140: 6974 7320 3d20 6c6f 6769 7473 2e76 6965  its = logits.vie
+00016150: 7728 2d31 2c20 7365 6c66 2e6e 756d 5f6c  w(-1, self.num_l
+00016160: 6162 656c 7329 0a20 2020 2020 2020 2020  abels).         
+00016170: 2020 2020 2020 2061 6374 6976 655f 6c61         active_la
+00016180: 6265 6c73 203d 2074 6f72 6368 2e77 6865  bels = torch.whe
+00016190: 7265 280a 2020 2020 2020 2020 2020 2020  re(.            
+000161a0: 2020 2020 2020 2020 6163 7469 7665 5f6c          active_l
+000161b0: 6f73 732c 206c 6162 656c 732e 7669 6577  oss, labels.view
+000161c0: 282d 3129 2c0a 2020 2020 2020 2020 2020  (-1),.          
+000161d0: 2020 2020 2020 2020 2020 746f 7263 682e            torch.
+000161e0: 7465 6e73 6f72 286c 6f73 735f 6663 742e  tensor(loss_fct.
+000161f0: 6967 6e6f 7265 5f69 6e64 6578 292e 7479  ignore_index).ty
+00016200: 7065 5f61 7328 6c61 6265 6c73 2929 0a20  pe_as(labels)). 
+00016210: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+00016220: 6f73 7320 3d20 6c6f 7373 5f66 6374 2861  oss = loss_fct(a
+00016230: 6374 6976 655f 6c6f 6769 7473 2c20 6163  ctive_logits, ac
+00016240: 7469 7665 5f6c 6162 656c 7329 0a20 2020  tive_labels).   
+00016250: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+00016260: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+00016270: 6f73 7320 3d20 6c6f 7373 5f66 6374 280a  oss = loss_fct(.
+00016280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016290: 2020 2020 6c6f 6769 7473 2e76 6965 7728      logits.view(
+000162a0: 2d31 2c20 7365 6c66 2e6e 756d 5f6c 6162  -1, self.num_lab
+000162b0: 656c 7329 2c20 6c61 6265 6c73 2e76 6965  els), labels.vie
+000162c0: 7728 2d31 2929 0a0a 2020 2020 2020 2020  w(-1))..        
+000162d0: 6966 206e 6f74 2072 6574 7572 6e5f 6469  if not return_di
+000162e0: 6374 3a0a 2020 2020 2020 2020 2020 2020  ct:.            
+000162f0: 6f75 7470 7574 203d 2028 6c6f 6769 7473  output = (logits
+00016300: 2c20 2920 2b20 6f75 7470 7574 735b 323a  , ) + outputs[2:
+00016310: 5d0a 2020 2020 2020 2020 2020 2020 7265  ].            re
+00016320: 7475 726e 2028 286c 6f73 732c 2029 202b  turn ((loss, ) +
+00016330: 206f 7574 7075 7429 2069 6620 6c6f 7373   output) if loss
+00016340: 2069 7320 6e6f 7420 4e6f 6e65 2065 6c73   is not None els
+00016350: 6520 6f75 7470 7574 0a0a 2020 2020 2020  e output..      
+00016360: 2020 7265 7475 726e 2054 6f6b 656e 436c    return TokenCl
+00016370: 6173 7369 6669 6572 4f75 7470 7574 280a  assifierOutput(.
+00016380: 2020 2020 2020 2020 2020 2020 6c6f 7373              loss
+00016390: 3d6c 6f73 732c 0a20 2020 2020 2020 2020  =loss,.         
+000163a0: 2020 206c 6f67 6974 733d 6c6f 6769 7473     logits=logits
+000163b0: 2c0a 2020 2020 2020 2020 2020 2020 6869  ,.            hi
+000163c0: 6464 656e 5f73 7461 7465 733d 6f75 7470  dden_states=outp
+000163d0: 7574 732e 6869 6464 656e 5f73 7461 7465  uts.hidden_state
+000163e0: 732c 0a20 2020 2020 2020 2020 2020 2061  s,.            a
+000163f0: 7474 656e 7469 6f6e 733d 6f75 7470 7574  ttentions=output
+00016400: 732e 6174 7465 6e74 696f 6e73 2c0a 2020  s.attentions,.  
+00016410: 2020 2020 2020 290a 0a0a 636c 6173 7320        )...class 
+00016420: 4265 7274 466f 7251 7565 7374 696f 6e41  BertForQuestionA
+00016430: 6e73 7765 7269 6e67 2842 6572 7450 7265  nswering(BertPre
+00016440: 5472 6169 6e65 644d 6f64 656c 293a 0a0a  TrainedModel):..
+00016450: 2020 2020 5f6b 6579 735f 746f 5f69 676e      _keys_to_ign
+00016460: 6f72 655f 6f6e 5f6c 6f61 645f 756e 6578  ore_on_load_unex
+00016470: 7065 6374 6564 203d 205b 7227 706f 6f6c  pected = [r'pool
+00016480: 6572 275d 0a0a 2020 2020 6465 6620 5f5f  er']..    def __
+00016490: 696e 6974 5f5f 2873 656c 662c 2063 6f6e  init__(self, con
+000164a0: 6669 6729 3a0a 2020 2020 2020 2020 7375  fig):.        su
+000164b0: 7065 7228 292e 5f5f 696e 6974 5f5f 2863  per().__init__(c
+000164c0: 6f6e 6669 6729 0a20 2020 2020 2020 2073  onfig).        s
+000164d0: 656c 662e 6e75 6d5f 6c61 6265 6c73 203d  elf.num_labels =
+000164e0: 2063 6f6e 6669 672e 6e75 6d5f 6c61 6265   config.num_labe
+000164f0: 6c73 0a0a 2020 2020 2020 2020 7365 6c66  ls..        self
+00016500: 2e62 6572 7420 3d20 4265 7274 4d6f 6465  .bert = BertMode
+00016510: 6c28 636f 6e66 6967 2c20 6164 645f 706f  l(config, add_po
+00016520: 6f6c 696e 675f 6c61 7965 723d 4661 6c73  oling_layer=Fals
+00016530: 6529 0a20 2020 2020 2020 2073 656c 662e  e).        self.
+00016540: 7161 5f6f 7574 7075 7473 203d 206e 6e2e  qa_outputs = nn.
+00016550: 4c69 6e65 6172 2863 6f6e 6669 672e 6869  Linear(config.hi
+00016560: 6464 656e 5f73 697a 652c 2063 6f6e 6669  dden_size, confi
+00016570: 672e 6e75 6d5f 6c61 6265 6c73 290a 0a20  g.num_labels).. 
+00016580: 2020 2020 2020 2073 656c 662e 696e 6974         self.init
+00016590: 5f77 6569 6768 7473 2829 0a0a 2020 2020  _weights()..    
+000165a0: 6465 6620 666f 7277 6172 6428 0a20 2020  def forward(.   
+000165b0: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+000165c0: 2020 2069 6e70 7574 5f69 6473 3d4e 6f6e     input_ids=Non
+000165d0: 652c 0a20 2020 2020 2020 2061 7474 656e  e,.        atten
+000165e0: 7469 6f6e 5f6d 6173 6b3d 4e6f 6e65 2c0a  tion_mask=None,.
+000165f0: 2020 2020 2020 2020 746f 6b65 6e5f 7479          token_ty
+00016600: 7065 5f69 6473 3d4e 6f6e 652c 0a20 2020  pe_ids=None,.   
+00016610: 2020 2020 2070 6f73 6974 696f 6e5f 6964       position_id
+00016620: 733d 4e6f 6e65 2c0a 2020 2020 2020 2020  s=None,.        
+00016630: 6865 6164 5f6d 6173 6b3d 4e6f 6e65 2c0a  head_mask=None,.
+00016640: 2020 2020 2020 2020 696e 7075 7473 5f65          inputs_e
+00016650: 6d62 6564 733d 4e6f 6e65 2c0a 2020 2020  mbeds=None,.    
+00016660: 2020 2020 7374 6172 745f 706f 7369 7469      start_positi
+00016670: 6f6e 733d 4e6f 6e65 2c0a 2020 2020 2020  ons=None,.      
+00016680: 2020 656e 645f 706f 7369 7469 6f6e 733d    end_positions=
+00016690: 4e6f 6e65 2c0a 2020 2020 2020 2020 6f75  None,.        ou
+000166a0: 7470 7574 5f61 7474 656e 7469 6f6e 733d  tput_attentions=
+000166b0: 4e6f 6e65 2c0a 2020 2020 2020 2020 6f75  None,.        ou
+000166c0: 7470 7574 5f68 6964 6465 6e5f 7374 6174  tput_hidden_stat
+000166d0: 6573 3d4e 6f6e 652c 0a20 2020 2020 2020  es=None,.       
+000166e0: 2072 6574 7572 6e5f 6469 6374 3d4e 6f6e   return_dict=Non
+000166f0: 652c 0a20 2020 2029 3a0a 2020 2020 2020  e,.    ):.      
+00016700: 2020 7222 2222 0a20 2020 2020 2020 2073    r""".        s
+00016710: 7461 7274 5f70 6f73 6974 696f 6e73 2028  tart_positions (
+00016720: 3a6f 626a 3a60 746f 7263 682e 4c6f 6e67  :obj:`torch.Long
+00016730: 5465 6e73 6f72 6020 6f66 2073 6861 7065  Tensor` of shape
+00016740: 203a 6f62 6a3a 6028 6261 7463 685f 7369   :obj:`(batch_si
+00016750: 7a65 2c29 602c 0a20 2020 2020 2020 2060  ze,)`,.        `
+00016760: 6f70 7469 6f6e 616c 6029 3a0a 2020 2020  optional`):.    
+00016770: 2020 2020 2020 2020 4c61 6265 6c73 2066          Labels f
+00016780: 6f72 2070 6f73 6974 696f 6e20 2869 6e64  or position (ind
+00016790: 6578 2920 6f66 2074 6865 2073 7461 7274  ex) of the start
+000167a0: 206f 6620 7468 6520 6c61 6265 6c6c 6564   of the labelled
+000167b0: 2073 7061 6e20 666f 720a 2020 2020 2020   span for.      
+000167c0: 2020 2020 2020 636f 6d70 7574 696e 6720        computing 
+000167d0: 7468 6520 746f 6b65 6e20 636c 6173 7369  the token classi
+000167e0: 6669 6361 7469 6f6e 206c 6f73 732e 2050  fication loss. P
+000167f0: 6f73 6974 696f 6e73 2061 7265 2063 6c61  ositions are cla
+00016800: 6d70 6564 2074 6f0a 2020 2020 2020 2020  mped to.        
+00016810: 2020 2020 7468 6520 6c65 6e67 7468 206f      the length o
+00016820: 6620 7468 6520 7365 7175 656e 6365 2028  f the sequence (
+00016830: 3a6f 626a 3a60 7365 7175 656e 6365 5f6c  :obj:`sequence_l
+00016840: 656e 6774 6860 292e 2050 6f73 6974 696f  ength`). Positio
+00016850: 6e0a 2020 2020 2020 2020 2020 2020 6f75  n.            ou
+00016860: 7473 6964 6520 6f66 2074 6865 2073 6571  tside of the seq
+00016870: 7565 6e63 6520 6172 6520 6e6f 7420 7461  uence are not ta
+00016880: 6b65 6e20 696e 746f 2061 6363 6f75 6e74  ken into account
+00016890: 2066 6f72 2063 6f6d 7075 7469 6e67 2074   for computing t
+000168a0: 6865 0a20 2020 2020 2020 2020 2020 206c  he.            l
+000168b0: 6f73 732e 0a20 2020 2020 2020 2065 6e64  oss..        end
+000168c0: 5f70 6f73 6974 696f 6e73 2028 3a6f 626a  _positions (:obj
+000168d0: 3a60 746f 7263 682e 4c6f 6e67 5465 6e73  :`torch.LongTens
+000168e0: 6f72 6020 6f66 2073 6861 7065 203a 6f62  or` of shape :ob
+000168f0: 6a3a 6028 6261 7463 685f 7369 7a65 2c29  j:`(batch_size,)
+00016900: 602c 0a20 2020 2020 2020 2060 6f70 7469  `,.        `opti
+00016910: 6f6e 616c 6029 3a0a 2020 2020 2020 2020  onal`):.        
+00016920: 2020 2020 4c61 6265 6c73 2066 6f72 2070      Labels for p
+00016930: 6f73 6974 696f 6e20 2869 6e64 6578 2920  osition (index) 
+00016940: 6f66 2074 6865 2065 6e64 206f 6620 7468  of the end of th
+00016950: 6520 6c61 6265 6c6c 6564 2073 7061 6e20  e labelled span 
+00016960: 666f 720a 2020 2020 2020 2020 2020 2020  for.            
+00016970: 636f 6d70 7574 696e 6720 7468 6520 746f  computing the to
+00016980: 6b65 6e20 636c 6173 7369 6669 6361 7469  ken classificati
+00016990: 6f6e 206c 6f73 732e 2050 6f73 6974 696f  on loss. Positio
+000169a0: 6e73 2061 7265 2063 6c61 6d70 6564 2074  ns are clamped t
+000169b0: 6f0a 2020 2020 2020 2020 2020 2020 7468  o.            th
+000169c0: 6520 6c65 6e67 7468 206f 6620 7468 6520  e length of the 
+000169d0: 7365 7175 656e 6365 2028 3a6f 626a 3a60  sequence (:obj:`
+000169e0: 7365 7175 656e 6365 5f6c 656e 6774 6860  sequence_length`
+000169f0: 292e 2050 6f73 6974 696f 6e0a 2020 2020  ). Position.    
+00016a00: 2020 2020 2020 2020 6f75 7473 6964 6520          outside 
+00016a10: 6f66 2074 6865 2073 6571 7565 6e63 6520  of the sequence 
+00016a20: 6172 6520 6e6f 7420 7461 6b65 6e20 696e  are not taken in
+00016a30: 746f 2061 6363 6f75 6e74 2066 6f72 2063  to account for c
+00016a40: 6f6d 7075 7469 6e67 2074 6865 0a20 2020  omputing the.   
+00016a50: 2020 2020 2020 2020 206c 6f73 732e 0a20           loss.. 
+00016a60: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00016a70: 2020 2072 6574 7572 6e5f 6469 6374 203d     return_dict =
+00016a80: 2072 6574 7572 6e5f 6469 6374 2069 6620   return_dict if 
+00016a90: 7265 7475 726e 5f64 6963 7420 6973 206e  return_dict is n
+00016aa0: 6f74 204e 6f6e 6520 656c 7365 2073 656c  ot None else sel
+00016ab0: 662e 636f 6e66 6967 2e75 7365 5f72 6574  f.config.use_ret
+00016ac0: 7572 6e5f 6469 6374 0a0a 2020 2020 2020  urn_dict..      
+00016ad0: 2020 6f75 7470 7574 7320 3d20 7365 6c66    outputs = self
+00016ae0: 2e62 6572 7428 0a20 2020 2020 2020 2020  .bert(.         
+00016af0: 2020 2069 6e70 7574 5f69 6473 2c0a 2020     input_ids,.  
+00016b00: 2020 2020 2020 2020 2020 6174 7465 6e74            attent
+00016b10: 696f 6e5f 6d61 736b 3d61 7474 656e 7469  ion_mask=attenti
+00016b20: 6f6e 5f6d 6173 6b2c 0a20 2020 2020 2020  on_mask,.       
+00016b30: 2020 2020 2074 6f6b 656e 5f74 7970 655f       token_type_
+00016b40: 6964 733d 746f 6b65 6e5f 7479 7065 5f69  ids=token_type_i
+00016b50: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
+00016b60: 706f 7369 7469 6f6e 5f69 6473 3d70 6f73  position_ids=pos
+00016b70: 6974 696f 6e5f 6964 732c 0a20 2020 2020  ition_ids,.     
+00016b80: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
+00016b90: 3d68 6561 645f 6d61 736b 2c0a 2020 2020  =head_mask,.    
+00016ba0: 2020 2020 2020 2020 696e 7075 7473 5f65          inputs_e
+00016bb0: 6d62 6564 733d 696e 7075 7473 5f65 6d62  mbeds=inputs_emb
+00016bc0: 6564 732c 0a20 2020 2020 2020 2020 2020  eds,.           
+00016bd0: 206f 7574 7075 745f 6174 7465 6e74 696f   output_attentio
+00016be0: 6e73 3d6f 7574 7075 745f 6174 7465 6e74  ns=output_attent
+00016bf0: 696f 6e73 2c0a 2020 2020 2020 2020 2020  ions,.          
+00016c00: 2020 6f75 7470 7574 5f68 6964 6465 6e5f    output_hidden_
+00016c10: 7374 6174 6573 3d6f 7574 7075 745f 6869  states=output_hi
+00016c20: 6464 656e 5f73 7461 7465 732c 0a20 2020  dden_states,.   
+00016c30: 2020 2020 2020 2020 2072 6574 7572 6e5f           return_
+00016c40: 6469 6374 3d72 6574 7572 6e5f 6469 6374  dict=return_dict
+00016c50: 2c0a 2020 2020 2020 2020 290a 0a20 2020  ,.        )..   
+00016c60: 2020 2020 2073 6571 7565 6e63 655f 6f75       sequence_ou
+00016c70: 7470 7574 203d 206f 7574 7075 7473 5b30  tput = outputs[0
+00016c80: 5d0a 0a20 2020 2020 2020 206c 6f67 6974  ]..        logit
+00016c90: 7320 3d20 7365 6c66 2e71 615f 6f75 7470  s = self.qa_outp
+00016ca0: 7574 7328 7365 7175 656e 6365 5f6f 7574  uts(sequence_out
+00016cb0: 7075 7429 0a20 2020 2020 2020 2073 7461  put).        sta
+00016cc0: 7274 5f6c 6f67 6974 732c 2065 6e64 5f6c  rt_logits, end_l
+00016cd0: 6f67 6974 7320 3d20 6c6f 6769 7473 2e73  ogits = logits.s
+00016ce0: 706c 6974 2831 2c20 6469 6d3d 2d31 290a  plit(1, dim=-1).
+00016cf0: 2020 2020 2020 2020 7374 6172 745f 6c6f          start_lo
+00016d00: 6769 7473 203d 2073 7461 7274 5f6c 6f67  gits = start_log
+00016d10: 6974 732e 7371 7565 657a 6528 2d31 290a  its.squeeze(-1).
+00016d20: 2020 2020 2020 2020 656e 645f 6c6f 6769          end_logi
+00016d30: 7473 203d 2065 6e64 5f6c 6f67 6974 732e  ts = end_logits.
+00016d40: 7371 7565 657a 6528 2d31 290a 0a20 2020  squeeze(-1)..   
+00016d50: 2020 2020 2074 6f74 616c 5f6c 6f73 7320       total_loss 
+00016d60: 3d20 4e6f 6e65 0a20 2020 2020 2020 2069  = None.        i
+00016d70: 6620 7374 6172 745f 706f 7369 7469 6f6e  f start_position
+00016d80: 7320 6973 206e 6f74 204e 6f6e 6520 616e  s is not None an
+00016d90: 6420 656e 645f 706f 7369 7469 6f6e 7320  d end_positions 
+00016da0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+00016db0: 2020 2020 2020 2020 2023 2049 6620 7765           # If we
+00016dc0: 2061 7265 206f 6e20 6d75 6c74 692d 4750   are on multi-GP
+00016dd0: 552c 2073 706c 6974 2061 6464 2061 2064  U, split add a d
+00016de0: 696d 656e 7369 6f6e 0a20 2020 2020 2020  imension.       
+00016df0: 2020 2020 2069 6620 6c65 6e28 7374 6172       if len(star
+00016e00: 745f 706f 7369 7469 6f6e 732e 7369 7a65  t_positions.size
+00016e10: 2829 2920 3e20 313a 0a20 2020 2020 2020  ()) > 1:.       
+00016e20: 2020 2020 2020 2020 2073 7461 7274 5f70           start_p
+00016e30: 6f73 6974 696f 6e73 203d 2073 7461 7274  ositions = start
+00016e40: 5f70 6f73 6974 696f 6e73 2e73 7175 6565  _positions.squee
+00016e50: 7a65 282d 3129 0a20 2020 2020 2020 2020  ze(-1).         
+00016e60: 2020 2069 6620 6c65 6e28 656e 645f 706f     if len(end_po
+00016e70: 7369 7469 6f6e 732e 7369 7a65 2829 2920  sitions.size()) 
+00016e80: 3e20 313a 0a20 2020 2020 2020 2020 2020  > 1:.           
+00016e90: 2020 2020 2065 6e64 5f70 6f73 6974 696f       end_positio
+00016ea0: 6e73 203d 2065 6e64 5f70 6f73 6974 696f  ns = end_positio
+00016eb0: 6e73 2e73 7175 6565 7a65 282d 3129 0a20  ns.squeeze(-1). 
+00016ec0: 2020 2020 2020 2020 2020 2023 2073 6f6d             # som
+00016ed0: 6574 696d 6573 2074 6865 2073 7461 7274  etimes the start
+00016ee0: 2f65 6e64 2070 6f73 6974 696f 6e73 2061  /end positions a
+00016ef0: 7265 206f 7574 7369 6465 206f 7572 206d  re outside our m
+00016f00: 6f64 656c 2069 6e70 7574 732c 2077 6520  odel inputs, we 
+00016f10: 6967 6e6f 7265 2074 6865 7365 2074 6572  ignore these ter
+00016f20: 6d73 0a20 2020 2020 2020 2020 2020 2069  ms.            i
+00016f30: 676e 6f72 6564 5f69 6e64 6578 203d 2073  gnored_index = s
+00016f40: 7461 7274 5f6c 6f67 6974 732e 7369 7a65  tart_logits.size
+00016f50: 2831 290a 2020 2020 2020 2020 2020 2020  (1).            
+00016f60: 7374 6172 745f 706f 7369 7469 6f6e 732e  start_positions.
+00016f70: 636c 616d 705f 2830 2c20 6967 6e6f 7265  clamp_(0, ignore
+00016f80: 645f 696e 6465 7829 0a20 2020 2020 2020  d_index).       
+00016f90: 2020 2020 2065 6e64 5f70 6f73 6974 696f       end_positio
+00016fa0: 6e73 2e63 6c61 6d70 5f28 302c 2069 676e  ns.clamp_(0, ign
+00016fb0: 6f72 6564 5f69 6e64 6578 290a 0a20 2020  ored_index)..   
+00016fc0: 2020 2020 2020 2020 206c 6f73 735f 6663           loss_fc
+00016fd0: 7420 3d20 4372 6f73 7345 6e74 726f 7079  t = CrossEntropy
+00016fe0: 4c6f 7373 2869 676e 6f72 655f 696e 6465  Loss(ignore_inde
+00016ff0: 783d 6967 6e6f 7265 645f 696e 6465 7829  x=ignored_index)
+00017000: 0a20 2020 2020 2020 2020 2020 2073 7461  .            sta
+00017010: 7274 5f6c 6f73 7320 3d20 6c6f 7373 5f66  rt_loss = loss_f
+00017020: 6374 2873 7461 7274 5f6c 6f67 6974 732c  ct(start_logits,
+00017030: 2073 7461 7274 5f70 6f73 6974 696f 6e73   start_positions
+00017040: 290a 2020 2020 2020 2020 2020 2020 656e  ).            en
+00017050: 645f 6c6f 7373 203d 206c 6f73 735f 6663  d_loss = loss_fc
+00017060: 7428 656e 645f 6c6f 6769 7473 2c20 656e  t(end_logits, en
+00017070: 645f 706f 7369 7469 6f6e 7329 0a20 2020  d_positions).   
+00017080: 2020 2020 2020 2020 2074 6f74 616c 5f6c           total_l
+00017090: 6f73 7320 3d20 2873 7461 7274 5f6c 6f73  oss = (start_los
+000170a0: 7320 2b20 656e 645f 6c6f 7373 2920 2f20  s + end_loss) / 
+000170b0: 320a 0a20 2020 2020 2020 2069 6620 6e6f  2..        if no
+000170c0: 7420 7265 7475 726e 5f64 6963 743a 0a20  t return_dict:. 
+000170d0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+000170e0: 7420 3d20 2873 7461 7274 5f6c 6f67 6974  t = (start_logit
+000170f0: 732c 2065 6e64 5f6c 6f67 6974 7329 202b  s, end_logits) +
+00017100: 206f 7574 7075 7473 5b32 3a5d 0a20 2020   outputs[2:].   
+00017110: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00017120: 2828 746f 7461 6c5f 6c6f 7373 2c20 290a  ((total_loss, ).
+00017130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017140: 2020 2020 2b20 6f75 7470 7574 2920 6966      + output) if
+00017150: 2074 6f74 616c 5f6c 6f73 7320 6973 206e   total_loss is n
+00017160: 6f74 204e 6f6e 6520 656c 7365 206f 7574  ot None else out
+00017170: 7075 740a 0a20 2020 2020 2020 2072 6574  put..        ret
+00017180: 7572 6e20 5175 6573 7469 6f6e 416e 7377  urn QuestionAnsw
+00017190: 6572 696e 674d 6f64 656c 4f75 7470 7574  eringModelOutput
+000171a0: 280a 2020 2020 2020 2020 2020 2020 6c6f  (.            lo
+000171b0: 7373 3d74 6f74 616c 5f6c 6f73 732c 0a20  ss=total_loss,. 
+000171c0: 2020 2020 2020 2020 2020 2073 7461 7274             start
+000171d0: 5f6c 6f67 6974 733d 7374 6172 745f 6c6f  _logits=start_lo
+000171e0: 6769 7473 2c0a 2020 2020 2020 2020 2020  gits,.          
+000171f0: 2020 656e 645f 6c6f 6769 7473 3d65 6e64    end_logits=end
+00017200: 5f6c 6f67 6974 732c 0a20 2020 2020 2020  _logits,.       
+00017210: 2020 2020 2068 6964 6465 6e5f 7374 6174       hidden_stat
+00017220: 6573 3d6f 7574 7075 7473 2e68 6964 6465  es=outputs.hidde
+00017230: 6e5f 7374 6174 6573 2c0a 2020 2020 2020  n_states,.      
+00017240: 2020 2020 2020 6174 7465 6e74 696f 6e73        attentions
+00017250: 3d6f 7574 7075 7473 2e61 7474 656e 7469  =outputs.attenti
+00017260: 6f6e 732c 0a20 2020 2020 2020 2029 0a0a  ons,.        )..
+00017270: 0a63 6c61 7373 204d 4765 6f50 7265 5472  .class MGeoPreTr
+00017280: 6169 6e65 644d 6f64 656c 2854 6f72 6368  ainedModel(Torch
+00017290: 4d6f 6465 6c2c 2050 7265 5472 6169 6e65  Model, PreTraine
+000172a0: 644d 6f64 656c 293a 0a20 2020 2022 2222  dModel):.    """
+000172b0: 0a20 2020 2041 6e20 6162 7374 7261 6374  .    An abstract
+000172c0: 2063 6c61 7373 2074 6f20 6861 6e64 6c65   class to handle
+000172d0: 2077 6569 6768 7473 2069 6e69 7469 616c   weights initial
+000172e0: 697a 6174 696f 6e20 616e 6420 6120 7369  ization and a si
+000172f0: 6d70 6c65 2069 6e74 6572 6661 6365 0a20  mple interface. 
+00017300: 2020 2066 6f72 2064 6f77 6e6c 6f61 6469     for downloadi
+00017310: 6e67 2061 6e64 206c 6f61 6469 6e67 2070  ng and loading p
+00017320: 7265 7472 6169 6e65 6420 6d6f 6465 6c73  retrained models
+00017330: 2e0a 2020 2020 2222 220a 0a20 2020 2063  ..    """..    c
+00017340: 6f6e 6669 675f 636c 6173 7320 3d20 4265  onfig_class = Be
+00017350: 7274 436f 6e66 6967 0a20 2020 2062 6173  rtConfig.    bas
+00017360: 655f 6d6f 6465 6c5f 7072 6566 6978 203d  e_model_prefix =
+00017370: 2027 6265 7274 270a 2020 2020 7375 7070   'bert'.    supp
+00017380: 6f72 7473 5f67 7261 6469 656e 745f 6368  orts_gradient_ch
+00017390: 6563 6b70 6f69 6e74 696e 6720 3d20 5472  eckpointing = Tr
+000173a0: 7565 0a20 2020 205f 6b65 7973 5f74 6f5f  ue.    _keys_to_
+000173b0: 6967 6e6f 7265 5f6f 6e5f 6c6f 6164 5f6d  ignore_on_load_m
+000173c0: 6973 7369 6e67 203d 205b 7227 706f 7369  issing = [r'posi
+000173d0: 7469 6f6e 5f69 6473 275d 0a0a 2020 2020  tion_ids']..    
+000173e0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+000173f0: 662c 2063 6f6e 6669 672c 202a 2a6b 7761  f, config, **kwa
+00017400: 7267 7329 3a0a 2020 2020 2020 2020 7375  rgs):.        su
+00017410: 7065 7228 292e 5f5f 696e 6974 5f5f 2863  per().__init__(c
+00017420: 6f6e 6669 672e 6e61 6d65 5f6f 725f 7061  onfig.name_or_pa
+00017430: 7468 2c20 2a2a 6b77 6172 6773 290a 2020  th, **kwargs).  
+00017440: 2020 2020 2020 7375 7065 7228 4261 7365        super(Base
+00017450: 4d6f 6465 6c2c 2073 656c 6629 2e5f 5f69  Model, self).__i
+00017460: 6e69 745f 5f28 636f 6e66 6967 290a 0a20  nit__(config).. 
+00017470: 2020 2064 6566 205f 696e 6974 5f77 6569     def _init_wei
+00017480: 6768 7473 2873 656c 662c 206d 6f64 756c  ghts(self, modul
+00017490: 6529 3a0a 2020 2020 2020 2020 2222 2249  e):.        """I
+000174a0: 6e69 7469 616c 697a 6520 7468 6520 7765  nitialize the we
+000174b0: 6967 6874 7322 2222 0a20 2020 2020 2020  ights""".       
+000174c0: 2069 6620 6973 696e 7374 616e 6365 286d   if isinstance(m
+000174d0: 6f64 756c 652c 206e 6e2e 4c69 6e65 6172  odule, nn.Linear
+000174e0: 293a 0a20 2020 2020 2020 2020 2020 2023  ):.            #
+000174f0: 2053 6c69 6768 746c 7920 6469 6666 6572   Slightly differ
+00017500: 656e 7420 6672 6f6d 2074 6865 2054 4620  ent from the TF 
+00017510: 7665 7273 696f 6e20 7768 6963 6820 7573  version which us
+00017520: 6573 2074 7275 6e63 6174 6564 5f6e 6f72  es truncated_nor
+00017530: 6d61 6c20 666f 7220 696e 6974 6961 6c69  mal for initiali
+00017540: 7a61 7469 6f6e 0a20 2020 2020 2020 2020  zation.         
+00017550: 2020 2023 2063 6620 6874 7470 733a 2f2f     # cf https://
+00017560: 6769 7468 7562 2e63 6f6d 2f70 7974 6f72  github.com/pytor
+00017570: 6368 2f70 7974 6f72 6368 2f70 756c 6c2f  ch/pytorch/pull/
+00017580: 3536 3137 0a20 2020 2020 2020 2020 2020  5617.           
+00017590: 206d 6f64 756c 652e 7765 6967 6874 2e64   module.weight.d
+000175a0: 6174 612e 6e6f 726d 616c 5f28 0a20 2020  ata.normal_(.   
+000175b0: 2020 2020 2020 2020 2020 2020 206d 6561               mea
+000175c0: 6e3d 302e 302c 2073 7464 3d73 656c 662e  n=0.0, std=self.
+000175d0: 636f 6e66 6967 2e69 6e69 7469 616c 697a  config.initializ
+000175e0: 6572 5f72 616e 6765 290a 2020 2020 2020  er_range).      
+000175f0: 2020 2020 2020 6966 206d 6f64 756c 652e        if module.
+00017600: 6269 6173 2069 7320 6e6f 7420 4e6f 6e65  bias is not None
+00017610: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00017620: 2020 6d6f 6475 6c65 2e62 6961 732e 6461    module.bias.da
+00017630: 7461 2e7a 6572 6f5f 2829 0a20 2020 2020  ta.zero_().     
+00017640: 2020 2065 6c69 6620 6973 696e 7374 616e     elif isinstan
+00017650: 6365 286d 6f64 756c 652c 206e 6e2e 456d  ce(module, nn.Em
+00017660: 6265 6464 696e 6729 3a0a 2020 2020 2020  bedding):.      
+00017670: 2020 2020 2020 6d6f 6475 6c65 2e77 6569        module.wei
+00017680: 6768 742e 6461 7461 2e6e 6f72 6d61 6c5f  ght.data.normal_
+00017690: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+000176a0: 2020 6d65 616e 3d30 2e30 2c20 7374 643d    mean=0.0, std=
+000176b0: 7365 6c66 2e63 6f6e 6669 672e 696e 6974  self.config.init
+000176c0: 6961 6c69 7a65 725f 7261 6e67 6529 0a20  ializer_range). 
+000176d0: 2020 2020 2020 2020 2020 2069 6620 6d6f             if mo
+000176e0: 6475 6c65 2e70 6164 6469 6e67 5f69 6478  dule.padding_idx
+000176f0: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+00017700: 2020 2020 2020 2020 2020 2020 2020 6d6f                mo
+00017710: 6475 6c65 2e77 6569 6768 742e 6461 7461  dule.weight.data
+00017720: 5b6d 6f64 756c 652e 7061 6464 696e 675f  [module.padding_
+00017730: 6964 785d 2e7a 6572 6f5f 2829 0a20 2020  idx].zero_().   
+00017740: 2020 2020 2065 6c69 6620 6973 696e 7374       elif isinst
+00017750: 616e 6365 286d 6f64 756c 652c 206e 6e2e  ance(module, nn.
+00017760: 4c61 7965 724e 6f72 6d29 3a0a 2020 2020  LayerNorm):.    
+00017770: 2020 2020 2020 2020 6d6f 6475 6c65 2e62          module.b
+00017780: 6961 732e 6461 7461 2e7a 6572 6f5f 2829  ias.data.zero_()
+00017790: 0a20 2020 2020 2020 2020 2020 206d 6f64  .            mod
+000177a0: 756c 652e 7765 6967 6874 2e64 6174 612e  ule.weight.data.
+000177b0: 6669 6c6c 5f28 312e 3029 0a0a 2020 2020  fill_(1.0)..    
+000177c0: 6465 6620 5f73 6574 5f67 7261 6469 656e  def _set_gradien
+000177d0: 745f 6368 6563 6b70 6f69 6e74 696e 6728  t_checkpointing(
+000177e0: 7365 6c66 2c20 6d6f 6475 6c65 2c20 7661  self, module, va
+000177f0: 6c75 653d 4661 6c73 6529 3a0a 2020 2020  lue=False):.    
+00017800: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+00017810: 6528 6d6f 6475 6c65 2c20 4265 7274 456e  e(module, BertEn
+00017820: 636f 6465 7229 3a0a 2020 2020 2020 2020  coder):.        
+00017830: 2020 2020 6d6f 6475 6c65 2e67 7261 6469      module.gradi
+00017840: 656e 745f 6368 6563 6b70 6f69 6e74 696e  ent_checkpointin
+00017850: 6720 3d20 7661 6c75 650a 0a20 2020 2040  g = value..    @
+00017860: 636c 6173 736d 6574 686f 640a 2020 2020  classmethod.    
+00017870: 6465 6620 5f69 6e73 7461 6e74 6961 7465  def _instantiate
+00017880: 2863 6c73 2c20 2a2a 6b77 6172 6773 293a  (cls, **kwargs):
+00017890: 0a20 2020 2020 2020 2022 2222 496e 7374  .        """Inst
+000178a0: 616e 7469 6174 6520 7468 6520 6d6f 6465  antiate the mode
+000178b0: 6c2e 0a0a 2020 2020 2020 2020 4172 6773  l...        Args
+000178c0: 3a0a 2020 2020 2020 2020 2020 2020 6b77  :.            kw
+000178d0: 6172 6773 3a20 496e 7075 7420 6172 6773  args: Input args
+000178e0: 2e0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000178f0: 2020 2020 2020 6d6f 6465 6c5f 6469 723a        model_dir:
+00017900: 2054 6865 206d 6f64 656c 2064 6972 2075   The model dir u
+00017910: 7365 6420 746f 206c 6f61 6420 7468 6520  sed to load the 
+00017920: 6368 6563 6b70 6f69 6e74 2061 6e64 2074  checkpoint and t
+00017930: 6865 0a20 2020 2020 2020 2020 2020 2020  he.             
+00017940: 2020 2020 2020 206c 6162 656c 2069 6e66         label inf
+00017950: 6f72 6d61 7469 6f6e 2e20 6e75 6d5f 6c61  ormation. num_la
+00017960: 6265 6c73 3a20 416e 206f 7074 696f 6e61  bels: An optiona
+00017970: 6c20 6172 6720 746f 2074 656c 6c20 7468  l arg to tell th
+00017980: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+00017990: 2020 2020 2020 6d6f 6465 6c20 686f 7720        model how 
+000179a0: 6d61 6e79 2063 6c61 7373 6573 2074 6f20  many classes to 
+000179b0: 696e 6974 6961 6c69 7a65 2e0a 2020 2020  initialize..    
+000179c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000179d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000179e0: 4d65 7468 6f64 2077 696c 6c20 6361 6c6c  Method will call
+000179f0: 2075 7469 6c73 2e70 6172 7365 5f6c 6162   utils.parse_lab
+00017a00: 656c 5f6d 6170 7069 6e67 0a20 2020 2020  el_mapping.     
+00017a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017a20: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00017a30: 6620 6e75 6d5f 6c61 6265 6c73 206e 6f74  f num_labels not
+00017a40: 2073 7570 706c 6965 642e 2049 6620 6e75   supplied. If nu
+00017a50: 6d5f 6c61 6265 6c73 2069 730a 2020 2020  m_labels is.    
+00017a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017a80: 6e6f 7420 666f 756e 642c 2074 6865 206d  not found, the m
+00017a90: 6f64 656c 2077 696c 6c20 7573 6520 7468  odel will use th
+00017aa0: 6520 6465 6661 756c 740a 2020 2020 2020  e default.      
+00017ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017ac0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00017ad0: 7474 696e 6720 2832 2063 6c61 7373 6573  tting (2 classes
+00017ae0: 292e 0a0a 2020 2020 2020 2020 5265 7475  )...        Retu
+00017af0: 726e 733a 0a20 2020 2020 2020 2020 2020  rns:.           
+00017b00: 2054 6865 206c 6f61 6465 6420 6d6f 6465   The loaded mode
+00017b10: 6c2c 2077 6869 6368 2069 7320 696e 6974  l, which is init
+00017b20: 6961 6c69 7a65 6420 6279 0a20 2020 2020  ialized by.     
+00017b30: 2020 2020 2020 2074 7261 6e73 666f 726d         transform
+00017b40: 6572 732e 5072 6554 7261 696e 6564 4d6f  ers.PreTrainedMo
+00017b50: 6465 6c2e 6672 6f6d 5f70 7265 7472 6169  del.from_pretrai
+00017b60: 6e65 640a 2020 2020 2020 2020 2222 220a  ned.        """.
+00017b70: 0a20 2020 2020 2020 206d 6f64 656c 5f64  .        model_d
+00017b80: 6972 203d 206b 7761 7267 732e 706f 7028  ir = kwargs.pop(
+00017b90: 276d 6f64 656c 5f64 6972 272c 204e 6f6e  'model_dir', Non
+00017ba0: 6529 0a20 2020 2020 2020 2063 6667 203d  e).        cfg =
+00017bb0: 206b 7761 7267 732e 706f 7028 2763 6667   kwargs.pop('cfg
+00017bc0: 272c 204e 6f6e 6529 0a20 2020 2020 2020  ', None).       
+00017bd0: 206d 6f64 656c 5f61 7267 7320 3d20 7061   model_args = pa
+00017be0: 7273 655f 6c61 6265 6c73 5f69 6e5f 6f72  rse_labels_in_or
+00017bf0: 6465 7228 6d6f 6465 6c5f 6469 722c 2063  der(model_dir, c
+00017c00: 6667 2c20 2a2a 6b77 6172 6773 290a 2020  fg, **kwargs).  
+00017c10: 2020 2020 2020 6966 206d 6f64 656c 5f64        if model_d
+00017c20: 6972 2069 7320 4e6f 6e65 3a0a 2020 2020  ir is None:.    
+00017c30: 2020 2020 2020 2020 636f 6e66 6967 203d          config =
+00017c40: 2042 6572 7443 6f6e 6669 6728 2a2a 6d6f   BertConfig(**mo
+00017c50: 6465 6c5f 6172 6773 290a 2020 2020 2020  del_args).      
+00017c60: 2020 2020 2020 6d6f 6465 6c20 3d20 636c        model = cl
+00017c70: 7328 636f 6e66 6967 290a 2020 2020 2020  s(config).      
+00017c80: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00017c90: 2020 2020 6d6f 6465 6c20 3d20 7375 7065      model = supe
+00017ca0: 7228 4d6f 6465 6c2c 2063 6c73 292e 6672  r(Model, cls).fr
+00017cb0: 6f6d 5f70 7265 7472 6169 6e65 6428 0a20  om_pretrained(. 
+00017cc0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00017cd0: 7265 7472 6169 6e65 645f 6d6f 6465 6c5f  retrained_model_
+00017ce0: 6e61 6d65 5f6f 725f 7061 7468 3d6d 6f64  name_or_path=mod
+00017cf0: 656c 5f64 6972 2c20 2a2a 6d6f 6465 6c5f  el_dir, **model_
+00017d00: 6172 6773 290a 2020 2020 2020 2020 6d6f  args).        mo
+00017d10: 6465 6c2e 6d6f 6465 6c5f 6469 7220 3d20  del.model_dir = 
+00017d20: 6d6f 6465 6c5f 6469 720a 2020 2020 2020  model_dir.      
+00017d30: 2020 7265 7475 726e 206d 6f64 656c 0a0a    return model..
+00017d40: 0a40 4d4f 4445 4c53 2e72 6567 6973 7465  .@MODELS.registe
+00017d50: 725f 6d6f 6475 6c65 2854 6173 6b73 2e62  r_module(Tasks.b
+00017d60: 6163 6b62 6f6e 652c 206d 6f64 756c 655f  ackbone, module_
+00017d70: 6e61 6d65 3d4d 6f64 656c 732e 6d67 656f  name=Models.mgeo
+00017d80: 290a 636c 6173 7320 4d47 656f 284d 4765  ).class MGeo(MGe
+00017d90: 6f50 7265 5472 6169 6e65 644d 6f64 656c  oPreTrainedModel
+00017da0: 293a 0a0a 2020 2020 6465 6620 5f5f 696e  ):..    def __in
+00017db0: 6974 5f5f 2873 656c 662c 0a20 2020 2020  it__(self,.     
+00017dc0: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+00017dd0: 6967 3a20 4265 7274 436f 6e66 6967 2c0a  ig: BertConfig,.
+00017de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017df0: 2066 696e 6574 756e 655f 6d6f 6465 3a20   finetune_mode: 
+00017e00: 7374 7220 3d20 2773 696e 676c 652d 6d6f  str = 'single-mo
+00017e10: 6461 6c27 2c0a 2020 2020 2020 2020 2020  dal',.          
+00017e20: 2020 2020 2020 2067 6973 5f6e 756d 3a20         gis_num: 
+00017e30: 696e 7420 3d20 312c 0a20 2020 2020 2020  int = 1,.       
+00017e40: 2020 2020 2020 2020 2020 6164 645f 706f            add_po
+00017e50: 6f6c 696e 675f 6c61 7965 723d 4661 6c73  oling_layer=Fals
+00017e60: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00017e70: 2020 2020 2a2a 6b77 6172 6773 293a 0a20      **kwargs):. 
+00017e80: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
+00017e90: 5f69 6e69 745f 5f28 636f 6e66 6967 290a  _init__(config).
+00017ea0: 0a20 2020 2020 2020 2073 656c 662e 6669  .        self.fi
+00017eb0: 6e65 7475 6e65 5f6d 6f64 6520 3d20 6669  netune_mode = fi
+00017ec0: 6e65 7475 6e65 5f6d 6f64 650a 0a20 2020  netune_mode..   
+00017ed0: 2020 2020 2073 656c 662e 636f 6e66 6967       self.config
+00017ee0: 203d 2063 6f6e 6669 670a 2020 2020 2020   = config.      
+00017ef0: 2020 7365 6c66 2e74 6578 745f 656e 636f    self.text_enco
+00017f00: 6465 7220 3d20 4265 7274 4d6f 6465 6c28  der = BertModel(
+00017f10: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
+00017f20: 6669 672c 2061 6464 5f70 6f6f 6c69 6e67  fig, add_pooling
+00017f30: 5f6c 6179 6572 3d61 6464 5f70 6f6f 6c69  _layer=add_pooli
+00017f40: 6e67 5f6c 6179 6572 290a 0a20 2020 2020  ng_layer)..     
+00017f50: 2020 2069 6620 7365 6c66 2e66 696e 6574     if self.finet
+00017f60: 756e 655f 6d6f 6465 203d 3d20 276d 756c  une_mode == 'mul
+00017f70: 7469 2d6d 6f64 616c 273a 0a20 2020 2020  ti-modal':.     
+00017f80: 2020 2020 2020 2067 6973 5f63 6f6e 6669         gis_confi
+00017f90: 6720 3d20 4265 7274 436f 6e66 6967 2e66  g = BertConfig.f
+00017fa0: 726f 6d5f 6469 6374 2863 6f6e 6669 672e  rom_dict(config.
+00017fb0: 6769 735f 656e 636f 6465 7229 0a20 2020  gis_encoder).   
+00017fc0: 2020 2020 2020 2020 2073 656c 662e 6769           self.gi
+00017fd0: 735f 656e 636f 6465 7220 3d20 4265 7274  s_encoder = Bert
+00017fe0: 4d6f 6465 6c28 6769 735f 636f 6e66 6967  Model(gis_config
+00017ff0: 2c20 6164 645f 706f 6f6c 696e 675f 6c61  , add_pooling_la
+00018000: 7965 723d 4661 6c73 6529 0a20 2020 2020  yer=False).     
+00018010: 2020 2020 2020 2066 6f72 2070 6172 616d         for param
+00018020: 2069 6e20 7365 6c66 2e67 6973 5f65 6e63   in self.gis_enc
+00018030: 6f64 6572 2e70 6172 616d 6574 6572 7328  oder.parameters(
+00018040: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+00018050: 2020 2070 6172 616d 2e72 6571 7569 7265     param.require
+00018060: 735f 6772 6164 203d 2046 616c 7365 0a20  s_grad = False. 
+00018070: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00018080: 6769 7332 7465 7874 203d 206e 6e2e 4c69  gis2text = nn.Li
+00018090: 6e65 6172 2867 6973 5f63 6f6e 6669 672e  near(gis_config.
+000180a0: 6869 6464 656e 5f73 697a 652c 0a20 2020  hidden_size,.   
+000180b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000180c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000180d0: 2020 2073 656c 662e 636f 6e66 6967 2e68     self.config.h
+000180e0: 6964 6465 6e5f 7369 7a65 290a 2020 2020  idden_size).    
+000180f0: 2020 2020 2020 2020 7365 6c66 2e67 6973          self.gis
+00018100: 5f74 7970 6520 3d20 6e6e 2e45 6d62 6564  _type = nn.Embed
+00018110: 6469 6e67 2867 6973 5f6e 756d 2c20 6769  ding(gis_num, gi
+00018120: 735f 636f 6e66 6967 2e68 6964 6465 6e5f  s_config.hidden_
+00018130: 7369 7a65 290a 0a20 2020 2020 2020 2073  size)..        s
+00018140: 656c 662e 696e 6974 5f77 6569 6768 7473  elf.init_weights
+00018150: 2829 0a0a 2020 2020 6465 6620 666f 7277  ()..    def forw
+00018160: 6172 6428 7365 6c66 2c0a 2020 2020 2020  ard(self,.      
+00018170: 2020 2020 2020 2020 2020 696e 7075 745f            input_
+00018180: 6964 733d 4e6f 6e65 2c0a 2020 2020 2020  ids=None,.      
+00018190: 2020 2020 2020 2020 2020 6174 7465 6e74            attent
+000181a0: 696f 6e5f 6d61 736b 3d4e 6f6e 652c 0a20  ion_mask=None,. 
+000181b0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+000181c0: 6f6b 656e 5f74 7970 655f 6964 733d 4e6f  oken_type_ids=No
+000181d0: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
+000181e0: 2020 2020 706f 7369 7469 6f6e 5f69 6473      position_ids
+000181f0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2020  =None,.         
+00018200: 2020 2020 2020 2068 6561 645f 6d61 736b         head_mask
+00018210: 3d4e 6f6e 652c 0a20 2020 2020 2020 2020  =None,.         
+00018220: 2020 2020 2020 2069 6e70 7574 735f 656d         inputs_em
+00018230: 6265 6473 3d4e 6f6e 652c 0a20 2020 2020  beds=None,.     
+00018240: 2020 2020 2020 2020 2020 2065 6e63 6f64             encod
+00018250: 6572 5f65 6d62 6564 733d 4e6f 6e65 2c0a  er_embeds=None,.
+00018260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018270: 656e 636f 6465 725f 6869 6464 656e 5f73  encoder_hidden_s
+00018280: 7461 7465 733d 4e6f 6e65 2c0a 2020 2020  tates=None,.    
+00018290: 2020 2020 2020 2020 2020 2020 656e 636f              enco
+000182a0: 6465 725f 6174 7465 6e74 696f 6e5f 6d61  der_attention_ma
+000182b0: 736b 3d4e 6f6e 652c 0a20 2020 2020 2020  sk=None,.       
+000182c0: 2020 2020 2020 2020 2070 6173 745f 6b65           past_ke
+000182d0: 795f 7661 6c75 6573 3d4e 6f6e 652c 0a20  y_values=None,. 
+000182e0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
+000182f0: 7365 5f63 6163 6865 3d4e 6f6e 652c 0a20  se_cache=None,. 
+00018300: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00018310: 7574 7075 745f 6174 7465 6e74 696f 6e73  utput_attentions
+00018320: 3d4e 6f6e 652c 0a20 2020 2020 2020 2020  =None,.         
+00018330: 2020 2020 2020 206f 7574 7075 745f 6869         output_hi
+00018340: 6464 656e 5f73 7461 7465 733d 4e6f 6e65  dden_states=None
+00018350: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00018360: 2020 7265 7475 726e 5f64 6963 743d 4e6f    return_dict=No
+00018370: 6e65 2c0a 2020 2020 2020 2020 2020 2020  ne,.            
+00018380: 2020 2020 6973 5f64 6563 6f64 6572 3d46      is_decoder=F
+00018390: 616c 7365 2c0a 2020 2020 2020 2020 2020  alse,.          
+000183a0: 2020 2020 2020 6d6f 6465 3d27 7369 6e67        mode='sing
+000183b0: 6c65 2d6d 6f64 616c 272c 0a20 2020 2020  le-modal',.     
+000183c0: 2020 2020 2020 2020 2020 2067 6973 5f6c             gis_l
+000183d0: 6973 743d 4e6f 6e65 2c0a 2020 2020 2020  ist=None,.      
+000183e0: 2020 2020 2020 2020 2020 6769 735f 7470            gis_tp
+000183f0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2020  =None,.         
+00018400: 2020 2020 2020 2075 7365 5f74 6f6b 656e         use_token
+00018410: 5f74 7970 653d 4661 6c73 6529 3a0a 2020  _type=False):.  
+00018420: 2020 2020 2020 6966 2073 656c 662e 6669        if self.fi
+00018430: 6e65 7475 6e65 5f6d 6f64 6520 3d3d 2027  netune_mode == '
+00018440: 6d75 6c74 692d 6d6f 6461 6c27 2061 6e64  multi-modal' and
+00018450: 2067 6973 5f6c 6973 7420 6973 206e 6f74   gis_list is not
+00018460: 204e 6f6e 6520 616e 6420 6c65 6e28 0a20   None and len(. 
+00018470: 2020 2020 2020 2020 2020 2020 2020 2067                 g
+00018480: 6973 5f6c 6973 7429 203e 2030 3a0a 2020  is_list) > 0:.  
+00018490: 2020 2020 2020 2020 2020 6769 735f 656d            gis_em
+000184a0: 6273 203d 205b 5d0a 2020 2020 2020 2020  bs = [].        
+000184b0: 2020 2020 6769 735f 6174 7473 203d 205b      gis_atts = [
+000184c0: 5d0a 2020 2020 2020 2020 2020 2020 666f  ].            fo
+000184d0: 7220 6769 7320 696e 2067 6973 5f6c 6973  r gis in gis_lis
+000184e0: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
+000184f0: 2020 2067 6973 5f65 6d62 732e 6170 7065     gis_embs.appe
+00018500: 6e64 280a 2020 2020 2020 2020 2020 2020  nd(.            
+00018510: 2020 2020 2020 2020 7365 6c66 2e67 6973          self.gis
+00018520: 5f65 6e63 6f64 6572 2872 6574 7572 6e5f  _encoder(return_
+00018530: 6469 6374 3d54 7275 652c 206d 6f64 653d  dict=True, mode=
+00018540: 2774 6578 7427 2c0a 2020 2020 2020 2020  'text',.        
+00018550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018560: 2020 2020 2020 2020 2020 2020 202a 2a67               **g
+00018570: 6973 292e 6c61 7374 5f68 6964 6465 6e5f  is).last_hidden_
+00018580: 7374 6174 6529 0a20 2020 2020 2020 2020  state).         
+00018590: 2020 2020 2020 2067 6973 5f61 7474 732e         gis_atts.
+000185a0: 6170 7065 6e64 2867 6973 5b27 6174 7465  append(gis['atte
+000185b0: 6e74 696f 6e5f 6d61 736b 275d 290a 2020  ntion_mask']).  
+000185c0: 2020 2020 2020 6966 2075 7365 5f74 6f6b        if use_tok
+000185d0: 656e 5f74 7970 653a 0a20 2020 2020 2020  en_type:.       
+000185e0: 2020 2020 2065 6d62 6564 6469 6e67 5f6f       embedding_o
+000185f0: 7574 7075 7420 3d20 7365 6c66 2e74 6578  utput = self.tex
+00018600: 745f 656e 636f 6465 722e 656d 6265 6464  t_encoder.embedd
+00018610: 696e 6773 280a 2020 2020 2020 2020 2020  ings(.          
+00018620: 2020 2020 2020 696e 7075 745f 6964 733d        input_ids=
+00018630: 696e 7075 745f 6964 732c 0a20 2020 2020  input_ids,.     
+00018640: 2020 2020 2020 2020 2020 2070 6f73 6974             posit
+00018650: 696f 6e5f 6964 733d 706f 7369 7469 6f6e  ion_ids=position
+00018660: 5f69 6473 2c0a 2020 2020 2020 2020 2020  _ids,.          
+00018670: 2020 2020 2020 746f 6b65 6e5f 7479 7065        token_type
+00018680: 5f69 6473 3d74 6f6b 656e 5f74 7970 655f  _ids=token_type_
+00018690: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
+000186a0: 2029 0a20 2020 2020 2020 2065 6c73 653a   ).        else:
+000186b0: 0a20 2020 2020 2020 2020 2020 2065 6d62  .            emb
+000186c0: 6564 6469 6e67 5f6f 7574 7075 7420 3d20  edding_output = 
+000186d0: 7365 6c66 2e74 6578 745f 656e 636f 6465  self.text_encode
+000186e0: 722e 656d 6265 6464 696e 6773 280a 2020  r.embeddings(.  
+000186f0: 2020 2020 2020 2020 2020 2020 2020 696e                in
+00018700: 7075 745f 6964 733d 696e 7075 745f 6964  put_ids=input_id
+00018710: 732c 2029 0a0a 2020 2020 2020 2020 6966  s, )..        if
+00018720: 2073 656c 662e 6669 6e65 7475 6e65 5f6d   self.finetune_m
+00018730: 6f64 6520 3d3d 2027 6d75 6c74 692d 6d6f  ode == 'multi-mo
+00018740: 6461 6c27 2061 6e64 2067 6973 5f6c 6973  dal' and gis_lis
+00018750: 7420 6973 206e 6f74 204e 6f6e 6520 616e  t is not None an
+00018760: 6420 6c65 6e28 0a20 2020 2020 2020 2020  d len(.         
+00018770: 2020 2020 2020 2067 6973 5f6c 6973 7429         gis_list)
+00018780: 203e 2030 3a0a 2020 2020 2020 2020 2020   > 0:.          
+00018790: 2020 656d 6273 203d 205b 656d 6265 6464    embs = [embedd
+000187a0: 696e 675f 6f75 7470 7574 5d0a 2020 2020  ing_output].    
+000187b0: 2020 2020 2020 2020 6174 7473 203d 205b          atts = [
+000187c0: 6174 7465 6e74 696f 6e5f 6d61 736b 5d0a  attention_mask].
+000187d0: 2020 2020 2020 2020 2020 2020 7470 5f65              tp_e
+000187e0: 6d62 203d 205b 7365 6c66 2e67 6973 5f74  mb = [self.gis_t
+000187f0: 7970 6528 6774 7029 2066 6f72 2067 7470  ype(gtp) for gtp
+00018800: 2069 6e20 6769 735f 7470 5d0a 2020 2020   in gis_tp].    
+00018810: 2020 2020 2020 2020 666f 7220 6765 2c20          for ge, 
+00018820: 6761 2c20 6774 2069 6e20 7a69 7028 6769  ga, gt in zip(gi
+00018830: 735f 656d 6273 2c20 6769 735f 6174 7473  s_embs, gis_atts
+00018840: 2c20 7470 5f65 6d62 293a 0a20 2020 2020  , tp_emb):.     
+00018850: 2020 2020 2020 2020 2020 2065 6d62 732e             embs.
+00018860: 6170 7065 6e64 2873 656c 662e 6769 7332  append(self.gis2
+00018870: 7465 7874 2867 6520 2b20 6774 2929 0a20  text(ge + gt)). 
+00018880: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+00018890: 7474 732e 6170 7065 6e64 2867 6129 0a20  tts.append(ga). 
+000188a0: 2020 2020 2020 2020 2020 206d 6572 6765             merge
+000188b0: 5f65 6d62 203d 2074 6f72 6368 2e63 6174  _emb = torch.cat
+000188c0: 2865 6d62 732c 2064 696d 3d31 290a 2020  (embs, dim=1).  
+000188d0: 2020 2020 2020 2020 2020 6d65 7267 655f            merge_
+000188e0: 6174 7465 6e74 696f 6e20 3d20 746f 7263  attention = torc
+000188f0: 682e 6361 7428 6174 7473 2c20 6469 6d3d  h.cat(atts, dim=
+00018900: 2d31 290a 2020 2020 2020 2020 656c 7365  -1).        else
+00018910: 3a0a 2020 2020 2020 2020 2020 2020 6d65  :.            me
+00018920: 7267 655f 656d 6220 3d20 656d 6265 6464  rge_emb = embedd
+00018930: 696e 675f 6f75 7470 7574 0a20 2020 2020  ing_output.     
+00018940: 2020 2020 2020 206d 6572 6765 5f61 7474         merge_att
+00018950: 656e 7469 6f6e 203d 2061 7474 656e 7469  ention = attenti
+00018960: 6f6e 5f6d 6173 6b0a 2020 2020 2020 2020  on_mask.        
+00018970: 656e 636f 6465 725f 6f75 7470 7574 7320  encoder_outputs 
+00018980: 3d20 7365 6c66 2e74 6578 745f 656e 636f  = self.text_enco
+00018990: 6465 7228 0a20 2020 2020 2020 2020 2020  der(.           
+000189a0: 2061 7474 656e 7469 6f6e 5f6d 6173 6b3d   attention_mask=
+000189b0: 6d65 7267 655f 6174 7465 6e74 696f 6e2c  merge_attention,
+000189c0: 0a20 2020 2020 2020 2020 2020 2065 6e63  .            enc
+000189d0: 6f64 6572 5f65 6d62 6564 733d 6d65 7267  oder_embeds=merg
+000189e0: 655f 656d 622c 0a20 2020 2020 2020 2020  e_emb,.         
+000189f0: 2020 206f 7574 7075 745f 6174 7465 6e74     output_attent
+00018a00: 696f 6e73 3d6f 7574 7075 745f 6174 7465  ions=output_atte
+00018a10: 6e74 696f 6e73 2c0a 2020 2020 2020 2020  ntions,.        
+00018a20: 2020 2020 6f75 7470 7574 5f68 6964 6465      output_hidde
+00018a30: 6e5f 7374 6174 6573 3d6f 7574 7075 745f  n_states=output_
+00018a40: 6869 6464 656e 5f73 7461 7465 732c 0a20  hidden_states,. 
+00018a50: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00018a60: 6e5f 6469 6374 3d72 6574 7572 6e5f 6469  n_dict=return_di
+00018a70: 6374 2c0a 2020 2020 2020 2020 2020 2020  ct,.            
+00018a80: 6d6f 6465 3d27 7465 7874 2729 0a0a 2020  mode='text')..  
+00018a90: 2020 2020 2020 6966 206e 6f74 2072 6574        if not ret
+00018aa0: 7572 6e5f 6469 6374 3a0a 2020 2020 2020  urn_dict:.      
+00018ab0: 2020 2020 2020 7265 7475 726e 2065 6e63        return enc
+00018ac0: 6f64 6572 5f6f 7574 7075 7473 0a0a 2020  oder_outputs..  
+00018ad0: 2020 2020 2020 7265 7475 726e 2041 7474        return Att
+00018ae0: 656e 7469 6f6e 4261 636b 626f 6e65 4d6f  entionBackboneMo
+00018af0: 6465 6c4f 7574 7075 7428 0a20 2020 2020  delOutput(.     
+00018b00: 2020 2020 2020 206c 6173 745f 6869 6464         last_hidd
+00018b10: 656e 5f73 7461 7465 3d65 6e63 6f64 6572  en_state=encoder
+00018b20: 5f6f 7574 7075 7473 2e6c 6173 745f 6869  _outputs.last_hi
+00018b30: 6464 656e 5f73 7461 7465 2c0a 2020 2020  dden_state,.    
+00018b40: 2020 2020 2020 2020 706f 6f6c 6572 5f6f          pooler_o
+00018b50: 7574 7075 743d 656e 636f 6465 725f 6f75  utput=encoder_ou
+00018b60: 7470 7574 732e 706f 6f6c 6572 5f6f 7574  tputs.pooler_out
+00018b70: 7075 742c 0a20 2020 2020 2020 2020 2020  put,.           
+00018b80: 2070 6173 745f 6b65 795f 7661 6c75 6573   past_key_values
+00018b90: 3d65 6e63 6f64 6572 5f6f 7574 7075 7473  =encoder_outputs
+00018ba0: 2e70 6173 745f 6b65 795f 7661 6c75 6573  .past_key_values
+00018bb0: 2c0a 2020 2020 2020 2020 2020 2020 6869  ,.            hi
+00018bc0: 6464 656e 5f73 7461 7465 733d 656e 636f  dden_states=enco
+00018bd0: 6465 725f 6f75 7470 7574 732e 6869 6464  der_outputs.hidd
+00018be0: 656e 5f73 7461 7465 732c 0a20 2020 2020  en_states,.     
+00018bf0: 2020 2020 2020 2061 7474 656e 7469 6f6e         attention
+00018c00: 733d 656e 636f 6465 725f 6f75 7470 7574  s=encoder_output
+00018c10: 732e 6174 7465 6e74 696f 6e73 2c0a 2020  s.attentions,.  
+00018c20: 2020 2020 2020 2020 2020 6372 6f73 735f            cross_
+00018c30: 6174 7465 6e74 696f 6e73 3d65 6e63 6f64  attentions=encod
+00018c40: 6572 5f6f 7574 7075 7473 2e63 726f 7373  er_outputs.cross
+00018c50: 5f61 7474 656e 7469 6f6e 732c 0a20 2020  _attentions,.   
+00018c60: 2020 2020 2029 0a20 2020 2020 2020 2072       ).        r
+00018c70: 6574 7572 6e20 6f75 7470 7574 0a0a 2020  eturn output..  
+00018c80: 2020 6465 6620 6578 7472 6163 745f 7365    def extract_se
+00018c90: 7175 656e 6365 5f6f 7574 7075 7473 2873  quence_outputs(s
+00018ca0: 656c 662c 206f 7574 7075 7473 293a 0a20  elf, outputs):. 
+00018cb0: 2020 2020 2020 2072 6574 7572 6e20 6f75         return ou
+00018cc0: 7470 7574 735b 276c 6173 745f 6869 6464  tputs['last_hidd
+00018cd0: 656e 5f73 7461 7465 275d 0a0a 2020 2020  en_state']..    
+00018ce0: 6465 6620 6578 7472 6163 745f 706f 6f6c  def extract_pool
+00018cf0: 6564 5f6f 7574 7075 7473 2873 656c 662c  ed_outputs(self,
+00018d00: 206f 7574 7075 7473 293a 0a20 2020 2020   outputs):.     
+00018d10: 2020 2072 6574 7572 6e20 6f75 7470 7574     return output
+00018d20: 735b 2770 6f6f 6c65 725f 6f75 7470 7574  s['pooler_output
+00018d30: 275d 0a                                  '].
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/text_classification.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mgeo/text_classification.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 # All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
@@ -16,19 +15,19 @@
 # limitations under the License.
 
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTextClassificationModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.outputs import AttentionTextClassificationModelOutput
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
 from .backbone import MGeo, MGeoPreTrainedModel
 
 logger = logging.get_logger()
 
 
 @MODELS.register_module(Tasks.text_classification, module_name=Models.mgeo)
 @MODELS.register_module(Tasks.nli, module_name=Models.mgeo)
@@ -119,16 +118,16 @@
             config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),
             If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).
 
         Returns:
             Returns `modelscope.outputs.AttentionTextClassificationModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
+            >>> from weathon.models import Model
+            >>> from weathon.preprocessors import Preprocessor
             >>> model = Model.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
             >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
             >>> print(model(**preprocessor(('This is a test', 'This is also a test'))))
         """
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
 
         outputs = self.base_model.forward(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/text_ranking.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mgeo/text_ranking.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 
-from modelscope.metainfo import Models
-from modelscope.models import Model
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTextClassificationModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.outputs import AttentionTextClassificationModelOutput
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
 from .backbone import MGeo, MGeoPreTrainedModel
 
 logger = logging.get_logger()
 
 
 @MODELS.register_module(Tasks.text_ranking, module_name=Models.mgeo)
 class MGeoForTextRanking(MGeoPreTrainedModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mgeo/token_classification.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mgeo/token_classification.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 # All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
@@ -16,19 +15,19 @@
 # limitations under the License.
 
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 from torch.nn import CrossEntropyLoss
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTokenClassificationModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.outputs import AttentionTokenClassificationModelOutput
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
 from .backbone import MGeo, MGeoPreTrainedModel
 
 logger = logging.get_logger()
 
 
 @MODELS.register_module(Tasks.token_classification, module_name=Models.mgeo)
 @MODELS.register_module(Tasks.part_of_speech, module_name=Models.mgeo)
@@ -170,16 +169,16 @@
             - 1 for tokens that are **not masked**,
             - 0 for tokens that are **masked**.
 
         Returns:
             Returns `modelscope.outputs.AttentionTokenClassificationModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
+            >>> from weathon.models import Model
+            >>> from weathon.preprocessors import Preprocessor
             >>> model = Model.from_pretrained('damo/nlp_bert_word-segmentation_chinese-base')
             >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_bert_word-segmentation_chinese-base')
             >>> print(model(**preprocessor(('This is a test', 'This is also a test'))))
         """
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
 
         outputs = self.bert(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/dataloaders/rawvideo_util.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mmr/dataloaders/rawvideo_util.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 import cv2
 import numpy as np
 import torch as th
 from PIL import Image
 from torchvision.transforms import (CenterCrop, Compose, InterpolationMode,
                                     Normalize, Resize, ToTensor)
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class RawVideoExtractorCV2():
 
     def __init__(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,20 +11,20 @@
 
 import json
 import numpy as np
 import torch
 from decord import VideoReader, cpu
 from PIL import Image
 
-from modelscope.hub.file_download import http_get_file
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.hub import http_get_file
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from ..dataloaders.rawvideo_util import RawVideoExtractor
 from .modeling import CLIP4Clip
 from .tokenization_clip import SimpleTokenizer as ClipTokenizer
 
 logger = get_logger()
 
 
@@ -205,15 +205,15 @@
 
         video_mask[:max_video_length] = [1] * max_video_length
 
         return video, video_mask
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
 
-        from modelscope.outputs import OutputKeys
+        from weathon.outputs import OutputKeys
         output = {}
 
         if 'video' in input and input['video'] is not None:
             video_path = input['video']
             video, video_mask = self._get_rawvideo_dec(video_path,
                                                        self.rawVideoExtractor,
                                                        self.local_transform)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/dynamic_inverted_softmax.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/dynamic_inverted_softmax.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/modeling.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/modeling.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,22 +5,22 @@
 from collections import OrderedDict
 from types import SimpleNamespace
 
 import torch
 from torch import nn
 from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
 
-from modelscope.models.multi_modal.mmr.models.module_clip import (
+from weathon.models.multi_modal.mmr.models.module_clip import (
     _PT_NAME, CLIP, QuickGELU, convert_weights)
-from modelscope.models.multi_modal.mmr.models.module_cross import \
+from weathon.models.multi_modal.mmr.models.module_cross import \
     Transformer as TransformerClip
-from modelscope.models.multi_modal.mmr.models.until_module import (AllGather,
+from weathon.models.multi_modal.mmr.models.until_module import (AllGather,
                                                                    CrossEn,
                                                                    LayerNorm)
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 allgather = AllGather.apply
 
 logger = get_logger()
 __all__ = ['CLIP4Clip']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/module_clip.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/module_clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/module_cross.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/module_cross.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/tokenization_clip.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/tokenization_clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mmr/models/until_module.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mmr/models/until_module.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/__init__.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/clip/clip.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug/clip/clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/configuration_mplug.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug/configuration_mplug.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 import os
 from typing import Any, Dict, Union
 
 import yaml
 from transformers import PretrainedConfig
 from transformers.utils import logging
 
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants import Tasks
 
 logger = logging.get_logger()
 
 
 class MPlugConfig(PretrainedConfig):
 
     model_type = 'mplug'
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/modeling_mplug.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug/modeling_mplug.py`

 * *Files 0% similar despite different names*

```diff
@@ -36,19 +36,19 @@
     CausalLMOutputWithCrossAttentions)
 from transformers.modeling_utils import (PreTrainedModel,
                                          apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 from transformers.utils import logging
 
-from modelscope.models.multi_modal.mplug.configuration_mplug import (
+from weathon.models.multi_modal.mplug.configuration_mplug import (
     HiTeAConfig, MPlugConfig)
-from modelscope.models.multi_modal.mplug.mvit import MViTv2, MViTv2_Base_config
-from modelscope.models.multi_modal.mplug.predictor import TextGenerator
-from modelscope.utils.constant import ModelFile
+from weathon.models.multi_modal.mplug.mvit import MViTv2, MViTv2_Base_config
+from weathon.models.multi_modal.mplug.predictor import TextGenerator
+from weathon.utils.constants import ModelFile
 
 transformers.logging.set_verbosity_error()
 
 logger = logging.get_logger()
 
 CONFIG_NAME = 'config.yaml'
 
@@ -1850,15 +1850,15 @@
         self.text_encoder = BertModel(
             self.config_encoder, add_pooling_layer=False)
         self.fusion_encoder = FusionModel(
             self.config_fusion, add_pooling_layer=False)
 
     @classmethod
     def from_pretrained(cls, model_dir, task=None, load_checkpoint=True):
-        from modelscope.utils.constant import Tasks
+        from weathon.utils.constants import Tasks
 
         task_mapping = {
             Tasks.visual_question_answering: MPlugForVisualQuestionAnswering,
             Tasks.image_captioning: MPlugForImageCaption,
             Tasks.image_text_retrieval: MPlugForImageTextRetrieval,
         }
         config = cls.config_class.from_yaml_file(
@@ -2504,15 +2504,15 @@
         self.text_encoder = BertModel(
             self.config_encoder, add_pooling_layer=False)
         self.fusion_encoder = FusionModel(
             self.config_fusion, add_pooling_layer=False)
 
     @classmethod
     def from_pretrained(cls, model_dir, load_checkpoint=True):
-        from modelscope.utils.constant import Tasks
+        from weathon.utils.constants import Tasks
 
         task_mapping = {
             Tasks.video_question_answering: HiTeAForVideoQuestionAnswering,
             Tasks.video_captioning: HiTeAForVideoCaption,
         }
         config = cls.config_class.from_yaml_file(
             os.path.join(model_dir, CONFIG_NAME))
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/mvit.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug/mvit.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug/predictor.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug/predictor.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_for_all_tasks.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug_for_all_tasks.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Dict, List
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.utils.typing import Tensor
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['MPlugForAllTasks', 'HiTeAForAllTasks']
 
 
 @MODELS.register_module(
     Tasks.visual_question_answering, module_name=Models.mplug)
 @MODELS.register_module(Tasks.image_captioning, module_name=Models.mplug)
@@ -23,15 +21,15 @@
     def __init__(self, model_dir: str, task=None, *args, **kwargs):
         """initialize the mplug model from the `model_dir` path.
         Args:
             model_dir (str): the model path.
         """
 
         super().__init__(model_dir, *args, **kwargs)
-        from modelscope.models.multi_modal.mplug import MPlug
+        from weathon.models.multi_modal.mplug import MPlug
         self.model = MPlug.from_pretrained(model_dir, task=task)
         self.tokenizer = self.model.tokenizer
 
     def forward(self, input: Dict[str, Tensor]) -> Dict[str, Tensor]:
         """return the result by the model
 
         Args:
@@ -91,15 +89,15 @@
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the hitea model from the `model_dir` path.
         Args:
             model_dir (str): the model path.
         """
 
         super().__init__(model_dir, *args, **kwargs)
-        from modelscope.models.multi_modal.mplug import HiTeA
+        from weathon.models.multi_modal.mplug import HiTeA
         self.model = HiTeA.from_pretrained(model_dir)
         self.tokenizer = self.model.tokenizer
 
     def forward(self, input: Dict[str, Tensor]) -> Dict[str, Tensor]:
         """return the result by the model
 
         Args:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_owl/__init__.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug_owl/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_owl/configuration_mplug_owl.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug_owl/configuration_mplug_owl.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 import os
 from typing import Union
 
 from transformers import PretrainedConfig
 from transformers.models.auto import CONFIG_MAPPING
 from transformers.utils import logging
 
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants import Tasks
 
 logger = logging.get_logger()
 
 
 class MplugOwlVisionConfig(PretrainedConfig):
     r"""
     Args:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/mplug_owl/modeling_mplug_owl.py` & `weathon-0.0.0.14/weathon/models/multi_modal/mplug_owl/modeling_mplug_owl.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,51 +11,36 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """PyTorch MPLUG OWL model. """
 
-import copy
-import logging
 import math
-import os
-import os.path as osp
-import random
 from dataclasses import dataclass
-from io import BytesIO
-from typing import Any, Dict, List, Optional, Tuple, Union
+from typing import Any, Dict, Optional, Tuple, Union
 
 import torch
 import torch.nn as nn
-import torch.nn.functional as F
 import torch.utils.checkpoint
-import transformers
-from torch.nn import CrossEntropyLoss
-from transformers.activations import ACT2FN
 from transformers.modeling_outputs import (
-    BaseModelOutput, BaseModelOutputWithPastAndCrossAttentions,
-    BaseModelOutputWithPooling, BaseModelOutputWithPoolingAndCrossAttentions,
-    CausalLMOutputWithCrossAttentions)
+    BaseModelOutput, BaseModelOutputWithPooling)
 from transformers.modeling_utils import (PreTrainedModel,
-                                         apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 from transformers.models.auto import AutoModelForCausalLM
 from transformers.utils import ModelOutput
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.mplug_owl.configuration_mplug_owl import (
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.utils.typing import Tensor
+from weathon.registry import MODELS
+from weathon.models.multi_modal.mplug_owl.configuration_mplug_owl import (
     MplugOwlConfig, MplugOwlVisionConfig, MplugOwlVisualAbstractorConfig)
-from modelscope.outputs import OutputKeys
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants import Tasks
 
 __all__ = ['MplugOwlForConditionalGeneration']
 
 
 @dataclass
 class MplugOwlForConditionalGenerationModelOutput(ModelOutput):
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/clip.py` & `weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/decoder.py` & `weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/decoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py` & `weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 # publicly available at https://github.com/CompVis/latent-diffusion.
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
 import math
 
 import torch
 
-from modelscope.models.multi_modal.dpm_solver_pytorch import (
+from weathon.models.multi_modal.dpm_solver_pytorch import (
     DPM_Solver, NoiseScheduleVP, model_wrapper, model_wrapper_guided_diffusion)
 
 __all__ = ['GaussianDiffusion', 'beta_schedule']
 
 
 def kl_divergence(mu1, logvar1, mu2, logvar2):
     u1 = -1.0 + logvar2 - logvar1 + torch.exp(logvar1 - logvar2)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/model.py`

 * *Files 13% similar despite different names*

```diff
@@ -8,30 +8,30 @@
 import numpy as np
 import torch
 import torch.cuda.amp as amp
 import torch.nn as nn
 import torch.nn.functional as F
 from PIL import Image
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.multi_stage_diffusion.clip import CLIP
-from modelscope.models.multi_modal.multi_stage_diffusion.decoder import Decoder
-from modelscope.models.multi_modal.multi_stage_diffusion.gaussian_diffusion import (
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.multi_modal.multi_stage_diffusion.clip import CLIP
+from weathon.models.multi_modal.multi_stage_diffusion.decoder import Decoder
+from weathon.models.multi_modal.multi_stage_diffusion.gaussian_diffusion import (
     GaussianDiffusion, beta_schedule)
-from modelscope.models.multi_modal.multi_stage_diffusion.prior import Prior
-from modelscope.models.multi_modal.multi_stage_diffusion.tokenizer import (
+from weathon.models.multi_modal.multi_stage_diffusion.prior import Prior
+from weathon.models.multi_modal.multi_stage_diffusion.tokenizer import (
     CLIPTokenizer, XGLMTokenizer)
-from modelscope.models.multi_modal.multi_stage_diffusion.upsampler import (
+from weathon.models.multi_modal.multi_stage_diffusion.upsampler import (
     Upsampler256, Upsampler1024)
-from modelscope.models.multi_modal.multi_stage_diffusion.xglm import XGLM
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.device import create_device
-from modelscope.utils.logger import get_logger
+from weathon.models.multi_modal.multi_stage_diffusion.xglm import XGLM
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.device import create_device
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['MultiStageDiffusionForTextToImageSynthesis']
 
 
 def make_diffusion(schedule,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/prior.py` & `weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/prior.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/tokenizer.py` & `weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/upsampler.py` & `weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/upsampler.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/multi_stage_diffusion/xglm.py` & `weathon-0.0.0.14/weathon/models/multi_modal/multi_stage_diffusion/xglm.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/configuration_mmspeech.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/configuration_mmspeech.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/configuration_ofa.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/configuration_ofa.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/incremental_decoding_utils.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/incremental_decoding_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/multihead_attention.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/multihead_attention.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/ngram_repeat_block.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/ngram_repeat_block.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/search.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/search.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/sequence_generator.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/sequence_generator.py`

 * *Files 0% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 import sys
 from typing import Dict, List, Optional, Tuple
 
 import torch
 import torch.nn as nn
 from torch import Tensor
 
-from modelscope.models.multi_modal.ofa.generate import search
-from modelscope.models.multi_modal.ofa.generate.ngram_repeat_block import \
+from weathon.models.multi_modal.ofa.generate import search
+from weathon.models.multi_modal.ofa.generate.ngram_repeat_block import \
     NGramRepeatBlock
 
 
 def _expand_mask(mask: torch.Tensor,
                  dtype: torch.dtype,
                  tgt_len: Optional[int] = None):
     r"""
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/token_generation_constraints.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/token_generation_constraints.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/generate/utils.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/generate/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/modeling_mmspeech.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/modeling_mmspeech.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/modeling_ofa.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/modeling_ofa.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/resnet.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/resnet.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/tokenization_ofa.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/tokenization_ofa.py`

 * *Files 0% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 
 from transformers import PreTrainedTokenizer
 from transformers.models.bart.tokenization_bart import BartTokenizer
 from transformers.models.bert.tokenization_bert import (BasicTokenizer,
                                                         WordpieceTokenizer)
 from transformers.utils import logging
 
-from modelscope.utils.constant import ModelFile
+from weathon.utils.constants import ModelFile
 
 logger = logging.get_logger()
 
 VOCAB_FILES_NAMES = {'vocab_file': 'vocab.json', 'merges_file': 'merges.txt'}
 
 PRETRAINED_VOCAB_FILES_MAP = {
     'vocab_file': {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/tokenization_ofa_fast.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/tokenization_ofa_fast.py`

 * *Files 0% similar despite different names*

```diff
@@ -16,15 +16,15 @@
 
 import json
 from tokenizers import normalizers
 from transformers import PreTrainedTokenizerFast
 from transformers.models.bart.tokenization_bart_fast import BartTokenizerFast
 from transformers.utils import logging
 
-from modelscope.utils.constant import ModelFile
+from weathon.utils.constants import ModelFile
 from .tokenization_ofa import OFATokenizer, OFATokenizerZH
 
 logger = logging.get_logger()
 
 VOCAB_FILES_NAMES = {
     'vocab_file': 'vocab.json',
     'merges_file': 'merges.txt',
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/utils/constant.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/utils/constant.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,9 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import Tasks
+from weathon.outputs import OutputKeys
+from weathon.utils.constants import Tasks
 
 OFA_TASK_KEY_MAPPING = {
     Tasks.ocr_recognition: OutputKeys.TEXT,
     Tasks.image_captioning: OutputKeys.CAPTION,
     Tasks.text_summarization: OutputKeys.TEXT,
     Tasks.visual_question_answering: OutputKeys.TEXT,
     Tasks.visual_grounding: OutputKeys.BOXES,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/utils/utils.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/utils/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Optional
 
 import torch
 import torch.nn as nn
 
 
 def expand_mask(mask: torch.Tensor,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa/vit.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa/vit.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa_for_all_tasks.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa_for_all_tasks.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 import os
 import re
 import string
 from functools import partial
 from os import path as osp
 from typing import Any, Callable, Dict, List, Optional, Union
 
 import json
 import torch.cuda
 import torch.nn.functional as F
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors.ofa.utils.collate import collate_tokens
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.trie import Trie
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.preprocessors.ofa.utils.collate import collate_tokens
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile
+from weathon.utils.trie import Trie
 from .ofa import MMSpeechModel, OFAModel, OFATokenizer, OFATokenizerZH
 from .ofa.generate import sequence_generator as sg
 from .ofa.generate.utils import move_to_device
 from .ofa.utils.constant import OFA_TASK_KEY_MAPPING, Tasks
 from .ofa.utils.utils import expand_mask
 
 __all__ = ['OfaForAllTasks']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/ofa_for_text_to_image_synthesis_model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/ofa_for_text_to_image_synthesis_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,35 +1,33 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from os import path as osp
 from typing import Any, Dict
 
 import json
 import numpy as np
 import torch
 import torch.cuda
 from PIL import Image
 from pkg_resources import packaging
 from taming.models.vqgan import GumbelVQ, VQModel
 from torchvision.transforms import (CenterCrop, Compose, Normalize, Resize,
                                     ToTensor)
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.mmr.models.module_clip import CLIP
-from modelscope.models.multi_modal.mmr.models.tokenization_clip import \
+from weathon.utils.constants.metainfo import Models
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.models.multi_modal.mmr.models.module_clip import CLIP
+from weathon.models.multi_modal.mmr.models.tokenization_clip import \
     SimpleTokenizer as ClipTokenizer
-from modelscope.models.multi_modal.ofa import OFAModel, OFATokenizer
-from modelscope.models.multi_modal.ofa.generate import sequence_generator as sg
-from modelscope.models.multi_modal.ofa.generate.search import Sampling
-from modelscope.models.multi_modal.ofa.generate.utils import move_to_device
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.models.multi_modal.ofa import OFAModel, OFATokenizer
+from weathon.models.multi_modal.ofa.generate import sequence_generator as sg
+from weathon.models.multi_modal.ofa.generate.search import Sampling
+from weathon.models.multi_modal.ofa.generate.utils import move_to_device
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 
 try:
     from torchvision.transforms import InterpolationMode
 
     BICUBIC = InterpolationMode.BICUBIC
 except ImportError:
     BICUBIC = Image.BICUBIC
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/rleg/model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/rleg/model.py`

 * *Files 0% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 import os
 
 import json
 import torch
 import torch.nn.functional as F
 from torch import nn
 
-from modelscope.models.multi_modal.gemm import gemm_base, tokenizer
+from weathon.models.multi_modal.gemm import gemm_base, tokenizer
 
 
 class ImageEncoder(nn.Module):
     """Image Feature Encoder
     ViT Style Transformer
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/rleg/rleg.py` & `weathon-0.0.0.14/weathon/models/multi_modal/gemm/gemm_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,54 +1,55 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 """ Generative Multimodal Model Wrapper."""
 from typing import Any, Dict
 
 import torch
 from torchvision import transforms as T
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.rleg.model import RLEGModel
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.multi_modal.gemm.gemm_base import GEMMModel
+from weathon.outputs import OutputKeys
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
-__all__ = ['RLEGForMultiModalEmbedding']
+__all__ = ['GEMMForMultiModalEmbedding']
 
 
 @MODELS.register_module(
-    Tasks.generative_multi_modal_embedding, module_name=Models.rleg)
-class RLEGForMultiModalEmbedding(TorchModel):
-    """ Generative multi-modal model for multi-modal embedding.
-    The model is trained by representation learning with embedding generation.
+    Tasks.generative_multi_modal_embedding, module_name=Models.gemm)
+class GEMMForMultiModalEmbedding(TorchModel):
+    """ Generative multi-modal model for multi-modal embedding
     Inputs could be image or text or both of them.
     Outputs could be features of input image or text,
+    image caption could also be produced when image is available.
     """
 
     def __init__(self, model_dir, device_id=0, *args, **kwargs):
         super().__init__(
             model_dir=model_dir, device_id=device_id, *args, **kwargs)
-        self.model = RLEGModel(model_dir=model_dir)
+        self.gemm_model = GEMMModel(model_dir=model_dir)
         pretrained_params = torch.load('{}/{}'.format(
             model_dir, ModelFile.TORCH_MODEL_BIN_FILE))
-        self.model.load_state_dict(pretrained_params)
-        self.model.eval()
+        self.gemm_model.load_state_dict(pretrained_params)
+        self.gemm_model.eval()
         self.device_id = device_id
         if self.device_id >= 0 and torch.cuda.is_available():
-            self.model.to('cuda:{}'.format(self.device_id))
+            self.gemm_model.to('cuda:{}'.format(self.device_id))
             logger.info('Use GPU: {}'.format(self.device_id))
         else:
             self.device_id = -1
             logger.info('Use CPU for inference')
         self.img_preprocessor = T.Compose([
-            T.Resize((224, 224)),
+            T.Resize(224),
+            T.CenterCrop(224),
             T.ToTensor(),
             T.Normalize((0.48145466, 0.4578275, 0.40821073),
                         (0.26862954, 0.26130258, 0.27577711))
         ])
 
     def parse_image(self, input_img):
         if input_img is None:
@@ -59,27 +60,29 @@
             img_tensor = img_tensor.to('cuda:{}'.format(self.device_id))
         return img_tensor
 
     def parse_text(self, text_str):
         if text_str is None or len(text_str) == 0:
             return None
         if isinstance(text_str, str):
-            text_ids_tensor = self.model.tokenize(text_str)
+            text_ids_tensor = self.gemm_model.tokenize(text_str)
         else:
             raise TypeError(f'text should be str, but got {type(text_str)}')
         if self.device_id >= 0:
             text_ids_tensor = text_ids_tensor.to('cuda:{}'.format(
                 self.device_id))
         return text_ids_tensor.view(1, -1)
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
         image_input = input.get('image', input.get('img', None))
         text_input = input.get('text', input.get('txt', None))
+        captioning_input = input.get('captioning', None)
         image = self.parse_image(image_input)
         text = self.parse_text(text_input)
-        out = self.model(image, text)
+        captioning = captioning_input is True or text_input == ''
+        out = self.gemm_model(image, text, captioning)
         output = {
             OutputKeys.IMG_EMBEDDING: out.get('image_feature', None),
             OutputKeys.TEXT_EMBEDDING: out.get('text_feature', None),
             OutputKeys.CAPTION: out.get('caption', None)
         }
         return output
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,23 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .tokenizer import SimpleTokenizer
-    from .model import SOONet
-    from .utils import decode_video
-    from .clip import load_clip
+    from .model import SpaceGenerator
+    from .model import SpaceModelBase, SpaceTokenizer
+    from .dialog_intent_prediction import SpaceForDialogIntent
+    from .dialog_modeling import SpaceForDialogModeling
+    from .dialog_state_tracking import SpaceForDST
+    from .configuration import SpaceConfig
 else:
     _import_structure = {
-        'model': ['SOONet'],
-        'tokenizer': ['SimpleTokenizer'],
-        'utils': ['decode_video'],
-        'clip': ['load_clip']
+        'model': ['SpaceGenerator', 'SpaceModelBase', 'SpaceTokenizer'],
+        'dialog_intent_prediction': ['SpaceForDialogIntent'],
+        'dialog_modeling': ['SpaceForDialogModeling'],
+        'dialog_state_tracking': ['SpaceForDST'],
+        'configuration': ['SpaceConfig']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/blocks.py` & `weathon-0.0.0.14/weathon/models/multi_modal/soonet/blocks.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/clip.py` & `weathon-0.0.0.14/weathon/models/multi_modal/soonet/clip.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/soonet/model.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Copyright 2022-2023 The Alibaba Fundamental Vision  Team Authors. All rights reserved.
 
 import os
 
 import torch
 import torch.nn as nn
 
-from modelscope.metainfo import Models
-from modelscope.models.base.base_torch_model import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base.base_torch_model import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 from .blocks import (BboxRegressor, Q2VRankerStage1, Q2VRankerStage2,
                      V2QRankerStage1, V2QRankerStage2)
 from .swin_transformer import SwinTransformerV2_1D
 
 
 @MODELS.register_module(
     Tasks.video_temporal_grounding, module_name=Models.soonet)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/swin_transformer.py` & `weathon-0.0.0.14/weathon/models/multi_modal/soonet/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/tokenizer.py` & `weathon-0.0.0.14/weathon/models/multi_modal/soonet/tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/soonet/utils.py` & `weathon-0.0.0.14/weathon/models/multi_modal/soonet/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/team/team_model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/team/team_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,23 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Any, Dict
 
-import cv2
-import numpy as np
 import torch
-import torch.nn as nn
-import torch.nn.functional as F
 from PIL import Image
 from tokenizers import BertWordPieceTokenizer
 from torchvision.transforms import Compose, Normalize, Resize, ToTensor
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
-from .utils import TEAM, BertWrapper, CLIPVisionWrapper, CrossLayer
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
+from .utils import TEAM, BertWrapper, CLIPVisionWrapper
 
 logger = get_logger()
 
 __all__ = ['TEAMForMultiModalSimilarity']
 
 
 @MODELS.register_module(Tasks.multi_modal_similarity, module_name=Models.team)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/team/utils.py` & `weathon-0.0.0.14/weathon/models/multi_modal/team/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/autoencoder.py` & `weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/autoencoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/diffusion.py` & `weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/diffusion.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -5,24 +5,24 @@
 from typing import Any, Dict
 
 import open_clip
 import torch
 import torch.cuda.amp as amp
 from einops import rearrange
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.video_synthesis.autoencoder import \
+from weathon.utils.constants.metainfo import Models
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.models.multi_modal.video_synthesis.autoencoder import \
     AutoencoderKL
-from modelscope.models.multi_modal.video_synthesis.diffusion import (
+from weathon.models.multi_modal.video_synthesis.diffusion import (
     GaussianDiffusion, beta_schedule)
-from modelscope.models.multi_modal.video_synthesis.unet_sd import UNetSD
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.models.multi_modal.video_synthesis.unet_sd import UNetSD
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['TextToVideoSynthesis']
 
 
 @MODELS.register_module(
     Tasks.text_to_video_synthesis, module_name=Models.video_synthesis)
 class TextToVideoSynthesis(Model):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/video_synthesis/unet_sd.py` & `weathon-0.0.0.14/weathon/models/multi_modal/video_synthesis/unet_sd.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/conv_fpn_trans.py` & `weathon-0.0.0.14/weathon/models/multi_modal/vldoc/conv_fpn_trans.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import random
 from collections import OrderedDict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from timm.models.layers import DropPath, trunc_normal_
 
-from modelscope.models.multi_modal.vldoc.convnext import convnext_tiny
-from modelscope.utils.logger import get_logger
+from weathon.models.multi_modal.vldoc.convnext import convnext_tiny
+from weathon.utils.logger import get_logger
 
 try:
     import apex
     import apex.normalization
     LN = apex.normalization.FusedLayerNorm
 except ImportError:
     LN = torch.nn.LayerNorm
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/convnext.py` & `weathon-0.0.0.14/weathon/models/multi_modal/vldoc/convnext.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/model.py` & `weathon-0.0.0.14/weathon/models/multi_modal/vldoc/model.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,32 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import copy
-import logging
-import math
 import os
-import re
-import sys
 
-import json
 import torch
-import torch.distributed as dist
 import torch.nn as nn
 from torchvision.ops import roi_align
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.multi_modal.vldoc.conv_fpn_trans import FPNTrans
-from modelscope.models.multi_modal.vldoc.modeling_layout_roberta import (
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.multi_modal.vldoc.conv_fpn_trans import FPNTrans
+from weathon.models.multi_modal.vldoc.modeling_layout_roberta import (
     LayoutRobertaModel, LayoutRobertaPreTrainedModel)
-from modelscope.models.multi_modal.vldoc.transformer_local import (
+from weathon.models.multi_modal.vldoc.transformer_local import (
     TransformerDecoder, TransformerDecoderLayer)
-from modelscope.utils.constant import ModeKeys, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['VLDocForDocVLEmbedding']
 
 
 class GeoVLDocModelOutputs(object):
@@ -262,29 +254,29 @@
             the path in model hub, e.g., 'damo/multi-modal_convnext-roberta-base_vldoc-embedding'
     """
 
     def __init__(self, model_dir: str, *args, **kwargs):
         super().__init__(model_dir=model_dir, *args, **kwargs)
 
         # Initialize the model.
-        from modelscope.models.multi_modal.vldoc.modeling_layout_roberta import LayoutRobertaConfig
+        from weathon.models.multi_modal.vldoc.modeling_layout_roberta import LayoutRobertaConfig
         model_cfg_path = os.path.join(model_dir, 'config.json')
         logger.info('Loading config file from {}'.format(model_cfg_path))
         assert os.path.exists(model_cfg_path)
         self.config = LayoutRobertaConfig.from_json_file(model_cfg_path)
         self.doc_model = GeoVLDocModel(self.config)
 
         # restore the pretrained weight
         model_path = os.path.join(model_dir, ModelFile.TORCH_MODEL_FILE)
         assert os.path.exists(model_path)
         self.doc_model.from_pretrained(model_path)
         logger.info('Loading model from {}'.format(model_path))
 
         # Initialize the tokenizer.
-        from modelscope.models.multi_modal.vldoc.tokenization import VLDocXLMTokenizer
+        from weathon.models.multi_modal.vldoc.tokenization import VLDocXLMTokenizer
         tokenizer_path = os.path.join(model_dir, ModelFile.TOKENIZER_FOLDER)
         self.tokenizer = VLDocXLMTokenizer.from_pretrained(tokenizer_path)
 
         # place the model
         self.device = 'cuda:{}'.format(int(os.environ.get(
             'LOCAL_RANK', 0))) if torch.cuda.is_available() else 'cpu'
         if torch.cuda.is_available():
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/modeling_layout_roberta.py` & `weathon-0.0.0.14/weathon/models/multi_modal/vldoc/modeling_layout_roberta.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/processing.py` & `weathon-0.0.0.14/weathon/models/multi_modal/vldoc/processing.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """
 Processor class for GeoLayoutLM.
 """
 
 from collections import defaultdict
 from typing import Dict, Iterable, List, Union
 
 import cv2
 import numpy as np
 import PIL
 import torch
 from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from torchvision import transforms
 
-from modelscope.preprocessors.image import LoadImage
+from weathon.preprocessors.image import LoadImage
 
 
 def custom_tokenize(tokenizer, text):
     toks = tokenizer.tokenize('pad ' + text)[1:]
     toks2 = toks[1:] if len(toks) > 0 and toks[0] == '' else toks
     return toks2
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/tokenization.py` & `weathon-0.0.0.14/weathon/models/multi_modal/vldoc/tokenization.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 
 from transformers import XLMRobertaTokenizer
 
 SPIECE_UNDERLINE = ''
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/multi_modal/vldoc/transformer_local.py` & `weathon-0.0.0.14/weathon/models/multi_modal/vldoc/transformer_local.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/T5/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/llama/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,21 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .backbone import T5Model
-    from .text2text_generation import T5ForConditionalGeneration
-
+    from .configuration import LlamaConfig
+    from .text_generation import LlamaForTextGeneration
+    from .backbone import LlamaModel
+    from .tokenization import LlamaTokenizer
+    from .tokenization_fast import LlamaTokenizerFast
 else:
     _import_structure = {
-        'backbone': ['T5Model'],
-        'text2text_generation': ['T5ForConditionalGeneration'],
+        'configuration': ['LlamaConfig'],
+        'text_generation': ['LlamaForTextGeneration'],
+        'backbone': ['LlamaModel'],
+        'tokenization': ['LlamaTokenizer'],
+        'tokenization_fast': ['LlamaTokenizerFast'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/T5/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/T5/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 Mesh TensorFlow authors, T5 Authors and HuggingFace Inc. team.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
@@ -25,26 +24,24 @@
 from torch.utils.checkpoint import checkpoint
 from transformers.activations import ACT2FN
 from transformers.modeling_outputs import \
     BaseModelOutputWithPastAndCrossAttentions
 from transformers.modeling_utils import (PreTrainedModel,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
-from transformers.utils import (DUMMY_INPUTS, DUMMY_MASK, add_start_docstrings,
-                                add_start_docstrings_to_model_forward,
-                                is_torch_fx_proxy, replace_return_docstrings)
+from transformers.utils import (DUMMY_INPUTS, DUMMY_MASK, is_torch_fx_proxy)
 from transformers.utils.model_parallel_utils import (assert_device_map,
                                                      get_device_map)
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model, Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput, Seq2SeqModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.base import BaseModel, TorchModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput, Seq2SeqModelOutput
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 from .configuration import T5Config
 
 logger = get_logger()
 
 
 ###################################################
 # This is a conversion method from TF 1.0 to PyTorch
@@ -712,15 +709,15 @@
     load_tf_weights = load_tf_weights_in_t5
     base_model_prefix = 'transformer'
     is_parallelizable = True
     supports_gradient_checkpointing = True
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     @property
     def dummy_inputs(self):
         input_ids = torch.tensor(DUMMY_INPUTS)
         input_mask = torch.tensor(DUMMY_MASK)
         dummy_inputs = {
             'decoder_input_ids': input_ids,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/T5/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/T5/configuration.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2020, The T5 Authors and HuggingFace Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
@@ -14,15 +13,15 @@
 # limitations under the License.
 """ T5 model configuration"""
 from typing import Mapping
 
 from transformers.configuration_utils import PretrainedConfig
 from transformers.onnx import OnnxSeq2SeqConfigWithPast
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class T5Config(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration of a [`T5Model`] or a [`TFT5Model`]. It is used to
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/T5/text2text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/T5/text2text_generation.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 Mesh TensorFlow authors, T5 Authors and HuggingFace Inc. team.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
@@ -18,21 +17,20 @@
 
 import torch
 from torch import nn
 from torch.nn import CrossEntropyLoss
 from transformers.utils.model_parallel_utils import (assert_device_map,
                                                      get_device_map)
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import (AttentionBackboneModelOutput, Seq2SeqLMOutput,
-                                TokenGeneratorOutput)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from .backbone import T5PreTrainedModel, T5Stack
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
+from weathon.utils.output.nlp_outputs import Seq2SeqLMOutput, AttentionBackboneModelOutput, TokenGeneratorOutput
+from .backbone import T5PreTrainedModel, T5Stack, __HEAD_MASK_WARNING_MSG
 from .configuration import T5Config
 
 logger = get_logger()
 
 # Warning message for FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask
 __HEAD_MASK_WARNING_MSG = """
 The input argument `head_mask` was split into two arguments `head_mask` and
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,82 +1,55 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .bart import BartForTextErrorCorrection
-    from .bert import (
-        BertForMaskedLM,
-        BertForTextRanking,
-        BertForSentenceEmbedding,
-        BertForSequenceClassification,
-        BertForTokenClassification,
-        BertForDocumentSegmentation,
-        BertModel,
-        BertConfig,
-        SiameseUieModel,
-    )
-    from .bloom import BloomModel
-    from .codegeex import CodeGeeXForCodeTranslation, CodeGeeXForCodeGeneration
-    from .glm_130b import GLM130bForTextGeneration
-    from .csanmt import CsanmtForTranslation
-    from .canmt import CanmtForTranslation
-    from .deberta_v2 import DebertaV2ForMaskedLM, DebertaV2Model
-    from .gpt_neo import GPTNeoModel
-    from .gpt2 import GPT2Model
-    from .gpt3 import GPT3ForTextGeneration, DistributedGPT3
-    from .gpt_moe import GPTMoEForTextGeneration, DistributedGPTMoE
+    from .backbone.bart import BartForTextErrorCorrection
+    from .backbone.bloom import BloomModel
+    from .backbone.glm_130b import GLM130bForTextGeneration
+    from .backbone.canmt import CanmtForTranslation
+    from .backbone.deberta_v2 import DebertaV2ForMaskedLM, DebertaV2Model
+    from .backbone.gpt_neo import GPTNeoModel
+    from weathon.models.nlp.backbone.gpt2 import GPT2Model
+    from .backbone.gpt3 import GPT3ForTextGeneration, DistributedGPT3
+    from .backbone.gpt_moe import GPTMoEForTextGeneration, DistributedGPTMoE
     from .heads import TextClassificationHead
-    from .hf_transformers import TransformersModel
-    from .lstm import (
+    from .backbone.hf_transformers import TransformersModel
+    from .backbone.lstm import (
         LSTMModel,
         LSTMForTokenClassificationWithCRF,
     )
-    from .megatron_bert import (
-        MegatronBertConfig,
-        MegatronBertForMaskedLM,
-        MegatronBertModel,
-    )
-    from .mglm import MGLMForTextSummarization
-    from .palm_v2 import PalmForTextGeneration
-    from .plug_mental import (PlugMentalConfig, PlugMentalModel,
+    from .backbone.mglm import MGLMForTextSummarization
+    from weathon.models.nlp.backbone.palm_v2 import PalmForTextGeneration
+    from .backbone.plug_mental import (PlugMentalConfig, PlugMentalModel,
                               PlugMentalForSequenceClassification)
-    from .ponet import PoNetForMaskedLM, PoNetModel, PoNetConfig
-    from .space import SpaceForDialogIntent, SpaceForDialogModeling, SpaceForDST
-    from .space_T_cn import TableQuestionAnswering
-    from .space_T_en import StarForTextToSql
-    from .structbert import (
+    from .backbone.ponet import PoNetForMaskedLM, PoNetModel, PoNetConfig
+    from .backbone.space_T_cn import TableQuestionAnswering
+    from .backbone.space_T_en import StarForTextToSql
+    from weathon.models.nlp.backbone.structbert import (
         SbertForFaqQuestionAnswering,
         SbertForMaskedLM,
         SbertForSequenceClassification,
         SbertForTokenClassification,
         SbertModel,
     )
-    from .T5 import T5ForConditionalGeneration
+    from .backbone.T5 import T5ForConditionalGeneration
     from .task_models import (
         ModelForFeatureExtraction,
         ModelForInformationExtraction,
         ModelForTextClassification,
         SingleBackboneTaskModelBase,
         ModelForTextGeneration,
         ModelForTextRanking,
         ModelForTokenClassification,
         ModelForTokenClassificationWithCRF,
     )
-    from .unite import UniTEForTranslationEvaluation
-    from .use import UserSatisfactionEstimation
-    from .veco import (VecoConfig, VecoForMaskedLM,
-                       VecoForSequenceClassification,
-                       VecoForTokenClassification, VecoModel)
-    from .dgds import (DocumentGroundedDialogGenerateModel,
-                       DocumentGroundedDialogRetrievalModel,
-                       DocumentGroundedDialogRerankModel)
-    from .xlm_roberta import XLMRobertaConfig, XLMRobertaModel
-    from .llama import LlamaForTextGeneration, LlamaConfig, LlamaModel, LlamaTokenizer, LlamaTokenizerFast
+    from weathon.models.nlp.backbone.unite import UniTEForTranslationEvaluation
+    from .backbone.use import UserSatisfactionEstimation
+    from .backbone.llama import LlamaForTextGeneration, LlamaConfig, LlamaModel, LlamaTokenizer, LlamaTokenizerFast
 
 else:
     _import_structure = {
         'bart': ['BartForTextErrorCorrection'],
         'bert': [
             'BertForMaskedLM',
             'BertForTextRanking',
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bart/text_error_correction.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bart/text_error_correction.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,21 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import torch.cuda
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import TextErrorCorrectionOutput
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+
 
 __all__ = ['BartForTextErrorCorrection']
 
+from weathon.utils.output.nlp_outputs import TextErrorCorrectionOutput
+
 
 @MODELS.register_module(Tasks.text_error_correction, module_name=Models.bart)
 class BartForTextErrorCorrection(TorchModel):
 
     def __init__(self, model_dir, *args, **kwargs):
         super().__init__(model_dir=model_dir, *args, **kwargs)
         """initialize the text error correction model from the `model_dir` path.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .backbone import (
         BertLayer,
         BertModel,
         BertPreTrainedModel,
     )
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -23,21 +22,21 @@
 from torch import nn
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import (PreTrainedModel,
                                          apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.base import TorchModel, BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.logger import get_logger
+from weathon.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
 from .configuration import BertConfig
 
 logger = get_logger()
 
 _CONFIG_FOR_DOC = 'BertConfig'
 
 
@@ -592,15 +591,15 @@
     config_class = BertConfig
     base_model_prefix = 'bert'
     supports_gradient_checkpointing = True
     _keys_to_ignore_on_load_missing = [r'position_ids']
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def _init_weights(self, module):
         """Initialize the weights"""
         if isinstance(module, nn.Linear):
             # Slightly different from the TF version which uses truncated_normal for initialization
             # cf https://github.com/pytorch/pytorch/pull/5617
             module.weight.data.normal_(
@@ -638,15 +637,15 @@
         model_dir = kwargs.pop('model_dir', None)
         cfg = kwargs.pop('cfg', None)
         model_args = parse_labels_in_order(model_dir, cfg, **kwargs)
         if model_dir is None:
             config = BertConfig(**model_args)
             model = cls(config)
         else:
-            model = super(Model, cls).from_pretrained(
+            model = super(BaseModel, cls).from_pretrained(
                 pretrained_model_name_or_path=model_dir, **model_args)
         model.model_dir = model_dir
         return model
 
 
 @MODELS.register_module(group_key=Tasks.backbone, module_name=Models.bert)
 class BertModel(BertPreTrainedModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/configuration.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -16,15 +15,15 @@
 """ BERT model configuration """
 from collections import OrderedDict
 from typing import Mapping
 
 from transformers.configuration_utils import PretrainedConfig
 from transformers.onnx import OnnxConfig
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class BertConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration of a
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/document_segmentation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/document_segmentation.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,29 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 import torch
 from torch import nn
 from torch.nn import CrossEntropyLoss
 
-from modelscope.metainfo import Models
-from modelscope.models import Model
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.ponet import PoNetConfig
-from modelscope.outputs import AttentionTokenClassificationModelOutput
-from modelscope.utils.constant import Tasks
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.nlp.ponet import PoNetConfig
+from weathon.utils.output.nlp_outputs import AttentionTokenClassificationModelOutput
 from .backbone import BertModel, BertPreTrainedModel
 from .configuration import BertConfig
 
 __all__ = ['BertForDocumentSegmentation']
 
 
-@MODELS.register_module(
-    Tasks.document_segmentation, module_name=Models.bert_for_ds)
+@MODELS.register_module(Tasks.document_segmentation, module_name=Models.bert_for_ds)
 class BertForDocumentSegmentation(BertPreTrainedModel):
 
     _keys_to_ignore_on_load_unexpected = [r'pooler']
 
     def __init__(self, config, **kwargs):
         super().__init__(config)
         self.num_labels = config.num_labels
@@ -101,12 +98,12 @@
             config = BertConfig.from_pretrained(model_dir, num_labels=2)
         elif model_config['type'] == 'ponet':
             config = PoNetConfig.from_pretrained(model_dir, num_labels=2)
         else:
             raise ValueError(
                 f'Expected config type bert and ponet, which is : {model_config["type"]}'
             )
-        model = super(Model, cls).from_pretrained(
+        model = super(BaseModel, cls).from_pretrained(
             model_dir, from_tf=False, config=config)
         model.model_dir = model_dir
         model.model_cfg = model_config
         return model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/sentence_embedding.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/sentence_embedding.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 from torch import nn
 
-from modelscope.metainfo import Models
-from modelscope.models import Model
-from modelscope.models.builder import MODELS
-from modelscope.outputs import SentencEmbeddingModelOutput
-from modelscope.utils.constant import Tasks
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.output.nlp_outputs import SentencEmbeddingModelOutput
 from .backbone import BertModel, BertPreTrainedModel
 
 
 class Pooler(nn.Module):
     """
     Parameter-free poolers to get the sentence embedding
     'cls': [CLS] representation with BERT/RoBERTa's MLP pooler.
@@ -74,18 +72,17 @@
                 for details.
             docs (:obj: `dict`): Dict of pretrained models's input for the query sequence. See
                 :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__`
                 for details.
         Returns:
             Returns `modelscope.outputs.SentencEmbeddingModelOutput
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_corom_sentence-embedding_chinese-base')
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_corom_sentence-embedding_chinese-base')
+            >>> from weathon.base import BaseModel, BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_corom_sentence-embedding_chinese-base')
+            >>> preprocessor = BasePreprocessor.from_pretrained('damo/nlp_corom_sentence-embedding_chinese-base')
             >>> print(model(**preprocessor('source_sentence':['This is a test'])))
         """
         query_embeddings, doc_embeddings = None, None
         if query is not None:
             query_embeddings = self.encode(**query)
         if docs is not None:
             doc_embeddings = self.encode(**docs)
@@ -96,30 +93,30 @@
         if self.base_model.training:
             loss_fct = nn.CrossEntropyLoss()
             scores = torch.matmul(query_embeddings, doc_embeddings.T)
             if labels is None:
                 labels = torch.arange(
                     scores.size(0), device=scores.device, dtype=torch.long)
                 labels = labels * (
-                    doc_embeddings.size(0) // query_embeddings.size(0))
+                        doc_embeddings.size(0) // query_embeddings.size(0))
             loss = loss_fct(scores, labels)
             outputs.loss = loss
         return outputs
 
     def encode(
-        self,
-        input_ids=None,
-        attention_mask=None,
-        token_type_ids=None,
-        position_ids=None,
-        head_mask=None,
-        inputs_embeds=None,
-        output_attentions=None,
-        output_hidden_states=None,
-        return_dict=None,
+            self,
+            input_ids=None,
+            attention_mask=None,
+            token_type_ids=None,
+            position_ids=None,
+            head_mask=None,
+            inputs_embeds=None,
+            output_attentions=None,
+            output_hidden_states=None,
+            return_dict=None,
     ):
         outputs = self.base_model.forward(
             input_ids,
             attention_mask=attention_mask,
             token_type_ids=token_type_ids,
             position_ids=position_ids,
             head_mask=head_mask,
@@ -138,12 +135,10 @@
             kwargs: Input args.
                     model_dir: The model dir used to load the checkpoint and the label information.
 
         Returns:
             The loaded model, which is initialized by transformers.PreTrainedModel.from_pretrained
         """
         model_dir = kwargs.get('model_dir')
-        model = super(
-            Model,
-            cls).from_pretrained(pretrained_model_name_or_path=model_dir)
+        model = super(BaseModel, cls).from_pretrained(pretrained_model_name_or_path=model_dir)
         model.model_dir = model_dir
         return model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/siamese_uie.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/siamese_uie.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from copy import deepcopy
 
 import torch
 from torch import nn
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 from .backbone import BertEncoder, BertModel, BertPreTrainedModel
 
 __all__ = ['SiameseUieModel']
 
 
 @MODELS.register_module(Tasks.siamese_uie, module_name=Models.bert)
 class SiameseUieModel(BertPreTrainedModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/text_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/token_classification.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,31 +1,43 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp import ModelForTextClassification
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
+# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
+# All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Heads, Models
+from weathon.models.nlp.task_models.token_classification import (
+    ModelForTokenClassification, ModelForTokenClassificationWithCRF)
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
-@MODELS.register_module(Tasks.text_classification, module_name=Models.bert)
-@MODELS.register_module(Tasks.nli, module_name=Models.bert)
-@MODELS.register_module(
-    Tasks.sentiment_classification, module_name=Models.bert)
-@MODELS.register_module(Tasks.sentence_similarity, module_name=Models.bert)
-@MODELS.register_module(
-    Tasks.zero_shot_classification, module_name=Models.bert)
-class BertForSequenceClassification(ModelForTextClassification):
-    r"""Bert Model transformer with a sequence classification/regression head on top
-    (a linear layer on top of the pooled output) e.g. for GLUE tasks.
+@MODELS.register_module(Tasks.token_classification, module_name=Models.bert)
+@MODELS.register_module(Tasks.part_of_speech, module_name=Models.bert)
+@MODELS.register_module(Tasks.word_segmentation, module_name=Models.bert)
+class BertForTokenClassification(ModelForTokenClassification):
+    r"""Bert Model with a token classification head on top (a linear layer on top of
+    the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks, word-segmentation.
 
-    This model inherits from :class:`SequenceClassificationModel`. Check the superclass documentation for the generic
+    This model inherits from :class:`TokenClassificationModel`. Check the superclass documentation for the generic
     methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
     pruning heads etc.)
 
     This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__
     subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
     general usage and behavior.
+
     """
+
     base_model_type = 'bert'
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/text_ranking.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/text_ranking.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,14 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp import ModelForTextRanking
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.nlp import ModelForTextRanking
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 @MODELS.register_module(Tasks.text_ranking, module_name=Models.bert)
 class BertForTextRanking(ModelForTextRanking):
     r"""Bert Model transformer with a sequence classification/regression head on top
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/token_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/lstm/token_classification.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 # All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
@@ -11,35 +10,39 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from modelscope.metainfo import Heads, Models
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.task_models.token_classification import (
+from weathon.utils.constants.metainfo import Heads, Models
+from weathon.registry import MODELS
+from weathon.models.nlp.task_models import (
     ModelForTokenClassification, ModelForTokenClassificationWithCRF)
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
 
 logger = logging.get_logger()
 
 
-@MODELS.register_module(Tasks.token_classification, module_name=Models.bert)
-@MODELS.register_module(Tasks.part_of_speech, module_name=Models.bert)
-@MODELS.register_module(Tasks.word_segmentation, module_name=Models.bert)
-class BertForTokenClassification(ModelForTokenClassification):
-    r"""Bert Model with a token classification head on top (a linear layer on top of
+@MODELS.register_module(Tasks.token_classification, module_name=Models.lcrf)
+@MODELS.register_module(
+    Tasks.named_entity_recognition, module_name=Models.lcrf)
+@MODELS.register_module(Tasks.part_of_speech, module_name=Models.lcrf)
+@MODELS.register_module(Tasks.word_segmentation, module_name=Models.lcrf)
+@MODELS.register_module(Tasks.word_segmentation, module_name=Models.lcrf_wseg)
+class LSTMForTokenClassificationWithCRF(ModelForTokenClassificationWithCRF):
+    r"""Model with a token classification head on top (a linear layer on top of
     the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks, word-segmentation.
 
-    This model inherits from :class:`TokenClassificationModel`. Check the superclass documentation for the generic
-    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
-    pruning heads etc.)
-
-    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__
-    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to
-    general usage and behavior.
-
     """
-
-    base_model_type = 'bert'
+    override_base_model_type = True
+    base_model_type = Models.lstm
+    head_type = Heads.lstm_crf
+
+    def parse_head_cfg(self):
+        head_cfg = super(ModelForTokenClassification, self).parse_head_cfg()
+        head_cfg['hidden_size'] = (
+            head_cfg.hidden_size
+            if hasattr(head_cfg, 'hidden_size') else head_cfg.lstm_hidden_size)
+        head_cfg['num_labels'] = self.config.num_labels
+        return head_cfg
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/bert/word_alignment.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/bert/word_alignment.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 # All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
@@ -15,19 +14,19 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import WordAlignmentOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils import logger as logging
+from weathon.utils.output.nlp_outputs import WordAlignmentOutput
 from .backbone import BertModel, BertPreTrainedModel
 
 logger = logging.get_logger()
 
 
 @MODELS.register_module(Tasks.word_alignment, module_name=Models.bert)
 class MBertForWordAlignment(BertPreTrainedModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/canmt/canmt_model.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/canmt/canmt_model.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/canmt/canmt_translation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/canmt/canmt_translation.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,28 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
 import os.path as osp
-from typing import Any, Dict, List, Optional, Tuple
+from typing import Dict
 
-import numpy
 import torch
-import torch.nn as nn
 from torch import Tensor
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.config.config import Config
 
 __all__ = ['CanmtForTranslation']
 
 
-@MODELS.register_module(
-    Tasks.competency_aware_translation, module_name=Models.canmt)
+@MODELS.register_module(Tasks.competency_aware_translation, module_name=Models.canmt)
 class CanmtForTranslation(TorchModel):
 
     def __init__(self, model_dir, **args):
         """
             CanmtForTranslation implements a Competency-Aware Neural Machine Translaton,
             which has both translation and self-estimation abilities.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/canmt/sequence_generator.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/canmt/sequence_generator.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/codegeex.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/codegeex.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/codegeex_for_code_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/codegeex_for_code_generation.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 # Copyright (c) 2022 Zhipu.AI
 import copy
-from typing import Any, Dict
+from typing import Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
 from .codegeex import CodeGeeXModel
 from .inference import get_token_stream
 from .tokenizer import CodeGeeXTokenizer
 
 
 def model_provider():
     """Build the model."""
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/codegeex_for_code_translation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/codegeex_for_code_translation.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,18 @@
 # Copyright (c) 2022 Zhipu.AI
 import copy
-from typing import Any, Dict
+from typing import Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.logger import get_logger
 from .codegeex import CodeGeeXModel
 from .inference import get_token_stream
 from .tokenizer import CodeGeeXTokenizer
 
 
 def model_provider():
     """Build the model."""
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/inference.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/inference.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/codegeex/tokenizer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/codegeex/tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/csanmt/translation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/csanmt/translation.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,26 +1,29 @@
 # Part of the implementation is borrowed and modified from THUMT,
 # publicly available at https://github.com/THUNLP-MT/THUMT
 # Copyright 2017-2022 The Alibaba MT Team Authors. All rights reserved.
 import math
+import sys
 from collections import namedtuple
 from typing import Dict
 
 import tensorflow as tf
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model, Tensor
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import Tasks
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
 __all__ = ['CsanmtForTranslation']
 
+from weathon.utils.typing import Tensor
+
 
 @MODELS.register_module(Tasks.translation, module_name=Models.translation)
-class CsanmtForTranslation(Model):
+class CsanmtForTranslation(BaseModel):
 
     def __init__(self, model_dir, *args, **kwargs):
         """
         Args:
             params (dict): the model configuration.
         """
         super().__init__(model_dir, *args, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .configuration import DebertaV2Config
     from .tokenization import DebertaV2Tokenizer
     from .tokenization_fast import DebertaV2TokenizerFast
     from .backbone import (
         DebertaV2Model,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/backbone.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,20 +21,20 @@
 import torch.utils.checkpoint
 from torch import nn
 from torch.nn import LayerNorm
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import PreTrainedModel
 from transformers.pytorch_utils import softmax_backward_data
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel, BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils import logger as logging
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
 from .configuration import DebertaV2Config
 
 logger = logging.get_logger()
 
 
 # Copied from transformers.models.deberta.modeling_deberta.ContextPooler
 class ContextPooler(nn.Module):
@@ -1008,15 +1008,15 @@
     base_model_prefix = 'deberta'
     _keys_to_ignore_on_load_missing = ['position_ids']
     _keys_to_ignore_on_load_unexpected = ['position_embeddings']
     supports_gradient_checkpointing = True
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def _init_weights(self, module):
         """Initialize the weights."""
         if isinstance(module, nn.Linear):
             # Slightly different from the TF version which uses truncated_normal for initialization
             # cf https://github.com/pytorch/pytorch/pull/5617
             module.weight.data.normal_(
@@ -1036,17 +1036,15 @@
     @classmethod
     def _instantiate(cls, **kwargs):
         model_dir = kwargs.pop('model_dir', None)
         if model_dir is None:
             ponet_config = DebertaV2Config(**kwargs)
             model = cls(ponet_config)
         else:
-            model = super(
-                Model,
-                cls).from_pretrained(pretrained_model_name_or_path=model_dir)
+            model = super(BaseModel,cls).from_pretrained(pretrained_model_name_or_path=model_dir)
         return model
 
 
 @MODELS.register_module(Tasks.backbone, module_name=Models.deberta_v2)
 # Copied from transformers.models.deberta.modeling_deberta.DebertaModel with Deberta->DebertaV2
 class DebertaV2Model(DebertaV2PreTrainedModel):
     """The bare DeBERTa_v2 Model transformer outputting raw hidden-states without any specific head on top.
@@ -1136,18 +1134,17 @@
             return_dict (`bool`, *optional*):
                 Whether or not to return a dataclass instead of a plain tuple.
 
         Returns:
             Returns `modelscope.outputs.AttentionBackboneModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_debertav2_fill-mask_chinese-lite', task='backbone')
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_debertav2_fill-mask_chinese-lite')
+            >>> from weathon.base import BaseModel,BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_debertav2_fill-mask_chinese-lite', task='backbone')
+            >>> preprocessor = BasePreprocessor.from_pretrained('damo/nlp_debertav2_fill-mask_chinese-lite')
             >>> print(model(**preprocessor('')))
         """
 
         output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions
         output_hidden_states = (
             output_hidden_states if output_hidden_states is not None else
             self.config.output_hidden_states)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """ DeBERTa-v2 model configuration, mainly copied from :class:`~transformers.DeBERTaV2Config"""
 
 from transformers import PretrainedConfig
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class DebertaV2Config(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration of a [`DebertaV2Model`]. It is used to instantiate a
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/fill_mask.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/fill_mask.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,18 +17,18 @@
 
 import torch
 import torch.utils.checkpoint
 from torch import nn
 from torch.nn import CrossEntropyLoss
 from transformers.activations import ACT2FN
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionFillMaskModelOutput
-from modelscope.utils.constant import Tasks
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.output.nlp_outputs import AttentionFillMaskModelOutput
 from .backbone import DebertaV2Model, DebertaV2PreTrainedModel
 
 
 # Copied from transformers.models.deberta.modeling_deberta.DebertaForMaskedLM with Deberta->DebertaV2
 @MODELS.register_module(Tasks.fill_mask, module_name=Models.deberta_v2)
 class DebertaV2ForMaskedLM(DebertaV2PreTrainedModel):
     r"""DeBERTa_v2 Model with a `language modeling` head on top.
@@ -123,22 +123,21 @@
                 config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are
                 ignored (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`
 
         Returns:
             Returns `modelscope.outputs.AttentionFillMaskModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_debertav2_fill-mask_chinese-lite')
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_debertav2_fill-mask_chinese-lite')
+            >>> from weathon.base import BaseModel,BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_debertav2_fill-mask_chinese-lite')
+            >>> preprocessor = BasePreprocessor.from_pretrained('damo/nlp_debertav2_fill-mask_chinese-lite')
             >>> # Call the model, return some tensors
             >>> print(model(**preprocessor('[MASK]')))
             >>> # Call the pipeline
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.base import pipeline
             >>> pipeline_ins = pipeline('fill-mask', model=model, preprocessor=preprocessor)
             >>> print(pipeline_ins('[MASK]'))
         """
 
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
 
         outputs = self.deberta(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/tokenization.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/tokenization.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/deberta_v2/tokenization_fast.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/deberta_v2/tokenization_fast.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 import os
 from shutil import copyfile
 from typing import Optional, Tuple
 
 from transformers.file_utils import is_sentencepiece_available
 from transformers.tokenization_utils_fast import PreTrainedTokenizerFast
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 if is_sentencepiece_available():
     from .tokenization import DebertaV2Tokenizer
 else:
     DebertaV2Tokenizer = None
 
 logger = logging.get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/dgds/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .document_grounded_dialog_generate import DocumentGroundedDialogGenerateModel
     from .document_grounded_dialog_rerank import DocumentGroundedDialogRerankModel
     from .document_grounded_dialog_retrieval import DocumentGroundedDialogRetrievalModel
 else:
     _import_structure = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/dgds/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/backbone.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 from torch import nn
 from torch.utils.checkpoint import checkpoint
 from transformers import (AutoConfig, DPRConfig, DPRQuestionEncoder,
                           MT5ForConditionalGeneration, RagTokenForGeneration,
                           XLMRobertaForSequenceClassification, XLMRobertaModel,
                           XLMRobertaTokenizer)
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class Wrapper(nn.Module):
 
     def __init__(self, encoder):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/dgds/document_grounded_dialog_retrieval.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/dgds/document_grounded_dialog_retrieval.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 import os
 from typing import Dict
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
 from .backbone import DPRModel
 
 
-@MODELS.register_module(
-    Tasks.document_grounded_dialog_retrieval, module_name=Models.doc2bot)
+@MODELS.register_module(Tasks.document_grounded_dialog_retrieval, module_name=Models.doc2bot)
 class DocumentGroundedDialogRetrievalModel(TorchModel):
     _backbone_prefix = ''
 
     def __init__(self, model_dir, *args, **kwargs):
         super().__init__(model_dir, *args, **kwargs)
         self.config = Config.from_file(
             os.path.join(self.model_dir, ModelFile.CONFIGURATION))
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/fid_T5/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/fid_T5/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .text_generation import (T5Chat, FIDT5Chat)
 else:
     _import_structure = {
         'text_generation': ['T5Chat', 'FIDT5Chat'],
     }
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/fid_T5/text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/fid_T5/text_generation.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,21 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 import os
 
 import torch
 from transformers import AutoConfig
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.T5 import T5ForConditionalGeneration
-from modelscope.outputs import TextGenerationModelOutput, TokenGeneratorOutput
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.models.nlp import T5ForConditionalGeneration
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.output.nlp_outputs import TokenGeneratorOutput, TextGenerationModelOutput
+
+# from weathon.models.base import TorchModel
+# from weathon.registry import MODELS
+# from weathon.models.nlp.T5 import T5ForConditionalGeneration
+# from weathon.outputs import TextGenerationModelOutput, TokenGeneratorOutput
+# from weathon.utils.constants import Tasks
 
 WEIGHTS_NAME = 'pytorch_model.bin'
 
 
 class T5Chat(TorchModel):
 
     def __init__(self, model_dir, *args, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .configuration import PlugConfig
     from .text_generation import (PlugV2Chat, PlugV2FidChat)
 else:
     _import_structure = {
         'configuration': ['PlugConfig'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/backbone.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/configuration.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/fid_plug/text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/fid_plug/text_generation.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 import os
 
 import torch
 from transformers.modeling_outputs import Seq2SeqLMOutput
 
-from modelscope.metainfo import Models
-from modelscope.models import Model
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import TextGenerationModelOutput, TokenGeneratorOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.output.nlp_outputs import TextGenerationModelOutput, TokenGeneratorOutput
+# from weathon.models.base import TorchModel
+# from weathon.registry import MODELS
+# from weathon.outputs import TextGenerationModelOutput, TokenGeneratorOutput
+# from weathon.utils.constants import Tasks
 from .backbone import PlugForConditionalGeneration
 from .configuration import PlugConfig
 
 CONFIG_NAME = 'config.json'
 WEIGHTS_NAME = 'pytorch_model.bin'
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # Modified by Zhipu.AI
 # Original Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING, Union
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .text_generation import GLM130bForTextGeneration
 else:
     _import_structure = {'text_generation': ['GLM130bForTextGeneration']}
 
     import sys
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/generation/strategies.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/generation/strategies.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/initialize.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/initialize.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/kernels/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/kernels/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/quantization/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/quantization/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/quantization/functional.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/quantization/functional.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/quantization/layers.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/quantization/layers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/glm_130b/text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/glm_130b/text_generation.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,21 +12,26 @@
 import torch
 from SwissArmyTransformer import mpu
 from SwissArmyTransformer.generation.autoregressive_sampling import (
     get_masks_and_position_ids_default, update_mems)
 from SwissArmyTransformer.generation.utils import (generate_continually,
                                                    timed_name)
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.constants.output_constant import OutputKeys
+# from weathon.models.base import TorchModel
+# from weathon.registry import MODELS
+# from weathon.outputs import OutputKeys
+# from weathon.utils.config.config import Config
+# from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from .generation import BaseStrategy, BeamSearchStrategy
 from .initialize import initialize, initialize_model_and_tokenizer
 
 torch.set_num_threads(24)
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .configuration import GPT3Config
-    from .backbone import GPT3Model
-    from .text_generation import GPT3ForTextGeneration
+    from .configuration import GPTMoEConfig
+    from .backbone import GPTMoEModel
+    from .text_generation import GPTMoEForTextGeneration
     from .tokenizer import JiebaBPETokenizer
-    from .distributed_gpt3 import DistributedGPT3
+    from .distributed_gpt_moe import DistributedGPTMoE
 else:
     _import_structure = {
-        'configuration': ['GPT3Config'],
-        'backbone': ['GPT3Model'],
-        'text_generation': ['GPT3ForTextGeneration'],
+        'configuration': ['GPTMoEConfig'],
+        'backbone': ['GPTMoEModel'],
+        'text_generation': ['GPTMoEForTextGeneration'],
         'tokenizer': ['JiebaBPETokenizer'],
-        'distributed_gpt3': ['DistributedGPT3'],
+        'distributed_gpt_moe': ['DistributedGPTMoE'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -19,16 +19,18 @@
 
 import addict
 import torch
 from torch import nn
 from torch.nn import functional as F
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.outputs import TokenGeneratorOutput
-from modelscope.utils.constant import ModelFile
+from weathon.utils.constants import ModelFile
+from weathon.utils.output.nlp_outputs import TokenGeneratorOutput
+# from weathon.outputs import TokenGeneratorOutput
+# from weathon.utils.constants import ModelFile
 from .configuration import GPT3Config
 from .distributed_gpt3 import sample
 
 
 class GPT3SelfAttention(nn.Module):
     """Parallel self-attention layer abstract class.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/configuration.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/distributed_gpt3.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/distributed_gpt3.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,19 +24,19 @@
 from megatron_util.model import (AttnMaskType, Float16Module, LayerNorm,
                                  bias_gelu_impl)
 from megatron_util.model.fused_softmax import FusedScaleMaskSoftmax
 from torch import nn
 from torch.nn import functional as F
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.models import TorchModel
-from modelscope.models.nlp.gpt3 import GPT3Config
-from modelscope.outputs import TextGenerationModelOutput, TokenGeneratorOutput
-from modelscope.utils.megatron_utils import init_megatron_util
-from modelscope.utils.nlp.load_checkpoint import pre_load
+from weathon.base import TorchModel
+from weathon.models.nlp.gpt3 import GPT3Config
+from weathon.utils.megatron_utils import init_megatron_util
+from weathon.utils.nlp.load_checkpoint import pre_load
+from weathon.utils.output.nlp_outputs import TextGenerationModelOutput, TokenGeneratorOutput
 
 
 class GPT3ParallelMLP(nn.Module):
     """MLP.
 
     MLP will take the input with h hidden state, project it to 4*h
     hidden dimension, perform nonlinear transformation, and project the
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/text_generation.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from collections import OrderedDict
 from typing import Dict
 
 import torch
 from transformers import BertTokenizer
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.gpt3 import GPT3Model
-from modelscope.utils.constant import Tasks
-from modelscope.utils.hub import read_config
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.nlp.gpt3 import GPT3Model
 
 __all__ = ['GPT3ForTextGeneration']
 
+from weathon.utils.hub.utils import read_config
+from weathon.utils.typing import Tensor
+
 
 @MODELS.register_module(Tasks.text_generation, module_name=Models.gpt3)
 class GPT3ForTextGeneration(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the text generation model from the `model_dir` path.
 
@@ -26,15 +27,15 @@
         """
         super().__init__(model_dir, *args, **kwargs)
 
         # Temporarily compatible with DistributedGPT3 and GPT3Model,
         # the base/large model based on GPT3Model will be replaced in the future,
         # and GPT3Model will be deprecated
         if 'megatron' in read_config(model_dir):
-            from modelscope.models.nlp import DistributedGPT3
+            from weathon.models.nlp import DistributedGPT3
             self.model = DistributedGPT3(model_dir, **kwargs)
         else:
             self.model = GPT3Model.from_pretrained(model_dir)
             self.tokenizer = BertTokenizer.from_pretrained(model_dir)
 
     def forward(self, input: Dict[str, Tensor]) -> Dict[str, Tensor]:
         """return the result by the model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt3/tokenizer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt3/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .configuration import GPTMoEConfig
-    from .backbone import GPTMoEModel
-    from .text_generation import GPTMoEForTextGeneration
+    from .configuration import GPT3Config
+    from .backbone import GPT3Model
+    from .text_generation import GPT3ForTextGeneration
     from .tokenizer import JiebaBPETokenizer
-    from .distributed_gpt_moe import DistributedGPTMoE
+    from .distributed_gpt3 import DistributedGPT3
 else:
     _import_structure = {
-        'configuration': ['GPTMoEConfig'],
-        'backbone': ['GPTMoEModel'],
-        'text_generation': ['GPTMoEForTextGeneration'],
+        'configuration': ['GPT3Config'],
+        'backbone': ['GPT3Model'],
+        'text_generation': ['GPT3ForTextGeneration'],
         'tokenizer': ['JiebaBPETokenizer'],
-        'distributed_gpt_moe': ['DistributedGPTMoE'],
+        'distributed_gpt3': ['DistributedGPT3'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/backbone.py`

 * *Files 0% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 
 import addict
 import torch
 from torch import nn
 from torch.nn import functional as F
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.utils.constant import ModelFile
+from weathon.utils.constants import ModelFile
 from .configuration import GPTMoEConfig
 
 
 class GPTMoESelfAttention(nn.Module):
     """Parallel self-attention layer abstract class.
 
     Self-attention layer takes input with size [s, b, h]
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/checkpointing.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/checkpointing.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/configuration.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/distributed_gpt_moe.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/distributed_gpt_moe.py`

 * *Files 0% similar despite different names*

```diff
@@ -21,18 +21,18 @@
 from megatron_util.model import (AttnMaskType, Float16Module, LayerNorm,
                                  bias_gelu_impl)
 from megatron_util.model.fused_softmax import FusedScaleMaskSoftmax
 from torch import nn
 from torch.nn import functional as F
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.models import TorchModel
-from modelscope.models.nlp.gpt_moe import GPTMoEConfig
-from modelscope.outputs import TextGenerationModelOutput, TokenGeneratorOutput
-from modelscope.utils.megatron_utils import init_megatron_util
+from weathon.base import TorchModel
+from weathon.models.nlp.gpt_moe import GPTMoEConfig
+from weathon.utils.megatron_utils import init_megatron_util
+from weathon.utils.output.nlp_outputs import TextGenerationModelOutput, TokenGeneratorOutput
 from .checkpointing import load_checkpoint
 from .moe.layer import MoE
 
 
 class GPTMoEParallelMLP(nn.Module):
 
     def __init__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/experts.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/experts.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/layer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/layer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/mappings.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/mappings.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/sharded_moe.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/sharded_moe.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/moe/utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/moe/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/text_generation.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,20 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Dict
 
 from transformers import BertTokenizer
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.gpt_moe import GPTMoEModel
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.nlp.gpt_moe import GPTMoEModel
 
 __all__ = ['GPTMoEForTextGeneration']
 
+from weathon.utils.typing import Tensor
+
 
 @MODELS.register_module(Tasks.text_generation, module_name=Models.gpt_moe)
 class GPTMoEForTextGeneration(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the text generation model from the `model_dir` path.
 
@@ -23,15 +24,15 @@
         """
         super().__init__(model_dir, *args, **kwargs)
 
         # Temporarily compatible with DistributedGPT3 and GPT3Model,
         # the base/large model based on GPT3Model will be replaced in the future,
         # and GPT3Model will be deprecated
         if 'model_parallel_size' in kwargs:
-            from modelscope.models.nlp import DistributedGPTMoE
+            from weathon.models.nlp import DistributedGPTMoE
             self.model = DistributedGPTMoE(model_dir, **kwargs)
         else:
             self.model = GPTMoEModel.from_pretrained(model_dir)
             self.tokenizer = BertTokenizer.from_pretrained(model_dir)
 
     def forward(self, input: Dict[str, Tensor]) -> Dict[str, Tensor]:
         """return the result by the model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/gpt_moe/tokenizer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/gpt_moe/tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/heads/crf_head.py` & `weathon-0.0.0.14/weathon/models/nlp/heads/crf_head.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 #
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
@@ -19,38 +18,35 @@
 
 import torch
 import torch.nn.functional as F
 from torch import nn
 from torch.nn import CrossEntropyLoss
 from transformers.activations import ACT2FN
 
-from modelscope.metainfo import Heads
-from modelscope.models.base import TorchHead
-from modelscope.models.builder import HEADS
-from modelscope.outputs import (AttentionTokenClassificationModelOutput,
-                                ModelOutputBase, OutputKeys,
-                                TokenClassificationModelOutput)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchHead, BaseModelOutput
+from weathon.registry import HEADS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Heads
+from weathon.utils.output.nlp_outputs import TokenClassificationModelOutput, AttentionTokenClassificationModelOutput
 
 
 @HEADS.register_module(Tasks.token_classification, module_name=Heads.lstm_crf)
-@HEADS.register_module(
-    Tasks.named_entity_recognition, module_name=Heads.lstm_crf)
+@HEADS.register_module(Tasks.named_entity_recognition, module_name=Heads.lstm_crf)
 @HEADS.register_module(Tasks.word_segmentation, module_name=Heads.lstm_crf)
 @HEADS.register_module(Tasks.part_of_speech, module_name=Heads.lstm_crf)
 class LSTMCRFHead(TorchHead):
 
     def __init__(self, hidden_size=100, num_labels=None, **kwargs):
         super().__init__(hidden_size=hidden_size, num_labels=num_labels)
         assert num_labels is not None
         self.ffn = nn.Linear(hidden_size * 2, num_labels)
         self.crf = CRF(num_labels, batch_first=True)
 
     def forward(self,
-                inputs: ModelOutputBase,
+                inputs: BaseModelOutput,
                 attention_mask=None,
                 label=None,
                 label_mask=None,
                 offset_mapping=None,
                 **kwargs):
         logits = self.ffn(inputs.last_hidden_state)
 
@@ -82,15 +78,15 @@
     def __init__(self, hidden_size, num_labels, **kwargs):
         super().__init__(
             hidden_size=hidden_size, num_labels=num_labels, **kwargs)
         self.linear = nn.Linear(hidden_size, num_labels)
         self.crf = CRF(num_labels, batch_first=True)
 
     def forward(self,
-                inputs: ModelOutputBase,
+                inputs: BaseModelOutput,
                 attention_mask=None,
                 label=None,
                 label_mask=None,
                 offset_mapping=None,
                 **kwargs):
         logits = self.linear(inputs.last_hidden_state)
         if label_mask is not None:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/heads/fill_mask_head.py` & `weathon-0.0.0.14/weathon/models/nlp/heads/fill_mask_head.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 #
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
@@ -19,20 +18,26 @@
 
 import torch
 import torch.nn.functional as F
 from torch import nn
 from torch.nn import CrossEntropyLoss
 from transformers.activations import ACT2FN, gelu
 
-from modelscope.metainfo import Heads
-from modelscope.models.base import TorchHead
-from modelscope.models.builder import HEADS
-from modelscope.outputs import (AttentionFillMaskModelOutput, ModelOutputBase,
-                                OutputKeys)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchHead, BaseModelOutput
+from weathon.registry import HEADS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Heads
+from weathon.utils.output.nlp_outputs import AttentionFillMaskModelOutput
+
+
+# from weathon.models.base import TorchHead
+# from weathon.models.builder import HEADS
+# from weathon.outputs import (AttentionFillMaskModelOutput, ModelOutputBase,
+#                                 OutputKeys)
+# from weathon.utils.constants import Tasks
 
 
 @HEADS.register_module(Tasks.fill_mask, module_name=Heads.bert_mlm)
 @HEADS.register_module(Tasks.fill_mask, module_name=Heads.fill_mask)
 class BertFillMaskHead(TorchHead):
 
     def __init__(self,
@@ -45,15 +50,15 @@
             hidden_size=hidden_size,
             hidden_act=hidden_act,
             layer_norm_eps=layer_norm_eps,
             vocab_size=vocab_size)
         self.cls = BertOnlyMLMHead(self.config)
 
     def forward(self,
-                inputs: ModelOutputBase,
+                inputs: BaseModelOutput,
                 attention_mask=None,
                 labels=None,
                 **kwargs):
         logits = self.cls(inputs.last_hidden_state)
         loss = None
         if labels is not None:
             loss = self.compute_loss(logits, labels)
@@ -87,15 +92,15 @@
             hidden_size=hidden_size,
             hidden_act=hidden_act,
             layer_norm_eps=layer_norm_eps,
             vocab_size=vocab_size)
         self.lm_head = XLMRobertaLMHead(self.config)
 
     def forward(self,
-                inputs: ModelOutputBase,
+                inputs: BaseModelOutput,
                 attention_mask=None,
                 labels=None,
                 **kwargs):
         logits = self.lm_head(inputs.last_hidden_state)
         loss = None
         if labels is not None:
             loss = self.compute_loss(logits, labels)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/heads/infromation_extraction_head.py` & `weathon-0.0.0.14/weathon/models/nlp/heads/infromation_extraction_head.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,35 +1,38 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 from torch import nn
 
-from modelscope.metainfo import Heads
-from modelscope.models.base import TorchHead
-from modelscope.models.builder import HEADS
-from modelscope.outputs import InformationExtractionOutput, ModelOutputBase
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchHead, BaseModelOutput
+from weathon.registry import HEADS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Heads
+from weathon.utils.output.nlp_outputs import InformationExtractionOutput
 
 
-@HEADS.register_module(
-    Tasks.information_extraction, module_name=Heads.information_extraction)
-@HEADS.register_module(
-    Tasks.relation_extraction, module_name=Heads.information_extraction)
+# from weathon.models.base import TorchHead
+# from weathon.models.builder import HEADS
+# from weathon.outputs import InformationExtractionOutput, ModelOutputBase
+# from weathon.utils.constants import Tasks
+
+
+@HEADS.register_module(Tasks.information_extraction, module_name=Heads.information_extraction)
+@HEADS.register_module(Tasks.relation_extraction, module_name=Heads.information_extraction)
 class InformationExtractionHead(TorchHead):
 
     def __init__(self, hidden_size=768, labels=None, **kwargs):
         super().__init__(hidden_size=hidden_size, labels=labels)
         assert labels is not None
         self.labels = labels
         self.s_layer = nn.Linear(hidden_size, 2)  # head, tail, bce
         self.o_layer = nn.Linear(2 * hidden_size, 2)  # head, tail, bce
         self.p_layer = nn.Linear(hidden_size, len(self.labels))  # label, ce
         self.mha = nn.MultiheadAttention(hidden_size, 4)
 
     def forward(self,
-                inputs: ModelOutputBase,
+                inputs: BaseModelOutput,
                 attention_mask=None,
                 labels=None,
                 text=None,
                 offsets=None,
                 threshold=0.5,
                 **kwargs) -> InformationExtractionOutput:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/heads/text_classification_head.py` & `weathon-0.0.0.14/weathon/models/nlp/heads/text_classification_head.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,29 +1,31 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Dict
 
 import torch
 import torch.nn.functional as F
 from torch import nn
 
-from modelscope.metainfo import Heads
-from modelscope.models.base import TorchHead
-from modelscope.models.builder import HEADS
-from modelscope.outputs import (AttentionTextClassificationModelOutput,
-                                ModelOutputBase, OutputKeys)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchHead, BaseModelOutput
+from weathon.registry import HEADS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Heads
+from weathon.utils.output.nlp_outputs import AttentionTextClassificationModelOutput
+
+
+# from weathon.models.base import TorchHead
+# from weathon.models.builder import HEADS
+# from weathon.outputs import (AttentionTextClassificationModelOutput,
+#                                 ModelOutputBase, OutputKeys)
+# from weathon.utils.constants import Tasks
 
 
-@HEADS.register_module(
-    Tasks.text_classification, module_name=Heads.text_classification)
-@HEADS.register_module(
-    Tasks.sentence_similarity, module_name=Heads.text_classification)
+@HEADS.register_module(Tasks.text_classification, module_name=Heads.text_classification)
+@HEADS.register_module(Tasks.sentence_similarity, module_name=Heads.text_classification)
 @HEADS.register_module(Tasks.nli, module_name=Heads.text_classification)
-@HEADS.register_module(
-    Tasks.sentiment_classification, module_name=Heads.text_classification)
+@HEADS.register_module(Tasks.sentiment_classification, module_name=Heads.text_classification)
 class TextClassificationHead(TorchHead):
 
     def __init__(self,
                  hidden_size=768,
                  classifier_dropout=0.1,
                  num_labels=None,
                  **kwargs):
@@ -33,15 +35,15 @@
             num_labels=num_labels,
         )
         assert num_labels is not None
         self.dropout = nn.Dropout(classifier_dropout)
         self.classifier = nn.Linear(hidden_size, num_labels)
 
     def forward(self,
-                inputs: ModelOutputBase,
+                inputs: BaseModelOutput,
                 attention_mask=None,
                 labels=None,
                 **kwargs):
         pooler_output = inputs.pooler_output
         pooler_output = self.dropout(pooler_output)
         logits = self.classifier(pooler_output)
         loss = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/heads/text_ranking_head.py` & `weathon-0.0.0.14/weathon/models/nlp/heads/text_ranking_head.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,19 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Dict
-
 import torch
 from torch import nn
 
-from modelscope.metainfo import Heads
-from modelscope.models.base import TorchHead
-from modelscope.models.builder import HEADS
-from modelscope.outputs import (AttentionTextClassificationModelOutput,
-                                ModelOutputBase, OutputKeys)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchHead, BaseModelOutput
+from weathon.registry import HEADS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Heads
+from weathon.utils.output.nlp_outputs import AttentionTextClassificationModelOutput
+
+
+# from weathon.models.base import TorchHead
+# from weathon.models.builder import HEADS
+# from weathon.outputs import (AttentionTextClassificationModelOutput,
+#                              ModelOutputBase)
+# from weathon.utils.constants import Tasks
 
 
 @HEADS.register_module(Tasks.text_ranking, module_name=Heads.text_ranking)
 class TextRankingHead(TorchHead):
 
     def __init__(self,
                  hidden_size=768,
@@ -28,15 +31,15 @@
             neg_sample=neg_sample,
         )
         self.neg_sample = neg_sample
         self.dropout = nn.Dropout(classifier_dropout)
         self.classifier = nn.Linear(hidden_size, num_labels)
 
     def forward(self,
-                inputs: ModelOutputBase,
+                inputs: BaseModelOutput,
                 attention_mask=None,
                 labels=None,
                 **kwargs):
         pooler_output = inputs.pooler_output
         pooler_output = self.dropout(pooler_output)
         logits = self.classifier(pooler_output)
         loss = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/heads/token_classification_head.py` & `weathon-0.0.0.14/weathon/models/nlp/heads/token_classification_head.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,29 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Dict
-
 import torch
-import torch.nn.functional as F
 from torch import nn
 from torch.nn import CrossEntropyLoss
 
-from modelscope.metainfo import Heads
-from modelscope.models.base import TorchHead
-from modelscope.models.builder import HEADS
-from modelscope.outputs import (AttentionTokenClassificationModelOutput,
-                                ModelOutputBase, OutputKeys)
-from modelscope.utils.constant import Tasks
-
-
-@HEADS.register_module(
-    Tasks.token_classification, module_name=Heads.token_classification)
-@HEADS.register_module(
-    Tasks.named_entity_recognition, module_name=Heads.token_classification)
-@HEADS.register_module(
-    Tasks.part_of_speech, module_name=Heads.token_classification)
+from weathon.base import TorchHead, BaseModelOutput
+from weathon.registry import HEADS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Heads
+from weathon.utils.output.nlp_outputs import AttentionTokenClassificationModelOutput
+
+
+# from weathon.models.base import TorchHead
+# from weathon.models.builder import HEADS
+# from weathon.outputs import (AttentionTokenClassificationModelOutput,
+#                              ModelOutputBase)
+# from weathon.utils.constants import Tasks
+
+
+@HEADS.register_module(Tasks.token_classification, module_name=Heads.token_classification)
+@HEADS.register_module(Tasks.named_entity_recognition, module_name=Heads.token_classification)
+@HEADS.register_module(Tasks.part_of_speech, module_name=Heads.token_classification)
 class TokenClassificationHead(TorchHead):
 
     def __init__(self,
                  hidden_size=768,
                  classifier_dropout=0.1,
                  num_labels=None,
                  **kwargs):
@@ -33,15 +32,15 @@
             hidden_size=hidden_size,
         )
         assert num_labels is not None
         self.dropout = nn.Dropout(classifier_dropout)
         self.classifier = nn.Linear(hidden_size, num_labels)
 
     def forward(self,
-                inputs: ModelOutputBase,
+                inputs: BaseModelOutput,
                 attention_mask=None,
                 labels=None,
                 **kwargs):
         sequence_output = inputs.last_hidden_state
         sequence_output = self.dropout(sequence_output)
         logits = self.classifier(sequence_output)
         loss = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/heads/torch_pretrain_head.py` & `weathon-0.0.0.14/weathon/models/nlp/heads/torch_pretrain_head.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,18 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Dict
 
 import torch
 from transformers.models.bert.modeling_bert import BertOnlyMLMHead
 from transformers.models.roberta.modeling_roberta import RobertaLMHead
 
-from modelscope.metainfo import Heads
-from modelscope.models.base import TorchHead
-from modelscope.models.builder import HEADS
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchHead
+from weathon.registry import HEADS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Heads
+# from weathon.models.base import TorchHead
+# from weathon.models.builder import HEADS
+# from weathon.utils.constants import Tasks
 
 
 # @HEADS.register_module(Tasks.fill_mask, module_name=Heads.bert_mlm)
 class BertMLMHead(BertOnlyMLMHead, TorchHead):
 
     def compute_loss(self, outputs: Dict[str, torch.Tensor],
                      labels) -> Dict[str, torch.Tensor]:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/hf_transformers/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/hf_transformers/backbone.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -14,21 +13,19 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """PyTorch BERT model. """
 
 from transformers import AutoConfig, AutoModel
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def _get_model_class(config, model_mapping):
     supported_models = model_mapping[type(config)]
     if not isinstance(supported_models, (list, tuple)):
@@ -45,16 +42,15 @@
             return name_to_model[f'Flax{arch}']
 
     # If not architecture is set in the config or match the supported models, the first element of the tuple is the
     # defaults.
     return supported_models[0]
 
 
-@MODELS.register_module(
-    group_key=Tasks.backbone, module_name=Models.transformers)
+@MODELS.register_module(group_key=Tasks.backbone, module_name=Models.transformers)
 class TransformersModel(TorchModel, PreTrainedModel):
     """The Bert Model transformer outputting raw hidden-states without any
     specific head on top.
 
     This model inherits from [`PreTrainedModel`]. Check the superclass
     documentation for the generic methods the library implements for all its
     model (such as downloading or saving, resizing the input embeddings, pruning
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/llama/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/llama/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved.
 #
 # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX
 # and OPT implementations in this library. It has been modified from its
 # original forms to accommodate minor architectural differences compared
 # to GPT-NeoX and OPT used by the Meta AI team that trained the model.
 #
@@ -23,20 +22,20 @@
 
 import torch
 import torch.utils.checkpoint
 from torch import nn
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 from .configuration import LlamaConfig
 
 logger = get_logger(__name__)
 
 _CONFIG_FOR_DOC = 'LlamaConfig'
 
 
@@ -381,15 +380,15 @@
     base_model_prefix = 'model'
     supports_gradient_checkpointing = True
     _no_split_modules = ['LlamaDecoderLayer']
     _keys_to_ignore_on_load_unexpected = [r'decoder\.version']
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def _init_weights(self, module):
         std = self.config.initializer_range
         if isinstance(module, nn.Linear):
             module.weight.data.normal_(mean=0.0, std=std)
             if module.bias is not None:
                 module.bias.data.zero_()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/llama/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/llama/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved.
 #
 # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX
 # and OPT implementations in this library. It has been modified from its
 # original forms to accommodate minor architectural differences compared
 # to GPT-NeoX and OPT used by the Meta AI team that trained the model.
 #
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/llama/convert_llama_weights_to_hf.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/llama/convert_llama_weights_to_hf.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2022 EleutherAI and The HuggingFace Inc. team. All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/llama/text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/llama/text_generation.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved.
 #
 # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX
 # and OPT implementations in this library. It has been modified from its
 # original forms to accommodate minor architectural differences compared
 # to GPT-NeoX and OPT used by the Meta AI team that trained the model.
 #
@@ -19,19 +18,19 @@
 # limitations under the License.
 from typing import Dict, List, Optional, Tuple, Union
 
 import torch.utils.checkpoint
 from torch import nn
 from torch.nn import CrossEntropyLoss
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTextGenerationModelOutput
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.typing import Tensor
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionTextGenerationModelOutput
+from weathon.utils.constants import Tasks
 from .backbone import LlamaModel, LlamaPreTrainedModel
 
 
 # This file is mainly copied from the llama code of transformers
 @MODELS.register_module(Tasks.text_generation, module_name=Models.llama)
 class LlamaForTextGeneration(LlamaPreTrainedModel):
     _keys_to_ignore_on_load_missing = [r'lm_head.weight']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/llama/tokenization.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/llama/tokenization.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # coding=utf-8
 # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved.
 #
 # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX
 # and OPT implementations in this library. It has been modified from its
 # original forms to accommodate minor architectural differences compared
 # to GPT-NeoX and OPT used by the Meta AI team that trained the model.
@@ -22,15 +21,15 @@
 import os
 from shutil import copyfile
 from typing import Any, Dict, List, Optional, Tuple
 
 import sentencepiece as spm
 from transformers.tokenization_utils import AddedToken, PreTrainedTokenizer
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 # This file is mainly copied from the llama code of transformers
 logger = get_logger(__name__)
 
 VOCAB_FILES_NAMES = {'vocab_file': 'tokenizer.model'}
 
 PRETRAINED_VOCAB_FILES_MAP = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/llama/tokenization_fast.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/llama/tokenization_fast.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # coding=utf-8
 # Copyright 2020 The HuggingFace Inc. team.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -17,15 +16,15 @@
 from shutil import copyfile
 from typing import Optional, Tuple
 
 from transformers.tokenization_utils_fast import PreTrainedTokenizerFast
 from transformers.utils import is_sentencepiece_available
 from transformers.utils.versions import require_version
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 # This file is mainly copied from the llama code of transformers
 require_version('tokenizers>=0.13.3')
 
 if is_sentencepiece_available():
     from .tokenization import LlamaTokenizer
 else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/lstm/__init__.py` & `weathon-0.0.0.14/weathon/exporters/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,19 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .backbone import LSTMModel
-    from .token_classification import LSTMForTokenClassificationWithCRF
+    from .cv import CartoonTranslationExporter, FaceDetectionSCRFDExporter
+    from .nlp import CsanmtForTranslationExporter,SbertForSequenceClassificationExporter, SbertForZeroShotClassificationExporter
 else:
     _import_structure = {
-        'backbone': ['LSTM'],
-        'token_classification': ['LSTMForTokenClassificationWithCRF'],
+        'cv': ['CartoonTranslationExporter', 'FaceDetectionSCRFDExporter'],
+        'nlp': [
+            'CsanmtForTranslationExporter',
+            'SbertForSequenceClassificationExporter',
+            'SbertForZeroShotClassificationExporter'
+        ],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/lstm/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/lstm/backbone.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """PyTorch LSTM model. """
 
 import torch.nn as nn
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import BackboneModelOutput
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import BackboneModelOutput
+from weathon.utils.constants import Tasks
 
 
 @MODELS.register_module(group_key=Tasks.backbone, module_name=Models.lstm)
 class LSTMModel(TorchModel):
 
     def __init__(self, vocab_size, embed_width, hidden_size=100, **kwargs):
         super().__init__()
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/megatron_bert/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -22,21 +21,21 @@
 from torch import nn
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import (PreTrainedModel,
                                          apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
+from weathon.utils.nlp.utils import parse_labels_in_order
 from .configuration import MegatronBertConfig
 
 logger = get_logger()
 
 _CONFIG_FOR_DOC = 'MegatronBertConfig'
 
 
@@ -590,15 +589,15 @@
     config_class = MegatronBertConfig
     base_model_prefix = 'bert'
     supports_gradient_checkpointing = True
     _keys_to_ignore_on_load_missing = [r'position_ids']
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def _init_weights(self, module):
         """Initialize the weights"""
         if isinstance(module, (nn.Linear, nn.Embedding)):
             # Slightly different from the TF version which uses truncated_normal for initialization
             # cf https://github.com/pytorch/pytorch/pull/5617
             module.weight.data.normal_(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/megatron_bert/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -17,15 +16,15 @@
 
 from collections import OrderedDict
 from typing import Mapping
 
 from transformers.configuration_utils import PretrainedConfig
 from transformers.onnx import OnnxConfig
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class MegatronBertConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration of a [`MegatronBertModel`]. It is used to instantiate a
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/megatron_bert/fill_mask.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/fill_mask.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 # All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
@@ -17,19 +16,19 @@
 
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 from torch.nn import CrossEntropyLoss
 from transformers.activations import ACT2FN
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionFillMaskModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.outputs import AttentionFillMaskModelOutput
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
 from .backbone import MegatronBertModel, MegatronBertPreTrainedModel
 from .configuration import MegatronBertConfig
 
 logger = logging.get_logger()
 
 
 # Copied from transformers.models.bert.modeling_bert.BertPredictionHeadTransform with Bert->MegatronBert
@@ -214,16 +213,16 @@
                 the loss is only computed for the tokens with labels in `[0, ...,
                 config.vocab_size]`
 
         Returns:
             Returns `modelscope.outputs.AttentionFillMaskModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
+            >>> from weathon.models import Model
+            >>> from weathon.preprocessors import Preprocessor
             >>> model = Model.from_pretrained('damo/nlp_megatronbert_backbone_base_std')
             >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_megatronbert_backbone_base_std')
             >>> print(model(**preprocessor(('This is a test', 'This is also a test'))))
         """
 
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/arguments.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/arguments.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/blocklm_utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/blocklm_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/configure_data.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/configure_data.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/corpora.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/corpora.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,16 +18,15 @@
 from multiprocessing import Process, Queue
 from queue import Empty
 
 import json
 import tqdm
 from torch.utils import data
 
-from modelscope.models.nlp.mglm.utils import print_rank_0
-from .datasets import csv_dataset, json_dataset
+from weathon.models.nlp.backbone.mglm.utils import print_rank_0
 from .lazy_loader import LazyLoader
 
 NUM_PROCESSES = 100
 
 
 def punctuation_standardization(string: str):
     punctuation_dict = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/datasets.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/datasets.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,32 +11,29 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """dataset objects for jsons, csvs, and BERT datasets"""
 
 import csv
 import math
-import os
 import random
-import time
 from bisect import bisect_right
 from itertools import accumulate
 from operator import itemgetter
 
 import json
 import nltk
 import numpy as np
 import pandas as pd
 import torch
-import tqdm
 from nltk import tokenize
 from torch.utils import data
 
-from modelscope.models.nlp.mglm.utils import print_rank_0
-from .lazy_loader import LazyLoader, exists_lazy
+from weathon.models.nlp.backbone.mglm.utils import print_rank_0
+from .lazy_loader import LazyLoader
 
 
 class ShuffleDataset(data.Dataset):
 
     def __init__(self, ds):
         self.ds = ds
         self.shuffle_ids = list(range(len(self.ds)))
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/extraction.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/extraction.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/file_utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/file_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/lazy_loader.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/lazy_loader.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/samplers.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/samplers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/sp_tokenizer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/sp_tokenizer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/tokenization.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/tokenization.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/tokenization_gpt2.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/tokenization_gpt2.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/data_utils/wordpiece.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/data_utils/wordpiece.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/generation_utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/generation_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/mglm_for_text_summarization.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/mglm_for_text_summarization.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,24 @@
 # Copyright (c) 2022 Zhipu.AI
 
-import os
-import random
 from os import path as osp
 from typing import Dict
 
-import numpy as np
 import torch
 import torch.nn.functional as F
 from megatron_util import mpu
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Tensor, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import OutputKeys
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.megatron_utils import init_megatron_util
+from weathon.utils.constants.metainfo import Models
+from weathon.models.base import TorchModel
+from weathon.registry import MODELS
+from weathon.outputs import OutputKeys
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.megatron_utils import init_megatron_util
 from .arguments import get_args
-from .generation_utils import BeamSearchScorer
 from .train_utils import get_model
 from .utils import load_checkpoint
 
 __all__ = ['MGLMForTextSummarization']
 
 
 def setup_args(args):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/distributed.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/distributed.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/downstream.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/downstream.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/modeling_bert.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/modeling_bert.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/modeling_glm.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/modeling_glm.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 """GPT-2 model."""
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from megatron_util import mpu, print_rank_0
 
-from modelscope.models.nlp.mglm.model.prompt import PromptSpell
+from weathon.models.nlp.mglm.model.prompt import PromptSpell
 from .transformer import GPT2ParallelTransformer
 
 
 def init_method_normal(std=0.02):
     """Init method based on normal distribution.
 
     This is only used for embeddings. The transformer has its
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/prompt.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/prompt.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/model/transformer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/model/transformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/process_grid.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/process_grid.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/test/test_block.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/test/test_block.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/test/test_rel_shift.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/test/test_rel_shift.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/train_utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/train_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/mglm/utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .configuration import PalmConfig
     from .text_generation import (
         AbsSummarizer,
         PalmForTextGeneration,
         Translator,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/configuration.py`

 * *Files 8% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """ PALM model configuration """
 
 from transformers.configuration_utils import PretrainedConfig
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class PalmConfig(PretrainedConfig):
     r"""
     Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model
@@ -61,15 +61,15 @@
         dec_hidden_layers (:obj:`int`, `optional`, defaults to 12):
             Number of hidden layers in the Transformer decoder.
         attn_separate (:obj:`bool`, `optional`, defaults to false):
             Whether or not to separate the q, k, v of attention.
 
     Examples:
 
-        >>> from modelscope.models.nlp.palm_v2 import PalmForConditionalGeneration, PalmConfig
+        >>> from weathon.models.nlp.palm_v2 import PalmForConditionalGeneration, PalmConfig
         >>> configuration = PalmConfig()
 
         >>> # Initializing a model from the configuration
         >>> model = PalmForConditionalGeneration(configuration)
 
         >>> # Accessing the model configuration
         >>> configuration = model.config
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/dureader_eval.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/dureader_eval.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/palm_v2/text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/palm_v2/text_generation.py`

 * *Files 1% similar despite different names*

```diff
@@ -29,21 +29,20 @@
 from torch import Tensor, nn
 from torch.nn.init import xavier_uniform_
 from transformers import (BertConfig, BertModel, BertTokenizer, RobertaConfig,
                           RobertaModel, RobertaTokenizer)
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.metainfo import Models
-from modelscope.models import Model
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import TextGenerationModelOutput, TokenGeneratorOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchModel, BaseModel
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
+from weathon.utils.output.nlp_outputs import TextGenerationModelOutput, TokenGeneratorOutput
 from .configuration import PalmConfig
 from .dureader_eval import compute_bleu_rouge, normalize
 
 CONFIG_NAME = 'config.json'
 WEIGHTS_NAME = 'pytorch_model.bin'
 
 
@@ -552,15 +551,15 @@
     """
 
     config_class = PalmConfig
     base_model_prefix = 'palm'
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     @classmethod
     def _from_pretrained(
             cls, pretrained_model_name_or_path: Optional[Union[str,
                                                                os.PathLike]],
             **kwargs):
         config_file = os.path.join(pretrained_model_name_or_path, CONFIG_NAME)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/peer/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/peer/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .configuration import PeerConfig
     from .text_classification import PeerForSequenceClassification
 else:
     _import_structure = {
         'configuration': ['PeerConfig'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/peer/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/peer/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,17 +26,17 @@
 from transformers.modeling_outputs import \
     BaseModelOutputWithPastAndCrossAttentions
 from transformers.modeling_utils import (PreTrainedModel,
                                          apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 
-from modelscope.models import Model, TorchModel
-from modelscope.utils import logger as logging
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.base import TorchModel
+from weathon.utils import logger as logging
+from weathon.utils.nlp.utils import parse_labels_in_order
 from .configuration import PeerConfig
 from .sas_utils import SequenceSideInfo
 
 logger = logging.get_logger(__name__)
 
 PEER_PRETRAINED_MODEL_ARCHIVE_LIST = [
     'google/peer-small-generator',
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/peer/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/peer/configuration.py`

 * *Files 0% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """ PEER model configuration """
 
 # modified the path according to the structure in my directory csssl_4_15/cssl/ and its env
 from transformers.configuration_utils import PretrainedConfig
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger(__name__)
 
 
 class PeerConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration of a :class:`~transformers.PeerModel` or a
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/peer/sas_utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/peer/sas_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/peer/text_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/peer/text_classification.py`

 * *Files 17% similar despite different names*

```diff
@@ -15,32 +15,30 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import copy
 
 from torch.nn import CrossEntropyLoss, MSELoss
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTextClassificationModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
+from weathon.utils.output.nlp_outputs import AttentionTextClassificationModelOutput
 from .backbone import (PeerClassificationHead, PeerModel, PeerPreTrainedModel,
                        PeerTopModel)
 
 logger = logging.get_logger()
 
 
 @MODELS.register_module(Tasks.text_classification, module_name=Models.peer)
 @MODELS.register_module(Tasks.nli, module_name=Models.peer)
-@MODELS.register_module(
-    Tasks.sentiment_classification, module_name=Models.peer)
+@MODELS.register_module(Tasks.sentiment_classification, module_name=Models.peer)
 @MODELS.register_module(Tasks.sentence_similarity, module_name=Models.peer)
-@MODELS.register_module(
-    Tasks.zero_shot_classification, module_name=Models.peer)
+@MODELS.register_module(Tasks.zero_shot_classification, module_name=Models.peer)
 class PeerForSequenceClassification(PeerPreTrainedModel):
 
     def __init__(self, config, **kwargs):
         super().__init__(config)
         self.num_labels = config.num_labels
         self.config = config
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug/AnnealingLR.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug/AnnealingLR.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/object_detection/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .configuration import PlugNLGConfig
-    from .backbone import PlugModel
-    from .distributed_plug import DistributedPlug
+    from .mmdet_model import DetectionModel
+    from .yolox_pai import YOLOX
+    from .dino import DINO
+
 else:
     _import_structure = {
-        'configuration': ['PlugNLGConfig'],
-        'backbone': ['PlugModel'],
-        'distributed_plug': ['DistributedPlug'],
+        'mmdet_model': ['DetectionModel'],
+        'yolox_pai': ['YOLOX'],
+        'dino': ['DINO']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug/backbone.py`

 * *Files 0% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 import math
 
 import torch
 import torch.nn.functional as F
 from megatron_util import mpu
 from torch import nn
 
-from modelscope.utils.nlp.distributed import (normal_init_method,
+from weathon.utils.nlp.distributed import (normal_init_method,
                                               scaled_init_method)
 from .configuration import PlugNLGConfig, PlugNLUConfig
 
 logger = logging.getLogger(__name__)
 
 
 def gelu(x):
@@ -908,15 +908,15 @@
             Initializing with a config file does not load the weights associated with the model, only the
             configuration. Check out the [`~DistributedPlug.initialize_model`] method to load the model weights.
     Examples:
 
     >>> # The PLUG model has 27B parameters and usually need to run on multiple GPUs. The example given
     >>> # here only initializes a slice of the model on a single GPU.
     >>> # Check out the [`~DistributedPipeline.__init__`] method to initialize entire PLUG model.
-    >>> from modelscope.models.nlp.plug import PlugNLGConfig, PlugModel
+    >>> from weathon.models.nlp.plug import PlugNLGConfig, PlugModel
 
     >>> # Initializing a Plug configuration
     >>> configuration = PlugNLGConfig()
 
     >>> # Initializing a model from the configuration
     >>> model = PlugModel(configuration)
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 # limitations under the License.
 
 import copy
 
 import json
 from transformers import PretrainedConfig
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class PlugNLUConfig(PretrainedConfig):
     model_type = 'plugNLU'
 
@@ -182,15 +182,15 @@
             Whether or not to separate query-key-value to query, key, value in the Attention.
 
     Example:
 
     >>> # The PLUG model has 27B parameters and usually need to run on multiple GPUs. The example given
     >>> # here only initializes a slice of the model on a single GPU.
     >>> # Check out the [`~DistributedPipeline.__init__`] method to initialize entire PLUG model.
-    >>> from modelscope.models.nlp.plug import PlugNLGConfig, PlugModel
+    >>> from weathon.models.nlp.plug import PlugNLGConfig, PlugModel
 
     >>> # Initializing a Plug configuration
     >>> configuration = PlugNLGConfig()
 
     >>> # Initializing a model from the configuration
     >>> model = PlugModel(configuration)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug/distributed_plug.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug/distributed_plug.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Dict
 
 import torch
 from megatron_util import mpu, print_rank_0
 from megatron_util.fp16 import FP16_Module
 from torch.nn import functional as F
 
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.utils.logger import get_logger
-from modelscope.utils.megatron_utils import init_megatron_util
-from modelscope.utils.nlp.load_checkpoint import pre_load
+from weathon.base import TorchModel
+from weathon.utils.logger import get_logger
+from weathon.utils.megatron_utils import init_megatron_util
+from weathon.utils.nlp.load_checkpoint import pre_load
+from weathon.utils.typing import Tensor
 from . import PlugModel
 from .configuration import PlugNLGConfig
 
 logger = get_logger()
 
 
 class DistributedPlug(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug/generator.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug/generator.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 
 
 class TextGenerator(object):
 
     def __init__(self,
                  model,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .backbone import (PlugMentalModel, PlugMentalPreTrainedModel)
     from .configuration import PlugMentalConfig
     from .text_classification import PlugMentalForSequenceClassification
 else:
     _import_structure = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/adv_utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/adv_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import torch
 from torch import nn
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def _symmetric_kl_div(logits1, logits2, attention_mask=None):
     """
     Calclate two logits' the KL div value symmetrically.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/backbone.py`

 * *Files 2% similar despite different names*

```diff
@@ -26,21 +26,21 @@
 from packaging import version
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import (PreTrainedModel,
                                          apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
+from weathon.utils.nlp.utils import parse_labels_in_order
 from .configuration import PlugMentalConfig
 
 logger = get_logger()
 
 
 class SbertEmbeddings(nn.Module):
     """Construct the embeddings from word, position and token_type embeddings."""
@@ -733,15 +733,15 @@
     config_class = PlugMentalConfig
     base_model_prefix = 'bert'
     supports_gradient_checkpointing = True
     _keys_to_ignore_on_load_missing = [r'position_ids']
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def _init_weights(self, module):
         """Initialize the weights"""
         if isinstance(module, nn.Linear):
             # Slightly different from the TF version which uses truncated_normal for initialization
             # cf https://github.com/pytorch/pytorch/pull/5617
             module.weight.data.normal_(
@@ -946,16 +946,16 @@
                 If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up
                 decoding (see :obj:`past_key_values`).
 
         Returns:
             Returns `modelscope.outputs.AttentionBackboneModelOutputWithEmbedding`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
+            >>> from weathon.models import Model
+            >>> from weathon.preprocessors import Preprocessor
             >>> model = Model.from_pretrained('damo/nlp_plug-mental_backbone_base_std', task='backbone')
             >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_plug-mental_backbone_base_std')
             >>> print(model(**preprocessor('')))
         """
 
         output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions
         output_hidden_states = (
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/configuration.py`

 * *Files 0% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """ PLUG mental model configuration, mainly copied from :class:`~transformers.BertConfig` """
 from transformers import PretrainedConfig
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class PlugMentalConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/plug_mental/text_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/plug_mental/text_classification.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,35 +16,31 @@
 # limitations under the License.
 
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTextClassificationModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
+from weathon.utils.output.nlp_outputs import AttentionTextClassificationModelOutput
 from .adv_utils import compute_adv_loss
 from .backbone import PlugMentalModel, PlugMentalPreTrainedModel
 from .configuration import PlugMentalConfig
 
 logger = logging.get_logger()
 
 
-@MODELS.register_module(
-    Tasks.text_classification, module_name=Models.plug_mental)
+@MODELS.register_module(Tasks.text_classification, module_name=Models.plug_mental)
 @MODELS.register_module(Tasks.nli, module_name=Models.plug_mental)
-@MODELS.register_module(
-    Tasks.sentiment_classification, module_name=Models.plug_mental)
-@MODELS.register_module(
-    Tasks.sentence_similarity, module_name=Models.plug_mental)
-@MODELS.register_module(
-    Tasks.zero_shot_classification, module_name=Models.plug_mental)
+@MODELS.register_module(Tasks.sentiment_classification, module_name=Models.plug_mental)
+@MODELS.register_module(Tasks.sentence_similarity, module_name=Models.plug_mental)
+@MODELS.register_module(Tasks.zero_shot_classification, module_name=Models.plug_mental)
 class PlugMentalForSequenceClassification(PlugMentalPreTrainedModel):
     r"""PlugMental Model transformer with a sequence classification/regression head on top
     (a linear layer on top of the pooled output) e.g. for GLUE tasks.
 
     This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic
     methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
     pruning heads etc.)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/ponet/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .configuration import PoNetConfig
     from .backbone import (PoNetModel, PoNetPreTrainedModel)
     from .tokenization import PoNetTokenizer
     from .fill_mask import PoNetForMaskedLM
     from .document_segmentation import PoNetForDocumentSegmentation
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/ponet/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,20 +24,20 @@
 from torch import nn
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import (PreTrainedModel,
                                          apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 from .configuration import PoNetConfig
 
 logger = get_logger()
 
 is_pytorch_12plus = LooseVersion(torch.__version__) >= LooseVersion('1.12.0')
 
 CLS_ID = 101
@@ -603,15 +603,15 @@
 
     config_class = PoNetConfig
     base_model_prefix = 'ponet'
     _keys_to_ignore_on_load_missing = [r'position_ids']
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def _init_weights(self, module):
         """Initialize the weights"""
         if isinstance(module, nn.Linear):
             # Slightly different from the TF version which uses truncated_normal for initialization
             # cf https://github.com/pytorch/pytorch/pull/5617
             module.weight.data.normal_(
@@ -781,16 +781,16 @@
                 If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up
                 decoding (see :obj:`past_key_values`).
 
         Returns:
             Returns `modelscope.outputs.AttentionBackboneModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
+            >>> from weathon.models import Model
+            >>> from weathon.preprocessors import Preprocessor
             >>> model = Model.from_pretrained('damo/nlp_ponet_fill-mask_chinese-base', task='backbone')
             >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_ponet_fill-mask_chinese-base')
             >>> print(model(**preprocessor('')))
         """
         output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions
         output_hidden_states = (
             output_hidden_states if output_hidden_states is not None else
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/ponet/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/configuration.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """ PoNet model configuration, mainly copied from :class:`~transformers.BertConfig` """
 from transformers import PretrainedConfig
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class PoNetConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/ponet/document_segmentation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/document_segmentation.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 import torch
 from torch import nn
 from torch.nn import CrossEntropyLoss
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.bert import BertConfig
-from modelscope.outputs import AttentionTokenClassificationModelOutput
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import BaseModel
+from weathon.registry import MODELS
+from weathon.models.nlp.bert import BertConfig
+from weathon.utils.constants import Tasks
+from weathon.utils.output.nlp_outputs import AttentionTokenClassificationModelOutput
 from .backbone import PoNetModel, PoNetPreTrainedModel
 from .configuration import PoNetConfig
 
 __all__ = ['PoNetForDocumentSegmentation']
 
 
 @MODELS.register_module(
@@ -106,11 +104,11 @@
             config = BertConfig.from_pretrained(model_dir, num_labels=2)
         elif model_config['type'] == 'ponet':
             config = PoNetConfig.from_pretrained(model_dir, num_labels=2)
         else:
             raise ValueError(
                 f'Expected config type bert and ponet, which is : {model_config["type"]}'
             )
-        model = super(Model, cls).from_pretrained(model_dir, config=config)
+        model = super(BaseModel, cls).from_pretrained(model_dir, config=config)
         model.model_dir = model_dir
         model.model_cfg = model_config
         return model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/ponet/fill_mask.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/fill_mask.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,19 +15,19 @@
 # limitations under the License.
 
 import torch.utils.checkpoint
 from torch import nn
 from torch.nn import CrossEntropyLoss
 from transformers.activations import ACT2FN
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionFillMaskModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
+from weathon.utils.output.nlp_outputs import AttentionFillMaskModelOutput
 from .backbone import PoNetModel, PoNetPreTrainedModel
 
 logger = get_logger()
 
 
 class PoNetPredictionHeadTransform(nn.Module):
 
@@ -196,22 +196,22 @@
                 config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored
                 (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``
 
         Returns:
             Returns `modelscope.outputs.AttentionFillMaskModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
+            >>> from weathon.models import Model
+            >>> from weathon.preprocessors import Preprocessor
             >>> model = Model.from_pretrained('damo/nlp_ponet_fill-mask_chinese-base')
             >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_ponet_fill-mask_chinese-base')
             >>> # Call the model, return some tensors
             >>> print(model(**preprocessor('[MASK]')))
             >>> # Call the pipeline
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('fill-mask', model=model, preprocessor=preprocessor)
             >>> print(pipeline_ins('[MASK]'))
         """
 
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
 
         outputs = self.ponet(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/ponet/tokenization.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/ponet/tokenization.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,16 +17,16 @@
 
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Union
 
 from transformers.file_utils import PaddingStrategy
 from transformers.models.bert.tokenization_bert import BertTokenizer
 from transformers.tokenization_utils import BatchEncoding, EncodedInput
 
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 VOCAB_FILES_NAMES = {'vocab_file': ModelFile.VOCAB_FILE}
 
 PRETRAINED_VOCAB_FILES_MAP = {'vocab_file': {}}
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/configuration.py`

 * *Files 12% similar despite different names*

```diff
@@ -13,16 +13,16 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """Space configuration, mainly copied from :class:`~transformers.configuration_xlm_roberta` """
 
-from modelscope.models.nlp.structbert import SbertConfig
-from modelscope.utils import logger as logging
+from weathon.models.nlp.backbone.structbert import SbertConfig
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class SpaceConfig(SbertConfig):
     """
     This class overrides [`SbertConfig`]. Please check the superclass for the appropriate
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/dialog_intent_prediction.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/dialog_intent_prediction.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,50 +1,47 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Dict
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.space import SpaceGenerator, SpaceModelBase
-from modelscope.preprocessors.nlp import IntentBPETextField
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants import Tasks, ModelFile
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.nlp.space import SpaceGenerator, SpaceModelBase
+from weathon.preprocessors.nlp import IntentBPETextField
+from weathon.utils.config.config import Config
 
 __all__ = ['SpaceForDialogIntent']
 
 
-@MODELS.register_module(
-    Tasks.task_oriented_conversation, module_name=Models.space_intent)
+from weathon.utils.typing import Tensor
+
+
+@MODELS.register_module(Tasks.task_oriented_conversation, module_name=Models.space_intent)
 class SpaceForDialogIntent(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the test generation model from the `model_dir` path.
 
         Args:
             model_dir (str): the model path.
             text_field (`BPETextField`, *optional*, defaults to `IntentBPETextField`):
                 The text field.
             config (`Config`, *optional*, defaults to config in model hub):
                 The config.
         """
 
         super().__init__(model_dir, *args, **kwargs)
-        from modelscope.trainers.nlp.space.trainer.intent_trainer import \
+        from weathon.trainers.nlp.space.trainer.intent_trainer import \
             IntentTrainer
         self.model_dir = model_dir
         self.config = kwargs.pop(
             'config',
             Config.from_file(
                 os.path.join(self.model_dir, ModelFile.CONFIGURATION)))
-        self.text_field = kwargs.pop(
-            'text_field',
-            IntentBPETextField(self.model_dir, config=self.config))
+        self.text_field = kwargs.pop('text_field', IntentBPETextField(self.model_dir, config=self.config))
 
         self.generator = SpaceGenerator.create(
             self.config, reader=self.text_field)
         self.model = SpaceModelBase.create(
             model_dir=model_dir,
             config=self.config,
             reader=self.text_field,
@@ -77,17 +74,17 @@
                     {
                         'pred': array([2.62349960e-03 4.12110658e-03 4.12748595e-05 3.77560973e-05
                                 1.08599677e-04 1.72710388e-05 2.95618793e-05 1.93638436e-04
                                 6.45841064e-05 1.15997791e-04 5.11605394e-05 9.87020373e-01
                                 2.66957268e-05 4.72324500e-05 9.74208378e-05], dtype=float32),
                     }
         Example:
-            >>> from modelscope.hub.snapshot_download import snapshot_download
-            >>> from modelscope.models.nlp import SpaceForDialogIntent
-            >>> from modelscope.preprocessors import DialogIntentPredictionPreprocessor
+            >>> from weathon.utils.hub.utils import snapshot_download
+            >>> from weathon.models.nlp import SpaceForDialogIntent
+            >>> from weathon.preprocessors import DialogIntentPredictionPreprocessor
             >>> cache_path = snapshot_download('damo/nlp_space_dialog-intent-prediction')
             >>> preprocessor = DialogIntentPredictionPreprocessor(model_dir=cache_path)
             >>> model = SpaceForDialogIntent(
                     model_dir=cache_path,
                     text_field=preprocessor.text_field,
                     config=preprocessor.config)
             >>> print(model(preprocessor("What do I need to do for the card activation?")))
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/dialog_modeling.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/dialog_modeling.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Dict
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.space import SpaceGenerator, SpaceModelBase
-from modelscope.preprocessors.nlp import MultiWOZBPETextField
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.models.nlp.space import SpaceGenerator, SpaceModelBase
+from weathon.preprocessors.nlp import MultiWOZBPETextField
+from weathon.utils.config.config import Config
 
 __all__ = ['SpaceForDialogModeling']
 
+from weathon.utils.typing import Tensor
+
 
-@MODELS.register_module(
-    Tasks.task_oriented_conversation, module_name=Models.space_modeling)
+@MODELS.register_module(Tasks.task_oriented_conversation, module_name=Models.space_modeling)
 class SpaceForDialogModeling(TorchModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the test generation model from the `model_dir` path.
 
         Args:
             model_dir (`str`):
@@ -28,15 +26,15 @@
             text_field (`BPETextField`, *optional*, defaults to `MultiWOZBPETextField`):
                 The text field.
             config (`Config`, *optional*, defaults to config in model hub):
                 The config.
         """
 
         super().__init__(model_dir, *args, **kwargs)
-        from modelscope.trainers.nlp.space.trainer.gen_trainer import MultiWOZTrainer
+        from weathon.trainers.nlp.space.trainer.gen_trainer import MultiWOZTrainer
         self.model_dir = model_dir
         self.config = kwargs.pop(
             'config',
             Config.from_file(
                 os.path.join(self.model_dir, ModelFile.CONFIGURATION)))
 
         import torch
@@ -85,17 +83,17 @@
                         'resp': array([293,1023,123,1123]), #vocab label for response
                         'bspn': array([123,321,2,24,1 ]),
                         'aspn': array([47,8345,32,29,1983]),
                         'db': array([19, 24, 20]),
                     }
 
         Examples:
-            >>> from modelscope.hub.snapshot_download import snapshot_download
-            >>> from modelscope.models.nlp import SpaceForDialogModeling
-            >>> from modelscope.preprocessors import DialogModelingPreprocessor
+            >>> from weathon.utils.hub.utils import snapshot_download
+            >>> from weathon.models.nlp import SpaceForDialogModeling
+            >>> from weathon.preprocessors import DialogModelingPreprocessor
             >>> cache_path = snapshot_download('damo/nlp_space_dialog-modeling')
             >>> preprocessor = DialogModelingPreprocessor(model_dir=cache_path)
             >>> model = SpaceForDialogModeling(model_dir=cache_path,
                     text_field=preprocessor.text_field,
                     config=preprocessor.config)
             >>> print(model(preprocessor({
                     'user_input': 'i would like a taxi from saint john \'s college to pizza hut fen ditton .',
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/dialog_state_tracking.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/dialog_state_tracking.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,21 +20,20 @@
 
 import torch
 from torch import nn
 from torch.nn import CrossEntropyLoss
 from transformers.file_utils import add_start_docstrings
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.structbert import (SbertForMaskedLM, SbertModel,
-                                              SbertPreTrainedModel)
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.utils.typing import Tensor
+from weathon.registry import MODELS
+from weathon.models.nlp.backbone.structbert import (SbertModel)
+from weathon.utils.constants import Tasks
 from .configuration import SpaceConfig
 
 SPACE_START_DOCSTRING = r"""
 
     This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic
     methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
     pruning heads etc.)
@@ -74,15 +73,15 @@
     config_class = SpaceConfig
     base_model_prefix = 'bert'
     supports_gradient_checkpointing = True
     _keys_to_ignore_on_load_missing = [r'position_ids']
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def _init_weights(self, module):
         """Initialize the weights"""
         if isinstance(module, nn.Linear):
             # Slightly different from the TF version which uses truncated_normal for initialization
             # cf https://github.com/pytorch/pytorch/pull/5617
             module.weight.data.normal_(
@@ -197,17 +196,17 @@
                         'values': array([{'taxi-leaveAt': 'none', 'taxi-destination': 'none'}]),
                         'inform':  array([{'taxi-leaveAt': 'none', 'taxi-destination': 'none'}]),
                         'prefix': str('final'), #default value
                         'ds':  array([{'taxi-leaveAt': 'none', 'taxi-destination': 'none'}])
                     }
 
         Example:
-            >>> from modelscope.hub.snapshot_download import snapshot_download
-            >>> from modelscope.models.nlp import SpaceForDST
-            >>> from modelscope.preprocessors import DialogStateTrackingPreprocessor
+            >>> from weathon.utils.hub.utils import snapshot_download
+            >>> from weathon.models.nlp import SpaceForDST
+            >>> from weathon.preprocessors import DialogStateTrackingPreprocessor
             >>> cache_path = snapshot_download('damo/nlp_space_dialog-state-tracking')
             >>> model = SpaceForDST.from_pretrained(cache_path)
             >>> preprocessor = DialogStateTrackingPreprocessor(model_dir=cache_path)
             >>> print(model(preprocessor({
                     'utter': {
                         'User-1': "Hi, I'm looking for a train that is going"
                             "to cambridge and arriving there by 20:45, is there anything like that?"
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/model/gen_unified_transformer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/gen_unified_transformer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 
 from .unified_transformer import UnifiedTransformer
 
 
 class GenUnifiedTransformer(UnifiedTransformer):
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/model/generator.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/generator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 
 import numpy as np
 import torch
 
 
 def repeat(var, times):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/model/intent_unified_transformer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/intent_unified_transformer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.utils.nlp.space.criterions import compute_kl_loss
+from weathon.utils.nlp.space.criterions import compute_kl_loss
 from .unified_transformer import UnifiedTransformer
 
 
 class IntentUnifiedTransformer(UnifiedTransformer):
     """
     Implement intent unified transformer.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/model/model_base.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/model_base.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 
 import torch.nn as nn
 
-from modelscope.utils.constant import ModelFile
+from weathon.utils.constants import ModelFile
 
 
 class SpaceModelBase(nn.Module):
     """
     Basic model wrapper for static graph and dygrpah.
     """
     _registry = dict()
@@ -25,16 +23,15 @@
     @staticmethod
     def create(model_dir, config, *args, **kwargs):
         model_cls = SpaceModelBase.by_name(config.Model.model)
         return model_cls(model_dir, config, *args, **kwargs)
 
     def __init__(self, model_dir, config):
         super(SpaceModelBase, self).__init__()
-        self.init_checkpoint = os.path.join(model_dir,
-                                            ModelFile.TORCH_MODEL_BIN_FILE)
+        self.init_checkpoint = os.path.join(model_dir,ModelFile.TORCH_MODEL_BIN_FILE)
         self.abandon_label = config.Dataset.abandon_label
         self.use_gpu = config.use_gpu
         self.gpu = config.Trainer.gpu
         return
 
     def _create_parameters(self):
         """ Create model's parameters. """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/model/tokenization_space.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/tokenization_space.py`

 * *Files 9% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License
 """Tokenization classes for Space. mainly copied from :module:`~transformers.tokenization_xlm_roberta`"""
 
 from transformers import BasicTokenizer, BertTokenizer, WordpieceTokenizer
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class SpaceTokenizer(BertTokenizer):
     """
     This class overrides [`SpaceTokenizer`]. Please check the superclass for the appropriate
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/model/unified_transformer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/model/unified_transformer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from modelscope.models.nlp.space.model.model_base import SpaceModelBase
-from modelscope.models.nlp.space.modules.embedder import Embedder
-from modelscope.models.nlp.space.modules.transformer_block import \
-    TransformerBlock
+from weathon.models.nlp.space.model.model_base import SpaceModelBase
+from weathon.models.nlp.space.modules.embedder import Embedder
+from weathon.models.nlp.space.modules.transformer_block import TransformerBlock
 
 
 class UnifiedTransformer(SpaceModelBase):
     """
     Implement unified transformer.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/embedder.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/embedder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
 
 class Embedder(nn.Module):
     """
     Composite embedding layer.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/feedforward.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/feedforward.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
 
 class FeedForward(nn.Module):
     """
     Positional feed forward layer.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/functions.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/functions.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 import torch
 import torch.nn.functional as F
 
 
 def unsqueeze(input, dims):
     """ Implement multi-dimension unsqueeze function. """
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/multihead_attention.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/multihead_attention.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
 
 class MultiheadAttention(nn.Module):
     """
     Multi head attention layer.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space/modules/transformer_block.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space/modules/transformer_block.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
 from .feedforward import FeedForward
 from .multihead_attention import MultiheadAttention
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/__init__.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,19 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .table_question_answering import TableQuestionAnswering
+    from .kws_farfield_dataset import KWSDataset, KWSDataLoader
+    from .kws_nearfield_dataset import kws_nearfield_dataset
+    from .asr_dataset import ASRDataset
+
 else:
     _import_structure = {
-        'table_question_answering': ['TableQuestionAnswering']
+        'kws_farfield_dataset': ['KWSDataset', 'KWSDataLoader'],
+        'kws_nearfield_dataset': ['kws_nearfield_dataset'],
+        'asr_dataset': ['ASRDataset'],
     }
-
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
         module_spec=__spec__,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_cn/backbone.py`

 * *Files 0% similar despite different names*

```diff
@@ -23,17 +23,17 @@
 import tarfile
 import tempfile
 
 import numpy as np
 import torch
 from torch import nn
 
-from modelscope.models.nlp.space_T_cn.configuration import SpaceTCnConfig
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.models.nlp.space_T_cn.configuration import SpaceTCnConfig
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 CONFIG_NAME = ModelFile.CONFIGURATION
 WEIGHTS_NAME = ModelFile.TORCH_MODEL_BIN_FILE
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_cn/configuration.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space_T_cn/table_question_answering.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_cn/table_question_answering.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,30 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Dict
 
 import numpy
 import torch
 import torch.nn.functional as F
 from transformers import BertTokenizer
 
-from modelscope.metainfo import Models
-from modelscope.models.base import Model, Tensor
-from modelscope.models.builder import MODELS
-from modelscope.preprocessors.nlp.space_T_cn.fields.struct import Constant
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import BaseModel
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.preprocessors.nlp.space_T_cn.fields.struct import Constant
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.typing import Tensor
 from .backbone import Seq2SQL, SpaceTCnModel
 from .configuration import SpaceTCnConfig
 
 __all__ = ['TableQuestionAnswering']
 
 
 @MODELS.register_module(
     Tasks.table_question_answering, module_name=Models.space_T_cn)
-class TableQuestionAnswering(Model):
+class TableQuestionAnswering(BaseModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the table-question-answering model from the `model_dir` path.
 
         Args:
             model_dir (str): the model path.
         """
@@ -764,16 +763,16 @@
                 >>>                 [0, 0, 0, 0, 0, 0]
                 >>>             ]
                 >>>         },
                 >>>     'history_sql': None
                 >>> }
 
         Example:
-            >>> from modelscope.models.nlp import TableQuestionAnswering
-            >>> from modelscope.preprocessors import TableQuestionAnsweringPreprocessor
+            >>> from weathon.models.nlp import TableQuestionAnswering
+            >>> from weathon.preprocessors import TableQuestionAnsweringPreprocessor
             >>> model = TableQuestionAnswering.from_pretrained('damo/nlp_convai_text2sql_pretrain_cn')
             >>> preprocessor = TableQuestionAnsweringPreprocessor(model_dir=model.model_dir)
             >>> print(model(preprocessor({'question': ''})))
         """
         result = self.predict(input['datas'])[0]
 
         return {
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/space_T_en/text_to_sql.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/space_T_en/text_to_sql.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Dict, Optional
 
 import torch
 from text2sql_lgesql.asdl.asdl import ASDLGrammar
 from text2sql_lgesql.asdl.transition_system import TransitionSystem
 from text2sql_lgesql.model.model_constructor import Text2SQL
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.utils.typing import Tensor
+from weathon.registry import MODELS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['StarForTextToSql']
 
 
 @MODELS.register_module(
     Tasks.table_question_answering, module_name=Models.space_T_en)
 class StarForTextToSql(TorchModel):
@@ -56,17 +54,17 @@
             input (Dict[str, Tensor]): the preprocessed data
 
         Returns:
             Dict[str, Tensor]: results
                 Example:
 
         Example:
-            >>> from modelscope.hub.snapshot_download import snapshot_download
-            >>> from modelscope.models.nlp import StarForTextToSql
-            >>> from modelscope.preprocessors import ConversationalTextToSqlPreprocessor
+            >>> from weathon.utils.hub.utils import snapshot_download
+            >>> from weathon.models.nlp import StarForTextToSql
+            >>> from weathon.preprocessors import ConversationalTextToSqlPreprocessor
             >>> test_case = {
                     'database_id': 'employee_hire_evaluation',
                     'local_db_path': None,
                     'utterance': [
                         "I'd like to see Shop names.", 'Which of these are hiring?',
                         'Which shop is hiring the highest number of employees?'
                         ' | do you want the name of the shop ? | Yes'
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/structbert/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .backbone import (SbertModel, SbertPreTrainedModel)
     from .configuration import SbertConfig
     from .faq_question_answering import SbertForFaqQuestionAnswering
     from .fill_mask import SbertForMaskedLM
     from .text_classification import SbertForSequenceClassification
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/structbert/adv_utils.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/adv_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import torch
 from torch import nn
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def _symmetric_kl_div(logits1, logits2, attention_mask=None):
     """
     Calclate two logits' the KL div value symmetrically.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/structbert/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/backbone.py`

 * *Files 4% similar despite different names*

```diff
@@ -26,21 +26,21 @@
 from packaging import version
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import (PreTrainedModel,
                                          apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel, BaseModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
+from weathon.utils.nlp.utils import parse_labels_in_order
 from .configuration import SbertConfig
 
 logger = get_logger()
 
 
 class SbertEmbeddings(nn.Module):
     """Construct the embeddings from word, position and token_type embeddings."""
@@ -136,31 +136,26 @@
         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(
                 config, 'embedding_size'):
             raise ValueError(
                 f'The hidden size ({config.hidden_size}) is not a multiple of the number of attention '
                 f'heads ({config.num_attention_heads})')
 
         self.num_attention_heads = config.num_attention_heads
-        self.attention_head_size = int(config.hidden_size
-                                       / config.num_attention_heads)
+        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)
         self.all_head_size = self.num_attention_heads * self.attention_head_size
 
         self.query = nn.Linear(config.hidden_size, self.all_head_size)
         self.key = nn.Linear(config.hidden_size, self.all_head_size)
         self.value = nn.Linear(config.hidden_size, self.all_head_size)
 
         self.dropout = nn.Dropout(config.attention_probs_dropout_prob)
-        self.position_embedding_type = getattr(config,
-                                               'position_embedding_type',
-                                               'absolute')
+        self.position_embedding_type = getattr(config, 'position_embedding_type', 'absolute')
         if self.position_embedding_type == 'relative_key' or self.position_embedding_type == 'relative_key_query':
             self.max_position_embeddings = config.max_position_embeddings
-            self.distance_embedding = nn.Embedding(
-                2 * config.max_position_embeddings - 1,
-                self.attention_head_size)
+            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)
 
         self.is_decoder = config.is_decoder
 
     def transpose_for_scores(self, x):
         new_x_shape = x.size()[:-1] + (self.num_attention_heads,
                                        self.attention_head_size)
         x = x.view(*new_x_shape)
@@ -277,16 +272,15 @@
 
 
 class SbertSelfOutput(nn.Module):
 
     def __init__(self, config):
         super().__init__()
         self.dense = nn.Linear(config.hidden_size, config.hidden_size)
-        self.LayerNorm = nn.LayerNorm(
-            config.hidden_size, eps=config.layer_norm_eps)
+        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)
         self.dropout = nn.Dropout(config.hidden_dropout_prob)
 
     def forward(self, hidden_states, input_tensor):
         hidden_states = self.dense(hidden_states)
         hidden_states = self.dropout(hidden_states)
         hidden_states = self.LayerNorm(hidden_states + input_tensor)
         return hidden_states
@@ -470,16 +464,15 @@
 
 
 class SbertEncoder(nn.Module):
 
     def __init__(self, config):
         super().__init__()
         self.config = config
-        self.layer = nn.ModuleList(
-            [SbertLayer(config) for _ in range(config.num_hidden_layers)])
+        self.layer = nn.ModuleList([SbertLayer(config) for _ in range(config.num_hidden_layers)])
         self.gradient_checkpointing = False
 
     def forward(
         self,
         hidden_states,
         attention_mask=None,
         head_mask=None,
@@ -595,15 +588,15 @@
     config_class = SbertConfig
     base_model_prefix = 'bert'
     supports_gradient_checkpointing = True
     _keys_to_ignore_on_load_missing = [r'position_ids']
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def _init_weights(self, module):
         """Initialize the weights"""
         if isinstance(module, nn.Linear):
             # Slightly different from the TF version which uses truncated_normal for initialization
             # cf https://github.com/pytorch/pytorch/pull/5617
             module.weight.data.normal_(
@@ -642,16 +635,15 @@
         cfg = kwargs.pop('cfg', None)
         model_args = parse_labels_in_order(model_dir, cfg, **kwargs)
 
         if model_dir is None:
             config = SbertConfig(**model_args)
             model = cls(config)
         else:
-            model = super(Model, cls).from_pretrained(
-                pretrained_model_name_or_path=model_dir, **model_args)
+            model = super(BaseModel, cls).from_pretrained(pretrained_model_name_or_path=model_dir, **model_args)
         return model
 
 
 @dataclass
 class AttentionBackboneModelOutputWithEmbedding(AttentionBackboneModelOutput):
     embedding_output: torch.FloatTensor = None
     logits: Optional[Union[tuple, torch.FloatTensor]] = None
@@ -796,18 +788,17 @@
                 If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up
                 decoding (see :obj:`past_key_values`).
 
         Returns:
             Returns `modelscope.outputs.AttentionBackboneModelOutputWithEmbedding`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_structbert_backbone_base_std', task='backbone')
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_structbert_backbone_base_std')
+            >>> from weathon.base import BaseModel,BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_structbert_backbone_base_std', task='backbone')
+            >>> preprocessor = BasePreprocessor.from_pretrained('damo/nlp_structbert_backbone_base_std')
             >>> print(model(**preprocessor('')))
         """
 
         output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions
         output_hidden_states = (
             output_hidden_states if output_hidden_states is not None else
             self.config.output_hidden_states)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/structbert/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/configuration.py`

 * *Files 3% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """ StructBERT model configuration, mainly copied from :class:`~transformers.BertConfig` """
 from transformers import PretrainedConfig
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class SbertConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration
@@ -121,14 +121,12 @@
         self.layer_norm_eps = layer_norm_eps
         self.position_embedding_type = position_embedding_type
         self.use_cache = use_cache
         self.classifier_dropout = classifier_dropout
         # adv_grad_factor, used in adv loss.
         # Users can check adv_utils.py for details.
         # if adv_grad_factor set to None, no adv loss will not applied to the model.
-        self.adv_grad_factor = 5e-5 if 'adv_grad_factor' not in kwargs else kwargs[
-            'adv_grad_factor']
+        self.adv_grad_factor = kwargs.get('adv_grad_factor', 5e-5)  
         # sigma value, used in adv loss.
-        self.sigma = 5e-6 if 'sigma' not in kwargs else kwargs['sigma']
+        self.sigma = kwargs.get('sigma', 5e-6) 
         # adv_bound value, used in adv loss.
-        self.adv_bound = 2 * self.sigma if 'adv_bound' not in kwargs else kwargs[
-            'adv_bound']
+        self.adv_bound = kwargs.get('adv_bound', 2 * self.sigma)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/structbert/faq_question_answering.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/faq_question_answering.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 import os
 from collections import namedtuple
 from typing import Dict
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torch import Tensor
 from torch.nn import BCEWithLogitsLoss
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.structbert import SbertConfig, SbertModel
-from modelscope.models.nlp.task_models.task_model import BaseTaskModel
-from modelscope.outputs import FaqQuestionAnsweringOutput
-from modelscope.utils.config import Config, ConfigFields
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.models.nlp.backbone.structbert import SbertConfig, SbertModel
+from weathon.models.nlp.task_models.task_model import BaseTaskModel
+from weathon.utils.constants import ModelFile, Tasks, ConfigFields
+from weathon.utils.logger import get_logger
+from weathon.utils.output.nlp_outputs import FaqQuestionAnsweringOutput
 
 logger = get_logger()
 
 activations = {
     'relu': F.relu,
     'tanh': torch.tanh,
     'linear': lambda x: x,
@@ -181,16 +179,15 @@
         proj_hidden_size=hidden_size,
         hidden_size=hidden_size,
         dropout=0.0,
         pooling=pooling_method)
     return args
 
 
-@MODELS.register_module(
-    Tasks.faq_question_answering, module_name=Models.structbert)
+@MODELS.register_module(Tasks.faq_question_answering, module_name=Models.structbert)
 class SbertForFaqQuestionAnswering(BaseTaskModel):
     _backbone_prefix = ''
     PROTO_NET = 'protonet'
     MGIMN_NET = 'mgimnnet'
 
     @classmethod
     def _instantiate(cls, **kwargs):
@@ -232,17 +229,17 @@
         Returns:
             Dict[str, Tensor]: result, it contains the following key:
 
                 - scores(:obj:`torch.FloatTensor` of shape :obj:`(batch_size, num_cls)`):
                     Predicted scores of all classes for each query.
 
         Examples:
-            >>> from modelscope.hub.snapshot_download import snapshot_download
-            >>> from modelscope.preprocessors import FaqQuestionAnsweringTransformersPreprocessor
-            >>> from modelscope.models.nlp import SbertForFaqQuestionAnswering
+            >>> from weathon.utils.hub.utils import snapshot_download
+            >>> from weathon.preprocessors import FaqQuestionAnsweringTransformersPreprocessor
+            >>> from weathon.models.nlp import SbertForFaqQuestionAnswering
             >>> cache_path = snapshot_download('damo/nlp_structbert_faq-question-answering_chinese-base')
             >>> preprocessor = FaqQuestionAnsweringTransformersPreprocessor.from_pretrained(cache_path)
             >>> model = SbertForFaqQuestionAnswering.from_pretrained(cache_path)
             >>> param = {
             >>>            'query_set': ['', '', ''],
             >>>            'support_set': [{
             >>>                    'text': '',
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/structbert/fill_mask.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/fill_mask.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,19 +17,19 @@
 
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 from torch.nn import CrossEntropyLoss
 from transformers.activations import ACT2FN
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionFillMaskModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
+from weathon.utils.output.nlp_outputs import AttentionFillMaskModelOutput
 from .backbone import SbertModel, SbertPreTrainedModel
 from .configuration import SbertConfig
 
 logger = logging.get_logger()
 
 
 class SbertPredictionHeadTransform(nn.Module):
@@ -210,22 +210,22 @@
                 config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored
                 (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``
 
         Returns:
             Returns `modelscope.outputs.AttentionFillMaskModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor, FillMaskTransformersPreprocessor
-            >>> model = Model.from_pretrained('damo/nlp_structbert_fill-mask_chinese-large')
+            >>> from weathon.base import BaseModel
+            >>> from weathon.preprocessors import  FillMaskTransformersPreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_structbert_fill-mask_chinese-large')
             >>> preprocessor = FillMaskTransformersPreprocessor('damo/nlp_structbert_fill-mask_chinese-large')
             >>> # Call the model, return some tensors
             >>> print(model(**preprocessor('[MASK]')))
             >>> # Call the pipeline
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('fill-mask', model=model, preprocessor=preprocessor)
             >>> print(pipeline_ins('[MASK]'))
         """
 
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
 
         outputs = self.bert(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/structbert/text_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/text_classification.py`

 * *Files 7% similar despite different names*

```diff
@@ -16,35 +16,30 @@
 # limitations under the License.
 
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTextClassificationModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionTextClassificationModelOutput
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
 from .adv_utils import compute_adv_loss
 from .backbone import SbertModel, SbertPreTrainedModel
 from .configuration import SbertConfig
 
 logger = logging.get_logger()
 
-
-@MODELS.register_module(
-    Tasks.text_classification, module_name=Models.structbert)
+@MODELS.register_module(Tasks.text_classification, module_name=Models.structbert)
 @MODELS.register_module(Tasks.nli, module_name=Models.structbert)
-@MODELS.register_module(
-    Tasks.sentiment_classification, module_name=Models.structbert)
-@MODELS.register_module(
-    Tasks.sentence_similarity, module_name=Models.structbert)
-@MODELS.register_module(
-    Tasks.zero_shot_classification, module_name=Models.structbert)
+@MODELS.register_module(Tasks.sentiment_classification, module_name=Models.structbert)
+@MODELS.register_module(Tasks.sentence_similarity, module_name=Models.structbert)
+@MODELS.register_module(Tasks.zero_shot_classification, module_name=Models.structbert)
 class SbertForSequenceClassification(SbertPreTrainedModel):
     r"""StructBERT Model transformer with a sequence classification/regression head on top
     (a linear layer on top of the pooled output) e.g. for GLUE tasks.
 
     This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic
     methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,
     pruning heads etc.)
@@ -71,24 +66,19 @@
     """
 
     def __init__(self, config: SbertConfig, **kwargs):
         super().__init__(config)
         self.num_labels = config.num_labels
         self.config = config
         if self.config.adv_grad_factor is None:
-            logger.warning(
-                'Adv parameters not set, skipping compute_adv_loss.')
+            logger.warning('Adv parameters not set, skipping compute_adv_loss.')
 
-        SbertForSequenceClassification.base_model_prefix = getattr(
-            config, 'base_model_prefix',
-            SbertForSequenceClassification.base_model_prefix)
+        SbertForSequenceClassification.base_model_prefix = getattr(config, 'base_model_prefix',SbertForSequenceClassification.base_model_prefix)
         setattr(self, self.base_model_prefix, SbertModel(config))
-        classifier_dropout = (
-            config.classifier_dropout if config.classifier_dropout is not None
-            else config.hidden_dropout_prob)
+        classifier_dropout = (config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob)
         self.dropout = nn.Dropout(classifier_dropout)
         self.classifier = nn.Linear(config.hidden_size, config.num_labels)
         self.init_weights()
 
     def _forward_call(self, **kwargs):
         outputs = self.base_model(**kwargs)
         pooled_output = outputs[1]
@@ -162,77 +152,67 @@
                 config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed
                 (Mean-Square loss), If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).
 
         Returns:
             Returns `modelscope.outputs.AttentionTextClassificationModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
+            >>> from weathon.base import BaseModel, BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
+            >>> preprocessor =BasePreprocessor.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
             >>> # Call the model, return some tensors
             >>> print(model(**preprocessor(('', ''))))
             >>> # Call the pipeline
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('text-classification', model=model, preprocessor=preprocessor)
             >>> print(pipeline_ins(('', '')))
         """
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
         if not return_dict:
             logger.error('Return tuple in sbert is not supported now.')
-        outputs = self._forward_call(
-            input_ids=input_ids,
-            attention_mask=attention_mask,
-            token_type_ids=token_type_ids,
-            position_ids=position_ids,
-            head_mask=head_mask,
-            inputs_embeds=inputs_embeds,
-            output_attentions=output_attentions,
-            output_hidden_states=output_hidden_states,
-            return_dict=return_dict)
+        outputs = self._forward_call(input_ids=input_ids,
+                                     attention_mask=attention_mask,
+                                     token_type_ids=token_type_ids,
+                                     position_ids=position_ids,
+                                     head_mask=head_mask,
+                                     inputs_embeds=inputs_embeds,
+                                     output_attentions=output_attentions,
+                                     output_hidden_states=output_hidden_states,
+                                     return_dict=return_dict)
         return self.compute_loss(outputs, labels, **outputs.kwargs)
 
     def compute_loss(self, outputs, labels, **kwargs):
         logits = outputs.logits
         embedding_output = outputs.embedding_output
         loss = None
         if labels is not None:
             if self.config.problem_type is None:
                 if self.num_labels == 1:
                     self.config.problem_type = 'regression'
-                elif self.num_labels > 1 and (labels.dtype == torch.long
-                                              or labels.dtype == torch.int):
+                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):
                     self.config.problem_type = 'single_label_classification'
                 else:
                     self.config.problem_type = 'multi_label_classification'
 
             if self.config.problem_type == 'regression':
                 loss_fct = MSELoss()
                 if self.num_labels == 1:
                     loss = loss_fct(logits.squeeze(), labels.squeeze())
                 else:
                     loss = loss_fct(logits, labels)
             elif self.config.problem_type == 'single_label_classification':
                 loss_fct = CrossEntropyLoss()
-                loss = loss_fct(
-                    logits.view(-1, self.num_labels), labels.view(-1))
+                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))
                 if self.config.adv_grad_factor is not None and self.training:
-                    loss = compute_adv_loss(
-                        embedding=embedding_output,
-                        model=self._forward_call,
-                        ori_logits=logits,
-                        ori_loss=loss,
-                        adv_bound=self.config.adv_bound,
-                        adv_grad_factor=self.config.adv_grad_factor,
-                        sigma=self.config.sigma,
-                        **kwargs)
+                    loss = compute_adv_loss(embedding=embedding_output,
+                                            model=self._forward_call,
+                                            ori_logits=logits,
+                                            ori_loss=loss,
+                                            adv_bound=self.config.adv_bound,
+                                            adv_grad_factor=self.config.adv_grad_factor,
+                                            sigma=self.config.sigma,
+                                            **kwargs)
             elif self.config.problem_type == 'multi_label_classification':
                 loss_fct = BCEWithLogitsLoss()
                 loss = loss_fct(logits, labels)
 
-        return AttentionTextClassificationModelOutput(
-            loss=loss,
-            logits=logits,
-            hidden_states=outputs.hidden_states,
-            attentions=outputs.attentions,
-        )
+        return AttentionTextClassificationModelOutput(loss=loss,logits=logits,hidden_states=outputs.hidden_states,attentions=outputs.attentions,)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/structbert/token_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/structbert/token_classification.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,19 +16,19 @@
 # limitations under the License.
 
 import torch
 import torch.nn as nn
 import torch.utils.checkpoint
 from torch.nn import CrossEntropyLoss
 
-from modelscope.metainfo import Models
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTokenClassificationModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
+from weathon.utils.output.nlp_outputs import AttentionTokenClassificationModelOutput
 from .adv_utils import compute_adv_loss
 from .backbone import SbertModel, SbertPreTrainedModel
 from .configuration import SbertConfig
 
 logger = logging.get_logger()
 
 
@@ -167,18 +167,17 @@
                 - 1 for tokens that are **not masked**,
                 - 0 for tokens that are **masked**.
 
         Returns:
             Returns `modelscope.outputs.AttentionTokenClassificationModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_structbert_word-segmentation_chinese-base')
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_structbert_word-segmentation_chinese-base')
+            >>> from weathon.base import BaseModel,BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_structbert_word-segmentation_chinese-base')
+            >>> preprocessor = BasePreprocessor.from_pretrained('damo/nlp_structbert_word-segmentation_chinese-base')
             >>> print(model(**preprocessor(('This is a test', 'This is also a test'))))
         """
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
         if not return_dict:
             logger.error('Return tuple in sbert is not supported now.')
 
         outputs = self._forward_call(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .information_extraction import ModelForInformationExtraction
     from .feature_extraction import ModelForFeatureExtraction
     from .fill_mask import ModelForFillMask
     from .text_classification import ModelForTextClassification
     from .task_model import SingleBackboneTaskModelBase
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/feature_extraction.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/feature_extraction.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import numpy as np
 
-from modelscope.metainfo import TaskModels
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.task_models.task_model import EncoderModel
-from modelscope.outputs import FeatureExtractionOutput, OutputKeys
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import TaskModels
+from weathon.registry import MODELS
+from weathon.models.nlp.task_models.task_model import EncoderModel
+from weathon.utils.constants import Tasks
 
 __all__ = ['ModelForFeatureExtraction']
 
 
 @MODELS.register_module(
     Tasks.feature_extraction, module_name=TaskModels.feature_extraction)
 class ModelForFeatureExtraction(EncoderModel):
@@ -81,18 +79,17 @@
             config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),
             If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).
 
         Returns:
             Returns `modelscope.outputs.AttentionTextClassificationModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
+            >>> from weathon.base import BaseModel,BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
+            >>> preprocessor = BasePreprocessor.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
             >>> print(model(**preprocessor(('This is a test', 'This is also a test'))))
         """
 
         # backbone do not need labels, only head need for loss compute
         feature = self.extract_feature(
             input_ids=input_ids,
             attention_mask=attention_mask,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/fill_mask.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/fill_mask.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Heads, TaskModels
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.task_models.task_model import EncoderModel
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Heads, TaskModels
+from weathon.registry import MODELS
+from weathon.models.nlp.task_models.task_model import EncoderModel
+from weathon.utils.constants import Tasks
 
 __all__ = ['ModelForFillMask']
 
 
 @MODELS.register_module(Tasks.fill_mask, module_name=TaskModels.fill_mask)
 class ModelForFillMask(EncoderModel):
     task = Tasks.fill_mask
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/information_extraction.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/information_extraction.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import numpy as np
 
-from modelscope.metainfo import Heads, TaskModels
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.task_models.task_model import EncoderModel
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Heads, TaskModels
+from weathon.registry import MODELS
+from weathon.models.nlp.task_models.task_model import EncoderModel
+from weathon.utils.constants import Tasks
 
 __all__ = ['ModelForInformationExtraction']
 
 
 @MODELS.register_module(
     Tasks.information_extraction,
     module_name=TaskModels.information_extraction)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/task_model.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/task_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path
 import re
 from abc import ABC
 from collections import OrderedDict
 from typing import Any, Dict, Optional
 
 import torch
 from torch import nn
 
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import build_backbone, build_head
-from modelscope.outputs import OutputKeys
-from modelscope.utils.checkpoint import load_task_model_checkpoint
-from modelscope.utils.config import Config, ConfigDict
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, ModelFile
-from modelscope.utils.file_utils import func_receive_dict_inputs
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchModel
+from weathon.registry import build_backbone, build_head
+from weathon.utils.checkpoint import load_task_model_checkpoint
+from weathon.utils.config.config import Config, ConfigDict
+from weathon.utils.constants import ModelFile, DEFAULT_MODEL_REVISION
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.fileio.file_utils import func_receive_dict_inputs
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['EncoderModel', 'SingleBackboneTaskModelBase']
 
 
 def _repr(modules, depth=1):
@@ -497,16 +496,15 @@
 
     def __repr__(self):
         # only log backbone and head name
         depth = 1
         return _repr(self, depth)
 
     def _get_transformer_config(self):
-        transformer_config_file = os.path.join(self.model_dir,
-                                               ModelFile.CONFIG)
+        transformer_config_file = os.path.join(self.model_dir,ModelFile.CONFIG)
         transformer_config = None
         if os.path.exists(transformer_config_file):
             transformer_config = Config.from_file(transformer_config_file)
         return transformer_config.copy()
 
     def _use_transformer_config(self, cfg):
         if 'model_type' not in cfg and 'type' not in cfg:
@@ -544,21 +542,20 @@
                 head_cfg = self._get_transformer_config()
                 head_cfg.type = self.head_type
         if 'type' not in head_cfg:
             head_cfg.type = self.head_type
         return head_cfg
 
     def build_encoder(self, cfg):
-        backbone = build_backbone(cfg)
+        backbone = build_backbone(cfg,default_args=dict())
         if 'prefix' in cfg:
             self.base_model_prefix = cfg['prefix']
         elif 'base_model_prefix' in cfg:
             self.base_model_prefix = cfg['base_model_prefix']
-        elif hasattr(backbone, 'base_model_prefix') \
-                and not self.override_base_model_prefix:
+        elif hasattr(backbone, 'base_model_prefix') and not self.override_base_model_prefix:
             self.base_model_prefix = backbone.base_model_prefix
         setattr(self, self.base_model_prefix, backbone)
 
     def build_head(self, cfg):
         if cfg is None:
             raise ValueError(
                 'Head config is missing, check if this was a backbone-only model'
@@ -652,18 +649,17 @@
         **kwargs:
             Accept additional kwargs in the children class
 
         Returns:
             Returns `modelscope.outputs.ModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
+            >>> from weathon.base import BaseModel,BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
+            >>> preprocessor = BasePreprocessor.from_pretrained('damo/nlp_structbert_sentence-similarity_chinese-base')
             >>> print(model(**preprocessor(('This is a test', 'This is also a test'))))
         """
 
         if OutputKeys.LABEL in kwargs and labels is None:
             labels = kwargs.pop(OutputKeys.LABEL, None)
         feature = self.extract_feature(
             input_ids=input_ids,
@@ -680,16 +676,15 @@
         outputs = self.head.forward(feature, attention_mask, labels, **kwargs)
         return outputs
 
     @classmethod
     def _instantiate(cls, **kwargs):
         model_dir = kwargs.get('model_dir')
         model = cls(**kwargs)
-        model_load_handler = load_task_model_checkpoint(
-            model_to_load=model, model_local_dir=model_dir, **kwargs)
+        model_load_handler = load_task_model_checkpoint(model_to_load=model, model_local_dir=model_dir, **kwargs)
         return model_load_handler['model']
 
     @classmethod
     def from_pretrained(cls,
                         model_name_or_path: str,
                         revision: Optional[str] = DEFAULT_MODEL_REVISION,
                         cfg_dict: Config = None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/text_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/text_classification.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,23 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict
-
-import numpy as np
-
-from modelscope.metainfo import Heads, TaskModels
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.task_models.task_model import EncoderModel
-from modelscope.utils.constant import Tasks
-from modelscope.utils.hub import parse_label_mapping
+from weathon.utils.constants.metainfo import Heads, TaskModels
+from weathon.registry import MODELS
+from weathon.models.nlp.task_models.task_model import EncoderModel
+from weathon.utils.constants import Tasks, Datasets
 
 __all__ = ['ModelForTextClassification']
 
+from weathon.utils.hub.utils import parse_label_mapping
+
 
-@MODELS.register_module(
-    Tasks.text_classification, module_name=TaskModels.text_classification)
+@MODELS.register_module(Tasks.text_classification, module_name=Datasets.jd_sentiment_text_classification)
+@MODELS.register_module(Tasks.text_classification, module_name=TaskModels.text_classification)
 class ModelForTextClassification(EncoderModel):
     task = Tasks.text_classification
 
     # The default base head type is text-classification for this head
     head_type = Heads.text_classification
 
     def __init__(self, model_dir: str, *args, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/text_generation.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/text_generation.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,24 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict
+from typing import Dict
 
 import numpy as np
 import torch
 from transformers.modeling_utils import PreTrainedModel
 
-from modelscope.metainfo import TaskModels
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.task_models.task_model import \
+from weathon.utils.constants.metainfo import TaskModels
+from weathon.registry import MODELS
+from weathon.models.nlp.task_models.task_model import \
     SingleBackboneTaskModelBase
-from modelscope.outputs import (OutputKeys, TextGenerationModelOutput,
-                                TokenGeneratorOutput)
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants import Tasks
 
 __all__ = ['ModelForTextGeneration']
 
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.output.nlp_outputs import TextGenerationModelOutput, TokenGeneratorOutput
+
 
 @MODELS.register_module(
     Tasks.text_generation, module_name=TaskModels.text_generation)
 class ModelForTextGeneration(SingleBackboneTaskModelBase, PreTrainedModel):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """initialize the text generation model from the `model_dir` path.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/text_ranking.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/text_ranking.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import numpy as np
 
-from modelscope.metainfo import Heads, TaskModels
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.task_models.task_model import EncoderModel
-from modelscope.utils.constant import Tasks
-from modelscope.utils.hub import parse_label_mapping
+from weathon.utils.constants.metainfo import Heads, TaskModels
+from weathon.registry import MODELS
+from weathon.models.nlp.task_models.task_model import EncoderModel
+from weathon.utils.constants import Tasks
 
 __all__ = ['ModelForTextRanking']
 
+from weathon.utils.hub.utils import parse_label_mapping
+
 
 @MODELS.register_module(
     Tasks.text_ranking, module_name=TaskModels.text_ranking)
 class ModelForTextRanking(EncoderModel):
     task = Tasks.text_ranking
 
     # The default base head type is text-ranking for this head
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/task_models/token_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/task_models/token_classification.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Heads, Models, TaskModels
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.task_models.task_model import EncoderModel
-from modelscope.outputs import (AttentionTokenClassificationModelOutput,
-                                OutputKeys)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.hub import parse_label_mapping
+from weathon.utils.constants.metainfo import Heads, Models, TaskModels
+from weathon.registry import MODELS
+from weathon.models.nlp.task_models.task_model import EncoderModel
+from weathon.utils.constants import Tasks
 
 __all__ = ['ModelForTokenClassification', 'ModelForTokenClassificationWithCRF']
 
+from weathon.utils.hub.utils import parse_label_mapping
+from weathon.utils.output.nlp_outputs import AttentionTokenClassificationModelOutput
+
 
 @MODELS.register_module(
     Tasks.token_classification, module_name=TaskModels.token_classification)
 @MODELS.register_module(
     Tasks.part_of_speech, module_name=TaskModels.token_classification)
 @MODELS.register_module(
     Tasks.named_entity_recognition,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/unite/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/unite/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,12 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .configuration import UniTEConfig
     from .translation_evaluation import UniTEForTranslationEvaluation
 else:
     _import_structure = {
         'configuration': ['UniTEConfig'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/unite/translation_evaluation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/unite/translation_evaluation.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,33 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """PyTorch UniTE model."""
 
-import warnings
-from dataclasses import dataclass
 from math import ceil
-from typing import Dict, List, Optional, Tuple, Union
+from typing import List, Optional
 
-import numpy as np
 import torch
 import torch.utils.checkpoint
-from packaging import version
-from torch.nn import (Dropout, Linear, Module, Parameter, ParameterList,
-                      Sequential)
+from torch.nn import (Dropout, Linear, Module, Parameter, Sequential)
 from torch.nn.functional import softmax
 from torch.nn.utils.rnn import pad_sequence
 from transformers import XLMRobertaConfig, XLMRobertaModel
 from transformers.activations import ACT2FN
 
-from modelscope.metainfo import Models
-from modelscope.models.base import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.models.nlp.unite.configuration import InputFormat
-from modelscope.outputs.nlp_outputs import TranslationEvaluationOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchModel
+from weathon.utils.constants.metainfo import Models
+from weathon.registry import MODELS
+from weathon.models.nlp.backbone.unite import InputFormat
+from weathon.utils.output.nlp_outputs import TranslationEvaluationOutput
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['UniTEForTranslationEvaluation']
 
 
 def _layer_norm_all(tensor, mask_float):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/use/transformer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/use/transformer.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 
 import torch
 import torch.nn as nn
 
 
 def gelu(x):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/use/user_satisfaction_estimation.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/use/user_satisfaction_estimation.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Dict, Union
 
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torch.nn.init import xavier_uniform_
 from transformers import BertModel
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.base import Tensor
-from modelscope.models.builder import MODELS
-from modelscope.outputs import DialogueUserSatisfactionEstimationModelOutput
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.utils.output.nlp_outputs import DialogueUserSatisfactionEstimationModelOutput
+from weathon.utils.typing import Tensor
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 from .transformer import TransformerEncoder
 
 __all__ = ['UserSatisfactionEstimation']
 
 
 @MODELS.register_module(Tasks.text_classification, module_name=Models.use)
 class UserSatisfactionEstimation(TorchModel):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/veco/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/veco/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .configuration import VecoConfig
     from .backbone import VecoModel
     from .text_classification import VecoForSequenceClassification
     from .token_classification import VecoForTokenClassification
     from .fill_mask import VecoForMaskedLM
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/veco/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/veco/backbone.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,20 +14,20 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """PyTorch Veco model. mainly copied from :module:`~transformers.modeling_xlm_roberta`"""
 
 from transformers import RobertaModel
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils import logger as logging
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
+from weathon.utils import logger as logging
+from weathon.utils.constants import Tasks
 from .configuration import VecoConfig
 
 logger = logging.get_logger()
 
 VECO_PRETRAINED_MODEL_ARCHIVE_LIST = []
 
 
@@ -53,24 +53,24 @@
     documentation alongside usage examples.
     """
 
     config_class = VecoConfig
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def forward(self, *args, **kwargs):
         """
         Returns:
             Returns `modelscope.outputs.AttentionBackboneModelOutputWithEmbedding`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
+            >>> from weathon.models import Model
+            >>> from weathon.preprocessors import Preprocessor
             >>> model = Model.from_pretrained('damo/nlp_veco_fill-mask-large', task='backbone')
             >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_veco_fill-mask-large')
             >>> print(model(**preprocessor('')))
 
         """
         kwargs['return_dict'] = True
         outputs = super(Model, self).forward(*args, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/veco/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/veco/configuration.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """Veco configuration, mainly copied from :class:`~transformers.configuration_xlm_roberta` """
 
 from transformers import RobertaConfig
 
-from modelscope.utils import logger as logging
+from weathon.utils import logger as logging
 
 logger = logging.get_logger()
 
 
 class VecoConfig(RobertaConfig):
     """
     This class overrides [`RobertaConfig`]. Please check the superclass for the appropriate
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/veco/fill_mask.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/veco/fill_mask.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,19 +13,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from transformers import RobertaForMaskedLM
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionFillMaskModelOutput
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel, BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.output.nlp_outputs import AttentionFillMaskModelOutput
 from .configuration import VecoConfig
 
 
 @MODELS.register_module(Tasks.fill_mask, module_name=Models.veco)
 class VecoForMaskedLM(TorchModel, RobertaForMaskedLM):
     """Veco Model transformer with a masked language model head on top (a linear layer on top of the
     pooled output).
@@ -52,36 +52,36 @@
     appropriate documentation alongside usage examples.
     """
 
     config_class = VecoConfig
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def forward(self, *args, **kwargs):
         """
         Returns:
             Returns `modelscope.outputs.AttentionFillMaskModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
+            >>> from weathon.models import Model
+            >>> from weathon.preprocessors import Preprocessor
             >>> model = Model.from_pretrained('damo/nlp_veco_fill-mask-large')
             >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_veco_fill-mask-large')
             >>> # Call the model, return some tensors
             >>> print(model(**preprocessor('<mask>')))
             >>> # Call the pipeline
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('fill-mask', model=model, preprocessor=preprocessor)
             >>> print(pipeline_ins('<mask>'))
         """
 
         kwargs['return_dict'] = True
-        outputs = super(Model, self).forward(*args, **kwargs)
+        outputs = super(BaseModel, self).forward(*args, **kwargs)
         return AttentionFillMaskModelOutput(
             loss=outputs.loss,
             logits=outputs.logits,
             hidden_states=outputs.hidden_states,
             attentions=outputs.attentions,
             input_ids=kwargs['input_ids'],
         )
@@ -90,10 +90,10 @@
     def _instantiate(cls, **kwargs):
         model_dir = kwargs.pop('model_dir', None)
         if model_dir is None:
             ponet_config = VecoConfig(**kwargs)
             model = cls(ponet_config)
         else:
             model = super(
-                Model,
+                BaseModel,
                 cls).from_pretrained(pretrained_model_name_or_path=model_dir)
         return model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/veco/text_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/veco/text_classification.py`

 * *Files 12% similar despite different names*

```diff
@@ -13,20 +13,20 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from transformers import RobertaForSequenceClassification
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTextClassificationModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel, BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.output.nlp_outputs import AttentionTextClassificationModelOutput
 from .configuration import VecoConfig
 
 
 @MODELS.register_module(Tasks.nli, module_name=Models.veco)
 @MODELS.register_module(
     Tasks.sentiment_classification, module_name=Models.veco)
 @MODELS.register_module(Tasks.sentence_similarity, module_name=Models.veco)
@@ -72,39 +72,38 @@
     appropriate documentation alongside usage examples.
     """
 
     config_class = VecoConfig
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def forward(self, *args, **kwargs):
         """
         Returns:
             Returns `modelscope.outputs.AttentionTextClassificationModelOutput`
 
         Examples:
-            >>> from modelscope.models import Model
-            >>> from modelscope.preprocessors import Preprocessor
-            >>> model = Model.from_pretrained('damo/nlp_veco_fill-mask-large',
+            >>> from weathon.base import BaseModel, BasePreprocessor
+            >>> model = BaseModel.from_pretrained('damo/nlp_veco_fill-mask-large',
             >>>                               task='text-classification', num_labels=2)
-            >>> preprocessor = Preprocessor.from_pretrained('damo/nlp_veco_fill-mask-large',
+            >>> preprocessor = BasePreprocessor.from_pretrained('damo/nlp_veco_fill-mask-large',
             >>>                                             label2id={'0': 0, '1': 1})
             >>> # Call the model, return some tensors
             >>> print(model(**preprocessor('')))
             >>> # Call the pipeline, the result may be incorrect
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('text-classification', pipeline_name='text-classification',
             >>>                         model=model, preprocessor=preprocessor)
             >>> print(pipeline_ins(''))
         """
 
         kwargs['return_dict'] = True
-        outputs = super(Model, self).forward(*args, **kwargs)
+        outputs = super(BaseModel, self).forward(*args, **kwargs)
         return AttentionTextClassificationModelOutput(
             loss=outputs.loss,
             logits=outputs.logits,
             hidden_states=outputs.hidden_states,
             attentions=outputs.attentions,
         )
 
@@ -127,10 +126,10 @@
         cfg = kwargs.pop('cfg', None)
         model_args = parse_labels_in_order(model_dir, cfg, **kwargs)
 
         if model_dir is None:
             config = VecoConfig(**model_args)
             model = cls(config)
         else:
-            model = super(Model, cls).from_pretrained(
+            model = super(BaseModel, cls).from_pretrained(
                 pretrained_model_name_or_path=model_dir, **model_args)
         return model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/veco/token_classification.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/veco/token_classification.py`

 * *Files 19% similar despite different names*

```diff
@@ -14,20 +14,20 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import torch
 from transformers import RobertaForTokenClassification
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionTokenClassificationModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel, BaseModel
+from weathon.registry import MODELS
+from weathon.utils.constants import Tasks
+from weathon.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.output.nlp_outputs import AttentionTokenClassificationModelOutput
 from .configuration import VecoConfig
 
 
 @MODELS.register_module(Tasks.token_classification, module_name=Models.veco)
 class VecoForTokenClassification(TorchModel, RobertaForTokenClassification):
     """Veco Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g.
     for Named-Entity-Recognition (NER) tasks.
@@ -50,19 +50,19 @@
     appropriate documentation alongside usage examples.
     """
 
     config_class = VecoConfig
 
     def __init__(self, config, **kwargs):
         super().__init__(config.name_or_path, **kwargs)
-        super(Model, self).__init__(config)
+        super(BaseModel, self).__init__(config)
 
     def forward(self, *args, **kwargs):
         kwargs['return_dict'] = True
-        outputs = super(Model, self).forward(*args, **kwargs)
+        outputs = super(BaseModel, self).forward(*args, **kwargs)
 
         return AttentionTokenClassificationModelOutput(
             loss=outputs.loss,
             logits=outputs.logits,
             hidden_states=outputs.hidden_states,
             attentions=outputs.attentions,
         )
@@ -86,10 +86,10 @@
         cfg = kwargs.pop('cfg', None)
         model_args = parse_labels_in_order(model_dir, cfg, **kwargs)
 
         if model_dir is None:
             config = VecoConfig(**model_args)
             model = cls(config)
         else:
-            model = super(Model, cls).from_pretrained(
+            model = super(BaseModel, cls).from_pretrained(
                 pretrained_model_name_or_path=model_dir, **model_args)
         return model
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/xlm_roberta/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/xlm_roberta/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .configuration import XLMRobertaConfig
     from .backbone import XLMRobertaModel
 else:
     _import_structure = {
         'configuration': ['XLMRobertaConfig'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/xlm_roberta/backbone.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/xlm_roberta/backbone.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -15,29 +14,28 @@
 # limitations under the License.
 """PyTorch XLM-RoBERTa model."""
 
 import math
 
 import torch
 import torch.utils.checkpoint
-from packaging import version
 from torch import nn
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import (PreTrainedModel,
                                          apply_chunking_to_forward,
                                          find_pruneable_heads_and_indices,
                                          prune_linear_layer)
 
-from modelscope.metainfo import Models
-from modelscope.models import Model, TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.outputs import AttentionBackboneModelOutput
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.nlp.utils import parse_labels_in_order
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.output.nlp_outputs import AttentionBackboneModelOutput
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
+from weathon.utils.nlp.utils import parse_labels_in_order
 from .configuration import XLMRobertaConfig
 
 logger = get_logger()
 
 _CONFIG_FOR_DOC = 'XLMRobertaConfig'
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/nlp/xlm_roberta/configuration.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/xlm_roberta/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.
 # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
@@ -16,15 +15,15 @@
 """ XLM-RoBERTa configuration"""
 from collections import OrderedDict
 from typing import Mapping
 
 from transformers.configuration_utils import PretrainedConfig
 from transformers.onnx import OnnxConfig
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class XLMRobertaConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration of a [`XLMRobertaModel`] or a [`TFXLMRobertaModel`]. It
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/config.py` & `weathon-0.0.0.14/weathon/models/science/unifold/config.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/data/__init__.py` & `weathon-0.0.0.14/weathon/models/science/unifold/data/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/data/data_ops.py` & `weathon-0.0.0.14/weathon/models/science/unifold/data/data_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -7,18 +7,18 @@
 from typing import List, MutableMapping, Optional
 
 import numpy as np
 import torch
 from unicore.data import data_utils
 from unicore.utils import batched_gather, one_hot, tensor_tree_map, tree_map
 
-from modelscope.models.science.unifold.config import (N_EXTRA_MSA, N_MSA,
+from weathon.models.science.unifold.config import (N_EXTRA_MSA, N_MSA,
                                                       N_RES, N_TPL)
-from modelscope.models.science.unifold.data import residue_constants as rc
-from modelscope.models.science.unifold.modules.frame import Frame, Rotation
+from weathon.models.science.unifold.data import residue_constants as rc
+from weathon.models.science.unifold.modules.frame import Frame, Rotation
 
 NumpyDict = MutableMapping[str, np.ndarray]
 TorchDict = MutableMapping[str, np.ndarray]
 
 protein: TorchDict
 
 MSA_FEATURE_NAMES = [
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/data/msa_pairing.py` & `weathon-0.0.0.14/weathon/models/science/unifold/data/msa_pairing.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/data/process.py` & `weathon-0.0.0.14/weathon/models/science/unifold/data/process.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 # and is publicly available at https://github.com/dptech-corp/Uni-Fold.
 
 from typing import Optional
 
 import numpy as np
 import torch
 
-from modelscope.models.science.unifold.data import data_ops
+from weathon.models.science.unifold.data import data_ops
 
 
 def nonensembled_fns(common_cfg, mode_cfg):
     """Input pipeline data transformers that are not ensembled."""
     v2_feature = common_cfg.v2_feature
     operators = []
     if mode_cfg.random_delete_msa:
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/data/process_multimer.py` & `weathon-0.0.0.14/weathon/models/science/unifold/data/process_multimer.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 """Feature processing logic for multimer data """
 
 import collections
 from typing import Iterable, List, MutableMapping
 
 import numpy as np
 
-from modelscope.models.science.unifold.data import (msa_pairing,
+from weathon.models.science.unifold.data import (msa_pairing,
                                                     residue_constants)
 from .utils import correct_template_restypes
 
 FeatureDict = MutableMapping[str, np.ndarray]
 
 REQUIRED_FEATURES = frozenset({
     'aatype',
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/data/protein.py` & `weathon-0.0.0.14/weathon/models/science/unifold/data/protein.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 import dataclasses
 import io
 from typing import Any, Mapping, Optional
 
 import numpy as np
 from Bio.PDB import PDBParser
 
-from modelscope.models.science.unifold.data import residue_constants
+from weathon.models.science.unifold.data import residue_constants
 
 FeatureDict = Mapping[str, np.ndarray]
 ModelOutput = Mapping[str, Any]  # Is a nested dict.
 
 # Complete sequence of chain IDs supported by the PDB format.
 PDB_CHAIN_IDS = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
 PDB_MAX_CHAINS = len(PDB_CHAIN_IDS)  # := 62.
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/data/residue_constants.py` & `weathon-0.0.0.14/weathon/models/science/unifold/data/residue_constants.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/data/utils.py` & `weathon-0.0.0.14/weathon/models/science/unifold/data/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/dataset.py` & `weathon-0.0.0.14/weathon/models/science/unifold/dataset.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/model.py` & `weathon-0.0.0.14/weathon/models/science/unifold/model.py`

 * *Files 17% similar despite different names*

```diff
@@ -3,18 +3,18 @@
 
 import argparse
 import os
 from typing import Any
 
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.models import TorchModel
-from modelscope.models.builder import MODELS
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.base import TorchModel
+from weathon.registry import MODELS
+from weathon.utils.constants import ModelFile, Tasks
 from .config import model_config
 from .modules.alphafold import AlphaFold
 
 __all__ = ['UnifoldForProteinStructrue']
 
 
 @MODELS.register_module(Tasks.protein_structure, module_name=Models.unifold)
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/alphafold.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/alphafold.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/attentions.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/attentions.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/auxillary_heads.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/auxillary_heads.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/common.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/common.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/confidence.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/confidence.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/embedders.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/embedders.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/evoformer.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/evoformer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/featurization.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/featurization.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 from typing import Dict
 
 import torch
 import torch.nn as nn
 from unicore.utils import batched_gather, one_hot
 
-from modelscope.models.science.unifold.data import residue_constants as rc
+from weathon.models.science.unifold.data import residue_constants as rc
 from .frame import Frame
 
 
 def pseudo_beta_fn(aatype, all_atom_positions, all_atom_masks):
     is_gly = aatype == rc.restype_order['G']
     ca_idx = rc.atom_order['CA']
     cb_idx = rc.atom_order['CB']
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/frame.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/frame.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/structure_module.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/structure_module.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 from typing import Tuple
 
 import torch
 import torch.nn as nn
 from unicore.modules import LayerNorm, softmax_dropout
 from unicore.utils import dict_multimap, one_hot, permute_final_dims
 
-from modelscope.models.science.unifold.data.residue_constants import (
+from weathon.models.science.unifold.data.residue_constants import (
     restype_atom14_mask, restype_atom14_rigid_group_positions,
     restype_atom14_to_rigid_group, restype_rigid_group_default_frame)
 from .attentions import gen_attn_mask
 from .common import Linear, SimpleModuleList, residual
 from .frame import Frame, Quaternion, Rotation
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/template.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/template.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/modules/triangle_multiplication.py` & `weathon-0.0.0.14/weathon/models/science/unifold/modules/triangle_multiplication.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/mmcif.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/mmcif.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/msa_identifiers.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/msa_identifiers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/parsers.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/parsers.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/pipeline.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,18 +15,18 @@
 
 import os
 from typing import Any, Mapping, MutableMapping, Optional, Sequence, Union
 
 import numpy as np
 from absl import logging
 
-from modelscope.models.science.unifold.data import residue_constants
-from modelscope.models.science.unifold.msa import (msa_identifiers, parsers,
+from weathon.models.science.unifold.data import residue_constants
+from weathon.models.science.unifold.msa import (msa_identifiers, parsers,
                                                    templates)
-from modelscope.models.science.unifold.msa.tools import (hhblits, hhsearch,
+from weathon.models.science.unifold.msa.tools import (hhblits, hhsearch,
                                                          hmmsearch, jackhmmer)
 
 FeatureDict = MutableMapping[str, np.ndarray]
 TemplateSearcher = Union[hhsearch.HHSearch, hmmsearch.Hmmsearch]
 
 
 def make_sequence_features(sequence: str, description: str,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/templates.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/templates.py`

 * *Files 0% similar despite different names*

```diff
@@ -20,17 +20,17 @@
 import os
 import re
 from typing import Any, Dict, Mapping, Optional, Sequence, Tuple
 
 import numpy as np
 from absl import logging
 
-from modelscope.models.science.unifold.data import residue_constants
-from modelscope.models.science.unifold.msa import mmcif, parsers
-from modelscope.models.science.unifold.msa.tools import kalign
+from weathon.models.science.unifold.data import residue_constants
+from weathon.models.science.unifold.msa import mmcif, parsers
+from weathon.models.science.unifold.msa.tools import kalign
 
 
 class Error(Exception):
     """Base class for exceptions."""
 
 
 class NoChainsError(Error):
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/__init__.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/hhblits.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/hhblits.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/hhsearch.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/hhsearch.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,15 +16,15 @@
 import glob
 import os
 import subprocess
 from typing import Sequence
 
 from absl import logging
 
-from modelscope.models.science.unifold.msa import parsers
+from weathon.models.science.unifold.msa import parsers
 from . import utils
 
 
 class HHSearch:
     """Python wrapper of the HHsearch binary."""
 
     def __init__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/hmmbuild.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/hmmbuild.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/hmmsearch.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/hmmsearch.py`

 * *Files 0% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
 import os
 import subprocess
 from typing import Optional, Sequence
 
 from absl import logging
 
-from modelscope.models.science.unifold.msa import parsers
+from weathon.models.science.unifold.msa import parsers
 from . import hmmbuild, utils
 
 
 class Hmmsearch(object):
     """Python wrapper of the hmmsearch binary."""
 
     def __init__(
```

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/jackhmmer.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/jackhmmer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/kalign.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/kalign.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/tools/utils.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/tools/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/models/science/unifold/msa/utils.py` & `weathon-0.0.0.14/weathon/models/science/unifold/msa/utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 import os
 from typing import Mapping, Sequence
 
 import json
 from absl import logging
 
-from modelscope.models.science.unifold.data import protein
+from weathon.models.science.unifold.data import protein
 
 
 def get_chain_id_map(
     sequences: Sequence[str],
     descriptions: Sequence[str],
 ):
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/auth/auth_config.py` & `weathon-0.0.0.14/weathon/utils/config/auth_config.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from http.cookiejar import CookieJar
 from typing import Tuple
 
 
 class BaseAuthConfig(object):
     """Base authorization config class."""
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/context/dataset_context_config.py` & `weathon-0.0.0.14/weathon/utils/config/dataset_context_config.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Mapping, Sequence, Union
 
-from modelscope.msdatasets.auth.auth_config import BaseAuthConfig
-from modelscope.msdatasets.download.download_config import DataDownloadConfig
-from modelscope.msdatasets.meta.data_meta_config import DataMetaConfig
-from modelscope.utils.constant import DownloadMode, Hubs
+from weathon.utils.config.auth_config import BaseAuthConfig
+from weathon.utils.config.download_config import DataDownloadConfig
+from weathon.utils.config.data_meta_config import DataMetaConfig
+from weathon.utils.constants import Hubs, DownloadMode
 
 
 class DatasetContextConfig:
     """Context configuration of dataset."""
 
     def __init__(self, dataset_name: Union[str, list], namespace: str,
                  version: str, subset_name: str, split: Union[str, list],
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/data_files/data_files_manager.py` & `weathon-0.0.0.14/weathon/utils/dataset/manager/data_files_manager.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,24 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Union
 
 from datasets import DatasetBuilder
 
-from modelscope.hub.api import HubApi
-from modelscope.msdatasets.context.dataset_context_config import \
-    DatasetContextConfig
-from modelscope.msdatasets.download.dataset_builder import (
-    CsvDatasetBuilder, IterableDatasetBuilder, TaskSpecificDatasetBuilder)
-from modelscope.msdatasets.download.download_config import DataDownloadConfig
-from modelscope.msdatasets.download.download_manager import (
-    DataDownloadManager, DataStreamingDownloadManager)
-from modelscope.utils.constant import (DatasetPathName, DownloadMode,
-                                       MetaDataFields)
+from weathon.utils.constants import DatasetPathName, DownloadMode, MetaDataFields
+from weathon.utils.hub.api import HubApi
+from weathon.utils.config.dataset_context_config import DatasetContextConfig
+from weathon.utils.dataset.dataset_downloader import (CsvDatasetBuilder, IterableDatasetBuilder, TaskSpecificDatasetBuilder)
+from weathon.utils.config.download_config import DataDownloadConfig
+from weathon.utils.dataset.manager.download_manager import (DataDownloadManager, DataStreamingDownloadManager)
 
 
 class DataFilesManager(object):
     """The modelscope data-files manager."""
 
     def __init__(self, dataset_context_config: DatasetContextConfig):
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/data_loader/data_loader.py` & `weathon-0.0.0.14/weathon/utils/dataset/data_loader.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,80 +1,38 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from abc import ABC, abstractmethod
 from typing import Optional, Union
 
 from datasets import (Dataset, DatasetBuilder, DatasetDict, IterableDataset,
                       IterableDatasetDict)
 from datasets import load_dataset as hf_load_dataset
 
-from modelscope.hub.api import ModelScopeConfig
-from modelscope.msdatasets.auth.auth_config import OssAuthConfig
-from modelscope.msdatasets.context.dataset_context_config import \
-    DatasetContextConfig
-from modelscope.msdatasets.data_files.data_files_manager import \
-    DataFilesManager
-from modelscope.msdatasets.dataset_cls import ExternalDataset
-from modelscope.msdatasets.meta.data_meta_manager import DataMetaManager
-from modelscope.utils.constant import (DatasetFormations, DatasetPathName,
-                                       DownloadMode, VirgoDatasetConfig)
-from modelscope.utils.logger import get_logger
-from modelscope.utils.url_utils import valid_url
+from weathon.base import BaseDownloader
+from weathon.utils.config.auth_config import OssAuthConfig, VirgoAuthConfig
+from weathon.utils.config.dataset_context_config import DatasetContextConfig
+from weathon.utils.dataset.manager.data_files_manager import DataFilesManager
+from weathon.utils.dataset.manager.data_meta_manager import DataMetaManager
+from weathon.utils.constants import DatasetFormations, DatasetPathName, DownloadMode, VirgoDatasetConfig
+from weathon.utils.dataset.dataset import ExternalDataset, VirgoDataset
+from weathon.utils.hub.api import ModelScopeConfig
+from weathon.utils.logger import get_logger
+from weathon.utils.url_utils import valid_url
 
 logger = get_logger()
 
 
-class BaseDownloader(ABC):
-    """Base dataset downloader to load data."""
-
-    def __init__(self, dataset_context_config: DatasetContextConfig):
-        self.dataset_context_config = dataset_context_config
-
-    @abstractmethod
-    def process(self):
-        """The entity processing pipeline for fetching the data. """
-        raise NotImplementedError(
-            f'No default implementation provided for {BaseDownloader.__name__}.process.'
-        )
-
-    @abstractmethod
-    def _authorize(self):
-        raise NotImplementedError(
-            f'No default implementation provided for {BaseDownloader.__name__}._authorize.'
-        )
-
-    @abstractmethod
-    def _build(self):
-        raise NotImplementedError(
-            f'No default implementation provided for {BaseDownloader.__name__}._build.'
-        )
-
-    @abstractmethod
-    def _prepare_and_download(self):
-        raise NotImplementedError(
-            f'No default implementation provided for {BaseDownloader.__name__}._prepare_and_download.'
-        )
-
-    @abstractmethod
-    def _post_process(self):
-        raise NotImplementedError(
-            f'No default implementation provided for {BaseDownloader.__name__}._post_process.'
-        )
-
 
 class OssDownloader(BaseDownloader):
 
     def __init__(self, dataset_context_config: DatasetContextConfig):
         super().__init__(dataset_context_config)
 
         self.data_files_builder: Optional[DataFilesManager] = None
         self.dataset: Optional[Union[Dataset, IterableDataset, DatasetDict,
-                                     IterableDatasetDict,
-                                     ExternalDataset]] = None
+        IterableDatasetDict, ExternalDataset]] = None
         self.builder: Optional[DatasetBuilder] = None
         self.data_files_manager: Optional[DataFilesManager] = None
 
     def process(self) -> None:
         """ Sequential data fetching process: authorize -> build -> prepare_and_download -> post_process,
         to keep dataset_context_config updated. """
 
@@ -129,28 +87,20 @@
         download_mode = self.dataset_context_config.download_mode
         input_kwargs = self.dataset_context_config.config_kwargs
 
         if self.builder is None and not dataset_py_script:
             raise f'meta-file: {dataset_name}.py not found on the modelscope hub.'
 
         if dataset_py_script and dataset_formation == DatasetFormations.hf_compatible:
-            self.dataset = hf_load_dataset(
-                dataset_py_script,
-                name=subset_name,
-                revision=version,
-                split=split,
-                data_dir=data_dir,
-                data_files=data_files,
-                cache_dir=cache_dir,
-                download_mode=download_mode.value,
-                ignore_verifications=True,
-                **input_kwargs)
+            self.dataset = hf_load_dataset(dataset_py_script, name=subset_name, revision=version, split=split,
+                                           data_dir=data_dir, data_files=data_files, cache_dir=cache_dir,
+                                           download_mode=download_mode.value,
+                                           ignore_verifications=True, **input_kwargs)
         else:
-            self.dataset = self.data_files_manager.fetch_data_files(
-                self.builder)
+            self.dataset = self.data_files_manager.fetch_data_files(self.builder)
 
     def _post_process(self) -> None:
         if isinstance(self.dataset, ExternalDataset):
             self.dataset.custom_map = self.dataset_context_config.data_meta_config.meta_type_map
 
 
 class VirgoDownloader(BaseDownloader):
@@ -167,15 +117,14 @@
         self._authorize()
         self._build()
         self._prepare_and_download()
         self._post_process()
 
     def _authorize(self):
         """Authorization of virgo dataset."""
-        from modelscope.msdatasets.auth.auth_config import VirgoAuthConfig
 
         cookies = ModelScopeConfig.get_cookies()
         user_info = ModelScopeConfig.get_user_info()
 
         if not self.dataset_context_config.auth_config:
             auth_config = VirgoAuthConfig(
                 cookies=cookies, git_token='', user_info=user_info)
@@ -187,34 +136,28 @@
 
         self.dataset_context_config.auth_config = auth_config
 
     def _build(self):
         """
         Fetch virgo meta and build virgo dataset.
         """
-        from modelscope.msdatasets.dataset_cls.dataset import VirgoDataset
         import pandas as pd
 
         meta_manager = DataMetaManager(self.dataset_context_config)
         meta_manager.fetch_virgo_meta()
         self.dataset_context_config = meta_manager.dataset_context_config
-        self.dataset = VirgoDataset(
-            **self.dataset_context_config.config_kwargs)
+        self.dataset = VirgoDataset(**self.dataset_context_config.config_kwargs)
 
         virgo_cache_dir = os.path.join(
             self.dataset_context_config.cache_root_dir,
             self.dataset_context_config.namespace,
             self.dataset_context_config.dataset_name,
             self.dataset_context_config.version)
-        os.makedirs(
-            os.path.join(virgo_cache_dir, DatasetPathName.META_NAME),
-            exist_ok=True)
-        meta_content_cache_file = os.path.join(virgo_cache_dir,
-                                               DatasetPathName.META_NAME,
-                                               'meta_content.csv')
+        os.makedirs(os.path.join(virgo_cache_dir, DatasetPathName.META_NAME), exist_ok=True)
+        meta_content_cache_file = os.path.join(virgo_cache_dir, DatasetPathName.META_NAME, 'meta_content.csv')
 
         if isinstance(self.dataset.meta, pd.DataFrame):
             meta_content_df = self.dataset.meta
             meta_content_df.to_csv(meta_content_cache_file, index=False)
             self.dataset.meta_content_cache_file = meta_content_cache_file
             self.dataset.virgo_cache_dir = virgo_cache_dir
             logger.info(
@@ -281,20 +224,16 @@
                                           DatasetPathName.DATA_FILES_NAME)
 
             if download_mode == DownloadMode.FORCE_REDOWNLOAD:
                 shutil.rmtree(data_files_dir, ignore_errors=True)
 
             from tqdm import tqdm
             tqdm.pandas(desc='apply download_file')
-            self.dataset.meta[
-                VirgoDatasetConfig.
-                col_cache_file] = self.dataset.meta.progress_apply(
-                    lambda row: partial(
-                        download_file, data_dir=data_files_dir)(row.meta_info),
-                    axis=1)
+            self.dataset.meta[VirgoDatasetConfig.col_cache_file] = self.dataset.meta.progress_apply(
+                lambda row: partial(download_file, data_dir=data_files_dir)(row.meta_info), axis=1)
 
     def _post_process(self):
         ...
 
 
 class MaxComputeDownloader(BaseDownloader):
     """Data downloader for MaxCompute data source."""
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/data_loader/data_loader_manager.py` & `weathon-0.0.0.14/weathon/utils/dataset/manager/data_loader_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import enum
 import os
 from abc import ABC, abstractmethod
 
 from datasets import load_dataset as hf_data_loader
 
-from modelscope.hub.api import HubApi
-from modelscope.msdatasets.context.dataset_context_config import \
-    DatasetContextConfig
-from modelscope.msdatasets.data_loader.data_loader import OssDownloader
-from modelscope.utils.constant import EXTENSIONS_TO_LOAD
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.dataset_context_config import DatasetContextConfig
+from weathon.utils.constants import EXTENSIONS_TO_LOAD
+from weathon.utils.hub.api import HubApi
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class LocalDataLoaderType(enum.Enum):
     """ Supported data loader types for local dataset: huggingface, PyTorch, Tensorflow """
     HF_DATA_LOADER = 'hf_data_loader'
@@ -123,14 +119,15 @@
             self.api.dataset_download_statistics(
                 dataset_name=dataset_name,
                 namespace=namespace,
                 use_streaming=use_streaming)
             return dataset_ret
         # To use the modelscope data loader
         elif data_loader_type == RemoteDataLoaderType.MS_DATA_LOADER:
+            from weathon.utils.dataset.data_loader import OssDownloader
             oss_data_loader = OssDownloader(
                 dataset_context_config=self.dataset_context_config)
             oss_data_loader.process()
             # download statistics
             self.api.dataset_download_statistics(
                 dataset_name=dataset_name,
                 namespace=namespace,
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .easycv_base import EasyCVBaseDataset
-    from .builder import CUSTOM_DATASETS, build_custom_dataset
-    from .torch_custom_dataset import TorchCustomDataset
     from .movie_scene_segmentation.movie_scene_segmentation_dataset import MovieSceneSegmentationDataset
     from .image_instance_segmentation_coco_dataset import ImageInstanceSegmentationCocoDataset
     from .gopro_image_deblurring_dataset import GoproImageDeblurringDataset
     from .language_guided_video_summarization_dataset import LanguageGuidedVideoSummarizationDataset
     from .mgeo_ranking_dataset import MGeoRankingDataset
     from .reds_image_deblurring_dataset import RedsImageDeblurringDataset
     from .text_ranking_dataset import TextRankingDataset
@@ -29,16 +26,14 @@
     from .video_super_resolution import VideoSuperResolutionDataset
     from .ocr_detection import DataLoader, ImageDataset, QuadMeasurer
     from .ocr_recognition_dataset import OCRRecognitionDataset
     from .image_colorization import ImageColorizationDataset
 else:
     _import_structure = {
         'easycv_base': ['EasyCVBaseDataset'],
-        'builder': ['CUSTOM_DATASETS', 'build_custom_dataset'],
-        'torch_custom_dataset': ['TorchCustomDataset'],
         'movie_scene_segmentation_dataset': ['MovieSceneSegmentationDataset'],
         'image_instance_segmentation_coco_dataset':
         ['ImageInstanceSegmentationCocoDataset'],
         'gopro_image_deblurring_dataset': ['GoproImageDeblurringDataset'],
         'language_guided_video_summarization_dataset':
         ['LanguageGuidedVideoSummarizationDataset'],
         'mgeo_ranking_dataset': ['MGeoRankingDataset'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/asr_dataset.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,15 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 
-from modelscope.msdatasets.ms_dataset import MsDataset
+from weathon.utils.dataset.dataset import WtDataset
 
 
-class ASRDataset(MsDataset):
+class ASRDataset(WtDataset):
     """ASR dataset for speech recognition.
     support load dataset from msdataset hub or local data_dir (including wav.scp and text)
     For more details, please refer to
         https://github.com/alibaba-damo-academy/FunASR/blob/main/funasr/datasets/ms_dataset.py.
     """
 
     @classmethod
@@ -38,11 +36,11 @@
             data_dir = dataset_name
             ds_dict = {}
             ds_dict['train'] = cls.load_core(data_dir, train_set)
             ds_dict['validation'] = cls.load_core(data_dir, dev_set)
             ds_dict['raw_data_dir'] = data_dir
             return ds_dict
         else:
-            from modelscope.msdatasets import MsDataset
+            from weathon.msdatasets import MsDataset
             ds_dict = MsDataset.load(
                 dataset_name=dataset_name, namespace=namespace)
             return ds_dict
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/kws_farfield_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 import os.path
 import queue
 import threading
 
 import numpy as np
 import torch
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 BLOCK_DEC = 2
 BLOCK_CAT = 3
 FBANK_SIZE = 40
 LABEL_SIZE = 1
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/kws_nearfield_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,19 +14,18 @@
 
 import random
 
 import torch
 import torch.distributed as dist
 from torch.utils.data import IterableDataset
 
-import modelscope.msdatasets.dataset_cls.custom_datasets.audio.kws_nearfield_processor as processor
-from modelscope.trainers.audio.kws_utils.file_utils import (make_pair,
+from weathon.trainers.audio.kws_utils.file_utils import (make_pair,
                                                             read_lists,
                                                             tokenize)
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class Processor(IterableDataset):
 
     def __init__(self, source, f, *args, **kw):
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/audio/kws_nearfield_processor.py`

 * *Files 0% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 import numpy as np
 import torch
 import torchaudio
 import torchaudio.compliance.kaldi as kaldi
 from torch.nn.utils.rnn import pad_sequence
 
 # torch.set_printoptions(profile="full")
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def parse_wav(data):
     """ Parse key/wav/txt from dict line
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,38 +1,33 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.preprocessors.cv import ImageQualityAssessmentMosPreprocessor
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors import LoadImage
-from modelscope.preprocessors.cv.bad_image_detecting_preprocessor import \
-    BadImageDetectingPreprocessor
-from modelscope.utils.constant import Tasks
-
-
-@CUSTOM_DATASETS.register_module(
-    Tasks.bad_image_detecting, module_name=Models.bad_image_detecting)
-class BadImageDetectingDataset(TorchCustomDataset):
-    """Paired image dataset for bad image detecting.
+
+@CUSTOM_DATASETS.register_module(Tasks.image_quality_assessment_mos, module_name=Models.image_quality_assessment_mos)
+class ImageQualityAssessmentMosDataset(TorchCustomDataset):
+    """Paired image dataset for image quality assessment mos.
     """
 
-    def __init__(self, dataset, opt):
+    def __init__(self,
+                 dataset,
+                 opt,
+                 preprocessor=ImageQualityAssessmentMosPreprocessor()):
+        self.preprocessor = preprocessor
         self.dataset = dataset
         self.opt = opt
-        self.preprocessor = BadImageDetectingPreprocessor()
+        self.scale = 0.2
 
     def __len__(self):
         return len(self.dataset)
 
     def __getitem__(self, index):
 
         # Load input video paths.
         item_dict = self.dataset[index]
-        iterm_label = item_dict['category']
-        # print(input)
-        img = LoadImage.convert_to_ndarray(item_dict['image:FILE'])
-        img = self.preprocessor(img)
-        return {
-            'input': img['input'].squeeze(0),
-            OutputKeys.LABEL: iterm_label
-        }
+        iterm_mos = float(item_dict['mos']) * self.scale
+
+        img = self.preprocessor(item_dict['image:FILE'])
+
+        return {'input': img['input'].squeeze(0), 'target': iterm_mos}
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/builder.py` & `weathon-0.0.0.14/weathon/registry/exporter.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,21 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+from weathon.registry.registry import build_from_cfg,Registry
+from weathon.utils.config.config import ConfigDict
 
-from modelscope.utils.config import ConfigDict
-from modelscope.utils.registry import Registry, build_from_cfg
 
-CUSTOM_DATASETS = Registry('custom_datasets')
+EXPORTERS = Registry('exporters')
 
 
-def build_custom_dataset(cfg: ConfigDict,
-                         task_name: str,
-                         default_args: dict = None):
-    """ Build custom dataset for user-define dataset given model config and task name.
+def build_exporter(cfg: ConfigDict,task_name: str = None,default_args: dict = None):
+    """ build exporter by the given model config dict
 
     Args:
-        cfg (:obj:`ConfigDict`): config dict for model object.
+        cfg (:obj:`ConfigDict`): config dict for exporter object.
         task_name (str, optional):  task name, refer to
             :obj:`Tasks` for more details
         default_args (dict, optional): Default initialization arguments.
     """
-    return build_from_cfg(
-        cfg, CUSTOM_DATASETS, group_key=task_name, default_args=default_args)
+    return build_from_cfg(cfg, EXPORTERS, group_key=task_name, default_args=default_args)
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/build.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # Copyright  Alibaba, Inc. and its affiliates.
 import bisect
 import copy
 import math
 
 import torch.utils.data
 
-from modelscope.utils.torch_utils import get_world_size
+from weathon.utils.torch_utils import get_world_size
 from . import datasets as D
 from .collate_batch import BatchCollator
 from .datasets import MosaicWrapper
 from .samplers import DistributedSampler, IterationBasedBatchSampler
 from .transforms import build_transforms
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/collate_batch.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 # Copyright  Alibaba, Inc. and its affiliates.
-from modelscope.models.cv.tinynas_detection.damo.structures.image_list import \
-    to_image_list
+from weathon.models.cv.tinynas_detection.damo.structures.image_list import to_image_list
 
 
 class BatchCollator(object):
     """
     From a list of samples from the dataset,
     returns the batched images and targets.
     This should be passed to the DataLoader
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/datasets/coco.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 # Copyright  Alibaba, Inc. and its affiliates.
 import cv2
 import numpy as np
 import torch
 from torchvision.datasets.coco import CocoDetection
 
-from modelscope.models.cv.tinynas_detection.damo.structures.bounding_box import \
+from weathon.models.cv.tinynas_detection.damo.structures.bounding_box import \
     BoxList
 
 cv2.setNumThreads(0)
 
 
 class COCODataset(CocoDetection):
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/datasets/mosaic_wrapper.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,17 +3,17 @@
 import math
 import random
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.models.cv.tinynas_detection.damo.structures.bounding_box import \
+from weathon.models.cv.tinynas_detection.damo.structures.bounding_box import \
     BoxList
-from modelscope.models.cv.tinynas_detection.damo.utils import adjust_box_anns
+from weathon.models.cv.tinynas_detection.damo.utils import adjust_box_anns
 
 
 def xyn2xy(x, scale, padw=0, padh=0):
     # Convert normalized segments into pixel segments, shape (n,2)
     y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
     y[:, 0] = scale * x[:, 0] + padw  # top left x
     y[:, 1] = scale * x[:, 1] + padh  # top left y
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/evaluation/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/evaluation/coco/__init__.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/evaluation/coco/coco_eval.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,19 +3,19 @@
 
 import os
 import tempfile
 from collections import OrderedDict
 
 import torch
 
-from modelscope.models.cv.tinynas_detection.damo.structures.bounding_box import \
+from weathon.models.cv.tinynas_detection.damo.structures.bounding_box import \
     BoxList
-from modelscope.models.cv.tinynas_detection.damo.structures.boxlist_ops import \
+from weathon.models.cv.tinynas_detection.damo.structures.boxlist_ops import \
     boxlist_iou
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def do_coco_evaluation(
     dataset,
     predictions,
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/samplers/distributed.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-# Code is copy-pasted exactly as in torch.utils.data.distributed.
 # FIXME remove this once c10d fixes the bug it has
 import math
 
 import torch
 import torch.distributed as dist
 from torch.utils.data.sampler import Sampler
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,7 @@
-# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-# Copyright  Alibaba, Inc. and its affiliates.
-
 import itertools
 
 import torch
 from torch.utils.data.sampler import BatchSampler, Sampler
 
 
 class GroupedBatchSampler(BatchSampler):
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-# Copyright  Alibaba, Inc. and its affiliates.
 from torch.utils.data.sampler import BatchSampler
 
 
 class IterationBasedBatchSampler(BatchSampler):
     """
     Wraps a BatchSampler, resampling from it until
     a specified number of iterations have been sampled
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/transforms/build.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,8 @@
-# Copyright  Alibaba, Inc. and its affiliates.
-from modelscope.models.cv.tinynas_detection.damo.augmentations.scale_aware_aug import \
-    SA_Aug
+from weathon.models.cv.tinynas_detection.damo.augmentations.scale_aware_aug import SA_Aug
 from . import transforms as T
 
 
 def build_transforms(start_epoch,
                      total_epochs,
                      no_aug_epochs,
                      iters_per_epoch,
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/damoyolo/transforms/transforms.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-# Copyright  Alibaba, Inc. and its affiliates.
 import random
 
 import cv2
 import numpy as np
 import torch
 from torchvision.transforms import functional as F
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/easycv_base.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/easycv_base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 
 
 class EasyCVBaseDataset(object):
     """Adapt to MSDataset.
 
     Args:
         split_config (dict): Dataset root path from MSDataset, e.g.
             {"train":"local cache path"} or {"evaluation":"local cache path"}.
-        preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+        preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied. Not support yet.
         mode: Training or Evaluation.
     """
     DATA_ROOT_PATTERN = '${data_root}'
 
     def __init__(self,
                  split_config=None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/gopro_image_deblurring_dataset.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,28 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import cv2
 import numpy as np
 
-from modelscope.metainfo import CustomDatasets
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.data_utils import (
-    img2tensor, padding)
-from modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.transforms import (
-    augment, paired_random_crop)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import CustomDatasets
+from weathon.datasets.custom_datasets.sidd_image_denoising.data_utils import img2tensor, padding
+from weathon.datasets.custom_datasets.sidd_image_denoising.transforms import augment,paired_random_crop
 
 
 def default_loader(path):
     return cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.image_deblurring, module_name=CustomDatasets.GoproDataset)
+@CUSTOM_DATASETS.register_module(Tasks.image_deblurring, module_name=CustomDatasets.GoproDataset)
 class GoproImageDeblurringDataset(TorchCustomDataset):
     """Paired image dataset for image restoration.
     """
 
     def __init__(self, dataset, opt, is_train):
         self.dataset = dataset
         self.opt = opt
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_colorization/image_colorization_dataset.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,25 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
 
 def default_loader(path):
     return cv2.imread(path).astype(np.float32) / 255.0
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.image_colorization, module_name=Models.ddcolor)
+@CUSTOM_DATASETS.register_module(Tasks.image_colorization, module_name=Models.ddcolor)
 class ImageColorizationDataset(TorchCustomDataset):
     """Image dataset for image colorization.
     """
 
     def __init__(self, dataset, opt, is_train):
         self.dataset = dataset
         self.opt = opt
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_inpainting/aug.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_inpainting/image_inpainting_dataset.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,19 +6,22 @@
 import os.path as osp
 from enum import Enum
 
 import albumentations as A
 import cv2
 import numpy as np
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+# from weathon.msdatasets.dataset_cls.custom_datasets import (
+#     CUSTOM_DATASETS, TorchCustomDataset)
+# from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 from .aug import IAAAffine2, IAAPerspective2
 
 LOGGER = get_logger()
 
 
 class LinearRamp:
 
@@ -288,16 +291,15 @@
             A.PadIfNeeded(min_height=out_size, min_width=out_size),
             A.CenterCrop(height=out_size, width=out_size),
             A.ToFloat()
         ])
     return transform
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.image_inpainting, module_name=Models.image_inpainting)
+@CUSTOM_DATASETS.register_module(Tasks.image_inpainting, module_name=Models.image_inpainting)
 class ImageInpaintingDataset(TorchCustomDataset):
 
     def __init__(self, **kwargs):
         split_config = kwargs['split_config']
         LOGGER.info(kwargs)
         mode = kwargs.get('test_mode', False)
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_instance_segmentation_coco_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,34 +1,32 @@
 # Part of the implementation is borrowed and modified from MMDetection, publicly available at
 # https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/coco.py
 import os.path as osp
 
 import numpy as np
 from pycocotools.coco import COCO
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
 DATASET_STRUCTURE = {
     'train': {
         'annotation': 'annotations/instances_train.json',
         'images': 'images/train'
     },
     'validation': {
         'annotation': 'annotations/instances_val.json',
         'images': 'images/val'
     }
 }
 
 
-@CUSTOM_DATASETS.register_module(
-    module_name=Models.cascade_mask_rcnn_swin,
-    group_key=Tasks.image_segmentation)
+@CUSTOM_DATASETS.register_module(module_name=Models.cascade_mask_rcnn_swin, group_key=Tasks.image_segmentation)
 class ImageInstanceSegmentationCocoDataset(TorchCustomDataset):
     """Coco-style dataset for image instance segmentation.
 
     Args:
         split_config (dict): Annotation file path. {"train":"xxxxx"}
         classes (Sequence[str], optional): Specify classes to load.
             If is None, ``cls.CLASSES`` will be used. Default: None.
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_portrait_enhancement/data_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,25 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import cv2
 import numpy as np
 
-from modelscope.metainfo import CustomDatasets
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import CustomDatasets
 from .data_utils import img2tensor
 
 
 def default_loader(path):
     return cv2.imread(path, cv2.IMREAD_COLOR).astype(np.float32) / 255.0
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.image_portrait_enhancement, module_name=CustomDatasets.PairedDataset)
+@CUSTOM_DATASETS.register_module(Tasks.image_portrait_enhancement, module_name=CustomDatasets.PairedDataset)
 class ImagePortraitEnhancementDataset(TorchCustomDataset):
     """Paired image dataset for image portrait enhancement.
     """
 
     def __init__(self, dataset, is_train):
         self.dataset = dataset
         self.gt_size = 256
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,45 +1,45 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+import cv2
+import numpy as np
+import torch
 
-from torchvision import transforms
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-
-
-@CUSTOM_DATASETS.register_module(
-    Tasks.image_quality_assessment_degradation,
-    module_name=Models.image_quality_assessment_degradation)
-class ImageQualityAssessmentDegradationDataset(TorchCustomDataset):
-    """Paired image dataset for image quality assessment degradation.
+
+def default_loader(path):
+    return cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32)
+
+
+@CUSTOM_DATASETS.register_module(Tasks.video_frame_interpolation,module_name=Models.video_frame_interpolation)
+class VideoFrameInterpolationDataset(TorchCustomDataset):
+    """Dataset for video frame-interpolation.
     """
 
-    def __init__(self, dataset):
+    def __init__(self, dataset, opt):
         self.dataset = dataset
+        self.opt = opt
 
     def __len__(self):
         return len(self.dataset)
 
     def __getitem__(self, index):
 
-        # Load input video paths.
+        # Load frames. Dimension order: HWC; channel order: BGR;
+        # image range: [0, 1], float32
         item_dict = self.dataset[index]
-        item_id = item_dict['image:FILE'].split('/')[-1].split('_')[0]
-        item_degree = item_dict['degree']
-        item_distortion_type = '%02d' % item_dict['degradation_category']
-
-        img = LoadImage.convert_to_img(item_dict['image:FILE'])
-        w, h = img.size
-        if h * w < 1280 * 720:
-            img = transforms.functional.resize(img, 720)
-        test_transforms = transforms.Compose([transforms.ToTensor()])
-        img = test_transforms(img)
-
-        return {
-            'input': img,
-            'item_id': item_id,
-            'target': item_degree,
-            'distortion_type': item_distortion_type
-        }
+        img0 = default_loader(item_dict['Input1:FILE'])
+        img1 = default_loader(item_dict['Input2:FILE'])
+        img2 = default_loader(item_dict['Input3:FILE'])
+        img3 = default_loader(item_dict['Input4:FILE'])
+        gt = default_loader(item_dict['Output:FILE'])
+
+        img0, img1, img2, img3, gt = img2tensor([img0, img1, img2, img3, gt],
+                                                bgr2rgb=False,
+                                                float32=True)
+
+        imgs = torch.cat((img0, img1, img2, img3), dim=0)
+        height, width = imgs.size(1), imgs.size(2)
+        imgs = img_padding(imgs, height, width, pad_num=32)
+        return {'input': imgs, 'target': gt / 255.0}
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/language_guided_video_summarization_dataset.py`

 * *Files 4% similar despite different names*

```diff
@@ -20,25 +20,22 @@
 import os
 
 import h5py
 import json
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.language_guided_video_summarization,
-    module_name=Models.language_guided_video_summarization)
+@CUSTOM_DATASETS.register_module(Tasks.language_guided_video_summarization,module_name=Models.language_guided_video_summarization)
 class LanguageGuidedVideoSummarizationDataset(TorchCustomDataset):
-
     def __init__(self, mode, opt, root_dir):
         self.mode = mode
         self.data_filename = os.path.join(root_dir, opt.dataset_file)
         self.split_filename = os.path.join(root_dir, opt.split_file)
         self.split_index = opt.split_index
         hdf = h5py.File(self.data_filename, 'r')
         self.list_image_features = []
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/mgeo_ranking_dataset.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,45 +1,38 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import random
 from typing import Any, List, Union
 
 import json
 import torch
 from torch.utils.data import ConcatDataset
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import ModeKeys, Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks, ModeKeys
+from weathon.utils.constants.metainfo import Models
 
 
-@CUSTOM_DATASETS.register_module(
-    group_key=Tasks.text_ranking, module_name=Models.mgeo)
+@CUSTOM_DATASETS.register_module(group_key=Tasks.text_ranking, module_name=Models.mgeo)
 class MGeoRankingDataset(TorchCustomDataset):
 
     def __init__(self,
                  datasets: Union[Any, List[Any]],
                  mode,
                  preprocessor=None,
                  *args,
                  **kwargs):
         self.seed = kwargs.get('seed', 42)
         self.permutation = None
         self.datasets = None
         self.dataset_config = kwargs
-        self.query_sequence = self.dataset_config.get('query_sequence',
-                                                      'query')
-        self.query_gis_sequence = self.dataset_config.get(
-            'query_gis_sequence', 'query_gis')
-        self.pos_sequence = self.dataset_config.get('pos_sequence',
-                                                    'positive_passages')
-        self.neg_sequence = self.dataset_config.get('neg_sequence',
-                                                    'negative_passages')
-        self.text_fileds = self.dataset_config.get('text_fileds',
-                                                   ['text', 'gis'])
+        self.query_sequence = self.dataset_config.get('query_sequence', 'query')
+        self.query_gis_sequence = self.dataset_config.get('query_gis_sequence', 'query_gis')
+        self.pos_sequence = self.dataset_config.get('pos_sequence', 'positive_passages')
+        self.neg_sequence = self.dataset_config.get('neg_sequence', 'negative_passages')
+        self.text_fileds = self.dataset_config.get('text_fileds', ['text', 'gis'])
         self.qid_field = self.dataset_config.get('qid_field', 'query_id')
         if mode == ModeKeys.TRAIN:
             self.neg_samples = self.dataset_config.get('neg_sample', 4)
 
         super().__init__(datasets, mode, preprocessor, **kwargs)
 
     def __getitem__(self, index) -> Any:
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/referring_video_object_segmentation/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .movie_scene_segmentation_dataset import MovieSceneSegmentationDataset
+    from .referring_video_object_segmentation_dataset import ReferringVideoObjectSegmentationDataset
 else:
     _import_structure = {
-        'movie_scene_segmentation_dataset': ['MovieSceneSegmentationDataset'],
+        'referring_video_object_segmentation_dataset':
+        ['MovieSceneSegmentationDataset'],
     }
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py`

 * *Files 9% similar despite different names*

```diff
@@ -5,18 +5,17 @@
 import os.path as osp
 import random
 
 import json
 import torch
 from torchvision.datasets.folder import pil_loader
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets.builder import \
-    CUSTOM_DATASETS
-from modelscope.utils.constant import Tasks
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 from . import sampler
 
 DATASET_STRUCTURE = {
     'train': {
         'annotation': 'anno/train.json',
         'images': 'keyf_240p',
         'feat': 'feat'
@@ -25,16 +24,15 @@
         'annotation': 'anno/test.json',
         'images': 'keyf_240p',
         'feat': 'feat'
     }
 }
 
 
-@CUSTOM_DATASETS.register_module(
-    group_key=Tasks.movie_scene_segmentation, module_name=Models.resnet50_bert)
+@CUSTOM_DATASETS.register_module(group_key=Tasks.movie_scene_segmentation, module_name=Models.resnet50_bert)
 class MovieSceneSegmentationDataset(torch.utils.data.Dataset):
     """dataset for movie scene segmentation.
 
     Args:
         split_config (dict): Annotation file path. {"train":"xxxxx"}
         data_root (str, optional): Data root for ``ann_file``,
             ``img_prefix``, ``seg_prefix``, ``proposal_file`` if specified.
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/movie_scene_segmentation/sampler.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/augmenter.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/data_loader.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/image_dataset.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/measures/iou_evaluator.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/measures/quad_measurer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/augment_data.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/data_process.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/make_border_map.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/make_icdar_data.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/make_seg_detection_data.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/normalize_image.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_detection/processes/random_crop_data.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/ocr_recognition_dataset.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,24 +1,18 @@
 import os
+import sys
 
-import cv2
-import json
 import lmdb
-import numpy as np
 import six
-import torch
 from PIL import Image
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets.builder import \
-    CUSTOM_DATASETS
-from modelscope.msdatasets.dataset_cls.custom_datasets.torch_custom_dataset import \
-    TorchCustomDataset
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
 DATASET_STRUCTURE = {'image': 'image', 'label': 'label.txt', 'lmdb': 'lmdb'}
 
 
 def Q2B(uchar):
     inside_code = ord(uchar)
     if inside_code == 0x3000:
@@ -26,16 +20,15 @@
     else:
         inside_code -= 0xfee0
     if inside_code < 0x0020 or inside_code > 0x7e:
         return uchar
     return chr(inside_code)
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.ocr_recognition, module_name=Models.ocr_recognition)
+@CUSTOM_DATASETS.register_module(Tasks.ocr_recognition, module_name=Models.ocr_recognition)
 class OCRRecognitionDataset(TorchCustomDataset):
 
     def __init__(self, local_lmdb=None, preprocessor=None, **kwargs):
         split_config = kwargs['split_config']
         cache_root = next(iter(split_config.values()))
         lmdb_path = os.path.join(cache_root, DATASET_STRUCTURE['lmdb'])
         if local_lmdb is not None:
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/reds_image_deblurring_dataset.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,28 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import cv2
 import numpy as np
 
-from modelscope.metainfo import CustomDatasets
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.data_utils import (
-    img2tensor, padding)
-from modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.transforms import (
-    augment, paired_random_crop)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import CustomDatasets
+from weathon.datasets.custom_datasets.sidd_image_denoising.data_utils import img2tensor, padding
+from weathon.datasets.custom_datasets.sidd_image_denoising.transforms import augment,paired_random_crop
 
 
 def default_loader(path):
     return cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.image_deblurring, module_name=CustomDatasets.RedsDataset)
+@CUSTOM_DATASETS.register_module(Tasks.image_deblurring, module_name=CustomDatasets.RedsDataset)
 class RedsImageDeblurringDataset(TorchCustomDataset):
     """Paired image dataset for image restoration.
     """
 
     def __init__(self, dataset, opt, is_train):
         self.dataset = dataset
         self.opt = opt
@@ -41,19 +36,15 @@
         # augmentation for training
         if self.is_train:
             gt_size = self.opt.gt_size
             # padding
             img_hq, img_lq = padding(img_hq, img_lq, gt_size)
 
             # random crop
-            img_hq, img_lq = paired_random_crop(
-                img_hq, img_lq, gt_size, scale=1)
+            img_hq, img_lq = paired_random_crop(img_hq, img_lq, gt_size, scale=1)
 
             # flip, rotation
-            img_hq, img_lq = augment([img_hq, img_lq], self.opt.use_flip,
-                                     self.opt.use_rot)
+            img_hq, img_lq = augment([img_hq, img_lq], self.opt.use_flip, self.opt.use_rot)
 
         # BGR to RGB, HWC to CHW, numpy to tensor
-        img_hq, img_lq = img2tensor([img_hq, img_lq],
-                                    bgr2rgb=True,
-                                    float32=True)
+        img_hq, img_lq = img2tensor([img_hq, img_lq], bgr2rgb=True, float32=True)
         return {'input': img_lq, 'target': img_hq}
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py` & `weathon-0.0.0.14/weathon/models/cv/image_classification/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,19 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .referring_video_object_segmentation_dataset import ReferringVideoObjectSegmentationDataset
+    from .mmcls_model import ClassificationModel
+    from .resnet50_cc import ContentCheckBackbone
+
 else:
     _import_structure = {
-        'referring_video_object_segmentation_dataset':
-        ['MovieSceneSegmentationDataset'],
+        'mmcls_model': ['ClassificationModel'],
+        'resnet50_cc': ['ContentCheckBackbone'],
     }
+
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
         _import_structure,
         module_spec=__spec__,
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,34 +11,32 @@
 import torch
 import torch.distributed as dist
 import torchvision.transforms.functional as F
 from pycocotools.mask import area, encode
 from torchvision.io import read_video
 from tqdm import tqdm
 
-from modelscope.metainfo import Models
-from modelscope.models.cv.referring_video_object_segmentation.utils import \
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
+from weathon.models.cv.referring_video_object_segmentation.utils import \
     nested_tensor_from_videos_list
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 from . import transformers as T
 
 LOGGER = get_logger()
 
 
 def get_image_id(video_id, frame_idx, ref_instance_a2d_id):
     image_id = f'v_{video_id}_f_{frame_idx}_i_{ref_instance_a2d_id}'
     return image_id
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.referring_video_object_segmentation,
-    module_name=Models.referring_video_object_segmentation)
+@CUSTOM_DATASETS.register_module(Tasks.referring_video_object_segmentation, module_name=Models.referring_video_object_segmentation)
 class ReferringVideoObjectSegmentationDataset(TorchCustomDataset):
 
     def __init__(self, **kwargs):
         split_config = kwargs['split_config']
         LOGGER.info(kwargs)
         data_cfg = kwargs.get('cfg').data_kwargs
         trans_cfg = kwargs.get('cfg').transformers_kwargs
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/referring_video_object_segmentation/transformers.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 import random
 
 import PIL
 import torch
 import torchvision.transforms as T
 import torchvision.transforms.functional as F
 
-from modelscope.models.cv.referring_video_object_segmentation.utils import \
+from weathon.models.cv.referring_video_object_segmentation.utils import \
     interpolate
 
 
 def crop(image, target, region):
     cropped_image = F.crop(image, *region)
 
     target = target.copy()
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/sidd_image_denoising/data_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,26 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import cv2
 import numpy as np
 
-from modelscope.metainfo import CustomDatasets
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import CustomDatasets
 from .data_utils import img2tensor, padding
 from .transforms import augment, paired_random_crop
 
 
 def default_loader(path):
     return cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.image_denoising, module_name=CustomDatasets.SiddDataset)
+@CUSTOM_DATASETS.register_module(Tasks.image_denoising, module_name=CustomDatasets.SiddDataset)
 class SiddImageDenoisingDataset(TorchCustomDataset):
     """Paired image dataset for image restoration.
     """
 
     def __init__(self, dataset, opt, is_train):
         self.dataset = dataset
         self.opt = opt
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/sidd_image_denoising/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/text_ranking_dataset.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,44 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import random
 from typing import Any, List, Union
 
 import torch
 from torch.utils.data import ConcatDataset
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import ModeKeys, Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks, ModeKeys
+from weathon.utils.constants.metainfo import Models
 
 
-@CUSTOM_DATASETS.register_module(
-    group_key=Tasks.text_ranking, module_name=Models.bert)
-@CUSTOM_DATASETS.register_module(
-    group_key=Tasks.sentence_embedding, module_name=Models.bert)
+@CUSTOM_DATASETS.register_module(group_key=Tasks.text_ranking, module_name=Models.bert)
+@CUSTOM_DATASETS.register_module(group_key=Tasks.sentence_embedding, module_name=Models.bert)
 class TextRankingDataset(TorchCustomDataset):
 
     def __init__(self,
                  datasets: Union[Any, List[Any]],
                  mode,
                  preprocessor=None,
                  *args,
                  **kwargs):
         self.seed = kwargs.get('seed', 42)
         self.permutation = None
         self.datasets = None
         self.dataset_config = kwargs
-        self.query_sequence = self.dataset_config.get('query_sequence',
-                                                      'query')
-        self.pos_sequence = self.dataset_config.get('pos_sequence',
-                                                    'positive_passages')
-        self.neg_sequence = self.dataset_config.get('neg_sequence',
-                                                    'negative_passages')
-        self.text_fileds = self.dataset_config.get('text_fileds',
-                                                   ['title', 'text'])
+        self.query_sequence = self.dataset_config.get('query_sequence', 'query')
+        self.pos_sequence = self.dataset_config.get('pos_sequence', 'positive_passages')
+        self.neg_sequence = self.dataset_config.get('neg_sequence', 'negative_passages')
+        self.text_fileds = self.dataset_config.get('text_fileds', ['title', 'text'])
         self.qid_field = self.dataset_config.get('qid_field', 'query_id')
         if mode == ModeKeys.TRAIN:
             self.neg_samples = self.dataset_config.get('neg_sample', 4)
 
         super().__init__(datasets, mode, preprocessor, **kwargs)
 
     def __getitem__(self, index) -> Any:
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/veco_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/veco_dataset.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, List, Union
 
 import numpy as np
 from datasets import Dataset, IterableDataset, concatenate_datasets
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
 
 @CUSTOM_DATASETS.register_module(module_name=Models.veco, group_key=Tasks.nli)
 class VecoDataset(TorchCustomDataset):
 
     def __init__(self,
                  datasets: Union[Any, List[Any]],
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/video_frame_interpolation/data_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/video_summarization_dataset.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,16 +4,15 @@
 import os
 
 import h5py
 import json
 import numpy as np
 import torch
 
-from modelscope.msdatasets.dataset_cls.custom_datasets import \
-    TorchCustomDataset
+from weathon.base import TorchCustomDataset
 
 
 class VideoSummarizationDataset(TorchCustomDataset):
 
     def __init__(self, mode, opt, root_dir):
         self.mode = mode
         self.data_filename = os.path.join(root_dir, opt.dataset_file)
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py` & `weathon-0.0.0.14/weathon/datasets/custom_datasets/video_super_resolution/video_super_resolution_dataset.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from collections import defaultdict
 
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Models
-from modelscope.msdatasets.dataset_cls.custom_datasets import (
-    CUSTOM_DATASETS, TorchCustomDataset)
-from modelscope.utils.constant import Tasks
+from weathon.base import TorchCustomDataset
+from weathon.registry import CUSTOM_DATASETS
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.metainfo import Models
 
 
 def default_loader(path):
     return cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0
 
 
 def img2tensor(imgs, bgr2rgb=True, float32=True):
@@ -37,16 +35,15 @@
 
     if isinstance(imgs, list):
         return [_totensor(img, bgr2rgb, float32) for img in imgs]
     else:
         return _totensor(imgs, bgr2rgb, float32)
 
 
-@CUSTOM_DATASETS.register_module(
-    Tasks.video_super_resolution, module_name=Models.real_basicvsr)
+@CUSTOM_DATASETS.register_module(Tasks.video_super_resolution, module_name=Models.real_basicvsr)
 class VideoSuperResolutionDataset(TorchCustomDataset):
     """single video dataset for video super-resolution.
     """
 
     def __init__(self, dataset):
         frames_len = len(dataset)
         self.dataset = defaultdict(list)
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/download/dataset_builder.py` & `weathon-0.0.0.14/weathon/utils/dataset/dataset_downloader.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Dict, Union
 
 import datasets
 import pandas as pd
 import pyarrow as pa
 from datasets import (ArrowBasedBuilder, GeneratorBasedBuilder,
@@ -11,26 +9,21 @@
 from datasets.filesystems import is_remote_filesystem
 from datasets.info import DatasetInfo
 from datasets.naming import camelcase_to_snakecase
 from datasets.packaged_modules import csv
 from datasets.utils.filelock import FileLock
 from datasets.utils.py_utils import map_nested
 
-from modelscope.hub.api import HubApi
-from modelscope.msdatasets.context.dataset_context_config import \
-    DatasetContextConfig
-from modelscope.msdatasets.dataset_cls import (ExternalDataset,
-                                               NativeIterableDataset)
-from modelscope.msdatasets.download.download_manager import \
-    DataStreamingDownloadManager
-from modelscope.msdatasets.utils.dataset_utils import \
-    get_subdir_hash_from_split
-from modelscope.utils.constant import (DEFAULT_DATASET_NAMESPACE,
-                                       DatasetPathName, DownloadMode)
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.dataset_context_config import DatasetContextConfig
+from weathon.utils.dataset.dataset import NativeIterableDataset, ExternalDataset
+from weathon.utils.dataset.manager.download_manager import DataStreamingDownloadManager
+from weathon.utils.dataset.dataset_utils import get_subdir_hash_from_split
+from weathon.utils.constants import DatasetPathName, DEFAULT_DATASET_NAMESPACE, DownloadMode
+from weathon.utils.hub.api import HubApi
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 DELIMITER_NAME = 'delimiter'
 DEFAULT_CSV_DELIMITER = ','
 
 
@@ -44,18 +37,16 @@
         self.version = dataset_context_config.version
         self.subset_name = dataset_context_config.subset_name
         self.split = dataset_context_config.split
         self.meta_data_files = dataset_context_config.data_meta_config.meta_data_files
         self.zip_data_files = dataset_context_config.data_meta_config.zip_data_files
         self.input_config_kwargs = dataset_context_config.config_kwargs
 
-        self.cache_build_dir = os.path.join(self.cache_root_dir,
-                                            self.namespace, self.dataset_name,
-                                            self.version,
-                                            DatasetPathName.META_NAME)
+        self.cache_build_dir = os.path.join(self.cache_root_dir,self.namespace, self.dataset_name,
+                                            self.version,DatasetPathName.META_NAME)
         self.csv_delimiter = DEFAULT_CSV_DELIMITER
         if DELIMITER_NAME in self.input_config_kwargs:
             self.csv_delimiter = self.input_config_kwargs[DELIMITER_NAME]
 
         split = self.split or list(dataset_context_config.data_meta_config.
                                    target_dataset_structure.keys())
         sub_dir_hash = get_subdir_hash_from_split(
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/download/download_manager.py` & `weathon-0.0.0.14/weathon/utils/dataset/manager/download_manager.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,16 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from datasets.download.download_manager import DownloadManager
-from datasets.download.streaming_download_manager import \
-    StreamingDownloadManager
+from datasets.download.streaming_download_manager import StreamingDownloadManager
 from datasets.utils.file_utils import cached_path, is_relative_path
 
-from modelscope.msdatasets.download.download_config import DataDownloadConfig
-from modelscope.msdatasets.utils.oss_utils import OssUtilities
+from weathon.utils.config.download_config import DataDownloadConfig
+from weathon.utils.dataset.oss_utils import OssUtilities
 
 
 class DataDownloadManager(DownloadManager):
 
     def __init__(self, download_config: DataDownloadConfig):
         super().__init__(
             dataset_name=download_config.dataset_name,
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/meta/data_meta_config.py` & `weathon-0.0.0.14/weathon/utils/config/data_meta_config.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+
 
 
 class DataMetaConfig(object):
     """Modelscope data-meta config class.
 
     Attributes:
         dataset_scripts(str): The local path of dataset scripts.
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/meta/data_meta_manager.py` & `weathon-0.0.0.14/weathon/utils/dataset/manager/data_meta_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import shutil
 from collections import defaultdict
 
 import json
 from datasets.utils.filelock import FileLock
 
-from modelscope.hub.api import HubApi
-from modelscope.msdatasets.context.dataset_context_config import \
-    DatasetContextConfig
-from modelscope.msdatasets.meta.data_meta_config import DataMetaConfig
-from modelscope.msdatasets.utils.dataset_utils import (
-    get_dataset_files, get_target_dataset_structure)
-from modelscope.utils.constant import (DatasetFormations, DatasetPathName,
-                                       DownloadMode)
+from weathon.utils.config.dataset_context_config import DatasetContextConfig
+from weathon.utils.config.data_meta_config import DataMetaConfig
+from weathon.utils.constants import DatasetPathName, DownloadMode, DatasetFormations
+from weathon.utils.dataset.dataset_utils import (get_dataset_files, get_target_dataset_structure)
+from weathon.utils.hub.api import HubApi
 
 
 class DataMetaManager(object):
     """Data-meta manager."""
 
     def __init__(self, dataset_context_config: DatasetContextConfig):
         self.dataset_context_config = dataset_context_config
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/ms_dataset.py` & `weathon-0.0.0.14/weathon/utils/dataset/dataset.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,56 +1,284 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
+import copy
 import os
 import warnings
-from typing import (Any, Callable, Dict, Iterable, List, Mapping, Optional,
-                    Sequence, Union)
+from traceback import format_list
+from typing import Union, Optional, Sequence, Mapping, List, Callable, Any, Dict, Iterable
 
+import datasets
 import numpy as np
-from datasets import Dataset, DatasetDict, IterableDataset, IterableDatasetDict
-from datasets.packaged_modules import _PACKAGED_DATASETS_MODULES
+import pandas as pd
+from datasets import Dataset, IterableDataset, DatasetDict, IterableDatasetDict
 from datasets.utils.file_utils import is_relative_path
 
-from modelscope.hub.repository import DatasetRepository
-from modelscope.msdatasets.context.dataset_context_config import \
-    DatasetContextConfig
-from modelscope.msdatasets.data_loader.data_loader import VirgoDownloader
-from modelscope.msdatasets.data_loader.data_loader_manager import (
-    LocalDataLoaderManager, LocalDataLoaderType, RemoteDataLoaderManager,
-    RemoteDataLoaderType)
-from modelscope.msdatasets.dataset_cls import (ExternalDataset,
-                                               NativeIterableDataset)
-from modelscope.msdatasets.dataset_cls.custom_datasets.builder import \
-    build_custom_dataset
-from modelscope.msdatasets.utils.delete_utils import DatasetDeleteManager
-from modelscope.msdatasets.utils.upload_utils import DatasetUploadManager
-from modelscope.preprocessors import build_preprocessor
-from modelscope.utils.config import Config, ConfigDict
-from modelscope.utils.config_ds import MS_DATASETS_CACHE
-from modelscope.utils.constant import (DEFAULT_DATASET_NAMESPACE,
-                                       DEFAULT_DATASET_REVISION, ConfigFields,
-                                       DownloadMode, Hubs, ModeKeys, Tasks,
-                                       UploadMode, VirgoDatasetConfig)
-from modelscope.utils.import_utils import is_tf_available, is_torch_available
-from modelscope.utils.logger import get_logger
+from weathon.base.preprocessor import build_preprocessor
+from weathon.registry import build_custom_dataset
+from weathon.utils.dataset.manager.data_delete_manager import DatasetDeleteManager
+from weathon.utils.dataset.manager.data_loader_manager import LocalDataLoaderManager, LocalDataLoaderType, \
+    RemoteDataLoaderManager, RemoteDataLoaderType
+from weathon.utils.dataset.manager.data_upload_manager import DatasetUploadManager
+from weathon.utils.dataset.maxcompute_utils import MaxComputeUtil
+from weathon.utils.config.config import Config, ConfigDict
+from weathon.utils.config.dataset_context_config import DatasetContextConfig
+from weathon.utils.constants import DEFAULT_DATASET_NAMESPACE, DEFAULT_DATASET_REVISION, Hubs, DownloadMode, \
+    MS_DATASETS_CACHE, VirgoDatasetConfig, CACHE_HOME, UploadMode, ModeKeys, ConfigFields, Tasks, EXTENSIONS_TO_LOAD, \
+    MaxComputeEnvs, DEFAULT_MAXCOMPUTE_ENDPOINT
+from weathon.utils.hub.repository import DatasetRepository
+from weathon.utils.import_utils import is_torch_available, is_tf_available
+from weathon.utils.logger import get_logger
+from weathon.utils.url_utils import valid_url, fetch_csv_with_url
 
 logger = get_logger()
 
 
-def format_list(para) -> List:
-    if para is None:
-        para = []
-    elif isinstance(para, str):
-        para = [para]
-    elif len(set(para)) < len(para):
-        raise ValueError(f'List columns contains duplicates: {para}')
-    return para
+class ExternalDataset(object):
+    """Dataset class for custom datasets."""
+
+    def __init__(self, split_path_dict, config_kwargs):
+        self.split_path_dict = split_path_dict
+        self.config_kwargs = copy.deepcopy(config_kwargs)
+        self.config_kwargs.update({'split_config': split_path_dict})
+        # dataset for specific extensions
+        self.spec_extension_dataset = None
+        self.split_data_files = {k: [] for k, _ in split_path_dict.items()}
+        self.custom_map = {}
+
+        # the extension of file
+        file_ext = ''
+        for split_name, split_dir in split_path_dict.items():
+            if isinstance(split_dir, str) and os.path.isdir(split_dir):
+                split_file_names = os.listdir(split_dir)
+                set_files_exts = set([
+                    os.path.splitext(file_name)[-1].strip('.')
+                    for file_name in split_file_names
+                ])
+                if '' in set_files_exts:
+                    continue
+                # ensure these files have same extensions
+                if len(set_files_exts) != 1:
+                    supported_exts = ','.join(EXTENSIONS_TO_LOAD.keys())
+                    logger.error(
+                        f'Split-{split_name} has been ignored, please flatten your folder structure, '
+                        f'and make sure these files have same extensions. '
+                        f'Supported extensions: {supported_exts} .')
+                    continue
+                file_ext = list(set_files_exts)[0]
+                if file_ext not in EXTENSIONS_TO_LOAD:
+                    continue
+
+                split_file_paths = [
+                    os.path.join(split_dir, file_name)
+                    for file_name in split_file_names
+                ]
+                self.split_data_files[split_name] = split_file_paths
+
+        if file_ext:
+            file_ext = EXTENSIONS_TO_LOAD.get(file_ext)
+            self.spec_extension_dataset = datasets.load_dataset(file_ext, data_files=self.split_data_files,
+                                                                **config_kwargs)
+
+    def __len__(self):
+        return len(
+            self.split_path_dict
+        ) if not self.spec_extension_dataset else self.spec_extension_dataset.__len__(
+        )
+
+    def __getitem__(self, item):
+        if not self.spec_extension_dataset:
+            return self.split_path_dict.get(item)
+        else:
+            return self.spec_extension_dataset.__getitem__(item)
+
+    def __iter__(self):
+        if not self.spec_extension_dataset:
+            for k, v in self.split_path_dict.items():
+                yield k, v
+        else:
+            for k, v in self.spec_extension_dataset.items():
+                yield k, v
+
+
+class NativeIterableDataset(IterableDataset):
+    """The modelscope iterable dataset class."""
+
+    def __init__(self, ex_iterable, info, split):
+        super().__init__(ex_iterable=ex_iterable, info=info, split=split)
+
+    def __iter__(self):
+        for key, entity in self._iter():
+            if isinstance(entity, dict):
+                ret = {}
+                for k, v in entity.items():
+                    ret[k] = v
+                    if k.endswith(':FILE'):
+                        dl_manager = self._ex_iterable.kwargs.get('dl_manager')
+                        ex_cache_path = dl_manager.download_and_extract(v)
+                        ret[k] = ex_cache_path
+                        if k.endswith('Image:FILE'):
+                            from PIL import Image
+                            ret[k + ':Object'] = Image.open(fp=ex_cache_path)
+                        if k.endswith('Audio:FILE'):
+                            import torchaudio
+                            waveform_and_rate = torchaudio.load(ex_cache_path)
+                            ret[k + ':Object'] = waveform_and_rate
+                entity = ret
 
+            yield entity
 
-class MsDataset:
+    def __len__(self):
+        return 1
+
+
+class VirgoDataset(object):
+    """Dataset class for Virgo.
+
+    Attributes:
+        _meta_content (str): Virgo meta data content, could be a url that contains csv file.
+        _data_type (int): Virgo dataset type, 0-Standard virgo dataset; Others-User define dataset (to be supported)
+
+    Examples:
+        >>> from weathon.utils.dataset.dataset import VirgoDataset
+        >>> input_kwargs = {'metaContent': 'http://xxx-xxx/xxx.csv', 'samplingType': 0}
+        >>> virgo_dataset = VirgoDataset(**input_kwargs)
+        >>> print(virgo_dataset[1])
+        >>> print(len(virgo_dataset))
+        >>> for line in virgo_dataset:
+        >>>     print(line)
+
+        Note: If you set `download_virgo_files` to True by using
+            MsDataset.load(dataset_name='your-virgo-dataset-id', hub=Hubs.virgo, download_virgo_files=True),
+            you can get the cache file path of the virgo dataset, the column name is `cache_file`.
+        >>> if virgo_dataset.download_virgo_files:
+        >>>     print(virgo_dataset[1].get('cache_file'))
+    """
+
+    def __init__(self, **kwargs):
+
+        self._meta_content: str = ''
+        self.data_type: int = 0
+        self.odps_table_name: str = ''
+        self.odps_table_partition: str = None
+        self._odps_utils: MaxComputeUtil = None
+        self.config_kwargs = kwargs
+
+        self._meta: pd.DataFrame = pd.DataFrame()
+
+        self._meta_content = self.config_kwargs.pop(VirgoDatasetConfig.meta_content, '')
+        self.data_type = self.config_kwargs.pop(VirgoDatasetConfig.sampling_type, 0)
+
+        self._check_variables()
+        self._parse_meta()
+
+        self.meta_content_cache_file = ''
+        self.virgo_cache_dir = ''
+        self.download_virgo_files: bool = False
+
+        self.odps_table_ins = None
+        self.odps_reader_ins = None
+        self.odps_batch_size = self.config_kwargs.pop('odps_batch_size', 100)
+        self.odps_limit = self.config_kwargs.pop('odps_limit', None)
+        self.odps_drop_last = self.config_kwargs.pop('odps_drop_last', False)
+        if self._odps_utils:
+            self.odps_table_ins, self.odps_reader_ins = self._odps_utils.get_table_reader_ins(
+                self.odps_table_name, self.odps_table_partition)
+
+    def __getitem__(self, index):
+        if self.odps_reader_ins:
+            return MaxComputeUtil.gen_reader_item(
+                reader=self.odps_reader_ins,
+                index=index,
+                batch_size_in=self.odps_batch_size,
+                limit_in=self.odps_limit,
+                drop_last_in=self.odps_drop_last,
+                partitions=self.odps_table_ins.table_schema.partitions,
+                columns=self.odps_table_ins.table_schema.names)
+        return self._meta.iloc[index].to_dict()
+
+    def __len__(self):
+        if isinstance(self._meta, dict):
+            return self._meta.get('odpsCount', 0)
+        return len(self._meta)
+
+    def __iter__(self):
+        if self.odps_reader_ins:
+            odps_batch_data = MaxComputeUtil.gen_reader_batch(
+                reader=self.odps_reader_ins,
+                batch_size_in=self.odps_batch_size,
+                limit_in=self.odps_limit,
+                drop_last_in=self.odps_drop_last,
+                partitions=self.odps_table_ins.table_schema.partitions,
+                columns=self.odps_table_ins.table_schema.names)
+            for batch in odps_batch_data:
+                yield batch
+        else:
+            for _, row in self._meta.iterrows():
+                yield row.to_dict()
+
+    @property
+    def meta(self) -> pd.DataFrame:
+        """
+        Virgo meta data. Contains columns: id, meta_info, analysis_result, external_info and
+            cache_file (if download_virgo_files is True).
+        """
+        return self._meta
+
+    def _parse_meta(self):
+        # Fetch csv content
+        if isinstance(self._meta_content, str) and valid_url(self._meta_content):
+            meta_content_df = fetch_csv_with_url(self._meta_content)
+            self._meta = meta_content_df
+        elif isinstance(self._meta_content, dict):
+            self._meta = self._meta_content
+            self.odps_table_name = self._meta.get('odpsTableName', '')
+            self.odps_table_partition = self._meta.get('odpsTablePartition', None)
+            self._odps_utils = self._get_odps_info()
+        else:
+            raise 'The meta content must be url or dict.'
+
+    @staticmethod
+    def _get_odps_info() -> MaxComputeUtil:
+        """
+        Get MaxComputeUtil instance.
+
+        Args:
+            None
+
+        Returns:
+            MaxComputeUtil instance.
+        """
+        access_id = os.environ.get(MaxComputeEnvs.ACCESS_ID, '')
+        access_key = os.environ.get(MaxComputeEnvs.ACCESS_SECRET_KEY, '')
+        proj_name = os.environ.get(MaxComputeEnvs.PROJECT_NAME, '')
+        endpoint = os.environ.get(MaxComputeEnvs.ENDPOINT, DEFAULT_MAXCOMPUTE_ENDPOINT)
+
+        if not access_id or not access_key or not proj_name:
+            raise ValueError(
+                f'Please set MaxCompute envs for Virgo: {MaxComputeEnvs.ACCESS_ID}, '
+                f'{MaxComputeEnvs.ACCESS_SECRET_KEY}, {MaxComputeEnvs.PROJECT_NAME}, '
+                f'{MaxComputeEnvs.ENDPOINT}(default: http://service-corp.odps.aliyun-inc.com/api)'
+            )
+
+        return MaxComputeUtil(access_id, access_key, proj_name, endpoint)
+
+    def _check_variables(self):
+        """Check member variables in this class.
+            1. Condition-1: self._meta_content cannot be empty
+            2. Condition-2: self._meta_content must be url when self._data_type is 0
+        """
+        if not self._meta_content:
+            raise 'Them meta content cannot be empty.'
+        if self.data_type not in [0, 1]:
+            raise 'Supported samplingType should be 0 or 1, others are not supported yet.'
+        if self.data_type == 0 and not valid_url(self._meta_content):
+            raise 'The meta content must be url when data type is 0.'
+        if self.data_type == 1 and not isinstance(self._meta_content, dict):
+            raise 'The meta content must be dict when data type is 1.'
+
+
+class WtDataset:
     """
     ModelScope Dataset (aka, MsDataset) is backed by a huggingface Dataset to
     provide efficient data access and local storage managements. On top of
     that, MsDataset supports the data integration and interactions with multiple
     remote hubs, particularly, ModelScope's own Dataset-hub. MsDataset also
     abstracts away data-access details with other remote storage, including both
     general external web-hosted data and cloud storage such as OSS.
@@ -77,16 +305,15 @@
             else:
                 yield item
 
     def __getitem__(self, key):
         return self._hf_ds[key]
 
     def __len__(self):
-        if isinstance(self._hf_ds, IterableDataset) or isinstance(
-                self._hf_ds, NativeIterableDataset):
+        if isinstance(self._hf_ds, IterableDataset) or isinstance(self._hf_ds, NativeIterableDataset):
             logger.warning(
                 f'object of type `{self._hf_ds.__class__.__name__}` has default length 1'
             )
             return 1
         return len(self._hf_ds)
 
     @property
@@ -104,35 +331,31 @@
     def from_hf_dataset(cls,
                         hf_ds: Union[Dataset, DatasetDict, ExternalDataset],
                         target: str = None) -> Union[dict, 'MsDataset']:
         r"""
         @deprecated
         This method is deprecated and may be removed in future releases, please use `to_ms_dataset()` instead.
         """
-        warnings.warn(
-            'from_hf_dataset is deprecated, please use to_ms_dataset instead.',
-            DeprecationWarning)
+        warnings.warn('from_hf_dataset is deprecated, please use to_ms_dataset instead.', DeprecationWarning)
         if isinstance(hf_ds, Dataset):
             return cls(hf_ds, target)
         elif isinstance(hf_ds, DatasetDict):
             if len(hf_ds.keys()) == 1:
                 return cls(next(iter(hf_ds.values())), target)
             return {k: cls(v, target) for k, v in hf_ds.items()}
         elif isinstance(hf_ds, ExternalDataset):
             return cls(hf_ds)
         else:
-            raise TypeError(
-                f'"hf_ds" must be a Dataset or DatasetDict, but got {type(hf_ds)}'
-            )
+            raise TypeError(f'"hf_ds" must be a Dataset or DatasetDict, but got {type(hf_ds)}')
 
     @classmethod
     def to_ms_dataset(cls,
                       ds_instance: Union[Dataset, DatasetDict, ExternalDataset,
-                                         NativeIterableDataset,
-                                         IterableDataset, IterableDatasetDict],
+                      NativeIterableDataset,
+                      IterableDataset, IterableDatasetDict],
                       target: str = None) -> Union[dict, 'MsDataset']:
         """Convert input to `MsDataset` instance."""
         if isinstance(ds_instance, Dataset):
             return cls(ds_instance, target)
         elif isinstance(ds_instance, DatasetDict):
             if len(ds_instance.keys()) == 1:
                 return cls(next(iter(ds_instance.values())), target)
@@ -150,31 +373,31 @@
         else:
             raise TypeError(
                 f'"ds_instance" must be a Dataset or DatasetDict, but got {type(ds_instance)}'
             )
 
     @staticmethod
     def load(
-        dataset_name: Union[str, list],
-        namespace: Optional[str] = DEFAULT_DATASET_NAMESPACE,
-        target: Optional[str] = None,
-        version: Optional[str] = DEFAULT_DATASET_REVISION,
-        hub: Optional[Hubs] = Hubs.modelscope,
-        subset_name: Optional[str] = None,
-        split: Optional[str] = None,
-        data_dir: Optional[str] = None,
-        data_files: Optional[Union[str, Sequence[str],
-                                   Mapping[str, Union[str,
-                                                      Sequence[str]]]]] = None,
-        download_mode: Optional[DownloadMode] = DownloadMode.
-        REUSE_DATASET_IF_EXISTS,
-        cache_dir: Optional[str] = MS_DATASETS_CACHE,
-        use_streaming: Optional[bool] = False,
-        custom_cfg: Optional[Config] = Config(),
-        **config_kwargs,
+            dataset_name: Union[str, list],
+            namespace: Optional[str] = DEFAULT_DATASET_NAMESPACE,
+            target: Optional[str] = None,
+            version: Optional[str] = DEFAULT_DATASET_REVISION,
+            hub: Optional[Hubs] = Hubs.modelscope,
+            subset_name: Optional[str] = None,
+            split: Optional[str] = None,
+            data_dir: Optional[str] = None,
+            data_files: Optional[Union[str, Sequence[str],
+            Mapping[str, Union[str,
+            Sequence[str]]]]] = None,
+            download_mode: Optional[DownloadMode] = DownloadMode.
+            REUSE_DATASET_IF_EXISTS,
+            cache_dir: Optional[str] = MS_DATASETS_CACHE,
+            use_streaming: Optional[bool] = False,
+            custom_cfg: Optional[Config] = Config(),
+            **config_kwargs,
     ) -> Union[dict, 'MsDataset', NativeIterableDataset]:
         """Load a MsDataset from the ModelScope Hub, Hugging Face Hub, urls, or a local dataset.
 
             Args:
                 dataset_name (str): Path or name of the dataset.
                     The form of `namespace/dataset_name` is also supported.
                 namespace(str, optional): Namespace of the dataset. It should not be None if you load a remote dataset
@@ -213,15 +436,15 @@
                 f'dataset_name must be `str` or `list`, but got {type(dataset_name)}'
             )
 
         if isinstance(dataset_name, list):
             if target is None:
                 target = 'target'
             dataset_inst = Dataset.from_dict({target: dataset_name})
-            return MsDataset.to_ms_dataset(dataset_inst, target=target)
+            return WtDataset.to_ms_dataset(dataset_inst, target=target)
 
         dataset_name = os.path.expanduser(dataset_name)
         is_local_path = os.path.exists(dataset_name)
         if is_relative_path(dataset_name) and dataset_name.count(
                 '/') == 1 and not is_local_path:
             dataset_name_split = dataset_name.split('/')
             namespace = dataset_name_split[0].strip()
@@ -242,61 +465,54 @@
             data_files=data_files,
             download_mode=download_mode,
             cache_root_dir=cache_dir,
             use_streaming=use_streaming,
             **config_kwargs)
 
         # Load from local disk
-        if dataset_name in _PACKAGED_DATASETS_MODULES or os.path.isdir(
-                dataset_name) or os.path.isfile(dataset_name):
-            dataset_inst = LocalDataLoaderManager(
-                dataset_context_config).load_dataset(
-                    LocalDataLoaderType.HF_DATA_LOADER)
-            dataset_inst = MsDataset.to_ms_dataset(dataset_inst, target=target)
-            if isinstance(dataset_inst, MsDataset):
+        if dataset_name in _PACKAGED_DATASETS_MODULES or os.path.isdir(dataset_name) or os.path.isfile(dataset_name):
+            dataset_inst = LocalDataLoaderManager(dataset_context_config).load_dataset(
+                LocalDataLoaderType.HF_DATA_LOADER)
+            dataset_inst = WtDataset.to_ms_dataset(dataset_inst, target=target)
+            if isinstance(dataset_inst, WtDataset):
                 dataset_inst._dataset_context_config = dataset_context_config
                 if custom_cfg:
                     dataset_inst.to_custom_dataset(
                         custom_cfg=custom_cfg, **config_kwargs)
                     dataset_inst.is_custom = True
             return dataset_inst
         # Load from the huggingface hub
         elif hub == Hubs.huggingface:
-            dataset_inst = RemoteDataLoaderManager(
-                dataset_context_config).load_dataset(
-                    RemoteDataLoaderType.HF_DATA_LOADER)
-            dataset_inst = MsDataset.to_ms_dataset(dataset_inst, target=target)
+            dataset_inst = RemoteDataLoaderManager(dataset_context_config).load_dataset(
+                RemoteDataLoaderType.HF_DATA_LOADER)
+            dataset_inst = WtDataset.to_ms_dataset(dataset_inst, target=target)
             dataset_inst._dataset_context_config = dataset_context_config
             if custom_cfg:
-                dataset_inst.to_custom_dataset(
-                    custom_cfg=custom_cfg, **config_kwargs)
+                dataset_inst.to_custom_dataset(custom_cfg=custom_cfg, **config_kwargs)
                 dataset_inst.is_custom = True
             return dataset_inst
         # Load from the modelscope hub
         elif hub == Hubs.modelscope:
-            remote_dataloader_manager = RemoteDataLoaderManager(
-                dataset_context_config)
-            dataset_inst = remote_dataloader_manager.load_dataset(
-                RemoteDataLoaderType.MS_DATA_LOADER)
-            dataset_inst = MsDataset.to_ms_dataset(dataset_inst, target=target)
-            if isinstance(dataset_inst, MsDataset):
+            from weathon.utils.dataset.data_loader import VirgoDownloader
+            remote_dataloader_manager = RemoteDataLoaderManager(dataset_context_config)
+            dataset_inst = remote_dataloader_manager.load_dataset(RemoteDataLoaderType.MS_DATA_LOADER)
+            dataset_inst = WtDataset.to_ms_dataset(dataset_inst, target=target)
+            if isinstance(dataset_inst, WtDataset):
                 dataset_inst._dataset_context_config = remote_dataloader_manager.dataset_context_config
                 if custom_cfg:
-                    dataset_inst.to_custom_dataset(
-                        custom_cfg=custom_cfg, **config_kwargs)
+                    dataset_inst.to_custom_dataset(custom_cfg=custom_cfg, **config_kwargs)
                     dataset_inst.is_custom = True
             return dataset_inst
         elif hub == Hubs.virgo:
             # Rewrite the namespace, version and cache_dir for virgo dataset.
             if namespace == DEFAULT_DATASET_NAMESPACE:
                 dataset_context_config.namespace = VirgoDatasetConfig.default_virgo_namespace
             if version == DEFAULT_DATASET_REVISION:
                 dataset_context_config.version = VirgoDatasetConfig.default_dataset_version
             if cache_dir == MS_DATASETS_CACHE:
-                from modelscope.utils.config_ds import CACHE_HOME
                 cache_dir = os.path.join(CACHE_HOME, 'virgo', 'hub',
                                          'datasets')
                 dataset_context_config.cache_root_dir = cache_dir
 
             virgo_downloader = VirgoDownloader(dataset_context_config)
             virgo_downloader.process()
 
@@ -339,16 +555,15 @@
         Returns:
             None
 
         """
         if not object_name:
             raise ValueError('object_name cannot be empty!')
 
-        _upload_manager = DatasetUploadManager(
-            dataset_name=dataset_name, namespace=namespace, version=version)
+        _upload_manager = DatasetUploadManager(dataset_name=dataset_name, namespace=namespace, version=version)
 
         upload_mode = UploadMode(upload_mode or UploadMode.OVERWRITE)
 
         if os.path.isfile(local_file_path):
             _upload_manager.upload(
                 object_name=object_name,
                 local_file_path=local_file_path,
@@ -383,20 +598,16 @@
                 as the token is already saved when you login the first time, if None, we will use saved token.
             git_path (str, optional):
                 The git command line path, if None, we use 'git'
         Returns:
             None
         """
 
-        _repo = DatasetRepository(
-            repo_work_dir=dataset_work_dir,
-            dataset_id=dataset_id,
-            revision=revision,
-            auth_token=auth_token,
-            git_path=git_path)
+        _repo = DatasetRepository(repo_work_dir=dataset_work_dir, dataset_id=dataset_id, revision=revision,
+                                  auth_token=auth_token, git_path=git_path)
         clone_work_dir = _repo.clone()
         if clone_work_dir:
             logger.info('Already cloned repo to: {}'.format(clone_work_dir))
         else:
             logger.warning(
                 'Repo dir already exists: {}'.format(clone_work_dir))
 
@@ -448,28 +659,27 @@
             namespace(str, optional): Namespace of the dataset.
             version (str, optional): Version of the dataset.
 
         Returns:
             res_msg (str): Response message.
 
         """
-        _delete_manager = DatasetDeleteManager(
-            dataset_name=dataset_name, namespace=namespace, version=version)
+        _delete_manager = DatasetDeleteManager(dataset_name=dataset_name, namespace=namespace, version=version)
         resp_msg = _delete_manager.delete(object_name=object_name)
         logger.info(f'Object {object_name} successfully removed!')
         return resp_msg
 
     def to_torch_dataset(
-        self,
-        columns: Union[str, List[str]] = None,
-        preprocessors: Union[Callable, List[Callable]] = None,
-        task_name: str = None,
-        data_config: ConfigDict = None,
-        to_tensor: bool = True,
-        **format_kwargs,
+            self,
+            columns: Union[str, List[str]] = None,
+            preprocessors: Union[Callable, List[Callable]] = None,
+            task_name: str = None,
+            data_config: ConfigDict = None,
+            to_tensor: bool = True,
+            **format_kwargs,
     ):
         """Create a torch.utils.data.Dataset from the MS Dataset. The torch.utils.data.Dataset can be passed to
            torch.utils.data.DataLoader.
 
         Args:
             preprocessors (Callable or List[Callable], default None): (list of) Preprocessor object used to process
                 every sample of the dataset. The output type of processors is dict, and each (numeric) field of the dict
@@ -505,24 +715,24 @@
         else:
             self._hf_ds.reset_format()
             self._hf_ds.set_format(
                 type='torch', columns=columns, format_kwargs=format_kwargs)
             return self._hf_ds
 
     def to_tf_dataset(
-        self,
-        batch_size: int,
-        shuffle: bool,
-        preprocessors: Union[Callable, List[Callable]] = None,
-        columns: Union[str, List[str]] = None,
-        collate_fn: Callable = None,
-        drop_remainder: bool = None,
-        collate_fn_args: Dict[str, Any] = None,
-        label_cols: Union[str, List[str]] = None,
-        prefetch: bool = True,
+            self,
+            batch_size: int,
+            shuffle: bool,
+            preprocessors: Union[Callable, List[Callable]] = None,
+            columns: Union[str, List[str]] = None,
+            collate_fn: Callable = None,
+            drop_remainder: bool = None,
+            collate_fn_args: Dict[str, Any] = None,
+            label_cols: Union[str, List[str]] = None,
+            prefetch: bool = True,
     ):
         """Create a tf.data.Dataset from the MS Dataset. This tf.data.Dataset can be passed to tf methods like
            model.fit() or model.predict().
 
         Args:
             batch_size (int): Number of samples in a single batch.
             shuffle(bool): Shuffle the dataset order.
@@ -587,18 +797,18 @@
         Returns:
             underlying hf dataset
         """
         self._hf_ds.reset_format()
         return self._hf_ds.rename_columns(column_mapping)
 
     def _to_torch_dataset_with_processors(
-        self,
-        preprocessors: Union[Callable, List[Callable]],
-        columns: Union[str, List[str]] = None,
-        to_tensor: bool = True,
+            self,
+            preprocessors: Union[Callable, List[Callable]],
+            columns: Union[str, List[str]] = None,
+            to_tensor: bool = True,
     ):
         preprocessor_list = preprocessors if isinstance(
             preprocessors, list) else [preprocessors]
 
         columns = format_list(columns)
 
         columns = [
@@ -625,20 +835,20 @@
                         f'Data of column {k} is non-numeric, will be removed')
                     retained_unumeric_columns.append(k)
                     continue
                 retained_numeric_columns.append(k)
 
         import torch
 
-        class MsMapDataset(torch.utils.data.Dataset):
+        class WtMapDataset(torch.utils.data.Dataset):
 
             def __init__(self, dataset: Iterable, preprocessor_list,
                          retained_numeric_columns, retained_unumeric_columns,
                          columns, to_tensor):
-                super(MsDataset).__init__()
+                super(WtDataset).__init__()
                 self.dataset = dataset
                 self.preprocessor_list = preprocessor_list
                 self.to_tensor = to_tensor
                 self.retained_numeric_columns = retained_numeric_columns
                 self.retained_unumeric_columns = retained_unumeric_columns
                 self.columns = columns
 
@@ -652,38 +862,36 @@
                     return x
 
             def __getitem__(self, index):
                 item_dict = self.dataset[index]
                 res = {
                     k: self.type_converter(item_dict[k])
                     for k in self.columns if (not self.to_tensor)
-                    or k in self.retained_numeric_columns
+                                             or k in self.retained_numeric_columns
                 }
                 for preprocessor in self.preprocessor_list:
                     for k, v in preprocessor(item_dict).items():
-                        if (not self.to_tensor) or \
-                                k in self.retained_numeric_columns:
+                        if (not self.to_tensor) or k in self.retained_numeric_columns:
                             res[k] = self.type_converter(v)
                         elif k in self.retained_unumeric_columns:
                             res[k] = v
                 return res
 
-        return MsMapDataset(self._hf_ds, preprocessor_list,
-                            retained_numeric_columns,
-                            retained_unumeric_columns, columns, to_tensor)
+        return WtMapDataset(self._hf_ds, preprocessor_list, retained_numeric_columns, retained_unumeric_columns,
+                            columns, to_tensor)
 
     def _to_tf_dataset_with_processors(
-        self,
-        batch_size: int,
-        shuffle: bool,
-        preprocessors: Union[Callable, List[Callable]],
-        drop_remainder: bool = None,
-        prefetch: bool = True,
-        label_cols: Union[str, List[str]] = None,
-        columns: Union[str, List[str]] = None,
+            self,
+            batch_size: int,
+            shuffle: bool,
+            preprocessors: Union[Callable, List[Callable]],
+            drop_remainder: bool = None,
+            prefetch: bool = True,
+            label_cols: Union[str, List[str]] = None,
+            columns: Union[str, List[str]] = None,
     ):
         preprocessor_list = preprocessors if isinstance(
             preprocessors, list) else [preprocessors]
 
         label_cols = format_list(label_cols)
         columns = format_list(columns)
         cols_to_retain = list(set(label_cols + columns))
@@ -764,17 +972,15 @@
             mode (str, Optional): See modelscope.utils.constant.ModeKeys
 
         Returns:
             `MsDataset`
         """
 
         if not is_torch_available():
-            raise ImportError(
-                'The function to_custom_dataset requires pytorch to be installed'
-            )
+            raise ImportError('The function to_custom_dataset requires pytorch to be installed')
         if not custom_cfg:
             return
 
         # Set the flag that it has been converted to custom dataset
         self.is_custom = True
 
         # Check mode
@@ -802,19 +1008,17 @@
             if preprocessor_cfg:
                 preprocessor = build_preprocessor(preprocessor_cfg, field_name)
 
         # Build custom dataset
         if isinstance(self._hf_ds, ExternalDataset):
             data_cfg.update(dict(preprocessor=preprocessor))
             data_cfg.update(self._hf_ds.config_kwargs)
-            self._hf_ds = build_custom_dataset(
-                cfg=data_cfg, task_name=custom_cfg.task)
+            self._hf_ds = build_custom_dataset(cfg=data_cfg, task_name=custom_cfg.task)
             return
 
         if preprocessor is not None:
             to_tensor = kwargs.get('to_tensor', True)
-            self._hf_ds = self._to_torch_dataset_with_processors(
-                preprocessors=preprocessor, to_tensor=to_tensor)
+            self._hf_ds = self._to_torch_dataset_with_processors(preprocessors=preprocessor, to_tensor=to_tensor)
         else:
             self._hf_ds.reset_format()
             self._hf_ds.set_format(type='torch')
         return
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/utils/dataset_utils.py` & `weathon-0.0.0.14/weathon/utils/dataset/dataset_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from collections import defaultdict
 from typing import Optional, Union
 
-from modelscope.hub.api import HubApi
-from modelscope.utils.constant import DEFAULT_DATASET_REVISION, MetaDataFields
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import DEFAULT_DATASET_REVISION, MetaDataFields
+from weathon.utils.hub.api import HubApi
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def format_dataset_structure(dataset_structure):
     return {
         k: v
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/utils/delete_utils.py` & `weathon-0.0.0.14/weathon/utils/dataset/manager/data_delete_manager.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,8 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from modelscope.hub.api import HubApi
+from weathon.utils.hub.api import HubApi
 
 
 class DatasetDeleteManager(object):
 
     def __init__(self, dataset_name: str, namespace: str, version: str):
         self.api = HubApi()
         self.dataset_name = dataset_name
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/utils/maxcompute_utils.py` & `weathon-0.0.0.14/weathon/utils/dataset/maxcompute_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 
 import pandas as pd
 
 
 class MaxComputeUtil:
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/utils/oss_utils.py` & `weathon-0.0.0.14/weathon/utils/dataset/oss_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from __future__ import print_function
 import multiprocessing
 import os
 
 import oss2
 from datasets.utils.file_utils import hash_url_to_filename
 
-from modelscope.hub.api import HubApi
-from modelscope.msdatasets.download.download_config import DataDownloadConfig
-from modelscope.utils.config_ds import MS_CACHE_HOME
-from modelscope.utils.constant import (DEFAULT_DATA_ACCELERATION_ENDPOINT,
-                                       MetaDataFields, UploadMode)
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import MS_CACHE_HOME, DEFAULT_DATA_ACCELERATION_ENDPOINT, MetaDataFields, UploadMode
+from weathon.utils.hub.api import HubApi
+from weathon.utils.config.download_config import DataDownloadConfig
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 ACCESS_ID = 'AccessId'
 ACCESS_SECRET = 'AccessSecret'
 SECURITY_TOKEN = 'SecurityToken'
 BUCKET = 'Bucket'
```

### Comparing `weathon-0.0.0.13/weathon/dl/msdatasets/utils/upload_utils.py` & `weathon-0.0.0.14/weathon/utils/dataset/manager/data_upload_manager.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,22 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from multiprocessing.dummy import Pool as ThreadPool
 
 from tqdm import tqdm
 
-from modelscope.msdatasets.utils.oss_utils import OssUtilities
-from modelscope.utils.constant import UploadMode
+from weathon.utils.constants import UploadMode
+from weathon.utils.dataset.oss_utils import OssUtilities
 
 
 class DatasetUploadManager(object):
 
     def __init__(self, dataset_name: str, namespace: str, version: str):
-        from modelscope.hub.api import HubApi
+        from weathon.utils.hub.api import HubApi
         _hub_api = HubApi()
         _oss_config = _hub_api.get_dataset_access_config_session(
             dataset_name=dataset_name,
             namespace=namespace,
             check_cookie=False,
             revision=version)
```

### Comparing `weathon-0.0.0.13/weathon/dl/ops/ailut/pyinterfaces.py` & `weathon-0.0.0.14/weathon/utils/ops/ailut/pyinterfaces.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/functions/quadtree_attention.py` & `weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/functions/quadtree_attention.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from pathlib import Path
 
 import torch
 from einops.einops import rearrange
 from torch.autograd import Function
 from torch.utils.cpp_extension import load
```

### Comparing `weathon-0.0.0.13/weathon/dl/ops/quadtree_attention/modules/quadtree_attention.py` & `weathon-0.0.0.14/weathon/utils/ops/quadtree_attention/modules/quadtree_attention.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
-import torch.nn.functional as F
 from einops.einops import rearrange
 
-from modelscope.ops.quadtree_attention.functions.quadtree_attention import (
+from weathon.utils.ops.quadtree_attention.functions.quadtree_attention import (
     score_computation_op, value_aggregation_op)
 
 
 class QTAttA(nn.Module):
 
     def __init__(
         self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/outputs/cv_outputs.py` & `weathon-0.0.0.14/weathon/utils/output/cv_outputs.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,21 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from dataclasses import dataclass
-from typing import Optional, Tuple, Union
-
-import numpy as np
+from typing import Union
 
-from modelscope.outputs.outputs import ModelOutputBase
+from weathon.base import BaseModelOutput
 
 Tensor = Union['torch.Tensor', 'tf.Tensor']
 
 
 @dataclass
-class DetectionOutput(ModelOutputBase):
+class DetectionOutput(BaseModelOutput):
     """The output class for object detection models.
 
     Args:
         class_ids (`Tensor`, *optional*): class id for each object.
         boxes (`Tensor`, *optional*): Bounding box for each detected object in  [left, top, right, bottom] format.
         scores (`Tensor`, *optional*): Detection score for each object.
         keypoints (`Tensor`, *optional*): Keypoints for each object using four corner points in a 8-dim tensor
```

### Comparing `weathon-0.0.0.13/weathon/dl/outputs/nlp_outputs.py` & `weathon-0.0.0.14/weathon/utils/output/nlp_outputs.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from dataclasses import dataclass
 from typing import List, Optional, Tuple, Union
 
 import numpy as np
 
-from modelscope.outputs.outputs import ModelOutputBase
+from weathon.base import BaseModelOutput
 
 Tensor = Union['torch.Tensor', 'tf.Tensor']
 
 
 @dataclass
-class BackboneModelOutput(ModelOutputBase):
+class BackboneModelOutput(BaseModelOutput):
     """The output class for text classification models.
 
     Args:
         last_hidden_state (`Tensor`, *optional*): Sequence of hidden-states at
             the output of the last layer of the model.
         pooler_output (`Tensor`, *optional*) The tensor of the pooled hidden state.
         hidden_states (`Tensor`, *optional*) Hidden-states of the model at
@@ -64,15 +64,15 @@
     """
     attentions: Tensor = None
     past_key_values: Tensor = None
     cross_attentions: Tensor = None
 
 
 @dataclass
-class Seq2SeqModelOutput(ModelOutputBase):
+class Seq2SeqModelOutput(BaseModelOutput):
     """
     Base class for model encoder's outputs that also contains : pre-computed
     hidden states that can speed up sequential decoding.
 
     Args:
         last_hidden_state (`torch.FloatTensor` of shape `(batch_size,
         sequence_length, hidden_size)`):
@@ -148,34 +148,34 @@
     cross_attentions: Optional[Tuple[Tensor]] = None
     encoder_last_hidden_state: Optional[Tensor] = None
     encoder_hidden_states: Optional[Tuple[Tensor]] = None
     encoder_attentions: Optional[Tuple[Tensor]] = None
 
 
 @dataclass
-class FaqQuestionAnsweringOutput(ModelOutputBase):
+class FaqQuestionAnsweringOutput(BaseModelOutput):
     """The output class for faq QA models.
     """
 
     scores: Tensor = None
     labels: Tensor = None
     loss: Tensor = None
     logits: Tensor = None
 
 
 @dataclass
-class FeatureExtractionOutput(ModelOutputBase):
+class FeatureExtractionOutput(BaseModelOutput):
     """The output class for feature extraction models.
     """
 
     text_embedding: Tensor = None
 
 
 @dataclass
-class FillMaskModelOutput(ModelOutputBase):
+class FillMaskModelOutput(BaseModelOutput):
     """The output class for fill mask models.
 
     Args:
         logits (`Tensor`): The logits output of the model.
         loss (`Tensor`, *optional*) The loss of the model, available when training.
         input_ids (`Tensor`, *optional*) The input id tensor fed into the model.
         hidden_states (`Tensor`, *optional*) Hidden-states of the model at the
@@ -197,23 +197,23 @@
         attention softmax, used to compute the weighted average in the
         self-attention heads.
     """
     attentions: Tensor = None
 
 
 @dataclass
-class InformationExtractionOutput(ModelOutputBase):
+class InformationExtractionOutput(BaseModelOutput):
     """The output class for information extraction models.
     """
 
     spo_list: np.ndarray = None
 
 
 @dataclass
-class Seq2SeqLMOutput(ModelOutputBase):
+class Seq2SeqLMOutput(BaseModelOutput):
     """
     Base class for sequence-to-sequence language models outputs.
 
     Args:
         loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when
         `labels` is provided):
             Language modeling loss.
@@ -289,15 +289,15 @@
     cross_attentions: Optional[Tuple[Tensor]] = None
     encoder_last_hidden_state: Optional[Tensor] = None
     encoder_hidden_states: Optional[Tuple[Tensor]] = None
     encoder_attentions: Optional[Tuple[Tensor]] = None
 
 
 @dataclass
-class TextClassificationModelOutput(ModelOutputBase):
+class TextClassificationModelOutput(BaseModelOutput):
     """The output class for text classification models.
 
     Args:
         logits (`Tensor`): The logits output of the model. loss (`Tensor`,
         *optional*) The loss of the model, available when training.
         hidden_states (`Tensor`, *optional*) Hidden-states of the model at the
         output of each layer plus the optional initial embedding outputs.
@@ -318,31 +318,31 @@
     """
     attentions: Tensor = None
     hidden_states: Tensor = None
     past_key_values: Tensor = None
 
 
 @dataclass
-class TextErrorCorrectionOutput(ModelOutputBase):
+class TextErrorCorrectionOutput(BaseModelOutput):
     """The output class for information extraction models.
     """
 
     predictions: np.ndarray = None
 
 
 @dataclass
-class WordAlignmentOutput(ModelOutputBase):
+class WordAlignmentOutput(BaseModelOutput):
     """The output class for word alignment models.
     """
 
     predictions: List = None
 
 
 @dataclass
-class TextGenerationModelOutput(ModelOutputBase):
+class TextGenerationModelOutput(BaseModelOutput):
     """The output class for text generation models.
 
     Args:
         logits (`Tensor`): The logits output of the model. loss (`Tensor`,
         *optional*) The loss of the model, available when training.
         hidden_states (`Tensor`, *optional*) Hidden-states of the model at the
         output of each layer plus the optional initial embedding outputs.
@@ -364,15 +364,15 @@
     """
     attentions: Tensor = None
     hidden_states: Tensor = None
     past_key_values: Tensor = None
 
 
 @dataclass
-class TokenGeneratorOutput(ModelOutputBase):
+class TokenGeneratorOutput(BaseModelOutput):
     """
     The output class for generate method of text generation models.
 
 
     Args:
         sequences (`torch.LongTensor` of shape `(batch_size*num_return_sequences, sequence_length)`):
             The generated sequences. The second dimension (sequence_length) is either equal to `max_length` or shorter
@@ -396,15 +396,15 @@
     sequences: Tensor = None
     scores: Optional[Tuple[Tensor]] = None
     attentions: Optional[Tuple[Tuple[Tensor]]] = None
     hidden_states: Optional[Tuple[Tuple[Tensor]]] = None
 
 
 @dataclass
-class TokenClassificationModelOutput(ModelOutputBase):
+class TokenClassificationModelOutput(BaseModelOutput):
     """The output class for token classification models.
         logits (`Tensor`): The logits output of the model.
         loss (`Tensor`, *optional*) The loss of the model, available when training.
         predictions: A PyTorch tensor of the best tag sequence for each batch of shape
             (nbest, batch_size, seq_length)
         offset_mapping (:obj:`torch.FloatTensor` of shape :obj:`(batch_size,
         sequence_length)`, `optional`):
@@ -428,39 +428,39 @@
         used to compute the weighted average in the self-attention heads.
     """
     attentions: Tensor = None
     hidden_states: Tensor = None
 
 
 @dataclass
-class DialogueUserSatisfactionEstimationModelOutput(ModelOutputBase):
+class DialogueUserSatisfactionEstimationModelOutput(BaseModelOutput):
     """The output class for user satisfaction estimation.
 
     Args:
         logits (`Tensor`): The logits output of the model.
     """
     logits: Tensor = None
 
 
 @dataclass
-class SentencEmbeddingModelOutput(ModelOutputBase):
+class SentencEmbeddingModelOutput(BaseModelOutput):
     """The output class for text classification models.
 
     Args:
         query_embs (`Tensor`, *optional*): The tensor of the query embeddings.
         doc_embs (`Tensor`, *optional*) Then tensor of the doc embeddings.
         loss (`torch.FloatTensor` of shape `(1,)`, *optional*): Sentence Embedding modeling loss.
     """
 
     query_embeddings: Tensor = None
     doc_embeddings: Tensor = None
     loss: Tensor = None
 
 
 @dataclass
-class TranslationEvaluationOutput(ModelOutputBase):
+class TranslationEvaluationOutput(BaseModelOutput):
     """The output class for translation evaluation models.
     """
 
     score: Tensor = None
     loss: Tensor = None
     input_format: List[str] = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/outputs/outputs.py` & `weathon-0.0.0.14/weathon/utils/constants/output_constant.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from collections import OrderedDict, namedtuple
-from dataclasses import dataclass, fields
-from typing import Dict, List, Tuple
+from typing import List, Dict
 
 import numpy as np
-import torch
 
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants import Tasks
 
 
 class OutputKeys(object):
     LOSS = 'loss'
     LOGITS = 'logits'
     SCORES = 'scores'
     SCORE = 'score'
@@ -72,15 +68,15 @@
     OutputKeys.SCORES: List[float],  # checked
     OutputKeys.SCORE: float,  # checked
     OutputKeys.LABEL: str,  # checked
     OutputKeys.LABELS: List[str],  # checked
     OutputKeys.INPUT_IDS: np.ndarray,  # checked
     OutputKeys.LABEL_POS: np.ndarray,  # checked
     OutputKeys.POSES:
-    List[np.ndarray],  # [Tuple(np.ndarray, np.ndarray)]  # checked doubtful
+        List[np.ndarray],  # [Tuple(np.ndarray, np.ndarray)]  # checked doubtful
     OutputKeys.CAPTION: str,
     OutputKeys.BOXES: np.ndarray,  # checked
     OutputKeys.KEYPOINTS: np.ndarray,  # checked
     OutputKeys.MASKS: np.ndarray,  # checked
     OutputKeys.DEPTHS: List[np.ndarray],  # checked
     OutputKeys.DEPTHS_COLOR: List[np.ndarray],  # checked
     OutputKeys.LAYOUT: np.ndarray,  # checked
@@ -398,15 +394,15 @@
     OutputKeys.TBOUNDS: {
         'type': 'object'
     },
 }
 
 TASK_OUTPUTS = {
     Tasks.task_template:
-    [OutputKeys.BOXES, OutputKeys.OUTPUT_IMG, OutputKeys.TEXT_EMBEDDING],
+        [OutputKeys.BOXES, OutputKeys.OUTPUT_IMG, OutputKeys.TEXT_EMBEDDING],
     # ============ vision tasks ===================
 
     # ocr detection result for single sample
     # {
     #   "polygons": np.array with shape [num_text, 8], each polygon is
     #       [x1, y1, x2, y2, x3, y3, x4, y4]
     # }
@@ -425,15 +421,15 @@
 
     # document vl embedding for single sample
     # {
     #    "img_embedding": np.array with shape [M, D],
     #    "text_embedding": np.array with shape [N, D]
     # }
     Tasks.document_vl_embedding:
-    [OutputKeys.IMG_EMBEDDING, OutputKeys.TEXT_EMBEDDING],
+        [OutputKeys.IMG_EMBEDDING, OutputKeys.TEXT_EMBEDDING],
 
     # face 2d keypoint result for single sample
     #   {
     #       "keypoints": [
     #           [[x, y]*106],
     #           [[x, y]*106],
     #           [[x, y]*106],
@@ -446,15 +442,15 @@
     #        "boxes": [
     #           [x1, y1, x2, y2],
     #           [x1, y1, x2, y2],
     #           [x1, y1, x2, y2],
     #       ]
     #   }
     Tasks.face_2d_keypoints:
-    [OutputKeys.KEYPOINTS, OutputKeys.POSES, OutputKeys.BOXES],
+        [OutputKeys.KEYPOINTS, OutputKeys.POSES, OutputKeys.BOXES],
 
     # face detection result for single sample
     #   {
     #       "scores": [0.9, 0.1, 0.05, 0.05]
     #       "boxes": [
     #           [x1, y1, x2, y2],
     #           [x1, y1, x2, y2],
@@ -465,15 +461,15 @@
     #           [x1, y1, x2, y2, x3, y3, x4, y4, x5, y5],
     #           [x1, y1, x2, y2, x3, y3, x4, y4, x5, y5],
     #           [x1, y1, x2, y2, x3, y3, x4, y4, x5, y5],
     #           [x1, y1, x2, y2, x3, y3, x4, y4, x5, y5],
     #       ],
     #   }
     Tasks.face_detection:
-    [OutputKeys.SCORES, OutputKeys.BOXES, OutputKeys.KEYPOINTS],
+        [OutputKeys.SCORES, OutputKeys.BOXES, OutputKeys.KEYPOINTS],
 
     # card detection result for single sample
     #   {
     #       "scores": [0.9, 0.1, 0.05, 0.05]
     #       "boxes": [
     #           [x1, y1, x2, y2],
     #           [x1, y1, x2, y2],
@@ -484,15 +480,15 @@
     #           [x1, y1, x2, y2, x3, y3, x4, y4],
     #           [x1, y1, x2, y2, x3, y3, x4, y4],
     #           [x1, y1, x2, y2, x3, y3, x4, y4],
     #           [x1, y1, x2, y2, x3, y3, x4, y4],
     #       ],
     #   }
     Tasks.card_detection:
-    [OutputKeys.SCORES, OutputKeys.BOXES, OutputKeys.KEYPOINTS],
+        [OutputKeys.SCORES, OutputKeys.BOXES, OutputKeys.KEYPOINTS],
 
     # content check result for single sample
     #   {
     #       "scores": [0.9] # non sexy probability
     #   }
     Tasks.content_check: [OutputKeys.SCORES],
 
@@ -527,15 +523,15 @@
 
     # facial expression recognition result for single sample
     #   {
     #       "scores": [0.9, 0.1, 0.02, 0.02, 0.02, 0.02, 0.02],
     #       "labels": ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
     #   }
     Tasks.facial_expression_recognition:
-    [OutputKeys.SCORES, OutputKeys.LABELS],
+        [OutputKeys.SCORES, OutputKeys.LABELS],
 
     # face processing base result for single img
     #   {
     #       "scores": [0.85]
     #       "boxes": [x1, y1, x2, y2]
     #       "keypoints": [x1, y1, x2, y2, x3, y3, x4, y4]
     #   }
@@ -565,15 +561,15 @@
     #           [x1, y1, x2, y2],
     #           [x1, y1, x2, y2],
     #           [x1, y1, x2, y2],
     #       ],
     #   }
     #
     Tasks.human_detection:
-    [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
+        [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
 
     # face generation result for single sample
     # {
     #   "output_img": np.array with shape(h, w, 3)
     # }
     Tasks.face_image_generation: [OutputKeys.OUTPUT_IMG],
 
@@ -591,19 +587,19 @@
     #       "boxes": [
     #           [x1, y1, x2, y2],
     #           [x1, y1, x2, y2],
     #           [x1, y1, x2, y2],
     #       ],
     #   }
     Tasks.image_object_detection:
-    [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
+        [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
     Tasks.domain_specific_object_detection:
-    [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
+        [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
     Tasks.open_vocabulary_detection:
-    [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
+        [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
 
     # video object detection result for single sample
     #   {
 
     #         "scores": [[0.8, 0.25, 0.05, 0.05], [0.9, 0.1, 0.05, 0.05]]
     #         "labels": [["person", "traffic light", "car", "bus"],
     #                     ["person", "traffic light", "car", "bus"]]
@@ -621,15 +617,15 @@
     #                [x1, y1, x2, y2],
     #                [x1, y1, x2, y2],
     #               ]
     #           ],
 
     #   }
     Tasks.video_object_detection:
-    [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
+        [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.BOXES],
 
     # 3d object detection result for single sample
     # {
     #   "output_img": np.array with shape(h, w, 3)
     # }
     Tasks.object_detection_3d: [OutputKeys.OUTPUT_IMG],
 
@@ -638,15 +634,15 @@
     #       "scores": [0.9, 0.1, 0.05, 0.05],
     #       "labels": ["dog", "horse", "cow", "cat"],
     #       "masks": [
     #           np.array # 2D array containing only 0, 1
     #       ]
     #   }
     Tasks.image_segmentation:
-    [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.MASKS],
+        [OutputKeys.SCORES, OutputKeys.LABELS, OutputKeys.MASKS],
 
     # video panoptic segmentation result for single sample
     #         "scores": [[0.8, 0.25, 0.05, 0.05], [0.9, 0.1, 0.05, 0.05]]
     #         "labels": [["person", "traffic light", "car", "bus"],
     #                     ["person", "traffic light", "car", "bus"]]
     #       "masks": [ #array containing only 0, 1
     #           [np.array, np.array, np.array, np.array],
@@ -1482,64 +1478,7 @@
     Tasks.vision_efficient_tuning: [OutputKeys.SCORES, OutputKeys.LABELS],
     Tasks.document_grounded_dialog_generate: [OutputKeys.TEXT],
     Tasks.document_grounded_dialog_rerank: [OutputKeys.OUTPUT],
     Tasks.document_grounded_dialog_retrieval: [OutputKeys.OUTPUT],
     Tasks.video_temporal_grounding: [OutputKeys.SCORES, OutputKeys.TBOUNDS],
     Tasks.text_to_video_synthesis: [OutputKeys.OUTPUT_VIDEO],
 }
-
-
-class ModelOutputBase(list):
-
-    def __post_init__(self):
-        self.reconstruct()
-        self.post_init = True
-
-    def reconstruct(self):
-        # Low performance, but low frequency.
-        self.clear()
-        for idx, key in enumerate(self.keys()):
-            self.append(getattr(self, key))
-
-    def __getitem__(self, item):
-        if isinstance(item, str):
-            if hasattr(self, item):
-                return getattr(self, item)
-        elif isinstance(item, (int, slice)):
-            return super().__getitem__(item)
-        raise IndexError(f'No Index {item} found in the dataclass.')
-
-    def __setitem__(self, key, value):
-        if isinstance(key, str):
-            if key in [f.name for f in fields(self)]:
-                if key not in self.keys():
-                    super().__setattr__(key, value)
-                    self.reconstruct()
-                elif id(getattr(self, key)) != id(value):
-                    super().__setattr__(key, value)
-                    super().__setitem__(self.keys().index(key), value)
-            else:
-                super().__setattr__(key, value)
-        elif isinstance(key, int):
-            super().__setitem__(key, value)
-            key_name = self.keys()[key]
-            super().__setattr__(key_name, value)
-
-    def __setattr__(self, key, value):
-        if getattr(self, 'post_init', False):
-            return self.__setitem__(key, value)
-        else:
-            return super().__setattr__(key, value)
-
-    def keys(self):
-        return [
-            f.name for f in fields(self) if getattr(self, f.name) is not None
-        ]
-
-    def items(self):
-        return self.to_dict().items()
-
-    def to_dict(self):
-        output = OrderedDict()
-        for key in self.keys():
-            output[key] = getattr(self, key)
-        return output
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipeline_inputs.py` & `weathon-0.0.0.14/weathon/utils/constants/pipeline_inputs.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
-from PIL import Image
 
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants import Tasks
+from PIL import Image
 
 
 class InputKeys(object):
     IMAGE = 'image'
     TEXT = 'text'
     VIDEO = 'video'
 
@@ -66,23 +64,14 @@
     },  # unknown item type.
     InputType.NUMBER: {
         'type': 'integer'
     },
 }
 
 
-def check_input_type(input_type, input):
-    expected_type = INPUT_TYPE[input_type]
-    if input_type == InputType.VIDEO:
-        # special type checking using class name, to avoid introduction of opencv dependency into fundamental framework.
-        assert type(input).__name__ == 'VideoCapture' or isinstance(input, expected_type),\
-            f'invalid input type for {input_type}, expected {expected_type} but got {type(input)}\n {input}'
-    else:
-        assert isinstance(input, expected_type), \
-            f'invalid input type for {input_type}, expected {expected_type} but got {type(input)}\n {input}'
 
 
 TASK_INPUTS = {
 
     Tasks.task_template: {
         'image': InputType.IMAGE,
         'text': InputType.TEXT
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/__init__.py` & `weathon-0.0.0.14/weathon/pipelines/audio/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .ans_pipeline import ANSPipeline
     from .asr_inference_pipeline import AutomaticSpeechRecognitionPipeline
     from .kws_farfield_pipeline import KWSFarfieldPipeline
     from .kws_kwsbp_pipeline import KeyWordSpottingKwsbpPipeline
     from .linear_aec_pipeline import LinearAECPipeline
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/ans_dfsmn_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/ans_dfsmn_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,38 +1,36 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import collections
 import io
 import os
 import sys
 from typing import Any, Dict
 
 import librosa
 import numpy as np
 import soundfile as sf
 import torch
 
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.base import BasePipeline
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.fileio import File
+from weathon.utils.typing import Input
 
 HOP_LENGTH = 960
 N_FFT = 1920
 WINDOW_NAME_HAM = 'hamming'
 STFT_WIN_LEN = 1920
 WINLEN = 3840
 STRIDE = 1920
 
 
-@PIPELINES.register_module(
-    Tasks.acoustic_noise_suppression,
-    module_name=Pipelines.speech_dfsmn_ans_psm_48k_causal)
-class ANSDFSMNPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.acoustic_noise_suppression,module_name=Pipelines.speech_dfsmn_ans_psm_48k_causal)
+class ANSDFSMNPipeline(BasePipeline):
     """ANS (Acoustic Noise Suppression) inference pipeline based on DFSMN model.
 
     Args:
         stream_mode: set its work mode, default False
         In stream model, it accepts bytes as pipeline input that should be the audio data in PCM format.
         In normal model, it accepts str and treat it as the path of local wav file or the http link of remote wav file.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/ans_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/ans_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 from typing import Any, Dict
 
 import librosa
 import numpy as np
 import soundfile as sf
 import torch
 
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.audio.audio_utils import audio_norm
-from modelscope.utils.constant import Tasks
+from weathon.fileio import File
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.audio.audio_utils import audio_norm
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     Tasks.acoustic_noise_suppression,
     module_name=Pipelines.speech_frcrn_ans_cirm_16k)
 class ANSPipeline(Pipeline):
     r"""ANS (Acoustic Noise Suppression) Inference Pipeline .
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/asr_inference_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/asr_inference_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,41 +1,38 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
 
 import json
 import yaml
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import WavToScp
-from modelscope.utils.audio.audio_utils import (extract_pcm_from_wav,
-                                                generate_scp_from_url,
-                                                load_bytes_from_url,
-                                                update_local_model)
-from modelscope.utils.constant import Frameworks, ModelFile, Tasks
-from modelscope.utils.hub import snapshot_download
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import WavToScp
+from weathon.utils.audio.audio_utils import (generate_scp_from_url,
+                                             update_local_model)
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.hub import snapshot_download
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['AutomaticSpeechRecognitionPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.auto_speech_recognition, module_name=Pipelines.asr_inference)
 class AutomaticSpeechRecognitionPipeline(Pipeline):
     """ASR Inference Pipeline
     Example:
 
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
     >>> inference_pipeline = pipeline(
     >>>     task=Tasks.auto_speech_recognition,
     >>>     model='damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch')
 
     >>> rec_result = inference_pipeline(
     >>>     audio_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav')
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/asr_wenet_inference_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/asr_wenet_inference_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import WavToScp
-from modelscope.utils.audio.audio_utils import (extract_pcm_from_wav,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import WavToScp
+from weathon.utils.audio.audio_utils import (extract_pcm_from_wav,
                                                 load_bytes_from_url)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['WeNetAutomaticSpeechRecognitionPipeline']
 
 
 @PIPELINES.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/inverse_text_processing_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/inverse_text_processing_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import shutil
 from typing import Any, Dict, List, Sequence, Tuple, Union
 
 import yaml
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Frameworks, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constant import Frameworks, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['InverseTextProcessingPipeline']
 
 
 @PIPELINES.register_module(
@@ -27,15 +26,15 @@
     Args:
         model (BartForTextErrorCorrection): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the preprocessor's constructor.
 
     Examples:
 
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
     >>> pipeline_itn = pipeline(
     >>>    task=Tasks.inverse_text_processing, model='damo/speech_inverse_text_processing_fun-text-processing-itn-id')
     >>> sentence = 'sembilan ribu sembilan ratus sembilan puluh sembilan'
     >>> print(pipeline_itn(sentence))
 
     To view other examples plese check tests/pipelines/test_inverse_text_processing.py.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/kws_farfield_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/kws_farfield_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 import wave
 from typing import Any, Dict
 
 import numpy
 import soundfile as sf
 
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
+from weathon.base import BasePipeline
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.fileio import File
+from weathon.utils.typing import Input
 
 
-@PIPELINES.register_module(
-    Tasks.keyword_spotting,
-    module_name=Pipelines.speech_dfsmn_kws_char_farfield)
-class KWSFarfieldPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.keyword_spotting,module_name=Pipelines.speech_dfsmn_kws_char_farfield)
+class KWSFarfieldPipeline(BasePipeline):
     r"""A Keyword Spotting Inference Pipeline .
 
     When invoke the class with pipeline.__call__(), it accept only one parameter:
         inputs(str): the path of wav file
     """
     SAMPLE_RATE = 16000
     SAMPLE_WIDTH = 2
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/kws_kwsbp_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/kws_kwsbp_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,36 +1,33 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, List, Union
 
 import json
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import WavToLists
-from modelscope.utils.audio.audio_utils import (extract_pcm_from_wav,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BasePipeline, BaseModel
+from weathon.registry import PIPELINES
+from weathon.preprocessors import WavToLists
+from weathon.utils.audio.audio_utils import (extract_pcm_from_wav,
                                                 load_bytes_from_url)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['KeyWordSpottingKwsbpPipeline']
 
 
-@PIPELINES.register_module(
-    Tasks.keyword_spotting, module_name=Pipelines.kws_kwsbp)
-class KeyWordSpottingKwsbpPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.keyword_spotting, module_name=Pipelines.kws_kwsbp)
+class KeyWordSpottingKwsbpPipeline(BasePipeline):
     """KWS Pipeline - key word spotting decoding
     """
 
     def __init__(self,
-                 model: Union[Model, str] = None,
+                 model: Union[BaseModel, str] = None,
                  preprocessor: WavToLists = None,
                  **kwargs):
         """use `model` and `preprocessor` to create a kws pipeline for prediction
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
 
     def __call__(self, audio_in: Union[List[str], str, bytes],
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/linear_aec_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/linear_aec_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import importlib
 import os
 from typing import Any, Dict
 
 import numpy as np
 import scipy.io.wavfile as wav
 import torch
 import yaml
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LinearAECAndFbank
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LinearAECAndFbank
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 FEATURE_MVN = 'feature.DEY.mvn.txt'
 
 CONFIG_YAML = 'dey_mini.yaml'
 
@@ -44,15 +42,15 @@
     module = importlib.import_module(module_cfg['module'])
     return getattr(module, module_cfg['main'])(**module_cfg['args'])
 
 
 @PIPELINES.register_module(
     Tasks.acoustic_echo_cancellation,
     module_name=Pipelines.speech_dfsmn_aec_psm_16k)
-class LinearAECPipeline(Pipeline):
+class LinearAECPipeline(BasePipeline):
     r"""AEC Inference Pipeline only support 16000 sample rate.
 
     When invoke the class with pipeline.__call__(), you should provide two params:
         Dict[str, Any]
             the path of wav files, eg:{
             "nearend_mic": "/your/data/near_end_mic_audio.wav",
             "farend_speech": "/your/data/far_end_speech_audio.wav"}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/lm_infer_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/lm_infer_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,35 +1,34 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.audio.audio_utils import (generate_text_from_url,
+from torch.distributed.pipeline.sync.pipeline import Pipeline
+
+from weathon.utils.constants import Tasks, ModelFile, Frameworks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.audio.audio_utils import (generate_text_from_url,
                                                 update_local_model)
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Frameworks, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['LanguageModelPipeline']
 
 
-@PIPELINES.register_module(
-    Tasks.language_score_prediction, module_name=Pipelines.lm_inference)
+@PIPELINES.register_module(Tasks.language_score_prediction, module_name=Pipelines.lm_inference)
 class LanguageModelPipeline(Pipeline):
     """Language Model Inference Pipeline
 
     Example:
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
     >>> inference_pipeline = pipeline(
     >>>    task=Tasks.language_score_prediction,
     >>>    model='damo/speech_transformer_lm_zh-cn-common-vocab8404-pytorch')
     >>> text_in='hello    '
     >>> print(inference_pipeline(text_in))
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/punctuation_processing_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/punctuation_processing_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,50 +1,44 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-import shutil
-from typing import Any, Dict, List, Sequence, Tuple, Union
+from typing import Any, Dict, List, Union
 
-import yaml
-
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.audio.audio_utils import (generate_text_from_url,
+from weathon.utils.constants import Tasks, Frameworks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.audio.audio_utils import (generate_text_from_url,
                                                 update_local_model)
-from modelscope.utils.constant import Frameworks, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['PunctuationProcessingPipeline']
 
 
-@PIPELINES.register_module(
-    Tasks.punctuation, module_name=Pipelines.punc_inference)
-class PunctuationProcessingPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.punctuation, module_name=Pipelines.punc_inference)
+class PunctuationProcessingPipeline(BasePipeline):
     """Punctuation Processing Inference Pipeline
     use `model` to create a Punctuation Processing pipeline.
 
     Args:
         model (PunctuationProcessingPipeline): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the preprocessor's constructor.
     Examples
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
     >>> pipeline_punc = pipeline(
     >>>    task=Tasks.punctuation, model='damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch')
     >>> text_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_text/punc_example.txt'
     >>> print(pipeline_punc(text_in))
 
     """
 
     def __init__(self,
-                 model: Union[Model, str] = None,
+                 model: Union[BaseModel, str] = None,
                  ngpu: int = 1,
                  **kwargs):
         """use `model` to create an asr pipeline for prediction
         """
         super().__init__(model=model, **kwargs)
         self.model_cfg = self.model.forward()
         self.cmd = self.get_cmd(kwargs, model)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/separation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/facial_expression_recognition_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,71 +1,67 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import io
+import os.path as osp
 from typing import Any, Dict
 
-import numpy
-import soundfile as sf
+import cv2
+import numpy as np
+import PIL
 import torch
 
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Input
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_recognition.align_face import align_face
+from weathon.models.cv.facial_expression_recognition import \
+    FacialExpressionRecognition
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
+from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.speech_separation, module_name=Pipelines.speech_separation)
-class SeparationPipeline(Pipeline):
-
-    def __init__(self, model, **kwargs):
-        """create a speech separation pipeline for prediction
+    Tasks.facial_expression_recognition,
+    module_name=Pipelines.facial_expression_recognition)
+class FacialExpressionRecognitionPipeline(FaceProcessingBasePipeline):
 
+    def __init__(self, model: str, **kwargs):
+        """
+        use `model` to create a face detection pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
-        logger.info('loading model...')
         super().__init__(model=model, **kwargs)
-        self.model.load_check_point(device=self.device)
-        self.model.eval()
+        ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_FILE)
+        logger.info(f'loading model from {ckpt_path}')
+        device = torch.device(
+            f'cuda:{0}' if torch.cuda.is_available() else 'cpu')
+        fer = FacialExpressionRecognition(model_path=ckpt_path, device=device)
+        self.fer = fer
+        self.device = device
+        logger.info('load model done')
+
+        self.map_list = [
+            'Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'
+        ]
+
+    def preprocess(self, input: Input) -> Dict[str, Any]:
+        result = super().preprocess(input)
+        if result is None:
+            rtn_dict = {}
+            rtn_dict['img'] = None
+            return rtn_dict
+        return result
+
+    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
+        if input['img'] is None:
+            return {OutputKeys.SCORES: None, OutputKeys.LABELS: None}
+        result = self.fer(input)
+        assert result is not None
+        scores = result[0].tolist()
+        return {OutputKeys.SCORES: scores, OutputKeys.LABELS: self.map_list}
 
-    def preprocess(self, inputs: Input, **preprocess_params) -> Dict[str, Any]:
-        if isinstance(inputs, str):
-            file_bytes = File.read(inputs)
-            data, fs = sf.read(io.BytesIO(file_bytes), dtype='float32')
-            if fs != 8000:
-                raise ValueError(
-                    'modelscope error: The audio sample rate should be 8000')
-        elif isinstance(inputs, bytes):
-            data = torch.from_numpy(
-                numpy.frombuffer(inputs, dtype=numpy.float32))
-        return dict(data=data)
-
-    def postprocess(self, inputs: Dict[str, Any],
-                    **post_params) -> Dict[str, Any]:
+    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
-
-    def forward(
-        self, inputs: Dict[str, Any], **forward_params
-    ) -> Dict[str, Any]:  # mix, targets, stage, noise=None):
-        """Forward computations from the mixture to the separated signals."""
-        logger.info('Start forward...')
-        # Unpack lists and put tensors in the right device
-        mix = inputs['data'].to(self.device)
-        mix = torch.unsqueeze(mix, dim=1).transpose(0, 1)
-        est_source = self.model(mix)
-        result = []
-        for ns in range(self.model.num_spks):
-            signal = est_source[0, :, ns]
-            signal = signal / signal.abs().max() * 0.5
-            signal = signal.unsqueeze(0).cpu()
-            # convert tensor to pcm
-            output = (signal.numpy() * 32768).astype(numpy.int16).tobytes()
-            result.append(output)
-        logger.info('Finish forward.')
-        return {OutputKeys.OUTPUT_PCM_LIST: result}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_change_locating_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/speaker_change_locating_pipeline.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,42 +1,41 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 from typing import Any, Dict, List, Union
 
 import numpy as np
 import soundfile as sf
 import torch
 
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import InputModel, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import BasePipeline
+from weathon.base.pipeline import InputModel
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.fileio import File
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['SpeakerChangeLocatingPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.speaker_diarization, module_name=Pipelines.speaker_change_locating)
-class SpeakerChangeLocatingPipeline(Pipeline):
+class SpeakerChangeLocatingPipeline(BasePipeline):
     """Speaker Change Locating Inference Pipeline
     use `model` to create a speaker change Locating pipeline.
 
     Args:
         model (SpeakerChangeLocatingPipeline): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the pipeline's constructor.
     Example:
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
     >>> p = pipeline(
     >>>    task=Tasks.speaker_diarization, model='damo/speech_campplus-transformer_scl_zh-cn_16k-common')
     >>> print(p(audio))
 
     """
 
     def __init__(self, model: InputModel, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_diarization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/speaker_diarization_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,56 +1,49 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-import shutil
-from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
+from typing import Any, Dict, Optional, Union
 
 import json
 import numpy
-import yaml
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.audio.audio_utils import (generate_scp_for_sv,
-                                                generate_sd_scp_from_url,
-                                                update_local_model)
-from modelscope.utils.constant import Frameworks, ModelFile, Tasks
-from modelscope.utils.hub import snapshot_download
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks, ModelFile, Frameworks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BasePipeline, BaseModel
+from weathon.registry import PIPELINES
+from weathon.utils.audio.audio_utils import (generate_sd_scp_from_url,
+                                             update_local_model)
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.hub.utils import snapshot_download
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['SpeakerDiarizationPipeline']
 
 
-@PIPELINES.register_module(
-    Tasks.speaker_diarization,
-    module_name=Pipelines.speaker_diarization_inference)
-class SpeakerDiarizationPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.speaker_diarization,module_name=Pipelines.speaker_diarization_inference)
+class SpeakerDiarizationPipeline(BasePipeline):
     """Speaker Diarization Inference Pipeline
     use `model` to create a Speaker Diarization pipeline.
 
     Args:
         model (SpeakerDiarizationPipeline): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the preprocessor's constructor.
     Examples:
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> pipeline_sd = pipeline(
         >>>    task=Tasks.speaker_diarization, model='damo/xxxxxxxxxxxxx')
         >>> audio_in=('','','','')
         >>> print(pipeline_sd(audio_in))
 
     """
 
     def __init__(self,
-                 model: Union[Model, str] = None,
-                 sv_model: Optional[Union[Model, str]] = None,
+                 model: Union[BaseModel, str] = None,
+                 sv_model: Optional[Union[BaseModel, str]] = None,
                  sv_model_revision: Optional[str] = None,
                  ngpu: int = 1,
                  **kwargs):
         """use `model` to create a speaker diarization pipeline for prediction
         Args:
             model ('Model' or 'str'):
                 The pipeline handles three types of model:
@@ -210,16 +203,15 @@
         return cmd
 
     def load_sv_model(self, cmd):
         if self.sv_model is not None and self.sv_model != '':
             if os.path.exists(self.sv_model):
                 sv_model = self.sv_model
             else:
-                sv_model = snapshot_download(
-                    self.sv_model, revision=self.sv_model_revision)
+                sv_model = snapshot_download(self.sv_model, revision=self.sv_model_revision)
             logger.info(
                 'loading speaker verification model from {0} ...'.format(
                     sv_model))
             config_path = os.path.join(sv_model, ModelFile.CONFIGURATION)
             model_cfg = json.loads(open(config_path).read())
             model_dir = os.path.dirname(config_path)
             cmd['param_dict']['sv_model_file'] = os.path.join(
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_verification_eres2net_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/speaker_verification_eres2net_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,40 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 from typing import Any, Dict, List, Union
 
 import soundfile as sf
 import torch
 
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import InputModel, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import BasePipeline
+from weathon.base.pipeline import InputModel
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.fileio import File
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
-@PIPELINES.register_module(
-    Tasks.speaker_verification,
-    module_name=Pipelines.speaker_verification_eres2net)
-class ERes2Net_Pipeline(Pipeline):
+@PIPELINES.register_module(Tasks.speaker_verification,module_name=Pipelines.speaker_verification_eres2net)
+class ERes2Net_Pipeline(BasePipeline):
     """Speaker Verification Inference Pipeline
     use `model` to create a Speaker Verification pipeline.
 
     Args:
         model (SpeakerVerificationPipeline): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the pipeline's constructor.
     Example:
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
     >>> p = pipeline(
     >>>    task=Tasks.speaker_verification, model='damo/speech_ecapa-tdnn_sv_en_voxceleb_16k')
     >>> print(p([audio_1, audio_2]))
 
     """
 
     def __init__(self, model: InputModel, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_verification_light_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/speaker_verification_rdino_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,41 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 from typing import Any, Dict, List, Union
 
 import soundfile as sf
 import torch
 
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import InputModel, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import BasePipeline
+from weathon.base.pipeline import InputModel
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.fileio import File
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
-__all__ = ['SpeakerVerificationPipeline']
-
 
-@PIPELINES.register_module(
-    Tasks.speaker_verification, module_name=Pipelines.speaker_verification)
-class SpeakerVerificationPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.speaker_verification,module_name=Pipelines.speaker_verification_rdino)
+class RDINO_Pipeline(BasePipeline):
     """Speaker Verification Inference Pipeline
     use `model` to create a Speaker Verification pipeline.
 
     Args:
         model (SpeakerVerificationPipeline): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the pipeline's constructor.
     Example:
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
     >>> p = pipeline(
     >>>    task=Tasks.speaker_verification, model='damo/speech_ecapa-tdnn_sv_en_voxceleb_16k')
     >>> print(p([audio_1, audio_2]))
 
     """
 
     def __init__(self, model: InputModel, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_verification_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/speaker_verification_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,42 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-import shutil
-from typing import Any, Dict, List, Sequence, Tuple, Union
+from typing import Any, Dict, Union
 
-import yaml
-
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.audio.audio_utils import (generate_scp_for_sv,
+from weathon.utils.constants import Tasks, Frameworks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.audio.audio_utils import (generate_scp_for_sv,
                                                 generate_sv_scp_from_url,
                                                 update_local_model)
-from modelscope.utils.constant import Frameworks, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['SpeakerVerificationPipeline']
 
 
-@PIPELINES.register_module(
-    Tasks.speaker_verification, module_name=Pipelines.sv_inference)
-class SpeakerVerificationPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.speaker_verification, module_name=Pipelines.sv_inference)
+class SpeakerVerificationPipeline(BasePipeline):
     """Speaker Verification Inference Pipeline
     use `model` to create a Speaker Verification pipeline.
 
     Args:
         model (SpeakerVerificationPipeline): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the preprocessor's constructor.
     Examples:
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> pipeline_sv = pipeline(
         >>>    task=Tasks.speaker_verification, model='damo/speech_xvector_sv-zh-cn-cnceleb-16k-spk3465-pytorch')
         >>> audio_in=('sv_example_enroll.wav', 'sv_example_same.wav')
         >>> print(pipeline_sv(audio_in))
         >>> # {'label': ['Same', 'Different'], 'scores': [0.8540488358969999, 0.14595116410300013]}
 
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/speaker_verification_rdino_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/speaker_verification_light_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,40 +1,39 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 from typing import Any, Dict, List, Union
 
 import soundfile as sf
 import torch
 
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import InputModel, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import BasePipeline
+from weathon.base.pipeline import InputModel
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.fileio import File
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
+__all__ = ['SpeakerVerificationPipeline']
+
 
-@PIPELINES.register_module(
-    Tasks.speaker_verification,
-    module_name=Pipelines.speaker_verification_rdino)
-class RDINO_Pipeline(Pipeline):
+@PIPELINES.register_module(Tasks.speaker_verification, module_name=Pipelines.speaker_verification)
+class SpeakerVerificationPipeline(BasePipeline):
     """Speaker Verification Inference Pipeline
     use `model` to create a Speaker Verification pipeline.
 
     Args:
         model (SpeakerVerificationPipeline): A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the pipeline's constructor.
     Example:
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
     >>> p = pipeline(
     >>>    task=Tasks.speaker_verification, model='damo/speech_ecapa-tdnn_sv_en_voxceleb_16k')
     >>> print(p([audio_1, audio_2]))
 
     """
 
     def __init__(self, model: InputModel, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/text_to_speech_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/text_to_speech_pipeline.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,27 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from typing import Any, Dict, List
+from typing import Any, Dict
 
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.audio.tts import SambertHifigan
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, InputModel, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Fields, Tasks
+from weathon.base import BasePipeline
+from weathon.base.pipeline import InputModel, Input
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.audio.tts import SambertHifigan
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
 
 __all__ = ['TextToSpeechSambertHifiganPipeline']
 
+from weathon.utils.constants.output_constant import OutputKeys
+
 
 @PIPELINES.register_module(
     Tasks.text_to_speech, module_name=Pipelines.sambert_hifigan_tts)
-class TextToSpeechSambertHifiganPipeline(Pipeline):
+class TextToSpeechSambertHifiganPipeline(BasePipeline):
 
     def __init__(self, model: InputModel, **kwargs):
         """use `model` to create a text-to-speech pipeline for prediction
 
         Args:
             model (SambertHifigan or str): a model instance or valid offical model id
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/timestamp_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/timestamp_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,51 +1,48 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from typing import Any, Dict, List, Sequence, Tuple, Union
+from typing import Any, Dict, Sequence, Tuple, Union
 
 import json
 import yaml
 from funasr.utils import asr_utils
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.audio.audio_utils import (generate_scp_from_url,
-                                                update_local_model)
-from modelscope.utils.constant import Frameworks, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks, ModelFile, Frameworks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BasePipeline, BaseModel
+from weathon.registry import PIPELINES
+from weathon.utils.audio.audio_utils import (generate_scp_from_url,
+                                             update_local_model, generate_text_from_url)
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['TimestampPipeline']
 
 
-@PIPELINES.register_module(
-    Tasks.speech_timestamp, module_name=Pipelines.speech_timestamp_inference)
-class TimestampPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.speech_timestamp, module_name=Pipelines.speech_timestamp_inference)
+class TimestampPipeline(BasePipeline):
     """Timestamp Inference Pipeline
     Example:
 
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
     >>> pipeline_infer = pipeline(
     >>>    task=Tasks.speech_timestamp,
     >>>    model='damo/speech_timestamp_predictor-v1-16k-offline')
 
     >>> audio_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_timestamps.wav'
     >>> text_in='                   '
     >>> print(pipeline_infer(audio_in, text_in))
 
     """
 
     def __init__(self,
-                 model: Union[Model, str] = None,
+                 model: Union[BaseModel, str] = None,
                  ngpu: int = 1,
                  **kwargs):
         """
         Use `model` and `preprocessor` to create an asr pipeline for prediction
         Args:
             model ('Model' or 'str'):
                 The pipeline handles three types of model:
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/audio/voice_activity_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/audio/voice_activity_detection_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,52 +1,49 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-from typing import Any, Dict, List, Sequence, Tuple, Union
+from typing import Any, Dict, Sequence, Tuple, Union
 
 import json
 import yaml
 from funasr.utils import asr_utils
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.audio.audio_utils import (generate_scp_from_url,
+from weathon.utils.constants import Tasks, ModelFile, Frameworks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BasePipeline, BaseModel
+from weathon.registry import PIPELINES
+from weathon.utils.audio.audio_utils import (generate_scp_from_url,
                                                 update_local_model)
-from modelscope.utils.constant import Frameworks, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['VoiceActivityDetectionPipeline']
 
 
-@PIPELINES.register_module(
-    Tasks.voice_activity_detection, module_name=Pipelines.vad_inference)
-class VoiceActivityDetectionPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.voice_activity_detection, module_name=Pipelines.vad_inference)
+class VoiceActivityDetectionPipeline(BasePipeline):
     """Voice Activity Detection Inference Pipeline
     use `model` to create a Voice Activity Detection pipeline.
 
     Args:
         model: A model instance, or a model local dir, or a model id in the model hub.
         kwargs (dict, `optional`):
             Extra kwargs passed into the preprocessor's constructor.
 
     Example:
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> pipeline_vad = pipeline(
         >>>    task=Tasks.voice_activity_detection, model='damo/speech_fsmn_vad_zh-cn-16k-common-pytorch')
         >>> audio_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.pcm'
         >>> print(pipeline_vad(audio_in))
 
     """
 
     def __init__(self,
-                 model: Union[Model, str] = None,
+                 model: Union[BaseModel, str] = None,
                  ngpu: int = 1,
                  **kwargs):
         """use `model` to create an vad pipeline for prediction
         """
         super().__init__(model=model, **kwargs)
         config_path = os.path.join(model, ModelFile.CONFIGURATION)
         self.cmd = self.get_cmd(config_path, kwargs, model)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/base.py` & `weathon-0.0.0.14/weathon/base/pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,77 +1,72 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import os.path as osp
 import random
 from abc import ABC, abstractmethod
 from functools import partial
 from multiprocessing import Pool
 from threading import Lock
 from typing import Any, Dict, Generator, List, Mapping, Union
 
 import numpy as np
-from packaging import version
 
-from modelscope.models.base import Model
-from modelscope.msdatasets import MsDataset
-from modelscope.outputs import TASK_OUTPUTS, ModelOutputBase
-from modelscope.pipeline_inputs import TASK_INPUTS, check_input_type
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Frameworks, Invoke, ModelFile
-from modelscope.utils.device import (create_device, device_placement,
-                                     verify_device)
-from modelscope.utils.hub import read_config, snapshot_download
-from modelscope.utils.import_utils import is_tf_available, is_torch_available
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import compile_model
-from .util import is_model, is_official_hub_path
+from .model import BaseModel
+from .modeloutput import BaseModelOutput
+from .preprocessor import BasePreprocessor
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Invoke, Frameworks, ModelFile
+from weathon.utils.constants.output_constant import TASK_OUTPUTS
+from weathon.utils.constants.pipeline_inputs import TASK_INPUTS
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.device import verify_device, create_device, device_placement
+from weathon.utils.hub.utils import read_config, snapshot_download
+from weathon.utils.import_utils import is_torch_available, is_tf_available
+from weathon.utils.logger import get_logger
+from weathon.utils.pipeline_utils import check_input_type,is_official_hub_path, is_model
+from weathon.utils.torch_utils import compile_model
+
 
 if is_torch_available():
     import torch
 
 if is_tf_available():
     pass
 
 Tensor = Union['torch.Tensor', 'tf.Tensor']
-Input = Union[str, tuple, MsDataset, 'Image.Image', 'numpy.ndarray']
-InputModel = Union[str, Model, 'torch.nn.Module']
+Input = Union[str, tuple, WtDataset, 'Image.Image', 'numpy.ndarray']
+InputModel = Union[str, BaseModel, 'torch.nn.Module']
 
 logger = get_logger()
 
 
-class Pipeline(ABC):
+class BasePipeline(ABC):
     """Pipeline base.
     """
 
     def initiate_single_model(self, model):
         if isinstance(model, str):
             logger.info(f'initiate model from {model}')
         if isinstance(model, str) and is_official_hub_path(model):
             logger.info(f'initiate model from location {model}.')
             # expecting model has been prefetched to local cache beforehand
-            return Model.from_pretrained(
-                model,
-                device=self.device_name,
-                model_prefetched=True,
-                invoked_by=Invoke.PIPELINE) if is_model(model) else model
+            return BaseModel.from_pretrained(model, device=self.device_name, model_prefetched=True,
+                                             invoked_by=Invoke.PIPELINE) if is_model(model) else model
         else:
             return model
 
     def initiate_multiple_models(self, input_models: List[InputModel]):
         models = []
         for model in input_models:
             models.append(self.initiate_single_model(model))
         return models
 
     def __init__(self,
                  config_file: str = None,
                  model: Union[InputModel, List[InputModel]] = None,
-                 preprocessor: Union[Preprocessor, List[Preprocessor]] = None,
+                 preprocessor: Union[BasePreprocessor, List[BasePreprocessor]] = None,
                  device: str = 'gpu',
                  auto_collate=True,
                  **kwargs):
         """ Base class for pipeline.
 
         If config_file is provided, model and preprocessor will be
         instantiated from corresponding config. Otherwise, model
@@ -106,15 +101,15 @@
             if isinstance(self.model, str):
                 model_dir = self.model
             else:
                 model_dir = self.model.model_dir
             self.cfg = read_config(model_dir)
 
         if preprocessor is None and not self.has_multiple_models:
-            self.preprocessor = Preprocessor.from_pretrained(model_dir)
+            self.preprocessor = BasePreprocessor.from_pretrained(model_dir)
         else:
             self.preprocessor = preprocessor
 
         if self.model or (self.has_multiple_models and self.models[0]):
             self.framework = self._get_framework()
         else:
             self.framework = None
@@ -201,15 +196,15 @@
             if batch_size is None:
                 output = []
                 for ele in input:
                     output.append(self._process_single(ele, *args, **kwargs))
             else:
                 output = self._process_batch(input, batch_size, **kwargs)
 
-        elif isinstance(input, MsDataset):
+        elif isinstance(input, WtDataset):
             return self._process_iterator(input, *args, **kwargs)
 
         else:
             output = self._process_single(input, *args, **kwargs)
         return output
 
     def _sanitize_parameters(self, **pipeline_parameters):
@@ -360,27 +355,27 @@
             if not getattr(self, '_output_has_warned', False):
                 logger.warning(f'task {task_name} output keys are missing')
                 self._output_has_warned = True
             return
         output_keys = TASK_OUTPUTS[task_name]
         missing_keys = []
         input = input.keys() if isinstance(input,
-                                           (dict, ModelOutputBase)) else input
+                                           (dict, BaseModelOutput)) else input
         for k in output_keys:
             if k not in input:
                 missing_keys.append(k)
         if len(missing_keys) > 0:
             raise ValueError(f'expected output keys are {output_keys}, '
                              f'those {missing_keys} are missing')
 
     def preprocess(self, inputs: Input, **preprocess_params) -> Dict[str, Any]:
         """ Provide default implementation based on preprocess_cfg and user can reimplement it
         """
         assert self.preprocessor is not None, 'preprocess method should be implemented'
-        assert not isinstance(self.preprocessor, List),\
+        assert not isinstance(self.preprocessor, List), \
             'default implementation does not support using multiple preprocessors.'
         return self.preprocessor(inputs, **preprocess_params)
 
     def forward(self, inputs: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         """ Provide default implementation using self.model and user can reimplement it
         """
@@ -401,15 +396,15 @@
         Return:
             dict of results:  a dict containing outputs of model, each
                 output should have the standard output name.
         """
         raise NotImplementedError('postprocess')
 
 
-class DistributedPipeline(Pipeline):
+class DistributedPipeline(BasePipeline):
     """This pipeline is used to load multi gpu models.
 
     What will this class do:
     1. Read the global config from the configuration.json
     2. Set the multiprocessing method to spawn
     3. Open a multiprocessing pool of the world_size to instantiate model pieces.
     4. Set the master port and ip
@@ -420,15 +415,15 @@
 
     NOTE: _instantiate_one and _forward_one are class methods, any derived class should implement them and
     store the model handler in the class field.
     """
 
     def __init__(self,
                  model: str = None,
-                 preprocessor: Union[Preprocessor, List[Preprocessor]] = None,
+                 preprocessor: Union[BasePreprocessor, List[BasePreprocessor]] = None,
                  auto_collate=True,
                  **kwargs):
         # DistributedPipeline uses classmethod to initialize model
         # without calling super().__init__ method
         self.preprocessor = preprocessor
         self._model_prepare = False
         self._model_prepare_lock = Lock()
@@ -450,16 +445,16 @@
         ranks = list(range(self.world_size))
         self.model_pool = Pool(self.world_size)
 
         if 'master_ip' not in kwargs:
             kwargs['master_ip'] = '127.0.0.1'
         master_port = int(kwargs['master_port']
                           ) if 'master_port' in kwargs else random.randint(
-                              29500, 39500)
-        from modelscope.utils.torch_utils import _find_free_port, _is_free_port
+            29500, 39500)
+        from weathon.utils.torch_utils import _find_free_port, _is_free_port
         if not _is_free_port(master_port):
             master_port = _find_free_port()
         kwargs['master_port'] = str(master_port)
         # TODO: Pass ip and port to megatron_util for initialization
         os.environ['MASTER_ADDR'] = kwargs['master_ip']
         os.environ['MASTER_PORT'] = kwargs['master_port']
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/__init__.py` & `weathon-0.0.0.14/weathon/pipelines/cv/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .action_recognition_pipeline import ActionRecognitionPipeline
     from .action_detection_pipeline import ActionDetectionPipeline
     from .animal_recognition_pipeline import AnimalRecognitionPipeline
     from .body_2d_keypoints_pipeline import Body2DKeypointsPipeline
     from .body_3d_keypoints_pipeline import Body3DKeypointsPipeline
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/action_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/action_detection_pipeline.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import math
 import os.path as osp
 from typing import Any, Dict
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.action_detection import ActionDetONNX
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.action_detection import ActionDetONNX
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.action_detection, module_name=Pipelines.action_detection)
 class ActionDetectionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/action_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/action_recognition_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 import os.path as osp
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.action_recognition import (BaseVideoModel,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.action_recognition import (BaseVideoModel,
                                                      PatchShiftTransformer)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import ReadVideoData
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import ReadVideoData
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.action_recognition, module_name=Pipelines.action_recognition)
 class ActionRecognitionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/animal_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/animal_recognition_pipeline.py`

 * *Files 16% similar despite different names*

```diff
@@ -4,22 +4,22 @@
 
 import cv2
 import numpy as np
 import torch
 from PIL import Image
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.animal_recognition import Bottleneck, ResNet
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Devices, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.animal_recognition import Bottleneck, ResNet
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constant import Devices, ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.animal_recognition, module_name=Pipelines.animal_recognition)
 class AnimalRecognitionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/arc_face_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_recognition_ood_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,50 +1,44 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
 from typing import Any, Dict
 
-import cv2
 import numpy as np
-import PIL
-import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.face_recognition.torchkit.backbone.arcface_backbone import \
-    _iresnet
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_recognition, module_name=Pipelines.arc_face_recognition)
-class ArcFaceRecognitionPipeline(FaceProcessingBasePipeline):
+    Tasks.face_recognition, module_name=Pipelines.face_recognition_ood)
+class FaceRecognitionOodPipeline(FaceProcessingBasePipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a face recognition pipeline for prediction
+        use `model` to create a face recognition ood pipeline for prediction
         Args:
             model: model id on modelscope hub.
+
+        Examples:
+
+        >>> from weathon.pipelines import pipeline
+        >>> fr_ood= pipeline('face-recognition-ood', 'damo/cv_ir_face-recognition-ood_rts')
+        >>> fr_ood("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/face_recognition_1.png")
+        {{'img_embedding': array([[ 0.02276129, -0.00761525, ...,0.05735306]],
+            dtype=float32, 'scores': [[0.7656678557395935]]}
         """
 
         # face recong model
         super().__init__(model=model, **kwargs)
-        face_model = _iresnet('arcface_i50', [3, 4, 14, 3])
-        face_model.load_state_dict(
-            torch.load(
-                osp.join(model, ModelFile.TORCH_MODEL_FILE),
-                map_location=self.device))
+        face_model = self.model
         face_model = face_model.to(self.device)
         face_model.eval()
         self.face_model = face_model
         logger.info('face recognition model loaded!')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
         result = super().preprocess(input)
@@ -58,15 +52,17 @@
         face_img = (face_img / 255. - 0.5) / 0.5
         face_img = face_img.astype(np.float32)
         result['img'] = face_img
         return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
         if input['img'] is None:
-            return {OutputKeys.IMG_EMBEDDING: None}
+            return {OutputKeys.IMG_EMBEDDING: None, OutputKeys.SCORES: None}
         img = input['img'].unsqueeze(0)
-        emb = self.face_model(img).detach().cpu().numpy()
+        output = self.face_model(img)
+        emb = output[0].detach().cpu().numpy()
         emb /= np.sqrt(np.sum(emb**2, -1, keepdims=True))  # l2 norm
-        return {OutputKeys.IMG_EMBEDDING: emb}
+        scores = output[1].exp().detach().cpu().numpy().tolist()
+        return {OutputKeys.IMG_EMBEDDING: emb, OutputKeys.SCORES: scores}
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/bad_image_detecting_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/bad_image_detecting_pipeline.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,35 +1,34 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.bad_image_detecting import BadImageDetecting
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.bad_image_detecting import BadImageDetecting
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['BadImageDetecingPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.bad_image_detecting, module_name=Pipelines.bad_image_detecting)
 class BadImageDetecingPipeline(Pipeline):
     """ Image Restoration Pipeline .
 
     Take bad_image_detecting as an example
     ```python
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
     >>> image_pipeline = pipeline(Tasks.bad_image_detecting, model=model_id)
     >>> image_pipeline("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/dogs.jpg")
 
     ```
     """
 
     def __init__(self, model: Union[BadImageDetecting, str], **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/body_2d_keypoints_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/body_2d_keypoints_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,30 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
-from typing import Any, Dict, List, Union
+from typing import Any, Dict, Union
 
 import cv2
-import json
 import numpy as np
 import torch
-from PIL import Image
-from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.body_2d_keypoints.hrnet_v2 import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.body_2d_keypoints.hrnet_v2 import \
     PoseHighResolutionNetV2
-from modelscope.models.cv.body_2d_keypoints.w48 import cfg_128x128_15
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Model, Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.models.cv.body_2d_keypoints.w48 import cfg_128x128_15
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.body_2d_keypoints, module_name=Pipelines.body_2d_keypoints)
 class Body2DKeypointsPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/body_3d_keypoints_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/body_3d_keypoints_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,33 +1,29 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import datetime
-import os.path as osp
 import tempfile
-from typing import Any, Dict, List, Union
+from typing import Any, Dict, Union
 
 import cv2
 import matplotlib
 import matplotlib.pyplot as plt
 import mpl_toolkits.mplot3d.axes3d as p3
 import numpy as np
 import torch
 from matplotlib import animation
 from matplotlib.animation import writers
 from matplotlib.ticker import MultipleLocator
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.body_3d_keypoints.cannonical_pose.body_3d_pose import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.body_3d_keypoints.cannonical_pose.body_3d_pose import \
     KeypointsTypes
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Model, Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 matplotlib.use('Agg')
 
 logger = get_logger()
 
 
 def convert_2_h36m(joints, joints_nbr=15):
@@ -115,15 +111,15 @@
     def __init__(self, model: str, **kwargs):
         """Human body 3D pose estimation.
 
         Args:
             model (str): model id on modelscope hub.
             kwargs (dict, `optional`): Extra kwargs passed into the preprocessor's constructor.
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> body_3d_keypoints = pipeline(Tasks.body_3d_keypoints,
                 model='damo/cv_hdformer_body-3d-keypoints_video')
             >>> test_video_url = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/videos/Walking.54138969.mp4'
             >>> output = body_3d_keypoints(test_video_url)
             >>> print(output)
         """
         super().__init__(model=model, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/card_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/card_detection_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,29 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, List, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base.base_model import Model
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.typing import Image
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.base.base_model import Model
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
+from weathon.utils.typing import Image
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.card_detection, module_name=Pipelines.card_detection)
 class CardDetectionPipeline(Pipeline):
     r""" Card Detection Pipeline.
 
     Examples:
 
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
 
     >>> detector = pipeline('card-detection', 'damo/cv_resnet_carddetection_scrfd34gkps')
     >>> detector("http://www.modelscope.cn/api/v1/models/damo/cv_resnet_carddetection_scrfd34gkps/repo?Revision=master"
     >>>             "&FilePath=description/card_detection1.jpg")
     >>>   {
     >>>    "boxes": [
     >>>        [
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/cmdssl_video_embedding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/cmdssl_video_embedding_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -5,22 +5,22 @@
 
 import decord
 import numpy as np
 import torch
 import torchvision.transforms.functional as TF
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.cmdssl_video_embedding import resnet26_2p1d
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.cmdssl_video_embedding import resnet26_2p1d
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_embedding, module_name=Pipelines.cmdssl_video_embedding)
 class CMDSSLVideoEmbeddingPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/content_check_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_debanding_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,74 +1,65 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
-from typing import Any, Dict
-
-import cv2
-import numpy as np
-import PIL
+from typing import Any, Dict, Optional, Union
+
 import torch
-import torch.nn.functional as F
-from torch import nn
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.models.cv.image_debanding import RRDBImageDebanding
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.image_classification, module_name=Pipelines.content_check)
-class ContentCheckPipeline(Pipeline):
+    Tasks.image_debanding, module_name=Pipelines.image_debanding)
+class ImageDebandingPipeline(Pipeline):
+
+    def __init__(self, model: Union[RRDBImageDebanding, str], **kwargs):
+        """The inference pipeline for image debanding.
 
-    def __init__(self, model: str, **kwargs):
-        """
-        use `model` to create a content check pipeline for prediction
         Args:
-            model: model id on modelscope hub.
-        Example:
-        ContentCheckPipeline can judge whether the picture is pornographic
+            model (`str` or `Model` or module instance): A model instance or a model local dir
+                or a model id in the model hub.
+            preprocessor (`Preprocessor`, `optional`): A Preprocessor instance.
+            kwargs (dict, `optional`):
+                Extra kwargs passed into the preprocessor's constructor.
 
-        ```python
-        >>> from modelscope.pipelines import pipeline
-        >>> cc_func = pipeline('image_classification', 'damo/cv_resnet50_image-classification_cc')
-        >>> cc_func("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/content_check.jpg")
-        {'scores': [0.2789826989173889], 'labels': 'pornographic'}
-        ```
+        Example:
+            >>> import cv2
+            >>> from weathon.outputs import OutputKeys
+            >>> from weathon.pipelines import pipeline
+            >>> from weathon.utils.constants import Tasks
+            >>> debanding = pipeline(Tasks.image_debanding, model='damo/cv_rrdb_image-debanding')
+                result = debanding(
+                    'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/debanding.png')
+            >>> cv2.imwrite('result.png', result[OutputKeys.OUTPUT_IMG])
         """
-
-        # content check model
         super().__init__(model=model, **kwargs)
-        self.test_transforms = transforms.Compose([
-            transforms.Resize(224),
-            transforms.CenterCrop(224),
-            transforms.ToTensor(),
-            transforms.Normalize(
-                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
-        ])
-        logger.info('content check model loaded!')
+        self.model.eval()
+
+        if torch.cuda.is_available():
+            self._device = torch.device('cuda')
+        else:
+            self._device = torch.device('cpu')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
         img = LoadImage.convert_to_img(input)
-        img = self.test_transforms(img).float()
-        result = {}
-        result['img'] = img
+        test_transforms = transforms.Compose([transforms.ToTensor()])
+        img = test_transforms(img)
+        result = {'src': img.unsqueeze(0).to(self._device)}
         return result
 
+    @torch.no_grad()
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        img = input['img'].unsqueeze(0)
-        result = self.model(img)
-        score = [1 - F.softmax(result[:, :5])[0][-1].tolist()]
-        if score[0] < 0.5:
-            label = 'pornographic'
-        else:
-            label = 'normal'
-        return {OutputKeys.SCORES: score, OutputKeys.LABELS: label}
+        return super().forward(input)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        return inputs
+        output_img = (inputs['outputs'].squeeze(0) * 255.).type(
+            torch.uint8).cpu().permute(1, 2, 0).numpy()[:, :, ::-1]
+        return {OutputKeys.OUTPUT_IMG: output_img}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/controllable_image_generation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/controllable_image_generation_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,30 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import glob
-import math
 import os
-import subprocess
-import tempfile
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
-import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.models.cv.controllable_image_generation import ControlNet
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import is_model, is_official_hub_path
-from modelscope.preprocessors.cv.controllable_image_generation import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.models.cv.controllable_image_generation import ControlNet
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import is_model, is_official_hub_path
+from weathon.preprocessors.cv.controllable_image_generation import \
     ControllableImageGenerationPreprocessor
-from modelscope.utils.constant import Frameworks, Invoke, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constant import Invoke, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ControllableImageGenerationPipeline']
 
 
 @PIPELINES.register_module(
@@ -32,17 +26,17 @@
     module_name=Pipelines.controllable_image_generation)
 class ControllableImageGenerationPipeline(Pipeline):
     """  controllable image generation Pipeline.
 
     Examples:
 
     >>> import cv2
-    >>> from modelscope.outputs import OutputKeys
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.outputs import OutputKeys
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
     >>> input_location = 'data/test/images/image_inpainting/image_inpainting_mask_1.png'
     >>> prompt = 'hot air balloon'
     >>> output_image_path = './result.png'
     >>> input = {
     >>>     'image': input_location,
     >>>     'prompt': prompt
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/crowd_counting_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/crowd_counting_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 from typing import Any, Dict
 
 import numpy as np
 import torch
 import torchvision.transforms as transforms
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.crowd_counting import HRNetCrowdCounting
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.crowd_counting import HRNetCrowdCounting
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.crowd_counting, module_name=Pipelines.crowd_counting)
 class CrowdCountingPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ddcolor_image_colorization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ddcolor_image_colorization_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,36 +1,34 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
 import torch
 import torch.nn.functional as F
-from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_colorization import DDColorForImageColorization
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_colorization import DDColorForImageColorization
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_colorization, module_name=Pipelines.ddcolor_image_colorization)
 class DDColorImageColorizationPipeline(Pipeline):
     """ DDColor Image Colorization Pipeline.
 
     Examples:
 
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
 
     >>> colorizer = pipeline('image-colorization', 'damo/cv_ddcolor_image-colorization')
     >>> colorizer("data/test/images/audrey_hepburn.jpg")
        {'output_img': array([[[198, 199, 193],
          [198, 199, 193],
          [197, 199, 195],
          ...,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ddpm_semantic_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ddpm_semantic_segmentation_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 import torch
 import torchvision.transforms as T
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.semantic_segmentation,
     module_name=Pipelines.ddpm_image_semantic_segmentation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_attribute_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_attribute_recognition_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,27 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_attribute_recognition import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_attribute_recognition import \
     FaceAttributeRecognition
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.models.cv.face_recognition.align_face import align_face
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.face_attribute_recognition,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_detection_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,27 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict, List, Union
 
-import cv2
-import numpy as np
-import PIL
-import torch
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.base.base_model import Model
-from modelscope.models.cv.face_detection import ScrfdDetect, SCRFDPreprocessor
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
-from modelscope.utils.typing import Image
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.base.base_model import Model
+from weathon.models.cv.face_detection import ScrfdDetect, SCRFDPreprocessor
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
+from weathon.utils.typing import Image
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.face_detection, module_name=Pipelines.face_detection)
 class FaceDetectionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_emotion_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_emotion_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,20 +1,18 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Any, Dict
 
-import numpy as np
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_emotion import emotion_infer
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_emotion import emotion_infer
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.face_emotion, module_name=Pipelines.face_emotion)
 class FaceEmotionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_human_hand_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_human_hand_detection_pipeline.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,21 +1,19 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
 from typing import Any, Dict
 
-import numpy as np
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_human_hand_detection import det_infer
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_human_hand_detection import det_infer
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.face_human_hand_detection,
     module_name=Pipelines.face_human_hand_detection)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_image_generation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_image_generation_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os
 from typing import Any, Dict
 
-import cv2
 import numpy as np
-import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_generation import Generator
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import load_image
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_generation import Generator
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.face_image_generation, module_name=Pipelines.face_image_generation)
 class FaceImageGenerationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_liveness_ir_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_multi_object_tracking_pipeline.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,90 +1,89 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
-import cv2
-import numpy as np
-import onnxruntime
-import PIL
 import torch
-import torch.nn.functional as F
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.facial_landmark_confidence import \
-    FacialLandmarkConfidence
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
-from . import FaceProcessingBasePipeline
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_multi_object_tracking.tracker.multitracker import \
+    JDETracker
+from weathon.models.cv.video_multi_object_tracking.utils.utils import (
+    LoadVideo, cfg_opt)
+from weathon.models.cv.video_single_object_tracking.utils.utils import \
+    timestamp_format
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_liveness, module_name=Pipelines.face_liveness_ir)
-class FaceLivenessIrPipeline(FaceProcessingBasePipeline):
+    Tasks.video_multi_object_tracking,
+    module_name=Pipelines.video_multi_object_tracking)
+class VideoMultiObjectTrackingPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a face lievness ir pipeline for prediction
+        use `model` to create a multi object tracking pipeline
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, **kwargs)
-        onnx_path = osp.join(model, ModelFile.ONNX_MODEL_FILE)
-        logger.info(f'loading model from {onnx_path}')
-        self.sess, self.input_node_name, self.out_node_name = self.load_onnx_model(
-            onnx_path)
-        logger.info('load model done')
-
-    def load_onnx_model(self, onnx_path):
-        sess = onnxruntime.InferenceSession(onnx_path)
-        out_node_name = []
-        input_node_name = []
-        for node in sess.get_outputs():
-            out_node_name.append(node.name)
-
-        for node in sess.get_inputs():
-            input_node_name.append(node.name)
-
-        return sess, input_node_name, out_node_name
-
-    def preprocess(self, input: Input) -> Dict[str, Any]:
-
-        result = super().preprocess(input)
-        if result is None:
-            rtn_dict = {}
-            rtn_dict['input_tensor'] = None
-            return rtn_dict
-        orig_img = LoadImage.convert_to_ndarray(input)
-        orig_img = orig_img[:, :, ::-1]
-        img = super(FaceLivenessIrPipeline,
-                    self).align_face_padding(orig_img, result['bbox'], 16)
-        if img.shape[0] != 112:
-            img = img[8:120, 8:120, :]
-        img = (img - 127.5) * 0.0078125
-        input_tensor = img.astype('float32').transpose(
-            (2, 0, 1))[np.newaxis, :]
-        result['input_tensor'] = input_tensor
-        return result
-
-    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        if input['input_tensor'] is None:
-            return {OutputKeys.SCORES: None, OutputKeys.BOXES: None}
-        input_feed = {}
-        input_feed[
-            self.input_node_name[0]] = input['input_tensor'].cpu().numpy()
-        result = self.sess.run(self.out_node_name, input_feed=input_feed)
-        out = F.softmax(torch.FloatTensor(result), dim=-1)[0][0]
-        assert result is not None
-        scores = [1 - out[1].tolist()]
-        boxes = input['bbox'].cpu().numpy()[np.newaxis, :].tolist()
-        return {OutputKeys.SCORES: scores, OutputKeys.BOXES: boxes}
+        ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_BIN_FILE)
+        logger.info(f'loading model from {ckpt_path}')
+        opt = cfg_opt()
+        self.opt = opt
+        self.tracker = JDETracker(opt, ckpt_path, self.device)
+        logger.info('init tracker done')
+
+    def preprocess(self, input) -> Input:
+        self.video_path = input[0]
+        return input
+
+    def forward(self, input: Input) -> Dict[str, Any]:
+        dataloader = LoadVideo(input, self.opt.img_size)
+        self.tracker.set_buffer_len(dataloader.frame_rate)
+
+        output_boxes = []
+        output_labels = []
+        output_timestamps = []
+        frame_id = 0
+        for i, (path, img, img0) in enumerate(dataloader):
+            output_boxex_cur = []
+            output_labels_cur = []
+            output_timestamps.append(
+                timestamp_format(seconds=frame_id / dataloader.frame_rate))
+            blob = torch.from_numpy(img).unsqueeze(0)
+            online_targets = self.tracker.update(blob, img0)
+            online_tlwhs = []
+            online_ids = []
+            for t in online_targets:
+                tlwh = t.tlwh
+                tid = t.track_id
+                vertical = tlwh[2] / tlwh[3] > 1.6
+                if tlwh[2] * tlwh[3] > self.opt.min_box_area and not vertical:
+                    online_tlwhs.append([
+                        tlwh[0], tlwh[1], tlwh[0] + tlwh[2], tlwh[1] + tlwh[3]
+                    ])
+                    online_ids.append(tid)
+                output_boxex_cur.append([
+                    int(max(0, tlwh[0])),
+                    int(max(0, tlwh[1])),
+                    int(tlwh[0] + tlwh[2]),
+                    int(tlwh[1] + tlwh[3])
+                ])
+                output_labels_cur.append(tid)
+            output_boxes.append(output_boxex_cur)
+            output_labels.append(output_labels_cur)
+            frame_id += 1
+
+        return {
+            OutputKeys.BOXES: output_boxes,
+            OutputKeys.LABELS: output_labels,
+            OutputKeys.TIMESTAMPS: output_timestamps
+        }
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_liveness_xc_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_quality_assessment_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,59 +1,58 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
-import cv2
 import numpy as np
 import onnxruntime
-import PIL
-import torch
-import torch.nn.functional as F
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.facial_landmark_confidence import \
-    FacialLandmarkConfidence
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_liveness, module_name=Pipelines.face_liveness_xc)
-class FaceLivenessXcPipeline(FaceProcessingBasePipeline):
+    Tasks.face_quality_assessment,
+    module_name=Pipelines.face_quality_assessment)
+class FaceQualityAssessmentPipeline(FaceProcessingBasePipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        FaceLivenessXcPipeline can judge the input face is a real or fake face.
-        use `model` to create a face lievness ir pipeline for prediction
+        use `model` to create a face quality assessment pipeline for prediction
         Args:
             model: model id on modelscope hub.
+        Example:
+        FaceQualityAssessmentPipeline can measure the quality of an input face image,
+        the higher output score represents the better quality
+
         ```python
-        >>> from modelscope.pipelines import pipeline
-        >>> fl_xc = pipeline('face_liveness', 'damo/cv_manual_face-liveness_flxc')
-        >>> fl_xc("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/face_liveness_xc.png")
-        {'scores': [0.03821974992752075], 'boxes': [[12.569677352905273, 6.428711891174316,
-            94.17887115478516, 106.74441528320312]]}
+        >>> from weathon.pipelines import pipeline
+        >>> fqa = pipeline('face-quality-assessment', 'damo/cv_manual_face-quality-assessment_fqa')
+        >>> frfm("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/face_recognition_1.png")
+        {'scores': [0.99949193], 'boxes': [[157.72341918945312, 67.5608139038086,
+            305.8574523925781, 271.25555419921875]]}
+
         ```
         """
         super().__init__(model=model, **kwargs)
         onnx_path = osp.join(model, ModelFile.ONNX_MODEL_FILE)
         logger.info(f'loading model from {onnx_path}')
         self.sess, self.input_node_name, self.out_node_name = self.load_onnx_model(
             onnx_path)
         logger.info('load model done')
 
+    def _batch(self, data):
+        return batch_process(self.model, data)
+
     def load_onnx_model(self, onnx_path):
         sess = onnxruntime.InferenceSession(onnx_path)
         out_node_name = []
         input_node_name = []
         for node in sess.get_outputs():
             out_node_name.append(node.name)
 
@@ -64,30 +63,30 @@
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
         result = super().preprocess(input)
         if result is None:
             rtn_dict = {}
             rtn_dict['input_tensor'] = None
             return rtn_dict
-        img = result['img']
-        img = (img - 127.5) * 0.0078125
-        img = np.expand_dims(img, 0).copy()
-        input_tensor = np.concatenate([img, img, img, img], axis=3)
-        input_tensor = np.transpose(
-            input_tensor, axes=(0, 3, 1, 2)).astype(np.float32)
-        result['input_tensor'] = input_tensor
+        align_img = result['img']
+        face_img = align_img[:, :, ::-1]  # to rgb
+        face_img = (face_img / 255. - 0.5) / 0.5
+        face_img = np.expand_dims(face_img, 0).copy()
+        face_img = np.transpose(face_img, axes=(0, 3, 1, 2))
+        face_img = face_img.astype(np.float32)
+        result['input_tensor'] = face_img
         return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
         if input['input_tensor'] is None:
             return {OutputKeys.SCORES: None, OutputKeys.BOXES: None}
         input_feed = {}
         input_feed[
             self.input_node_name[0]] = input['input_tensor'].cpu().numpy()
         result = self.sess.run(self.out_node_name, input_feed=input_feed)
-        scores = [result[0][0][0].tolist()]
-
+        assert result is not None
+        scores = [np.mean(result[0][0])]
         boxes = input['bbox'].cpu().numpy()[np.newaxis, :].tolist()
         return {OutputKeys.SCORES: scores, OutputKeys.BOXES: boxes}
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_processing_base_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_processing_base_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_recognition.align_face import align_face
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class FaceProcessingBasePipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_quality_assessment_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_recognition_onnx_ir_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,68 +1,48 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
-import cv2
 import numpy as np
 import onnxruntime
-import PIL
-import torch
-import torch.nn.functional as F
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.facial_landmark_confidence import \
-    FacialLandmarkConfidence
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_quality_assessment,
-    module_name=Pipelines.face_quality_assessment)
-class FaceQualityAssessmentPipeline(FaceProcessingBasePipeline):
+    Tasks.face_recognition, module_name=Pipelines.face_recognition_onnx_ir)
+class FaceRecognitionOnnxIrPipeline(FaceProcessingBasePipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a face quality assessment pipeline for prediction
+        FaceRecognitionOnnxIrPipeline  can extract 512-dim feature of IR face image.
+        use `model` to create a face recognition ir onnx pipeline for prediction.
         Args:
             model: model id on modelscope hub.
         Example:
-        FaceQualityAssessmentPipeline can measure the quality of an input face image,
-        the higher output score represents the better quality
-
-        ```python
-        >>> from modelscope.pipelines import pipeline
-        >>> fqa = pipeline('face-quality-assessment', 'damo/cv_manual_face-quality-assessment_fqa')
-        >>> frfm("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/face_recognition_1.png")
-        {'scores': [0.99949193], 'boxes': [[157.72341918945312, 67.5608139038086,
-            305.8574523925781, 271.25555419921875]]}
 
-        ```
+        >>> from weathon.pipelines import pipeline
+        >>> frir = pipeline('face-recognition-ood', 'damo/cv_manual_face-recognition_frir')
+        >>> frir("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/ir_face_recognition_1.png")
+        >>> # {{'img_embedding': array([[ 0.02276129, -0.00761525, ...,0.05735306]], dtype=float32)} }
         """
         super().__init__(model=model, **kwargs)
         onnx_path = osp.join(model, ModelFile.ONNX_MODEL_FILE)
         logger.info(f'loading model from {onnx_path}')
         self.sess, self.input_node_name, self.out_node_name = self.load_onnx_model(
             onnx_path)
         logger.info('load model done')
 
-    def _batch(self, data):
-        return batch_process(self.model, data)
-
     def load_onnx_model(self, onnx_path):
         sess = onnxruntime.InferenceSession(onnx_path)
         out_node_name = []
         input_node_name = []
         for node in sess.get_outputs():
             out_node_name.append(node.name)
 
@@ -84,19 +64,17 @@
         face_img = np.transpose(face_img, axes=(0, 3, 1, 2))
         face_img = face_img.astype(np.float32)
         result['input_tensor'] = face_img
         return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
         if input['input_tensor'] is None:
-            return {OutputKeys.SCORES: None, OutputKeys.BOXES: None}
+            return {OutputKeys.IMG_EMBEDDING: None}
         input_feed = {}
         input_feed[
             self.input_node_name[0]] = input['input_tensor'].cpu().numpy()
-        result = self.sess.run(self.out_node_name, input_feed=input_feed)
-        assert result is not None
-        scores = [np.mean(result[0][0])]
-        boxes = input['bbox'].cpu().numpy()[np.newaxis, :].tolist()
-        return {OutputKeys.SCORES: scores, OutputKeys.BOXES: boxes}
+        emb = self.sess.run(self.out_node_name, input_feed=input_feed)[0]
+        emb /= np.sqrt(np.sum(emb**2, -1, keepdims=True))  # l2 norm
+        return {OutputKeys.IMG_EMBEDDING: emb}
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_recognition_onnx_fm_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_recognition_onnx_fm_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,29 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
-import cv2
 import numpy as np
 import onnxruntime
-import PIL
-import torch
-import torch.nn.functional as F
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.facial_landmark_confidence import \
-    FacialLandmarkConfidence
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.face_recognition, module_name=Pipelines.face_recognition_onnx_fm)
@@ -35,15 +25,15 @@
         to create a face recognition face mask onnx pipeline for prediction.
 
         Args:
             model: model id on modelscope hub.
 
         Examples:
 
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> frfm = pipeline('face-recognition-ood', 'damo/cv_manual_face-recognition_frfm')
         >>> frfm("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/face_recognition_1.png")
         >>> {{'img_embedding': array([[ 0.02276129, -0.00761525, ...,0.05735306]],
         >>>    dtype=float32)} }
         """
         super().__init__(model=model, **kwargs)
         onnx_path = osp.join(model, ModelFile.ONNX_MODEL_FILE)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_recognition_onnx_ir_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/text_error_correction_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,90 +1,87 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
-from typing import Any, Dict
-
-import cv2
-import numpy as np
-import onnxruntime
-import PIL
+from typing import Any, Dict, Optional, Union
+
 import torch
-import torch.nn.functional as F
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.facial_landmark_confidence import \
-    FacialLandmarkConfidence
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
-from . import FaceProcessingBasePipeline
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.nlp import BartForTextErrorCorrection
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
-logger = get_logger()
+__all__ = ['TextErrorCorrectionPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.face_recognition, module_name=Pipelines.face_recognition_onnx_ir)
-class FaceRecognitionOnnxIrPipeline(FaceProcessingBasePipeline):
+    Tasks.text_error_correction, module_name=Pipelines.text_error_correction)
+class TextErrorCorrectionPipeline(Pipeline):
+
+    def __init__(self,
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
+                 config_file: str = None,
+                 device: str = 'gpu',
+                 auto_collate=True,
+                 **kwargs):
+        """
+        Use `model` and `preprocessor` to create a nlp text correction pipeline.
+
+        Args:
+            model (BartForTextErrorCorrection): A model instance, or a model local dir, or a model id in the model hub.
+            preprocessor (TextErrorCorrectionPreprocessor): An optional preprocessor instance.
+            kwargs (dict, `optional`):
+                Extra kwargs passed into the preprocessor's constructor.
+
+        Examples:
+            >>> from weathon.pipelines import pipeline
+            >>> pipeline_ins = pipeline(
+            >>>    task='text-error-correction', model='damo/nlp_bart_text-error-correction_chinese')
+            >>> sentence1 = ''
+            >>> print(pipeline_ins(sentence1))
+
+        To view other examples plese check tests/pipelines/test_text_error_correction.py.
+        """
+        super().__init__(
+            model=model,
+            preprocessor=preprocessor,
+            config_file=config_file,
+            device=device,
+            auto_collate=auto_collate)
+        assert isinstance(self.model, Model), \
+            f'please check whether model config exists in {ModelFile.CONFIGURATION}'
+        if preprocessor is None:
+            self.preprocessor = Preprocessor.from_pretrained(
+                self.model.model_dir, **kwargs)
+        self.vocab = self.preprocessor.vocab
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        with torch.no_grad():
+            return super().forward(inputs, **forward_params)
 
-    def __init__(self, model: str, **kwargs):
+    def postprocess(self, inputs: Dict[str, Tensor],
+                    **postprocess_params) -> Dict[str, str]:
         """
-        FaceRecognitionOnnxIrPipeline  can extract 512-dim feature of IR face image.
-        use `model` to create a face recognition ir onnx pipeline for prediction.
         Args:
-            model: model id on modelscope hub.
-        Example:
+            inputs (Dict[str, Tensor])
+            Examples:
+                {
+                    'predictions': Tensor([1377, 4959, 2785, 6392...]), # tokens need to be decode by tokenizer
+                }
+        Returns:
+            Dict[str, str]: which contains following:
+                - 'output': output str, for example ''
 
-        >>> from modelscope.pipelines import pipeline
-        >>> frir = pipeline('face-recognition-ood', 'damo/cv_manual_face-recognition_frir')
-        >>> frir("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/ir_face_recognition_1.png")
-        >>> # {{'img_embedding': array([[ 0.02276129, -0.00761525, ...,0.05735306]], dtype=float32)} }
         """
-        super().__init__(model=model, **kwargs)
-        onnx_path = osp.join(model, ModelFile.ONNX_MODEL_FILE)
-        logger.info(f'loading model from {onnx_path}')
-        self.sess, self.input_node_name, self.out_node_name = self.load_onnx_model(
-            onnx_path)
-        logger.info('load model done')
-
-    def load_onnx_model(self, onnx_path):
-        sess = onnxruntime.InferenceSession(onnx_path)
-        out_node_name = []
-        input_node_name = []
-        for node in sess.get_outputs():
-            out_node_name.append(node.name)
-
-        for node in sess.get_inputs():
-            input_node_name.append(node.name)
-
-        return sess, input_node_name, out_node_name
-
-    def preprocess(self, input: Input) -> Dict[str, Any]:
-        result = super().preprocess(input)
-        if result is None:
-            rtn_dict = {}
-            rtn_dict['input_tensor'] = None
-            return rtn_dict
-        align_img = result['img']
-        face_img = align_img[:, :, ::-1]  # to rgb
-        face_img = (face_img / 255. - 0.5) / 0.5
-        face_img = np.expand_dims(face_img, 0).copy()
-        face_img = np.transpose(face_img, axes=(0, 3, 1, 2))
-        face_img = face_img.astype(np.float32)
-        result['input_tensor'] = face_img
-        return result
-
-    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        if input['input_tensor'] is None:
-            return {OutputKeys.IMG_EMBEDDING: None}
-        input_feed = {}
-        input_feed[
-            self.input_node_name[0]] = input['input_tensor'].cpu().numpy()
-        emb = self.sess.run(self.out_node_name, input_feed=input_feed)[0]
-        emb /= np.sqrt(np.sum(emb**2, -1, keepdims=True))  # l2 norm
-        return {OutputKeys.IMG_EMBEDDING: emb}
 
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        return inputs
+        sc_tensor = inputs['predictions']
+        if isinstance(sc_tensor, list):
+            sc_tensor = sc_tensor[0]
+        sc_sent = self.vocab.string(
+            sc_tensor, extra_symbols_to_ignore={self.vocab.pad()})
+        sc_sent = (sc_sent + ' ').replace('##', '').rstrip()
+        sc_sent = ''.join(sc_sent.split())
+
+        return {OutputKeys.OUTPUT: sc_sent}
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_recognition_ood_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_recognition_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,77 +1,68 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_recognition.align_face import align_face
+from weathon.models.cv.face_recognition.torchkit.backbone import get_model
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_recognition, module_name=Pipelines.face_recognition_ood)
-class FaceRecognitionOodPipeline(FaceProcessingBasePipeline):
+    Tasks.face_recognition, module_name=Pipelines.face_recognition)
+class FaceRecognitionPipeline(FaceProcessingBasePipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a face recognition ood pipeline for prediction
+        use `model` to create a face recognition pipeline for prediction
         Args:
             model: model id on modelscope hub.
-
-        Examples:
-
-        >>> from modelscope.pipelines import pipeline
-        >>> fr_ood= pipeline('face-recognition-ood', 'damo/cv_ir_face-recognition-ood_rts')
-        >>> fr_ood("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/face_recognition_1.png")
-        {{'img_embedding': array([[ 0.02276129, -0.00761525, ...,0.05735306]],
-            dtype=float32, 'scores': [[0.7656678557395935]]}
         """
 
         # face recong model
         super().__init__(model=model, **kwargs)
-        face_model = self.model
-        face_model = face_model.to(self.device)
+        device = torch.device(
+            f'cuda:{0}' if torch.cuda.is_available() else 'cpu')
+        self.device = device
+        face_model = get_model('IR_101')([112, 112])
+        face_model.load_state_dict(
+            torch.load(
+                osp.join(model, ModelFile.TORCH_MODEL_BIN_FILE),
+                map_location=device))
+        face_model = face_model.to(device)
         face_model.eval()
         self.face_model = face_model
         logger.info('face recognition model loaded!')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
         result = super().preprocess(input)
-        if result is None:
-            rtn_dict = {}
-            rtn_dict['img'] = None
-            return rtn_dict
         align_img = result['img']
         face_img = align_img[:, :, ::-1]  # to rgb
         face_img = np.transpose(face_img, axes=(2, 0, 1))
         face_img = (face_img / 255. - 0.5) / 0.5
         face_img = face_img.astype(np.float32)
         result['img'] = face_img
         return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        if input['img'] is None:
-            return {OutputKeys.IMG_EMBEDDING: None, OutputKeys.SCORES: None}
+        assert input['img'] is not None
         img = input['img'].unsqueeze(0)
-        output = self.face_model(img)
-        emb = output[0].detach().cpu().numpy()
+        emb = self.face_model(img).detach().cpu().numpy()
         emb /= np.sqrt(np.sum(emb**2, -1, keepdims=True))  # l2 norm
-        scores = output[1].exp().detach().cpu().numpy().tolist()
-        return {OutputKeys.IMG_EMBEDDING: emb, OutputKeys.SCORES: scores}
+        return {OutputKeys.IMG_EMBEDDING: emb}
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/mask_face_recognition_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,57 +1,63 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
+from collections import OrderedDict
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.face_recognition.torchkit.backbone import get_model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_recognition.align_face import align_face
+from weathon.models.cv.face_recognition.torchkit.backbone.facemask_backbone import \
+    iresnet286
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_recognition, module_name=Pipelines.face_recognition)
-class FaceRecognitionPipeline(FaceProcessingBasePipeline):
+    Tasks.face_recognition, module_name=Pipelines.mask_face_recognition)
+class MaskFaceRecognitionPipeline(FaceProcessingBasePipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a face recognition pipeline for prediction
+        use `model` to create a mask face recognition pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
 
         # face recong model
         super().__init__(model=model, **kwargs)
-        device = torch.device(
-            f'cuda:{0}' if torch.cuda.is_available() else 'cpu')
-        self.device = device
-        face_model = get_model('IR_101')([112, 112])
-        face_model.load_state_dict(
-            torch.load(
-                osp.join(model, ModelFile.TORCH_MODEL_BIN_FILE),
-                map_location=device))
-        face_model = face_model.to(device)
+        face_model = iresnet286()
+        state_dict = torch.load(osp.join(model, ModelFile.TORCH_MODEL_FILE))
+        reviesed_state_dict = self._prefix_revision(state_dict)
+        face_model.load_state_dict(reviesed_state_dict, strict=True)
+        face_model = face_model.to(self.device)
         face_model.eval()
         self.face_model = face_model
         logger.info('face recognition model loaded!')
 
+    def _prefix_revision(self, state_dict):
+        new_state_dict = OrderedDict()
+        for k, v in state_dict.items():
+            if k.startswith('module.'):
+                k = k[7:]
+            new_state_dict[k] = v
+        state = new_state_dict
+        return state
+
     def preprocess(self, input: Input) -> Dict[str, Any]:
         result = super().preprocess(input)
         align_img = result['img']
         face_img = align_img[:, :, ::-1]  # to rgb
         face_img = np.transpose(face_img, axes=(2, 0, 1))
         face_img = (face_img / 255. - 0.5) / 0.5
         face_img = face_img.astype(np.float32)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/face_reconstruction_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/face_reconstruction_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,38 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import io
 import os
 import shutil
 from typing import Any, Dict
 
 import cv2
 import face_alignment
 import numpy as np
 import PIL.Image
 import tensorflow as tf
 import torch
 from scipy.io import loadmat, savemat
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_reconstruction.models.facelandmark.large_base_lmks_infer import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_reconstruction.models.facelandmark.large_base_lmks_infer import \
     LargeBaseLmkInfer
-from modelscope.models.cv.face_reconstruction.utils import (
+from weathon.models.cv.face_reconstruction.utils import (
     align_for_lm, align_img, draw_line, enlarged_bbox, image_warp_grid1,
     load_lm3d, mesh_to_string, read_obj, resize_on_long_side, spread_flow,
     write_obj)
-from modelscope.models.cv.skin_retouching.retinaface.predict_single import \
+from weathon.models.cv.skin_retouching.retinaface.predict_single import \
     Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.device import create_device, device_placement
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.device import create_device, device_placement
+from weathon.utils.logger import get_logger
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
     tf.disable_eager_execution()
 
 logger = get_logger()
 
@@ -46,15 +45,15 @@
 
         Args:
             model (`str` or `Model` or module instance): A model instance or a model local dir
                 or a model id in the model hub.
             device ('str'): device str, should be either cpu, cuda, gpu, gpu:X or cuda:X.
 
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> test_image = 'data/test/images/face_reconstruction.jpg'
             >>> pipeline_faceRecon = pipeline('face-reconstruction',
                 model='damo/cv_resnet50_face-reconstruction')
             >>> result = pipeline_faceRecon(test_image)
             >>> mesh = result[OutputKeys.OUTPUT]['mesh']
             >>> texture_map = result[OutputKeys.OUTPUT_IMG]
             >>> mesh['texture_map'] = texture_map
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/facial_expression_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/facial_landmark_confidence_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,68 +1,77 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.facial_expression_recognition import \
-    FacialExpressionRecognition
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_recognition.align_face import align_face
+from weathon.models.cv.facial_landmark_confidence import \
+    FacialLandmarkConfidence
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.facial_expression_recognition,
-    module_name=Pipelines.facial_expression_recognition)
-class FacialExpressionRecognitionPipeline(FaceProcessingBasePipeline):
+    Tasks.face_2d_keypoints, module_name=Pipelines.facial_landmark_confidence)
+class FacialLandmarkConfidencePipeline(FaceProcessingBasePipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a face detection pipeline for prediction
+        use `model` to create a facial landmrk confidence pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, **kwargs)
         ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_FILE)
         logger.info(f'loading model from {ckpt_path}')
-        device = torch.device(
-            f'cuda:{0}' if torch.cuda.is_available() else 'cpu')
-        fer = FacialExpressionRecognition(model_path=ckpt_path, device=device)
-        self.fer = fer
-        self.device = device
+        flcm = FacialLandmarkConfidence(
+            model_path=ckpt_path, device=self.device)
+        self.flcm = flcm
         logger.info('load model done')
 
-        self.map_list = [
-            'Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'
-        ]
-
     def preprocess(self, input: Input) -> Dict[str, Any]:
+
         result = super().preprocess(input)
         if result is None:
             rtn_dict = {}
             rtn_dict['img'] = None
             return rtn_dict
+        img = LoadImage.convert_to_ndarray(input)
+        img = img[:, :, ::-1]
+        result['orig_img'] = img.astype(np.float32)
         return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
         if input['img'] is None:
-            return {OutputKeys.SCORES: None, OutputKeys.LABELS: None}
-        result = self.fer(input)
+            return {
+                OutputKeys.SCORES: None,
+                OutputKeys.POSES: None,
+                OutputKeys.KEYPOINTS: None,
+                OutputKeys.BOXES: None
+            }
+        result = self.flcm(input)
         assert result is not None
-        scores = result[0].tolist()
-        return {OutputKeys.SCORES: scores, OutputKeys.LABELS: self.map_list}
+        lms = result[0].reshape(-1, 10).tolist()
+        scores = [1 - result[1].tolist()]
+        boxes = input['bbox'].cpu().numpy()[np.newaxis, :].tolist()
+        output_poses = []
+        return {
+            OutputKeys.SCORES: scores,
+            OutputKeys.POSES: output_poses,
+            OutputKeys.KEYPOINTS: lms,
+            OutputKeys.BOXES: boxes
+        }
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/facial_landmark_confidence_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_face_fusion_pipeline.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,78 +1,65 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
 from typing import Any, Dict
 
-import cv2
-import numpy as np
-import PIL
-import torch
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_recognition.align_face import align_face
-from modelscope.models.cv.facial_landmark_confidence import \
-    FacialLandmarkConfidence
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
-from . import FaceProcessingBasePipeline
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_2d_keypoints, module_name=Pipelines.facial_landmark_confidence)
-class FacialLandmarkConfidencePipeline(FaceProcessingBasePipeline):
+    Tasks.image_face_fusion, module_name=Pipelines.image_face_fusion)
+class ImageFaceFusionPipeline(Pipeline):
+    """
+    Image face fusion pipeline.
+
+    Examples:
+
+    >>> from weathon.pipelines import pipeline
+    >>> image_face_fusion = pipeline(Tasks.image_face_fusion,
+                   model='damo/cv_unet-image-face-fusion_damo')
+    >>> image_face_fusion({
+            'template': 'facefusion_template.jpg', # template path (str)
+            'image': 'facefusion_user.jpg', # user path (str)
+        })
+       {
+        "output_img": [H * W * 3] 0~255, we can use cv2.imwrite to save output_img as an image.
+        }
+    """
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a facial landmrk confidence pipeline for prediction
+        use `model` to create image-face-fusion pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, **kwargs)
-        ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_FILE)
-        logger.info(f'loading model from {ckpt_path}')
-        flcm = FacialLandmarkConfidence(
-            model_path=ckpt_path, device=self.device)
-        self.flcm = flcm
-        logger.info('load model done')
-
-    def preprocess(self, input: Input) -> Dict[str, Any]:
-
-        result = super().preprocess(input)
-        if result is None:
-            rtn_dict = {}
-            rtn_dict['img'] = None
-            return rtn_dict
-        img = LoadImage.convert_to_ndarray(input)
-        img = img[:, :, ::-1]
-        result['orig_img'] = img.astype(np.float32)
+        logger.info('image face fusion model init done')
+
+    def preprocess(self,
+                   template: Input,
+                   user: Input = None) -> Dict[str, Any]:
+        if type(template) is dict:  # for demo service
+            user = template['user']
+            template = template['template']
+
+        template_img = LoadImage.convert_to_ndarray(template)
+        user_img = LoadImage.convert_to_ndarray(user)
+
+        result = {'template': template_img, 'user': user_img}
         return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        if input['img'] is None:
-            return {
-                OutputKeys.SCORES: None,
-                OutputKeys.POSES: None,
-                OutputKeys.KEYPOINTS: None,
-                OutputKeys.BOXES: None
-            }
-        result = self.flcm(input)
-        assert result is not None
-        lms = result[0].reshape(-1, 10).tolist()
-        scores = [1 - result[1].tolist()]
-        boxes = input['bbox'].cpu().numpy()[np.newaxis, :].tolist()
-        output_poses = []
-        return {
-            OutputKeys.SCORES: scores,
-            OutputKeys.POSES: output_poses,
-            OutputKeys.KEYPOINTS: lms,
-            OutputKeys.BOXES: boxes
-        }
+        template_img = input['template']
+        user_img = input['user']
+        output = self.model.inference(template_img, user_img)
+        result = {'outputs': output}
+        return result
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        return inputs
+        output_img = inputs['outputs']
+        return {OutputKeys.OUTPUT_IMG: output_img}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/fast_instance_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/fast_instance_segmentation_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import numpy as np
 import torch
 import torchvision.transforms as T
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_instance_segmentation import FastInst
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_instance_segmentation import FastInst
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_segmentation, module_name=Pipelines.fast_instance_segmentation)
 class FastInstanceSegmentationPipeline(Pipeline):
@@ -33,16 +32,16 @@
             model (`str` or `Model` or module instance): A model instance or a model local dir
                 or a model id in the model hub.
             preprocessor (`Preprocessor`, `optional`): A Preprocessor instance.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.outputs import OutputKeys
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.outputs import OutputKeys
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('image-segmentation',
                 model='damo/cv_resnet50_fast-instance-segmentation_coco')
             >>> input_img = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/image_instance_segmentation.jpg'
             >>> print(pipeline_ins(input_img)[OutputKeys.LABELS])
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
         self.model.eval()
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/general_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/general_recognition_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -4,22 +4,22 @@
 
 import cv2
 import numpy as np
 import torch
 from PIL import Image
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.animal_recognition import resnet
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage, load_image
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.animal_recognition import resnet
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage, load_image
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.general_recognition, module_name=Pipelines.general_recognition)
 class GeneralRecognitionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/hand_static_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_detection_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,41 +1,57 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Any, Dict
 
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.hand_static import hand_model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-
-logger = get_logger()
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
-    Tasks.hand_static, module_name=Pipelines.hand_static)
-class HandStaticPipeline(Pipeline):
+    Tasks.human_detection, module_name=Pipelines.human_detection)
+@PIPELINES.register_module(
+    Tasks.image_object_detection, module_name=Pipelines.object_detection)
+@PIPELINES.register_module(
+    Tasks.image_object_detection,
+    module_name=Pipelines.abnormal_object_detection)
+class ImageDetectionPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create hand static pipeline for prediction
-        Args:
             model: model id on modelscope hub.
         """
-
-        super().__init__(model=model, **kwargs)
-        logger.info('load model done')
+        super().__init__(model=model, auto_collate=False, **kwargs)
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
-        img = LoadImage.convert_to_ndarray(input['img_path'])
-        return img
+
+        img = LoadImage.convert_to_ndarray(input)
+        img = img.astype(np.float64)
+        img = self.model.preprocess(img)
+        result = {'img': img}
+        return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        result = hand_model.infer(input, self.model, self.device)
-        return {OutputKeys.OUTPUT: result}
+
+        outputs = self.model.inference(input['img'])
+        result = {'data': outputs}
+        return result
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        return inputs
+
+        bboxes, scores, labels = self.model.postprocess(inputs['data'])
+        if bboxes is None:
+            outputs = {
+                OutputKeys.SCORES: [],
+                OutputKeys.LABELS: [],
+                OutputKeys.BOXES: []
+            }
+            return outputs
+        outputs = {
+            OutputKeys.SCORES: scores,
+            OutputKeys.LABELS: labels,
+            OutputKeys.BOXES: bboxes
+        }
+        return outputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/hicossl_video_embedding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/hicossl_video_embedding_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 import os.path as osp
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.action_recognition import BaseVideoModel
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import ReadVideoData
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.action_recognition import BaseVideoModel
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import ReadVideoData
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_embedding, module_name=Pipelines.hicossl_video_embedding)
 class HICOSSLVideoEmbeddingPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/human_reconstruction_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/human_reconstruction_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,26 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import shutil
 from typing import Any, Dict
 
 import numpy as np
 import torch
 import trimesh
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.human_reconstruction.utils import (
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.human_reconstruction.utils import (
     keep_largest, reconstruction, save_obj_mesh, save_obj_mesh_with_color,
     to_tensor)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.human_reconstruction, module_name=Pipelines.human_reconstruction)
 class HumanReconstructionPipeline(Pipeline):
@@ -30,15 +29,15 @@
         Human Reconstruction Pipeline. Given one image generate a human mesh.
 
         Args:
             model (`str` or `Model` or module instance): A model instance or a model local dir
                 or a model id in the model hub.
 
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> test_input = 'human_reconstruction.jpg' # input image path
             >>> pipeline_humanRecon = pipeline('human-reconstruction',
                 model='damo/cv_hrnet_image-human-reconstruction')
             >>> result = pipeline_humanRecon(test_input)
             >>> output =  result[OutputKeys.OUTPUT]
         """
         super().__init__(model=model, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_bts_depth_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_bts_depth_estimation_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,39 +1,38 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import albumentations as A
 import cv2
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.cv.image_utils import depth_to_color
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.cv.image_utils import depth_to_color
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_depth_estimation,
     module_name=Pipelines.image_bts_depth_estimation)
 class ImageBTSDepthEstimationPipeline(Pipeline):
     r""" Image depth estimation pipeline of BTS model.
 
         Examples:
 
         >>> import cv2
-        >>> from modelscope.outputs import OutputKeys
-        >>> from modelscope.pipelines import pipeline
-        >>> from modelscope.utils.constant import Tasks
+        >>> from weathon.outputs import OutputKeys
+        >>> from weathon.pipelines import pipeline
+        >>> from weathon.utils.constants import Tasks
 
         >>> estimator = pipeline(Tasks.image_depth_estimation, 'damo/cv_densenet161_image-depth-estimation_bts')
         >>> result = estimator(
             "https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/image_depth_estimation_kitti_007517.png")
         >>> cv2.imwrite('result_depth_color.jpg', result[OutputKeys.DEPTHS_COLOR])
         >>> cv2.imwrite('result_depth.jpg', result[OutputKeys.DEPTHS])
         >>>
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_cartoon_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_cartoon_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,27 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import tensorflow as tf
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.cartoon import (FaceAna, get_f5p,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.cartoon import (FaceAna, get_f5p,
                                           get_reference_facial_points,
                                           padTo16x, resize_size,
                                           warp_and_crop_face)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 from ...utils.device import device_placement
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
     tf.disable_eager_execution()
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_classification_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_classification_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines, Preprocessors
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.constant import Fields, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines, Preprocessors
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import Preprocessor
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.constants import Fields, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_classification, module_name=Pipelines.image_classification)
 @PIPELINES.register_module(
@@ -76,15 +75,15 @@
                 if next(self.model.parameters()).is_cuda:
                     self.target_gpus = [next(self.model.parameters()).device]
                 assert hasattr(self.model, 'model_dir'), 'Model used in GeneralImageClassificationPipeline' \
                                                          ' should has a `model_dir` attribute to build a preprocessor.'
                 self.preprocessor = Preprocessor.from_pretrained(
                     self.model.model_dir, **kwargs)
                 if self.preprocessor.__class__.__name__ == 'ImageClassificationBypassPreprocessor':
-                    from modelscope.preprocessors import ImageClassificationMmcvPreprocessor
+                    from weathon.preprocessors import ImageClassificationMmcvPreprocessor
                     self.preprocessor = ImageClassificationMmcvPreprocessor(
                         self.model.model_dir, **kwargs)
         logger.info('load model done')
 
     def _batch(self, data):
         if self.model.__class__.__name__ == 'OfaForAllTasks':
             return batch_process(self.model, data)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_color_enhance_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_color_enhance_pipeline.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import (ImageColorEnhanceFinetunePreprocessor,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import (ImageColorEnhanceFinetunePreprocessor,
                                       LoadImage)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_color_enhancement,
     module_name=Pipelines.adaint_image_color_enhance)
@@ -41,17 +40,17 @@
                 or a model id in the model hub.
             preprocessor (`Preprocessor`, `optional`): A Preprocessor instance.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Example:
             >>> import cv2
-            >>> from modelscope.outputs import OutputKeys
-            >>> from modelscope.pipelines import pipeline
-            >>> from modelscope.utils.constant import Tasks
+            >>> from weathon.outputs import OutputKeys
+            >>> from weathon.pipelines import pipeline
+            >>> from weathon.utils.constants import Tasks
 
             >>> img = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/image_color_enhance.png'
                 image_color_enhance = pipeline(Tasks.image_color_enhancement,
                     model='damo/cv_deeplpfnet_image-color-enhance-models')
                 result = image_color_enhance(img)
             >>> cv2.imwrite('enhanced_result.png', result[OutputKeys.OUTPUT_IMG])
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_colorization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_colorization_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 from torchvision import models, transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_colorization import (DynamicUnetDeep,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_colorization import (DynamicUnetDeep,
                                                      DynamicUnetWide, NormType)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_colorization, module_name=Pipelines.image_colorization)
 class ImageColorizationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_debanding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_reid_person_pipeline.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,66 +1,59 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Optional, Union
+import math
+import os
+from typing import Any, Dict
 
 import torch
-from torchvision import transforms
+import torchvision.transforms as T
+from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.models.cv.image_debanding import RRDBImageDebanding
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.image_debanding, module_name=Pipelines.image_debanding)
-class ImageDebandingPipeline(Pipeline):
+    Tasks.image_reid_person, module_name=Pipelines.image_reid_person)
+class ImageReidPersonPipeline(Pipeline):
 
-    def __init__(self, model: Union[RRDBImageDebanding, str], **kwargs):
-        """The inference pipeline for image debanding.
-
-        Args:
-            model (`str` or `Model` or module instance): A model instance or a model local dir
-                or a model id in the model hub.
-            preprocessor (`Preprocessor`, `optional`): A Preprocessor instance.
-            kwargs (dict, `optional`):
-                Extra kwargs passed into the preprocessor's constructor.
-
-        Example:
-            >>> import cv2
-            >>> from modelscope.outputs import OutputKeys
-            >>> from modelscope.pipelines import pipeline
-            >>> from modelscope.utils.constant import Tasks
-            >>> debanding = pipeline(Tasks.image_debanding, model='damo/cv_rrdb_image-debanding')
-                result = debanding(
-                    'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/debanding.png')
-            >>> cv2.imwrite('result.png', result[OutputKeys.OUTPUT_IMG])
+    def __init__(self, model: str, **kwargs):
+        """
+            model: model id on modelscope hub.
         """
-        super().__init__(model=model, **kwargs)
+        assert isinstance(model, str), 'model must be a single str'
+        super().__init__(model=model, auto_collate=False, **kwargs)
+        logger.info(f'loading model config from dir {model}')
+
+        cfg_path = os.path.join(model, ModelFile.CONFIGURATION)
+        cfg = Config.from_file(cfg_path)
+        cfg = cfg.model.cfg
+        self.model = self.model.to(self.device)
         self.model.eval()
 
-        if torch.cuda.is_available():
-            self._device = torch.device('cuda')
-        else:
-            self._device = torch.device('cpu')
+        self.val_transforms = T.Compose([
+            T.Resize(cfg.INPUT.SIZE_TEST),
+            T.ToTensor(),
+            T.Normalize(mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD)
+        ])
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
         img = LoadImage.convert_to_img(input)
-        test_transforms = transforms.Compose([transforms.ToTensor()])
-        img = test_transforms(img)
-        result = {'src': img.unsqueeze(0).to(self._device)}
-        return result
+        img = self.val_transforms(img)
+        img = img.unsqueeze(0)
+        img = img.to(self.device)
+        return {'img': img}
 
-    @torch.no_grad()
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        return super().forward(input)
+        img = input['img']
+        img_embedding = self.model(img)
+        img_embedding = img_embedding.detach().cpu().numpy()
+        return {OutputKeys.IMG_EMBEDDING: img_embedding}
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        output_img = (inputs['outputs'].squeeze(0) * 255.).type(
-            torch.uint8).cpu().permute(1, 2, 0).numpy()[:, :, ::-1]
-        return {OutputKeys.OUTPUT_IMG: output_img}
+        return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_deblur_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_deblur_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,37 +1,36 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_deblur import NAFNetForImageDeblur
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import ImageDeblurPreprocessor, LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_deblur import NAFNetForImageDeblur
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import ImageDeblurPreprocessor, LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ImageDeblurPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.image_deblurring, module_name=Pipelines.image_deblur)
 class ImageDeblurPipeline(Pipeline):
     """
 
     Examples:
 
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
-    >>> from modelscope.outputs import OutputKeys
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
+    >>> from weathon.outputs import OutputKeys
     >>> import cv2
     >>>
     >>> img = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/blurry.jpg'
     >>> image_deblur_pipeline = pipeline(Tasks.image_deblurring, 'damo/cv_nafnet_image-deblur_gopro')
     >>> result = image_deblur_pipeline(img)[OutputKeys.OUTPUT_IMG]
     >>> cv2.imwrite('result.png', result)
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_defrcn_fewshot_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_defrcn_fewshot_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,34 +1,32 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base.base_model import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.base.base_model import Model
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @PIPELINES.register_module(
     Tasks.image_fewshot_detection,
     module_name=Pipelines.image_fewshot_detection)
 class ImageDefrcnDetectionPipeline(Pipeline):
     r"""
     Image DeFRCN few-shot detection Pipeline. Given a image, pipeline will return the detection results on the image.
 
     Examples:
 
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> detector = pipeline('image-fewshot-detection', 'damo/cv_resnet101_detection_fewshot-defrcn')
         >>> detector('/Path/Image')
         >>> {'scores': [0.8307567834854126, 0.1606406420469284],
         >>>  'labels': ['person', 'dog'],
         >>>  'boxes': [[27.391937255859375, 0.0, 353.0, 500.0],
         >>>            [64.22428131103516, 229.2884521484375, 213.90573120117188, 370.0657958984375]]}
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_denoise_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_denoise_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.cv.image_denoise import NAFNetForImageDenoise
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import ImageDenoisePreprocessor, LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.cv.image_denoise import NAFNetForImageDenoise
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import ImageDenoisePreprocessor, LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ImageDenoisePipeline']
 
 
 @PIPELINES.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_depth_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_depth_estimation_pipeline.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Union
+from typing import Any, Dict
 
 import cv2
 import numpy as np
-import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.cv.image_utils import depth_to_color
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.cv.image_utils import depth_to_color
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_depth_estimation, module_name=Pipelines.image_depth_estimation)
 class ImageDepthEstimationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_depth_estimation_pipeline.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,59 +1,49 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
-import numpy as np
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
+logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.human_detection, module_name=Pipelines.human_detection)
-@PIPELINES.register_module(
-    Tasks.image_object_detection, module_name=Pipelines.object_detection)
-@PIPELINES.register_module(
-    Tasks.image_object_detection,
-    module_name=Pipelines.abnormal_object_detection)
-class ImageDetectionPipeline(Pipeline):
+    Tasks.video_depth_estimation, module_name=Pipelines.video_depth_estimation)
+class VideoDepthEstimationPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
+        use `model` to create a video depth estimation pipeline for prediction
+        Args:
             model: model id on modelscope hub.
         """
-        super().__init__(model=model, auto_collate=False, **kwargs)
+        super().__init__(model=model, **kwargs)
+
+        logger.info('depth estimation model, pipeline init')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
+        video_path = input
+        data = {'video_path': video_path}
 
-        img = LoadImage.convert_to_ndarray(input)
-        img = img.astype(np.float64)
-        img = self.model.preprocess(img)
-        result = {'img': img}
-        return result
+        return data
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-
-        outputs = self.model.inference(input['img'])
-        result = {'data': outputs}
-        return result
+        results = self.model.inference(input)
+        return results
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
+        results = self.model.postprocess(inputs)
+        depths = results['depths']
+        depths_color = results['depths_color']
+        poses = results['poses']
 
-        bboxes, scores, labels = self.model.postprocess(inputs['data'])
-        if bboxes is None:
-            outputs = {
-                OutputKeys.SCORES: [],
-                OutputKeys.LABELS: [],
-                OutputKeys.BOXES: []
-            }
-            return outputs
         outputs = {
-            OutputKeys.SCORES: scores,
-            OutputKeys.LABELS: labels,
-            OutputKeys.BOXES: bboxes
+            OutputKeys.DEPTHS: depths,
+            OutputKeys.DEPTHS_COLOR: depths_color,
+            OutputKeys.POSES: poses
         }
+
         return outputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_driving_perception_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_driving_perception_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,38 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_driving_perception import (
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_driving_perception import (
     ImageDrivingPerceptionPreprocessor, driving_area_mask, lane_line_mask,
     non_max_suppression, scale_coords, split_for_trace_model)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_driving_perception,
     module_name=Pipelines.yolopv2_image_driving_percetion_bdd100k)
 class ImageDrivingPerceptionPipeline(Pipeline):
     """ Image Driving Perception Pipeline. Given a image,
     pipeline will detects cars, and segments both lane lines and drivable areas.
     Example:
 
     ```python
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
     >>> image_driving_perception_pipeline = pipeline(Tasks.image_driving_perception,
                                                         model='damo/cv_yolopv2_image-driving-perception_bdd100k')
     >>> image_driving_perception_pipeline(img_path)
     {
         'boxes': array([[1.0000e+00, 2.8600e+02, 4.0700e+02, 6.2600e+02],
                         [8.8200e+02, 2.9600e+02, 1.0910e+03, 4.4700e+02],
                         [3.7200e+02, 2.7500e+02, 5.2100e+02, 3.5500e+02],
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_face_fusion_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/text_to_image_synthesis_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,68 +1,51 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict
+from typing import Any, Dict, Optional
 
-import numpy as np
-
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import (
+    MultiStageDiffusionForTextToImageSynthesis, OfaForTextToImageSynthesis)
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import OfaPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.image_face_fusion, module_name=Pipelines.image_face_fusion)
-class ImageFaceFusionPipeline(Pipeline):
-    """
-    Image face fusion pipeline.
-
-    Examples:
-
-    >>> from modelscope.pipelines import pipeline
-    >>> image_face_fusion = pipeline(Tasks.image_face_fusion,
-                   model='damo/cv_unet-image-face-fusion_damo')
-    >>> image_face_fusion({
-            'template': 'facefusion_template.jpg', # template path (str)
-            'image': 'facefusion_user.jpg', # user path (str)
-        })
-       {
-        "output_img": [H * W * 3] 0~255, we can use cv2.imwrite to save output_img as an image.
-        }
-    """
-
-    def __init__(self, model: str, **kwargs):
+    Tasks.text_to_image_synthesis,
+    module_name=Pipelines.text_to_image_synthesis)
+class TextToImageSynthesisPipeline(Pipeline):
+
+    def __init__(self,
+                 model: str,
+                 preprocessor: Optional[Preprocessor] = None,
+                 **kwargs):
         """
-        use `model` to create image-face-fusion pipeline for prediction
+        use `model` and `preprocessor` to create a kws pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
-        super().__init__(model=model, **kwargs)
-        logger.info('image face fusion model init done')
-
-    def preprocess(self,
-                   template: Input,
-                   user: Input = None) -> Dict[str, Any]:
-        if type(template) is dict:  # for demo service
-            user = template['user']
-            template = template['template']
-
-        template_img = LoadImage.convert_to_ndarray(template)
-        user_img = LoadImage.convert_to_ndarray(user)
-
-        result = {'template': template_img, 'user': user_img}
-        return result
+        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
+        if preprocessor is None and isinstance(self.model,
+                                               OfaForTextToImageSynthesis):
+            self.preprocessor = OfaPreprocessor(self.model.model_dir)
+
+    def preprocess(self, input: Input, **preprocess_params) -> Dict[str, Any]:
+        if self.preprocessor is not None:
+            return self.preprocessor(input, **preprocess_params)
+        else:
+            return input
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        template_img = input['template']
-        user_img = input['user']
-        output = self.model.inference(template_img, user_img)
-        result = {'outputs': output}
-        return result
+        if isinstance(self.model,
+                      (OfaForTextToImageSynthesis,
+                       MultiStageDiffusionForTextToImageSynthesis)):
+            return self.model(input)
+        return self.model.generate(input)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        output_img = inputs['outputs']
-        return {OutputKeys.OUTPUT_IMG: output_img}
+        if not isinstance(inputs, list):
+            inputs = [inputs]
+        return {OutputKeys.OUTPUT_IMGS: inputs}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_human_parsing_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_human_parsing_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import numpy as np
 import torch
 import torchvision.transforms as T
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_human_parsing import (
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_human_parsing import (
     M2FP, center_to_target_size_test)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_segmentation, module_name=Pipelines.image_human_parsing)
 class ImageHumanParsingPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_inpainting_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_inpainting_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,26 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 import torch.nn as nn
 from torch.utils.data._utils.collate import default_collate
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_inpainting import FFTInpainting
-from modelscope.models.cv.image_inpainting.refinement import refine_predict
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_inpainting import FFTInpainting
+from weathon.models.cv.image_inpainting.refinement import refine_predict
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_inpainting, module_name=Pipelines.image_inpainting)
 class ImageInpaintingPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_inpainting_sdv2_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_inpainting_sdv2_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,41 +1,36 @@
 # Copyright  Alibaba, Inc. and its affiliates.
 
-import math
-import os
-import sys
-import tempfile
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict
 
 import cv2
 import numpy as np
 import torch
 from diffusers import StableDiffusionInpaintPipeline
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.registry import PIPELINES
+from weathon.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
     DiffusersPipeline
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Tasks
+from weathon.preprocessors.image import load_image
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     Tasks.image_inpainting, module_name=Pipelines.image_inpainting_sdv2)
 class ImageInpaintingSDV2Pipeline(DiffusersPipeline):
     """ Stable Diffusion for Image Inpainting Pipeline.
 
     Example:
 
     >>> import cv2
-    >>> from modelscope.outputs import OutputKeys
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.outputs import OutputKeys
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
     >>> input_location = 'data/test/images/image_inpainting/image_inpainting.png'
     >>> input_mask_location = 'data/test/images/image_inpainting/image_inpainting_mask.png'
     >>> prompt = 'background'
 
     >>> input = {
     >>>     'image': input_location,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_instance_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_instance_segmentation_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,27 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Optional, Union
 
 import cv2
 import numpy as np
 import torch
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base.base_model import Model
-from modelscope.models.cv.image_instance_segmentation import (
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.base.base_model import Model
+from weathon.models.cv.image_instance_segmentation import (
     CascadeMaskRCNNSwinModel, get_img_ins_seg_result)
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import (ImageInstanceSegmentationPreprocessor,
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import (ImageInstanceSegmentationPreprocessor,
                                       build_preprocessor, load_image)
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Fields, ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_segmentation,
     module_name=Pipelines.image_instance_segmentation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_matching_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_matching_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,36 +1,35 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, List, Union
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_matching, module_name=Pipelines.image_matching)
 class ImageMatchingPipeline(Pipeline):
     """ Image Matching Pipeline.
 
     Examples:
 
-    >>> from modelscope.outputs import OutputKeys
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.outputs import OutputKeys
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
 
     >>> task = 'image-matching'
     >>> model_id = 'damo/cv_quadtree_attention_image-matching_outdoor'
 
     >>> input_location = [
     >>>                     ['data/test/images/image_matching1.jpg',
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_matting_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_matting_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import tensorflow as tf
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.device import device_placement
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.device import device_placement
+from weathon.utils.logger import get_logger
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_mvs_depth_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_mvs_depth_estimation_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import shutil
 from tempfile import TemporaryDirectory
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.cv.image_utils import depth_to_color
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.cv.image_utils import depth_to_color
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_multi_view_depth_estimation,
     module_name=Pipelines.image_multi_view_depth_estimation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_open_vocabulary_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_open_vocabulary_detection_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
 import PIL
 import torch
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.open_vocabulary_detection,
     module_name=Pipelines.open_vocabulary_detection_vild)
@@ -28,15 +27,15 @@
 
     def __init__(self, model: str, **kwargs):
         """
         use `model` to create a image open vocabulary detection pipeline for prediction
         Args:
             model: model id on modelscope hub.
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> vild_pipeline = pipeline(Tasks.open_vocabulary_detection,
                 model='damo/cv_resnet152_open-vocabulary-detection_vild')
 
             >>> image_path = 'test.jpg'
             >>> category_names =  ';'.join([
                     'flipflop', 'street sign', 'bracelet', 'necklace', 'shorts',
                     'floral camisole', 'orange shirt', 'purple dress', 'yellow tee',
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_paintbyexample_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_paintbyexample_pipeline.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,30 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
-import torch.nn as nn
 import torchvision
 from einops import rearrange
 from PIL import Image
-from torch.utils.data._utils.collate import default_collate
 from torchvision.transforms import Resize
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_paintbyexample import \
-    StablediffusionPaintbyexample
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.image import load_image
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_paintbyexample, module_name=Pipelines.image_paintbyexample)
 class ImagePaintbyexamplePipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_portrait_enhancement_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_portrait_enhancement_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,33 +1,29 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
 from typing import Any, Dict
 
 import cv2
 import numpy as np
-import PIL
 import torch
 import torch.nn.functional as F
-from scipy.ndimage import gaussian_filter
 from scipy.spatial.distance import pdist, squareform
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_portrait_enhancement import gpen
-from modelscope.models.cv.image_portrait_enhancement.align_faces import (
-    get_reference_facial_points, warp_and_crop_face)
-from modelscope.models.cv.image_portrait_enhancement.eqface import fqa
-from modelscope.models.cv.image_portrait_enhancement.retinaface import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_portrait_enhancement import gpen
+from weathon.models.cv.image_portrait_enhancement.align_faces import (
+    warp_and_crop_face)
+from weathon.models.cv.image_portrait_enhancement.eqface import fqa
+from weathon.models.cv.image_portrait_enhancement.retinaface import \
     detection
-from modelscope.models.cv.super_resolution import rrdbnet_arch
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage, load_image
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.models.cv.super_resolution import rrdbnet_arch
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_portrait_enhancement,
     module_name=Pipelines.image_portrait_enhancement)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_quality_assessment_degradation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_quality_assessment_degradation_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,42 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
-import tempfile
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
-import cv2
-import numpy as np
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_quality_assessment_degradation import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_quality_assessment_degradation import \
     ImageQualityAssessmentDegradation
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_quality_assessment_degradation,
     module_name=Pipelines.image_quality_assessment_degradation)
 class ImageQualityAssessmentDegradationPipeline(Pipeline):
     """ Image Quality Assessment Degradation Pipeline which will return mean option score for the input image.
 
         Example:
 
         ```python
-        >>> from modelscope.pipelines import pipeline
-        >>> from modelscope.outputs import OutputKeys
-        >>> from modelscope.utils.constant import Tasks
+        >>> from weathon.pipelines import pipeline
+        >>> from weathon.outputs import OutputKeys
+        >>> from weathon.utils.constants import Tasks
 
         >>> test_image = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/dogs.jpg'
         >>> assessment_predictor = pipeline(Tasks.image_quality_assessment_degradation, \
             model='damo/cv_resnet50_image-quality-assessment_degradation')
         >>> out_res = assessment_predictor(test_image)[OutputKeys.SCORES]
         >>> print('Pipeline: the output noise degree is {}, the output blur degree is {}, \
                 the output compression degree is {}'.format(out_res[0], out_res[1], out_res[2]))
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_quality_assessment_man_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_quality_assessment_man_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,44 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
-import tempfile
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
-import cv2
-import numpy as np
 import torch
-from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_quality_assessment_man import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_quality_assessment_man import \
     ImageQualityAssessmentMAN
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.preprocessors.cv import ImageQualityAssessmentMANPreprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.cv import ImageQualityAssessmentMANPreprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_quality_assessment_mos,
     module_name=Pipelines.image_quality_assessment_man)
 class ImageQualityAssessmentMANPipeline(Pipeline):
     """ Image Quality Assessment MAN Pipeline which will use Multi-dimension Attention Network
         to return Mean Opinion Score (MOS) for the input image.
 
         Example:
 
         ```python
-        >>> from modelscope.pipelines import pipeline
-        >>> from modelscope.outputs import OutputKeys
-        >>> from modelscope.utils.constant import Tasks
+        >>> from weathon.pipelines import pipeline
+        >>> from weathon.outputs import OutputKeys
+        >>> from weathon.utils.constants import Tasks
 
         >>> test_image = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/dogs.jpg'
         >>> assessment_predictor = pipeline(Tasks.image_quality_assessment_man, \
             model='damo/cv_man_image-quality-assessment')
         >>> out_mos = assessment_predictor(test_image)[OutputKeys.SCORE]
         >>> print('Pipeline: the output mos is {}'.format(out_mos))
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_quality_assessment_mos_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/feature_extraction_pipeline.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,80 +1,84 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
-import tempfile
 from typing import Any, Dict, Optional, Union
 
-import cv2
-import numpy as np
 import torch
-from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_quality_assessment_mos import \
-    ImageQualityAssessmentMos
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.preprocessors.cv import \
-    ImageQualityAssessmentMosPreprocessor as MosPreprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import (Preprocessor)
+from weathon.utils.constants import ModelFile, Tasks
 
-logger = get_logger()
+__all__ = ['FeatureExtractionPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.image_quality_assessment_mos,
-    module_name=Pipelines.image_quality_assessment_mos)
-class ImageQualityAssessmentMosPipeline(Pipeline):
-    """ Image Quality Assessment MOS Pipeline which will return mean option score for the input image.
-
-        Example:
-
-        ```python
-        >>> from modelscope.pipelines import pipeline
-        >>> from modelscope.outputs import OutputKeys
-        >>> from modelscope.utils.constant import Tasks
-
-        >>> test_image = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/dogs.jpg'
-        >>> assessment_predictor = pipeline(Tasks.image_quality_assessment_mos, \
-            model='damo/cv_resnet_image-quality-assessment-mos_youtubeUGC')
-        >>> out_mos = assessment_predictor(test_image)[OutputKeys.SCORE]
-        >>> print('Pipeline: the output mos is {}'.format(out_mos))
-
-        ```
-        """
+    Tasks.feature_extraction, module_name=Pipelines.feature_extraction)
+class FeatureExtractionPipeline(Pipeline):
 
     def __init__(self,
-                 model: Union[ImageQualityAssessmentMos, str],
-                 preprocessor=MosPreprocessor(),
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
+                 config_file: str = None,
+                 device: str = 'gpu',
+                 auto_collate=True,
+                 padding=False,
+                 sequence_length=128,
                  **kwargs):
-        """
-        use `model` to create image quality assessment mos pipeline for prediction
+        """Use `model` and `preprocessor` to create a nlp feature extraction pipeline for prediction
+
         Args:
-            model: model id on modelscope hub or `ImageQualityAssessmentMos` Model.
-            preprocessor: preprocessor for input image
+            model (str or Model): Supply either a local model dir which supported feature extraction task, or a
+            no-head model id from the model hub, or a torch model instance.
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            the model if supplied.
+            kwargs (dict, `optional`):
+                Extra kwargs passed into the preprocessor's constructor.
+
+        Examples:
+            >>> from weathon.pipelines import pipeline
+            >>> pipe_ins = pipeline('feature_extraction', model='damo/nlp_structbert_feature-extraction_english-large')
+            >>> input = 'Everything you love is treasure'
+            >>> print(pipe_ins(input))
 
-        """
-        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
 
-        if torch.cuda.is_available():
-            self._device = torch.device('cuda')
-        else:
-            self._device = torch.device('cpu')
+        """
+        super().__init__(
+            model=model,
+            preprocessor=preprocessor,
+            config_file=config_file,
+            device=device,
+            auto_collate=auto_collate,
+            compile=kwargs.pop('compile', False),
+            compile_options=kwargs.pop('compile_options', {}))
+
+        assert isinstance(self.model, Model), \
+            f'please check whether model config exists in {ModelFile.CONFIGURATION}'
+        if preprocessor is None:
+            self.preprocessor = Preprocessor.from_pretrained(
+                self.model.model_dir,
+                padding=padding,
+                sequence_length=sequence_length,
+                **kwargs)
+        self.model.eval()
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        with torch.no_grad():
+            return self.model(**inputs, **forward_params)
 
-        logger.info('load vqa-mos model done')
+    def postprocess(self, inputs: Dict[str, Tensor]) -> Dict[str, Tensor]:
+        """process the prediction results
 
-    @torch.no_grad()
-    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        """
-        inference for image quality assessment prediction
         Args:
-            input: dict including torch tensor.
+            inputs (Dict[str, Any]): _description_
 
+        Returns:
+            Dict[str, str]: the prediction results
         """
-        outputs = self.model.forward({'input': input['input']})['output'].cpu()
-        return {OutputKeys.SCORE: outputs.item()}
 
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        return inputs
+        return {
+            OutputKeys.TEXT_EMBEDDING:
+            inputs[OutputKeys.TEXT_EMBEDDING].tolist()
+        }
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_reid_person_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/retina_face_detection_pipeline.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,60 +1,58 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
-import os
+import os.path as osp
 from typing import Any, Dict
 
+import cv2
+import numpy as np
+import PIL
 import torch
-import torchvision.transforms as T
-from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_detection import RetinaFaceDetection
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.image_reid_person, module_name=Pipelines.image_reid_person)
-class ImageReidPersonPipeline(Pipeline):
+    Tasks.face_detection, module_name=Pipelines.retina_face_detection)
+class RetinaFaceDetectionPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
+        use `model` to create a face detection pipeline for prediction
+        Args:
             model: model id on modelscope hub.
         """
-        assert isinstance(model, str), 'model must be a single str'
-        super().__init__(model=model, auto_collate=False, **kwargs)
-        logger.info(f'loading model config from dir {model}')
-
-        cfg_path = os.path.join(model, ModelFile.CONFIGURATION)
-        cfg = Config.from_file(cfg_path)
-        cfg = cfg.model.cfg
-        self.model = self.model.to(self.device)
-        self.model.eval()
-
-        self.val_transforms = T.Compose([
-            T.Resize(cfg.INPUT.SIZE_TEST),
-            T.ToTensor(),
-            T.Normalize(mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD)
-        ])
+        super().__init__(model=model, **kwargs)
+        ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_FILE)
+        logger.info(f'loading model from {ckpt_path}')
+        detector = RetinaFaceDetection(
+            model_path=ckpt_path, device=self.device)
+        self.detector = detector
+        logger.info('load model done')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
-        img = LoadImage.convert_to_img(input)
-        img = self.val_transforms(img)
-        img = img.unsqueeze(0)
-        img = img.to(self.device)
-        return {'img': img}
+        img = LoadImage.convert_to_ndarray(input)
+        img = img.astype(np.float32)
+        result = {'img': img}
+        return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        img = input['img']
-        img_embedding = self.model(img)
-        img_embedding = img_embedding.detach().cpu().numpy()
-        return {OutputKeys.IMG_EMBEDDING: img_embedding}
+        result = self.detector(input)
+        assert result is not None
+        bboxes = result[0][:, :4].tolist()
+        scores = result[0][:, 4].tolist()
+        lms = result[1].tolist()
+        return {
+            OutputKeys.SCORES: scores,
+            OutputKeys.BOXES: bboxes,
+            OutputKeys.KEYPOINTS: lms,
+        }
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_restoration_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_restoration_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     Tasks.image_demoireing, module_name=Pipelines.image_demoire)
 class ImageRestorationPipeline(Pipeline):
     """ Image Restoration Pipeline .
 
     Take image_demoireing as an example:
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> image_demoire = pipeline(Tasks.image_demoireing, model=model_id)
         >>> image_demoire("https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/image_moire.jpg")
 
     """
 
     def __init__(self, model: str, **kwargs):
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_salient_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_salient_detection_pipeline.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     Tasks.semantic_segmentation, module_name=Pipelines.salient_detection)
 @PIPELINES.register_module(
     Tasks.semantic_segmentation,
     module_name=Pipelines.salient_boudary_detection)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_semantic_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_semantic_segmentation_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,22 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Union
+from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
-import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import load_image
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import load_image
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_segmentation,
     module_name=Pipelines.image_semantic_segmentation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_skychange_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/mog_face_detection_pipeline.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,60 +1,54 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import pdb
-import time
-from typing import Any, Dict, Union
+import os.path as osp
+from typing import Any, Dict
 
-import cv2
 import numpy as np
-import PIL
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_skychange import ImageSkyChangePreprocessor
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_detection import MogFaceDetector
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.image_skychange, module_name=Pipelines.image_skychange)
-class ImageSkychangePipeline(Pipeline):
-    """
-    Image Sky Change Pipeline. Given two images(sky_image and scene_image), pipeline will replace the sky style
-    of sky_image with the sky style of scene_image.
-
-    Examples:
-
-    >>> from modelscope.pipelines import pipeline
-    >>> detector = pipeline('image-skychange', 'damo/cv_hrnetocr_skychange')
-    >>> detector({
-            'sky_image': 'sky_image.jpg', # sky_image path (str)
-            'scene_image': 'scene_image.jpg', # scene_image path (str)
-        })
-    >>> {"output_img": [H * W * 3] 0~255, we can use cv2.imwrite to save output_img as an image.}
-    """
+    Tasks.face_detection, module_name=Pipelines.mog_face_detection)
+class MogFaceDetectionPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a image sky change pipeline for image editing
+        use `model` to create a face detection pipeline for prediction
         Args:
-            model (`str` or `Model`): model_id on modelscope hub
-            preprocessor(`Preprocessor`, *optional*,  defaults to None): `ImageSkyChangePreprocessor`.
+            model: model id on modelscope hub.
         """
         super().__init__(model=model, **kwargs)
-        if not isinstance(self.model, Model):
-            logger.error('model object is not initialized.')
-            raise Exception('model object is not initialized.')
-        if self.preprocessor is None:
-            self.preprocessor = ImageSkyChangePreprocessor()
+        ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_FILE)
+        logger.info(f'loading model from {ckpt_path}')
+        detector = MogFaceDetector(model_path=ckpt_path, device=self.device)
+        self.detector = detector
         logger.info('load model done')
 
+    def preprocess(self, input: Input) -> Dict[str, Any]:
+        img = LoadImage.convert_to_ndarray(input)
+        img = img.astype(np.float32)
+        result = {'img': img}
+        return result
+
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        res = self.model.forward(**input)
-        return {OutputKeys.OUTPUT_IMG: res}
+
+        result = self.detector(input)
+        assert result is not None
+        bboxes = result[:, :4].tolist()
+        scores = result[:, 4].tolist()
+        return {
+            OutputKeys.SCORES: scores,
+            OutputKeys.BOXES: bboxes,
+            OutputKeys.KEYPOINTS: None,
+        }
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_structured_model_probing_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_structured_model_probing_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,27 +1,23 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
-import math
 import os
-import os.path as osp
 from typing import Any, Dict
 
-import numpy as np
 import torch
 import torchvision.transforms as transforms
 from mmcv.parallel import collate, scatter
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_classification,
     module_name=Pipelines.image_structured_model_probing)
@@ -29,15 +25,15 @@
 
     def __init__(self, model: str, **kwargs):
         """
         use `model` to create a vision middleware pipeline for prediction
         Args:
             model: model id on modelscope hub.
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> recognition_pipeline = pipeline(self.task, self.model_id)
             >>> file_name = 'data/test/images/\
                 image_structured_model_probing_test_image.jpg'
             >>> result = recognition_pipeline(file_name)
             >>> print(f'recognition output: {result}.')
         """
         super().__init__(model=model, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_style_transfer_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_style_transfer_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.device import device_placement
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.device import device_placement
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_style_transfer, module_name=Pipelines.image_style_transfer)
 class ImageStyleTransferPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_super_resolution_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_super_resolution_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 import torch.nn.functional as F
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.super_resolution import RRDBNet
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.super_resolution import RRDBNet
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_super_resolution, module_name=Pipelines.image_super_resolution)
 class ImageSuperResolutionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_to_image_generate_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_to_image_generate_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,35 +1,29 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
-import cv2
-import numpy as np
-import PIL
 import torch
 import torch.nn.functional as F
 import torchvision.transforms as T
 import torchvision.transforms.functional as TF
-from PIL import Image
-from torchvision.utils import save_image
 
 import modelscope.models.cv.image_to_image_generation.data as data
 import modelscope.models.cv.image_to_image_generation.models as models
 import modelscope.models.cv.image_to_image_generation.ops as ops
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_to_image_generation.model import UNet
-from modelscope.models.cv.image_to_image_generation.models.clip import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_to_image_generation.model import UNet
+from weathon.models.cv.image_to_image_generation.models.clip import \
     VisionTransformer
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_to_image_generation,
     module_name=Pipelines.image_to_image_generation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/image_to_image_translation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_to_image_translation_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,34 +1,32 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import io
 import os.path as osp
-import sys
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import torch
 import torchvision.transforms as T
 from PIL import Image
 from torchvision.utils import save_image
 
 import modelscope.models.cv.image_to_image_translation.data as data
 import modelscope.models.cv.image_to_image_translation.models as models
 import modelscope.models.cv.image_to_image_translation.ops as ops
-from modelscope.fileio import File
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_to_image_translation.model_translation import \
+from weathon.fileio import File
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_to_image_translation.model_translation import \
     UNet
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import load_image
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import load_image
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def save_grid(imgs, filename, nrow=5):
     save_image(
         imgs.clamp(-1, 1), filename, range=(-1, 1), normalize=True, nrow=nrow)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/indoor_layout_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/indoor_layout_estimation_pipeline.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Union
+from typing import Any, Dict
 
 import cv2
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.indoor_layout_estimation.networks.misc.fourier import (
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.indoor_layout_estimation.networks.misc.fourier import (
     fourier, fourier_gray)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.indoor_layout_estimation,
     module_name=Pipelines.indoor_layout_estimation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/language_guided_video_summarization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/language_guided_video_summarization_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,37 +1,35 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import os.path as osp
 import random
 import shutil
 import tempfile
 from typing import Any, Dict
 
 import clip
 import cv2
 import numpy as np
 import torch
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base.base_model import Model
-from modelscope.models.cv.language_guided_video_summarization import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.base.base_model import Model
+from weathon.models.cv.language_guided_video_summarization import \
     ClipItVideoSummarization
-from modelscope.models.cv.language_guided_video_summarization.summarizer import (
+from weathon.models.cv.language_guided_video_summarization.summarizer import (
     extract_video_features, video_features_to_txt)
-from modelscope.models.cv.video_summarization import summary_format
-from modelscope.models.cv.video_summarization.summarizer import (
+from weathon.models.cv.video_summarization import summary_format
+from weathon.models.cv.video_summarization.summarizer import (
     generate_summary, get_change_points)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.language_guided_video_summarization,
     module_name=Pipelines.language_guided_video_summarization)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/license_plate_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/license_plate_detection_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,30 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
-import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.cv.ocr_utils.model_resnet18_half import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.cv.ocr_utils.model_resnet18_half import \
     LicensePlateDet
-from modelscope.pipelines.cv.ocr_utils.table_process import (
+from weathon.pipelines.cv.ocr_utils.table_process import (
     bbox_decode, bbox_post_process, decode_by_ind, get_affine_transform, nms)
-from modelscope.preprocessors import load_image
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.license_plate_detection,
     module_name=Pipelines.license_plate_detection)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/lineless_table_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/lineless_table_recognition_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,41 +1,40 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 import os.path as osp
 from typing import Any, Dict, Optional, Union
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.table_recognition import LoreModel
-from modelscope.models.cv.table_recognition.lineless_table_process import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.table_recognition import LoreModel
+from weathon.models.cv.table_recognition.lineless_table_process import \
     get_affine_transform_upper_left
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import load_image
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import load_image
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.lineless_table_recognition,
     module_name=Pipelines.lineless_table_recognition)
 class LinelessTableRecognitionPipeline(Pipeline):
     r""" Lineless Table Recognition Pipeline.
 
     Examples:
 
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
 
     >>> detector = pipeline('lineless-table-recognition', 'damo/cv_resnet-transformer_table-structure-recognition_lore')
     >>> detector("data/test/images/lineless_table_recognition.jpg")
     >>>   {
     >>>    "polygons": [
     >>>        [
     >>>            159.65718,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/live_category_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/live_category_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,21 +8,21 @@
 import torch.nn as nn
 import torch.nn.functional as F
 import torchvision.models as models
 import torchvision.transforms.functional as TF
 from decord import VideoReader, cpu
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.live_category, module_name=Pipelines.live_category)
 class LiveCategoryPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/maskdino_instance_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/maskdino_instance_segmentation_pipeline.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 import torchvision.transforms as T
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_instance_segmentation import (
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_instance_segmentation import (
     MaskDINOSwinModel, get_maskdino_ins_seg_result)
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_segmentation,
     module_name=Pipelines.maskdino_instance_segmentation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/mobile_image_super_resolution_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/mobile_image_super_resolution_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import numpy as np
 import skimage.color as sc
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.cv.super_resolution import ECBSRModel
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.cv.super_resolution import ECBSRModel
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['MobileImageSuperResolutionPipeline']
 
 
 @PIPELINES.register_module(
@@ -36,19 +35,19 @@
             model (`str` or `Model` or module instance): A model instance or a model local dir
                 or a model id in the model hub.
             preprocessor (`Preprocessor`, `optional`): A Preprocessor instance.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> import cv2
-            >>> from modelscope.outputs import OutputKeys
-            >>> from modelscope.pipelines import pipeline
-            >>> from modelscope.utils.constant import Tasks
+            >>> from weathon.outputs import OutputKeys
+            >>> from weathon.pipelines import pipeline
+            >>> from weathon.utils.constants import Tasks
             >>> sr = pipeline(Tasks.image_super_resolution, model='damo/cv_ecbsr_image-super-resolution_mobile')
             >>> result = sr('data/test/images/butterfly_lrx2_y.png')
             >>> cv2.imwrite('result.png', result[OutputKeys.OUTPUT_IMG])
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
         self.model.eval()
         self.config = self.model.config
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/mog_face_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ulfd_face_detection_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,54 +1,52 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_detection import MogFaceDetector
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_detection import UlfdFaceDetector
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_detection, module_name=Pipelines.mog_face_detection)
-class MogFaceDetectionPipeline(Pipeline):
+    Tasks.face_detection, module_name=Pipelines.ulfd_face_detection)
+class UlfdFaceDetectionPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
         use `model` to create a face detection pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, **kwargs)
         ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_FILE)
         logger.info(f'loading model from {ckpt_path}')
-        detector = MogFaceDetector(model_path=ckpt_path, device=self.device)
+        detector = UlfdFaceDetector(model_path=ckpt_path, device=self.device)
         self.detector = detector
         logger.info('load model done')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
         img = LoadImage.convert_to_ndarray(input)
         img = img.astype(np.float32)
         result = {'img': img}
         return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-
         result = self.detector(input)
         assert result is not None
-        bboxes = result[:, :4].tolist()
-        scores = result[:, 4].tolist()
+        bboxes = result[0].tolist()
+        scores = result[1].tolist()
         return {
             OutputKeys.SCORES: scores,
             OutputKeys.BOXES: bboxes,
             OutputKeys.KEYPOINTS: None,
         }
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/motion_generation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/motion_generation_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 import tempfile
 from typing import Any, Dict
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.motion_generation import (ClassifierFreeSampleModel,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.motion_generation import (ClassifierFreeSampleModel,
                                                     create_model,
                                                     load_model_wo_clip)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.cv.motion_utils.motion_process import recover_from_ric
-from modelscope.utils.cv.motion_utils.plot_script import plot_3d_motion
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.cv.motion_utils.motion_process import recover_from_ric
+from weathon.utils.cv.motion_utils.plot_script import plot_3d_motion
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.motion_generation, module_name=Pipelines.motion_generattion)
 class MDMMotionGeneration(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/movie_scene_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/movie_scene_segmentation_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.movie_scene_segmentation,
     module_name=Pipelines.movie_scene_segmentation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/mtcnn_face_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/ocr_recognition_pipeline.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,57 +1,48 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
-from typing import Any, Dict
+from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_detection import MtcnnFaceDetector
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import OfaForAllTasks
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import OfaPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_detection, module_name=Pipelines.mtcnn_face_detection)
-class MtcnnFaceDetectionPipeline(Pipeline):
+    Tasks.ocr_recognition, module_name=Pipelines.ofa_ocr_recognition)
+class OcrRecognitionPipeline(Pipeline):
 
-    def __init__(self, model: str, **kwargs):
+    def __init__(self,
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
+                 **kwargs):
         """
-        use `model` to create a face detection pipeline for prediction
+        use `model` and `preprocessor` to create a ocr recognition pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
-        super().__init__(model=model, **kwargs)
-        ckpt_path = osp.join(model, './weights')
-        logger.info(f'loading model from {ckpt_path}')
-        device = torch.device(
-            f'cuda:{0}' if torch.cuda.is_available() else 'cpu')
-        detector = MtcnnFaceDetector(model_path=ckpt_path, device=device)
-        self.detector = detector
-        self.device = device
-        logger.info('load model done')
-
-    def preprocess(self, input: Input) -> Dict[str, Any]:
-        img = LoadImage.convert_to_ndarray(input)
-        result = {'img': img}
-        return result
-
-    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        result = self.detector(input)
-        assert result is not None
-        bboxes = result[0][:, :4].tolist()
-        scores = result[0][:, 4].tolist()
-        lms = result[1].tolist()
-        return {
-            OutputKeys.SCORES: scores,
-            OutputKeys.BOXES: bboxes,
-            OutputKeys.KEYPOINTS: lms,
-        }
+        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
+        self.model.eval()
+        if preprocessor is None:
+            if isinstance(self.model, OfaForAllTasks):
+                self.preprocessor = OfaPreprocessor(self.model.model_dir)
+
+    def _batch(self, data):
+        if isinstance(self.model, OfaForAllTasks):
+            return batch_process(self.model, data)
+        else:
+            return super(OcrRecognitionPipeline, self)._batch(data)
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        with torch.no_grad():
+            return super().forward(inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/object_detection_3d_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/object_detection_3d_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,29 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import os.path as osp
 from tempfile import TemporaryDirectory
 from typing import Any, Dict
 
-import cv2
 import numpy as np
-import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.object_detection_3d.depe import DepeDetect
-from modelscope.models.cv.object_detection_3d.depe.result_vis import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.object_detection_3d.depe import DepeDetect
+from weathon.models.cv.object_detection_3d.depe.result_vis import \
     plot_result
-from modelscope.msdatasets import MsDataset
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.msdatasets import MsDataset
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.object_detection_3d, module_name=Pipelines.object_detection_3d_depe)
 class ObjectDetection3DPipeline(Pipeline):
@@ -32,16 +29,16 @@
         """
         use `model` to create a 3d object detection pipeline for prediction
         Args:
             model: model id on modelscope hub.
 
         Example:
             >>> import cv2
-            >>> from modelscope.pipelines import pipeline
-            >>> from modelscope.msdatasets import MsDataset
+            >>> from weathon.pipelines import pipeline
+            >>> from weathon.datasets import MsDataset
             >>> ms_ds_nuscenes = MsDataset.load('nuScenes_mini', namespace='shaoxuan')
             >>> data_path = ms_ds_nuscenes.config_kwargs['split_config']
             >>> val_dir = data_path['validation']
             >>> val_root = val_dir + '/' + os.listdir(val_dir)[0] + '/'
             >>> depe = pipeline('object-detection-3d', model='damo/cv_object-detection-3d_depe')
             >>> input_dict = {'data_root': val_root, 'sample_idx': 0}
             >>> result = depe(input_dict)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_detection_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,36 +1,33 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
 import os
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import tensorflow as tf
-import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.ocr_detection import OCRDetection
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.device import device_placement
-from modelscope.utils.logger import get_logger
-from .ocr_utils import (SegLinkDetector, boxes_from_bitmap, cal_width,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.device import device_placement
+from weathon.utils.logger import get_logger
+from .ocr_utils import (SegLinkDetector, cal_width,
                         combine_segments_python, decode_segments_links_python,
-                        nms_python, polygons_from_bitmap, rboxes_to_polygons)
+                        nms_python, rboxes_to_polygons)
+from ...base import BasePipeline
+from ...utils.constants.output_constant import OutputKeys
+from ...utils.typing import Input
 
 if tf.__version__ >= '2.0':
-    import tf_slim as slim
+    pass
 else:
-    from tensorflow.contrib import slim
+    pass
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
 tf.compat.v1.disable_eager_execution()
 
 logger = get_logger()
 
@@ -45,21 +42,21 @@
                           'Confidence threshold for nodes')
 tf.app.flags.DEFINE_float('link_threshold', 0.6,
                           'Confidence threshold for links')
 
 
 @PIPELINES.register_module(
     Tasks.ocr_detection, module_name=Pipelines.ocr_detection)
-class OCRDetectionPipeline(Pipeline):
+class OCRDetectionPipeline(BasePipeline):
     """ OCR Detection Pipeline.
 
     Example:
 
     ```python
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
 
     >>> ocr_detection = pipeline('ocr_detection', model='damo/cv_resnet18_ocr-detection-line-level_damo')
     >>> result = ocr_detection('https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/ocr_detection.jpg')
 
         {'polygons': array([[220,  14, 780,  14, 780,  64, 220,  64],
        [196, 369, 604, 370, 604, 425, 196, 425],
        [ 21, 730, 425, 731, 425, 787,  21, 786],
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_recognition_pipeline.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,28 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.ocr_recognition import OCRRecognition
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.base import BasePipeline
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.ocr_recognition import OCRRecognition
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.ocr_recognition, module_name=Pipelines.ocr_recognition)
-class OCRRecognitionPipeline(Pipeline):
+class OCRRecognitionPipeline(BasePipeline):
     """ OCR Recognition Pipeline.
 
     Example:
 
     ```python
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
 
     >>> ocr_recognition = pipeline('ocr-recognition', 'damo/cv_crnn_ocr-recognition-general_damo')
     >>> ocr_recognition("http://duguang-labelling.oss-cn-shanghai.aliyuncs.com"
         "/mass_img_tmp_20220922/ocr_recognition_handwritten.jpg")
 
         {'text': 'BOM'}
     ```
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/__init__.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .model_resnet_mutex_v4_linewithchar import SegLinkDetector
     from .ops import decode_segments_links_python, combine_segments_python
     from .utils import (rboxes_to_polygons, cal_width, nms_python,
                         polygons_from_bitmap, rboxes_from_bitmap)
 else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_dla34.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_dla34.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_resnet18_half.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_resnet18_half.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/model_vlpt.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/model_vlpt.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ocr_modules/convnext.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ocr_modules/convnext.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ocr_modules/vitstr.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ocr_modules/vitstr.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/ops.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/ops.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/resnet18_v1.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/resnet18_v1.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/resnet_utils.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/resnet_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/table_process.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/table_process.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ocr_utils/utils.py` & `weathon-0.0.0.14/weathon/pipelines/cv/ocr_utils/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import cv2
 import numpy as np
 import pyclipper
 from shapely.geometry import Polygon
 
 
 def rboxes_to_polygons(rboxes):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/panorama_depth_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/panorama_depth_estimation_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,40 +1,39 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
 import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.cv.image_utils import depth_to_color
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.cv.image_utils import depth_to_color
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.panorama_depth_estimation,
     module_name=Pipelines.panorama_depth_estimation)
 class PanoramaDepthEstimationPipeline(Pipeline):
     """ This pipeline will estimation the depth panoramic image from one rgb panoramic image.
         The input panoramic image should be equirectanlar, in the size of 512x1024.
 
     Examples:
 
     >>> import cv2
-    >>> from modelscope.outputs import OutputKeys
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.outputs import OutputKeys
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
     >>> task = 'panorama-depth-estimation'
     >>> model_id = 'damo/cv_unifuse_image-depth-estimation'
 
     >>> input_location = 'data/test/images/panorama_depth_estimation.jpg'
     >>> estimator = pipeline(Tasks.panorama_depth_estimation, model=model_id)
     >>> result = estimator(input_location)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/pedestrian_attribute_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/pedestrian_attribute_recognition_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,44 +1,39 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
-from typing import Any, Dict, List, Union
+from typing import Any, Dict, Union
 
 import cv2
-import json
 import numpy as np
 import torch
-from PIL import Image
-from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.pedestrian_attribute_recognition.model import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.pedestrian_attribute_recognition.model import \
     PedestrainAttribute
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Model, Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.pedestrian_attribute_recognition,
     module_name=Pipelines.pedestrian_attribute_recognition)
 class PedestrainAttributeRecognitionPipeline(Pipeline):
     """ Pedestrian attribute recognition Pipeline.
 
     Example:
 
     ```python
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
     >>> model_id = 'damo/cv_resnet50_pedestrian-attribute-recognition_image'
     >>> handle = pipeline(Tasks.pedestrian_attribute_recognition, model=model_id)
     >>> output = handle('https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/keypoints_detect/000000442836.jpg')
     ```
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Union
 
 import numpy as np
 import torch
 from plyfile import PlyData, PlyElement
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.cv.image_utils import depth_to_color
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.cv.image_utils import depth_to_color
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.pointcloud_sceneflow_estimation,
     module_name=Pipelines.pointcloud_sceneflow_estimation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/product_retrieval_embedding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,46 +1,40 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
 from typing import Any, Dict
 
-import cv2
-import numpy as np
-import torch
-from PIL import Image
-from torchvision import transforms
-
-from modelscope.metainfo import Pipelines
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.device import device_placement
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.product_retrieval_embedding,
-    module_name=Pipelines.product_retrieval_embedding)
-class ProductRetrievalEmbeddingPipeline(Pipeline):
+    Tasks.video_multi_modal_embedding,
+    module_name=Pipelines.video_multi_modal_embedding)
+class VideoMultiModalEmbeddingPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
-        """use `model` to create a pipeline for prediction
+        """
+        use `model` to create a video_multi_modal_embedding pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
-        super().__init__(model=model, **kwargs)
+        super().__init__(model=model)
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
-        """
-        preprocess the input image to cv2-bgr style
-        """
-        img = LoadImage.convert_to_ndarray(input)  # array with rgb
-        img = np.ascontiguousarray(img[:, :, ::-1])  # array with bgr
-        result = {'img': img}  # only for detection
-        return result
+        return input
+
+    def _process_single(self, input: Input, *args, **kwargs) -> Dict[str, Any]:
+        with device_placement(self.framework, self.device_name):
+            out = self.forward(input)
+
+        self._check_output(out)
+        return out
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
         return self.model(input)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/product_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/arc_face_recognition_pipeline.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,44 +1,66 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
-
+import os.path as osp
 from typing import Any, Dict
 
 import numpy as np
+import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.product_segmentation import seg_infer
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.face_recognition.torchkit.backbone.arcface_backbone import \
+    _iresnet
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
+from . import FaceProcessingBasePipeline
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.product_segmentation, module_name=Pipelines.product_segmentation)
-class F3NetForProductSegmentationPipeline(Pipeline):
+    Tasks.face_recognition, module_name=Pipelines.arc_face_recognition)
+class ArcFaceRecognitionPipeline(FaceProcessingBasePipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create product segmentation pipeline for prediction
+        use `model` to create a face recognition pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
 
+        # face recong model
         super().__init__(model=model, **kwargs)
-        logger.info('load model done')
+        face_model = _iresnet('arcface_i50', [3, 4, 14, 3])
+        face_model.load_state_dict(
+            torch.load(
+                osp.join(model, ModelFile.TORCH_MODEL_FILE),
+                map_location=self.device))
+        face_model = face_model.to(self.device)
+        face_model.eval()
+        self.face_model = face_model
+        logger.info('face recognition model loaded!')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
-        img = LoadImage.convert_to_ndarray(input['input_path'])
-        img = img.astype(np.float32)
-        return img
+        result = super().preprocess(input)
+        if result is None:
+            rtn_dict = {}
+            rtn_dict['img'] = None
+            return rtn_dict
+        align_img = result['img']
+        face_img = align_img[:, :, ::-1]  # to rgb
+        face_img = np.transpose(face_img, axes=(2, 0, 1))
+        face_img = (face_img / 255. - 0.5) / 0.5
+        face_img = face_img.astype(np.float32)
+        result['img'] = face_img
+        return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-
-        mask = seg_infer.inference(self.model, self.device, input)
-        return {OutputKeys.MASKS: mask}
+        if input['img'] is None:
+            return {OutputKeys.IMG_EMBEDDING: None}
+        img = input['img'].unsqueeze(0)
+        emb = self.face_model(img).detach().cpu().numpy()
+        emb /= np.sqrt(np.sum(emb**2, -1, keepdims=True))  # l2 norm
+        return {OutputKeys.IMG_EMBEDDING: emb}
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/realtime_video_object_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/text2sql_pipeline.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,59 +1,50 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
-from typing import Any, Dict, List, Union
-
-import cv2
-import json
-import numpy as np
+from typing import Any, Dict, Optional, Union
+
 import torch
-from PIL import Image
-from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.stream_yolo import RealtimeVideoDetector
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Model, Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import load_image
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import OfaForAllTasks
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import OfaPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
-@PIPELINES.register_module(
-    Tasks.video_object_detection,
-    module_name=Pipelines.realtime_video_object_detection)
-class RealtimeVideoObjectDetectionPipeline(Pipeline):
-
-    def __init__(self, model: str, **kwargs):
-        super().__init__(model=model, **kwargs)
-
-    def preprocess(self, input: Input) -> Dict[Tensor, Union[str, np.ndarray]]:
-        return input
-
-    def forward(self, input: Input) -> Dict[Tensor, Dict[str, np.ndarray]]:
-        self.video_path = input
-        # Processing the whole video and return results for each frame
-        forward_output = self.model.inference_video(self.video_path)
-        return {'forward_output': forward_output}
-
-    def postprocess(self, input: Dict[Tensor, Dict[str, np.ndarray]],
-                    **kwargs) -> str:
-        forward_output = input['forward_output']
-
-        scores, boxes, labels, timestamps = [], [], [], []
-        for result in forward_output:
-            box, score, label, timestamp = result
-            scores.append(score)
-            boxes.append(box)
-            labels.append(label)
-            timestamps.append(timestamp)
-
-        return {
-            OutputKeys.BOXES: boxes,
-            OutputKeys.SCORES: scores,
-            OutputKeys.LABELS: labels,
-            OutputKeys.TIMESTAMPS: timestamps,
-        }
+@PIPELINES.register_module(Tasks.text2sql, module_name=Pipelines.ofa_text2sql)
+class TextToSqlPipeline(Pipeline):
+    R"""
+    pipeline for text to sql task
+    """
+
+    def __init__(self,
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
+                 **kwargs):
+        """
+        use `model` and `preprocessor` to create a pipeline for text2sql task
+        Args:
+            model: model id on modelscope hub.
+        """
+        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
+        self.model.eval()
+        if preprocessor is None:
+            if isinstance(self.model, OfaForAllTasks):
+                self.preprocessor = OfaPreprocessor(self.model.model_dir)
+
+    def _batch(self, data):
+        if isinstance(self.model, OfaForAllTasks):
+            return batch_process(self.model, data)
+        else:
+            return super(TextToSqlPipeline, self)._batch(data)
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        with torch.no_grad():
+            return super().forward(inputs, **forward_params)
+
+    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
+        return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/referring_video_object_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/referring_video_object_segmentation_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,29 +1,27 @@
 # The implementation here is modified based on MTTR,
 # originally Apache 2.0 License and publicly available at https://github.com/mttr2021/MTTR
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import tempfile
 from typing import Any, Dict
 
 import numpy as np
 import torch
 import torchvision
 import torchvision.transforms.functional as F
 from einops import rearrange
 from moviepy.editor import AudioFileClip, ImageSequenceClip, VideoFileClip
 from PIL import Image, ImageDraw, ImageFont, ImageOps
 from tqdm import tqdm
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.referring_video_object_segmentation,
     module_name=Pipelines.referring_video_object_segmentation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/retina_face_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/visual_entailment_pipeline.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,59 +1,47 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
-from typing import Any, Dict
-
-import cv2
-import numpy as np
-import PIL
+from typing import Any, Dict, Optional, Union
+
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_detection import RetinaFaceDetection
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import OfaForAllTasks
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import OfaPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_detection, module_name=Pipelines.retina_face_detection)
-class RetinaFaceDetectionPipeline(Pipeline):
+    Tasks.visual_entailment, module_name=Pipelines.visual_entailment)
+class VisualEntailmentPipeline(Pipeline):
 
-    def __init__(self, model: str, **kwargs):
+    def __init__(self,
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
+                 **kwargs):
         """
-        use `model` to create a face detection pipeline for prediction
+        use `model` and `preprocessor` to create a visual entailment pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
-        super().__init__(model=model, **kwargs)
-        ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_FILE)
-        logger.info(f'loading model from {ckpt_path}')
-        detector = RetinaFaceDetection(
-            model_path=ckpt_path, device=self.device)
-        self.detector = detector
-        logger.info('load model done')
-
-    def preprocess(self, input: Input) -> Dict[str, Any]:
-        img = LoadImage.convert_to_ndarray(input)
-        img = img.astype(np.float32)
-        result = {'img': img}
-        return result
-
-    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        result = self.detector(input)
-        assert result is not None
-        bboxes = result[0][:, :4].tolist()
-        scores = result[0][:, 4].tolist()
-        lms = result[1].tolist()
-        return {
-            OutputKeys.SCORES: scores,
-            OutputKeys.BOXES: bboxes,
-            OutputKeys.KEYPOINTS: lms,
-        }
+        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
+        self.model.eval()
+        if preprocessor is None and isinstance(self.model, OfaForAllTasks):
+            self.preprocessor = OfaPreprocessor(model_dir=self.model.model_dir)
+
+    def _batch(self, data):
+        if isinstance(self.model, OfaForAllTasks):
+            return batch_process(self.model, data)
+        else:
+            return super(VisualEntailmentPipeline, self)._batch(data)
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        with torch.no_grad():
+            return super().forward(inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/shop_segmentation_pipleline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/product_segmentation_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,52 +1,44 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
+
 from typing import Any, Dict
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
+import numpy as np
+
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.product_segmentation import seg_infer
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
+
+logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.shop_segmentation, module_name=Pipelines.shop_segmentation)
-class ShopSegmentationPipeline(Pipeline):
+    Tasks.product_segmentation, module_name=Pipelines.product_segmentation)
+class F3NetForProductSegmentationPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
+        use `model` to create product segmentation pipeline for prediction
+        Args:
             model: model id on modelscope hub.
         """
-        super().__init__(model=model, auto_collate=False, **kwargs)
+
+        super().__init__(model=model, **kwargs)
+        logger.info('load model done')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
-        img = LoadImage.convert_to_ndarray(input)
-        img_tensor, ori_h, ori_w, crop_h, crop_w = self.model.preprocess(img)
-        result = {
-            'img': img_tensor,
-            'ori_h': ori_h,
-            'ori_w': ori_w,
-            'crop_h': crop_h,
-            'crop_w': crop_w
-        }
-        return result
+        img = LoadImage.convert_to_ndarray(input['input_path'])
+        img = img.astype(np.float32)
+        return img
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
 
-        outputs = self.model.inference(input['img'])
-        result = {
-            'data': outputs,
-            'ori_h': input['ori_h'],
-            'ori_w': input['ori_w'],
-            'crop_h': input['crop_h'],
-            'crop_w': input['crop_w'],
-        }
-        return result
+        mask = seg_infer.inference(self.model, self.device, input)
+        return {OutputKeys.MASKS: mask}
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-
-        data = self.model.postprocess(inputs['data'], inputs['crop_h'],
-                                      inputs['crop_w'], inputs['ori_h'],
-                                      inputs['ori_w'])
-        outputs = {OutputKeys.MASKS: data}
-        return outputs
+        return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/skin_retouching_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/skin_retouching_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,34 +1,32 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import cv2
 import numpy as np
-import PIL
 import tensorflow as tf
 import torch
 import torch.nn.functional as F
 import torchvision.transforms as transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.skin_retouching.detection_model.detection_unet_in import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.skin_retouching.detection_model.detection_unet_in import \
     DetectionUNet
-from modelscope.models.cv.skin_retouching.inpainting_model.inpainting_unet import \
+from weathon.models.cv.skin_retouching.inpainting_model.inpainting_unet import \
     RetouchingNet
-from modelscope.models.cv.skin_retouching.unet_deploy import UNet
-from modelscope.models.cv.skin_retouching.utils import *  # noqa F403
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.device import create_device, device_placement
-from modelscope.utils.logger import get_logger
+from weathon.models.cv.skin_retouching.unet_deploy import UNet
+from weathon.models.cv.skin_retouching.utils import *  # noqa F403
+from weathon.outputs import OutputKeys
+from weathon.pipelines import pipeline
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.device import create_device, device_placement
+from weathon.utils.logger import get_logger
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
     tf.disable_eager_execution()
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/table_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/table_recognition_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,29 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import math
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import numpy as np
-import PIL
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.cv.ocr_utils.model_dla34 import TableRecModel
-from modelscope.pipelines.cv.ocr_utils.table_process import (
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.cv.ocr_utils.model_dla34 import TableRecModel
+from weathon.pipelines.cv.ocr_utils.table_process import (
     bbox_decode, bbox_post_process, gbox_decode, gbox_post_process,
     get_affine_transform, group_bbox_by_gbox, nms)
-from modelscope.preprocessors import load_image
-from modelscope.preprocessors.image import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.preprocessors.image import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.table_recognition, module_name=Pipelines.table_recognition)
 class TableRecognitionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/tbs_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/tbs_detection_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import colorsys
 import os
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import torch
-from PIL import Image, ImageDraw, ImageFile, ImageFont
+from PIL import Image, ImageFile
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.cv.tbs_detection_utils.utils import (_get_anchors,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.cv.tbs_detection_utils.utils import (_get_anchors,
                                                                generate,
                                                                post_process)
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 ImageFile.LOAD_TRUNCATED_IMAGES = True
 
 logger = get_logger()
 
 __all__ = ['TBSDetectionPipeline']
 
@@ -31,15 +28,15 @@
     Tasks.image_object_detection, module_name=Pipelines.tbs_detection)
 class TBSDetectionPipeline(Pipeline):
     """ TBS Detection Pipeline.
 
     Example:
 
     ```python
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
 
     >>> tbs_detect = pipeline(Tasks.image_object_detection, model='landingAI/LD_CytoBrainCerv')
     >>> tbs_detect(input='data/test/images/tbs_detection.jpg')
        {
         "boxes": [
             [
             446.9007568359375,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/tbs_detection_utils/utils.py` & `weathon-0.0.0.14/weathon/pipelines/cv/tbs_detection_utils/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import pandas as pd
 import torch
 import torch.nn as nn
 from matplotlib import pyplot as plt
 from PIL import Image
 from torchvision.ops.boxes import batched_nms, nms
 
-from modelscope.preprocessors.image import load_image
+from weathon.preprocessors.image import load_image
 
 plt.switch_backend('Agg')
 
 
 class DecodeBox(nn.Module):
 
     def __init__(self, anchors, num_classes, img_size):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/text_driven_segmentation_pipleline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/text_driven_segmentation_pipleline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     Tasks.text_driven_segmentation,
     module_name=Pipelines.text_driven_segmentation)
 class TextDrivenSegmentationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/tinynas_classification_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/tinynas_classification_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 import os.path as osp
 from typing import Any, Dict
 
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.tinynas_classfication import get_zennet
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.tinynas_classfication import get_zennet
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_classification, module_name=Pipelines.tinynas_classification)
 class TinynasClassificationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/tinynas_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/tinynas_detection_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Optional, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.outputs.cv_outputs import DetectionOutput
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.cv.image_utils import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.utils.output.cv_outputs import DetectionOutput
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.cv.image_utils import \
     show_image_object_detection_auto_result
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.domain_specific_object_detection,
     module_name=Pipelines.tinynas_detection)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/ulfd_face_detection_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/multi_modal_embedding_pipeline.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,57 +1,41 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os.path as osp
-from typing import Any, Dict
-
-import cv2
-import numpy as np
-import PIL
-import torch
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.face_detection import UlfdFaceDetector
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from typing import Any, Dict, Optional, Union
+
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal.clip.model import CLIPForMultiModalEmbedding
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.multi_modal import CLIPPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.face_detection, module_name=Pipelines.ulfd_face_detection)
-class UlfdFaceDetectionPipeline(Pipeline):
+    Tasks.image_text_retrieval, module_name=Pipelines.multi_modal_embedding)
+@PIPELINES.register_module(
+    Tasks.multi_modal_embedding, module_name=Pipelines.multi_modal_embedding)
+class MultiModalEmbeddingPipeline(Pipeline):
 
-    def __init__(self, model: str, **kwargs):
+    def __init__(self,
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
+                 **kwargs):
         """
-        use `model` to create a face detection pipeline for prediction
+        use `model` and `preprocessor` to create a kws pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
-        super().__init__(model=model, **kwargs)
-        ckpt_path = osp.join(model, ModelFile.TORCH_MODEL_FILE)
-        logger.info(f'loading model from {ckpt_path}')
-        detector = UlfdFaceDetector(model_path=ckpt_path, device=self.device)
-        self.detector = detector
-        logger.info('load model done')
-
-    def preprocess(self, input: Input) -> Dict[str, Any]:
-        img = LoadImage.convert_to_ndarray(input)
-        img = img.astype(np.float32)
-        result = {'img': img}
-        return result
+        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
+        self.model.eval()
+        if preprocessor is None:
+            if isinstance(self.model, CLIPForMultiModalEmbedding):
+                self.preprocessor = CLIPPreprocessor(self.model.model_dir)
+            else:
+                raise NotImplementedError
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        result = self.detector(input)
-        assert result is not None
-        bboxes = result[0].tolist()
-        scores = result[1].tolist()
-        return {
-            OutputKeys.SCORES: scores,
-            OutputKeys.BOXES: bboxes,
-            OutputKeys.KEYPOINTS: None,
-        }
+        return self.model(self.preprocess(input))
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_category_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_category_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,20 +9,20 @@
 import torch.nn as nn
 import torch.nn.functional as F
 import torchvision.models as models
 import torchvision.transforms.functional as TF
 from decord import VideoReader, cpu
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_category, module_name=Pipelines.video_category)
 class VideoCategoryPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_colorization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_colorization_pipeline.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,28 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import subprocess
 import tempfile
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import PIL
 import torch
 from torchvision import models, transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.image_colorization import (DynamicUnetDeep,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.image_colorization import (DynamicUnetDeep,
                                                      DynamicUnetWide, NormType)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.cv import VideoReader
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.cv import VideoReader
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_colorization, module_name=Pipelines.video_colorization)
 class VideoColorizationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_deinterlace_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_deinterlace_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 # The implementation here is modified based on RealBasicVSR,
 # originally Apache 2.0 License and publicly available at
 # https://github.com/ckkelvinchan/RealBasicVSR/blob/master/inference_realbasicvsr.py
 import math
 import os
 import subprocess
 import tempfile
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
 import torch
 from torchvision.utils import make_grid
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_deinterlace.UNet_for_video_deinterlace import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_deinterlace.UNet_for_video_deinterlace import \
     UNetForVideoDeinterlace
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.cv import VideoReader
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.cv import VideoReader
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 VIDEO_EXTENSIONS = ('.mp4', '.mov')
 
 logger = get_logger()
 
 
 def tensor2img(tensor, out_type=np.uint8, min_max=(0, 1)):
@@ -103,15 +103,15 @@
             model (`str` or `Model` or module instance): A model instance or a model local dir
                 or a model id in the model hub.
             preprocessor (`Preprocessor`, `optional`): A Preprocessor instance.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('video-deinterlace',
                 model='damo/cv_unet_video-deinterlace')
             >>> input = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/videos/video_deinterlace_test.mp4'
             >>> print(pipeline_ins(input)[OutputKeys.OUTPUT_VIDEO])
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
         if torch.cuda.is_available():
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_depth_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/image_body_reshaping_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,50 +1,39 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.video_depth_estimation, module_name=Pipelines.video_depth_estimation)
-class VideoDepthEstimationPipeline(Pipeline):
+    Tasks.image_body_reshaping, module_name=Pipelines.image_body_reshaping)
+class ImageBodyReshapingPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
-        use `model` to create a video depth estimation pipeline for prediction
+        use `model` to create a image body reshaping pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, **kwargs)
-
-        logger.info('depth estimation model, pipeline init')
+        logger.info('body reshaping model init done')
 
     def preprocess(self, input: Input) -> Dict[str, Any]:
-        video_path = input
-        data = {'video_path': video_path}
-
-        return data
+        img = LoadImage.convert_to_ndarray(input)
+        result = {'img': img}
+        return result
 
     def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        results = self.model.inference(input)
-        return results
+        output = self.model.inference(input['img'])
+        result = {'outputs': output}
+        return result
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        results = self.model.postprocess(inputs)
-        depths = results['depths']
-        depths_color = results['depths_color']
-        poses = results['poses']
-
-        outputs = {
-            OutputKeys.DEPTHS: depths,
-            OutputKeys.DEPTHS_COLOR: depths_color,
-            OutputKeys.POSES: poses
-        }
-
-        return outputs
+        output_img = inputs['outputs']
+        return {OutputKeys.OUTPUT_IMG: output_img}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_frame_interpolation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_frame_interpolation_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,35 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import glob
-import math
 import os
-import os.path as osp
 import subprocess
 import tempfile
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
 import torch
 import torch.nn.functional as F
-from torchvision.utils import make_grid
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_frame_interpolation.utils.scene_change_detection import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_frame_interpolation.utils.scene_change_detection import \
     do_scene_detect
-from modelscope.models.cv.video_frame_interpolation.VFINet_for_video_frame_interpolation import \
+from weathon.models.cv.video_frame_interpolation.VFINet_for_video_frame_interpolation import \
     VFINetForVideoFrameInterpolation
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.preprocessors.cv import VideoReader
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.cv import VideoReader
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 VIDEO_EXTENSIONS = ('.mp4', '.mov')
 logger = get_logger()
 
 
 def img_trans(img_tensor):  # in format of RGB
     img_tensor = img_tensor / 255.0
@@ -495,17 +488,17 @@
     Tasks.video_frame_interpolation,
     module_name=Pipelines.video_frame_interpolation)
 class VideoFrameInterpolationPipeline(Pipeline):
     """ Video Frame Interpolation Pipeline.
 
     Examples:
 
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
-    >>> from modelscope.outputs import OutputKeys
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
+    >>> from weathon.outputs import OutputKeys
 
     >>> video = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/videos/video_frame_interpolation_test.mp4'
     >>> video_frame_interpolation_pipeline = pipeline(Tasks.video_frame_interpolation,
     'damo/cv_raft_video-frame-interpolation')
     >>> result = video_frame_interpolation_pipeline(video)[OutputKeys.OUTPUT_VIDEO]
     >>> print('pipeline: the output video path is {}'.format(result))
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_inpainting_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/fasttext_text_classification_pipeline.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,48 +1,66 @@
-# Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
-from typing import Any, Dict
+import os
+from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_inpainting import inpainting
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
-
-logger = get_logger()
+import sentencepiece
+from fasttext import load_model
+from fasttext.FastText import _FastText
+
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+
+__all__ = ['FasttextSequenceClassificationPipeline']
+
+
+def sentencepiece_tokenize(sp_model, sent):
+    tokens = []
+    for t in sp_model.EncodeAsPieces(sent):
+        s = t.strip()
+        if s:
+            tokens.append(s)
+    return ' '.join(tokens)
 
 
 @PIPELINES.register_module(
-    Tasks.video_inpainting, module_name=Pipelines.video_inpainting)
-class VideoInpaintingPipeline(Pipeline):
+    Tasks.text_classification, module_name=Pipelines.domain_classification)
+class FasttextSequenceClassificationPipeline(Pipeline):
+
+    def __init__(self, model: Union[str, _FastText], **kwargs):
+        """use `model` and `preprocessor` to create a nlp text classification pipeline for prediction
 
-    def __init__(self, model: str, **kwargs):
-        """
-        use `model` to create video inpainting pipeline for prediction
         Args:
-            model: model id on modelscope hub.
+            model: A model directory including model.bin and spm.model
         """
-
-        super().__init__(model=model, **kwargs)
-        logger.info('load model done')
-
-    def preprocess(self, input: Input) -> Dict[str, Any]:
-        return input
-
-    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        decode_error, fps, w, h = inpainting.video_process(
-            input['video_input_path'])
-
-        if decode_error is not None:
-            return {OutputKeys.OUTPUT: 'decode_error'}
-
-        inpainting.inpainting_by_model_balance(self.model,
-                                               input['video_input_path'],
-                                               input['mask_path'],
-                                               input['video_output_path'], fps,
-                                               w, h)
-
-        return {OutputKeys.OUTPUT: 'Done'}
+        super().__init__(model=model)
+        model_file = os.path.join(model, ModelFile.TORCH_MODEL_BIN_FILE)
+        spm_file = os.path.join(model, 'sentencepiece.model')
+        assert os.path.isdir(model) and os.path.exists(model_file) and os.path.exists(spm_file), \
+            '`model` should be a directory contains `model.bin` and `sentencepiece.model`'
+        self.model = load_model(model_file)
+        self.spm = sentencepiece.SentencePieceProcessor()
+        self.spm.Load(spm_file)
+
+    def preprocess(self, inputs: str) -> Dict[str, Any]:
+        text = inputs.strip()
+        text_sp = sentencepiece_tokenize(self.spm, text)
+        return {'text_sp': text_sp, 'text': text}
+
+    def forward(self,
+                inputs: Dict[str, Any],
+                topk: int = None) -> Dict[str, Any]:
+        if topk is None:
+            topk = inputs.get('topk', -1)
+        label, probs = self.model.predict(inputs['text_sp'], k=topk)
+        label = [x.replace('__label__', '') for x in label]
+        result = {
+            OutputKeys.LABEL: label[0],
+            OutputKeys.SCORE: probs[0],
+            OutputKeys.LABELS: label,
+            OutputKeys.SCORES: probs
+        }
+        return result
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_instance_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_instance_segmentation_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,41 +1,36 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import os
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import mmcv
 import numpy as np
 import torch
-from tqdm import tqdm
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_instance_segmentation.video_knet import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_instance_segmentation.video_knet import \
     KNetTrack
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_instance_segmentation,
     module_name=Pipelines.video_instance_segmentation)
 class VideoInstanceSegmentationPipeline(Pipeline):
     r""" Video Instance Segmentation Pipeline.
 
     Examples:
 
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
 
     >>> detector = pipeline('video-instance-segmentation', 'damo/cv_swinb_video-instance-segmentation')
     >>> detector("http://www.modelscope.cn/api/v1/models/damo/cv_swinb_video-instance-segmentation/repo?Revision=master"
     >>>             "&FilePath=resources/kitti-step_testing_image_02_0000.mp4")
     >>>   {
     >>>    "boxes": [
     >>>        [
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_object_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_object_segmentation_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import numpy as np
 import torch
 import torch.nn.functional as F
 from PIL import Image
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_object_segmentation.inference_core import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_object_segmentation.inference_core import \
     InferenceCore
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 im_normalization = transforms.Normalize(
     mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_panoptic_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_panoptic_segmentation_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,28 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import os
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 import mmcv
 import numpy as np
 import torch
 from tqdm import tqdm
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_panoptic_segmentation.video_k_net import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_panoptic_segmentation.video_k_net import \
     VideoKNet
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_panoptic_segmentation,
     module_name=Pipelines.video_panoptic_segmentation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_single_object_tracking_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_single_object_tracking_pipeline.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 from typing import Any, Dict
 
 import cv2
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_single_object_tracking.config.ostrack import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_single_object_tracking.config.ostrack import \
     cfg
-from modelscope.models.cv.video_single_object_tracking.tracker import (
+from weathon.models.cv.video_single_object_tracking.tracker import (
     OSTrack, ProContEXT)
-from modelscope.models.cv.video_single_object_tracking.utils.utils import (
+from weathon.models.cv.video_single_object_tracking.utils.utils import (
     check_box, timestamp_format)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_single_object_tracking,
     module_name=Pipelines.video_single_object_tracking_procontext)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_stabilization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_stabilization_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # Modified from https://github.com/Annbless/DUTCode
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import glob
-import math
 import os
 import subprocess
 import tempfile
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
-import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.metrics.video_stabilization_metric import warpprocess
-from modelscope.models.cv.video_stabilization.DUTRAFTStabilizer import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.metrics.video_stabilization_metric import warpprocess
+from weathon.models.cv.video_stabilization.DUTRAFTStabilizer import \
     DUTRAFTStabilizer
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.preprocessors.cv import VideoReader
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.cv import VideoReader
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def check_file_exist(filename, msg_tmpl='file "{}" does not exist'):
     if not osp.isfile(filename):
         raise FileNotFoundError(msg_tmpl.format(filename))
@@ -38,17 +33,17 @@
     Tasks.video_stabilization, module_name=Pipelines.video_stabilization)
 class VideoStabilizationPipeline(Pipeline):
     """  Video Stabilization Pipeline.
 
     Examples:
 
     >>> import cv2
-    >>> from modelscope.outputs import OutputKeys
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.utils.constant import Tasks
+    >>> from weathon.outputs import OutputKeys
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.utils.constants import Tasks
 
     >>> test_video = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/videos/video_stabilization_test_video.avi'
     >>> video_stabilization = pipeline(Tasks.video_stabilization, model='damo/cv_dut-raft_video-stabilization_base')
     >>> out_video_path = video_stabilization(test_video)[OutputKeys.OUTPUT_VIDEO]
     >>> print('Pipeline: the output video path is {}'.format(out_video_path))
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_summarization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_summarization_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -5,26 +5,26 @@
 from typing import Any, Dict
 
 import cv2
 import numpy as np
 import torch
 from tqdm import tqdm
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_summarization import (PGLVideoSummarization,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_summarization import (PGLVideoSummarization,
                                                       summary_format)
-from modelscope.models.cv.video_summarization.base_model import bvlc_googlenet
-from modelscope.models.cv.video_summarization.summarizer import (
+from weathon.models.cv.video_summarization.base_model import bvlc_googlenet
+from weathon.models.cv.video_summarization.summarizer import (
     generate_summary, get_change_points)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_summarization, module_name=Pipelines.video_summarization)
 class VideoSummarizationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/video_super_resolution_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/video_super_resolution_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 # The implementation here is modified based on RealBasicVSR,
 # originally Apache 2.0 License and publicly available at
 # https://github.com/ckkelvinchan/RealBasicVSR/blob/master/inference_realbasicvsr.py
 import math
 import os
 import subprocess
 import tempfile
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
 import torch
 from torchvision.utils import make_grid
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.video_super_resolution import (
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.video_super_resolution import (
     MSRResNetLiteModel, RealBasicVSRNetForVideoSR)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.cv import VideoReader
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.cv import VideoReader
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 VIDEO_EXTENSIONS = ('.mp4', '.mov')
 
 logger = get_logger()
 
 
 def tensor2img(tensor, out_type=np.uint8, min_max=(0, 1)):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/vidt_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/vidt_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,35 +1,35 @@
 # Copyright 2022-2023 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Any, Dict
 
 import torch
 import torchvision.transforms as transforms
 from torch import nn
 
-from modelscope.metainfo import Pipelines
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_object_detection, module_name=Pipelines.vidt)
 class VidtPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         """
         use `model` to create a vidt pipeline for prediction
         Args:
             model: model id on modelscope hub.
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> vidt_pipeline = pipeline('image-object-detection', 'damo/ViDT-logo-detection')
             >>> result = vidt_pipeline(
                 'data/test/images/vidt_test1.png')
             >>> print(f'Output: {result}.')
         """
         super().__init__(model=model, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/virtual_try_on_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/virtual_try_on_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
 import PIL
 import torch
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.virual_tryon import SDAFNet_Tryon
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import load_image
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.virual_tryon import SDAFNet_Tryon
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import load_image
+from weathon.utils.constants import ModelFile, Tasks
 
 
 @PIPELINES.register_module(
     Tasks.virtual_try_on, module_name=Pipelines.virtual_try_on)
 class VirtualTryonPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/vision_efficient_tuning_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/vision_efficient_tuning_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,22 +1,21 @@
 # Copyright 2022-2023 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Any, Dict
 
 import numpy as np
 import torch
-import torch.nn.functional as F
 import torchvision.transforms as transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.vision_efficient_tuning,
     module_name=Pipelines.vision_efficient_tuning)
@@ -24,15 +23,15 @@
 
     def __init__(self, model: str, **kwargs):
         """
         use `model` to create a vision efficient tuning pipeline for prediction
         Args:
             model: model id on modelscope hub.
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> petl_pipeline = pipeline('vision-efficient-tuning',
                 'damo/cv_vitb16_classification_vision-efficient-tuning-adapter')
             >>> result = petl_pipeline(
                 'data/test/images/vision_efficient_tuning_test_1.png')
             >>> print(f'Output: {result}.')
         """
         super().__init__(model=model, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/vision_middleware_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/vision_middleware_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -5,23 +5,23 @@
 from typing import Any, Dict
 
 import numpy as np
 import torch
 import torchvision.transforms as transforms
 from mmcv.parallel import collate, scatter
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.cv.vision_middleware import VisionMiddlewareModel
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.cv.vision_middleware import VisionMiddlewareModel
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_segmentation,
     module_name=Pipelines.vision_middleware_multi_task)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/vop_retrieval_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/vop_retrieval_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,34 +1,32 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import gzip
 import math
 import os
 import os.path as osp
 import pickle
 import random
 from collections import defaultdict, deque
 from typing import Any, Dict
 
 import numpy as np
 import torch
 from tqdm import tqdm
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.cv.vop_retrieval import (LengthAdaptiveTokenizer, VoP,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.cv.vop_retrieval import (LengthAdaptiveTokenizer, VoP,
                                                 init_transform_dict, load_data,
                                                 load_frames_from_video)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import load_image
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import load_image
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.vop_retrieval, module_name=Pipelines.vop_retrieval)
 class VopRetrievalPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/cv/vop_retrieval_se_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/vop_retrieval_se_pipeline.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,41 +1,38 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import gzip
 import os.path as osp
 from typing import Any, Dict
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.cv.vop_retrieval import (LengthAdaptiveTokenizer,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.cv.vop_retrieval import (LengthAdaptiveTokenizer,
                                                 init_transform_dict, load_data,
                                                 load_frames_from_video)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.vop_retrieval, module_name=Pipelines.vop_retrieval_se)
 class VopRetrievalSEPipeline(Pipeline):
 
     def __init__(self, model: str, **kwargs):
         r""" Card VopRetrievalSE Pipeline.
 
         Examples:
         >>>
-        >>>   from modelscope.pipelines import pipeline
+        >>>   from weathon.pipelines import pipeline
         >>>   vop_pipeline = pipeline(Tasks.vop_retrieval,
         >>>            model='damo/cv_vit-b32_retrieval_vop_bias')
         >>>
         >>>   # IF DO TEXT-TO-VIDEO:
         >>>   input_text = 'a squid is talking'
         >>>   result = vop_pipeline(input_text)
         >>>   result:
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/__init__.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .generative_multi_modal_embedding_pipeline import GEMMMultiModalEmbeddingPipeline
     from .image_captioning_pipeline import ImageCaptioningPipeline
     from .visual_entailment_pipeline import VisualEntailmentPipeline
     from .visual_grounding_pipeline import VisualGroundingPipeline
     from .multi_modal_embedding_pipeline import MultiModalEmbeddingPipeline
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/asr_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/asr_pipeline.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import MPlugForAllTasks, OfaForAllTasks
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import (MPlugPreprocessor, OfaPreprocessor,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import MPlugForAllTasks, OfaForAllTasks
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import (MPlugPreprocessor, OfaPreprocessor,
                                       Preprocessor)
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.auto_speech_recognition, module_name=Pipelines.ofa_asr)
 class AutomaticSpeechRecognitionPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/megatron_bert/__init__.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,19 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .stable_diffusion import StableDiffusionWrapperPipeline
-    from .stable_diffusion import ChineseStableDiffusionPipeline
+    from .configuration import MegatronBertConfig
+    from .backbone import MegatronBertModel
+    from .fill_mask import MegatronBertForMaskedLM
 else:
     _import_structure = {
-        'stable_diffusion':
-        ['StableDiffusionWrapperPipeline', 'ChineseStableDiffusionPipeline']
+        'configuration': ['MegatronBertConfig'],
+        'backbone': ['MegatronBertModel'],
+        'fill_mask': ['MegatronBertForMaskedLM'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict, Generator, List, Union
 
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.utils.constant import Hubs
-from modelscope.utils.device import create_device
-from modelscope.utils.hub import snapshot_download
+from weathon.pipelines.base import Input, Pipeline
+from weathon.utils.constant import Hubs
+from weathon.utils.device import create_device
+from weathon.utils.hub import snapshot_download
 
 
 class DiffusersPipeline(Pipeline):
 
     def __init__(self, model: str, device: str = 'gpu', **kwargs):
         """
         use `model` to create a diffusers pipeline
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -18,20 +18,20 @@
                                   EulerAncestralDiscreteScheduler,
                                   EulerDiscreteScheduler, LMSDiscreteScheduler,
                                   PNDMScheduler)
 from PIL import Image
 from transformers import (ChineseCLIPProcessor, ChineseCLIPTextModel,
                           CLIPFeatureExtractor)
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.registry import PIPELINES
+from weathon.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
     DiffusersPipeline
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     Tasks.text_to_image_synthesis,
     module_name=Pipelines.chinese_stable_diffusion)
 class ChineseStableDiffusionPipeline(DiffusersPipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -4,20 +4,20 @@
 
 import cv2
 import numpy as np
 import torch
 from diffusers import StableDiffusionPipeline
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.registry import PIPELINES
+from weathon.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
     DiffusersPipeline
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants import Tasks
 
 
 # Wrap around the diffusers stable diffusion pipeline implementation
 # for a unified ModelScope pipeline experience. Native stable diffusion
 # pipelines will be implemented in later releases.
 @PIPELINES.register_module(
     Tasks.text_to_image_synthesis,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,23 +14,23 @@
 import torch
 import torch.nn as nn
 import torchvision.transforms as T
 import torchvision.transforms.functional as TF
 from PIL import Image
 from torch.nn import functional as F
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal.guided_diffusion.script import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal.guided_diffusion.script import \
     create_diffusion
-from modelscope.models.multi_modal.guided_diffusion.unet import HFUNetModel
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
+from weathon.models.multi_modal.guided_diffusion.unet import HFUNetModel
+from weathon.outputs import OutputKeys
+from weathon.registry import PIPELINES
+from weathon.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
     DiffusersPipeline
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants import Tasks
 from .utils import resize
 
 
 def parse_prompt(prompt):
     if prompt.startswith('http://') or prompt.startswith('https://'):
         vals = prompt.rsplit(':', 2)
         vals = [vals[0] + ':' + vals[1], *vals[2:]]
@@ -167,16 +167,16 @@
 
     def __init__(self, model: str, device: str = 'gpu', **kwargs):
         """  Chinese Disco Diffusion Pipeline.
 
         Examples:
 
         >>> import cv2
-        >>> from modelscope.pipelines import pipeline
-        >>> from modelscope.utils.constant import Tasks
+        >>> from weathon.pipelines import pipeline
+        >>> from weathon.utils.constants import Tasks
 
         >>> prompt = ''
         >>> output_image_path = './result.png'
         >>> input = {
         >>>     'text': prompt
         >>> }
         >>> pipe = pipeline(
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/document_vl_embedding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/document_vl_embedding_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,21 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
-import torch
-
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal.vldoc.model import VLDocForDocVLEmbedding
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.multi_modal import (Preprocessor,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal.vldoc.model import VLDocForDocVLEmbedding
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors.multi_modal import (Preprocessor,
                                                   VLDocPreprocessor)
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.document_vl_embedding, module_name=Pipelines.document_vl_embedding)
 class DocumentVLEmbeddingPipeline(Pipeline):
@@ -28,16 +24,16 @@
 
         Args:
             model: model id on modelscope hub.
             preprocessor: type `Preprocessor`. If None, `VLDocPreprocessor` is used.
 
         Examples:
 
-        >>> from modelscope.models import Model
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.models import Model
+        >>> from weathon.pipelines import pipeline
         >>> model = Model.from_pretrained(
             'damo/multi-modal_convnext-roberta-base_vldoc-embedding')
         >>> doc_VL_emb_pipeline = pipeline(task='document-vl-embedding', model=model)
         >>> inp = {
                 'images': ['data/demo.png'],
                 'ocr_info_paths': ['data/demo.json']
             }
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -3,21 +3,21 @@
 
 import cv2
 import numpy as np
 import torch
 import torchvision.transforms as transforms
 from PIL import Image
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import LoadImage
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.efficient_diffusion_tuning,
     module_name=Pipelines.efficient_diffusion_tuning)
@@ -25,15 +25,15 @@
 
     def __init__(self, model: str, **kwargs):
         """
         use `model` to create a diffusion efficient tuning pipeline for prediction
         Args:
             model: model id on modelscope hub.
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> petl_pipeline = pipeline('efficient-diffusion-tuning',
                 'damo/cv_vitb16_classification_vision-efficient-tuning-adapter')
             >>> result = petl_pipeline(
                 'data/test/images/vision_efficient_tuning_test_1.png')
             >>> print(f'Output: {result}.')
         """
         super().__init__(model=model, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 
 from typing import Any, Dict
 
-from modelscope.metainfo import Pipelines
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.generative_multi_modal_embedding,
     module_name=Pipelines.generative_multi_modal_embedding)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/gridvlp_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/gridvlp_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 import time
 import traceback
-from typing import Any, Dict, Optional
+from typing import Any, Dict
 
 import json
 import numpy as np
 import torch
 from PIL import Image
 from transformers import BertTokenizer
 
-from modelscope.hub.snapshot_download import snapshot_download
-from modelscope.metainfo import Pipelines
-from modelscope.pipelines import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, Frameworks,
-                                       Invoke, Tasks)
-from modelscope.utils.logger import get_logger
+from weathon.base import BasePipeline
+from weathon.utils.constants import Invoke, DEFAULT_MODEL_REVISION, Frameworks, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.registry import PIPELINES
+from weathon.preprocessors.image import load_image
+from weathon.utils.hub.utils import snapshot_download
+
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def cost(end, begin):
     return '{:.2f}ms'.format((end - begin) * 1000)
 
@@ -65,32 +63,29 @@
     _img = np.require(_img.transpose((2, 0, 1)), dtype=np.float32)
     _img *= Config.SCALE
     _img -= Config.MEAN
     _img /= Config.STD
     return _img
 
 
-class GridVlpPipeline(Pipeline):
+class GridVlpPipeline(BasePipeline):
     """ Pipeline for gridvlp, including classification and embedding."""
 
     def __init__(self, model_name_or_path: str, **kwargs):
         """ Pipeline for gridvlp, including classification and embedding.
         Args:
             model: path to local model directory.
         """
         # download model from modelscope to local model dir
         logger.info(f'load checkpoint from modelscope {model_name_or_path}')
         if osp.exists(model_name_or_path):
             local_model_dir = model_name_or_path
         else:
             invoked_by = '%s/%s' % (Invoke.KEY, Invoke.PIPELINE)
-            local_model_dir = snapshot_download(
-                model_name_or_path,
-                DEFAULT_MODEL_REVISION,
-                user_agent=invoked_by)
+            local_model_dir = snapshot_download(model_name_or_path,DEFAULT_MODEL_REVISION, user_agent=invoked_by)
         self.local_model_dir = local_model_dir
 
         # load model from cpu and torch jit model
         logger.info(f'load model from {local_model_dir}')
         self.model = torch.jit.load(
             osp.join(local_model_dir, 'pytorch_model.pt'))
         self.framework = Frameworks.torch
@@ -147,39 +142,32 @@
             'input_ids': inputs['input_ids'],
             'input_mask': inputs['attention_mask'],
             'segment_ids': inputs['token_type_ids']
         }
         return input_dict
 
 
-@PIPELINES.register_module(
-    Tasks.visual_question_answering,
-    module_name=Pipelines.gridvlp_multi_modal_classification)
+@PIPELINES.register_module(Tasks.visual_question_answering, module_name=Pipelines.gridvlp_multi_modal_classification)
 class GridVlpClassificationPipeline(GridVlpPipeline):
     """ Pipeline for gridvlp classification, including cate classfication and
     brand classification.
 
     Example:
 
     ```python
-    >>> from modelscope.pipelines.multi_modal.gridvlp_pipeline import \
-    GridVlpClassificationPipeline
-
+    >>> from weathon.pipelines.multi_modal.gridvlp_pipeline import GridVlpClassificationPipeline
     >>> pipeline = GridVlpClassificationPipeline('rgtjf1/multi-modal_gridvlp_classification_chinese-base-ecom-cate')
-    >>> output = pipeline({'text': '448575',\
-        'image':'https://yejiabo-public.oss-cn-zhangjiakou.aliyuncs.com/alinlp/clothes.png'})
+    >>> output = pipeline({'text': '448575', 'image':'https://yejiabo-public.oss-cn-zhangjiakou.aliyuncs.com/alinlp/clothes.png'})
     >>> output['text'][0]
     {'label': {'cate_name': '', 'cate_path': '>>>>>>'}, 'score': 0.4146, 'rank': 0}
-
     ```
     """
 
     def __init__(self, model_name_or_path: str, **kwargs):
-        """ Pipeline for gridvlp classification, including cate classfication and
-    brand classification.
+        """ Pipeline for gridvlp classification, including cate classfication and brand classification.
         Args:
             model: path to local model directory.
         """
         super().__init__(model_name_or_path, **kwargs)
 
         # load label mapping
         logger.info(f'load label mapping from {self.local_model_dir}')
@@ -232,15 +220,15 @@
 class GridVlpEmbeddingPipeline(GridVlpPipeline):
     """ Pipeline for gridvlp embedding. These only generate unified multi-modal
     embeddings and output it in `text_embedding` or `img_embedding`.
 
     Example:
 
     ```python
-    >>> from modelscope.pipelines.multi_modal.gridvlp_pipeline import \
+    >>> from weathon.pipelines.multi_modal.gridvlp_pipeline import \
     GridVlpEmbeddingPipeline
 
     >>> pipeline = GridVlpEmbeddingPipeline('rgtjf1/multi-modal_gridvlp_classification_chinese-base-ecom-embedding')
     >>> outputs = pipeline({'text': '448575',\
         'image':'https://yejiabo-public.oss-cn-zhangjiakou.aliyuncs.com/alinlp/clothes.png'})
     >>> outputs["text_embedding"].shape
     (768,)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/image_captioning_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/image_captioning_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
-import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import (CLIP_Interrogator, MPlugForAllTasks,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import (CLIP_Interrogator, MPlugForAllTasks,
                                            OfaForAllTasks)
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import (
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import (
     ImageCaptioningClipInterrogatorPreprocessor, MPlugPreprocessor,
-    OfaPreprocessor, Preprocessor, load_image)
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+    OfaPreprocessor, Preprocessor)
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.image_captioning, module_name=Pipelines.image_captioning)
 class ImageCaptioningPipeline(Pipeline):
@@ -28,16 +26,16 @@
                  preprocessor: Optional[Preprocessor] = None,
                  **kwargs):
         """
         use `model` and `preprocessor` to create a image captioning pipeline for prediction
         Args:
             model: model id on modelscope hub.
         Examples:
-        from modelscope.pipelines import pipeline
-        from modelscope.utils.constant import Tasks
+        from weathon.pipelines import pipeline
+        from weathon.utils.constants import Tasks
 
         model_id = 'damo/cv_clip-interrogator'
         input_image = "test.png"
 
         pipeline_ci = pipeline(Tasks.image_captioning, model=model_id)
         print(pipeline_ci(input_image))
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/image_text_retrieval_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/video_question_answering_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,44 +1,52 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import MPlugPreprocessor, Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.multi_modal import HiTeAForAllTasks
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import HiTeAPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
 
-logger = get_logger()
+__all__ = ['VideoQuestionAnsweringPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.image_text_retrieval, module_name=Pipelines.image_text_retrieval)
-class ImageTextRetrievalPipeline(Pipeline):
+    Tasks.video_question_answering,
+    module_name=Pipelines.video_question_answering)
+class VideoQuestionAnsweringPipeline(Pipeline):
 
     def __init__(self,
                  model: Union[Model, str],
                  preprocessor: Optional[Preprocessor] = None,
                  **kwargs):
-        """
-        use `model` and `preprocessor` to create a
-        image text retrieval pipeline for prediction
+        """use `model` and `preprocessor` to create a video question answering pipeline for prediction
+
         Args:
-            model: model id on modelscope hub.
+            model (HiTeAForVideoQuestionAnswering): a model instance
+            preprocessor (HiTeAForVideoQuestionAnsweringPreprocessor): a preprocessor instance
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
-        self.model.eval()
-        assert isinstance(self.model, Model), \
-            f'please check whether model config exists in {ModelFile.CONFIGURATION}'
         if preprocessor is None:
-            self.preprocessor = MPlugPreprocessor(self.model.model_dir)
+            if isinstance(self.model, HiTeAForAllTasks):
+                self.preprocessor = HiTeAPreprocessor(self.model.model_dir)
+        self.model.eval()
 
     def forward(self, inputs: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         with torch.no_grad():
             return super().forward(inputs, **forward_params)
 
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
+    def postprocess(self, inputs: Dict[str, Tensor],
+                    **postprocess_params) -> Dict[str, str]:
+        """process the prediction results
+
+        Args:
+            inputs (Dict[str, Any]): _description_
+
+        Returns:
+            Dict[str, str]: the prediction results
+        """
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/mgeo_ranking_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/mgeo_ranking_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Optional, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['MGeoRankingPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.text_ranking, module_name=Pipelines.mgeo_ranking)
 class MGeoRankingPipeline(Pipeline):
@@ -30,15 +28,15 @@
                  **kwargs):
         """Use `model` and `preprocessor` to create a nlp word segment pipeline
            for prediction.
 
         Args:
             model (str or Model): Supply either a local model dir which
             supported the WS task, or a model id from the model hub, or a torch
-            model instance. preprocessor (Preprocessor): An optional
+            model instance. preprocessor (BasePreprocessor): An optional
             preprocessor instance, please make sure the preprocessor fits for
             the model if supplied. kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/multi_modal_embedding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/sudoku_pipeline.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,43 +1,52 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Optional, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal.clip.model import CLIPForMultiModalEmbedding
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors.multi_modal import CLIPPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+import torch
+
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import OfaForAllTasks
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import OfaPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
-@PIPELINES.register_module(
-    Tasks.image_text_retrieval, module_name=Pipelines.multi_modal_embedding)
-@PIPELINES.register_module(
-    Tasks.multi_modal_embedding, module_name=Pipelines.multi_modal_embedding)
-class MultiModalEmbeddingPipeline(Pipeline):
+@PIPELINES.register_module(Tasks.sudoku, module_name=Pipelines.ofa_sudoku)
+class SudokuPipeline(Pipeline):
+    R"""
+    pipeline for sudoku solving
+    """
 
     def __init__(self,
                  model: Union[Model, str],
                  preprocessor: Optional[Preprocessor] = None,
                  **kwargs):
         """
-        use `model` and `preprocessor` to create a kws pipeline for prediction
+        use `model` and `preprocessor` to create a pipeline for solving sudoku
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
         self.model.eval()
         if preprocessor is None:
-            if isinstance(self.model, CLIPForMultiModalEmbedding):
-                self.preprocessor = CLIPPreprocessor(self.model.model_dir)
+            if isinstance(self.model, OfaForAllTasks):
+                self.preprocessor = OfaPreprocessor(self.model.model_dir)
             else:
-                raise NotImplementedError
+                raise 'no preprocessor is provided'
 
-    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        return self.model(self.preprocess(input))
+    def _batch(self, data):
+        if isinstance(self.model, OfaForAllTasks):
+            return batch_process(self.model, data)
+        else:
+            return super(SudokuPipeline, self)._batch(data)
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        with torch.no_grad():
+            return super().forward(inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/multimodal_dialogue_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/multimodal_dialogue_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,31 +1,30 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import MplugOwlForConditionalGeneration
-from modelscope.outputs import OutputKeys, TokenGeneratorOutput
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import MplugOwlPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import MplugOwlForConditionalGeneration
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import MplugOwlPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.multimodal_dialogue, module_name=Pipelines.multimodal_dialogue)
 class MultimodalDialoguePipeline(Pipeline):
     r""" Multimodal Dialogue Pipeline.
 
     Examples:
-    >>> from modelscope.pipelines import pipeline
+    >>> from weathon.pipelines import pipeline
     >>> chatbot = pipeline('multimodal-dialogue', 'damo/multi-modal_mplug_owl_multimodal-dialogue_7b')
     >>> image = 'data/resource/portrait_input.png'
     >>> system_prompt_1 = 'The following is a conversation between a curious human and AI assistant.'
     >>> system_prompt_2 = "The assistant gives helpful, detailed, and polite answers to the user's questions."
     >>> messages = {
     >>>       'messages': [
     >>>            {
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/ocr_recognition_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/video_captioning_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,48 +1,54 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import OfaForAllTasks
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import OfaPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import HiTeAForAllTasks
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import HiTeAPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.ocr_recognition, module_name=Pipelines.ofa_ocr_recognition)
-class OcrRecognitionPipeline(Pipeline):
+    Tasks.video_captioning, module_name=Pipelines.video_captioning)
+class VideoCaptioningPipeline(Pipeline):
 
     def __init__(self,
                  model: Union[Model, str],
                  preprocessor: Optional[Preprocessor] = None,
                  **kwargs):
         """
-        use `model` and `preprocessor` to create a ocr recognition pipeline for prediction
+        use `model` and `preprocessor` to create a video captioning pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
         self.model.eval()
         if preprocessor is None:
-            if isinstance(self.model, OfaForAllTasks):
-                self.preprocessor = OfaPreprocessor(self.model.model_dir)
+            if isinstance(self.model, HiTeAForAllTasks):
+                self.preprocessor = HiTeAPreprocessor(self.model.model_dir)
 
     def _batch(self, data):
-        if isinstance(self.model, OfaForAllTasks):
-            return batch_process(self.model, data)
+        if isinstance(self.model, HiTeAForAllTasks):
+            from transformers.tokenization_utils_base import BatchEncoding
+            batch_data = dict(train=data[0]['train'])
+            batch_data['video'] = torch.cat([d['video'] for d in data])
+            question = {}
+            for k in data[0]['question'].keys():
+                question[k] = torch.cat([d['question'][k] for d in data])
+            batch_data['question'] = BatchEncoding(question)
+            return batch_data
         else:
-            return super(OcrRecognitionPipeline, self)._batch(data)
+            return super()._collate_batch(data)
 
     def forward(self, inputs: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         with torch.no_grad():
             return super().forward(inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -3,23 +3,23 @@
 import os
 from typing import Any, Dict
 
 import numpy as np
 import torch
 from torchvision import transforms
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal.soonet import (SimpleTokenizer,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal.soonet import (SimpleTokenizer,
                                                   decode_video, load_clip)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.video_temporal_grounding,
     module_name=Pipelines.soonet_video_temporal_grounding)
@@ -27,15 +27,15 @@
 
     def __init__(self, model: str, **kwargs):
         """
         SOONet pipeline for video temporal groundinng
 
         Examples:
 
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
 
         >>> soonet_pipeline = pipeline("video-temporal-grounding", "damo/multi-modal_soonet_video-temporal-grounding")
         >>> soonet_pipeline(
             ('a man takes food out of the refrigerator.',
              'soonet_video_temporal_grounding_test_video.mp4'))
 
         >>> {
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/sudoku_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/image_text_retrieval_pipeline.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,52 +1,42 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import OfaForAllTasks
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import OfaPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import MPlugPreprocessor, Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
-@PIPELINES.register_module(Tasks.sudoku, module_name=Pipelines.ofa_sudoku)
-class SudokuPipeline(Pipeline):
-    R"""
-    pipeline for sudoku solving
-    """
+@PIPELINES.register_module(
+    Tasks.image_text_retrieval, module_name=Pipelines.image_text_retrieval)
+class ImageTextRetrievalPipeline(Pipeline):
 
     def __init__(self,
                  model: Union[Model, str],
                  preprocessor: Optional[Preprocessor] = None,
                  **kwargs):
         """
-        use `model` and `preprocessor` to create a pipeline for solving sudoku
+        use `model` and `preprocessor` to create a
+        image text retrieval pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
         self.model.eval()
+        assert isinstance(self.model, Model), \
+            f'please check whether model config exists in {ModelFile.CONFIGURATION}'
         if preprocessor is None:
-            if isinstance(self.model, OfaForAllTasks):
-                self.preprocessor = OfaPreprocessor(self.model.model_dir)
-            else:
-                raise 'no preprocessor is provided'
-
-    def _batch(self, data):
-        if isinstance(self.model, OfaForAllTasks):
-            return batch_process(self.model, data)
-        else:
-            return super(SudokuPipeline, self)._batch(data)
+            self.preprocessor = MPlugPreprocessor(self.model.model_dir)
 
     def forward(self, inputs: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         with torch.no_grad():
             return super().forward(inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # Copyright 2021-2022 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Any, Dict
 
-from modelscope.metainfo import Pipelines
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.pipelines.base import Input, Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.multi_modal_similarity, module_name=Pipelines.multi_modal_similarity)
 class TEAMMultiModalSimilarityPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/text2sql_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/cv/product_retrieval_embedding_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,51 +1,40 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict
 
-import torch
+import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import OfaForAllTasks
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import OfaPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import LoadImage
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
-@PIPELINES.register_module(Tasks.text2sql, module_name=Pipelines.ofa_text2sql)
-class TextToSqlPipeline(Pipeline):
-    R"""
-    pipeline for text to sql task
-    """
-
-    def __init__(self,
-                 model: Union[Model, str],
-                 preprocessor: Optional[Preprocessor] = None,
-                 **kwargs):
-        """
-        use `model` and `preprocessor` to create a pipeline for text2sql task
+@PIPELINES.register_module(
+    Tasks.product_retrieval_embedding,
+    module_name=Pipelines.product_retrieval_embedding)
+class ProductRetrievalEmbeddingPipeline(Pipeline):
+
+    def __init__(self, model: str, **kwargs):
+        """use `model` to create a pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
-        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
-        self.model.eval()
-        if preprocessor is None:
-            if isinstance(self.model, OfaForAllTasks):
-                self.preprocessor = OfaPreprocessor(self.model.model_dir)
-
-    def _batch(self, data):
-        if isinstance(self.model, OfaForAllTasks):
-            return batch_process(self.model, data)
-        else:
-            return super(TextToSqlPipeline, self)._batch(data)
-
-    def forward(self, inputs: Dict[str, Any],
-                **forward_params) -> Dict[str, Any]:
-        with torch.no_grad():
-            return super().forward(inputs, **forward_params)
+        super().__init__(model=model, **kwargs)
+
+    def preprocess(self, input: Input) -> Dict[str, Any]:
+        """
+        preprocess the input image to cv2-bgr style
+        """
+        img = LoadImage.convert_to_ndarray(input)  # array with rgb
+        img = np.ascontiguousarray(img[:, :, ::-1])  # array with bgr
+        result = {'img': img}  # only for detection
+        return result
+
+    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
+        return self.model(input)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/text_to_image_synthesis_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/summarization_pipeline.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,55 +1,65 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from typing import Any, Dict, Optional
+from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import (
-    MultiStageDiffusionForTextToImageSynthesis, OfaForTextToImageSynthesis)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import OfaPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines, Preprocessors
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import Fields, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.text_to_image_synthesis,
-    module_name=Pipelines.text_to_image_synthesis)
-class TextToImageSynthesisPipeline(Pipeline):
+    Tasks.text_summarization, module_name=Pipelines.text_generation)
+class SummarizationPipeline(Pipeline):
 
     def __init__(self,
-                 model: str,
+                 model: Union[Model, str],
                  preprocessor: Optional[Preprocessor] = None,
+                 config_file: str = None,
+                 device: str = 'gpu',
+                 auto_collate=True,
                  **kwargs):
-        """
-        use `model` and `preprocessor` to create a kws pipeline for prediction
+        """Use `model` and `preprocessor` to create a Summarization pipeline for prediction.
+
         Args:
-            model: model id on modelscope hub.
+            model (str or Model): Supply either a local model dir which supported the summarization task,
+            or a model id from the model hub, or a model instance.
+            preprocessor (BasePreprocessor): An optional preprocessor instance.
+            kwargs (dict, `optional`):
+                Extra kwargs passed into the preprocessor's constructor.
         """
-        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
-        if preprocessor is None and isinstance(self.model,
-                                               OfaForTextToImageSynthesis):
-            self.preprocessor = OfaPreprocessor(self.model.model_dir)
-
-    def preprocess(self, input: Input, **preprocess_params) -> Dict[str, Any]:
-        if self.preprocessor is not None:
-            return self.preprocessor(input, **preprocess_params)
+        super().__init__(
+            model=model,
+            preprocessor=preprocessor,
+            config_file=config_file,
+            device=device,
+            auto_collate=auto_collate)
+        self.model.eval()
+        if preprocessor is None:
+            if self.model.__class__.__name__ == 'OfaForAllTasks':
+                self.preprocessor = Preprocessor.from_pretrained(
+                    self.model.model_dir,
+                    type=Preprocessors.ofa_tasks_preprocessor,
+                    field=Fields.multi_modal)
+            else:
+                self.preprocessor = Preprocessor.from_pretrained(
+                    self.model.model_dir, **kwargs)
+
+    def _batch(self, data):
+        if self.model.__class__.__name__ == 'OfaForAllTasks':
+            return batch_process(self.model, data)
         else:
-            return input
+            return super(SummarizationPipeline, self)._batch(data)
 
-    def forward(self, input: Dict[str, Any]) -> Dict[str, Any]:
-        if isinstance(self.model,
-                      (OfaForTextToImageSynthesis,
-                       MultiStageDiffusionForTextToImageSynthesis)):
-            return self.model(input)
-        return self.model.generate(input)
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        with torch.no_grad():
+            return super().forward(inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        if not isinstance(inputs, list):
-            inputs = [inputs]
-        return {OutputKeys.OUTPUT_IMGS: inputs}
+        return inputs
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/text_to_video_synthesis_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/text_to_video_synthesis_pipeline.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,36 +1,34 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import tempfile
-from typing import Any, Dict, Optional
+from typing import Any, Dict
 
 import cv2
 import torch
 from einops import rearrange
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Input, Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.pipelines.base import Input, Pipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.text_to_video_synthesis,
     module_name=Pipelines.text_to_video_synthesis)
 class TextToVideoSynthesisPipeline(Pipeline):
     r""" Text To Video Synthesis Pipeline.
 
     Examples:
-    >>> from modelscope.pipelines import pipeline
-    >>> from modelscope.outputs import OutputKeys
+    >>> from weathon.pipelines import pipeline
+    >>> from weathon.outputs import OutputKeys
 
     >>> p = pipeline('text-to-video-synthesis', 'damo/text-to-video-synthesis')
     >>> test_text = {
     >>>         'text': 'A panda eating bamboo on a rock.',
     >>>     }
     >>> p(test_text,)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/video_captioning_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/visual_grounding_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,55 +1,46 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import HiTeAForAllTasks
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import HiTeAPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.multi_modal import OfaForAllTasks
+from weathon.pipelines.base import Model, Pipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import OfaPreprocessor, Preprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
-    Tasks.video_captioning, module_name=Pipelines.video_captioning)
-class VideoCaptioningPipeline(Pipeline):
+    Tasks.visual_grounding, module_name=Pipelines.visual_grounding)
+class VisualGroundingPipeline(Pipeline):
 
     def __init__(self,
                  model: Union[Model, str],
                  preprocessor: Optional[Preprocessor] = None,
                  **kwargs):
         """
-        use `model` and `preprocessor` to create a video captioning pipeline for prediction
+        use `model` and `preprocessor` to create a visual grounding pipeline for prediction
         Args:
             model: model id on modelscope hub.
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
-        self.model.eval()
-        if preprocessor is None:
-            if isinstance(self.model, HiTeAForAllTasks):
-                self.preprocessor = HiTeAPreprocessor(self.model.model_dir)
+        self.model.model.eval()
+        if preprocessor is None and isinstance(self.model, OfaForAllTasks):
+            self.preprocessor = OfaPreprocessor(model_dir=self.model.model_dir)
 
     def _batch(self, data):
-        if isinstance(self.model, HiTeAForAllTasks):
-            from transformers.tokenization_utils_base import BatchEncoding
-            batch_data = dict(train=data[0]['train'])
-            batch_data['video'] = torch.cat([d['video'] for d in data])
-            question = {}
-            for k in data[0]['question'].keys():
-                question[k] = torch.cat([d['question'][k] for d in data])
-            batch_data['question'] = BatchEncoding(question)
-            return batch_data
+        if isinstance(self.model, OfaForAllTasks):
+            return batch_process(self.model, data)
         else:
-            return super()._collate_batch(data)
+            return super(VisualGroundingPipeline, self)._batch(data)
 
     def forward(self, inputs: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         with torch.no_grad():
             return super().forward(inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/video_question_answering_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/multi_modal/visual_question_answering_pipeline.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,45 +1,53 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.multi_modal import HiTeAForAllTasks
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import HiTeAPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.multi_modal import MPlugForAllTasks, OfaForAllTasks
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import (MPlugPreprocessor, OfaPreprocessor,
+                                      Preprocessor)
+from weathon.utils.constants import Tasks
 
-__all__ = ['VideoQuestionAnsweringPipeline']
+__all__ = ['VisualQuestionAnsweringPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.video_question_answering,
-    module_name=Pipelines.video_question_answering)
-class VideoQuestionAnsweringPipeline(Pipeline):
+    Tasks.visual_question_answering,
+    module_name=Pipelines.visual_question_answering)
+class VisualQuestionAnsweringPipeline(Pipeline):
 
     def __init__(self,
                  model: Union[Model, str],
                  preprocessor: Optional[Preprocessor] = None,
                  **kwargs):
-        """use `model` and `preprocessor` to create a video question answering pipeline for prediction
+        """use `model` and `preprocessor` to create a visual question answering pipeline for prediction
 
         Args:
-            model (HiTeAForVideoQuestionAnswering): a model instance
-            preprocessor (HiTeAForVideoQuestionAnsweringPreprocessor): a preprocessor instance
+            model (MPlugForVisualQuestionAnswering): a model instance
+            preprocessor (MPlugVisualQuestionAnsweringPreprocessor): a preprocessor instance
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
         if preprocessor is None:
-            if isinstance(self.model, HiTeAForAllTasks):
-                self.preprocessor = HiTeAPreprocessor(self.model.model_dir)
+            if isinstance(self.model, OfaForAllTasks):
+                self.preprocessor = OfaPreprocessor(self.model.model_dir)
+            elif isinstance(self.model, MPlugForAllTasks):
+                self.preprocessor = MPlugPreprocessor(self.model.model_dir)
         self.model.eval()
 
+    def _batch(self, data):
+        if isinstance(self.model, OfaForAllTasks):
+            return batch_process(self.model, data)
+        else:
+            return super(VisualQuestionAnsweringPipeline, self)._batch(data)
+
     def forward(self, inputs: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         with torch.no_grad():
             return super().forward(inputs, **forward_params)
 
     def postprocess(self, inputs: Dict[str, Tensor],
                     **postprocess_params) -> Dict[str, str]:
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/visual_grounding_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/mglm_text_summarization_pipeline.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,48 +1,46 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Optional, Union
+# Copyright (c) 2022 Zhipu.AI
 
-import torch
+import os
+from typing import Any, Dict, Optional, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.multi_modal import OfaForAllTasks
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import OfaPreprocessor, Preprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.models.nlp import MGLMForTextSummarization
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import (MGLMSummarizationPreprocessor,
+                                      Preprocessor)
+from weathon.utils.constants import Tasks
 
-logger = get_logger()
+__all__ = ['MGLMTextSummarizationPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.visual_grounding, module_name=Pipelines.visual_grounding)
-class VisualGroundingPipeline(Pipeline):
+    group_key=Tasks.text_summarization,
+    module_name=Pipelines.mglm_text_summarization)
+class MGLMTextSummarizationPipeline(Pipeline):
 
     def __init__(self,
-                 model: Union[Model, str],
+                 model: Union[MGLMForTextSummarization, str],
                  preprocessor: Optional[Preprocessor] = None,
+                 *args,
                  **kwargs):
-        """
-        use `model` and `preprocessor` to create a visual grounding pipeline for prediction
-        Args:
-            model: model id on modelscope hub.
-        """
+        model = MGLMForTextSummarization(model) if isinstance(model,
+                                                              str) else model
+        self.model = model
+        self.model.eval()
+        if preprocessor is None:
+            preprocessor = MGLMSummarizationPreprocessor()
+        from weathon.utils.torch_utils import _find_free_port
+        os.environ['MASTER_PORT'] = str(_find_free_port())
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
-        self.model.model.eval()
-        if preprocessor is None and isinstance(self.model, OfaForAllTasks):
-            self.preprocessor = OfaPreprocessor(model_dir=self.model.model_dir)
-
-    def _batch(self, data):
-        if isinstance(self.model, OfaForAllTasks):
-            return batch_process(self.model, data)
-        else:
-            return super(VisualGroundingPipeline, self)._batch(data)
 
-    def forward(self, inputs: Dict[str, Any],
+    # define the forward pass
+    def forward(self, inputs: Union[Dict, str],
                 **forward_params) -> Dict[str, Any]:
-        with torch.no_grad():
-            return super().forward(inputs, **forward_params)
+        inputs = {'text': inputs} if isinstance(inputs, str) else inputs
+        return self.model.generate(inputs)
 
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        return inputs
+    # format the outputs from pipeline
+    def postprocess(self, input, **kwargs) -> Dict[str, Any]:
+        return input
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/multi_modal/visual_question_answering_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/dialog_intent_prediction_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,63 +1,67 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict, Union
 
-import torch
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp import SpaceForDialogIntent
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import DialogIntentPredictionPreprocessor
+from weathon.utils.constants import Tasks
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.multi_modal import MPlugForAllTasks, OfaForAllTasks
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import (MPlugPreprocessor, OfaPreprocessor,
-                                      Preprocessor)
-from modelscope.utils.constant import Tasks
-
-__all__ = ['VisualQuestionAnsweringPipeline']
+__all__ = ['DialogIntentPredictionPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.visual_question_answering,
-    module_name=Pipelines.visual_question_answering)
-class VisualQuestionAnsweringPipeline(Pipeline):
+    Tasks.task_oriented_conversation,
+    module_name=Pipelines.dialog_intent_prediction)
+class DialogIntentPredictionPipeline(Pipeline):
 
     def __init__(self,
-                 model: Union[Model, str],
-                 preprocessor: Optional[Preprocessor] = None,
+                 model: Union[SpaceForDialogIntent, str],
+                 preprocessor: DialogIntentPredictionPreprocessor = None,
+                 config_file: str = None,
+                 device: str = 'gpu',
+                 auto_collate=True,
                  **kwargs):
-        """use `model` and `preprocessor` to create a visual question answering pipeline for prediction
+        """Use `model` and `preprocessor` to create a dialog intent prediction pipeline
 
         Args:
-            model (MPlugForVisualQuestionAnswering): a model instance
-            preprocessor (MPlugVisualQuestionAnsweringPreprocessor): a preprocessor instance
+            model (str or SpaceForDialogIntent): Supply either a local model dir or a model id from the model hub,
+            or a SpaceForDialogIntent instance.
+            preprocessor (DialogIntentPredictionPreprocessor): An optional preprocessor instance.
+            kwargs (dict, `optional`):
+                Extra kwargs passed into the preprocessor's constructor.
         """
-        super().__init__(model=model, preprocessor=preprocessor, **kwargs)
+        super().__init__(
+            model=model,
+            preprocessor=preprocessor,
+            config_file=config_file,
+            device=device,
+            auto_collate=auto_collate,
+            compile=kwargs.pop('compile', False),
+            compile_options=kwargs.pop('compile_options', {}))
         if preprocessor is None:
-            if isinstance(self.model, OfaForAllTasks):
-                self.preprocessor = OfaPreprocessor(self.model.model_dir)
-            elif isinstance(self.model, MPlugForAllTasks):
-                self.preprocessor = MPlugPreprocessor(self.model.model_dir)
-        self.model.eval()
-
-    def _batch(self, data):
-        if isinstance(self.model, OfaForAllTasks):
-            return batch_process(self.model, data)
-        else:
-            return super(VisualQuestionAnsweringPipeline, self)._batch(data)
-
-    def forward(self, inputs: Dict[str, Any],
-                **forward_params) -> Dict[str, Any]:
-        with torch.no_grad():
-            return super().forward(inputs, **forward_params)
+            self.preprocessor = DialogIntentPredictionPreprocessor(
+                self.model.model_dir, **kwargs)
+        self.categories = self.preprocessor.categories
 
-    def postprocess(self, inputs: Dict[str, Tensor],
-                    **postprocess_params) -> Dict[str, str]:
+    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, str]:
         """process the prediction results
 
         Args:
             inputs (Dict[str, Any]): _description_
 
         Returns:
             Dict[str, str]: the prediction results
         """
-        return inputs
+        import numpy as np
+        pred = inputs['pred']
+        pos = np.where(pred == np.max(pred))
+
+        return {
+            OutputKeys.OUTPUT: {
+                OutputKeys.PREDICTION: pred,
+                OutputKeys.LABEL_POS: pos[0],
+                OutputKeys.LABEL: self.categories[pos[0][0]]
+            }
+        }
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/__init__.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .automatic_post_editing_pipeline import AutomaticPostEditingPipeline
     from .conversational_text_to_sql_pipeline import ConversationalTextToSqlPipeline
     from .table_question_answering_pipeline import TableQuestionAnsweringPipeline
     from .dialog_intent_prediction_pipeline import DialogIntentPredictionPipeline
     from .dialog_modeling_pipeline import DialogModelingPipeline
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/automatic_post_editing_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/automatic_post_editing_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
-from html import unescape
 from typing import Any, Dict
 
-import jieba
 import numpy as np
 import tensorflow as tf
 from sacremoses import (MosesDetokenizer, MosesDetruecaser,
-                        MosesPunctNormalizer, MosesTokenizer, MosesTruecaser)
+                        MosesTokenizer, MosesTruecaser)
 from sentencepiece import SentencePieceProcessor
-from tensorflow.contrib.seq2seq.python.ops import beam_search_ops
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config, ConfigFields
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config, ConfigFields
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
     tf.disable_eager_execution()
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/canmt_translation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/canmt_translation_pipeline.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict, Optional, Union
 
 import torch
 from sacremoses import MosesDetokenizer
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import CanmtForTranslation
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import CanmtTranslationPreprocessor, Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.nlp import CanmtForTranslation
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import CanmtTranslationPreprocessor, Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['CanmtTranslationPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.competency_aware_translation,
     module_name=Pipelines.canmt_translation)
@@ -31,21 +29,21 @@
                  auto_collate=True,
                  **kwargs):
         """Use `model` and `preprocessor` to create a canmt translation pipeline for prediction.
 
         Args:
             model (str or Model): Supply either a local model dir which supported the canmt translation task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline(task='competency_aware_translation',
             >>>    model='damo/nlp_canmt_translation_zh2en_large')
             >>> sentence1 = ''
             >>> print(pipeline_ins(sentence1))
             >>> # Or use the list input:
             >>> print(pipeline_ins([sentence1])
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/codegeex_code_generation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/codegeex_code_generation_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 # Copyright (c) 2022 Zhipu.AI
 
-from typing import Any, Dict, Union
+from typing import Any, Dict, Union,List
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.nlp import CodeGeeXForCodeGeneration
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp import CodeGeeXForCodeGeneration
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     group_key=Tasks.code_generation,
     module_name=Pipelines.codegeex_code_generation)
 class CodeGeeXCodeGenerationPipeline(Pipeline):
 
     def __init__(self,
                  model: Union[CodeGeeXForCodeGeneration, str],
-                 preprocessor: [Preprocessor] = None,
+                 preprocessor: List[Preprocessor] = None,
                  *args,
                  **kwargs):
         model = CodeGeeXForCodeGeneration(model) if isinstance(model,
                                                                str) else model
         self.model = model
         self.model.eval()
         self.model.half()
@@ -29,15 +29,15 @@
 
         super().__init__(model=model, **kwargs)
 
     def preprocess(self, inputs, **preprocess_params) -> Dict[str, Any]:
         return inputs
 
     # define the forward pass
-    def forward(self, inputs: Union[Dict], **forward_params) -> Dict[str, Any]:
+    def forward(self, inputs: Dict, **forward_params) -> Dict[str, Any]:
         # check input format
         for para in ['prompt', 'language']:
             if para not in inputs:
                 raise Exception('Please check your input format.')
         if inputs['language'] not in [
                 'C++', 'C', 'C#', 'Cuda', 'Objective-C', 'Objective-C++',
                 'Python', 'Java', 'Scala', 'TeX', 'HTML', 'PHP', 'JavaScript',
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/codegeex_code_translation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/codegeex_code_translation_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 # Copyright (c) 2022 Zhipu.AI
 
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.nlp import CodeGeeXForCodeTranslation
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp import CodeGeeXForCodeTranslation
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     group_key=Tasks.code_translation,
     module_name=Pipelines.codegeex_code_translation)
 class CodeGeeXCodeTranslationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/conversational_text_to_sql_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/conversational_text_to_sql_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Union
 
-import torch
 from text2sql_lgesql.utils.example import Example
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import StarForTextToSql
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import ConversationalTextToSqlPreprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp import StarForTextToSql
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import ConversationalTextToSqlPreprocessor
+from weathon.utils.constants import Tasks
 
 __all__ = ['ConversationalTextToSqlPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.table_question_answering,
     module_name=Pipelines.conversational_text_to_sql)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/dialog_intent_prediction_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/named_entity_recognition_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,70 +1,70 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+from typing import Optional, Union
 
-from typing import Any, Dict, Union
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.registry import PIPELINES
+from weathon.pipelines.nlp import TokenClassificationPipeline
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import SpaceForDialogIntent
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import DialogIntentPredictionPreprocessor
-from modelscope.utils.constant import Tasks
-
-__all__ = ['DialogIntentPredictionPipeline']
+__all__ = ['NamedEntityRecognitionPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.task_oriented_conversation,
-    module_name=Pipelines.dialog_intent_prediction)
-class DialogIntentPredictionPipeline(Pipeline):
+    Tasks.named_entity_recognition,
+    module_name=Pipelines.named_entity_recognition)
+@PIPELINES.register_module(
+    Tasks.named_entity_recognition,
+    module_name=Pipelines.named_entity_recognition_thai)
+@PIPELINES.register_module(
+    Tasks.named_entity_recognition,
+    module_name=Pipelines.named_entity_recognition_viet)
+class NamedEntityRecognitionPipeline(TokenClassificationPipeline):
 
     def __init__(self,
-                 model: Union[SpaceForDialogIntent, str],
-                 preprocessor: DialogIntentPredictionPreprocessor = None,
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
                  config_file: str = None,
                  device: str = 'gpu',
                  auto_collate=True,
+                 sequence_length=512,
                  **kwargs):
-        """Use `model` and `preprocessor` to create a dialog intent prediction pipeline
+        """Use `model` and `preprocessor` to create a nlp NER pipeline for prediction
 
         Args:
-            model (str or SpaceForDialogIntent): Supply either a local model dir or a model id from the model hub,
-            or a SpaceForDialogIntent instance.
-            preprocessor (DialogIntentPredictionPreprocessor): An optional preprocessor instance.
+            model (str or Model): Supply either a local model dir which supported NER task, or a
+            model id from the model hub, or a torch model instance.
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+                the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
+
+        Examples:
+            >>> from weathon.pipelines import pipeline
+            >>> pipeline_ins = pipeline(task='named-entity-recognition',
+            >>>        model='damo/nlp_raner_named-entity-recognition_chinese-base-news')
+            >>> input = ''
+            >>> print(pipeline_ins(input))
+
+            To view other examples plese check the tests/pipelines/test_plugin_model.py.
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
             config_file=config_file,
             device=device,
             auto_collate=auto_collate,
             compile=kwargs.pop('compile', False),
             compile_options=kwargs.pop('compile_options', {}))
-        if preprocessor is None:
-            self.preprocessor = DialogIntentPredictionPreprocessor(
-                self.model.model_dir, **kwargs)
-        self.categories = self.preprocessor.categories
-
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, str]:
-        """process the prediction results
 
-        Args:
-            inputs (Dict[str, Any]): _description_
+        assert isinstance(self.model, Model), \
+            f'please check whether model config exists in {ModelFile.CONFIGURATION}'
 
-        Returns:
-            Dict[str, str]: the prediction results
-        """
-        import numpy as np
-        pred = inputs['pred']
-        pos = np.where(pred == np.max(pred))
-
-        return {
-            OutputKeys.OUTPUT: {
-                OutputKeys.PREDICTION: pred,
-                OutputKeys.LABEL_POS: pos[0],
-                OutputKeys.LABEL: self.categories[pos[0][0]]
-            }
-        }
+        if preprocessor is None:
+            self.preprocessor = Preprocessor.from_pretrained(
+                self.model.model_dir,
+                sequence_length=sequence_length,
+                **kwargs)
+        self.model.eval()
+        assert hasattr(self.preprocessor, 'id2label')
+        self.id2label = self.preprocessor.id2label
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/dialog_modeling_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/dialog_modeling_pipeline.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import SpaceForDialogModeling
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import DialogModelingPreprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.nlp import SpaceForDialogModeling
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import DialogModelingPreprocessor
+from weathon.utils.constants import Tasks
 
 __all__ = ['DialogModelingPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.task_oriented_conversation, module_name=Pipelines.dialog_modeling)
 class DialogModelingPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/dialog_state_tracking_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/dialog_state_tracking_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import SpaceForDST
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import DialogStateTrackingPreprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp import SpaceForDST
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import DialogStateTrackingPreprocessor
+from weathon.utils.constants import Tasks
 
 __all__ = ['DialogStateTrackingPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.task_oriented_conversation,
     module_name=Pipelines.dialog_state_tracking)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/distributed_gpt3_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/sentence_embedding_pipeline.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,66 +1,82 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from typing import Any, Dict
+from typing import Any, Dict, Optional, Union
 
+import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.nlp import DistributedGPT3
-from modelscope.pipelines.base import DistributedPipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import TextGenerationJiebaPreprocessor
-from modelscope.utils.constant import Tasks
-
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
-@PIPELINES.register_module(
-    Tasks.text_generation, module_name=Pipelines.gpt3_generation)
-class DistributedGPT3Pipeline(DistributedPipeline):
-    """This class is used to instantiate the gpt3 model.
-    """
+__all__ = ['SentenceEmbeddingPipeline']
 
-    model = None
 
-    def __init__(self, model, preprocessor=None, **kwargs):
-        """
+@PIPELINES.register_module(
+    Tasks.sentence_embedding, module_name=Pipelines.sentence_embedding)
+class SentenceEmbeddingPipeline(Pipeline):
 
+    def __init__(self,
+                 model: Union[Model, str],
+                 preprocessor: Optional[Preprocessor] = None,
+                 config_file: str = None,
+                 device: str = 'gpu',
+                 auto_collate=True,
+                 sequence_length=128,
+                 **kwargs):
+        """Use `model` and `preprocessor` to create a nlp text dual encoder then generates the text representation.
         Args:
-            model: The model piece, str is not supported.
-            preprocessor: The preprocessor matched with the model.
+            model (str or Model): Supply either a local model dir which supported the WS task,
+            or a model id from the model hub, or a torch model instance.
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
         """
+        super().__init__(
+            model=model,
+            preprocessor=preprocessor,
+            config_file=config_file,
+            device=device,
+            auto_collate=auto_collate,
+            compile=kwargs.pop('compile', False),
+            compile_options=kwargs.pop('compile_options', {}))
+
+        assert isinstance(self.model, Model), \
+            f'please check whether model config exists in {ModelFile.CONFIGURATION}'
+
         if preprocessor is None:
-            preprocessor = TextGenerationJiebaPreprocessor(model)
-        super().__init__(model, preprocessor=preprocessor, **kwargs)
-        assert hasattr(preprocessor, 'tokenizer')
-
-    @classmethod
-    def _instantiate_one(cls, rank, model_dir, **kwargs):
-        cls.model = DistributedGPT3(model_dir, rank, **kwargs)
-        cls.model.eval()
-
-    @classmethod
-    def _forward_one(cls, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        tokens = inputs['inputs']['input_ids'].cuda(
-            torch.cuda.current_device())
-        return cls.model.generate(tokens, **inputs['forward_params'])
+            self.preprocessor = Preprocessor.from_pretrained(
+                self.model.model_dir,
+                sequence_length=sequence_length,
+                **kwargs)
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        return self.model(**inputs, **forward_params)
 
-    def postprocess(self, inputs: Dict[str, Any],
-                    **postprocess_params) -> Dict[str, str]:
+    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         """process the prediction results
 
         Args:
             inputs (Dict[str, Any]): _description_
 
         Returns:
-            Dict[str, str]: the prediction results
+            Dict[str, Any]: the predicted text representation
         """
-        from modelscope.outputs import OutputKeys
+        embeddings = inputs['query_embeddings']
+        doc_embeddings = inputs['doc_embeddings']
+        if doc_embeddings is not None:
+            embeddings = torch.cat((embeddings, doc_embeddings), dim=0)
+        embeddings = embeddings.detach().cpu().numpy()
+        if doc_embeddings is not None:
+            scores = np.dot(embeddings[0:1, ],
+                            np.transpose(embeddings[1:, ], (1, 0))).tolist()[0]
+        else:
+            scores = []
         return {
-            OutputKeys.TEXT:
-            self.preprocessor.tokenizer.detokenize(
-                inputs.sequences[0].tolist())
+            OutputKeys.TEXT_EMBEDDING: embeddings,
+            OutputKeys.SCORES: scores
         }
-
-    def _sanitize_parameters(self, **pipeline_parameters):
-        return {}, pipeline_parameters, {}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/distributed_gpt_moe_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/distributed_gpt_moe_pipeline.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.nlp.gpt_moe.distributed_gpt_moe import DistributedGPTMoE
-from modelscope.pipelines.base import DistributedPipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import TextGenerationJiebaPreprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp.gpt_moe.distributed_gpt_moe import DistributedGPTMoE
+from weathon.pipelines.base import DistributedPipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import TextGenerationJiebaPreprocessor
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     Tasks.text_generation, module_name=Pipelines.gpt_moe_generation)
 class DistributedGPTMoEPipeline(DistributedPipeline):
     """This class is used to instantiate the gpt-moe model.
     """
@@ -43,13 +41,13 @@
 
         Args:
             inputs (Dict[str, Any]): _description_
 
         Returns:
             Dict[str, str]: the prediction results
         """
-        from modelscope.outputs import OutputKeys
+        from weathon.outputs import OutputKeys
         return {
             OutputKeys.TEXT:
             self.preprocessor.tokenizer.detokenize(
                 inputs.sequences[0].tolist())
         }
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/distributed_plug_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/distributed_plug_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.nlp.plug import DistributedPlug
-from modelscope.pipelines.base import DistributedPipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import TextGenerationTransformersPreprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp.plug import DistributedPlug
+from weathon.pipelines.base import DistributedPipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import TextGenerationTransformersPreprocessor
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     Tasks.text_generation, module_name=Pipelines.plug_generation)
 class DistributedPlugPipeline(DistributedPipeline):
     """This class is used to instantiate the plug model.
     """
@@ -97,13 +95,13 @@
 
         Args:
             inputs (Dict[str, Any]): _description_
 
         Returns:
             Dict[str, str]: the prediction results
         """
-        from modelscope.outputs import OutputKeys
+        from weathon.outputs import OutputKeys
         generate_context = inputs['generate_context']
         generate_context = ''.join(
             self.preprocessor.nlp_tokenizer.tokenizer.convert_ids_to_tokens(
                 generate_context)).replace('[UNK]', '').replace('##', '')
         return {OutputKeys.TEXT: generate_context}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/document_grounded_dialog_generate_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/document_grounded_dialog_generate_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import DocumentGroundedDialogGenerateModel
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import DocumentGroundedDialogGeneratePreprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.nlp import DocumentGroundedDialogGenerateModel
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import DocumentGroundedDialogGeneratePreprocessor
+from weathon.utils.constants import Tasks
 
 __all__ = ['DocumentGroundedDialogGeneratePipeline']
 
 
 @PIPELINES.register_module(
     Tasks.document_grounded_dialog_generate,
     module_name=Pipelines.document_grounded_dialog_generate)
@@ -34,15 +32,15 @@
             preprocessor: A preprocessor instance.
             config_file: Path to config file.
             device: Device to run the model.
             auto_collate: Apply auto collate.
             **kwargs: The preprocessor kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipe_ins = pipeline('document-grounded-dialog-generate', model='damo/nlp_convai_generate')
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
             config_file=config_file,
             device=device,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,24 +10,24 @@
 import numpy as np
 import torch
 import torch.nn.functional as F
 import transformers
 import ujson as json
 from torch import nn
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import DocumentGroundedDialogRerankModel
-from modelscope.models.nlp.ponet.configuration import PoNetConfig
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import DocumentGroundedDialogRerankPreprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.nlp import DocumentGroundedDialogRerankModel
+from weathon.models.nlp.ponet.configuration import PoNetConfig
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import DocumentGroundedDialogRerankPreprocessor
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['DocumentGroundedDialogRerankPipeline']
 
 
 @PIPELINES.register_module(
@@ -51,15 +51,15 @@
             config_file: Path to config file.
             device: Device to run the model.
             auto_collate: Apply auto collate.
             seed: Random seeds of random parameters.
             **kwargs: The preprocessor kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipe_ins = pipeline('document_grounded_dialog_rerank', model='damo/nlp_convai_rerank')
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
             config_file=config_file,
             device=device,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path
 from typing import Any, Dict, List, Union
 
 import faiss
 import json
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import DocumentGroundedDialogRetrievalModel
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.nlp import DocumentGroundedDialogRetrievalModel
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import \
     DocumentGroundedDialogRetrievalPreprocessor
-from modelscope.utils.constant import ModeKeys, Tasks
+from weathon.utils.constant import ModeKeys, Tasks
 
 __all__ = ['DocumentGroundedDialogRetrievalPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.document_grounded_dialog_retrieval,
     module_name=Pipelines.document_grounded_dialog_retrieval)
@@ -42,15 +41,15 @@
             device: Device to run the model.
             auto_collate: Apply auto collate.
             index_path: Index file path.
             per_gpu_batch_size: Batch size per GPU to run the code.
             **kwargs: The preprocessor kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipe_ins = pipeline('document-grounded-dialog-retrieval', model='damo/nlp_convai_retrieval')
 
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
             config_file=config_file,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/document_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/document_segmentation_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import re
 from typing import Any, Dict, List, Union
 
 import numpy as np
 import torch
 from datasets import Dataset
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import \
     DocumentSegmentationTransformersPreprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['DocumentSegmentationPipeline']
 
 
 @PIPELINES.register_module(
@@ -34,15 +32,15 @@
             device: str = 'gpu',
             auto_collate=True,
             **kwargs):
         """The document segmentation pipeline.
 
         Args:
             model (str or Model): Supply either a local model dir or a model id from the model hub
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
             config_file=config_file,
             device=device,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/extractive_summarization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/extractive_summarization_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import re
 from typing import Any, Dict, List, Union
 
 import numpy as np
 import torch
 from datasets import Dataset
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import \
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import \
     DocumentSegmentationTransformersPreprocessor
-from modelscope.utils.constant import Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ExtractiveSummarizationPipeline']
 
 
 @PIPELINES.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/faq_question_answering_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/faq_question_answering_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['FaqQuestionAnsweringPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.faq_question_answering, module_name=Pipelines.faq_question_answering)
 class FaqQuestionAnsweringPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/fid_dialogue_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/fid_dialogue_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import re
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.models.nlp.fid_T5.text_generation import T5Chat
-from modelscope.outputs import OutputKeys, TokenGeneratorOutput
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.chinese_utils import remove_space_between_chinese_chars
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp.backbone.fid_T5.text_generation import T5Chat
+from weathon.outputs import OutputKeys, TokenGeneratorOutput
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.chinese_utils import remove_space_between_chinese_chars
+from weathon.utils.constants import ModelFile, Tasks
 
 context_template = '{context}'
 history_template = '{context}' \
                    '#{history}'
 knowledge_template = '{context}' \
                      '#{knowledge}'
 user_profile_template = '{context}' \
@@ -40,21 +35,21 @@
                  auto_collate=True,
                  **kwargs):
         """Use `model` and `preprocessor` to create a fid-dialogue pipeline for prediction.
 
         Args:
             model (str or Model): Supply either a local model dir which supported the text generation task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
             Examples:
-                >>> from modelscope.pipelines import pipeline
-                >>> from modelscope.utils.constant import Tasks
+                >>> from weathon.pipelines import pipeline
+                >>> from weathon.utils.constants import Tasks
                 >>> pipeline_ins = pipeline(Tasks.fid_dialogue, model='damo/plug-dialogue', model_revision='v1.0.1')
                 >>> input = {
                 >>>    "history": "[SEP][SEP]",
                 >>>    "bot_profile": ";;;21;20011111",
                 >>>    "knowledge": "70176212,,,[SEP]701762",
                 >>>    "user_profile": ""
                 >>> }
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/fill_mask_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/fill_mask_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Optional, Union
 
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['FillMaskPipeline']
 
 
 @PIPELINES.register_module(Tasks.fill_mask, module_name=Pipelines.fill_mask)
 @PIPELINES.register_module(
     Tasks.fill_mask, module_name=Pipelines.fill_mask_ponet)
@@ -36,22 +34,22 @@
                 or a model id in the model hub.
             preprocessor (`Preprocessor`, `optional`): A Preprocessor instance.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Examples:
 
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> pipeline_ins = pipeline('fill-mask', model='damo/nlp_structbert_fill-mask_english-large')
         >>> input = 'Everything in [MASK] you call reality is really [MASK] a reflection of your [MASK].'
         >>> print(pipeline_ins(input))
 
         Examples:
 
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> pipeline_ins = pipeline('fill-mask', model='damo/nlp_ponet_fill-mask_english-base')
         >>> input = 'Everything in [MASK] you call reality is really [MASK] a reflection of your [MASK].'
         >>> print(pipeline_ins(input))
 
         NOTE2: Please pay attention to the model's special tokens.
         If bert based model(bert, structbert, etc.) is used, the mask token is '[MASK]'.
         If the xlm-roberta(xlm-roberta, veco, etc.) based model is used, the mask token is '<mask>'.
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/glm130b_text_generation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/glm130b_text_generation_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # Copyright (c) 2022 Zhipu.AI
 
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.nlp import GLM130bForTextGeneration
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp import GLM130bForTextGeneration
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
     group_key=Tasks.text_generation,
     module_name=Pipelines.glm130b_text_generation)
 class GLM130bTextGenerationPipeline(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/information_extraction_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/information_extraction_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['InformationExtractionPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.information_extraction, module_name=Pipelines.relation_extraction)
 @PIPELINES.register_module(
@@ -29,15 +27,15 @@
                  sequence_length=512,
                  **kwargs):
         """
 
         Args:
             model (str or Model): Supply either a local model dir which supported information extraction task, or a
             model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/interactive_translation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/interactive_translation_pipeline.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict
 
 import jieba
 import numpy as np
 import tensorflow as tf
 from sacremoses import MosesDetokenizer, MosesPunctNormalizer, MosesTokenizer
 from subword_nmt import apply_bpe
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.nlp.translation_pipeline import TranslationPipeline
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.nlp.translation_pipeline import TranslationPipeline
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
     tf.disable_eager_execution()
 
 logger = get_logger()
 
@@ -36,15 +34,15 @@
         """Build a interactive translation pipeline with a model dir or a model id in the model hub.
 
         Args:
             model (`str` or `Model` or module instance): A model instance or a model local dir
                 or a model id in the model hub.
 
         Example:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline(task=Tasks.translation,
                 model='damo/nlp_imt_translation_zh2en')
             >>> input_sequence = 'Elon Musk, co-founder and chief executive officer of Tesla Motors.'
             >>> input_prefix = ""
             >>> print(pipeline_ins(input_sequence + "<PREFIX_SPLIT>" + input_prefix))
         """
         super().__init__(model=model, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/language_identification_pipline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/language_identification_pipline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,621 +1,613 @@
-00000000: 2320 436f 7079 7269 6768 7420 2863 2920  # Copyright (c) 
-00000010: 416c 6962 6162 612c 2049 6e63 2e20 616e  Alibaba, Inc. an
-00000020: 6420 6974 7320 6166 6669 6c69 6174 6573  d its affiliates
-00000030: 2e0a 0a69 6d70 6f72 7420 6f73 0a69 6d70  ...import os.imp
-00000040: 6f72 7420 6f73 2e70 6174 6820 6173 206f  ort os.path as o
-00000050: 7370 0a69 6d70 6f72 7420 7265 0a66 726f  sp.import re.fro
-00000060: 6d20 7479 7069 6e67 2069 6d70 6f72 7420  m typing import 
-00000070: 416e 792c 2044 6963 740a 0a69 6d70 6f72  Any, Dict..impor
-00000080: 7420 6e75 6d70 7920 6173 206e 700a 696d  t numpy as np.im
-00000090: 706f 7274 2074 656e 736f 7266 6c6f 7720  port tensorflow 
-000000a0: 6173 2074 660a 0a66 726f 6d20 6d6f 6465  as tf..from mode
-000000b0: 6c73 636f 7065 2e6d 6574 6169 6e66 6f20  lscope.metainfo 
-000000c0: 696d 706f 7274 2050 6970 656c 696e 6573  import Pipelines
-000000d0: 0a66 726f 6d20 6d6f 6465 6c73 636f 7065  .from modelscope
-000000e0: 2e6d 6f64 656c 732e 6261 7365 2069 6d70  .models.base imp
-000000f0: 6f72 7420 4d6f 6465 6c0a 6672 6f6d 206d  ort Model.from m
-00000100: 6f64 656c 7363 6f70 652e 6f75 7470 7574  odelscope.output
-00000110: 7320 696d 706f 7274 204f 7574 7075 744b  s import OutputK
-00000120: 6579 730a 6672 6f6d 206d 6f64 656c 7363  eys.from modelsc
-00000130: 6f70 652e 7069 7065 6c69 6e65 732e 6261  ope.pipelines.ba
-00000140: 7365 2069 6d70 6f72 7420 5069 7065 6c69  se import Pipeli
-00000150: 6e65 0a66 726f 6d20 6d6f 6465 6c73 636f  ne.from modelsco
-00000160: 7065 2e70 6970 656c 696e 6573 2e62 7569  pe.pipelines.bui
-00000170: 6c64 6572 2069 6d70 6f72 7420 5049 5045  lder import PIPE
-00000180: 4c49 4e45 530a 6672 6f6d 206d 6f64 656c  LINES.from model
-00000190: 7363 6f70 652e 7574 696c 732e 636f 6e66  scope.utils.conf
-000001a0: 6967 2069 6d70 6f72 7420 436f 6e66 6967  ig import Config
-000001b0: 2c20 436f 6e66 6967 4669 656c 6473 0a66  , ConfigFields.f
-000001c0: 726f 6d20 6d6f 6465 6c73 636f 7065 2e75  rom modelscope.u
-000001d0: 7469 6c73 2e63 6f6e 7374 616e 7420 696d  tils.constant im
-000001e0: 706f 7274 204d 6f64 656c 4669 6c65 2c20  port ModelFile, 
-000001f0: 5461 736b 730a 6672 6f6d 206d 6f64 656c  Tasks.from model
-00000200: 7363 6f70 652e 7574 696c 732e 6c6f 6767  scope.utils.logg
-00000210: 6572 2069 6d70 6f72 7420 6765 745f 6c6f  er import get_lo
-00000220: 6767 6572 0a0a 6966 2074 662e 5f5f 7665  gger..if tf.__ve
-00000230: 7273 696f 6e5f 5f20 3e3d 2027 322e 3027  rsion__ >= '2.0'
-00000240: 3a0a 2020 2020 7466 203d 2074 662e 636f  :.    tf = tf.co
-00000250: 6d70 6174 2e76 310a 2020 2020 7466 2e64  mpat.v1.    tf.d
-00000260: 6973 6162 6c65 5f65 6167 6572 5f65 7865  isable_eager_exe
-00000270: 6375 7469 6f6e 2829 0a0a 6c6f 6767 6572  cution()..logger
-00000280: 203d 2067 6574 5f6c 6f67 6765 7228 290a   = get_logger().
-00000290: 0a5f 5f61 6c6c 5f5f 203d 205b 274c 616e  .__all__ = ['Lan
-000002a0: 6775 6167 6549 6465 6e74 6966 6963 6174  guageIdentificat
-000002b0: 696f 6e50 6970 656c 696e 6527 5d0a 0a0a  ionPipeline']...
-000002c0: 4050 4950 454c 494e 4553 2e72 6567 6973  @PIPELINES.regis
-000002d0: 7465 725f 6d6f 6475 6c65 280a 2020 2020  ter_module(.    
-000002e0: 5461 736b 732e 7465 7874 5f63 6c61 7373  Tasks.text_class
-000002f0: 6966 6963 6174 696f 6e2c 206d 6f64 756c  ification, modul
-00000300: 655f 6e61 6d65 3d50 6970 656c 696e 6573  e_name=Pipelines
-00000310: 2e6c 616e 6775 6167 655f 6964 656e 7469  .language_identi
-00000320: 6669 6361 7469 6f6e 290a 636c 6173 7320  fication).class 
-00000330: 4c61 6e67 7561 6765 4964 656e 7469 6669  LanguageIdentifi
-00000340: 6361 7469 6f6e 5069 7065 6c69 6e65 2850  cationPipeline(P
-00000350: 6970 656c 696e 6529 3a0a 2020 2020 7222  ipeline):.    r"
-00000360: 2222 204c 616e 6775 6167 6520 4964 656e  "" Language Iden
-00000370: 7469 6669 6361 7469 6f6e 2050 6970 656c  tification Pipel
-00000380: 696e 652e 0a0a 2020 2020 4578 616d 706c  ine...    Exampl
-00000390: 6573 3a0a 0a20 2020 203e 3e3e 2066 726f  es:..    >>> fro
-000003a0: 6d20 6d6f 6465 6c73 636f 7065 2e70 6970  m modelscope.pip
-000003b0: 656c 696e 6573 2069 6d70 6f72 7420 7069  elines import pi
-000003c0: 7065 6c69 6e65 0a20 2020 203e 3e3e 2066  peline.    >>> f
-000003d0: 726f 6d20 6d6f 6465 6c73 636f 7065 2e75  rom modelscope.u
-000003e0: 7469 6c73 2e63 6f6e 7374 616e 7420 696d  tils.constant im
-000003f0: 706f 7274 2054 6173 6b73 0a0a 2020 2020  port Tasks..    
-00000400: 3e3e 3e20 7069 7065 6c69 6e65 5f69 6e73  >>> pipeline_ins
-00000410: 203d 2070 6970 656c 696e 6528 5461 736b   = pipeline(Task
-00000420: 732e 7465 7874 5f63 6c61 7373 6966 6963  s.text_classific
-00000430: 6174 696f 6e2c 2027 6461 6d6f 2f6e 6c70  ation, 'damo/nlp
-00000440: 5f6c 616e 6775 6167 655f 6964 656e 7469  _language_identi
-00000450: 6669 6361 7469 6f6e 2d63 6c61 7373 6966  fication-classif
-00000460: 6963 6174 696f 6e2d 6261 7365 2729 0a20  ication-base'). 
-00000470: 2020 203e 3e3e 2070 6970 656c 696e 655f     >>> pipeline_
-00000480: 696e 7328 2745 6c6f 6e20 4d75 736b 2c20  ins('Elon Musk, 
-00000490: 636f 2d66 6f75 6e64 6572 2061 6e64 2063  co-founder and c
-000004a0: 6869 6566 2065 7865 6375 7469 7665 206f  hief executive o
-000004b0: 6666 6963 6572 206f 6620 5465 736c 6120  fficer of Tesla 
-000004c0: 4d6f 746f 7273 2e5c 6e27 205c 0a20 2020  Motors.\n' \.   
-000004d0: 203e 3e3e 2020 2020 2020 2020 2020 2020   >>>            
-000004e0: 2020 2747 6c65 6963 687a 6569 7469 6720    'Gleichzeitig 
-000004f0: 6e61 686d 2064 6965 204c 6567 696f 6e20  nahm die Legion 
-00000500: 616e 2064 6572 2042 6566 7269 6564 756e  an der Befriedun
-00000510: 6720 416c 6765 7269 656e 7320 7465 696c  g Algeriens teil
-00000520: 2c20 6469 6520 766f 6e2e 5c6e 2720 5c0a  , die von.\n' \.
-00000530: 2020 2020 3e3e 3e20 2020 2020 2020 2020      >>>         
-00000540: 2020 2020 2027 e4bd bfe7 94a8 7069 7065       '......pipe
-00000550: 6c69 6e65 e68e a8e7 9086 e58f 8ae5 9ca8  line............
-00000560: e7ba bfe4 bd93 e9aa 8ce5 8a9f e883 bde7  ................
-00000570: 9a84 e697 b6e5 8099 efbc 8ce5 b0bd e987  ................
-00000580: 8fe8 be93 e585 a5e5 8d95 e58f a5e6 9687  ................
-00000590: e69c acef bc8c e5a6 82e6 9e9c e698 afe5  ................
-000005a0: a49a e58f a5e9 95bf e696 87e6 9cac e5bb  ................
-000005b0: bae8 aeae e4ba bae5 b7a5 e588 86e5 8fa5  ................
-000005c0: e380 8227 0a0a 2020 2020 3e3e 3e20 7b0a  ...'..    >>> {.
-000005d0: 2020 2020 3e3e 3e20 2020 2022 6c61 6265      >>>    "labe
-000005e0: 6c73 223a 5b0a 2020 2020 3e3e 3e20 2020  ls":[.    >>>   
-000005f0: 2020 2020 2022 656e 222c 0a20 2020 203e       "en",.    >
-00000600: 3e3e 2020 2020 2020 2020 2264 6522 2c0a  >>        "de",.
-00000610: 2020 2020 3e3e 3e20 2020 2020 2020 2022      >>>        "
-00000620: 7a68 220a 2020 2020 3e3e 3e20 2020 205d  zh".    >>>    ]
-00000630: 2c0a 2020 2020 3e3e 3e20 2020 2022 7363  ,.    >>>    "sc
-00000640: 6f72 6573 223a 5b0a 2020 2020 3e3e 3e20  ores":[.    >>> 
-00000650: 2020 2020 2020 205b 2827 656e 272c 2030         [('en', 0
-00000660: 2e39 3929 5d2c 0a20 2020 203e 3e3e 2020  .99)],.    >>>  
-00000670: 2020 2020 2020 5b28 2764 6527 2c20 312e        [('de', 1.
-00000680: 3029 5d2c 0a20 2020 203e 3e3e 2020 2020  0)],.    >>>    
-00000690: 2020 2020 5b28 277a 6827 2c20 312e 3029      [('zh', 1.0)
-000006a0: 5d0a 2020 2020 3e3e 3e20 2020 205d 0a20  ].    >>>    ]. 
-000006b0: 2020 203e 3e3e 207d 0a20 2020 2022 2222     >>> }.    """
-000006c0: 0a0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
-000006d0: 5f5f 2873 656c 662c 206d 6f64 656c 3a20  __(self, model: 
-000006e0: 7374 722c 202a 2a6b 7761 7267 7329 3a0a  str, **kwargs):.
-000006f0: 2020 2020 2020 2020 2222 2242 7569 6c64          """Build
-00000700: 2061 206c 616e 6775 6167 6520 6964 656e   a language iden
-00000710: 7469 6669 6361 7469 6f6e 2070 6970 656c  tification pipel
-00000720: 696e 6520 7769 7468 2061 206d 6f64 656c  ine with a model
-00000730: 2064 6972 206f 7220 6120 6d6f 6465 6c20   dir or a model 
-00000740: 6964 2069 6e20 7468 6520 6d6f 6465 6c20  id in the model 
-00000750: 6875 622e 0a0a 2020 2020 2020 2020 4172  hub...        Ar
-00000760: 6773 3a0a 2020 2020 2020 2020 2020 2020  gs:.            
-00000770: 6d6f 6465 6c3a 2041 204d 6f64 656c 2069  model: A Model i
-00000780: 6e73 7461 6e63 652e 0a20 2020 2020 2020  nstance..       
-00000790: 2022 2222 0a20 2020 2020 2020 2073 7570   """.        sup
-000007a0: 6572 2829 2e5f 5f69 6e69 745f 5f28 6d6f  er().__init__(mo
-000007b0: 6465 6c3d 6d6f 6465 6c2c 202a 2a6b 7761  del=model, **kwa
-000007c0: 7267 7329 0a20 2020 2020 2020 2065 7870  rgs).        exp
-000007d0: 6f72 745f 6469 7220 3d20 6d6f 6465 6c0a  ort_dir = model.
-000007e0: 2020 2020 2020 2020 7365 6c66 2e64 6562          self.deb
-000007f0: 7567 203d 2046 616c 7365 0a0a 2020 2020  ug = False..    
-00000800: 2020 2020 7365 6c66 2e63 6667 203d 2043      self.cfg = C
-00000810: 6f6e 6669 672e 6672 6f6d 5f66 696c 6528  onfig.from_file(
-00000820: 0a20 2020 2020 2020 2020 2020 206f 732e  .            os.
-00000830: 7061 7468 2e6a 6f69 6e28 6578 706f 7274  path.join(export
-00000840: 5f64 6972 2c20 4d6f 6465 6c46 696c 652e  _dir, ModelFile.
-00000850: 434f 4e46 4947 5552 4154 494f 4e29 290a  CONFIGURATION)).
-00000860: 0a20 2020 2020 2020 206a 6f69 6e74 5f76  .        joint_v
-00000870: 6f63 6162 5f66 696c 6520 3d20 6f73 2e70  ocab_file = os.p
-00000880: 6174 682e 6a6f 696e 280a 2020 2020 2020  ath.join(.      
-00000890: 2020 2020 2020 6578 706f 7274 5f64 6972        export_dir
-000008a0: 2c20 7365 6c66 2e63 6667 5b43 6f6e 6669  , self.cfg[Confi
-000008b0: 6746 6965 6c64 732e 7072 6570 726f 6365  gFields.preproce
-000008c0: 7373 6f72 5d5b 2776 6f63 6162 275d 290a  ssor]['vocab']).
-000008d0: 2020 2020 2020 2020 766f 6361 6266 696c          vocabfil
-000008e0: 6573 203d 205b 5d0a 2020 2020 2020 2020  es = [].        
-000008f0: 766f 6361 6266 696c 6573 5f72 6576 6572  vocabfiles_rever
-00000900: 7365 203d 205b 5d0a 2020 2020 2020 2020  se = [].        
-00000910: 666f 7220 692c 2077 2069 6e20 656e 756d  for i, w in enum
-00000920: 6572 6174 6528 6f70 656e 286a 6f69 6e74  erate(open(joint
-00000930: 5f76 6f63 6162 5f66 696c 652c 2027 7262  _vocab_file, 'rb
-00000940: 2729 293a 0a20 2020 2020 2020 2020 2020  ')):.           
-00000950: 2077 203d 2077 2e73 7472 6970 2829 0a20   w = w.strip(). 
-00000960: 2020 2020 2020 2020 2020 2074 7279 3a0a             try:.
-00000970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000980: 7720 3d20 772e 6465 636f 6465 2827 7574  w = w.decode('ut
-00000990: 662d 3827 290a 2020 2020 2020 2020 2020  f-8').          
-000009a0: 2020 2020 2020 766f 6361 6266 696c 6573        vocabfiles
-000009b0: 2e61 7070 656e 6428 2877 2c20 6929 290a  .append((w, i)).
-000009c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000009d0: 766f 6361 6266 696c 6573 5f72 6576 6572  vocabfiles_rever
-000009e0: 7365 2e61 7070 656e 6428 2869 2c20 7729  se.append((i, w)
-000009f0: 290a 2020 2020 2020 2020 2020 2020 6578  ).            ex
-00000a00: 6365 7074 2055 6e69 636f 6465 4465 636f  cept UnicodeDeco
-00000a10: 6465 4572 726f 723a 0a20 2020 2020 2020  deError:.       
-00000a20: 2020 2020 2020 2020 2023 205b 6465 6275           # [debu
-00000a30: 675d 2070 7269 6e74 2065 7272 6f72 2069  g] print error i
-00000a40: 6e66 6f0a 2020 2020 2020 2020 2020 2020  nfo.            
-00000a50: 2020 2020 6966 2073 656c 662e 6465 6275      if self.debu
-00000a60: 673a 0a20 2020 2020 2020 2020 2020 2020  g:.             
-00000a70: 2020 2020 2020 2070 7269 6e74 2827 6572         print('er
-00000a80: 726f 7220 766f 6361 623a 272c 2077 2c20  ror vocab:', w, 
-00000a90: 6929 0a20 2020 2020 2020 2020 2020 2020  i).             
-00000aa0: 2020 2070 6173 730a 2020 2020 2020 2020     pass.        
-00000ab0: 7365 6c66 2e76 6f63 6162 203d 2064 6963  self.vocab = dic
-00000ac0: 7428 766f 6361 6266 696c 6573 290a 2020  t(vocabfiles).  
-00000ad0: 2020 2020 2020 7365 6c66 2e76 6f63 6162        self.vocab
-00000ae0: 5f72 6576 6572 7365 203d 2064 6963 7428  _reverse = dict(
-00000af0: 766f 6361 6266 696c 6573 5f72 6576 6572  vocabfiles_rever
-00000b00: 7365 290a 2020 2020 2020 2020 7365 6c66  se).        self
-00000b10: 2e75 6e6b 5f69 6420 3d20 7365 6c66 2e76  .unk_id = self.v
-00000b20: 6f63 6162 2e67 6574 2827 3c55 4e4b 3e27  ocab.get('<UNK>'
-00000b30: 2c20 3129 0a20 2020 2020 2020 2073 656c  , 1).        sel
-00000b40: 662e 7061 645f 6964 203d 2073 656c 662e  f.pad_id = self.
-00000b50: 766f 6361 622e 6765 7428 273c 2f53 3e27  vocab.get('</S>'
-00000b60: 2c20 3029 0a0a 2020 2020 2020 2020 6a6f  , 0)..        jo
-00000b70: 696e 745f 6c61 6265 6c5f 6669 6c65 203d  int_label_file =
-00000b80: 206f 732e 7061 7468 2e6a 6f69 6e28 0a20   os.path.join(. 
-00000b90: 2020 2020 2020 2020 2020 2065 7870 6f72             expor
-00000ba0: 745f 6469 722c 2073 656c 662e 6366 675b  t_dir, self.cfg[
-00000bb0: 436f 6e66 6967 4669 656c 6473 2e70 7265  ConfigFields.pre
-00000bc0: 7072 6f63 6573 736f 725d 5b27 6c61 6265  processor]['labe
-00000bd0: 6c27 5d29 0a20 2020 2020 2020 2073 656c  l']).        sel
-00000be0: 662e 6c61 6265 6c20 3d20 6469 6374 285b  f.label = dict([
-00000bf0: 2869 2c20 772e 7374 7269 7028 2929 2066  (i, w.strip()) f
-00000c00: 6f72 2069 2c20 7720 696e 2065 6e75 6d65  or i, w in enume
-00000c10: 7261 7465 280a 2020 2020 2020 2020 2020  rate(.          
-00000c20: 2020 6f70 656e 286a 6f69 6e74 5f6c 6162    open(joint_lab
-00000c30: 656c 5f66 696c 652c 2027 7227 2c20 656e  el_file, 'r', en
-00000c40: 636f 6469 6e67 3d27 7574 6638 2729 295d  coding='utf8'))]
-00000c50: 290a 2020 2020 2020 2020 7365 6c66 2e75  ).        self.u
-00000c60: 6e6b 5f6c 6162 656c 203d 2027 756e 6b27  nk_label = 'unk'
-00000c70: 0a0a 2020 2020 2020 2020 7466 2e72 6573  ..        tf.res
-00000c80: 6574 5f64 6566 6175 6c74 5f67 7261 7068  et_default_graph
-00000c90: 2829 0a20 2020 2020 2020 2074 665f 636f  ().        tf_co
-00000ca0: 6e66 6967 203d 2074 662e 436f 6e66 6967  nfig = tf.Config
-00000cb0: 5072 6f74 6f28 616c 6c6f 775f 736f 6674  Proto(allow_soft
-00000cc0: 5f70 6c61 6365 6d65 6e74 3d54 7275 6529  _placement=True)
-00000cd0: 0a20 2020 2020 2020 2074 665f 636f 6e66  .        tf_conf
-00000ce0: 6967 2e67 7075 5f6f 7074 696f 6e73 2e61  ig.gpu_options.a
-00000cf0: 6c6c 6f77 5f67 726f 7774 6820 3d20 5472  llow_growth = Tr
-00000d00: 7565 0a20 2020 2020 2020 2073 656c 662e  ue.        self.
-00000d10: 5f73 6573 7369 6f6e 203d 2074 662e 5365  _session = tf.Se
-00000d20: 7373 696f 6e28 636f 6e66 6967 3d74 665f  ssion(config=tf_
-00000d30: 636f 6e66 6967 290a 2020 2020 2020 2020  config).        
-00000d40: 7466 2e73 6176 6564 5f6d 6f64 656c 2e6c  tf.saved_model.l
-00000d50: 6f61 6465 722e 6c6f 6164 280a 2020 2020  oader.load(.    
-00000d60: 2020 2020 2020 2020 7365 6c66 2e5f 7365          self._se
-00000d70: 7373 696f 6e2c 205b 7466 2e70 7974 686f  ssion, [tf.pytho
-00000d80: 6e2e 7361 7665 645f 6d6f 6465 6c2e 7461  n.saved_model.ta
-00000d90: 675f 636f 6e73 7461 6e74 732e 5345 5256  g_constants.SERV
-00000da0: 494e 475d 2c0a 2020 2020 2020 2020 2020  ING],.          
-00000db0: 2020 6578 706f 7274 5f64 6972 290a 2020    export_dir).  
-00000dc0: 2020 2020 2020 6465 6661 756c 745f 6772        default_gr
-00000dd0: 6170 6820 3d20 7466 2e67 6574 5f64 6566  aph = tf.get_def
-00000de0: 6175 6c74 5f67 7261 7068 2829 0a20 2020  ault_graph().   
-00000df0: 2020 2020 2023 205b 6465 6275 675d 2070       # [debug] p
-00000e00: 7269 6e74 2067 7261 7068 206f 7073 0a20  rint graph ops. 
-00000e10: 2020 2020 2020 2069 6620 7365 6c66 2e64         if self.d
-00000e20: 6562 7567 3a0a 2020 2020 2020 2020 2020  ebug:.          
-00000e30: 2020 666f 7220 6f70 2069 6e20 6465 6661    for op in defa
-00000e40: 756c 745f 6772 6170 682e 6765 745f 6f70  ult_graph.get_op
-00000e50: 6572 6174 696f 6e73 2829 3a0a 2020 2020  erations():.    
-00000e60: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-00000e70: 7428 6f70 2e6e 616d 652c 206f 702e 7661  t(op.name, op.va
-00000e80: 6c75 6573 2829 290a 0a20 2020 2020 2020  lues())..       
-00000e90: 2073 656c 662e 696e 7075 745f 6964 7320   self.input_ids 
-00000ea0: 3d20 6465 6661 756c 745f 6772 6170 682e  = default_graph.
-00000eb0: 6765 745f 7465 6e73 6f72 5f62 795f 6e61  get_tensor_by_na
-00000ec0: 6d65 2827 7372 635f 6369 643a 3027 290a  me('src_cid:0').
-00000ed0: 2020 2020 2020 2020 6f75 7470 7574 5f6c          output_l
-00000ee0: 6162 656c 203d 2064 6566 6175 6c74 5f67  abel = default_g
-00000ef0: 7261 7068 2e67 6574 5f74 656e 736f 725f  raph.get_tensor_
-00000f00: 6279 5f6e 616d 6528 276f 7574 7075 745f  by_name('output_
-00000f10: 6c61 6265 6c3a 3027 290a 2020 2020 2020  label:0').      
-00000f20: 2020 6f75 7470 7574 5f73 636f 7265 203d    output_score =
-00000f30: 2064 6566 6175 6c74 5f67 7261 7068 2e67   default_graph.g
-00000f40: 6574 5f74 656e 736f 725f 6279 5f6e 616d  et_tensor_by_nam
-00000f50: 6528 2770 7265 6469 6374 5f73 636f 7265  e('predict_score
-00000f60: 3a30 2729 0a0a 2020 2020 2020 2020 7365  :0')..        se
-00000f70: 6c66 2e6f 7574 7075 7420 3d20 7b0a 2020  lf.output = {.  
-00000f80: 2020 2020 2020 2020 2020 276f 7574 7075            'outpu
-00000f90: 745f 6964 7327 3a20 6f75 7470 7574 5f6c  t_ids': output_l
-00000fa0: 6162 656c 2c0a 2020 2020 2020 2020 2020  abel,.          
-00000fb0: 2020 276f 7574 7075 745f 7363 6f72 6527    'output_score'
-00000fc0: 3a20 6f75 7470 7574 5f73 636f 7265 0a20  : output_score. 
-00000fd0: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
-00000fe0: 2069 6e69 7420 3d20 7466 2e67 6c6f 6261   init = tf.globa
-00000ff0: 6c5f 7661 7269 6162 6c65 735f 696e 6974  l_variables_init
-00001000: 6961 6c69 7a65 7228 290a 2020 2020 2020  ializer().      
-00001010: 2020 6c6f 6361 6c5f 696e 6974 203d 2074    local_init = t
-00001020: 662e 6c6f 6361 6c5f 7661 7269 6162 6c65  f.local_variable
-00001030: 735f 696e 6974 6961 6c69 7a65 7228 290a  s_initializer().
-00001040: 2020 2020 2020 2020 7365 6c66 2e5f 7365          self._se
-00001050: 7373 696f 6e2e 7275 6e28 5b69 6e69 742c  ssion.run([init,
-00001060: 206c 6f63 616c 5f69 6e69 745d 290a 2020   local_init]).  
-00001070: 2020 2020 2020 7466 2e73 6176 6564 5f6d        tf.saved_m
-00001080: 6f64 656c 2e6c 6f61 6465 722e 6c6f 6164  odel.loader.load
-00001090: 280a 2020 2020 2020 2020 2020 2020 7365  (.            se
-000010a0: 6c66 2e5f 7365 7373 696f 6e2c 205b 7466  lf._session, [tf
-000010b0: 2e70 7974 686f 6e2e 7361 7665 645f 6d6f  .python.saved_mo
-000010c0: 6465 6c2e 7461 675f 636f 6e73 7461 6e74  del.tag_constant
-000010d0: 732e 5345 5256 494e 475d 2c0a 2020 2020  s.SERVING],.    
-000010e0: 2020 2020 2020 2020 6578 706f 7274 5f64          export_d
-000010f0: 6972 290a 0a20 2020 2064 6566 205f 6c69  ir)..    def _li
-00001100: 645f 7072 6570 726f 6365 7373 2873 656c  d_preprocess(sel
-00001110: 662c 2069 6e70 7574 3a20 7374 7229 202d  f, input: str) -
-00001120: 3e20 6c69 7374 3a0a 2020 2020 2020 2020  > list:.        
-00001130: 7365 6e74 656e 6365 203d 2069 6e70 7574  sentence = input
-00001140: 2e6c 6f77 6572 2829 0a20 2020 2020 2020  .lower().       
-00001150: 2023 2048 746d 6c54 6f54 6578 740a 2020   # HtmlToText.  
-00001160: 2020 2020 2020 434c 4541 4e52 203d 2072        CLEANR = r
-00001170: 273c 2e2a 3f3e 7c26 285b 612d 7a30 2d39  '<.*?>|&([a-z0-9
-00001180: 5d2b 7c23 5b30 2d39 5d7b 312c 367d 7c23  ]+|#[0-9]{1,6}|#
-00001190: 785b 302d 3961 2d66 5d7b 312c 367d 293b  x[0-9a-f]{1,6});
-000011a0: 270a 2020 2020 2020 2020 7365 6e74 656e  '.        senten
-000011b0: 6365 203d 2072 652e 7375 6228 434c 4541  ce = re.sub(CLEA
-000011c0: 4e52 2c20 2727 2c20 7365 6e74 656e 6365  NR, '', sentence
-000011d0: 290a 2020 2020 2020 2020 2320 5265 6d6f  ).        # Remo
-000011e0: 7665 4c69 6e6b 730a 2020 2020 2020 2020  veLinks.        
-000011f0: 5552 4c52 4520 3d20 7227 5c53 2b5b 2e2f  URLRE = r'\S+[./
-00001200: 5d5c 532b 5c73 3f27 0a20 2020 2020 2020  ]\S+\s?'.       
-00001210: 2073 656e 7465 6e63 6520 3d20 7265 2e73   sentence = re.s
-00001220: 7562 2855 524c 5245 2c20 2727 2c20 7365  ub(URLRE, '', se
-00001230: 6e74 656e 6365 290a 2020 2020 2020 2020  ntence).        
-00001240: 454d 4149 4c52 4520 3d20 7227 5c53 2a40  EMAILRE = r'\S*@
-00001250: 5c53 2a5c 733f 270a 2020 2020 2020 2020  \S*\s?'.        
-00001260: 7365 6e74 656e 6365 203d 2072 652e 7375  sentence = re.su
-00001270: 6228 454d 4149 4c52 452c 2027 272c 2073  b(EMAILRE, '', s
-00001280: 656e 7465 6e63 6529 0a0a 2020 2020 2020  entence)..      
-00001290: 2020 2320 5342 4332 4442 430a 2020 2020    # SBC2DBC.    
-000012a0: 2020 2020 6465 6620 7374 7269 6e67 7061      def stringpa
-000012b0: 7274 5132 4228 7563 6861 7229 3a0a 2020  rtQ2B(uchar):.  
-000012c0: 2020 2020 2020 2020 2020 696e 7369 6465            inside
-000012d0: 5f63 6f64 6520 3d20 6f72 6428 7563 6861  _code = ord(ucha
-000012e0: 7229 0a20 2020 2020 2020 2020 2020 2069  r).            i
-000012f0: 6620 3078 4646 3030 203c 2069 6e73 6964  f 0xFF00 < insid
-00001300: 655f 636f 6465 206f 7220 696e 7369 6465  e_code or inside
-00001310: 5f63 6f64 6520 3e20 3078 4646 3546 3a0a  _code > 0xFF5F:.
-00001320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001330: 696e 7369 6465 5f63 6f64 6520 2d3d 2030  inside_code -= 0
-00001340: 7846 4545 300a 2020 2020 2020 2020 2020  xFEE0.          
-00001350: 2020 656c 6966 2069 6e73 6964 655f 636f    elif inside_co
-00001360: 6465 203d 3d20 3078 3330 3030 3a0a 2020  de == 0x3000:.  
-00001370: 2020 2020 2020 2020 2020 2020 2020 696e                in
-00001380: 7369 6465 5f63 6f64 6520 3d20 3078 3030  side_code = 0x00
-00001390: 3230 0a20 2020 2020 2020 2020 2020 2065  20.            e
-000013a0: 6c69 6620 696e 7369 6465 5f63 6f64 6520  lif inside_code 
-000013b0: 696e 205b 0a20 2020 2020 2020 2020 2020  in [.           
-000013c0: 2020 2020 2020 2020 2030 7833 3031 442c           0x301D,
-000013d0: 2030 7833 3031 452c 2030 7832 3031 432c   0x301E, 0x201C,
-000013e0: 2030 7832 3031 442c 2030 7832 3031 452c   0x201D, 0x201E,
-000013f0: 2030 7832 3031 460a 2020 2020 2020 2020   0x201F.        
-00001400: 2020 2020 5d3a 0a20 2020 2020 2020 2020      ]:.         
-00001410: 2020 2020 2020 2069 6e73 6964 655f 636f         inside_co
-00001420: 6465 203d 2030 7830 3032 320a 2020 2020  de = 0x0022.    
-00001430: 2020 2020 2020 2020 656c 6966 2069 6e73          elif ins
-00001440: 6964 655f 636f 6465 2069 6e20 5b30 7832  ide_code in [0x2
-00001450: 3031 382c 2030 7832 3031 392c 2030 7832  018, 0x2019, 0x2
-00001460: 3031 412c 2030 7832 3031 425d 3a0a 2020  01A, 0x201B]:.  
-00001470: 2020 2020 2020 2020 2020 2020 2020 696e                in
-00001480: 7369 6465 5f63 6f64 6520 3d20 3078 3030  side_code = 0x00
-00001490: 3237 0a20 2020 2020 2020 2020 2020 2072  27.            r
-000014a0: 6574 7572 6e20 6368 7228 696e 7369 6465  eturn chr(inside
-000014b0: 5f63 6f64 6529 0a0a 2020 2020 2020 2020  _code)..        
-000014c0: 2320 5265 6d6f 7665 4e6f 6973 7943 6861  # RemoveNoisyCha
-000014d0: 7273 0a20 2020 2020 2020 206d 5f6e 6f69  rs.        m_noi
-000014e0: 7379 4368 6172 7320 3d20 2201 0203 0405  syChars = ".....
-000014f0: 0607 0814 122c 2d2b 5c22 5c27 5c5c 262e  .....,-+\"\'\\&.
-00001500: 213d 3a3b c2b0 c2b7 24c2 abc2 bb7c c2b1  !=:;....$....|..
-00001510: 5b5d 7b7d 5f3f 3c3e 7e5e 2a2f 2523 4028  []{}_?<>~^*/%#@(
-00001520: 29ef bc8c e380 82ef bc81 e380 8ae3 808b  )...............
-00001530: efbc 9fe3 8081 605c 7863 325c 7861 30e2  ......`\xc2\xa0.
-00001540: 80a6 e280 bcef b88f 220a 2020 2020 2020  ........".      
-00001550: 2020 7365 6e74 656e 6365 203d 2027 272e    sentence = ''.
-00001560: 6a6f 696e 285b 0a20 2020 2020 2020 2020  join([.         
-00001570: 2020 2073 7472 696e 6770 6172 7451 3242     stringpartQ2B
-00001580: 2863 2920 6966 2063 206e 6f74 2069 6e20  (c) if c not in 
-00001590: 6d5f 6e6f 6973 7943 6861 7273 2065 6c73  m_noisyChars els
-000015a0: 6520 2720 270a 2020 2020 2020 2020 2020  e ' '.          
-000015b0: 2020 666f 7220 6320 696e 2073 656e 7465    for c in sente
-000015c0: 6e63 650a 2020 2020 2020 2020 5d29 0a20  nce.        ]). 
-000015d0: 2020 2020 2020 2045 4d4f 4a49 5245 203d         EMOJIRE =
-000015e0: 2072 652e 636f 6d70 696c 6528 0a20 2020   re.compile(.   
-000015f0: 2020 2020 2020 2020 2027 5b27 0a20 2020           '['.   
-00001600: 2020 2020 2020 2020 2075 275c 5530 3030           u'\U000
-00001610: 3146 3630 302d 5c55 3030 3031 4636 3446  1F600-\U0001F64F
-00001620: 2720 2023 2065 6d6f 7469 636f 6e73 0a20  '  # emoticons. 
-00001630: 2020 2020 2020 2020 2020 2075 275c 5530             u'\U0
-00001640: 3030 3146 3330 302d 5c55 3030 3031 4635  001F300-\U0001F5
-00001650: 4646 2720 2023 2073 796d 626f 6c73 2026  FF'  # symbols &
-00001660: 2070 6963 746f 6772 6170 6873 0a20 2020   pictographs.   
-00001670: 2020 2020 2020 2020 2075 275c 5530 3030           u'\U000
-00001680: 3146 3638 302d 5c55 3030 3031 4636 4646  1F680-\U0001F6FF
-00001690: 2720 2023 2074 7261 6e73 706f 7274 2026  '  # transport &
-000016a0: 206d 6170 2073 796d 626f 6c73 0a20 2020   map symbols.   
-000016b0: 2020 2020 2020 2020 2075 275c 5530 3030           u'\U000
-000016c0: 3146 3145 302d 5c55 3030 3031 4631 4646  1F1E0-\U0001F1FF
-000016d0: 2720 2023 2066 6c61 6773 2028 694f 5329  '  # flags (iOS)
-000016e0: 0a20 2020 2020 2020 2020 2020 2075 275c  .            u'\
-000016f0: 5530 3030 3166 3932 362d 5c55 3030 3031  U0001f926-\U0001
-00001700: 6639 3337 2720 2023 2065 6d6f 6a69 0a20  f937'  # emoji. 
-00001710: 2020 2020 2020 2020 2020 2075 275c 5530             u'\U0
-00001720: 3030 3130 3030 302d 5c55 3030 3130 6666  0010000-\U0010ff
-00001730: 6666 2720 2023 2063 6861 7220 656d 6f6a  ff'  # char emoj
-00001740: 690a 2020 2020 2020 2020 2020 2020 7527  i.            u'
-00001750: 5c55 3030 3030 3237 3032 2d5c 5530 3030  \U00002702-\U000
-00001760: 3032 3742 3027 2020 2320 6368 6172 2065  027B0'  # char e
-00001770: 6d6f 6a69 0a20 2020 2020 2020 2020 2020  moji.           
-00001780: 2075 275c 7532 3634 302d 5c75 3236 3432   u'\u2640-\u2642
-00001790: 5c75 3236 3030 2d5c 7532 4235 3527 0a20  \u2600-\u2B55'. 
-000017a0: 2020 2020 2020 2020 2020 2075 275c 7532             u'\u2
-000017b0: 3030 645c 7532 3363 665c 7532 3365 395c  00d\u23cf\u23e9\
-000017c0: 7532 3331 615c 7566 6530 665c 7533 3033  u231a\ufe0f\u303
-000017d0: 3027 2020 2320 6469 6e67 6261 7473 0a20  0'  # dingbats. 
-000017e0: 2020 2020 2020 2020 2020 2027 5d2b 272c             ']+',
-000017f0: 0a20 2020 2020 2020 2020 2020 2072 652e  .            re.
-00001800: 554e 4943 4f44 4529 0a20 2020 2020 2020  UNICODE).       
-00001810: 2073 656e 7465 6e63 6520 3d20 7265 2e73   sentence = re.s
-00001820: 7562 2845 4d4f 4a49 5245 2c20 2727 2c20  ub(EMOJIRE, '', 
-00001830: 7365 6e74 656e 6365 290a 2020 2020 2020  sentence).      
-00001840: 2020 2320 5265 6d6f 7665 4469 6769 7461    # RemoveDigita
-00001850: 6c57 6f72 6473 0a20 2020 2020 2020 2073  lWords.        s
-00001860: 656e 7465 6e63 6520 3d20 2720 272e 6a6f  entence = ' '.jo
-00001870: 696e 285b 0a20 2020 2020 2020 2020 2020  in([.           
-00001880: 2069 7465 6d20 666f 7220 6974 656d 2069   item for item i
-00001890: 6e20 7365 6e74 656e 6365 2e73 706c 6974  n sentence.split
-000018a0: 2829 0a20 2020 2020 2020 2020 2020 2069  ().            i
-000018b0: 6620 286e 6f74 2062 6f6f 6c28 7265 2e73  f (not bool(re.s
-000018c0: 6561 7263 6828 7227 5c64 272c 2069 7465  earch(r'\d', ite
-000018d0: 6d29 290a 2020 2020 2020 2020 2020 2020  m)).            
-000018e0: 2020 2020 6f72 206e 6f74 2062 6f6f 6c28      or not bool(
-000018f0: 7265 2e6d 6174 6368 2872 275e 5b61 2d7a  re.match(r'^[a-z
-00001900: 302d 392b 2d5f 5d2b 2427 2c20 6974 656d  0-9+-_]+$', item
-00001910: 2929 290a 2020 2020 2020 2020 5d29 0a20  ))).        ]). 
-00001920: 2020 2020 2020 2023 2072 6570 6c61 6365         # replace
-00001930: 4272 616e 6457 6f72 6473 0a20 2020 2020  BrandWords.     
-00001940: 2020 2023 2077 6f72 6443 6f72 7265 6374     # wordCorrect
-00001950: 696f 6e0a 2020 2020 2020 2020 2320 7265  ion.        # re
-00001960: 6d6f 7665 5370 6163 6573 0a20 2020 2020  moveSpaces.     
-00001970: 2020 206f 7574 6964 7320 3d20 5b5d 0a20     outids = []. 
-00001980: 2020 2020 2020 2066 6f72 2077 2069 6e20         for w in 
-00001990: 7365 6e74 656e 6365 2e73 7472 6970 2829  sentence.strip()
-000019a0: 3a0a 2020 2020 2020 2020 2020 2020 746d  :.            tm
-000019b0: 7020 3d20 7365 6c66 2e76 6f63 6162 2e67  p = self.vocab.g
-000019c0: 6574 2877 2c20 7365 6c66 2e75 6e6b 5f69  et(w, self.unk_i
-000019d0: 6429 0a20 2020 2020 2020 2020 2020 2069  d).            i
-000019e0: 6620 6c65 6e28 6f75 7469 6473 0a20 2020  f len(outids.   
-000019f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001a00: 2920 3e20 3020 616e 6420 746d 7020 3d3d  ) > 0 and tmp ==
-00001a10: 2073 656c 662e 756e 6b5f 6964 2061 6e64   self.unk_id and
-00001a20: 206f 7574 6964 735b 2d31 5d20 3d3d 2073   outids[-1] == s
-00001a30: 656c 662e 756e 6b5f 6964 3a0a 2020 2020  elf.unk_id:.    
-00001a40: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-00001a50: 696e 7565 0a20 2020 2020 2020 2020 2020  inue.           
-00001a60: 206f 7574 6964 732e 6170 7065 6e64 2874   outids.append(t
-00001a70: 6d70 290a 2020 2020 2020 2020 6966 206c  mp).        if l
-00001a80: 656e 286f 7574 6964 7329 203e 2030 2061  en(outids) > 0 a
-00001a90: 6e64 206f 7574 6964 735b 305d 203d 3d20  nd outids[0] == 
-00001aa0: 7365 6c66 2e75 6e6b 5f69 643a 0a20 2020  self.unk_id:.   
-00001ab0: 2020 2020 2020 2020 206f 7574 6964 7320           outids 
-00001ac0: 3d20 6f75 7469 6473 5b31 3a5d 0a20 2020  = outids[1:].   
-00001ad0: 2020 2020 2069 6620 6c65 6e28 6f75 7469       if len(outi
-00001ae0: 6473 2920 3e20 3020 616e 6420 6f75 7469  ds) > 0 and outi
-00001af0: 6473 5b2d 315d 203d 3d20 7365 6c66 2e75  ds[-1] == self.u
-00001b00: 6e6b 5f69 643a 0a20 2020 2020 2020 2020  nk_id:.         
-00001b10: 2020 206f 7574 6964 7320 3d20 6f75 7469     outids = outi
-00001b20: 6473 5b3a 2d31 5d0a 2020 2020 2020 2020  ds[:-1].        
-00001b30: 7265 7475 726e 206f 7574 6964 730a 0a20  return outids.. 
-00001b40: 2020 2064 6566 2070 7265 7072 6f63 6573     def preproces
-00001b50: 7328 7365 6c66 2c20 696e 7075 743a 2073  s(self, input: s
-00001b60: 7472 2920 2d3e 2044 6963 745b 7374 722c  tr) -> Dict[str,
-00001b70: 2041 6e79 5d3a 0a20 2020 2020 2020 2073   Any]:.        s
-00001b80: 656e 7465 6e63 656c 7420 3d20 696e 7075  entencelt = inpu
-00001b90: 742e 7370 6c69 7428 275c 6e27 290a 2020  t.split('\n').  
-00001ba0: 2020 2020 2020 696e 7075 745f 6964 735f        input_ids_
-00001bb0: 6c74 203d 205b 0a20 2020 2020 2020 2020  lt = [.         
-00001bc0: 2020 2073 656c 662e 5f6c 6964 5f70 7265     self._lid_pre
-00001bd0: 7072 6f63 6573 7328 7365 6e74 656e 6365  process(sentence
-00001be0: 2920 666f 7220 7365 6e74 656e 6365 2069  ) for sentence i
-00001bf0: 6e20 7365 6e74 656e 6365 6c74 0a20 2020  n sentencelt.   
-00001c00: 2020 2020 2020 2020 2069 6620 7365 6e74           if sent
-00001c10: 656e 6365 2e73 7472 6970 2829 2021 3d20  ence.strip() != 
-00001c20: 2727 0a20 2020 2020 2020 205d 0a0a 2020  ''.        ]..  
-00001c30: 2020 2020 2020 2320 5b64 6562 7567 5d20        # [debug] 
-00001c40: 7072 696e 7420 696e 666f 2065 7861 6d70  print info examp
-00001c50: 6c65 3a0a 2020 2020 2020 2020 6966 2073  le:.        if s
-00001c60: 656c 662e 6465 6275 673a 0a20 2020 2020  elf.debug:.     
-00001c70: 2020 2020 2020 2066 6f72 2073 656e 7465         for sente
-00001c80: 6e63 652c 2069 6e70 7574 5f69 6473 2069  nce, input_ids i
-00001c90: 6e20 7a69 7028 7365 6e74 656e 6365 6c74  n zip(sentencelt
-00001ca0: 2c20 696e 7075 745f 6964 735f 6c74 293a  , input_ids_lt):
-00001cb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001cc0: 2070 7269 6e74 2827 7261 773a 272c 2073   print('raw:', s
-00001cd0: 656e 7465 6e63 6529 0a20 2020 2020 2020  entence).       
-00001ce0: 2020 2020 2020 2020 2070 7269 6e74 280a           print(.
-00001cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001d00: 2020 2020 2772 6573 3a27 2c20 2727 2e6a      'res:', ''.j
-00001d10: 6f69 6e28 5b0a 2020 2020 2020 2020 2020  oin([.          
-00001d20: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00001d30: 6c66 2e76 6f63 6162 5f72 6576 6572 7365  lf.vocab_reverse
-00001d40: 2e67 6574 2877 6964 2c20 7365 6c66 2e75  .get(wid, self.u
-00001d50: 6e6b 5f69 6429 2e72 6570 6c61 6365 280a  nk_id).replace(.
-00001d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001d70: 2020 2020 2020 2020 2020 2020 273c 554e              '<UN
-00001d80: 4b3e 272c 2027 2027 2920 666f 7220 7769  K>', ' ') for wi
-00001d90: 6420 696e 2069 6e70 7574 5f69 6473 0a20  d in input_ids. 
-00001da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001db0: 2020 205d 2929 0a20 2020 2020 2020 206d     ])).        m
-00001dc0: 6178 6c65 6e20 3d20 6d61 7828 5b6c 656e  axlen = max([len
-00001dd0: 2869 6473 2920 666f 7220 6964 7320 696e  (ids) for ids in
-00001de0: 2069 6e70 7574 5f69 6473 5f6c 745d 290a   input_ids_lt]).
-00001df0: 2020 2020 2020 2020 666f 7220 6964 7320          for ids 
-00001e00: 696e 2069 6e70 7574 5f69 6473 5f6c 743a  in input_ids_lt:
-00001e10: 0a20 2020 2020 2020 2020 2020 2069 6473  .            ids
-00001e20: 2e65 7874 656e 6428 5b73 656c 662e 7061  .extend([self.pa
-00001e30: 645f 6964 5d20 2a20 286d 6178 6c65 6e20  d_id] * (maxlen 
-00001e40: 2d20 6c65 6e28 6964 7329 2929 0a20 2020  - len(ids))).   
-00001e50: 2020 2020 2069 6e70 7574 5f69 6473 203d       input_ids =
-00001e60: 206e 702e 6172 7261 7928 696e 7075 745f   np.array(input_
-00001e70: 6964 735f 6c74 290a 0a20 2020 2020 2020  ids_lt)..       
-00001e80: 2072 6573 756c 7420 3d20 7b27 696e 7075   result = {'inpu
-00001e90: 745f 6964 7327 3a20 696e 7075 745f 6964  t_ids': input_id
-00001ea0: 737d 0a20 2020 2020 2020 2072 6574 7572  s}.        retur
-00001eb0: 6e20 7265 7375 6c74 0a0a 2020 2020 6465  n result..    de
-00001ec0: 6620 666f 7277 6172 6428 7365 6c66 2c20  f forward(self, 
-00001ed0: 696e 7075 743a 2044 6963 745b 7374 722c  input: Dict[str,
-00001ee0: 2041 6e79 5d29 202d 3e20 4469 6374 5b73   Any]) -> Dict[s
-00001ef0: 7472 2c20 416e 795d 3a0a 2020 2020 2020  tr, Any]:.      
-00001f00: 2020 7769 7468 2073 656c 662e 5f73 6573    with self._ses
-00001f10: 7369 6f6e 2e61 735f 6465 6661 756c 7428  sion.as_default(
-00001f20: 293a 0a20 2020 2020 2020 2020 2020 2066  ):.            f
-00001f30: 6565 645f 6469 6374 203d 207b 7365 6c66  eed_dict = {self
-00001f40: 2e69 6e70 7574 5f69 6473 3a20 696e 7075  .input_ids: inpu
-00001f50: 745b 2769 6e70 7574 5f69 6473 275d 7d0a  t['input_ids']}.
-00001f60: 2020 2020 2020 2020 2020 2020 7365 7373              sess
-00001f70: 5f6f 7574 7075 7473 203d 2073 656c 662e  _outputs = self.
-00001f80: 5f73 6573 7369 6f6e 2e72 756e 2873 656c  _session.run(sel
-00001f90: 662e 6f75 7470 7574 2c20 6665 6564 5f64  f.output, feed_d
-00001fa0: 6963 743d 6665 6564 5f64 6963 7429 0a20  ict=feed_dict). 
-00001fb0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00001fc0: 6e20 7365 7373 5f6f 7574 7075 7473 0a0a  n sess_outputs..
-00001fd0: 2020 2020 6465 6620 706f 7374 7072 6f63      def postproc
-00001fe0: 6573 7328 7365 6c66 2c20 696e 7075 7473  ess(self, inputs
-00001ff0: 3a20 4469 6374 5b73 7472 2c20 416e 795d  : Dict[str, Any]
-00002000: 2920 2d3e 2044 6963 745b 7374 722c 2041  ) -> Dict[str, A
-00002010: 6e79 5d3a 0a20 2020 2020 2020 206f 7574  ny]:.        out
-00002020: 7075 745f 7363 6f72 6573 5f72 6177 203d  put_scores_raw =
-00002030: 2069 6e70 7574 735b 276f 7574 7075 745f   inputs['output_
-00002040: 7363 6f72 6527 5d0a 0a20 2020 2020 2020  score']..       
-00002050: 2073 7570 706f 7274 6564 5f31 3034 5f6c   supported_104_l
-00002060: 616e 6720 3d20 7365 7428 5b0a 2020 2020  ang = set([.    
-00002070: 2020 2020 2020 2020 2761 6627 2c20 2761          'af', 'a
-00002080: 6d27 2c20 2761 7227 2c20 2761 7a27 2c20  m', 'ar', 'az', 
-00002090: 2762 6527 2c20 2762 6727 2c20 2762 6e27  'be', 'bg', 'bn'
-000020a0: 2c20 2762 7327 2c20 2763 6127 2c20 2763  , 'bs', 'ca', 'c
-000020b0: 6527 2c20 2763 6f27 2c0a 2020 2020 2020  e', 'co',.      
-000020c0: 2020 2020 2020 2763 7327 2c20 2763 7927        'cs', 'cy'
-000020d0: 2c20 2764 6127 2c20 2764 6527 2c20 2765  , 'da', 'de', 'e
-000020e0: 6c27 2c20 2765 6e27 2c20 2765 6f27 2c20  l', 'en', 'eo', 
-000020f0: 2765 7327 2c20 2765 7427 2c20 2765 7527  'es', 'et', 'eu'
-00002100: 2c20 2766 6127 2c0a 2020 2020 2020 2020  , 'fa',.        
-00002110: 2020 2020 2766 6927 2c20 2766 7227 2c20      'fi', 'fr', 
-00002120: 2766 7927 2c20 2767 6127 2c20 2767 6427  'fy', 'ga', 'gd'
-00002130: 2c20 2767 6c27 2c20 2767 7527 2c20 2768  , 'gl', 'gu', 'h
-00002140: 6127 2c20 2768 6177 272c 2027 6865 272c  a', 'haw', 'he',
-00002150: 2027 6869 272c 0a20 2020 2020 2020 2020   'hi',.         
-00002160: 2020 2027 686d 6e27 2c20 2768 7227 2c20     'hmn', 'hr', 
-00002170: 2768 7427 2c20 2768 7527 2c20 2768 7927  'ht', 'hu', 'hy'
-00002180: 2c20 2769 6427 2c20 2769 6727 2c20 2769  , 'id', 'ig', 'i
-00002190: 7327 2c20 2769 7427 2c20 276a 6127 2c20  s', 'it', 'ja', 
-000021a0: 276a 7627 2c0a 2020 2020 2020 2020 2020  'jv',.          
-000021b0: 2020 276b 6127 2c20 276b 6b27 2c20 276b    'ka', 'kk', 'k
-000021c0: 6d27 2c20 276b 6e27 2c20 276b 6f27 2c20  m', 'kn', 'ko', 
-000021d0: 276b 7527 2c20 276b 7927 2c20 276c 6127  'ku', 'ky', 'la'
-000021e0: 2c20 276c 6f27 2c20 276c 7427 2c20 276c  , 'lo', 'lt', 'l
-000021f0: 7627 2c0a 2020 2020 2020 2020 2020 2020  v',.            
-00002200: 276d 6727 2c20 276d 6927 2c20 276d 6b27  'mg', 'mi', 'mk'
-00002210: 2c20 276d 6c27 2c20 276d 6e27 2c20 276d  , 'ml', 'mn', 'm
-00002220: 7227 2c20 276d 7327 2c20 276d 7427 2c20  r', 'ms', 'mt', 
-00002230: 276d 7927 2c20 276e 6527 2c20 276e 6c27  'my', 'ne', 'nl'
-00002240: 2c0a 2020 2020 2020 2020 2020 2020 276e  ,.            'n
-00002250: 6f27 2c20 276e 7927 2c20 2770 6127 2c20  o', 'ny', 'pa', 
-00002260: 2770 6c27 2c20 2770 7327 2c20 2770 7427  'pl', 'ps', 'pt'
-00002270: 2c20 2772 6f27 2c20 2772 7527 2c20 2773  , 'ro', 'ru', 's
-00002280: 6427 2c20 2773 6927 2c20 2773 6b27 2c0a  d', 'si', 'sk',.
-00002290: 2020 2020 2020 2020 2020 2020 2773 6c27              'sl'
-000022a0: 2c20 2773 6d27 2c20 2773 6e27 2c20 2773  , 'sm', 'sn', 's
-000022b0: 6f27 2c20 2773 7127 2c20 2773 7227 2c20  o', 'sq', 'sr', 
-000022c0: 2773 7427 2c20 2773 7527 2c20 2773 7627  'st', 'su', 'sv'
-000022d0: 2c20 2773 7727 2c20 2774 6127 2c0a 2020  , 'sw', 'ta',.  
-000022e0: 2020 2020 2020 2020 2020 2774 6527 2c20            'te', 
-000022f0: 2774 6727 2c20 2774 6827 2c20 2774 6c27  'tg', 'th', 'tl'
-00002300: 2c20 2774 7227 2c20 2775 6727 2c20 2775  , 'tr', 'ug', 'u
-00002310: 6b27 2c20 2775 7227 2c20 2775 7a27 2c20  k', 'ur', 'uz', 
-00002320: 2776 6927 2c20 2778 6827 2c0a 2020 2020  'vi', 'xh',.    
-00002330: 2020 2020 2020 2020 2779 6927 2c20 2779          'yi', 'y
-00002340: 6f27 2c20 277a 6827 2c20 277a 682d 7477  o', 'zh', 'zh-tw
-00002350: 272c 2027 7a75 270a 2020 2020 2020 2020  ', 'zu'.        
-00002360: 5d29 0a20 2020 2020 2020 206c 6162 656c  ]).        label
-00002370: 735f 7363 6f72 6573 5f6c 7420 3d20 5b5d  s_scores_lt = []
-00002380: 0a20 2020 2020 2020 206f 7574 7075 745f  .        output_
-00002390: 6c61 6265 6c73 203d 205b 5d0a 2020 2020  labels = [].    
-000023a0: 2020 2020 666f 7220 6f75 7470 7574 5f73      for output_s
-000023b0: 636f 7265 2069 6e20 6f75 7470 7574 5f73  core in output_s
-000023c0: 636f 7265 735f 7261 773a 0a20 2020 2020  cores_raw:.     
-000023d0: 2020 2020 2020 2074 6d70 6c74 203d 205b         tmplt = [
-000023e0: 5d0a 2020 2020 2020 2020 2020 2020 666f  ].            fo
-000023f0: 7220 732c 206c 2069 6e20 7a69 7028 6f75  r s, l in zip(ou
-00002400: 7470 7574 5f73 636f 7265 2c20 7365 6c66  tput_score, self
-00002410: 2e6c 6162 656c 2e76 616c 7565 7328 2929  .label.values())
-00002420: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00002430: 2020 6966 206c 206e 6f74 2069 6e20 7375    if l not in su
-00002440: 7070 6f72 7465 645f 3130 345f 6c61 6e67  pported_104_lang
-00002450: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00002460: 2020 2020 2020 636f 6e74 696e 7565 0a20        continue. 
-00002470: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00002480: 6d70 6c74 2e61 7070 656e 6428 286c 2c20  mplt.append((l, 
-00002490: 7329 290a 2020 2020 2020 2020 2020 2020  s)).            
-000024a0: 746d 706c 7420 3d20 736f 7274 6564 2874  tmplt = sorted(t
-000024b0: 6d70 6c74 2c20 6b65 793d 6c61 6d62 6461  mplt, key=lambda
-000024c0: 2069 3a20 695b 315d 2c20 7265 7665 7273   i: i[1], revers
-000024d0: 653d 5472 7565 295b 3a33 5d0a 2020 2020  e=True)[:3].    
-000024e0: 2020 2020 2020 2020 6966 206c 656e 2874          if len(t
-000024f0: 6d70 6c74 2920 3d3d 2030 3a0a 2020 2020  mplt) == 0:.    
-00002500: 2020 2020 2020 2020 2020 2020 746d 706c              tmpl
-00002510: 7420 3d20 5b28 302c 2031 2e30 3029 5d0a  t = [(0, 1.00)].
-00002520: 2020 2020 2020 2020 2020 2020 6c61 6265              labe
-00002530: 6c73 5f73 636f 7265 735f 6c74 2e61 7070  ls_scores_lt.app
-00002540: 656e 6428 746d 706c 7429 0a20 2020 2020  end(tmplt).     
-00002550: 2020 2020 2020 206f 7574 7075 745f 6c61         output_la
-00002560: 6265 6c73 2e61 7070 656e 6428 746d 706c  bels.append(tmpl
-00002570: 745b 305d 5b30 5d29 0a20 2020 2020 2020  t[0][0]).       
-00002580: 206f 7574 7075 745f 7363 6f72 6573 203d   output_scores =
-00002590: 205b 5b28 6c61 6265 6c2c 2072 6f75 6e64   [[(label, round
-000025a0: 2873 636f 7265 2c20 3229 290a 2020 2020  (score, 2)).    
-000025b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000025c0: 2020 2020 2020 666f 7220 6c61 6265 6c2c        for label,
-000025d0: 2073 636f 7265 2069 6e20 6c61 6265 6c73   score in labels
-000025e0: 5f73 636f 7265 7320 6966 2073 636f 7265  _scores if score
-000025f0: 203e 2030 2e30 315d 0a20 2020 2020 2020   > 0.01].       
-00002600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002610: 2020 666f 7220 6c61 6265 6c73 5f73 636f    for labels_sco
-00002620: 7265 7320 696e 206c 6162 656c 735f 7363  res in labels_sc
-00002630: 6f72 6573 5f6c 745d 0a0a 2020 2020 2020  ores_lt]..      
-00002640: 2020 7265 7375 6c74 203d 207b 0a20 2020    result = {.   
-00002650: 2020 2020 2020 2020 204f 7574 7075 744b           OutputK
-00002660: 6579 732e 4c41 4245 4c53 3a20 6f75 7470  eys.LABELS: outp
-00002670: 7574 5f6c 6162 656c 732c 0a20 2020 2020  ut_labels,.     
-00002680: 2020 2020 2020 204f 7574 7075 744b 6579         OutputKey
-00002690: 732e 5343 4f52 4553 3a20 6f75 7470 7574  s.SCORES: output
-000026a0: 5f73 636f 7265 730a 2020 2020 2020 2020  _scores.        
-000026b0: 7d0a 2020 2020 2020 2020 7265 7475 726e  }.        return
-000026c0: 2072 6573 756c 740a                       result.
+00000000: 696d 706f 7274 206f 730a 696d 706f 7274  import os.import
+00000010: 2072 650a 6672 6f6d 2074 7970 696e 6720   re.from typing 
+00000020: 696d 706f 7274 2041 6e79 2c20 4469 6374  import Any, Dict
+00000030: 0a0a 696d 706f 7274 206e 756d 7079 2061  ..import numpy a
+00000040: 7320 6e70 0a69 6d70 6f72 7420 7465 6e73  s np.import tens
+00000050: 6f72 666c 6f77 2061 7320 7466 0a0a 6672  orflow as tf..fr
+00000060: 6f6d 2077 6561 7468 6f6e 2e75 7469 6c73  om weathon.utils
+00000070: 2e63 6f6e 7374 616e 7473 2e6d 6574 6169  .constants.metai
+00000080: 6e66 6f20 696d 706f 7274 2050 6970 656c  nfo import Pipel
+00000090: 696e 6573 0a66 726f 6d20 7765 6174 686f  ines.from weatho
+000000a0: 6e2e 6f75 7470 7574 7320 696d 706f 7274  n.outputs import
+000000b0: 204f 7574 7075 744b 6579 730a 6672 6f6d   OutputKeys.from
+000000c0: 2077 6561 7468 6f6e 2e62 6173 6520 696d   weathon.base im
+000000d0: 706f 7274 2042 6173 6550 6970 656c 696e  port BasePipelin
+000000e0: 650a 6672 6f6d 2077 6561 7468 6f6e 2e72  e.from weathon.r
+000000f0: 6567 6973 7472 7920 696d 706f 7274 2050  egistry import P
+00000100: 4950 454c 494e 4553 0a66 726f 6d20 7765  IPELINES.from we
+00000110: 6174 686f 6e2e 7574 696c 732e 636f 6e66  athon.utils.conf
+00000120: 6967 2e63 6f6e 6669 6720 696d 706f 7274  ig.config import
+00000130: 2043 6f6e 6669 672c 2043 6f6e 6669 6746   Config, ConfigF
+00000140: 6965 6c64 730a 6672 6f6d 2077 6561 7468  ields.from weath
+00000150: 6f6e 2e75 7469 6c73 2e63 6f6e 7374 616e  on.utils.constan
+00000160: 7473 2069 6d70 6f72 7420 4d6f 6465 6c46  ts import ModelF
+00000170: 696c 652c 2054 6173 6b73 0a66 726f 6d20  ile, Tasks.from 
+00000180: 7765 6174 686f 6e2e 7574 696c 732e 6c6f  weathon.utils.lo
+00000190: 6767 6572 2069 6d70 6f72 7420 6765 745f  gger import get_
+000001a0: 6c6f 6767 6572 0a0a 6966 2074 662e 5f5f  logger..if tf.__
+000001b0: 7665 7273 696f 6e5f 5f20 3e3d 2027 322e  version__ >= '2.
+000001c0: 3027 3a0a 2020 2020 7466 203d 2074 662e  0':.    tf = tf.
+000001d0: 636f 6d70 6174 2e76 310a 2020 2020 7466  compat.v1.    tf
+000001e0: 2e64 6973 6162 6c65 5f65 6167 6572 5f65  .disable_eager_e
+000001f0: 7865 6375 7469 6f6e 2829 0a0a 6c6f 6767  xecution()..logg
+00000200: 6572 203d 2067 6574 5f6c 6f67 6765 7228  er = get_logger(
+00000210: 290a 0a5f 5f61 6c6c 5f5f 203d 205b 274c  )..__all__ = ['L
+00000220: 616e 6775 6167 6549 6465 6e74 6966 6963  anguageIdentific
+00000230: 6174 696f 6e50 6970 656c 696e 6527 5d0a  ationPipeline'].
+00000240: 0a0a 4050 4950 454c 494e 4553 2e72 6567  ..@PIPELINES.reg
+00000250: 6973 7465 725f 6d6f 6475 6c65 280a 2020  ister_module(.  
+00000260: 2020 5461 736b 732e 7465 7874 5f63 6c61    Tasks.text_cla
+00000270: 7373 6966 6963 6174 696f 6e2c 206d 6f64  ssification, mod
+00000280: 756c 655f 6e61 6d65 3d50 6970 656c 696e  ule_name=Pipelin
+00000290: 6573 2e6c 616e 6775 6167 655f 6964 656e  es.language_iden
+000002a0: 7469 6669 6361 7469 6f6e 290a 636c 6173  tification).clas
+000002b0: 7320 4c61 6e67 7561 6765 4964 656e 7469  s LanguageIdenti
+000002c0: 6669 6361 7469 6f6e 5069 7065 6c69 6e65  ficationPipeline
+000002d0: 2850 6970 656c 696e 6529 3a0a 2020 2020  (Pipeline):.    
+000002e0: 7222 2222 204c 616e 6775 6167 6520 4964  r""" Language Id
+000002f0: 656e 7469 6669 6361 7469 6f6e 2050 6970  entification Pip
+00000300: 656c 696e 652e 0a0a 2020 2020 4578 616d  eline...    Exam
+00000310: 706c 6573 3a0a 0a20 2020 203e 3e3e 2066  ples:..    >>> f
+00000320: 726f 6d20 7765 6174 686f 6e2e 7069 7065  rom weathon.pipe
+00000330: 6c69 6e65 7320 696d 706f 7274 2070 6970  lines import pip
+00000340: 656c 696e 650a 2020 2020 3e3e 3e20 6672  eline.    >>> fr
+00000350: 6f6d 2077 6561 7468 6f6e 2e75 7469 6c73  om weathon.utils
+00000360: 2e63 6f6e 7374 616e 7473 2069 6d70 6f72  .constants impor
+00000370: 7420 5461 736b 730a 0a20 2020 203e 3e3e  t Tasks..    >>>
+00000380: 2070 6970 656c 696e 655f 696e 7320 3d20   pipeline_ins = 
+00000390: 7069 7065 6c69 6e65 2854 6173 6b73 2e74  pipeline(Tasks.t
+000003a0: 6578 745f 636c 6173 7369 6669 6361 7469  ext_classificati
+000003b0: 6f6e 2c20 2764 616d 6f2f 6e6c 705f 6c61  on, 'damo/nlp_la
+000003c0: 6e67 7561 6765 5f69 6465 6e74 6966 6963  nguage_identific
+000003d0: 6174 696f 6e2d 636c 6173 7369 6669 6361  ation-classifica
+000003e0: 7469 6f6e 2d62 6173 6527 290a 2020 2020  tion-base').    
+000003f0: 3e3e 3e20 7069 7065 6c69 6e65 5f69 6e73  >>> pipeline_ins
+00000400: 2827 456c 6f6e 204d 7573 6b2c 2063 6f2d  ('Elon Musk, co-
+00000410: 666f 756e 6465 7220 616e 6420 6368 6965  founder and chie
+00000420: 6620 6578 6563 7574 6976 6520 6f66 6669  f executive offi
+00000430: 6365 7220 6f66 2054 6573 6c61 204d 6f74  cer of Tesla Mot
+00000440: 6f72 732e 5c6e 2720 5c0a 2020 2020 3e3e  ors.\n' \.    >>
+00000450: 3e20 2020 2020 2020 2020 2020 2020 2027  >              '
+00000460: 476c 6569 6368 7a65 6974 6967 206e 6168  Gleichzeitig nah
+00000470: 6d20 6469 6520 4c65 6769 6f6e 2061 6e20  m die Legion an 
+00000480: 6465 7220 4265 6672 6965 6475 6e67 2041  der Befriedung A
+00000490: 6c67 6572 6965 6e73 2074 6569 6c2c 2064  lgeriens teil, d
+000004a0: 6965 2076 6f6e 2e5c 6e27 205c 0a20 2020  ie von.\n' \.   
+000004b0: 203e 3e3e 2020 2020 2020 2020 2020 2020   >>>            
+000004c0: 2020 27e4 bdbf e794 a870 6970 656c 696e    '......pipelin
+000004d0: 65e6 8ea8 e790 86e5 8f8a e59c a8e7 babf  e...............
+000004e0: e4bd 93e9 aa8c e58a 9fe8 83bd e79a 84e6  ................
+000004f0: 97b6 e580 99ef bc8c e5b0 bde9 878f e8be  ................
+00000500: 93e5 85a5 e58d 95e5 8fa5 e696 87e6 9cac  ................
+00000510: efbc 8ce5 a682 e69e 9ce6 98af e5a4 9ae5  ................
+00000520: 8fa5 e995 bfe6 9687 e69c ace5 bbba e8ae  ................
+00000530: aee4 baba e5b7 a5e5 8886 e58f a5e3 8082  ................
+00000540: 270a 0a20 2020 203e 3e3e 207b 0a20 2020  '..    >>> {.   
+00000550: 203e 3e3e 2020 2020 226c 6162 656c 7322   >>>    "labels"
+00000560: 3a5b 0a20 2020 203e 3e3e 2020 2020 2020  :[.    >>>      
+00000570: 2020 2265 6e22 2c0a 2020 2020 3e3e 3e20    "en",.    >>> 
+00000580: 2020 2020 2020 2022 6465 222c 0a20 2020         "de",.   
+00000590: 203e 3e3e 2020 2020 2020 2020 227a 6822   >>>        "zh"
+000005a0: 0a20 2020 203e 3e3e 2020 2020 5d2c 0a20  .    >>>    ],. 
+000005b0: 2020 203e 3e3e 2020 2020 2273 636f 7265     >>>    "score
+000005c0: 7322 3a5b 0a20 2020 203e 3e3e 2020 2020  s":[.    >>>    
+000005d0: 2020 2020 5b28 2765 6e27 2c20 302e 3939      [('en', 0.99
+000005e0: 295d 2c0a 2020 2020 3e3e 3e20 2020 2020  )],.    >>>     
+000005f0: 2020 205b 2827 6465 272c 2031 2e30 295d     [('de', 1.0)]
+00000600: 2c0a 2020 2020 3e3e 3e20 2020 2020 2020  ,.    >>>       
+00000610: 205b 2827 7a68 272c 2031 2e30 295d 0a20   [('zh', 1.0)]. 
+00000620: 2020 203e 3e3e 2020 2020 5d0a 2020 2020     >>>    ].    
+00000630: 3e3e 3e20 7d0a 2020 2020 2222 220a 0a20  >>> }.    """.. 
+00000640: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+00000650: 7365 6c66 2c20 6d6f 6465 6c3a 2073 7472  self, model: str
+00000660: 2c20 2a2a 6b77 6172 6773 293a 0a20 2020  , **kwargs):.   
+00000670: 2020 2020 2022 2222 4275 696c 6420 6120       """Build a 
+00000680: 6c61 6e67 7561 6765 2069 6465 6e74 6966  language identif
+00000690: 6963 6174 696f 6e20 7069 7065 6c69 6e65  ication pipeline
+000006a0: 2077 6974 6820 6120 6d6f 6465 6c20 6469   with a model di
+000006b0: 7220 6f72 2061 206d 6f64 656c 2069 6420  r or a model id 
+000006c0: 696e 2074 6865 206d 6f64 656c 2068 7562  in the model hub
+000006d0: 2e0a 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
+000006e0: 0a20 2020 2020 2020 2020 2020 206d 6f64  .            mod
+000006f0: 656c 3a20 4120 4d6f 6465 6c20 696e 7374  el: A Model inst
+00000700: 616e 6365 2e0a 2020 2020 2020 2020 2222  ance..        ""
+00000710: 220a 2020 2020 2020 2020 7375 7065 7228  ".        super(
+00000720: 292e 5f5f 696e 6974 5f5f 286d 6f64 656c  ).__init__(model
+00000730: 3d6d 6f64 656c 2c20 2a2a 6b77 6172 6773  =model, **kwargs
+00000740: 290a 2020 2020 2020 2020 6578 706f 7274  ).        export
+00000750: 5f64 6972 203d 206d 6f64 656c 0a20 2020  _dir = model.   
+00000760: 2020 2020 2073 656c 662e 6465 6275 6720       self.debug 
+00000770: 3d20 4661 6c73 650a 0a20 2020 2020 2020  = False..       
+00000780: 2073 656c 662e 6366 6720 3d20 436f 6e66   self.cfg = Conf
+00000790: 6967 2e66 726f 6d5f 6669 6c65 280a 2020  ig.from_file(.  
+000007a0: 2020 2020 2020 2020 2020 6f73 2e70 6174            os.pat
+000007b0: 682e 6a6f 696e 2865 7870 6f72 745f 6469  h.join(export_di
+000007c0: 722c 204d 6f64 656c 4669 6c65 2e43 4f4e  r, ModelFile.CON
+000007d0: 4649 4755 5241 5449 4f4e 2929 0a0a 2020  FIGURATION))..  
+000007e0: 2020 2020 2020 6a6f 696e 745f 766f 6361        joint_voca
+000007f0: 625f 6669 6c65 203d 206f 732e 7061 7468  b_file = os.path
+00000800: 2e6a 6f69 6e28 0a20 2020 2020 2020 2020  .join(.         
+00000810: 2020 2065 7870 6f72 745f 6469 722c 2073     export_dir, s
+00000820: 656c 662e 6366 675b 436f 6e66 6967 4669  elf.cfg[ConfigFi
+00000830: 656c 6473 2e70 7265 7072 6f63 6573 736f  elds.preprocesso
+00000840: 725d 5b27 766f 6361 6227 5d29 0a20 2020  r]['vocab']).   
+00000850: 2020 2020 2076 6f63 6162 6669 6c65 7320       vocabfiles 
+00000860: 3d20 5b5d 0a20 2020 2020 2020 2076 6f63  = [].        voc
+00000870: 6162 6669 6c65 735f 7265 7665 7273 6520  abfiles_reverse 
+00000880: 3d20 5b5d 0a20 2020 2020 2020 2066 6f72  = [].        for
+00000890: 2069 2c20 7720 696e 2065 6e75 6d65 7261   i, w in enumera
+000008a0: 7465 286f 7065 6e28 6a6f 696e 745f 766f  te(open(joint_vo
+000008b0: 6361 625f 6669 6c65 2c20 2772 6227 2929  cab_file, 'rb'))
+000008c0: 3a0a 2020 2020 2020 2020 2020 2020 7720  :.            w 
+000008d0: 3d20 772e 7374 7269 7028 290a 2020 2020  = w.strip().    
+000008e0: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+000008f0: 2020 2020 2020 2020 2020 2020 2077 203d               w =
+00000900: 2077 2e64 6563 6f64 6528 2775 7466 2d38   w.decode('utf-8
+00000910: 2729 0a20 2020 2020 2020 2020 2020 2020  ').             
+00000920: 2020 2076 6f63 6162 6669 6c65 732e 6170     vocabfiles.ap
+00000930: 7065 6e64 2828 772c 2069 2929 0a20 2020  pend((w, i)).   
+00000940: 2020 2020 2020 2020 2020 2020 2076 6f63               voc
+00000950: 6162 6669 6c65 735f 7265 7665 7273 652e  abfiles_reverse.
+00000960: 6170 7065 6e64 2828 692c 2077 2929 0a20  append((i, w)). 
+00000970: 2020 2020 2020 2020 2020 2065 7863 6570             excep
+00000980: 7420 556e 6963 6f64 6544 6563 6f64 6545  t UnicodeDecodeE
+00000990: 7272 6f72 3a0a 2020 2020 2020 2020 2020  rror:.          
+000009a0: 2020 2020 2020 2320 5b64 6562 7567 5d20        # [debug] 
+000009b0: 7072 696e 7420 6572 726f 7220 696e 666f  print error info
+000009c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000009d0: 2069 6620 7365 6c66 2e64 6562 7567 3a0a   if self.debug:.
+000009e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000009f0: 2020 2020 7072 696e 7428 2765 7272 6f72      print('error
+00000a00: 2076 6f63 6162 3a27 2c20 772c 2069 290a   vocab:', w, i).
+00000a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000a20: 7061 7373 0a20 2020 2020 2020 2073 656c  pass.        sel
+00000a30: 662e 766f 6361 6220 3d20 6469 6374 2876  f.vocab = dict(v
+00000a40: 6f63 6162 6669 6c65 7329 0a20 2020 2020  ocabfiles).     
+00000a50: 2020 2073 656c 662e 766f 6361 625f 7265     self.vocab_re
+00000a60: 7665 7273 6520 3d20 6469 6374 2876 6f63  verse = dict(voc
+00000a70: 6162 6669 6c65 735f 7265 7665 7273 6529  abfiles_reverse)
+00000a80: 0a20 2020 2020 2020 2073 656c 662e 756e  .        self.un
+00000a90: 6b5f 6964 203d 2073 656c 662e 766f 6361  k_id = self.voca
+00000aa0: 622e 6765 7428 273c 554e 4b3e 272c 2031  b.get('<UNK>', 1
+00000ab0: 290a 2020 2020 2020 2020 7365 6c66 2e70  ).        self.p
+00000ac0: 6164 5f69 6420 3d20 7365 6c66 2e76 6f63  ad_id = self.voc
+00000ad0: 6162 2e67 6574 2827 3c2f 533e 272c 2030  ab.get('</S>', 0
+00000ae0: 290a 0a20 2020 2020 2020 206a 6f69 6e74  )..        joint
+00000af0: 5f6c 6162 656c 5f66 696c 6520 3d20 6f73  _label_file = os
+00000b00: 2e70 6174 682e 6a6f 696e 280a 2020 2020  .path.join(.    
+00000b10: 2020 2020 2020 2020 6578 706f 7274 5f64          export_d
+00000b20: 6972 2c20 7365 6c66 2e63 6667 5b43 6f6e  ir, self.cfg[Con
+00000b30: 6669 6746 6965 6c64 732e 7072 6570 726f  figFields.prepro
+00000b40: 6365 7373 6f72 5d5b 276c 6162 656c 275d  cessor]['label']
+00000b50: 290a 2020 2020 2020 2020 7365 6c66 2e6c  ).        self.l
+00000b60: 6162 656c 203d 2064 6963 7428 5b28 692c  abel = dict([(i,
+00000b70: 2077 2e73 7472 6970 2829 2920 666f 7220   w.strip()) for 
+00000b80: 692c 2077 2069 6e20 656e 756d 6572 6174  i, w in enumerat
+00000b90: 6528 0a20 2020 2020 2020 2020 2020 206f  e(.            o
+00000ba0: 7065 6e28 6a6f 696e 745f 6c61 6265 6c5f  pen(joint_label_
+00000bb0: 6669 6c65 2c20 2772 272c 2065 6e63 6f64  file, 'r', encod
+00000bc0: 696e 673d 2775 7466 3827 2929 5d29 0a20  ing='utf8'))]). 
+00000bd0: 2020 2020 2020 2073 656c 662e 756e 6b5f         self.unk_
+00000be0: 6c61 6265 6c20 3d20 2775 6e6b 270a 0a20  label = 'unk'.. 
+00000bf0: 2020 2020 2020 2074 662e 7265 7365 745f         tf.reset_
+00000c00: 6465 6661 756c 745f 6772 6170 6828 290a  default_graph().
+00000c10: 2020 2020 2020 2020 7466 5f63 6f6e 6669          tf_confi
+00000c20: 6720 3d20 7466 2e43 6f6e 6669 6750 726f  g = tf.ConfigPro
+00000c30: 746f 2861 6c6c 6f77 5f73 6f66 745f 706c  to(allow_soft_pl
+00000c40: 6163 656d 656e 743d 5472 7565 290a 2020  acement=True).  
+00000c50: 2020 2020 2020 7466 5f63 6f6e 6669 672e        tf_config.
+00000c60: 6770 755f 6f70 7469 6f6e 732e 616c 6c6f  gpu_options.allo
+00000c70: 775f 6772 6f77 7468 203d 2054 7275 650a  w_growth = True.
+00000c80: 2020 2020 2020 2020 7365 6c66 2e5f 7365          self._se
+00000c90: 7373 696f 6e20 3d20 7466 2e53 6573 7369  ssion = tf.Sessi
+00000ca0: 6f6e 2863 6f6e 6669 673d 7466 5f63 6f6e  on(config=tf_con
+00000cb0: 6669 6729 0a20 2020 2020 2020 2074 662e  fig).        tf.
+00000cc0: 7361 7665 645f 6d6f 6465 6c2e 6c6f 6164  saved_model.load
+00000cd0: 6572 2e6c 6f61 6428 0a20 2020 2020 2020  er.load(.       
+00000ce0: 2020 2020 2073 656c 662e 5f73 6573 7369       self._sessi
+00000cf0: 6f6e 2c20 5b74 662e 7079 7468 6f6e 2e73  on, [tf.python.s
+00000d00: 6176 6564 5f6d 6f64 656c 2e74 6167 5f63  aved_model.tag_c
+00000d10: 6f6e 7374 616e 7473 2e53 4552 5649 4e47  onstants.SERVING
+00000d20: 5d2c 0a20 2020 2020 2020 2020 2020 2065  ],.            e
+00000d30: 7870 6f72 745f 6469 7229 0a20 2020 2020  xport_dir).     
+00000d40: 2020 2064 6566 6175 6c74 5f67 7261 7068     default_graph
+00000d50: 203d 2074 662e 6765 745f 6465 6661 756c   = tf.get_defaul
+00000d60: 745f 6772 6170 6828 290a 2020 2020 2020  t_graph().      
+00000d70: 2020 2320 5b64 6562 7567 5d20 7072 696e    # [debug] prin
+00000d80: 7420 6772 6170 6820 6f70 730a 2020 2020  t graph ops.    
+00000d90: 2020 2020 6966 2073 656c 662e 6465 6275      if self.debu
+00000da0: 673a 0a20 2020 2020 2020 2020 2020 2066  g:.            f
+00000db0: 6f72 206f 7020 696e 2064 6566 6175 6c74  or op in default
+00000dc0: 5f67 7261 7068 2e67 6574 5f6f 7065 7261  _graph.get_opera
+00000dd0: 7469 6f6e 7328 293a 0a20 2020 2020 2020  tions():.       
+00000de0: 2020 2020 2020 2020 2070 7269 6e74 286f           print(o
+00000df0: 702e 6e61 6d65 2c20 6f70 2e76 616c 7565  p.name, op.value
+00000e00: 7328 2929 0a0a 2020 2020 2020 2020 7365  s())..        se
+00000e10: 6c66 2e69 6e70 7574 5f69 6473 203d 2064  lf.input_ids = d
+00000e20: 6566 6175 6c74 5f67 7261 7068 2e67 6574  efault_graph.get
+00000e30: 5f74 656e 736f 725f 6279 5f6e 616d 6528  _tensor_by_name(
+00000e40: 2773 7263 5f63 6964 3a30 2729 0a20 2020  'src_cid:0').   
+00000e50: 2020 2020 206f 7574 7075 745f 6c61 6265       output_labe
+00000e60: 6c20 3d20 6465 6661 756c 745f 6772 6170  l = default_grap
+00000e70: 682e 6765 745f 7465 6e73 6f72 5f62 795f  h.get_tensor_by_
+00000e80: 6e61 6d65 2827 6f75 7470 7574 5f6c 6162  name('output_lab
+00000e90: 656c 3a30 2729 0a20 2020 2020 2020 206f  el:0').        o
+00000ea0: 7574 7075 745f 7363 6f72 6520 3d20 6465  utput_score = de
+00000eb0: 6661 756c 745f 6772 6170 682e 6765 745f  fault_graph.get_
+00000ec0: 7465 6e73 6f72 5f62 795f 6e61 6d65 2827  tensor_by_name('
+00000ed0: 7072 6564 6963 745f 7363 6f72 653a 3027  predict_score:0'
+00000ee0: 290a 0a20 2020 2020 2020 2073 656c 662e  )..        self.
+00000ef0: 6f75 7470 7574 203d 207b 0a20 2020 2020  output = {.     
+00000f00: 2020 2020 2020 2027 6f75 7470 7574 5f69         'output_i
+00000f10: 6473 273a 206f 7574 7075 745f 6c61 6265  ds': output_labe
+00000f20: 6c2c 0a20 2020 2020 2020 2020 2020 2027  l,.            '
+00000f30: 6f75 7470 7574 5f73 636f 7265 273a 206f  output_score': o
+00000f40: 7574 7075 745f 7363 6f72 650a 2020 2020  utput_score.    
+00000f50: 2020 2020 7d0a 2020 2020 2020 2020 696e      }.        in
+00000f60: 6974 203d 2074 662e 676c 6f62 616c 5f76  it = tf.global_v
+00000f70: 6172 6961 626c 6573 5f69 6e69 7469 616c  ariables_initial
+00000f80: 697a 6572 2829 0a20 2020 2020 2020 206c  izer().        l
+00000f90: 6f63 616c 5f69 6e69 7420 3d20 7466 2e6c  ocal_init = tf.l
+00000fa0: 6f63 616c 5f76 6172 6961 626c 6573 5f69  ocal_variables_i
+00000fb0: 6e69 7469 616c 697a 6572 2829 0a20 2020  nitializer().   
+00000fc0: 2020 2020 2073 656c 662e 5f73 6573 7369       self._sessi
+00000fd0: 6f6e 2e72 756e 285b 696e 6974 2c20 6c6f  on.run([init, lo
+00000fe0: 6361 6c5f 696e 6974 5d29 0a20 2020 2020  cal_init]).     
+00000ff0: 2020 2074 662e 7361 7665 645f 6d6f 6465     tf.saved_mode
+00001000: 6c2e 6c6f 6164 6572 2e6c 6f61 6428 0a20  l.loader.load(. 
+00001010: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00001020: 5f73 6573 7369 6f6e 2c20 5b74 662e 7079  _session, [tf.py
+00001030: 7468 6f6e 2e73 6176 6564 5f6d 6f64 656c  thon.saved_model
+00001040: 2e74 6167 5f63 6f6e 7374 616e 7473 2e53  .tag_constants.S
+00001050: 4552 5649 4e47 5d2c 0a20 2020 2020 2020  ERVING],.       
+00001060: 2020 2020 2065 7870 6f72 745f 6469 7229       export_dir)
+00001070: 0a0a 2020 2020 6465 6620 5f6c 6964 5f70  ..    def _lid_p
+00001080: 7265 7072 6f63 6573 7328 7365 6c66 2c20  reprocess(self, 
+00001090: 696e 7075 743a 2073 7472 2920 2d3e 206c  input: str) -> l
+000010a0: 6973 743a 0a20 2020 2020 2020 2073 656e  ist:.        sen
+000010b0: 7465 6e63 6520 3d20 696e 7075 742e 6c6f  tence = input.lo
+000010c0: 7765 7228 290a 2020 2020 2020 2020 2320  wer().        # 
+000010d0: 4874 6d6c 546f 5465 7874 0a20 2020 2020  HtmlToText.     
+000010e0: 2020 2043 4c45 414e 5220 3d20 7227 3c2e     CLEANR = r'<.
+000010f0: 2a3f 3e7c 2628 5b61 2d7a 302d 395d 2b7c  *?>|&([a-z0-9]+|
+00001100: 235b 302d 395d 7b31 2c36 7d7c 2378 5b30  #[0-9]{1,6}|#x[0
+00001110: 2d39 612d 665d 7b31 2c36 7d29 3b27 0a20  -9a-f]{1,6});'. 
+00001120: 2020 2020 2020 2073 656e 7465 6e63 6520         sentence 
+00001130: 3d20 7265 2e73 7562 2843 4c45 414e 522c  = re.sub(CLEANR,
+00001140: 2027 272c 2073 656e 7465 6e63 6529 0a20   '', sentence). 
+00001150: 2020 2020 2020 2023 2052 656d 6f76 654c         # RemoveL
+00001160: 696e 6b73 0a20 2020 2020 2020 2055 524c  inks.        URL
+00001170: 5245 203d 2072 275c 532b 5b2e 2f5d 5c53  RE = r'\S+[./]\S
+00001180: 2b5c 733f 270a 2020 2020 2020 2020 7365  +\s?'.        se
+00001190: 6e74 656e 6365 203d 2072 652e 7375 6228  ntence = re.sub(
+000011a0: 5552 4c52 452c 2027 272c 2073 656e 7465  URLRE, '', sente
+000011b0: 6e63 6529 0a20 2020 2020 2020 2045 4d41  nce).        EMA
+000011c0: 494c 5245 203d 2072 275c 532a 405c 532a  ILRE = r'\S*@\S*
+000011d0: 5c73 3f27 0a20 2020 2020 2020 2073 656e  \s?'.        sen
+000011e0: 7465 6e63 6520 3d20 7265 2e73 7562 2845  tence = re.sub(E
+000011f0: 4d41 494c 5245 2c20 2727 2c20 7365 6e74  MAILRE, '', sent
+00001200: 656e 6365 290a 0a20 2020 2020 2020 2023  ence)..        #
+00001210: 2053 4243 3244 4243 0a20 2020 2020 2020   SBC2DBC.       
+00001220: 2064 6566 2073 7472 696e 6770 6172 7451   def stringpartQ
+00001230: 3242 2875 6368 6172 293a 0a20 2020 2020  2B(uchar):.     
+00001240: 2020 2020 2020 2069 6e73 6964 655f 636f         inside_co
+00001250: 6465 203d 206f 7264 2875 6368 6172 290a  de = ord(uchar).
+00001260: 2020 2020 2020 2020 2020 2020 6966 2030              if 0
+00001270: 7846 4630 3020 3c20 696e 7369 6465 5f63  xFF00 < inside_c
+00001280: 6f64 6520 6f72 2069 6e73 6964 655f 636f  ode or inside_co
+00001290: 6465 203e 2030 7846 4635 463a 0a20 2020  de > 0xFF5F:.   
+000012a0: 2020 2020 2020 2020 2020 2020 2069 6e73               ins
+000012b0: 6964 655f 636f 6465 202d 3d20 3078 4645  ide_code -= 0xFE
+000012c0: 4530 0a20 2020 2020 2020 2020 2020 2065  E0.            e
+000012d0: 6c69 6620 696e 7369 6465 5f63 6f64 6520  lif inside_code 
+000012e0: 3d3d 2030 7833 3030 303a 0a20 2020 2020  == 0x3000:.     
+000012f0: 2020 2020 2020 2020 2020 2069 6e73 6964             insid
+00001300: 655f 636f 6465 203d 2030 7830 3032 300a  e_code = 0x0020.
+00001310: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+00001320: 2069 6e73 6964 655f 636f 6465 2069 6e20   inside_code in 
+00001330: 5b0a 2020 2020 2020 2020 2020 2020 2020  [.              
+00001340: 2020 2020 2020 3078 3330 3144 2c20 3078        0x301D, 0x
+00001350: 3330 3145 2c20 3078 3230 3143 2c20 3078  301E, 0x201C, 0x
+00001360: 3230 3144 2c20 3078 3230 3145 2c20 3078  201D, 0x201E, 0x
+00001370: 3230 3146 0a20 2020 2020 2020 2020 2020  201F.           
+00001380: 205d 3a0a 2020 2020 2020 2020 2020 2020   ]:.            
+00001390: 2020 2020 696e 7369 6465 5f63 6f64 6520      inside_code 
+000013a0: 3d20 3078 3030 3232 0a20 2020 2020 2020  = 0x0022.       
+000013b0: 2020 2020 2065 6c69 6620 696e 7369 6465       elif inside
+000013c0: 5f63 6f64 6520 696e 205b 3078 3230 3138  _code in [0x2018
+000013d0: 2c20 3078 3230 3139 2c20 3078 3230 3141  , 0x2019, 0x201A
+000013e0: 2c20 3078 3230 3142 5d3a 0a20 2020 2020  , 0x201B]:.     
+000013f0: 2020 2020 2020 2020 2020 2069 6e73 6964             insid
+00001400: 655f 636f 6465 203d 2030 7830 3032 370a  e_code = 0x0027.
+00001410: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00001420: 726e 2063 6872 2869 6e73 6964 655f 636f  rn chr(inside_co
+00001430: 6465 290a 0a20 2020 2020 2020 2023 2052  de)..        # R
+00001440: 656d 6f76 654e 6f69 7379 4368 6172 730a  emoveNoisyChars.
+00001450: 2020 2020 2020 2020 6d5f 6e6f 6973 7943          m_noisyC
+00001460: 6861 7273 203d 2022 0102 0304 0506 0708  hars = "........
+00001470: 1412 2c2d 2b5c 225c 275c 5c26 2e21 3d3a  ..,-+\"\'\\&.!=:
+00001480: 3bc2 b0c2 b724 c2ab c2bb 7cc2 b15b 5d7b  ;....$....|..[]{
+00001490: 7d5f 3f3c 3e7e 5e2a 2f25 2340 2829 efbc  }_?<>~^*/%#@()..
+000014a0: 8ce3 8082 efbc 81e3 808a e380 8bef bc9f  ................
+000014b0: e380 8160 5c78 6332 5c78 6130 e280 a6e2  ...`\xc2\xa0....
+000014c0: 80bc efb8 8f22 0a20 2020 2020 2020 2073  .....".        s
+000014d0: 656e 7465 6e63 6520 3d20 2727 2e6a 6f69  entence = ''.joi
+000014e0: 6e28 5b0a 2020 2020 2020 2020 2020 2020  n([.            
+000014f0: 7374 7269 6e67 7061 7274 5132 4228 6329  stringpartQ2B(c)
+00001500: 2069 6620 6320 6e6f 7420 696e 206d 5f6e   if c not in m_n
+00001510: 6f69 7379 4368 6172 7320 656c 7365 2027  oisyChars else '
+00001520: 2027 0a20 2020 2020 2020 2020 2020 2066   '.            f
+00001530: 6f72 2063 2069 6e20 7365 6e74 656e 6365  or c in sentence
+00001540: 0a20 2020 2020 2020 205d 290a 2020 2020  .        ]).    
+00001550: 2020 2020 454d 4f4a 4952 4520 3d20 7265      EMOJIRE = re
+00001560: 2e63 6f6d 7069 6c65 280a 2020 2020 2020  .compile(.      
+00001570: 2020 2020 2020 275b 270a 2020 2020 2020        '['.      
+00001580: 2020 2020 2020 7527 5c55 3030 3031 4636        u'\U0001F6
+00001590: 3030 2d5c 5530 3030 3146 3634 4627 2020  00-\U0001F64F'  
+000015a0: 2320 656d 6f74 6963 6f6e 730a 2020 2020  # emoticons.    
+000015b0: 2020 2020 2020 2020 7527 5c55 3030 3031          u'\U0001
+000015c0: 4633 3030 2d5c 5530 3030 3146 3546 4627  F300-\U0001F5FF'
+000015d0: 2020 2320 7379 6d62 6f6c 7320 2620 7069    # symbols & pi
+000015e0: 6374 6f67 7261 7068 730a 2020 2020 2020  ctographs.      
+000015f0: 2020 2020 2020 7527 5c55 3030 3031 4636        u'\U0001F6
+00001600: 3830 2d5c 5530 3030 3146 3646 4627 2020  80-\U0001F6FF'  
+00001610: 2320 7472 616e 7370 6f72 7420 2620 6d61  # transport & ma
+00001620: 7020 7379 6d62 6f6c 730a 2020 2020 2020  p symbols.      
+00001630: 2020 2020 2020 7527 5c55 3030 3031 4631        u'\U0001F1
+00001640: 4530 2d5c 5530 3030 3146 3146 4627 2020  E0-\U0001F1FF'  
+00001650: 2320 666c 6167 7320 2869 4f53 290a 2020  # flags (iOS).  
+00001660: 2020 2020 2020 2020 2020 7527 5c55 3030            u'\U00
+00001670: 3031 6639 3236 2d5c 5530 3030 3166 3933  01f926-\U0001f93
+00001680: 3727 2020 2320 656d 6f6a 690a 2020 2020  7'  # emoji.    
+00001690: 2020 2020 2020 2020 7527 5c55 3030 3031          u'\U0001
+000016a0: 3030 3030 2d5c 5530 3031 3066 6666 6627  0000-\U0010ffff'
+000016b0: 2020 2320 6368 6172 2065 6d6f 6a69 0a20    # char emoji. 
+000016c0: 2020 2020 2020 2020 2020 2075 275c 5530             u'\U0
+000016d0: 3030 3032 3730 322d 5c55 3030 3030 3237  0002702-\U000027
+000016e0: 4230 2720 2023 2063 6861 7220 656d 6f6a  B0'  # char emoj
+000016f0: 690a 2020 2020 2020 2020 2020 2020 7527  i.            u'
+00001700: 5c75 3236 3430 2d5c 7532 3634 325c 7532  \u2640-\u2642\u2
+00001710: 3630 302d 5c75 3242 3535 270a 2020 2020  600-\u2B55'.    
+00001720: 2020 2020 2020 2020 7527 5c75 3230 3064          u'\u200d
+00001730: 5c75 3233 6366 5c75 3233 6539 5c75 3233  \u23cf\u23e9\u23
+00001740: 3161 5c75 6665 3066 5c75 3330 3330 2720  1a\ufe0f\u3030' 
+00001750: 2023 2064 696e 6762 6174 730a 2020 2020   # dingbats.    
+00001760: 2020 2020 2020 2020 275d 2b27 2c0a 2020          ']+',.  
+00001770: 2020 2020 2020 2020 2020 7265 2e55 4e49            re.UNI
+00001780: 434f 4445 290a 2020 2020 2020 2020 7365  CODE).        se
+00001790: 6e74 656e 6365 203d 2072 652e 7375 6228  ntence = re.sub(
+000017a0: 454d 4f4a 4952 452c 2027 272c 2073 656e  EMOJIRE, '', sen
+000017b0: 7465 6e63 6529 0a20 2020 2020 2020 2023  tence).        #
+000017c0: 2052 656d 6f76 6544 6967 6974 616c 576f   RemoveDigitalWo
+000017d0: 7264 730a 2020 2020 2020 2020 7365 6e74  rds.        sent
+000017e0: 656e 6365 203d 2027 2027 2e6a 6f69 6e28  ence = ' '.join(
+000017f0: 5b0a 2020 2020 2020 2020 2020 2020 6974  [.            it
+00001800: 656d 2066 6f72 2069 7465 6d20 696e 2073  em for item in s
+00001810: 656e 7465 6e63 652e 7370 6c69 7428 290a  entence.split().
+00001820: 2020 2020 2020 2020 2020 2020 6966 2028              if (
+00001830: 6e6f 7420 626f 6f6c 2872 652e 7365 6172  not bool(re.sear
+00001840: 6368 2872 275c 6427 2c20 6974 656d 2929  ch(r'\d', item))
+00001850: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001860: 206f 7220 6e6f 7420 626f 6f6c 2872 652e   or not bool(re.
+00001870: 6d61 7463 6828 7227 5e5b 612d 7a30 2d39  match(r'^[a-z0-9
+00001880: 2b2d 5f5d 2b24 272c 2069 7465 6d29 2929  +-_]+$', item)))
+00001890: 0a20 2020 2020 2020 205d 290a 2020 2020  .        ]).    
+000018a0: 2020 2020 2320 7265 706c 6163 6542 7261      # replaceBra
+000018b0: 6e64 576f 7264 730a 2020 2020 2020 2020  ndWords.        
+000018c0: 2320 776f 7264 436f 7272 6563 7469 6f6e  # wordCorrection
+000018d0: 0a20 2020 2020 2020 2023 2072 656d 6f76  .        # remov
+000018e0: 6553 7061 6365 730a 2020 2020 2020 2020  eSpaces.        
+000018f0: 6f75 7469 6473 203d 205b 5d0a 2020 2020  outids = [].    
+00001900: 2020 2020 666f 7220 7720 696e 2073 656e      for w in sen
+00001910: 7465 6e63 652e 7374 7269 7028 293a 0a20  tence.strip():. 
+00001920: 2020 2020 2020 2020 2020 2074 6d70 203d             tmp =
+00001930: 2073 656c 662e 766f 6361 622e 6765 7428   self.vocab.get(
+00001940: 772c 2073 656c 662e 756e 6b5f 6964 290a  w, self.unk_id).
+00001950: 2020 2020 2020 2020 2020 2020 6966 206c              if l
+00001960: 656e 286f 7574 6964 730a 2020 2020 2020  en(outids.      
+00001970: 2020 2020 2020 2020 2020 2020 2029 203e               ) >
+00001980: 2030 2061 6e64 2074 6d70 203d 3d20 7365   0 and tmp == se
+00001990: 6c66 2e75 6e6b 5f69 6420 616e 6420 6f75  lf.unk_id and ou
+000019a0: 7469 6473 5b2d 315d 203d 3d20 7365 6c66  tids[-1] == self
+000019b0: 2e75 6e6b 5f69 643a 0a20 2020 2020 2020  .unk_id:.       
+000019c0: 2020 2020 2020 2020 2063 6f6e 7469 6e75           continu
+000019d0: 650a 2020 2020 2020 2020 2020 2020 6f75  e.            ou
+000019e0: 7469 6473 2e61 7070 656e 6428 746d 7029  tids.append(tmp)
+000019f0: 0a20 2020 2020 2020 2069 6620 6c65 6e28  .        if len(
+00001a00: 6f75 7469 6473 2920 3e20 3020 616e 6420  outids) > 0 and 
+00001a10: 6f75 7469 6473 5b30 5d20 3d3d 2073 656c  outids[0] == sel
+00001a20: 662e 756e 6b5f 6964 3a0a 2020 2020 2020  f.unk_id:.      
+00001a30: 2020 2020 2020 6f75 7469 6473 203d 206f        outids = o
+00001a40: 7574 6964 735b 313a 5d0a 2020 2020 2020  utids[1:].      
+00001a50: 2020 6966 206c 656e 286f 7574 6964 7329    if len(outids)
+00001a60: 203e 2030 2061 6e64 206f 7574 6964 735b   > 0 and outids[
+00001a70: 2d31 5d20 3d3d 2073 656c 662e 756e 6b5f  -1] == self.unk_
+00001a80: 6964 3a0a 2020 2020 2020 2020 2020 2020  id:.            
+00001a90: 6f75 7469 6473 203d 206f 7574 6964 735b  outids = outids[
+00001aa0: 3a2d 315d 0a20 2020 2020 2020 2072 6574  :-1].        ret
+00001ab0: 7572 6e20 6f75 7469 6473 0a0a 2020 2020  urn outids..    
+00001ac0: 6465 6620 7072 6570 726f 6365 7373 2873  def preprocess(s
+00001ad0: 656c 662c 2069 6e70 7574 3a20 7374 7229  elf, input: str)
+00001ae0: 202d 3e20 4469 6374 5b73 7472 2c20 416e   -> Dict[str, An
+00001af0: 795d 3a0a 2020 2020 2020 2020 7365 6e74  y]:.        sent
+00001b00: 656e 6365 6c74 203d 2069 6e70 7574 2e73  encelt = input.s
+00001b10: 706c 6974 2827 5c6e 2729 0a20 2020 2020  plit('\n').     
+00001b20: 2020 2069 6e70 7574 5f69 6473 5f6c 7420     input_ids_lt 
+00001b30: 3d20 5b0a 2020 2020 2020 2020 2020 2020  = [.            
+00001b40: 7365 6c66 2e5f 6c69 645f 7072 6570 726f  self._lid_prepro
+00001b50: 6365 7373 2873 656e 7465 6e63 6529 2066  cess(sentence) f
+00001b60: 6f72 2073 656e 7465 6e63 6520 696e 2073  or sentence in s
+00001b70: 656e 7465 6e63 656c 740a 2020 2020 2020  entencelt.      
+00001b80: 2020 2020 2020 6966 2073 656e 7465 6e63        if sentenc
+00001b90: 652e 7374 7269 7028 2920 213d 2027 270a  e.strip() != ''.
+00001ba0: 2020 2020 2020 2020 5d0a 0a20 2020 2020          ]..     
+00001bb0: 2020 2023 205b 6465 6275 675d 2070 7269     # [debug] pri
+00001bc0: 6e74 2069 6e66 6f20 6578 616d 706c 653a  nt info example:
+00001bd0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00001be0: 2e64 6562 7567 3a0a 2020 2020 2020 2020  .debug:.        
+00001bf0: 2020 2020 666f 7220 7365 6e74 656e 6365      for sentence
+00001c00: 2c20 696e 7075 745f 6964 7320 696e 207a  , input_ids in z
+00001c10: 6970 2873 656e 7465 6e63 656c 742c 2069  ip(sentencelt, i
+00001c20: 6e70 7574 5f69 6473 5f6c 7429 3a0a 2020  nput_ids_lt):.  
+00001c30: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+00001c40: 696e 7428 2772 6177 3a27 2c20 7365 6e74  int('raw:', sent
+00001c50: 656e 6365 290a 2020 2020 2020 2020 2020  ence).          
+00001c60: 2020 2020 2020 7072 696e 7428 0a20 2020        print(.   
+00001c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001c80: 2027 7265 733a 272c 2027 272e 6a6f 696e   'res:', ''.join
+00001c90: 285b 0a20 2020 2020 2020 2020 2020 2020  ([.             
+00001ca0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00001cb0: 766f 6361 625f 7265 7665 7273 652e 6765  vocab_reverse.ge
+00001cc0: 7428 7769 642c 2073 656c 662e 756e 6b5f  t(wid, self.unk_
+00001cd0: 6964 292e 7265 706c 6163 6528 0a20 2020  id).replace(.   
+00001ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001cf0: 2020 2020 2020 2020 2027 3c55 4e4b 3e27           '<UNK>'
+00001d00: 2c20 2720 2729 2066 6f72 2077 6964 2069  , ' ') for wid i
+00001d10: 6e20 696e 7075 745f 6964 730a 2020 2020  n input_ids.    
+00001d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001d30: 5d29 290a 2020 2020 2020 2020 6d61 786c  ])).        maxl
+00001d40: 656e 203d 206d 6178 285b 6c65 6e28 6964  en = max([len(id
+00001d50: 7329 2066 6f72 2069 6473 2069 6e20 696e  s) for ids in in
+00001d60: 7075 745f 6964 735f 6c74 5d29 0a20 2020  put_ids_lt]).   
+00001d70: 2020 2020 2066 6f72 2069 6473 2069 6e20       for ids in 
+00001d80: 696e 7075 745f 6964 735f 6c74 3a0a 2020  input_ids_lt:.  
+00001d90: 2020 2020 2020 2020 2020 6964 732e 6578            ids.ex
+00001da0: 7465 6e64 285b 7365 6c66 2e70 6164 5f69  tend([self.pad_i
+00001db0: 645d 202a 2028 6d61 786c 656e 202d 206c  d] * (maxlen - l
+00001dc0: 656e 2869 6473 2929 290a 2020 2020 2020  en(ids))).      
+00001dd0: 2020 696e 7075 745f 6964 7320 3d20 6e70    input_ids = np
+00001de0: 2e61 7272 6179 2869 6e70 7574 5f69 6473  .array(input_ids
+00001df0: 5f6c 7429 0a0a 2020 2020 2020 2020 7265  _lt)..        re
+00001e00: 7375 6c74 203d 207b 2769 6e70 7574 5f69  sult = {'input_i
+00001e10: 6473 273a 2069 6e70 7574 5f69 6473 7d0a  ds': input_ids}.
+00001e20: 2020 2020 2020 2020 7265 7475 726e 2072          return r
+00001e30: 6573 756c 740a 0a20 2020 2064 6566 2066  esult..    def f
+00001e40: 6f72 7761 7264 2873 656c 662c 2069 6e70  orward(self, inp
+00001e50: 7574 3a20 4469 6374 5b73 7472 2c20 416e  ut: Dict[str, An
+00001e60: 795d 2920 2d3e 2044 6963 745b 7374 722c  y]) -> Dict[str,
+00001e70: 2041 6e79 5d3a 0a20 2020 2020 2020 2077   Any]:.        w
+00001e80: 6974 6820 7365 6c66 2e5f 7365 7373 696f  ith self._sessio
+00001e90: 6e2e 6173 5f64 6566 6175 6c74 2829 3a0a  n.as_default():.
+00001ea0: 2020 2020 2020 2020 2020 2020 6665 6564              feed
+00001eb0: 5f64 6963 7420 3d20 7b73 656c 662e 696e  _dict = {self.in
+00001ec0: 7075 745f 6964 733a 2069 6e70 7574 5b27  put_ids: input['
+00001ed0: 696e 7075 745f 6964 7327 5d7d 0a20 2020  input_ids']}.   
+00001ee0: 2020 2020 2020 2020 2073 6573 735f 6f75           sess_ou
+00001ef0: 7470 7574 7320 3d20 7365 6c66 2e5f 7365  tputs = self._se
+00001f00: 7373 696f 6e2e 7275 6e28 7365 6c66 2e6f  ssion.run(self.o
+00001f10: 7574 7075 742c 2066 6565 645f 6469 6374  utput, feed_dict
+00001f20: 3d66 6565 645f 6469 6374 290a 2020 2020  =feed_dict).    
+00001f30: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00001f40: 6573 735f 6f75 7470 7574 730a 0a20 2020  ess_outputs..   
+00001f50: 2064 6566 2070 6f73 7470 726f 6365 7373   def postprocess
+00001f60: 2873 656c 662c 2069 6e70 7574 733a 2044  (self, inputs: D
+00001f70: 6963 745b 7374 722c 2041 6e79 5d29 202d  ict[str, Any]) -
+00001f80: 3e20 4469 6374 5b73 7472 2c20 416e 795d  > Dict[str, Any]
+00001f90: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
+00001fa0: 5f73 636f 7265 735f 7261 7720 3d20 696e  _scores_raw = in
+00001fb0: 7075 7473 5b27 6f75 7470 7574 5f73 636f  puts['output_sco
+00001fc0: 7265 275d 0a0a 2020 2020 2020 2020 7375  re']..        su
+00001fd0: 7070 6f72 7465 645f 3130 345f 6c61 6e67  pported_104_lang
+00001fe0: 203d 2073 6574 285b 0a20 2020 2020 2020   = set([.       
+00001ff0: 2020 2020 2027 6166 272c 2027 616d 272c       'af', 'am',
+00002000: 2027 6172 272c 2027 617a 272c 2027 6265   'ar', 'az', 'be
+00002010: 272c 2027 6267 272c 2027 626e 272c 2027  ', 'bg', 'bn', '
+00002020: 6273 272c 2027 6361 272c 2027 6365 272c  bs', 'ca', 'ce',
+00002030: 2027 636f 272c 0a20 2020 2020 2020 2020   'co',.         
+00002040: 2020 2027 6373 272c 2027 6379 272c 2027     'cs', 'cy', '
+00002050: 6461 272c 2027 6465 272c 2027 656c 272c  da', 'de', 'el',
+00002060: 2027 656e 272c 2027 656f 272c 2027 6573   'en', 'eo', 'es
+00002070: 272c 2027 6574 272c 2027 6575 272c 2027  ', 'et', 'eu', '
+00002080: 6661 272c 0a20 2020 2020 2020 2020 2020  fa',.           
+00002090: 2027 6669 272c 2027 6672 272c 2027 6679   'fi', 'fr', 'fy
+000020a0: 272c 2027 6761 272c 2027 6764 272c 2027  ', 'ga', 'gd', '
+000020b0: 676c 272c 2027 6775 272c 2027 6861 272c  gl', 'gu', 'ha',
+000020c0: 2027 6861 7727 2c20 2768 6527 2c20 2768   'haw', 'he', 'h
+000020d0: 6927 2c0a 2020 2020 2020 2020 2020 2020  i',.            
+000020e0: 2768 6d6e 272c 2027 6872 272c 2027 6874  'hmn', 'hr', 'ht
+000020f0: 272c 2027 6875 272c 2027 6879 272c 2027  ', 'hu', 'hy', '
+00002100: 6964 272c 2027 6967 272c 2027 6973 272c  id', 'ig', 'is',
+00002110: 2027 6974 272c 2027 6a61 272c 2027 6a76   'it', 'ja', 'jv
+00002120: 272c 0a20 2020 2020 2020 2020 2020 2027  ',.            '
+00002130: 6b61 272c 2027 6b6b 272c 2027 6b6d 272c  ka', 'kk', 'km',
+00002140: 2027 6b6e 272c 2027 6b6f 272c 2027 6b75   'kn', 'ko', 'ku
+00002150: 272c 2027 6b79 272c 2027 6c61 272c 2027  ', 'ky', 'la', '
+00002160: 6c6f 272c 2027 6c74 272c 2027 6c76 272c  lo', 'lt', 'lv',
+00002170: 0a20 2020 2020 2020 2020 2020 2027 6d67  .            'mg
+00002180: 272c 2027 6d69 272c 2027 6d6b 272c 2027  ', 'mi', 'mk', '
+00002190: 6d6c 272c 2027 6d6e 272c 2027 6d72 272c  ml', 'mn', 'mr',
+000021a0: 2027 6d73 272c 2027 6d74 272c 2027 6d79   'ms', 'mt', 'my
+000021b0: 272c 2027 6e65 272c 2027 6e6c 272c 0a20  ', 'ne', 'nl',. 
+000021c0: 2020 2020 2020 2020 2020 2027 6e6f 272c             'no',
+000021d0: 2027 6e79 272c 2027 7061 272c 2027 706c   'ny', 'pa', 'pl
+000021e0: 272c 2027 7073 272c 2027 7074 272c 2027  ', 'ps', 'pt', '
+000021f0: 726f 272c 2027 7275 272c 2027 7364 272c  ro', 'ru', 'sd',
+00002200: 2027 7369 272c 2027 736b 272c 0a20 2020   'si', 'sk',.   
+00002210: 2020 2020 2020 2020 2027 736c 272c 2027           'sl', '
+00002220: 736d 272c 2027 736e 272c 2027 736f 272c  sm', 'sn', 'so',
+00002230: 2027 7371 272c 2027 7372 272c 2027 7374   'sq', 'sr', 'st
+00002240: 272c 2027 7375 272c 2027 7376 272c 2027  ', 'su', 'sv', '
+00002250: 7377 272c 2027 7461 272c 0a20 2020 2020  sw', 'ta',.     
+00002260: 2020 2020 2020 2027 7465 272c 2027 7467         'te', 'tg
+00002270: 272c 2027 7468 272c 2027 746c 272c 2027  ', 'th', 'tl', '
+00002280: 7472 272c 2027 7567 272c 2027 756b 272c  tr', 'ug', 'uk',
+00002290: 2027 7572 272c 2027 757a 272c 2027 7669   'ur', 'uz', 'vi
+000022a0: 272c 2027 7868 272c 0a20 2020 2020 2020  ', 'xh',.       
+000022b0: 2020 2020 2027 7969 272c 2027 796f 272c       'yi', 'yo',
+000022c0: 2027 7a68 272c 2027 7a68 2d74 7727 2c20   'zh', 'zh-tw', 
+000022d0: 277a 7527 0a20 2020 2020 2020 205d 290a  'zu'.        ]).
+000022e0: 2020 2020 2020 2020 6c61 6265 6c73 5f73          labels_s
+000022f0: 636f 7265 735f 6c74 203d 205b 5d0a 2020  cores_lt = [].  
+00002300: 2020 2020 2020 6f75 7470 7574 5f6c 6162        output_lab
+00002310: 656c 7320 3d20 5b5d 0a20 2020 2020 2020  els = [].       
+00002320: 2066 6f72 206f 7574 7075 745f 7363 6f72   for output_scor
+00002330: 6520 696e 206f 7574 7075 745f 7363 6f72  e in output_scor
+00002340: 6573 5f72 6177 3a0a 2020 2020 2020 2020  es_raw:.        
+00002350: 2020 2020 746d 706c 7420 3d20 5b5d 0a20      tmplt = []. 
+00002360: 2020 2020 2020 2020 2020 2066 6f72 2073             for s
+00002370: 2c20 6c20 696e 207a 6970 286f 7574 7075  , l in zip(outpu
+00002380: 745f 7363 6f72 652c 2073 656c 662e 6c61  t_score, self.la
+00002390: 6265 6c2e 7661 6c75 6573 2829 293a 0a20  bel.values()):. 
+000023a0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+000023b0: 6620 6c20 6e6f 7420 696e 2073 7570 706f  f l not in suppo
+000023c0: 7274 6564 5f31 3034 5f6c 616e 673a 0a20  rted_104_lang:. 
+000023d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000023e0: 2020 2063 6f6e 7469 6e75 650a 2020 2020     continue.    
+000023f0: 2020 2020 2020 2020 2020 2020 746d 706c              tmpl
+00002400: 742e 6170 7065 6e64 2828 6c2c 2073 2929  t.append((l, s))
+00002410: 0a20 2020 2020 2020 2020 2020 2074 6d70  .            tmp
+00002420: 6c74 203d 2073 6f72 7465 6428 746d 706c  lt = sorted(tmpl
+00002430: 742c 206b 6579 3d6c 616d 6264 6120 693a  t, key=lambda i:
+00002440: 2069 5b31 5d2c 2072 6576 6572 7365 3d54   i[1], reverse=T
+00002450: 7275 6529 5b3a 335d 0a20 2020 2020 2020  rue)[:3].       
+00002460: 2020 2020 2069 6620 6c65 6e28 746d 706c       if len(tmpl
+00002470: 7429 203d 3d20 303a 0a20 2020 2020 2020  t) == 0:.       
+00002480: 2020 2020 2020 2020 2074 6d70 6c74 203d           tmplt =
+00002490: 205b 2830 2c20 312e 3030 295d 0a20 2020   [(0, 1.00)].   
+000024a0: 2020 2020 2020 2020 206c 6162 656c 735f           labels_
+000024b0: 7363 6f72 6573 5f6c 742e 6170 7065 6e64  scores_lt.append
+000024c0: 2874 6d70 6c74 290a 2020 2020 2020 2020  (tmplt).        
+000024d0: 2020 2020 6f75 7470 7574 5f6c 6162 656c      output_label
+000024e0: 732e 6170 7065 6e64 2874 6d70 6c74 5b30  s.append(tmplt[0
+000024f0: 5d5b 305d 290a 2020 2020 2020 2020 6f75  ][0]).        ou
+00002500: 7470 7574 5f73 636f 7265 7320 3d20 5b5b  tput_scores = [[
+00002510: 286c 6162 656c 2c20 726f 756e 6428 7363  (label, round(sc
+00002520: 6f72 652c 2032 2929 0a20 2020 2020 2020  ore, 2)).       
+00002530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002540: 2020 2066 6f72 206c 6162 656c 2c20 7363     for label, sc
+00002550: 6f72 6520 696e 206c 6162 656c 735f 7363  ore in labels_sc
+00002560: 6f72 6573 2069 6620 7363 6f72 6520 3e20  ores if score > 
+00002570: 302e 3031 5d0a 2020 2020 2020 2020 2020  0.01].          
+00002580: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00002590: 6f72 206c 6162 656c 735f 7363 6f72 6573  or labels_scores
+000025a0: 2069 6e20 6c61 6265 6c73 5f73 636f 7265   in labels_score
+000025b0: 735f 6c74 5d0a 0a20 2020 2020 2020 2072  s_lt]..        r
+000025c0: 6573 756c 7420 3d20 7b0a 2020 2020 2020  esult = {.      
+000025d0: 2020 2020 2020 4f75 7470 7574 4b65 7973        OutputKeys
+000025e0: 2e4c 4142 454c 533a 206f 7574 7075 745f  .LABELS: output_
+000025f0: 6c61 6265 6c73 2c0a 2020 2020 2020 2020  labels,.        
+00002600: 2020 2020 4f75 7470 7574 4b65 7973 2e53      OutputKeys.S
+00002610: 434f 5245 533a 206f 7574 7075 745f 7363  CORES: output_sc
+00002620: 6f72 6573 0a20 2020 2020 2020 207d 0a20  ores.        }. 
+00002630: 2020 2020 2020 2072 6574 7572 6e20 7265         return re
+00002640: 7375 6c74 0a                             sult.
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/siamese_uie_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/siamese_uie_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,31 +1,29 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import logging
 import os
 import pathlib
 from copy import deepcopy
 from math import ceil
 from time import time
 from typing import Any, Dict, Generator, List, Mapping, Optional, Union
 
 import json
 import torch
 from scipy.special import softmax
 from torch.cuda.amp import autocast
 from tqdm import tqdm
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.msdatasets import MsDataset
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor, SiameseUiePreprocessor
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.msdatasets import MsDataset
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor, SiameseUiePreprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
 Input = Union[str, tuple, MsDataset, 'Image.Image', 'numpy.ndarray']
 
 logger = logging.getLogger(__name__)
 
 os.environ['TOKENIZERS_PARALLELISM'] = 'true'
 
@@ -44,21 +42,21 @@
                  auto_collate=True,
                  **kwargs):
         """Use `model` and `preprocessor` to create a generation pipeline for prediction.
 
         Args:
             model (str or Model): Supply either a local model dir which supported the text generation task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline(Tasks.siamese_uie,
             >>>    model='damo/nlp_structbert_siamese-uie_chinese-base')
             >>> sentence = '19442.769'
             >>> print(pipeline_ins(sentence, schema={'': None, '': None, '': None}))
 
             To view other examples plese check tests/pipelines/test_siamese_uie.py.
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/summarization_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/distributed_gpt3_pipeline.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,66 +1,64 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Pipelines, Preprocessors
-from modelscope.pipelines.base import Model, Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import Fields, Tasks
-from modelscope.utils.logger import get_logger
-
-logger = get_logger()
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.nlp import DistributedGPT3
+from weathon.pipelines.base import DistributedPipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import TextGenerationJiebaPreprocessor
+from weathon.utils.constants import Tasks
 
 
 @PIPELINES.register_module(
-    Tasks.text_summarization, module_name=Pipelines.text_generation)
-class SummarizationPipeline(Pipeline):
+    Tasks.text_generation, module_name=Pipelines.gpt3_generation)
+class DistributedGPT3Pipeline(DistributedPipeline):
+    """This class is used to instantiate the gpt3 model.
+    """
+
+    model = None
 
-    def __init__(self,
-                 model: Union[Model, str],
-                 preprocessor: Optional[Preprocessor] = None,
-                 config_file: str = None,
-                 device: str = 'gpu',
-                 auto_collate=True,
-                 **kwargs):
-        """Use `model` and `preprocessor` to create a Summarization pipeline for prediction.
+    def __init__(self, model, preprocessor=None, **kwargs):
+        """
 
         Args:
-            model (str or Model): Supply either a local model dir which supported the summarization task,
-            or a model id from the model hub, or a model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance.
+            model: The model piece, str is not supported.
+            preprocessor: The preprocessor matched with the model.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
         """
-        super().__init__(
-            model=model,
-            preprocessor=preprocessor,
-            config_file=config_file,
-            device=device,
-            auto_collate=auto_collate)
-        self.model.eval()
         if preprocessor is None:
-            if self.model.__class__.__name__ == 'OfaForAllTasks':
-                self.preprocessor = Preprocessor.from_pretrained(
-                    self.model.model_dir,
-                    type=Preprocessors.ofa_tasks_preprocessor,
-                    field=Fields.multi_modal)
-            else:
-                self.preprocessor = Preprocessor.from_pretrained(
-                    self.model.model_dir, **kwargs)
-
-    def _batch(self, data):
-        if self.model.__class__.__name__ == 'OfaForAllTasks':
-            return batch_process(self.model, data)
-        else:
-            return super(SummarizationPipeline, self)._batch(data)
-
-    def forward(self, inputs: Dict[str, Any],
-                **forward_params) -> Dict[str, Any]:
-        with torch.no_grad():
-            return super().forward(inputs, **forward_params)
+            preprocessor = TextGenerationJiebaPreprocessor(model)
+        super().__init__(model, preprocessor=preprocessor, **kwargs)
+        assert hasattr(preprocessor, 'tokenizer')
+
+    @classmethod
+    def _instantiate_one(cls, rank, model_dir, **kwargs):
+        cls.model = DistributedGPT3(model_dir, rank, **kwargs)
+        cls.model.eval()
+
+    @classmethod
+    def _forward_one(cls, inputs: Dict[str, Any]) -> Dict[str, Any]:
+        tokens = inputs['inputs']['input_ids'].cuda(
+            torch.cuda.current_device())
+        return cls.model.generate(tokens, **inputs['forward_params'])
+
+    def postprocess(self, inputs: Dict[str, Any],
+                    **postprocess_params) -> Dict[str, str]:
+        """process the prediction results
+
+        Args:
+            inputs (Dict[str, Any]): _description_
+
+        Returns:
+            Dict[str, str]: the prediction results
+        """
+        from weathon.outputs import OutputKeys
+        return {
+            OutputKeys.TEXT:
+            self.preprocessor.tokenizer.detokenize(
+                inputs.sequences[0].tolist())
+        }
 
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        return inputs
+    def _sanitize_parameters(self, **pipeline_parameters):
+        return {}, pipeline_parameters, {}
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/table_question_answering_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/table_question_answering_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict, Union
 
 import json
 import torch
 from transformers import BertTokenizer
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import TableQuestionAnswering
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import TableQuestionAnsweringPreprocessor
-from modelscope.preprocessors.nlp.space_T_cn.fields.database import Database
-from modelscope.preprocessors.nlp.space_T_cn.fields.struct import (Constant,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.models.nlp import TableQuestionAnswering
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import TableQuestionAnsweringPreprocessor
+from weathon.preprocessors.nlp.space_T_cn.fields.database import Database
+from weathon.preprocessors.nlp.space_T_cn.fields.struct import (Constant,
                                                                    SQLQuery)
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['TableQuestionAnsweringPipeline']
 
 
 @PIPELINES.register_module(
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/text_classification_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/text_classification_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,22 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines, Preprocessors
-from modelscope.models.base import Model
-from modelscope.outputs import OutputKeys, TextClassificationModelOutput
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.util import batch_process
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import Fields, ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines, Preprocessors
+from weathon.base import BaseModel
+from weathon.outputs import OutputKeys, TextClassificationModelOutput
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.pipelines.util import batch_process
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import Fields, ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PIPELINES.register_module(
     Tasks.text_classification, module_name=Pipelines.sentiment_analysis)
 @PIPELINES.register_module(Tasks.nli, module_name=Pipelines.nli)
@@ -46,15 +45,15 @@
             model (`str` or `Model` or module instance): A model instance or a model local dir
                 or a model id in the model hub.
             preprocessor (`Preprocessor`, `optional`): A Preprocessor instance.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('text-classification',
                 model='damo/nlp_structbert_sentence-similarity_chinese-base')
             >>> input = ('', '')
             >>> print(pipeline_ins(input))
         """
         super().__init__(
             model=model,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/text_error_correction_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/translation_evaluation_pipeline.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,89 +1,110 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from typing import Any, Dict, Optional, Union
+import os.path as osp
+from typing import Any, Dict, List, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.models.nlp import BartForTextErrorCorrection
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.models.nlp.backbone.unite import InputFormat
+from weathon.pipelines.base import InputModel, Pipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
+
+logger = get_logger()
 
-__all__ = ['TextErrorCorrectionPipeline']
+__all__ = ['TranslationEvaluationPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.text_error_correction, module_name=Pipelines.text_error_correction)
-class TextErrorCorrectionPipeline(Pipeline):
+    Tasks.translation_evaluation, module_name=Pipelines.translation_evaluation)
+class TranslationEvaluationPipeline(Pipeline):
 
     def __init__(self,
-                 model: Union[Model, str],
+                 model: InputModel,
                  preprocessor: Optional[Preprocessor] = None,
-                 config_file: str = None,
+                 input_format: InputFormat = InputFormat.SRC_REF,
                  device: str = 'gpu',
-                 auto_collate=True,
                  **kwargs):
-        """
-        Use `model` and `preprocessor` to create a nlp text correction pipeline.
+        r"""Build a translation evaluation pipeline with a model dir or a model id in the model hub.
 
         Args:
-            model (BartForTextErrorCorrection): A model instance, or a model local dir, or a model id in the model hub.
-            preprocessor (TextErrorCorrectionPreprocessor): An optional preprocessor instance.
-            kwargs (dict, `optional`):
-                Extra kwargs passed into the preprocessor's constructor.
-
-        Examples:
-            >>> from modelscope.pipelines import pipeline
-            >>> pipeline_ins = pipeline(
-            >>>    task='text-error-correction', model='damo/nlp_bart_text-error-correction_chinese')
-            >>> sentence1 = ''
-            >>> print(pipeline_ins(sentence1))
-
-        To view other examples plese check tests/pipelines/test_text_error_correction.py.
+            model: A Model instance.
+            preprocessor: The preprocessor for this pipeline.
+            input_format: Input format, choosing one from `"InputFormat.SRC_REF"`,
+                `"InputFormat.SRC"`, `"InputFormat.REF"`. Aside from hypothesis, the
+                source/reference/source+reference can be presented during evaluation.
+            device: Used device for this pipeline.
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
-            config_file=config_file,
-            device=device,
-            auto_collate=auto_collate)
+            compile=kwargs.pop('compile', False),
+            compile_options=kwargs.pop('compile_options', {}))
+
+        self.input_format = input_format
+        self.checking_input_format()
         assert isinstance(self.model, Model), \
             f'please check whether model config exists in {ModelFile.CONFIGURATION}'
-        if preprocessor is None:
-            self.preprocessor = Preprocessor.from_pretrained(
-                self.model.model_dir, **kwargs)
-        self.vocab = self.preprocessor.vocab
-
-    def forward(self, inputs: Dict[str, Any],
-                **forward_params) -> Dict[str, Any]:
-        with torch.no_grad():
-            return super().forward(inputs, **forward_params)
 
-    def postprocess(self, inputs: Dict[str, Tensor],
-                    **postprocess_params) -> Dict[str, str]:
-        """
+        self.model.load_checkpoint(
+            osp.join(self.model.model_dir, ModelFile.TORCH_MODEL_BIN_FILE),
+            device=self.device,
+            plm_only=False)
+        self.model.eval()
+
+        return
+
+    def checking_input_format(self):
+        if self.input_format == InputFormat.SRC:
+            logger.info('Evaluation mode: source-only')
+        elif self.input_format == InputFormat.REF:
+            logger.info('Evaluation mode: reference-only')
+        elif self.input_format == InputFormat.SRC_REF:
+            logger.info('Evaluation mode: source-reference-combined')
+        else:
+            raise ValueError('Evaluation mode should be one choice among'
+                             '\'InputFormat.SRC\', \'InputFormat.REF\', and'
+                             '\'InputFormat.SRC_REF\'.')
+
+    def change_input_format(self,
+                            input_format: InputFormat = InputFormat.SRC_REF):
+        logger.info('Changing the evaluation mode.')
+        self.input_format = input_format
+        self.checking_input_format()
+        self.preprocessor.change_input_format(input_format)
+        return
+
+    def __call__(self, input_dict: Dict[str, Union[str, List[str]]], **kwargs):
+        r"""Implementation of __call__ function.
+
         Args:
-            inputs (Dict[str, Tensor])
-            Examples:
-                {
-                    'predictions': Tensor([1377, 4959, 2785, 6392...]), # tokens need to be decode by tokenizer
+            input: The formatted dict containing the inputted sentences.
+            An example of the formatted dict:
+                ```
+                input = {
+                    'hyp': [
+                        'This is a sentence.',
+                        'This is another sentence.',
+                    ],
+                    'src': [
+                        '',
+                        '',
+                    ],
+                    'ref': [
+                        'It is a sentence.',
+                        'It is another sentence.',
+                    ]
                 }
-        Returns:
-            Dict[str, str]: which contains following:
-                - 'output': output str, for example ''
-
+                ```
         """
+        return super().__call__(input=input_dict, **kwargs)
 
-        sc_tensor = inputs['predictions']
-        if isinstance(sc_tensor, list):
-            sc_tensor = sc_tensor[0]
-        sc_sent = self.vocab.string(
-            sc_tensor, extra_symbols_to_ignore={self.vocab.pad()})
-        sc_sent = (sc_sent + ' ').replace('##', '').rstrip()
-        sc_sent = ''.join(sc_sent.split())
+    def forward(
+            self, input_dict: Dict[str,
+                                   torch.Tensor]) -> Dict[str, torch.Tensor]:
+        return self.model(**input_dict)
 
-        return {OutputKeys.OUTPUT: sc_sent}
+    def postprocess(self, output: torch.Tensor) -> Dict[str, Any]:
+        return output
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/text_generation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/text_generation_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict, Optional, Union
 
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.outputs import (ModelOutputBase, OutputKeys,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.outputs import (ModelOutputBase, OutputKeys,
                                 TokenGeneratorOutput)
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.chinese_utils import remove_space_between_chinese_chars
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.hub import Config, read_config
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.chinese_utils import remove_space_between_chinese_chars
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.hub import Config, read_config
 
 __all__ = ['TextGenerationPipeline', 'TextGenerationT5Pipeline']
 
 
 @PIPELINES.register_module(
     Tasks.text_generation, module_name=Pipelines.text_generation)
 class TextGenerationPipeline(Pipeline):
@@ -32,21 +30,21 @@
                  first_sequence='sentence',
                  **kwargs):
         """Use `model` and `preprocessor` to create a generation pipeline for prediction.
 
         Args:
             model (str or Model): Supply either a local model dir which supported the text generation task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline(task='text-generation',
             >>>    model='damo/nlp_palm2.0_text-generation_chinese-base')
             >>> sentence1 = ''
             >>>     '1.2.3.4.'
             >>> print(pipeline_ins(sentence1))
             >>> # Or use the dict input:
             >>> print(pipeline_ins({'sentence': sentence1}))
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/text_ranking_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/text_ranking_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Optional, Union
 
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import (Preprocessor,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import (Preprocessor,
                                       TextRankingTransformersPreprocessor)
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['TextRankingPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.text_ranking, module_name=Pipelines.text_ranking)
 class TextRankingPipeline(Pipeline):
@@ -29,15 +27,15 @@
                  sequence_length=128,
                  **kwargs):
         """Use `model` and `preprocessor` to create a nlp word segment pipeline for prediction.
 
         Args:
             model (str or Model): Supply either a local model dir which supported the WS task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/token_classification_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/token_classification_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, List, Optional, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.tensor_utils import (torch_nested_detach,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.tensor_utils import (torch_nested_detach,
                                            torch_nested_numpify)
 
 __all__ = ['TokenClassificationPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.token_classification, module_name=Pipelines.token_classification)
@@ -38,15 +36,15 @@
                  auto_collate=True,
                  sequence_length=512,
                  **kwargs):
         """use `model` and `preprocessor` to create a token classification pipeline for prediction
 
         Args:
             model (str or Model): A model instance or a model local dir or a model id in the model hub.
-            preprocessor (Preprocessor): a preprocessor instance, must not be None.
+            preprocessor (BasePreprocessor): a preprocessor instance, must not be None.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
         """
         super().__init__(
             model=model,
             preprocessor=preprocessor,
             config_file=config_file,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/translation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/translation_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict
 
 import jieba
 import numpy as np
 import tensorflow as tf
 from sacremoses import MosesDetokenizer, MosesPunctNormalizer, MosesTokenizer
 from subword_nmt import apply_bpe
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
     tf.disable_eager_execution()
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/translation_quality_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/translation_quality_estimation_pipeline.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 import os
 from typing import Any, Dict
 
 import torch
 from transformers import XLMRobertaTokenizer
 
-from modelscope.metainfo import Pipelines
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['TranslationQualityEstimationPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.sentence_similarity,
     module_name=Pipelines.translation_quality_estimation)
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/user_satisfaction_estimation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/user_satisfaction_estimation_pipeline.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import DialogueClassificationUsePreprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import DialogueClassificationUsePreprocessor
+from weathon.utils.constants import Tasks
 
 __all__ = ['UserSatisfactionEstimationPipeline']
 
 
 @PIPELINES.register_module(
     group_key=Tasks.text_classification,
     module_name=Pipelines.user_satisfaction_estimation)
@@ -34,15 +32,15 @@
             model (str or Model): Supply either a local model dir which supported user satisfaction estimation task, or
             a model id from the model hub, or a torch model instance.
             preprocessor (DialogueClassificationUsePreprocessor): An optional preprocessor instance.
             device (str): device str, should be either cpu, cuda, gpu, gpu:X or cuda:X
             auto_collate (bool): automatically to convert data to tensor or not.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline('text-classification',
                 model='damo/nlp_user-satisfaction-estimation_chinese')
             >>> input = [('|||', '|||', '|||',
                        '|||')]
             >>> print(pipeline_ins(input))
         """
         super().__init__(
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/word_alignment_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/word_alignment_pipeline.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,20 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+from typing import Any, Dict, Union
 
-from typing import Any, Dict, Optional, Union
-
-import numpy as np
-
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import WordAlignmentPreprocessor
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import WordAlignmentPreprocessor
+from weathon.utils.constants import Tasks
 
 __all__ = ['WordAlignmentPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.word_alignment, module_name=Pipelines.word_alignment)
 class WordAlignmentPipeline(Pipeline):
@@ -27,20 +23,20 @@
                  auto_collate=True,
                  sequence_length=128,
                  **kwargs):
         """Use `model` and `preprocessor` to create a nlp text dual encoder then generates the text representation.
         Args:
             model (str or Model): Supply either a local model dir which supported the WS task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): A WordAlignmentPreprocessor.
+            preprocessor (BasePreprocessor): A WordAlignmentPreprocessor.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
          Example:
-            >>> from modelscope.pipelines import pipeline
-            >>> from modelscope.utils.constant import Tasks
+            >>> from weathon.pipelines import pipeline
+            >>> from weathon.utils.constants import Tasks
             >>> model_id = 'damo/Third-Party-Supervised-Word-Aligner-mBERT-base-zhen'
             >>> input = {"sentence_pair": '     ||| pele promotes autobiography in mexico .'}
             >>> pipeline_ins = pipeline(Tasks.word_alignment, model=model_id)
             >>> print(pipeline_ins(input)['output'])
         """
         super().__init__(
             model=model,
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/word_segmentation_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/word_segmentation_pipeline.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,39 +1,31 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Optional, Union
 
-import torch
-
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.nlp import TokenClassificationPipeline
-from modelscope.preprocessors import (
-    Preprocessor, TokenClassificationTransformersPreprocessor,
-    WordSegmentationPreprocessorThai)
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.tensor_utils import (torch_nested_detach,
-                                           torch_nested_numpify)
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.registry import PIPELINES
+from weathon.pipelines.nlp import TokenClassificationPipeline
+from weathon.preprocessors import (
+    Preprocessor, WordSegmentationPreprocessorThai)
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['WordSegmentationPipeline', 'WordSegmentationThaiPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.word_segmentation, module_name=Pipelines.word_segmentation)
 class WordSegmentationPipeline(TokenClassificationPipeline):
     """Use `model` and `preprocessor` to create a nlp word segment pipeline for prediction.
 
     NOTE: The preprocessor will first split the sentence into single characters,
     then feed them into the tokenizer with the parameter is_split_into_words=True.
 
     Examples:
-        >>> from modelscope.pipelines import pipeline
+        >>> from weathon.pipelines import pipeline
         >>> pipeline_ins = pipeline(task='word-segmentation',
         >>>    model='damo/nlp_structbert_word-segmentation_chinese-base')
         >>> sentence1 = ''
         >>> print(pipeline_ins(sentence1))
 
     To view other examples plese check tests/pipelines/test_word_segmentation.py.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/nlp/zero_shot_classification_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/nlp/zero_shot_classification_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Union
 
 import torch
 from scipy.special import softmax
 
-from modelscope.metainfo import Pipelines
-from modelscope.models import Model
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor
-from modelscope.utils.constant import ModelFile, Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models import Model
+from weathon.outputs import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor
+from weathon.utils.constants import ModelFile, Tasks
 
 __all__ = ['ZeroShotClassificationPipeline']
 
 
 @PIPELINES.register_module(
     Tasks.zero_shot_classification,
     module_name=Pipelines.zero_shot_classification)
@@ -41,21 +39,21 @@
         Then feed these sentences into the model and turn the task to a NLI task(entailment, contradiction),
         and compare the output logits to give the original classification label.
 
 
         Args:
             model (str or Model): Supply either a local model dir which supported the task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
             kwargs (dict, `optional`):
                 Extra kwargs passed into the preprocessor's constructor.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline(task='zero-shot-classification',
             >>>    model='damo/nlp_structbert_zero-shot-classification_chinese-base')
             >>> sentence1 = ' 20'
             >>> labels = ['', '', '', '', '', '', '', '', '']
             >>> template = '{}'
             >>> print(pipeline_ins(sentence1, candidate_labels=labels, hypothesis_template=template))
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/pipeline_template.py` & `weathon-0.0.0.14/weathon/pipelines/pipeline_template.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 import numpy as np
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base.base_model import Model
-from modelscope.outputs.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.models.base.base_model import Model
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.base import BasePipeline
+from weathon.registry import PIPELINES
+from weathon.utils.constants import Tasks
 
 __all__ = ['PipelineTemplate']
 
 
 @PIPELINES.register_module(
     Tasks.task_template, module_name=Pipelines.pipeline_template)
 class PipelineTemplate(Pipeline):
```

### Comparing `weathon-0.0.0.13/weathon/dl/pipelines/science/protein_structure_pipeline.py` & `weathon-0.0.0.14/weathon/pipelines/science/protein_structure_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,32 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
-import time
-from typing import Any, Dict, List, Optional, Union
+from typing import Any, Dict, Optional, Union
 
 import json
 import numpy as np
 import torch
 from unicore.utils import tensor_tree_map
 
-from modelscope.metainfo import Pipelines
-from modelscope.models.base import Model
-from modelscope.models.science.unifold.config import model_config
-from modelscope.models.science.unifold.data import protein, residue_constants
-from modelscope.models.science.unifold.dataset import (UnifoldDataset,
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.base import BaseModel
+from weathon.models.science.unifold.config import model_config
+from weathon.models.science.unifold.data import protein, residue_constants
+from weathon.models.science.unifold.dataset import (UnifoldDataset,
                                                        load_and_process)
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.base import Pipeline, Tensor
-from modelscope.pipelines.builder import PIPELINES
-from modelscope.preprocessors import Preprocessor, build_preprocessor
-from modelscope.utils.constant import Fields, Frameworks, Tasks
-from modelscope.utils.device import device_placement
-from modelscope.utils.hub import read_config
-from modelscope.utils.logger import get_logger
+from weathon.base import BasePipeline, Tensor
+from weathon.registry import PIPELINES
+from weathon.preprocessors import Preprocessor, build_preprocessor
+from weathon.utils.constants import Fields, Tasks
+from weathon.utils.device import device_placement
+from weathon.utils.hub.utils import read_config
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['ProteinStructurePipeline']
 
 
 def automatic_chunk_size(seq_len):
@@ -102,19 +98,19 @@
                  preprocessor: Optional[Preprocessor] = None,
                  **kwargs):
         """Use `model` and `preprocessor` to create a protein structure pipeline for prediction.
 
         Args:
             model (str or Model): Supply either a local model dir which supported the protein structure task,
             or a model id from the model hub, or a torch model instance.
-            preprocessor (Preprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
+            preprocessor (BasePreprocessor): An optional preprocessor instance, please make sure the preprocessor fits for
             the model if supplied.
 
         Examples:
-            >>> from modelscope.pipelines import pipeline
+            >>> from weathon.pipelines import pipeline
             >>> pipeline_ins = pipeline(task='protein-structure',
             >>>    model='DPTech/uni-fold-monomer')
             >>> protein = 'LILNLRGGAFVSNTQITMADKQKKFINEIQEGDLVRSYSITDETFQQNAVTSIVKHEADQLCQINFGKQHVVC'
             >>> print(pipeline_ins(protein))
 
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .base import Preprocessor
-    from .builder import PREPROCESSORS, build_preprocessor
-    from .common import Compose, ToTensor, Filter
     from .asr import WavToScp
     from .audio import LinearAECAndFbank, AudioBrainPreprocessor
     from .image import (LoadImage, load_image,
                         ImageColorEnhanceFinetunePreprocessor,
                         ImageInstanceSegmentationPreprocessor,
                         ImageDenoisePreprocessor, ImageDeblurPreprocessor)
     from .cv import (ImageClassificationMmcvPreprocessor,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/asr.py` & `weathon-0.0.0.14/weathon/preprocessors/asr.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,24 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
-from typing import Any, Dict, List, Union
+from typing import Any, Dict, Union
+
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, Frameworks
+from weathon.utils.constants.metainfo import Preprocessors
 
-from modelscope.metainfo import Preprocessors
-from modelscope.models.base import Model
-from modelscope.utils.constant import Fields, Frameworks
-from .base import Preprocessor
-from .builder import PREPROCESSORS
 
 __all__ = ['WavToScp']
 
 
-@PREPROCESSORS.register_module(
-    Fields.audio, module_name=Preprocessors.wav_to_scp)
-class WavToScp(Preprocessor):
+@PREPROCESSORS.register_module(Fields.audio, module_name=Preprocessors.wav_to_scp)
+class WavToScp(BasePreprocessor):
     """generate audio scp from wave or ark
     """
 
     def __init__(self):
         pass
 
     def __call__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/audio.py` & `weathon-0.0.0.14/weathon/preprocessors/audio.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 import os
 from typing import Any, Dict, Tuple, Union
 
 import numpy as np
 import scipy.io.wavfile as wav
 import torch
 
-from modelscope.fileio import File
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import ModeKeys, Fields
+from weathon.utils.fileio import File
 
 
-class AudioBrainPreprocessor(Preprocessor):
+class AudioBrainPreprocessor(BasePreprocessor):
     """A preprocessor takes audio file path and reads it into tensor
 
     Args:
         takes: the audio file field name
         provides: the tensor field name
         mode: process mode, default 'inference'
     """
@@ -142,15 +140,15 @@
         if self.mvn:
             feat = feat + self.shift
             feat = feat * self.scale
         return feat
 
 
 @PREPROCESSORS.register_module(Fields.audio)
-class LinearAECAndFbank(Preprocessor):
+class LinearAECAndFbank(BasePreprocessor):
     SAMPLE_RATE = 16000
 
     def __init__(self, io_config):
         import MinDAEC
         self.trunc_length = 7200 * self.SAMPLE_RATE
         self.linear_aec_delay = io_config['linear_aec_delay']
         self.feature = Feature(io_config['fbank_config'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/builder.py` & `weathon-0.0.0.14/weathon/registry/preprocessor.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,22 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from modelscope.utils.config import ConfigDict
-from modelscope.utils.constant import Fields
-from modelscope.utils.registry import Registry, build_from_cfg
+from weathon.registry.registry import Registry, build_from_cfg
+from weathon.utils.config.config import ConfigDict
 
 PREPROCESSORS = Registry('preprocessors')
 
 
-def build_preprocessor(cfg: ConfigDict,
-                       field_name: str = None,
-                       default_args: dict = None):
+def build_preprocessor(cfg: ConfigDict,task_name: str = None,default_args: dict = None):
     """ build preprocessor given model config dict
 
     Args:
         cfg (:obj:`ConfigDict`): config dict for model object.
-        field_name (str, optional):  application field name, refer to
+        task_name (str, optional):  application field name, refer to
             :obj:`Fields` for more details
         default_args (dict, optional): Default initialization arguments.
     """
-    return build_from_cfg(
-        cfg, PREPROCESSORS, group_key=field_name, default_args=default_args)
+    return build_from_cfg(cfg, PREPROCESSORS, group_key=task_name, default_args=default_args)
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/common.py` & `weathon-0.0.0.14/weathon/utils/transforms/common.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import time
 from collections.abc import Sequence
 from typing import Mapping
 
 import numpy as np
 import torch
 
-from modelscope.utils.registry import default_group
-from .builder import PREPROCESSORS, build_preprocessor
+from weathon.registry import PREPROCESSORS, build_preprocessor
+from weathon.registry.registry import default_group
 
 
 @PREPROCESSORS.register_module()
 class Compose(object):
     """Compose a data pipeline with a sequence of transforms.
     Args:
         transforms (list[dict | callable]):
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .video_super_resolution import (VideoReader)
     from .video_stabilization import (stabilization_preprocessor)
     from .mmcls_preprocessor import ImageClassificationMmcvPreprocessor
 
     from .image_quality_assessment_mos import ImageQualityAssessmentMosPreprocessor
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/action_detection_mapper.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/action_detection_mapper.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import copy
 import random
 
 import decord
 import numpy as np
 import torch
 from detectron2.data.transforms import (ExtentTransform, RandomBrightness,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/controllable_image_generation.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/controllable_image_generation.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,24 @@
 # Part of the implementation is borrowed and modified from ControlNet,
 # publicly available at https://github.com/lllyasviel/ControlNet
 
-import math
-import os
 from typing import Any, Dict
 
 import cv2
 import numpy as np
-import torch
-import torch.nn.functional as F
-from PIL import Image
-from torchvision import transforms
 
-from modelscope.metainfo import Preprocessors
-from modelscope.models.cv.controllable_image_generation.annotator.annotator import (
+from weathon.utils.constants import ModeKeys, Fields
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.models.cv.controllable_image_generation.annotator.annotator import (
     CannyDetector, HEDdetector, MidasDetector, MLSDdetector, OpenposeDetector,
     SegformerDetector, nms)
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, Fields, Invoke,
-                                       ModeKeys, Tasks)
-from modelscope.utils.type_assert import type_assert
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.preprocessors.image import load_image
+from weathon.utils.type_assert import type_assert
 
 
 def HWC3(x):
     assert x.dtype == np.uint8
     if x.ndim == 2:
         x = x[:, :, None]
     assert x.ndim == 3
@@ -127,15 +120,15 @@
 
     return detected_map
 
 
 @PREPROCESSORS.register_module(
     Fields.cv,
     module_name=Preprocessors.controllable_image_generation_preprocessor)
-class ControllableImageGenerationPreprocessor(Preprocessor):
+class ControllableImageGenerationPreprocessor(BasePreprocessor):
 
     def __init__(self, mode=ModeKeys.INFERENCE, *args, **kwargs):
         super().__init__(mode=ModeKeys.INFERENCE, *args, **kwargs)
         self.detector = build_detector(
             kwargs.get('control_type', 'hed'), kwargs.get('model_path', None),
             kwargs.get('device', 'cuda'))
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/cv2_transforms.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/cv2_transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/image_classification_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/image_classification_preprocessor.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,21 +7,20 @@
 import cv2
 import numpy as np
 import torch
 import torchvision.transforms as transforms
 from PIL import Image
 from torchvision.transforms.functional import InterpolationMode
 
-import modelscope.preprocessors.cv.cv2_transforms as cv2_transforms
-from modelscope.fileio import File
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS, build_preprocessor
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.registry import default_group
+from weathon.preprocessors.cv import cv2_transforms
+from weathon.registry.registry import default_group
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS, build_preprocessor
+from weathon.utils.constants import Fields, ModeKeys
 
 BACKEND_TORCHVISION = 'torchvision'
 BACKEND_PILLOW = 'pillow'
 BACKEND_CV2 = 'cv2'
 BACKENDS = (BACKEND_PILLOW, BACKEND_CV2, BACKEND_TORCHVISION)
 
 INTERPOLATION_STYLE = {
@@ -300,15 +299,15 @@
         raise TypeError(
             f'Expect pipeline_cfg to be dict or list or None, got {type(pipeline)}'
         )
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.image_classification_preprocessor)
-class ImageClassificationPreprocessor(Preprocessor):
+class ImageClassificationPreprocessor(BasePreprocessor):
 
     def __init__(self, *args, **kwargs):
         """image classification preprocessor in the fine-tune scenario
         """
         super().__init__(*args, **kwargs)
 
         self.training = kwargs.pop('training', True)
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/image_restoration_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/image_restoration_preprocessor.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,27 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import math
 from typing import Any, Dict
 
 import torch
 import torch.nn.functional as F
 from numpy import ndarray
 from PIL import Image
 from torchvision import transforms
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
+from weathon.utils.type_assert import type_assert
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.image_demoire_preprocessor)
-class ImageRestorationPreprocessor(Preprocessor):
+class ImageRestorationPreprocessor(BasePreprocessor):
 
     def __init__(self, pad_32, min_max_l, **kwargs):
         super().__init__(**kwargs)
 
         self.pad_32 = pad_32
         self.min_max_l = min_max_l
         self.transform_input = transforms.Compose([transforms.ToTensor()])
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/mmcls_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/mmcls_preprocessor.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,26 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import numpy as np
 from numpy import ndarray
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields
-from modelscope.utils.hub import read_config
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
+from weathon.utils.hub.utils import read_config
+from weathon.utils.type_assert import type_assert
 
 
 @PREPROCESSORS.register_module(
     Fields.cv,
     module_name=Preprocessors.image_classification_mmcv_preprocessor)
-class ImageClassificationMmcvPreprocessor(Preprocessor):
+class ImageClassificationMmcvPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir, **kwargs):
         """Preprocess the image.
 
         What this preprocessor will do:
         1. Remove the `LoadImageFromFile` preprocessor(which will be called in the pipeline).
         2. Compose and instantiate other preprocessors configured in the file.
@@ -33,15 +32,15 @@
 
         Args:
             model_dir (str): The model dir to build the preprocessor from.
         """
 
         import mmcv
         from mmcls.datasets.pipelines import Compose
-        from modelscope.models.cv.image_classification.utils import preprocess_transform
+        from weathon.models.cv.image_classification.utils import preprocess_transform
         super().__init__(**kwargs)
 
         self.config_type = 'ms_config'
         mm_config = os.path.join(model_dir, 'config.py')
         if os.path.exists(mm_config):
             cfg = mmcv.Config.fromfile(mm_config)
             cfg.model.pretrained = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/timer.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/timer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/util.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/util.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/video_stabilization.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/video_stabilization.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 # publicly available at https://github.com/Annbless/DUTCode
 
 import cv2
 import numpy as np
 import torch
 import torch.nn as nn
 
-from modelscope.preprocessors.cv import VideoReader
+from weathon.preprocessors.cv import VideoReader
 
 
 def stabilization_preprocessor(input, cfg):
     video_reader = VideoReader(input)
     inputs = []
     for frame in video_reader:
         inputs.append(np.flip(frame, axis=2))
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/cv/video_super_resolution.py` & `weathon-0.0.0.14/weathon/preprocessors/cv/video_super_resolution.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/image.py` & `weathon-0.0.0.14/weathon/preprocessors/image.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import io
 from typing import Any, Dict, Union
 
 import cv2
 import numpy as np
 import PIL
 from numpy import ndarray
 from PIL import Image, ImageOps
 
-from modelscope.fileio import File
-from modelscope.metainfo import Preprocessors
-from modelscope.utils.constant import Fields
-from modelscope.utils.type_assert import type_assert
-from .base import Preprocessor
-from .builder import PREPROCESSORS
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.utils.fileio import File
+from weathon.utils.type_assert import type_assert
 
 
 @PREPROCESSORS.register_module(Fields.cv, Preprocessors.load_image)
 class LoadImage:
     """Load an image from file or url.
     Added or updated keys are "filename", "img", "img_shape",
     "ori_shape" (same as `img_shape`), "pad_shape" (same as `img_shape`),
@@ -122,15 +121,15 @@
     """
     loader = LoadImage()
     return loader(image_path_or_url)['img']
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.object_detection_tinynas_preprocessor)
-class ObjectDetectionTinynasPreprocessor(Preprocessor):
+class ObjectDetectionTinynasPreprocessor(BasePreprocessor):
 
     def __init__(self, size_divisible=32, **kwargs):
         """Preprocess the image.
 
         What this preprocessor will do:
         1. Transpose the image matrix to make the channel the first dim.
         2. If the size_divisible is gt than 0, it will be used to pad the image.
@@ -171,15 +170,15 @@
         pad_img[:, :image.shape[1], :image.shape[2]] = image
         pad_img = np.expand_dims(pad_img, 0)
         return {'img': pad_img}
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.image_color_enhance_preprocessor)
-class ImageColorEnhanceFinetunePreprocessor(Preprocessor):
+class ImageColorEnhanceFinetunePreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """preprocess the data from the `model_dir` path
 
         Args:
             model_dir (str): model path
         """
@@ -204,26 +203,26 @@
         """
 
         return data
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.image_denoise_preprocessor)
-class ImageDenoisePreprocessor(Preprocessor):
+class ImageDenoisePreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """
 
         Args:
             model_dir (str): model path
         """
         super().__init__(*args, **kwargs)
         self.model_dir: str = model_dir
 
-        from .common import Filter
+        from weathon.utils.transforms.common import Filter
 
         # TODO: `Filter` should be moved to configurarion file of each model
         self._transforms = [Filter(reserved_keys=['input', 'target'])]
 
     def __call__(self, data: Dict[str, Any]) -> Dict[str, Any]:
         """process the raw input data
 
@@ -237,26 +236,26 @@
             data = t(data)
 
         return data
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.image_deblur_preprocessor)
-class ImageDeblurPreprocessor(Preprocessor):
+class ImageDeblurPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """
 
         Args:
             model_dir (str): model path
         """
         super().__init__(*args, **kwargs)
         self.model_dir: str = model_dir
 
-        from .common import Filter
+        from weathon.utils.transforms.common import Filter
 
         # TODO: `Filter` should be moved to configurarion file of each model
         self._transforms = [Filter(reserved_keys=['input', 'target'])]
 
     def __call__(self, data: Dict[str, Any]) -> Dict[str, Any]:
         """process the raw input data
 
@@ -271,15 +270,15 @@
 
         return data
 
 
 @PREPROCESSORS.register_module(
     Fields.cv,
     module_name=Preprocessors.image_portrait_enhancement_preprocessor)
-class ImagePortraitEnhancementPreprocessor(Preprocessor):
+class ImagePortraitEnhancementPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """
 
         Args:
             model_dir (str): model path
         """
@@ -297,30 +296,30 @@
         """
         return data
 
 
 @PREPROCESSORS.register_module(
     Fields.cv,
     module_name=Preprocessors.image_instance_segmentation_preprocessor)
-class ImageInstanceSegmentationPreprocessor(Preprocessor):
+class ImageInstanceSegmentationPreprocessor(BasePreprocessor):
 
     def __init__(self, *args, **kwargs):
         """image instance segmentation preprocessor in the fine-tune scenario
         """
 
         super().__init__(*args, **kwargs)
 
         self.training = kwargs.pop('training', True)
         self.preprocessor_train_cfg = kwargs.pop('train', None)
         self.preprocessor_test_cfg = kwargs.pop('val', None)
 
         self.train_transforms = []
         self.test_transforms = []
 
-        from modelscope.models.cv.image_instance_segmentation.datasets import \
+        from weathon.models.cv.image_instance_segmentation.datasets import \
             build_preprocess_transform
 
         if self.preprocessor_train_cfg is not None:
             if isinstance(self.preprocessor_train_cfg, dict):
                 self.preprocessor_train_cfg = [self.preprocessor_train_cfg]
             for cfg in self.preprocessor_train_cfg:
                 transform = build_preprocess_transform(cfg)
@@ -365,15 +364,15 @@
                 return None
 
         return results
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.video_summarization_preprocessor)
-class VideoSummarizationPreprocessor(Preprocessor):
+class VideoSummarizationPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """
 
         Args:
             model_dir (str): model path
         """
@@ -391,15 +390,15 @@
         """
         return data
 
 
 @PREPROCESSORS.register_module(
     Fields.cv,
     module_name=Preprocessors.image_classification_bypass_preprocessor)
-class ImageClassificationBypassPreprocessor(Preprocessor):
+class ImageClassificationBypassPreprocessor(BasePreprocessor):
 
     def __init__(self, *args, **kwargs):
         """image classification bypass preprocessor in the fine-tune scenario
         """
         super().__init__(*args, **kwargs)
 
         self.training = kwargs.pop('training', True)
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/kws.py` & `weathon-0.0.0.14/weathon/preprocessors/kws.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,33 +1,29 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict, List, Union
 
 import yaml
 
-from modelscope.metainfo import Preprocessors
-from modelscope.models.base import Model
-from modelscope.utils.constant import Fields
-from .base import Preprocessor
-from .builder import PREPROCESSORS
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BaseModel, BasePreprocessor
+from weathon.utils.constants import Fields
 
 __all__ = ['WavToLists']
 
 
-@PREPROCESSORS.register_module(
-    Fields.audio, module_name=Preprocessors.wav_to_lists)
-class WavToLists(Preprocessor):
+@PREPROCESSORS.register_module(Fields.audio, module_name=Preprocessors.wav_to_lists)
+class WavToLists(BasePreprocessor):
     """generate audio lists file from wav
     """
 
     def __init__(self):
         pass
 
-    def __call__(self, model: Model, audio_in: Union[List[str], str,
+    def __call__(self, model: BaseModel, audio_in: Union[List[str], str,
                                                      bytes]) -> Dict[str, Any]:
         """Call functions to load model and wav.
 
         Args:
             model (Model): model should be provided
             audio_in (Union[List[str], str, bytes]):
                 audio_in[0] is positive wav path, audio_in[1] is negative wav path;
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/movie_scene_segmentation/transforms.py` & `weathon-0.0.0.14/weathon/preprocessors/movie_scene_segmentation/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/multi_modal.py` & `weathon-0.0.0.14/weathon/preprocessors/multi_modal.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,47 +1,41 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os.path as osp
 import re
 from io import BytesIO
 from typing import Any, Dict, List, Tuple, Union
 
 import decord
 import json
 import numpy as np
 import torch
 from PIL import Image
 from timm.data import create_transform
 from torchvision import transforms
 from torchvision.transforms import Compose, Normalize, Resize, ToTensor
 
-from modelscope.hub.snapshot_download import snapshot_download
-from modelscope.metainfo import Preprocessors
-from modelscope.pipelines.base import Input
-from modelscope.pipelines.cv.cmdssl_video_embedding_pipeline import (
-    VCenterCrop, VCompose, VNormalize, VRescale, VToTensor)
-from modelscope.preprocessors import load_image
-from modelscope.utils.config import Config
-from modelscope.utils.constant import (Fields, Invoke, ModeKeys, ModelFile,
-                                       Tasks)
-from .base import Preprocessor
-from .builder import PREPROCESSORS
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import load_image
+from weathon.utils.config.config import Config
 from .ofa import *  # noqa
 from .ofa.utils.collate import collate_fn
 from .ofa.utils.constant import OFA_TASK_KEY_MAPPING
 
 __all__ = [
     'DiffusionImageGenerationPreprocessor', 'OfaPreprocessor',
     'MPlugPreprocessor', 'HiTeAPreprocessor', 'MplugOwlPreprocessor'
 ]
 
+from ..base import BasePreprocessor
 
-@PREPROCESSORS.register_module(
-    Fields.multi_modal,
-    module_name=Preprocessors.diffusion_image_generation_preprocessor)
-class DiffusionImageGenerationPreprocessor(Preprocessor):
+from ..registry import PREPROCESSORS
+from ..utils.constants import Fields, ModeKeys, Tasks
+
+
+@PREPROCESSORS.register_module(Fields.multi_modal,module_name=Preprocessors.diffusion_image_generation_preprocessor)
+class DiffusionImageGenerationPreprocessor(BasePreprocessor):
     """ Preprocessor the data with the combination of image and text.
         Args:
             data: process the value as an image for keys ending with 'FILE'
                 or existing in preprocessor_image_keys and pass-through the values of other keys.
 
     """
 
@@ -70,15 +64,15 @@
             else:
                 results[key.lower()] = value
         return results
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal, module_name=Preprocessors.ofa_tasks_preprocessor)
-class OfaPreprocessor(Preprocessor):
+class OfaPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  mode=ModeKeys.INFERENCE,
                  *args,
                  **kwargs):
         """preprocess the data
@@ -159,15 +153,15 @@
 
 def _convert_to_rgb(image):
     return image.convert('RGB')
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal, module_name=Preprocessors.clip_preprocessor)
-class CLIPPreprocessor(Preprocessor):
+class CLIPPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  mode=ModeKeys.INFERENCE,
                  *args,
                  **kwargs):
         """preprocess the data
@@ -177,15 +171,15 @@
             mode: preprocessor mode (model mode)
         """
         super().__init__(*args, **kwargs)
         model_dir = model_dir if osp.exists(model_dir) else snapshot_download(
             model_dir, user_agent={Invoke.KEY: Invoke.PREPROCESSOR})
         self.mode = mode
         # text tokenizer
-        from modelscope.models.multi_modal.clip.bert_tokenizer import FullTokenizer
+        from weathon.models.multi_modal.clip.bert_tokenizer import FullTokenizer
         if 'tokenizer' in kwargs and isinstance(kwargs['tokenizer'],
                                                 FullTokenizer):
             self.tokenizer = kwargs['tokenizer']
         else:
             vocab_file = f'{model_dir}/{ModelFile.VOCAB_FILE}'
             self.tokenizer = FullTokenizer(vocab_file=vocab_file)
         # image preprocessor
@@ -330,15 +324,15 @@
             output['text'] = text_tensor
 
         return output
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal, module_name=Preprocessors.mplug_tasks_preprocessor)
-class MPlugPreprocessor(Preprocessor):
+class MPlugPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  mode: str = ModeKeys.INFERENCE,
                  tokenizer_max_length: int = 25,
                  *args,
                  **kwargs):
@@ -359,15 +353,15 @@
             self._tokenizer = BertTokenizer.from_pretrained(self.model_dir)
         return self._tokenizer
 
     @property
     def patch_resize_transform(self):
         if self._patch_resize_transform is None:
             from torchvision import transforms
-            from modelscope.models.multi_modal.mplug import CONFIG_NAME, MPlugConfig
+            from weathon.models.multi_modal.mplug import CONFIG_NAME, MPlugConfig
 
             config = MPlugConfig.from_yaml_file(
                 osp.join(self.model_dir, CONFIG_NAME))
 
             mean = (0.48145466, 0.4578275, 0.40821073)
             std = (0.26862954, 0.26130258, 0.27577711)
 
@@ -433,15 +427,15 @@
             if self.cfg.task == Tasks.image_text_retrieval:
                 output['index'] = index
             return output
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal, module_name=Preprocessors.vldoc_preprocessor)
-class VLDocPreprocessor(Preprocessor):
+class VLDocPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  mode: str = ModeKeys.INFERENCE,
                  *args,
                  **kwargs):
         """Preprocess data for the model `VLDocForDocVLEmbedding`.
@@ -455,19 +449,19 @@
         self.model_dir = model_dir
         self.mode = mode
 
         model_cfg_path = osp.join(model_dir, 'config.json')
         with open(model_cfg_path, 'r', encoding='utf-8') as f:
             model_cfg = json.load(f)
 
-        from modelscope.models.multi_modal.vldoc.tokenization import VLDocXLMTokenizer
+        from weathon.models.multi_modal.vldoc.tokenization import VLDocXLMTokenizer
         tokenizer_path = osp.join(model_dir, ModelFile.TOKENIZER_FOLDER)
         self.tokenizer = VLDocXLMTokenizer.from_pretrained(tokenizer_path)
 
-        from modelscope.models.multi_modal.vldoc.processing import Processor, ImageProcessor
+        from weathon.models.multi_modal.vldoc.processing import Processor, ImageProcessor
         self.img_proc = ImageProcessor(
             do_preprocess=True,
             do_resize=True,
             image_size={
                 'height': model_cfg['image_size'][0],
                 'width': model_cfg['image_size'][1],
             },
@@ -505,15 +499,15 @@
         encodings = self.proc(**proc_input)
 
         return encodings
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal, module_name=Preprocessors.hitea_tasks_preprocessor)
-class HiTeAPreprocessor(Preprocessor):
+class HiTeAPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  mode: str = ModeKeys.INFERENCE,
                  tokenizer_max_length: int = 25,
                  *args,
                  **kwargs):
@@ -535,15 +529,15 @@
             self._tokenizer = BertTokenizer.from_pretrained(self.model_dir)
         return self._tokenizer
 
     @property
     def patch_resize_transform(self):
         if self._patch_resize_transform is None:
             from torchvision import transforms
-            from modelscope.models.multi_modal.mplug import CONFIG_NAME, HiTeAConfig
+            from weathon.models.multi_modal.mplug import CONFIG_NAME, HiTeAConfig
 
             config = HiTeAConfig.from_yaml_file(
                 osp.join(self.model_dir, CONFIG_NAME))
 
             mean = (0.48145466, 0.4578275, 0.40821073)
             std = (0.26862954, 0.26130258, 0.27577711)
 
@@ -555,15 +549,15 @@
             ])
         return self._patch_resize_transform
 
     @property
     def num_frames(self):
         if self._num_frames is None:
             from torchvision import transforms
-            from modelscope.models.multi_modal.mplug import CONFIG_NAME, HiTeAConfig
+            from weathon.models.multi_modal.mplug import CONFIG_NAME, HiTeAConfig
 
             config = HiTeAConfig.from_yaml_file(
                 osp.join(self.model_dir, CONFIG_NAME))
 
             self._num_frames = config.num_frames
         return self._num_frames
 
@@ -643,15 +637,15 @@
                 'answer_attention_mask': answer.attention_mask.squeeze(),
             }
             return output
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal, module_name=Preprocessors.mplug_owl_preprocessor)
-class MplugOwlPreprocessor(Preprocessor):
+class MplugOwlPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  mode: str = ModeKeys.INFERENCE,
                  *args,
                  **kwargs):
         super().__init__(*args, **kwargs)
@@ -661,15 +655,15 @@
         self._tokenizer = None
         self._patch_resize_transform = None
         self.media_token = {'<image>': 65}
         self._image_map = {}
 
     @property
     def tokenizer(self):
-        from modelscope.models.nlp.llama import LlamaTokenizer
+        from weathon.models.nlp.llama import LlamaTokenizer
 
         if self._tokenizer is None:
             self._tokenizer = LlamaTokenizer.from_pretrained(self.model_dir)
         return self._tokenizer
 
     @property
     def patch_resize_transform(self):
@@ -786,15 +780,15 @@
 
         return output
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal,
     module_name=Preprocessors.image_captioning_clip_interrogator_preprocessor)
-class ImageCaptioningClipInterrogatorPreprocessor(Preprocessor):
+class ImageCaptioningClipInterrogatorPreprocessor(BasePreprocessor):
 
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
 
     def __call__(self, data) -> Dict[str, Any]:
         image = load_image(data)
         data = np.array(image).transpose(2, 0, 1)
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .word_alignment_preprocessor import WordAlignmentPreprocessor
     from .text_error_correction import TextErrorCorrectionPreprocessor
     from .text_generation_preprocessor import TextGenerationJiebaPreprocessor
     from .bert_seq_cls_tokenizer import Tokenize
     from .document_segmentation_preprocessor import DocumentSegmentationTransformersPreprocessor
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/canmt_translation.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/canmt_translation.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict
 
 import jieba
 import torch
 from sacremoses import MosesDetokenizer, MosesPunctNormalizer, MosesTokenizer
 from subword_nmt import apply_bpe
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModelFile
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Fields, ModelFile
 from .text_clean import TextClean
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.canmt_translation)
-class CanmtTranslationPreprocessor(Preprocessor):
+class CanmtTranslationPreprocessor(BasePreprocessor):
     """The preprocessor used in text correction task.
     """
 
     def __init__(self,
                  model_dir: str,
                  max_length: int = None,
                  *args,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/dialog_classification_use_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/dialog_classification_use_preprocessor.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, List, Tuple
 
 import torch
 from torch.nn.utils.rnn import pad_sequence
 from transformers import BertTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields
-from modelscope.utils.hub import parse_label_mapping
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
+from weathon.utils.hub import parse_label_mapping
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.dialog_use_preprocessor)
-class DialogueClassificationUsePreprocessor(Preprocessor):
+class DialogueClassificationUsePreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  label2id: Dict = None,
                  max_length: int = None):
         """The preprocessor for user satisfaction estimation task, based on transformers' tokenizer.
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,101 +1,101 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import torch
-from transformers import MT5Tokenizer, XLMRobertaTokenizer
+from transformers import XLMRobertaTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModeKeys, ModelFile
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Fields, ModeKeys, ModelFile
+from weathon.utils.type_assert import type_assert
 
 
 @PREPROCESSORS.register_module(
-    Fields.nlp, module_name=Preprocessors.document_grounded_dialog_generate)
-class DocumentGroundedDialogGeneratePreprocessor(Preprocessor):
+    Fields.nlp, module_name=Preprocessors.document_grounded_dialog_retrieval)
+class DocumentGroundedDialogRetrievalPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
-        """The preprocessor for DGDS generate task, based on transformers' tokenizer.
+        """The preprocessor for DGDS retrieval task, based on transformers' tokenizer.
 
         Args:
             model_dir: The model dir containing the essential files to build the tokenizer.
         """
         super().__init__(*args, **kwargs)
 
         self.model_dir: str = model_dir
         self.config = Config.from_file(
             os.path.join(self.model_dir, ModelFile.CONFIGURATION))
         self.device = 'cuda' \
             if ('device' not in kwargs or kwargs['device'] == 'gpu') and torch.cuda.is_available() \
             else 'cpu'
-
-        self.top_k = self.config['top_k']
         self.query_sequence_length = self.config['query_sequence_length']
-        self.rerank_source_sequence_length = self.config[
-            'rerank_source_sequence_length']
-        self.source_sequence_length = self.config['source_sequence_length']
-        self.target_sequence_length = self.config['target_sequence_length']
-        self.rerank_tokenizer = XLMRobertaTokenizer.from_pretrained(
-            os.path.join(self.model_dir, 'rerank'))
-        self.generation_tokenizer = MT5Tokenizer.from_pretrained(
-            os.path.join(self.model_dir, 'generation'))
+        self.context_sequence_length = self.config['context_sequence_length']
+        self.tokenizer = XLMRobertaTokenizer.from_pretrained(
+            os.path.join(self.model_dir))
 
     @type_assert(object, Dict)
     def __call__(self,
                  data: Dict[str, Any],
                  invoke_mode=ModeKeys.INFERENCE,
+                 input_type='query',
                  **preprocessor_param) -> Dict[str, Any]:
-        query, context, label = data['query'], data['context'], data.get(
-            'label', None)
-        query = [
-            self.generation_tokenizer.decode(
-                self.generation_tokenizer([x],
-                                          add_special_tokens=False,
-                                          return_tensors='pt')['input_ids'][0]
-                [:self.query_sequence_length]) for x in query
-        ]
-
-        querys = [x for x in query for i in range(self.top_k)]
-        contexts = [x for ctxs in context for x in ctxs[:self.top_k]]
-        assert len(querys) == len(contexts)
-        rerank_input_ids = self.rerank_tokenizer(
-            querys,
-            contexts,
-            add_special_tokens=True,
-            return_tensors='pt',
-            max_length=self.rerank_source_sequence_length,
-            padding='longest',
-            truncation=True)
-
-        generator_inputs = [
-            ' '.join([query[i], '<passage>', doc]) for i in range(len(query))
-            for doc in context[i][:self.top_k]
-        ]
-        inputs_tokenizer_outputs = self.generation_tokenizer.batch_encode_plus(
-            list(generator_inputs),
-            padding=True,
-            return_tensors='pt',
-            max_length=self.source_sequence_length,
-            truncation=True)
-
-        result = {
-            'rerank_input_ids': rerank_input_ids,
-            'input_ids': inputs_tokenizer_outputs.input_ids,
-            'attention_mask': inputs_tokenizer_outputs.attention_mask
-        }
         if invoke_mode in (ModeKeys.TRAIN, ModeKeys.EVAL
                            ) and invoke_mode != ModeKeys.INFERENCE:
-            result['label_ids'] = self.generation_tokenizer.batch_encode_plus(
-                list(label),
+            query, positive, negative = data['query'], data['positive'], data[
+                'negative']
+
+            query_tokenizer_outputs = self.tokenizer.batch_encode_plus(
+                query,
+                padding=True,
+                return_tensors='pt',
+                max_length=self.query_sequence_length,
+                truncation=True)
+
+            context_tokenizer_outputs = self.tokenizer.batch_encode_plus(
+                positive + negative,
+                padding=True,
+                return_tensors='pt',
+                max_length=self.context_sequence_length,
+                truncation=True)
+
+            result = {
+                'query_input_ids': query_tokenizer_outputs.input_ids,
+                'query_attention_mask': query_tokenizer_outputs.attention_mask,
+                'context_input_ids': context_tokenizer_outputs.input_ids,
+                'context_attention_mask':
+                context_tokenizer_outputs.attention_mask,
+                'labels':
+                torch.tensor(list(range(len(query))), dtype=torch.long)
+            }
+        elif input_type == 'query':
+            query = data['query']
+            query_tokenizer_outputs = self.tokenizer.batch_encode_plus(
+                query,
+                padding=True,
+                return_tensors='pt',
+                max_length=self.query_sequence_length,
+                truncation=True)
+            result = {
+                'query_input_ids': query_tokenizer_outputs.input_ids,
+                'query_attention_mask': query_tokenizer_outputs.attention_mask,
+            }
+        else:
+            context = data['context']
+            context_tokenizer_outputs = self.tokenizer.batch_encode_plus(
+                context,
                 padding=True,
                 return_tensors='pt',
-                max_length=self.target_sequence_length,
-                truncation=True).input_ids
+                max_length=self.context_sequence_length,
+                truncation=True)
+            result = {
+                'context_input_ids': context_tokenizer_outputs.input_ids,
+                'context_attention_mask':
+                context_tokenizer_outputs.attention_mask,
+            }
 
         for k, v in result.items():
             result[k] = v.to(self.device)
 
         return result
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import copy
-import os
 from typing import Any, Dict
 
 import torch
 from transformers import XLMRobertaTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys, ModelFile
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
+from weathon.utils.type_assert import type_assert
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.document_grounded_dialog_rerank)
-class DocumentGroundedDialogRerankPreprocessor(Preprocessor):
+class DocumentGroundedDialogRerankPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, **kwargs):
         """The preprocessor for DGDS rerank task, based on transformers' tokenizer.
 
         Args:
             model_dir: The model dir containing the essential files to build the tokenizer.
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/text_ranking_preprocessor.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,102 +1,98 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import os
 from typing import Any, Dict
 
-import torch
-from transformers import XLMRobertaTokenizer
+from transformers import AutoTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModeKeys, ModelFile
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.type_assert import type_assert
+
+
+class TextRankingPreprocessorBase(BasePreprocessor):
+
+    def __init__(self,
+                 mode: str = ModeKeys.INFERENCE,
+                 first_sequence='source_sentence',
+                 second_sequence='sentences_to_compare',
+                 label='labels',
+                 qid='qid'):
+        """The tokenizer preprocessor class for the text ranking preprocessor.
+
+        Args:
+            first_sequence(str, `optional`): The key of the first sequence.
+            second_sequence(str, `optional`): The key of the second sequence.
+            label(str, `optional`): The keys of the label columns, default `labels`.
+            qid(str, `optional`): The qid info.
+            mode: The mode for the preprocessor.
+        """
+        super().__init__(mode)
+        self.first_sequence = first_sequence
+        self.second_sequence = second_sequence
+        self.label = label
+        self.qid = qid
 
 
 @PREPROCESSORS.register_module(
-    Fields.nlp, module_name=Preprocessors.document_grounded_dialog_retrieval)
-class DocumentGroundedDialogRetrievalPreprocessor(Preprocessor):
+    Fields.nlp, module_name=Preprocessors.text_ranking)
+class TextRankingTransformersPreprocessor(TextRankingPreprocessorBase):
 
-    def __init__(self, model_dir: str, *args, **kwargs):
-        """The preprocessor for DGDS retrieval task, based on transformers' tokenizer.
+    def __init__(self,
+                 model_dir: str,
+                 mode: str = ModeKeys.INFERENCE,
+                 first_sequence='source_sentence',
+                 second_sequence='sentences_to_compare',
+                 label='labels',
+                 qid='qid',
+                 max_length=None,
+                 padding='max_length',
+                 truncation=True,
+                 use_fast=True,
+                 **kwargs):
+        """The tokenizer preprocessor class for the text ranking preprocessor.
 
         Args:
-            model_dir: The model dir containing the essential files to build the tokenizer.
+            model_dir(str, `optional`): The model dir used to parse the label mapping, can be None.
+            max_length: The max sequence length which the model supported,
+                will be passed into tokenizer as the 'max_length' param.
         """
-        super().__init__(*args, **kwargs)
-
-        self.model_dir: str = model_dir
-        self.config = Config.from_file(
-            os.path.join(self.model_dir, ModelFile.CONFIGURATION))
-        self.device = 'cuda' \
-            if ('device' not in kwargs or kwargs['device'] == 'gpu') and torch.cuda.is_available() \
-            else 'cpu'
-        self.query_sequence_length = self.config['query_sequence_length']
-        self.context_sequence_length = self.config['context_sequence_length']
-        self.tokenizer = XLMRobertaTokenizer.from_pretrained(
-            os.path.join(self.model_dir))
-
-    @type_assert(object, Dict)
-    def __call__(self,
-                 data: Dict[str, Any],
-                 invoke_mode=ModeKeys.INFERENCE,
-                 input_type='query',
-                 **preprocessor_param) -> Dict[str, Any]:
-        if invoke_mode in (ModeKeys.TRAIN, ModeKeys.EVAL
-                           ) and invoke_mode != ModeKeys.INFERENCE:
-            query, positive, negative = data['query'], data['positive'], data[
-                'negative']
-
-            query_tokenizer_outputs = self.tokenizer.batch_encode_plus(
-                query,
-                padding=True,
-                return_tensors='pt',
-                max_length=self.query_sequence_length,
-                truncation=True)
-
-            context_tokenizer_outputs = self.tokenizer.batch_encode_plus(
-                positive + negative,
-                padding=True,
-                return_tensors='pt',
-                max_length=self.context_sequence_length,
-                truncation=True)
-
-            result = {
-                'query_input_ids': query_tokenizer_outputs.input_ids,
-                'query_attention_mask': query_tokenizer_outputs.attention_mask,
-                'context_input_ids': context_tokenizer_outputs.input_ids,
-                'context_attention_mask':
-                context_tokenizer_outputs.attention_mask,
-                'labels':
-                torch.tensor(list(range(len(query))), dtype=torch.long)
-            }
-        elif input_type == 'query':
-            query = data['query']
-            query_tokenizer_outputs = self.tokenizer.batch_encode_plus(
-                query,
-                padding=True,
-                return_tensors='pt',
-                max_length=self.query_sequence_length,
-                truncation=True)
-            result = {
-                'query_input_ids': query_tokenizer_outputs.input_ids,
-                'query_attention_mask': query_tokenizer_outputs.attention_mask,
-            }
-        else:
-            context = data['context']
-            context_tokenizer_outputs = self.tokenizer.batch_encode_plus(
-                context,
-                padding=True,
-                return_tensors='pt',
-                max_length=self.context_sequence_length,
-                truncation=True)
-            result = {
-                'context_input_ids': context_tokenizer_outputs.input_ids,
-                'context_attention_mask':
-                context_tokenizer_outputs.attention_mask,
-            }
-
-        for k, v in result.items():
-            result[k] = v.to(self.device)
-
-        return result
+        super().__init__(
+            mode=mode,
+            first_sequence=first_sequence,
+            second_sequence=second_sequence,
+            label=label,
+            qid=qid)
+        self.model_dir = model_dir
+        self.sequence_length = max_length if max_length is not None else kwargs.get(
+            'sequence_length', 128)
+        kwargs.pop('sequence_length', None)
+        self.tokenize_kwargs = kwargs
+        self.tokenize_kwargs['padding'] = padding
+        self.tokenize_kwargs['truncation'] = truncation
+        self.tokenizer = AutoTokenizer.from_pretrained(
+            self.model_dir, use_fast=use_fast)
+
+    @type_assert(object, dict)
+    def __call__(self, data: Dict, **kwargs) -> Dict[str, Any]:
+        sentence1 = data.get(self.first_sequence)
+        sentence2 = data.get(self.second_sequence)
+        labels = data.get(self.label)
+        qid = data.get(self.qid)
+
+        if isinstance(sentence2, str):
+            sentence2 = [sentence2]
+        if isinstance(sentence1, str):
+            sentence1 = [sentence1]
+        sentence1 = sentence1 * len(sentence2)
+        kwargs['max_length'] = kwargs.get(
+            'max_length', kwargs.pop('sequence_length', self.sequence_length))
+        if 'return_tensors' not in kwargs:
+            kwargs['return_tensors'] = 'pt'
+
+        self.tokenize_kwargs.update(kwargs)
+        feature = self.tokenizer(sentence1, sentence2, **self.tokenize_kwargs)
+        if labels is not None:
+            feature['labels'] = labels
+        if qid is not None:
+            feature['qid'] = qid
+        return feature
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/document_segmentation_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/document_segmentation_preprocessor.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.document_segmentation)
-class DocumentSegmentationTransformersPreprocessor(Preprocessor):
+class DocumentSegmentationTransformersPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  model_max_length: int,
                  mode: str = ModeKeys.INFERENCE,
                  question_column_name='labels',
                  context_column_name='sentences',
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/faq_question_answering_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/faq_question_answering_preprocessor.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.type_assert import type_assert
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.faq_question_answering_preprocessor)
-class FaqQuestionAnsweringTransformersPreprocessor(Preprocessor):
+class FaqQuestionAnsweringTransformersPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str,
                  mode: str = ModeKeys.INFERENCE,
                  tokenizer='BertTokenizer',
                  query_set='query_set',
                  support_set='support_set',
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/feature_extraction_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/feature_extraction_preprocessor.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Tuple, Union
 
 import numpy as np
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.hub import get_model_type
-from .transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.hub import get_model_type
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
 from .utils import parse_text_and_label
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.feature_extraction)
-class FeatureExtractionTransformersPreprocessor(Preprocessor):
+class FeatureExtractionTransformersPreprocessor(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str = None,
                  first_sequence: str = None,
                  second_sequence: str = None,
                  mode: str = ModeKeys.INFERENCE,
                  max_length: int = None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/fill_mask_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/fill_mask_preprocessor.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 import re
 from abc import abstractmethod
 from typing import Any, Dict, Tuple, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModeKeys, ModelFile
-from modelscope.utils.hub import get_model_type
-from modelscope.utils.nlp import import_external_nltk_data
-from .transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Fields, ModeKeys, ModelFile
+from weathon.utils.hub import get_model_type
+from weathon.utils.nlp import import_external_nltk_data
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
 from .utils import parse_text_and_label
 
 
-class FillMaskPreprocessorBase(Preprocessor):
+class FillMaskPreprocessorBase(BasePreprocessor):
 
     def __init__(self,
                  first_sequence: str = None,
                  second_sequence: str = None,
                  mode: str = ModeKeys.INFERENCE):
         """The base constructor for all the fill-mask preprocessors.
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/mgeo_ranking_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/mgeo_ranking_preprocessor.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 import torch
 from transformers import AutoTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.type_assert import type_assert
 from .text_ranking_preprocessor import TextRankingPreprocessorBase
 
 
 class GisUtt:
 
     def __init__(self, pad_token_id, cls_token_id):
         self.pad_token_id = pad_token_id
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/relation_extraction_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/relation_extraction_preprocessor.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
 from transformers import AutoTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.type_assert import type_assert
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.re_tokenizer)
-class RelationExtractionTransformersPreprocessor(Preprocessor):
+class RelationExtractionTransformersPreprocessor(BasePreprocessor):
 
     def __init__(
         self,
         model_dir: str,
         mode: str = ModeKeys.INFERENCE,
         **kwargs,
     ):
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/sentence_embedding_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/sentence_embedding_preprocessor.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.hub import get_model_type
-from .transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.hub import get_model_type
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.sentence_embedding)
-class SentenceEmbeddingTransformersPreprocessor(Preprocessor):
+class SentenceEmbeddingTransformersPreprocessor(BasePreprocessor):
     """The tokenizer preprocessor used in sentence embedding.
     """
 
     def __init__(self,
                  model_dir: str,
                  first_sequence='source_sentence',
                  second_sequence='sentences_to_compare',
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/siamese_uie_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/siamese_uie_preprocessor.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,24 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from typing import Any, Dict, Union
+from typing import Any, Dict
 
 from transformers import AutoTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.hub import get_model_type
-from .transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.siamese_uie_preprocessor)
-class SiameseUiePreprocessor(Preprocessor):
+class SiameseUiePreprocessor(BasePreprocessor):
     """The tokenizer preprocessor used in zero shot classification.
     """
 
     def __init__(
         self,
         model_dir: str,
         mode: str = ModeKeys.INFERENCE,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .data_loader import DataLoader
     from .dialog_intent_prediction_preprocessor import \
         DialogIntentPredictionPreprocessor
     from .dialog_modeling_preprocessor import DialogModelingPreprocessor
     from .dialog_state_tracking_preprocessor import DialogStateTrackingPreprocessor
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/args.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/args.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import argparse
 
 import json
 
 
 def str2bool(v):
     if v.lower() in ('yes', 'true', 't', 'y', '1'):
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/batch.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/batch.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 
 def batch(reader, batch_size, drop_last=False):
     """
     This operator creates a batched reader which combines the data from the
     input reader to batched data.
 
     Args:
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/data_loader.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/data_loader.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,18 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 import os
 
 import numpy as np
 
-from modelscope.preprocessors.nlp.space.args import str2bool
-from modelscope.preprocessors.nlp.space.batch import batch
-from modelscope.preprocessors.nlp.space.lazy_dataset import LazyDataset
-from modelscope.preprocessors.nlp.space.sampler import (RandomSampler,
+from weathon.preprocessors.nlp.space.args import str2bool
+from weathon.preprocessors.nlp.space.batch import batch
+from weathon.preprocessors.nlp.space.lazy_dataset import LazyDataset
+from weathon.preprocessors.nlp.space.sampler import (RandomSampler,
                                                         SequentialSampler,
                                                         SortedSampler)
 
 
 def get_data_loader(batch_size, reader, hparams, file, collate_fn, is_test):
     assert os.path.exists(file), f"{file} doesn't exist"
     dataset = LazyDataset(file, reader=reader)
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
 import json
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.preprocessors.nlp import IntentBPETextField
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModelFile
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.preprocessors.nlp import IntentBPETextField
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Fields, ModelFile
+from weathon.utils.type_assert import type_assert
 
 __all__ = ['DialogIntentPredictionPreprocessor']
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.dialog_intent_preprocessor)
-class DialogIntentPredictionPreprocessor(Preprocessor):
+class DialogIntentPredictionPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """preprocess the data
 
         Args:
             model_dir (str): model path
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/dialog_modeling_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/dialog_modeling_preprocessor.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Any, Dict
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.preprocessors.nlp import MultiWOZBPETextField
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModelFile
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.preprocessors.nlp import MultiWOZBPETextField
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Fields, ModelFile
+from weathon.utils.type_assert import type_assert
 
 __all__ = ['DialogModelingPreprocessor']
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.dialog_modeling_preprocessor)
-class DialogModelingPreprocessor(Preprocessor):
+class DialogModelingPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """preprocess the data
 
         Args:
             model_dir (str): model path
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,34 +1,32 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
+from weathon.utils.type_assert import type_assert
 from .dst_processors import convert_examples_to_features, multiwoz22Processor
 
 __all__ = ['DialogStateTrackingPreprocessor']
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.dialog_state_tracking_preprocessor)
-class DialogStateTrackingPreprocessor(Preprocessor):
+class DialogStateTrackingPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """preprocess the data
 
         Args:
             model_dir (str): model path
         """
         super().__init__(*args, **kwargs)
 
-        from modelscope.models.nlp.space import SpaceConfig, SpaceTokenizer
+        from weathon.models.nlp.space import SpaceConfig, SpaceTokenizer
         self.model_dir: str = model_dir
         self.config = SpaceConfig.from_pretrained(self.model_dir)
         self.tokenizer = SpaceTokenizer.from_pretrained(self.model_dir)
         self.processor = multiwoz22Processor()
 
     @type_assert(object, dict)
     def __call__(self, data: Dict[str, Any]) -> Dict[str, Any]:
@@ -43,16 +41,14 @@
                         'history_states': [{}]
                     }
 
         Returns:
             Dict[str, Any]: the preprocessed data
         """
         import torch
-        from torch.utils.data import (DataLoader, RandomSampler,
-                                      SequentialSampler)
 
         utter = data['utter']
         history_states = data['history_states']
         example = self.processor.create_example(
             inputs=utter,
             history_states=history_states,
             set_type='test',
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/dst_processors.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/dst_processors.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/fields/gen_field.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/fields/gen_field.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import random
 from asyncio import constants
 from collections import OrderedDict
 from itertools import chain
 
 import json
 import numpy as np
 
-from modelscope.preprocessors.nlp.space.tokenizer import Tokenizer
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
-from modelscope.utils.nlp.space import ontology, utils
-from modelscope.utils.nlp.space.db_ops import MultiWozDB
-from modelscope.utils.nlp.space.utils import list2np
+from weathon.preprocessors.nlp.space.tokenizer import Tokenizer
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
+from weathon.utils.nlp.space import ontology, utils
+from weathon.utils.nlp.space.db_ops import MultiWozDB
+from weathon.utils.nlp.space.utils import list2np
 
 logger = get_logger()
 
 
 class BPETextField(object):
 
     pad_token = '[PAD]'
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/fields/intent_field.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/fields/intent_field.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import glob
 import multiprocessing
 import os
 import random
 import re
 import time
 from collections import defaultdict
 from itertools import chain
 
 import json
 import numpy as np
 from tqdm import tqdm
 
-from modelscope.preprocessors.nlp.space.tokenizer import Tokenizer
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.nlp.space import ontology
-from modelscope.utils.nlp.space.scores import hierarchical_set_score
-from modelscope.utils.nlp.space.utils import list2np
+from weathon.preprocessors.nlp.space.tokenizer import Tokenizer
+from weathon.utils.constants import ModelFile
+from weathon.utils.nlp.space import ontology
+from weathon.utils.nlp.space.scores import hierarchical_set_score
+from weathon.utils.nlp.space.utils import list2np
 
 
 class BPETextField(object):
 
     pad_token = '[PAD]'
     bos_token = '[BOS]'
     eos_token = '[EOS]'
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/lazy_dataset.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/lazy_dataset.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import json
 
 
 class LazyDataset(object):
     """
     Lazy load dataset from disk.
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/preprocess.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/preprocess.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import glob
 import os
 
-from modelscope.preprocessors.nlp.space.fields.intent_field import \
+from weathon.preprocessors.nlp.space.fields.intent_field import \
     IntentBPETextField
 
 FILE_NAME = 'train.json'
 
 
 def intent_preprocess(path, cfg):
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/sampler.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/sampler.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 
 
 class Sampler(object):
 
     def __init__(self):
         return
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/tensorlistdataset.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/tensorlistdataset.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space/tokenizer.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space/tokenizer.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from __future__ import (absolute_import, division, print_function,
                         unicode_literals)
 import collections
 import logging
 import os
 import sys
 import unicodedata
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/__init__.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/lstm/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,20 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .table_question_answering_preprocessor import TableQuestionAnsweringPreprocessor
-    from .fields import MultiWOZBPETextField, IntentBPETextField
-
+    from .backbone import LSTMModel
+    from .token_classification import LSTMForTokenClassificationWithCRF
 else:
     _import_structure = {
-        'table_question_answering_preprocessor':
-        ['TableQuestionAnsweringPreprocessor'],
+        'backbone': ['LSTM'],
+        'token_classification': ['LSTMForTokenClassificationWithCRF'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/fields/database.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/fields/database.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import sqlite3
 
 import json
 import tqdm
 
 from .struct import Trie
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/fields/schema_link.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/fields/schema_link.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import re
 
 from .struct import TypeInfo
 
 
 class SchemaLinker:
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/fields/struct.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/fields/struct.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 cond_ops = ['>', '<', '==', '!=', 'ASC', 'DESC']
 agg_ops = [
     '', 'AVG', 'MAX', 'MIN', 'COUNT', 'SUM', 'COMPARE', 'GROUP BY', 'SAME'
 ]
 conn_ops = ['', 'AND', 'OR']
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,31 +1,30 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import torch
 from transformers import BertTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.preprocessors.nlp.space_T_cn.fields.database import Database
-from modelscope.preprocessors.nlp.space_T_cn.fields.schema_link import \
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.preprocessors.nlp.space_T_cn.fields.database import Database
+from weathon.preprocessors.nlp.space_T_cn.fields.schema_link import \
     SchemaLinker
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModelFile
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Fields, ModelFile
+from weathon.utils.type_assert import type_assert
 
 __all__ = ['TableQuestionAnsweringPreprocessor']
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp,
     module_name=Preprocessors.table_question_answering_preprocessor)
-class TableQuestionAnsweringPreprocessor(Preprocessor):
+class TableQuestionAnsweringPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, db: Database = None, *args, **kwargs):
         """preprocess the data
 
         Args:
             model_dir (str): model path
             db (Database): database instance
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .conversational_text_to_sql_preprocessor import \
         ConversationalTextToSqlPreprocessor
     from .fields import (get_label, SubPreprocessor, preprocess_dataset,
                          process_dataset)
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,36 +1,35 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from typing import Any, Dict
 
 import json
 import torch
 from text2sql_lgesql.preprocess.graph_utils import GraphProcessor
 from text2sql_lgesql.preprocess.process_graphs import process_dataset_graph
 from text2sql_lgesql.utils.batch import Batch
 from text2sql_lgesql.utils.example import Example
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.preprocessors.nlp.space_T_en.fields import SubPreprocessor
-from modelscope.preprocessors.nlp.space_T_en.fields.preprocess_dataset import \
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.preprocessors.nlp.space_T_en.fields import SubPreprocessor
+from weathon.preprocessors.nlp.space_T_en.fields.preprocess_dataset import \
     preprocess_dataset
-from modelscope.preprocessors.nlp.space_T_en.fields.process_dataset import (
+from weathon.preprocessors.nlp.space_T_en.fields.process_dataset import (
     process_dataset, process_tables)
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Fields, ModelFile
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.config.config import Config
+from weathon.utils.constants import Fields, ModelFile
+from weathon.utils.type_assert import type_assert
 
 __all__ = ['ConversationalTextToSqlPreprocessor']
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.conversational_text_to_sql)
-class ConversationalTextToSqlPreprocessor(Preprocessor):
+class ConversationalTextToSqlPreprocessor(BasePreprocessor):
 
     def __init__(self, model_dir: str, *args, **kwargs):
         """preprocess the data
 
         Args:
             model_dir (str): model path
         """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/__init__.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,26 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
-    from .common_utils import SubPreprocessor
-    from .parse import get_label
-    from .preprocess_dataset import \
-        preprocess_dataset
-    from .process_dataset import \
-        process_dataset, process_tables
+    from .clip import CLIPTrainer
+    from .team import TEAMImgClsTrainer
+    from .ofa import OFATrainer
+    from .mplug import MPlugTrainer
 
 else:
     _import_structure = {
-        'common_utils': ['SubPreprocessor'],
-        'parse': ['get_label'],
-        'preprocess_dataset': ['preprocess_dataset'],
-        'process_dataset': ['process_dataset', 'process_tables'],
+        'clip': ['CLIPTrainer'],
+        'team': ['TEAMImgClsTrainer'],
+        'ofa': ['OFATrainer'],
+        'mplug': ['MPlugTrainer'],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/common_utils.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/common_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 import sqlite3
 from itertools import combinations, product
 
 import nltk
 import numpy as np
 from text2sql_lgesql.utils.constants import MAX_RELATIVE_DIST
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 mwtokenizer = nltk.MWETokenizer(separator='')
 mwtokenizer.add_mwe(('[', 'CLS', ']'))
 logger = get_logger()
 
 
 def is_number(s):
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/parse.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/parse.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 CLAUSE_KEYWORDS = ('SELECT', 'FROM', 'WHERE', 'GROUP', 'ORDER', 'LIMIT',
                    'INTERSECT', 'UNION', 'EXCEPT')
 JOIN_KEYWORDS = ('JOIN', 'ON', 'AS')
 
 WHERE_OPS = ('NOT_IN', 'BETWEEN', '=', '>', '<', '>=', '<=', '!=', 'IN',
              'LIKE', 'IS', 'EXISTS')
 UNIT_OPS = ('NONE', '-', '+', '*', '/')
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from text2sql_lgesql.preprocess.parse_raw_json import Schema, get_schemas
 from text2sql_lgesql.process_sql import get_sql
 
 from .parse import get_label
 
 
 def preprocess_dataset(processor, dataset, output_tables, database_id, tables):
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/space_T_en/fields/process_dataset.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/space_T_en/fields/process_dataset.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_classification_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/text_classification/preprocessor.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,48 +1,46 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, List, Tuple, Union
 
 import numpy as np
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.hub import get_model_type, parse_label_mapping
-from modelscope.utils.logger import get_logger
-from .transformers_tokenizer import NLPTokenizer
-from .utils import labels_to_id, parse_text_and_label
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.config.config import Config
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.utils.logger import get_logger
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants import ModeKeys, Fields, Tasks,Datasets
+from weathon.utils.hub.utils import parse_label_mapping, get_model_type
+from weathon.utils.preprocessor.preprocessor_utils import parse_text_and_label, labels_to_id
 
 logger = get_logger()
 
 
-class TextClassificationPreprocessorBase(Preprocessor):
+class TextClassificationPreprocessorBase(BasePreprocessor):
 
     def __init__(
         self,
         model_dir=None,
         first_sequence: str = None,
         second_sequence: str = None,
         label: str = 'label',
         label2id: Dict = None,
         mode: str = ModeKeys.INFERENCE,
         keep_original_columns: List[str] = None,
     ):
-        """The base class for the text classification preprocessor.
+        """
 
         Args:
             model_dir(str, `optional`): The model dir used to parse the label mapping, can be None.
             first_sequence(str, `optional`): The key of the first sequence.
             second_sequence(str, `optional`): The key of the second sequence.
             label(str, `optional`): The keys of the label columns, default is `label`
             label2id: (dict, `optional`): The optional label2id mapping
             mode(str, `optional`): The mode for the preprocessor
-            keep_original_columns(List[str], `optional`): The original columns to keep,
-                only available when the input is a `dict`, default None
+            keep_original_columns(List[str], `optional`): inputdict,
         """
         super().__init__(mode)
         self.model_dir = model_dir
         self.first_sequence = first_sequence
         self.second_sequence = second_sequence
         self.label = label
         self.label2id = label2id
@@ -55,44 +53,38 @@
                     f'The key of label: {self.label}')
         if self.first_sequence is None:
             logger.warning('[Important] first_sequence attribute is not set, '
                            'this will cause an error if your input is a dict.')
 
     @property
     def id2label(self):
-        """Return the id2label mapping according to the label2id mapping.
-
-        @return: The id2label mapping if exists.
+        """ label2idid2label
         """
-        if self.label2id is not None:
-            return {id: label for label, id in self.label2id.items()}
-        return None
+        return {id: label for label, id in self.label2id.items()} if self.label2id else None
 
     def __call__(self, data: Union[str, Tuple, Dict],
                  **kwargs) -> Dict[str, Any]:
         """process the raw input data
 
         Args:
             data (tuple): [sentence1, sentence2]
                 sentence1 (str): a sentence
                 sentence2 (str): a sentence
 
         Returns:
             Dict[str, Any]: the preprocessed data
         """
 
-        text_a, text_b, labels = parse_text_and_label(data, self.mode,
+        text_a, text_b, labels = parse_text_and_label(data,
+                                                      self.mode,
                                                       self.first_sequence,
                                                       self.second_sequence,
                                                       self.label)
         output = self._tokenize_text(text_a, text_b, **kwargs)
-        output = {
-            k: np.array(v) if isinstance(v, list) else v
-            for k, v in output.items()
-        }
+        output = { k: np.array(v) if isinstance(v, list) else v for k, v in output.items() }
         labels_to_id(labels, output, self.label2id)
         if self.keep_original_columns and isinstance(data, dict):
             for column in self.keep_original_columns:
                 output[column] = data[column]
         return output
 
     def _tokenize_text(self, sequence1, sequence2=None, **kwargs):
@@ -103,30 +95,71 @@
             sequence2: The second sequence which may be None.
 
         Returns:
             The encoded sequence.
         """
         raise NotImplementedError()
 
+@PREPROCESSORS.register_module(group_key=Tasks.text_classification, module_name=Datasets.jd_sentiment_text_classification)
+class JDTextClassificationPreprocessor(TextClassificationPreprocessorBase):
 
-@PREPROCESSORS.register_module(
-    Fields.nlp, module_name=Preprocessors.nli_tokenizer)
-@PREPROCESSORS.register_module(
-    Fields.nlp, module_name=Preprocessors.sen_sim_tokenizer)
-@PREPROCESSORS.register_module(
-    Fields.nlp, module_name=Preprocessors.bert_seq_cls_tokenizer)
-@PREPROCESSORS.register_module(
-    Fields.nlp, module_name=Preprocessors.sen_cls_tokenizer)
-class TextClassificationTransformersPreprocessor(
-        TextClassificationPreprocessorBase):
+    def __init__(self, preprocessor_cfg: Config = None, *args, **kwargs):
+        preprocessor_cfg = preprocessor_cfg if preprocessor_cfg else dict()
+        
+        self.model_dir = kwargs.get('model_dir', preprocessor_cfg.get('model_dir', None))
+        self.sequence_length = kwargs.get('sequence_length',preprocessor_cfg.get('sequence_length', None))
+        self.sequence_length = kwargs.get('sequence_length', preprocessor_cfg.get('sequence_length', 128))
+        self.max_length = kwargs.get('max_length',preprocessor_cfg.get('max_length', self.sequence_length))
+        self.truncation = kwargs.get('truncation', preprocessor_cfg.get('truncation', True))
+        self.padding = kwargs.get('padding', preprocessor_cfg.get('padding', 'max_length'))
+        self.use_fast = kwargs.get('use_fast', preprocessor_cfg.get('use_fast', False))
+        self.first_sequence = kwargs.get('first_sequence', preprocessor_cfg.get('first_sequence', "sentence"))
+        self.second_sequence = kwargs.get('second_sequence', preprocessor_cfg.get('second_sequence', None))
+        self.label = kwargs.get('label', preprocessor_cfg.get('label',"label"))
+        self.label2id = kwargs.get('label2id', preprocessor_cfg.get('label2id',None))
+        self.mode = kwargs.get('mode', preprocessor_cfg.get('mode', 'train'))
+        self.keep_original_columns = kwargs.get('keep_original_columns', preprocessor_cfg.get('keep_original_columns',[]))
+        if self.label2id is None and self.model_dir is not None:
+            self.label2id = parse_label_mapping(self.model_dir)
+
+        tokenize_kwargs = dict(
+            truncation=self.truncation,
+            padding=self.padding,
+            max_length=self.max_length
+        )
+        logger.info(f'The key of sentence1: {self.first_sequence}, '
+                    f'The key of sentence2: {self.second_sequence}, '
+                    f'The key of label: {self.label}')
+        if self.first_sequence is None:
+            logger.warning('[Important] first_sequence attribute is not set, '
+                           'this will cause an error if your input is a dict.')
+
+        model_type = None
+        if self.model_dir is not None:
+            model_type = get_model_type(self.model_dir)
+        self.nlp_tokenizer = NLPTokenizer(self.model_dir, model_type, use_fast=self.use_fast, tokenize_kwargs=tokenize_kwargs)
 
     def _tokenize_text(self, sequence1, sequence2=None, **kwargs):
         if 'return_tensors' not in kwargs:
-            kwargs[
-                'return_tensors'] = 'pt' if self.mode == ModeKeys.INFERENCE else None
+            kwargs['return_tensors'] = 'pt' if self.mode == ModeKeys.INFERENCE else None
+        return self.nlp_tokenizer(sequence1, sequence2, **kwargs)
+
+
+
+
+
+@PREPROCESSORS.register_module(Fields.nlp, module_name=Preprocessors.nli_tokenizer)
+@PREPROCESSORS.register_module(Fields.nlp, module_name=Preprocessors.sen_sim_tokenizer)
+@PREPROCESSORS.register_module(Fields.nlp, module_name=Preprocessors.bert_seq_cls_tokenizer)
+@PREPROCESSORS.register_module(Fields.nlp, module_name=Preprocessors.sen_cls_tokenizer)
+class TextClassificationTransformersPreprocessor(TextClassificationPreprocessorBase):
+
+    def _tokenize_text(self, sequence1, sequence2=None, **kwargs):
+        if 'return_tensors' not in kwargs:
+            kwargs['return_tensors'] = 'pt' if self.mode == ModeKeys.INFERENCE else None
         return self.nlp_tokenizer(sequence1, sequence2, **kwargs)
 
     def __init__(self,
                  model_dir=None,
                  first_sequence: str = None,
                  second_sequence: str = None,
                  label: Union[str, List] = 'label',
@@ -142,18 +175,17 @@
             use_fast: Whether to use the fast tokenizer or not.
             max_length: The max sequence length which the model supported,
                 will be passed into tokenizer as the 'max_length' param.
             **kwargs: Extra args input into the tokenizer's __call__ method.
         """
         kwargs['truncation'] = kwargs.get('truncation', True)
         kwargs['padding'] = kwargs.get('padding', 'max_length')
-        kwargs[
-            'max_length'] = max_length if max_length is not None else kwargs.get(
-                'sequence_length', 128)
+        kwargs['max_length'] = max_length if max_length else kwargs.get('sequence_length', 128)
         kwargs.pop('sequence_length', None)
         model_type = None
         if model_dir is not None:
             model_type = get_model_type(model_dir)
-        self.nlp_tokenizer = NLPTokenizer(
-            model_dir, model_type, use_fast=use_fast, tokenize_kwargs=kwargs)
-        super().__init__(model_dir, first_sequence, second_sequence, label,
-                         label2id, mode, keep_original_columns)
+        self.nlp_tokenizer = NLPTokenizer(model_dir, model_type, use_fast=use_fast, tokenize_kwargs=kwargs)
+        super().__init__(model_dir, first_sequence, second_sequence, label,label2id, mode, keep_original_columns)
+
+
+
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_clean.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/text_clean.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import codecs
 import re
 import sys
 
 
 class TextClean(object):
 
@@ -56,15 +54,18 @@
             line = ''.join(line)
 
             line = self.space_pat.sub(' ', line).strip()
             return line
         except Exception:
             return ''
 
+    def __call__(self, s:str):
+        return self.clean(s)
+
 
 if __name__ == '__main__':
 
     tc = TextClean()
 
     for line in sys.stdin:
-        res = tc.clean(line)
+        res = tc(line)
         print(res)
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_error_correction.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/text_error_correction.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 from typing import Any, Dict
 
 import torch
 from transformers import BertTokenizer
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.text_error_correction)
-class TextErrorCorrectionPreprocessor(Preprocessor):
+class TextErrorCorrectionPreprocessor(BasePreprocessor):
     """The preprocessor used in text correction task.
     """
 
     def __init__(self,
                  model_dir: str,
                  max_length: int = None,
                  *args,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/text_generation_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/text_generation_preprocessor.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,29 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import os.path as osp
 from typing import Any, Dict, List, Optional, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.hub import get_model_type
-from modelscope.utils.logger import get_logger
-from .transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.hub import get_model_type
+from weathon.utils.logger import get_logger
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
 from .utils import parse_text_and_label
 
 logger = get_logger()
 
 
-class TextGenerationPreprocessorBase(Preprocessor):
+class TextGenerationPreprocessorBase(BasePreprocessor):
 
     def __init__(self,
                  mode: str = ModeKeys.INFERENCE,
                  src_txt='src_txt',
                  tgt_txt='tgt_txt',
                  keep_original_columns=None):
         """The base class for all the text generation task's preprocessors.
@@ -202,15 +200,15 @@
                  model_dir: str,
                  mode: str = ModeKeys.INFERENCE,
                  src_txt='src_txt',
                  tgt_txt='tgt_txt',
                  sequence_length: int = 128,
                  use_fast=None,
                  **kwargs):
-        from modelscope.models.nlp.gpt3 import JiebaBPETokenizer
+        from weathon.models.nlp.gpt3 import JiebaBPETokenizer
         super().__init__(mode, src_txt, tgt_txt, **kwargs)
         self.tokenizer = JiebaBPETokenizer(
             osp.join(model_dir, 'tokenizer.json'))
         self.max_length = sequence_length
 
     def decode(self, tokens, **kwargs):
         """Decode the tokens to real text.
@@ -295,16 +293,16 @@
         Args:
             model_dir: The model dir of the sentence piece model.
             mode: The preprocessor mode, currently either mode will have the same behaviour.
             src_txt: The key of input text, if input format is dict.
             tgt_txt: The key of target text, used in training.
 
         Examples:
-            >>> from modelscope.utils.hub import snapshot_download
-            >>> from modelscope.preprocessors import TextGenerationSentencePiecePreprocessor
+            >>> from weathon.utils.hub import snapshot_download
+            >>> from weathon.preprocessors import TextGenerationSentencePiecePreprocessor
             >>> model_dir = snapshot_download('langboat/mengzi-gpt-neo-base')
             >>> preprocessor = TextGenerationSentencePiecePreprocessor(model_dir)
             >>> print(preprocessor('test word'))
         """
         if 'first_sequence' in kwargs:
             src_txt = kwargs.pop('first_sequence')
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/token_classification_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/token_classification_preprocessor.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,32 +1,30 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, List, Tuple, Union
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Preprocessors
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.hub import get_model_type, parse_label_mapping
-from modelscope.utils.logger import get_logger
-from modelscope.utils.type_assert import type_assert
-from .transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.outputs import OutputKeys
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.hub import get_model_type, parse_label_mapping
+from weathon.utils.logger import get_logger
+from weathon.utils.type_assert import type_assert
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
 from .utils import parse_text_and_label
 
 logger = get_logger()
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp,
     module_name=Preprocessors.word_segment_text_to_label_preprocessor)
-class WordSegmentationBlankSetToLabelPreprocessor(Preprocessor):
+class WordSegmentationBlankSetToLabelPreprocessor(BasePreprocessor):
     """The preprocessor used to turn a single sentence to a labeled token-classification dict.
     """
 
     def __init__(self, generated_sentence='tokens', generated_label='labels'):
         super().__init__()
         self.generated_sentence = generated_sentence
         self.generated_label = generated_label
@@ -51,15 +49,15 @@
         chars, labels = produce_train_sample(data)
         return {
             self.generated_sentence: chars,
             self.generated_label: labels,
         }
 
 
-class TokenClassificationPreprocessorBase(Preprocessor):
+class TokenClassificationPreprocessorBase(BasePreprocessor):
 
     def __init__(self,
                  model_dir: str = None,
                  first_sequence: str = None,
                  label: str = 'label',
                  label2id: Dict = None,
                  label_all_tokens: bool = False,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/token_classification_thai_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/token_classification_thai_preprocessor.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,15 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields
-from modelscope.utils.type_assert import type_assert
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
+from weathon.utils.type_assert import type_assert
 from .token_classification_preprocessor import \
     TokenClassificationTransformersPreprocessor
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.thai_ner_tokenizer)
 class NERPreprocessorThai(TokenClassificationTransformersPreprocessor):
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/transformers_tokenizer.py` & `weathon-0.0.0.14/weathon/utils/preprocessor/transformers_tokenizer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
-from collections.abc import Mapping
 
 import json
 from transformers import AutoTokenizer
 
-from modelscope.metainfo import Models
-from modelscope.outputs import OutputKeys
-from modelscope.utils.constant import ModeKeys
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Models
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = [
     'NLPTokenizer',
 ]
 
@@ -49,20 +44,16 @@
         return self._tokenizer
 
     @property
     def use_fast(self):
         if self._use_fast is None:
             if self._use_fast is None and self.model_dir is None:
                 self._use_fast = False
-            elif self._use_fast is None and os.path.isfile(
-                    os.path.join(self.model_dir, 'tokenizer_config.json')):
-                with open(
-                        os.path.join(self.model_dir, 'tokenizer_config.json'),
-                        'r',
-                        encoding='utf-8') as f:
+            elif self._use_fast is None and os.path.isfile(os.path.join(self.model_dir, 'tokenizer_config.json')):
+                with open(os.path.join(self.model_dir, 'tokenizer_config.json'), 'r',encoding='utf-8') as f:
                     json_config = json.load(f)
                     self._use_fast = json_config.get('use_fast')
             self._use_fast = False if self._use_fast is None else self._use_fast
         return self._use_fast
 
     def build_tokenizer(self):
         """Build a tokenizer by the model type.
@@ -82,21 +73,19 @@
             from transformers import BertTokenizer, BertTokenizerFast
             tokenizer = BertTokenizerFast if self.use_fast else BertTokenizer
             return tokenizer.from_pretrained(
                 model_dir) if model_dir is not None else tokenizer()
         elif model_type == Models.veco:
             from transformers import XLMRobertaTokenizer, XLMRobertaTokenizerFast
             tokenizer = XLMRobertaTokenizerFast if self.use_fast else XLMRobertaTokenizer
-            return tokenizer.from_pretrained(
-                model_dir) if model_dir is not None else tokenizer()
+            return tokenizer.from_pretrained(model_dir) if model_dir is not None else tokenizer()
         elif model_type == Models.llama:
-            from modelscope.models.nlp import LlamaTokenizer, LlamaTokenizerFast
+            from weathon.models.nlp import LlamaTokenizer, LlamaTokenizerFast
             tokenizer = LlamaTokenizerFast if self.use_fast else LlamaTokenizer
-            return tokenizer.from_pretrained(
-                model_dir) if model_dir is not None else tokenizer()
+            return tokenizer.from_pretrained(model_dir) if model_dir is not None else tokenizer()
 
         assert model_dir is not None
         return AutoTokenizer.from_pretrained(model_dir, use_fast=self.use_fast)
 
     def __call__(self, text, text_pair=None, **kwargs):
         kwargs['max_length'] = kwargs.get('max_length',
                                           kwargs.pop('sequence_length', None))
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/translation_evaluation_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/translation_evaluation_preprocessor.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,27 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+from typing import Any, Dict, List
 
-from typing import Any, Dict, List, Union
-
-import torch
-from transformers import AutoTokenizer
-
-from modelscope.metainfo import Preprocessors
-from modelscope.models.nlp.unite.configuration import InputFormat
-from modelscope.models.nlp.unite.translation_evaluation import \
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.models.nlp.backbone.unite import InputFormat
+from weathon.models.nlp.backbone.unite import \
     combine_input_sentences
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from .transformers_tokenizer import NLPTokenizer
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.translation_evaluation)
-class TranslationEvaluationTransformersPreprocessor(Preprocessor):
+class TranslationEvaluationTransformersPreprocessor(BasePreprocessor):
     r"""The tokenizer preprocessor used for translation evaluation.
     """
 
     def __init__(self,
                  model_dir: str,
                  max_len: int,
                  pad_token_id: int,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/utils.py` & `weathon-0.0.0.14/weathon/utils/preprocessor/preprocessor_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,23 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+from typing import Mapping
 
-import os
-from collections.abc import Mapping
-from typing import Any, Dict, List, Tuple, Union
-
-import json
-import numpy as np
-from transformers import AutoTokenizer
-
-from modelscope.metainfo import Models
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.utils.constant import ModeKeys
-from modelscope.utils.hub import get_model_type, parse_label_mapping
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModeKeys
+from weathon.utils.constants.output_constant import OutputKeys
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['parse_text_and_label', 'labels_to_id']
 
 
 def parse_text_and_label(data,
@@ -79,21 +68,18 @@
 
     def label_can_be_mapped(label):
         return isinstance(label, str) or isinstance(label, int)
 
     try:
         if isinstance(labels, (tuple, list)) and all([label_can_be_mapped(label) for label in labels]) \
                 and label2id is not None:
-            output[OutputKeys.LABELS] = [
-                label2id[label] if label in label2id else label2id[str(label)]
-                for label in labels
-            ]
+            output[OutputKeys.LABELS] = [label2id[label] if label in label2id else label2id[str(label)] for label in
+                                         labels]
         elif label_can_be_mapped(labels) and label2id is not None:
-            output[OutputKeys.LABELS] = label2id[
-                labels] if labels in label2id else label2id[str(labels)]
+            output[OutputKeys.LABELS] = label2id[labels] if labels in label2id else label2id[str(labels)]
         elif labels is not None:
             output[OutputKeys.LABELS] = labels
     except KeyError as e:
         logger.error(
             f'Label {labels} cannot be found in the label mapping {label2id},'
             f'which comes from the user input or the configuration files. '
             f'Please consider matching your labels with this mapping.')
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/word_alignment_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/word_alignment_preprocessor.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,29 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import itertools
-import os
-import os.path as osp
-from typing import Any, Dict, Optional, Union
+from typing import Any, Dict
 
-import numpy as np
 import torch
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.hub import get_model_type
-from modelscope.utils.logger import get_logger
-from .transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.hub import get_model_type
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.word_alignment)
-class WordAlignmentPreprocessor(Preprocessor):
+class WordAlignmentPreprocessor(BasePreprocessor):
     """The tokenizer preprocessor used in word alignment .
     """
 
     def __init__(self,
                  model_dir: str,
                  sequence_pair='sentence_pair',
                  mode=ModeKeys.INFERENCE,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/nlp/zero_shot_classification_preprocessor.py` & `weathon-0.0.0.14/weathon/preprocessors/nlp/zero_shot_classification_preprocessor.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,22 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Any, Dict, Union
 
-from modelscope.metainfo import Preprocessors
-from modelscope.preprocessors import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.hub import get_model_type
-from .transformers_tokenizer import NLPTokenizer
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.preprocessors import Preprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.hub import get_model_type
+from weathon.utils.preprocessor.transformers_tokenizer import NLPTokenizer
 
 
 @PREPROCESSORS.register_module(
     Fields.nlp, module_name=Preprocessors.zero_shot_cls_tokenizer)
-class ZeroShotClassificationTransformersPreprocessor(Preprocessor):
+class ZeroShotClassificationTransformersPreprocessor(BasePreprocessor):
     """The tokenizer preprocessor used in zero shot classification.
     """
 
     def __init__(self,
                  model_dir: str,
                  first_sequence=None,
                  mode=ModeKeys.INFERENCE,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/__init__.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/__init__.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from .asr import OfaASRPreprocessor
 from .image_captioning import OfaImageCaptioningPreprocessor
 from .image_classification import OfaImageClassificationPreprocessor
 from .ocr_recognition import OfaOcrRecognitionPreprocessor
 from .sudoku import OfaSudokuPreprocessor
 from .summarization import OfaSummarizationPreprocessor
 from .text2sql import OfaTextToSqlPreprocessor
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/asr.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/asr.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import random
 from pathlib import Path
 from typing import Any, Dict
 
 import librosa
 import soundfile as sf
 import torch
 from fairseq.data.audio.feature_transforms import \
     CompositeAudioFeatureTransform
 from fairseq.data.audio.speech_to_text_dataset import S2TDataConfig
 
-from modelscope.utils.chinese_utils import pre_chinese
-from modelscope.utils.constant import ModeKeys
+from weathon.utils.chinese_utils import pre_chinese
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 from .utils.text2phone import Text2Phone
 
 
 class OfaASRPreprocessor(OfaBasePreprocessor):
 
     def __init__(self,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/base.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/base.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import io
 import os
 import re
 import string
 from os import path as osp
 
 import json
 import numpy as np
 import torch
 import torchaudio
 from PIL import Image
 
-from modelscope.fileio import File
-from modelscope.models.multi_modal.ofa import OFATokenizer, OFATokenizerZH
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.trie import Trie
+from weathon.fileio import File
+from weathon.models.multi_modal.ofa import OFATokenizer, OFATokenizerZH
+from weathon.preprocessors.image import load_image
+from weathon.utils.trie import Trie
 from .utils.audio_helper import (_get_kaldi_fbank, _get_torchaudio_fbank,
                                  convert_waveform)
 from .utils.constant import OFA_TASK_KEY_MAPPING
 from .utils.random_help import set_torch_seed
 
 
 class OfaBasePreprocessor:
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/image_captioning.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/image_captioning.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 from torchvision import transforms
 
-from modelscope.utils.constant import ModeKeys
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 
 
 class OfaImageCaptioningPreprocessor(OfaBasePreprocessor):
     r"""
     OFA preprocessor for image captioning task.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/image_classification.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/image_classification.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import functools
 from typing import Any, Dict
 
 import torch
 from PIL import Image, ImageFile
 from timm.data import create_transform
 from torchvision import transforms
 
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.constant import ModeKeys
+from weathon.preprocessors.image import load_image
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 from .utils.vision_helper import RandomAugment
 
 ImageFile.LOAD_TRUNCATED_IMAGES = True
 ImageFile.MAX_IMAGE_PIXELS = None
 Image.MAX_IMAGE_PIXELS = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/ocr_recognition.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/ocr_recognition.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 import unicodedata2
 from torchvision import transforms
 from torchvision.transforms import InterpolationMode
 from torchvision.transforms import functional as F
 from zhconv import convert
 
-from modelscope.utils.constant import ModeKeys
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 
 
 def ocr_resize(img, patch_image_size, is_document=False):
     r"""
     Image resize function for OCR tasks.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/sudoku.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/sudoku.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import numpy as np
 import torch
 
-from modelscope.utils.constant import ModeKeys
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 
 
 class OfaSudokuPreprocessor(OfaBasePreprocessor):
     r"""
     OFA preprocessor for sudoku tasks
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/summarization.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/summarization.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 
-from modelscope.utils.constant import ModeKeys
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 
 
 class OfaSummarizationPreprocessor(OfaBasePreprocessor):
     r"""
     OFA preprocessor for summarization tasks.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/text2sql.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/text2sql.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import random
 import re
 from typing import Any, Dict, List
 
 import torch
 
-from modelscope.utils.constant import ModeKeys
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 from .utils.bridge_content_encoder import get_database_matches
 from .utils.get_tables import dump_db_json_schema
 
 
 class OfaTextToSqlPreprocessor(OfaBasePreprocessor):
     r"""
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/text_classification.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/text_classification.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 
-from modelscope.utils.constant import ModeKeys
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 
 
 class OfaTextClassificationPreprocessor(OfaBasePreprocessor):
     r"""
     OFA preprocessor for text classification tasks.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/text_to_image_synthesis.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/text_to_image_synthesis.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,13 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 
-from modelscope.utils.constant import ModeKeys
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 
 
 class OfaTextToImageSynthesisPreprocessor(OfaBasePreprocessor):
     r"""
     OFA preprocessor for text to image synthesis tasks.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/audio_helper.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/utils/audio_helper.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Optional, Tuple, Union
 
 import numpy as np
 import torch
 
 
 def convert_waveform(
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/bridge_content_encoder.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/utils/bridge_content_encoder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/collate.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/utils/collate.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import List
 
 import numpy as np
 import torch
 
 
 def collate_fn(samples, pad_idx, eos_idx):
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/get_tables.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/utils/get_tables.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import sqlite3
 import sys
 import traceback
 
 EXIST = {'atis', 'geo', 'advising', 'yelp', 'restaurants', 'imdb', 'academic'}
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/random_help.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/utils/random_help.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 
 try:
     import torch_xla.core.xla_model as xm
 except ImportError:
     xm = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/text2phone.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/utils/text2phone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,8 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-from modelscope.utils.chinese_utils import normalize_chinese_number
+from weathon.utils.chinese_utils import normalize_chinese_number
 
 
 class TrieNode(object):
 
     def __init__(self):
         """
         Initialize your data structure here.
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/transforms.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/utils/transforms.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/utils/vision_helper.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/utils/vision_helper.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/visual_entailment.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/visual_entailment.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 from PIL import Image
 from torchvision import transforms
 
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.constant import ModeKeys
+from weathon.preprocessors.image import load_image
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 
 
 class OfaVisualEntailmentPreprocessor(OfaBasePreprocessor):
     r"""
     OFA preprocessor for visual entailment tasks.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/visual_grounding.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/visual_grounding.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import numpy as np
 import torch
 from PIL import Image
 from torchvision import transforms
 
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.constant import ModeKeys
+from weathon.preprocessors.image import load_image
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 from .utils import transforms as T
 
 
 class OfaVisualGroundingPreprocessor(OfaBasePreprocessor):
     r"""
     OFA preprocessor for visual grounding tasks.
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/ofa/visual_question_answering.py` & `weathon-0.0.0.14/weathon/preprocessors/ofa/visual_question_answering.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import Any, Dict
 
 import torch
 from PIL import Image
 from torchvision import transforms
 
-from modelscope.preprocessors.image import load_image
-from modelscope.utils.constant import ModeKeys
+from weathon.preprocessors.image import load_image
+from weathon.utils.constant import ModeKeys
 from .base import OfaBasePreprocessor
 
 
 class OfaVisualQuestionAnsweringPreprocessor(OfaBasePreprocessor):
     r"""
     OFA preprocessor for question answer tasks.
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/science/uni_fold.py` & `weathon-0.0.0.14/weathon/preprocessors/science/uni_fold.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,24 +16,24 @@
 
 import json
 import numpy as np
 import requests
 import torch
 from tqdm import tqdm
 
-from modelscope.metainfo import Preprocessors
-from modelscope.models.science.unifold.data import protein, residue_constants
-from modelscope.models.science.unifold.data.protein import PDB_CHAIN_IDS
-from modelscope.models.science.unifold.data.utils import compress_features
-from modelscope.models.science.unifold.msa import parsers, pipeline, templates
-from modelscope.models.science.unifold.msa.tools import hhsearch
-from modelscope.models.science.unifold.msa.utils import divide_multi_chains
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.builder import PREPROCESSORS
-from modelscope.utils.constant import Fields
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.models.science.unifold.data import protein, residue_constants
+from weathon.models.science.unifold.data.protein import PDB_CHAIN_IDS
+from weathon.models.science.unifold.data.utils import compress_features
+from weathon.models.science.unifold.msa import parsers, pipeline, templates
+from weathon.models.science.unifold.msa.tools import hhsearch
+from weathon.models.science.unifold.msa.utils import divide_multi_chains
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants import Fields
 
 __all__ = [
     'UniFoldPreprocessor',
 ]
 
 TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'
 DEFAULT_API_SERVER = 'https://api.colabfold.com'
@@ -281,15 +281,15 @@
     templates_result = template_featurizer.get_templates(
         query_sequence=query_sequence, hits=hhsearch_hits)
     return dict(templates_result.features)
 
 
 @PREPROCESSORS.register_module(
     Fields.science, module_name=Preprocessors.unifold_preprocessor)
-class UniFoldPreprocessor(Preprocessor):
+class UniFoldPreprocessor(BasePreprocessor):
 
     def __init__(self, **cfg):
         self.symmetry_group = cfg['symmetry_group']  # "C1"
         if not self.symmetry_group:
             self.symmetry_group = None
         self.MIN_SINGLE_SEQUENCE_LENGTH = 16  # TODO: change to cfg
         self.MAX_SINGLE_SEQUENCE_LENGTH = 1000
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/tts.py` & `weathon-0.0.0.14/weathon/preprocessors/tts.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,30 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
-from typing import Any, Dict, List, Union
 
 from kantts.preprocess.data_process import process_data
 
-from modelscope.metainfo import Preprocessors
-from modelscope.models.base import Model
-from modelscope.utils.audio.tts_exceptions import (
-    TtsDataPreprocessorAudioConfigNotExistsException,
-    TtsDataPreprocessorDirNotExistsException)
-from modelscope.utils.constant import Fields, Frameworks, Tasks
-from .base import Preprocessor
-from .builder import PREPROCESSORS
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.utils.audio.tts_exceptions import ( TtsDataPreprocessorAudioConfigNotExistsException, TtsDataPreprocessorDirNotExistsException)
+from weathon.utils.constants import Tasks
 
 __all__ = ['KanttsDataPreprocessor']
 
 
 @PREPROCESSORS.register_module(
     group_key=Tasks.text_to_speech,
     module_name=Preprocessors.kantts_data_preprocessor)
-class KanttsDataPreprocessor(Preprocessor):
+class KanttsDataPreprocessor(BasePreprocessor):
 
     def __init__(self):
         pass
 
     def __call__(self,
                  data_dir,
                  output_dir,
```

### Comparing `weathon-0.0.0.13/weathon/dl/preprocessors/video.py` & `weathon-0.0.0.14/weathon/preprocessors/video.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,20 +10,20 @@
 import torch
 import torch.utils.data
 import torch.utils.dlpack as dlpack
 import torchvision.transforms._transforms_video as transforms
 from decord import VideoReader
 from torchvision.transforms import Compose
 
-from modelscope.hub.file_download import http_get_file
-from modelscope.metainfo import Preprocessors
-from modelscope.utils.constant import Fields, ModeKeys
-from modelscope.utils.type_assert import type_assert
-from .base import Preprocessor
-from .builder import PREPROCESSORS
+from weathon.base import BasePreprocessor
+from weathon.registry import PREPROCESSORS
+from weathon.utils.hub import http_get_file
+from weathon.utils.constants.metainfo import Preprocessors
+from weathon.utils.constants import Fields, ModeKeys
+from weathon.utils.type_assert import type_assert
 
 
 def ReadVideoData(cfg,
                   video_path,
                   num_spatial_crops_override=None,
                   num_temporal_views_override=None):
     """ simple interface to load video frames from file
@@ -316,15 +316,15 @@
 
     def __call__(self, clip):
         return self._get_controlled_crop(clip)
 
 
 @PREPROCESSORS.register_module(
     Fields.cv, module_name=Preprocessors.movie_scene_segmentation_preprocessor)
-class MovieSceneSegmentationPreprocessor(Preprocessor):
+class MovieSceneSegmentationPreprocessor(BasePreprocessor):
 
     def __init__(self, *args, **kwargs):
         """
         movie scene segmentation preprocessor
         """
         super().__init__(*args, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/tools/eval.py` & `weathon-0.0.0.14/weathon/utils/tools/eval.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,12 +1,9 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import argparse
 
-from modelscope.trainers import build_trainer
 
 
 def parse_args():
     parser = argparse.ArgumentParser(description='evaluate a model')
     parser.add_argument('config', help='config file path', type=str)
     parser.add_argument(
         '--trainer_name', help='name for trainer', type=str, default=None)
```

### Comparing `weathon-0.0.0.13/weathon/dl/tools/speech_tts_autolabel.py` & `weathon-0.0.0.14/weathon/utils/tools/speech_tts_autolabel.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import argparse
 import os
 import sys
 import zipfile
 
-from modelscope.hub.check_model import check_local_model_is_latest
-from modelscope.hub.snapshot_download import snapshot_download
-from modelscope.utils.constant import ThirdParty
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ThirdParty
+from weathon.utils.hub.check_model import check_local_model_is_latest
+from weathon.utils.hub.utils import snapshot_download
+from weathon.utils.logger import get_logger
 
 try:
     from tts_autolabel import AutoLabeling
 except ImportError:
     raise ImportError('pls install tts-autolabel with \
                       "pip install tts-autolabel -f \
                       https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html"'
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/__init__.py` & `weathon-0.0.0.14/weathon/trainers/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .audio import ANSTrainer, KanttsTrainer
     from .base import DummyTrainer
     from .builder import build_trainer
     from .cv import (ImageInstanceSegmentationTrainer,
                      ImagePortraitEnhancementTrainer,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/asr_trainer.py` & `weathon-0.0.0.14/weathon/trainers/audio/asr_trainer.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,39 +1,35 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import shutil
 import tempfile
 from typing import Dict, Optional, Union
 
 import json
 from funasr.bin import build_trainer
 
-from modelscope.metainfo import Trainers
-from modelscope.msdatasets import MsDataset
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import (DEFAULT_DATASET_NAMESPACE,
-                                       DEFAULT_DATASET_REVISION,
-                                       DEFAULT_MODEL_REVISION, ModelFile,
-                                       Tasks, TrainerStages)
-from modelscope.utils.logger import get_logger
+from weathon.base import BaseTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import DEFAULT_MODEL_REVISION
+from weathon.utils.constants.metainfo import Trainers
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @TRAINERS.register_module(module_name=Trainers.speech_asr_trainer)
 class ASRTrainer(BaseTrainer):
     DATA_DIR = 'data'
 
     def __init__(self,
                  model: str,
                  work_dir: str = None,
                  distributed: bool = False,
                  dataset_type: str = 'small',
-                 data_dir: Optional[Union[MsDataset, str]] = None,
+                 data_dir: Optional[Union[WtDataset, str]] = None,
                  model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
                  batch_bins: Optional[int] = None,
                  max_epoch: Optional[int] = None,
                  lr: Optional[float] = None,
                  mate_params: Optional[dict] = None,
                  **kwargs):
         """ASR Trainer.
@@ -48,17 +44,17 @@
             batch_bins (str): batch size
             max_epoch (int): the maximum epoch number for training
             lr (float): learning rate
             mate_params (dict): for saving other training args
         Examples:
 
         >>> import os
-        >>> from modelscope.metainfo import Trainers
-        >>> from modelscope.msdatasets import MsDataset
-        >>> from modelscope.trainers import build_trainer
+        >>> from weathon.metainfo import Trainers
+        >>> from weathon.datasets import MsDataset
+        >>> from weathon.trainers import build_trainer
         >>> ds_dict = MsDataset.load('speech_asr_aishell1_trainsets')
         >>> kwargs = dict(
         >>>     model='damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch',
         >>>     data_dir=ds_dict,
         >>>     work_dir="./checkpoint")
         >>> trainer = build_trainer(
         >>>     Trainers.speech_asr_trainer, default_args=kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/kws_farfield_trainer.py` & `weathon-0.0.0.14/weathon/trainers/audio/kws_farfield_trainer.py`

 * *Files 10% similar despite different names*

```diff
@@ -6,26 +6,24 @@
 from typing import Callable, Dict, Optional
 
 import numpy as np
 import torch
 from torch import nn as nn
 from torch import optim as optim
 
-from modelscope.metainfo import Trainers
-from modelscope.models import Model, TorchModel
-from modelscope.msdatasets.dataset_cls.custom_datasets.audio import (
-    KWSDataLoader, KWSDataset)
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.audio.audio_utils import update_conf
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, ModelFile
-from modelscope.utils.data_utils import to_device
-from modelscope.utils.device import create_device
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import (get_dist_info, get_local_rank,
+from weathon.datasets.custom_datasets import KWSDataset, KWSDataLoader
+from weathon.registry import TRAINERS
+from weathon.utils.constants import DEFAULT_MODEL_REVISION, ModelFile
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import TorchModel, BaseTrainer, BaseModel
+from weathon.utils.audio.audio_utils import update_conf
+from weathon.utils.data_utils import to_device
+from weathon.utils.device import create_device
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import (get_dist_info, get_local_rank,
                                           init_dist, is_master)
 
 logger = get_logger()
 
 BASETRAIN_CONF_EASY = 'basetrain_easy'
 BASETRAIN_CONF_NORMAL = 'basetrain_normal'
 BASETRAIN_CONF_HARD = 'basetrain_hard'
@@ -56,16 +54,15 @@
                  custom_conf: Optional[dict] = None,
                  **kwargs):
 
         if isinstance(model, str):
             self.model_dir = self.get_or_download_model_dir(
                 model, model_revision)
             if cfg_file is None:
-                cfg_file = os.path.join(self.model_dir,
-                                        ModelFile.CONFIGURATION)
+                cfg_file = os.path.join(self.model_dir, ModelFile.CONFIGURATION)
         else:
             assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'
             self.model_dir = os.path.dirname(cfg_file)
 
         super().__init__(cfg_file, arg_parse_fn)
 
         # the number of model output dimension
@@ -155,15 +152,15 @@
     def build_model(self) -> nn.Module:
         """ Instantiate a pytorch model and return.
 
         By default, we will create a model using config from configuration file. You can
         override this method in a subclass.
 
         """
-        model = Model.from_pretrained(
+        model = BaseModel.from_pretrained(
             self.model_dir, cfg_dict=self.cfg, training=True)
         if isinstance(model, TorchModel) and hasattr(model, 'model'):
             return model.model
         elif isinstance(model, nn.Module):
             return model
 
     def train(self, *args, **kwargs):
@@ -280,16 +277,15 @@
         with open(val_dump_file, 'wb') as f:
             pickle.dump(self.data_val, f)
         logger.info('Finish generating validation set!')
 
     def create_dataloader(self, base_path, finetune_path):
         dataset = KWSDataset(base_path, finetune_path, self._threads,
                              self._single_rate, self._num_classes)
-        dataloader = KWSDataLoader(
-            dataset, batchsize=self._batch_size, numworkers=self._threads)
+        dataloader = KWSDataLoader(dataset, batchsize=self._batch_size, numworkers=self._threads)
         dataloader.start()
         return dataset, dataloader
 
     def evaluate(self, checkpoint_path: str, *args,
                  **kwargs) -> Dict[str, float]:
         logger.info('Start validation...')
         loss_val_epoch = 0.0
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/kws_nearfield_trainer.py` & `weathon-0.0.0.14/weathon/trainers/audio/kws_nearfield_trainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,45 +1,41 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import copy
 import datetime
 import os
 import re
 from typing import Callable, Dict, Optional
 
 import torch
 import torch.distributed as dist
 import yaml
 from tensorboardX import SummaryWriter
 from torch import nn as nn
 from torch import optim as optim
 from torch.utils.data import DataLoader
 
-from modelscope.metainfo import Trainers
-from modelscope.models import Model, TorchModel
-from modelscope.msdatasets.dataset_cls.custom_datasets.audio.kws_nearfield_dataset import \
-    kws_nearfield_dataset
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.checkpoint import load_checkpoint, save_checkpoint
-from modelscope.utils.config import Config
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, ModelFile
-from modelscope.utils.device import create_device
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import set_random_seed
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import TorchModel, BaseTrainer, BaseModel
+from weathon.utils.checkpoint import load_checkpoint, save_checkpoint
+from weathon.utils.config.config import Config
+from weathon.utils.device import create_device
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import set_random_seed
 from .kws_utils.batch_utils import executor_cv, executor_test, executor_train
 from .kws_utils.det_utils import compute_det
 from .kws_utils.file_utils import query_token_set, read_lexicon, read_token
 from .kws_utils.model_utils import (average_model, convert_to_kaldi,
                                     count_parameters)
+from ...datasets.custom_datasets import kws_nearfield_dataset
+from ...registry import TRAINERS
+from ...utils.constants import DEFAULT_MODEL_REVISION, ModelFile
 
 logger = get_logger()
 
 
-@TRAINERS.register_module(
-    module_name=Trainers.speech_kws_fsmn_char_ctc_nearfield)
+@TRAINERS.register_module(module_name=Trainers.speech_kws_fsmn_char_ctc_nearfield)
 class KWSNearfieldTrainer(BaseTrainer):
 
     def __init__(self,
                  model: str,
                  work_dir: str,
                  cfg_file: Optional[str] = None,
                  arg_parse_fn: Optional[Callable] = None,
@@ -53,16 +49,15 @@
             kwargs:
                 seed (int): random seed
         '''
         if isinstance(model, str):
             self.model_dir = self.get_or_download_model_dir(
                 model, model_revision)
             if cfg_file is None:
-                cfg_file = os.path.join(self.model_dir,
-                                        ModelFile.CONFIGURATION)
+                cfg_file = os.path.join(self.model_dir,ModelFile.CONFIGURATION)
         else:
             assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'
             self.model_dir = os.path.dirname(cfg_file)
 
         super().__init__(cfg_file, arg_parse_fn)
         configs = Config.from_file(cfg_file)
 
@@ -458,15 +453,15 @@
     def build_model(self, configs) -> nn.Module:
         """ Instantiate a pytorch model and return.
 
         By default, we will create a model using config from configuration file. You can
         override this method in a subclass.
 
         """
-        model = Model.from_pretrained(
+        model = BaseModel.from_pretrained(
             self.model_dir, cfg_dict=configs, training=True)
         if isinstance(model, TorchModel) and hasattr(model, 'model'):
             return model.model
         elif isinstance(model, nn.Module):
             return model
 
     def init_dist(self, train_nodes=1):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/__init__.py` & `weathon-0.0.0.14/weathon/trainers/audio/kws_utils/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     print('TYPE_CHECKING...')
     from .batch_utils import (executor_train, executor_cv, executor_test,
                               token_score_filter, is_sublist, ctc_loss,
                               ctc_prefix_beam_search)
     from .det_utils import (load_data_and_score, load_stats_file, compute_det,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/batch_utils.py` & `weathon-0.0.0.14/weathon/trainers/audio/kws_utils/batch_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 import numpy as np
 import torch
 import torch.distributed as dist
 import torch.nn.functional as F
 from torch.distributed import ReduceOp
 from torch.nn.utils import clip_grad_norm_
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 # torch.set_printoptions(threshold=np.inf)
 
 
 def executor_train(model, optimizer, data_loader, device, writer, args):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/det_utils.py` & `weathon-0.0.0.14/weathon/trainers/audio/kws_utils/det_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 import json
 import kaldiio
 import matplotlib.font_manager as fm
 import matplotlib.pyplot as plt
 import numpy as np
 import torch
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 from .file_utils import make_pair, read_lists, space_mixed_label
 
 logger = get_logger()
 
 font = fm.FontProperties(size=15)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/file_utils.py` & `weathon-0.0.0.14/weathon/trainers/audio/kws_utils/file_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import re
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 symbol_str = '[!"#$%&\'()*+,-./:;<>=?@?[\\]^_`{|}~]+'
 
 
 def split_mixed_label(input_str):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/model_utils.py` & `weathon-0.0.0.14/weathon/trainers/audio/kws_utils/model_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,16 +6,16 @@
 import re
 from shutil import copyfile
 
 import numpy as np
 import torch
 import yaml
 
-from modelscope.utils.checkpoint import load_checkpoint, save_checkpoint
-from modelscope.utils.logger import get_logger
+from weathon.utils.checkpoint import load_checkpoint, save_checkpoint
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def count_parameters(model):
     return sum(p.numel() for p in model.parameters() if p.requires_grad)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/kws_utils/runtime_utils.py` & `weathon-0.0.0.14/weathon/trainers/audio/kws_utils/runtime_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 import stat
 import sys
 from collections import OrderedDict
 from shutil import copyfile
 
 import json
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def make_runtime_res(model_dir, dest_path, kaldi_text, keywords):
     if not os.path.exists(dest_path):
         os.makedirs(dest_path)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/separation_trainer.py` & `weathon-0.0.0.14/weathon/trainers/audio/separation_trainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,32 +1,29 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import csv
 import os
 from typing import Dict, Optional, Union
 
 import numpy as np
 import speechbrain as sb
 import speechbrain.nnet.schedulers as schedulers
 import torch
 import torch.nn.functional as F
 import torchaudio
 from torch.cuda.amp import autocast
 from torch.utils.data import Dataset
 from tqdm import tqdm
 
-from modelscope.metainfo import Trainers
-from modelscope.models import Model, TorchModel
-from modelscope.msdatasets import MsDataset
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, ModelFile
-from modelscope.utils.device import create_device
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import (get_dist_info, get_local_rank,
+from weathon.registry import TRAINERS
+from weathon.utils.constants import DEFAULT_MODEL_REVISION, ModelFile
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import TorchModel, BaseTrainer, BaseModel
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.device import create_device
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import (get_dist_info, get_local_rank,
                                           init_dist)
 
 EVAL_KEY = 'si-snr'
 
 logger = get_logger()
 
 
@@ -43,16 +40,16 @@
         model_revision: the git version of model on modelhub
     """
 
     def __init__(self,
                  model: str,
                  work_dir: str,
                  cfg_file: Optional[str] = None,
-                 train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-                 eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
+                 train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+                 eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
                  model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
                  **kwargs):
 
         if isinstance(model, str):
             self.model_dir = self.get_or_download_model_dir(
                 model, model_revision)
             if cfg_file is None:
@@ -141,15 +138,15 @@
             run_opts=run_opts,
             checkpointer=self.hparams['checkpointer'],
         )
 
     def build_model(self) -> torch.nn.Module:
         """ Instantiate a pytorch model and return.
         """
-        model = Model.from_pretrained(
+        model = BaseModel.from_pretrained(
             self.model_dir, cfg_dict=self.cfg, training=True)
         if isinstance(model, TorchModel) and hasattr(model, 'model'):
             return model.model
         elif isinstance(model, torch.nn.Module):
             return model
 
     def train(self, *args, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/audio/tts_trainer.py` & `weathon-0.0.0.14/weathon/trainers/audio/tts_trainer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,53 +1,48 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import shutil
 import tempfile
 import zipfile
 from typing import Callable, Dict, List, Optional, Tuple, Union
 
 import json
 
-from modelscope.metainfo import Preprocessors, Trainers
-from modelscope.models import Model
-from modelscope.models.audio.tts import SambertHifigan
-from modelscope.msdatasets import MsDataset
-from modelscope.preprocessors.builder import build_preprocessor
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.audio.audio_utils import TtsTrainType
-from modelscope.utils.audio.tts_exceptions import (
+from weathon.base import BaseTrainer, BaseModel
+from weathon.registry import TRAINERS, build_preprocessor
+from weathon.utils.constants import DEFAULT_DATASET_NAMESPACE, DEFAULT_DATASET_REVISION, DEFAULT_MODEL_REVISION, \
+    ModelFile, Tasks
+from weathon.utils.constants.metainfo import Preprocessors, Trainers
+from weathon.models.audio.tts import SambertHifigan
+from weathon.utils.audio.audio_utils import TtsTrainType
+from weathon.utils.audio.tts_exceptions import (
     TtsTrainingCfgNotExistsException, TtsTrainingDatasetInvalidException,
     TtsTrainingHparamsInvalidException, TtsTrainingInvalidModelException,
     TtsTrainingWorkDirNotExistsException)
-from modelscope.utils.config import Config
-from modelscope.utils.constant import (DEFAULT_DATASET_NAMESPACE,
-                                       DEFAULT_DATASET_REVISION,
-                                       DEFAULT_MODEL_REVISION, ModelFile,
-                                       Tasks, TrainerStages)
-from modelscope.utils.data_utils import to_device
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.data_utils import to_device
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @TRAINERS.register_module(module_name=Trainers.speech_kantts_trainer)
 class KanttsTrainer(BaseTrainer):
     DATA_DIR = 'data'
     AM_TMP_DIR = 'tmp_am'
     VOC_TMP_DIR = 'tmp_voc'
     ORIG_MODEL_DIR = 'orig_model'
 
     def __init__(self,
-                 model: Union[Model, str],
+                 model: Union[BaseModel, str],
                  work_dir: str = None,
                  speaker: str = 'F7',
                  lang_type: str = 'PinYin',
                  cfg_file: str = None,
-                 train_dataset: Union[MsDataset, str] = None,
+                 train_dataset: Union[WtDataset, str] = None,
                  train_dataset_namespace: str = DEFAULT_DATASET_NAMESPACE,
                  train_dataset_revision: str = DEFAULT_DATASET_REVISION,
                  train_type: dict = {
                      TtsTrainType.TRAIN_TYPE_SAMBERT: {},
                      TtsTrainType.TRAIN_TYPE_VOC: {}
                  },
                  preprocess_skip_script=False,
@@ -102,15 +97,15 @@
             if isinstance(train_dataset, str):
                 if os.path.exists(train_dataset):
                     logger.info(f'load {train_dataset}')
                     self.raw_dataset_path = train_dataset
                 else:
                     logger.info(
                         f'load {train_dataset_namespace}/{train_dataset}')
-                    train_dataset = MsDataset.load(
+                    train_dataset = WtDataset.load(
                         dataset_name=train_dataset,
                         namespace=train_dataset_namespace,
                         version=train_dataset_revision)
                     logger.info(f'train dataset:{train_dataset.config_kwargs}')
                     self.raw_dataset_path = self.load_dataset_raw_path(
                         train_dataset)
             else:
@@ -173,24 +168,24 @@
                         self.raw_dataset_path = dataset
                     else:
                         if 'id' in dataset:
                             namespace = dataset.get('namespace',
                                                     DEFAULT_DATASET_NAMESPACE)
                             revision = dataset.get('revision',
                                                    DEFAULT_DATASET_REVISION)
-                            ms = MsDataset.load(
+                            ms = WtDataset.load(
                                 dataset_name=dataset['id'],
                                 namespace=namespace,
                                 version=revision)
                             self.raw_dataset_path = self.load_dataset_raw_path(
                                 ms)
                         elif 'path' in dataset:
                             self.raw_dataset_path = dataset['path']
 
-    def load_dataset_raw_path(self, dataset: MsDataset):
+    def load_dataset_raw_path(self, dataset: WtDataset):
         if 'split_config' not in dataset.config_kwargs:
             raise TtsTrainingDatasetInvalidException(
                 'split_config not found in config_kwargs')
         if 'train' not in dataset.config_kwargs['split_config']:
             raise TtsTrainingDatasetInvalidException(
                 'no train split in split_config')
         return dataset.config_kwargs['split_config']['train']
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/builder.py` & `weathon-0.0.0.14/weathon/registry/trainer.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,39 +1,33 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.metainfo import Trainers
-from modelscope.pipelines.builder import normalize_model_input
-from modelscope.pipelines.util import is_official_hub_path
-from modelscope.utils.config import check_config
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION
-from modelscope.utils.hub import read_config
-from modelscope.utils.plugins import (register_modelhub_repo,
-                                      register_plugins_repo)
-from modelscope.utils.registry import Registry, build_from_cfg
+from weathon.registry.registry import Registry,build_from_cfg
+from weathon.utils.config.config import ConfigDict
+from weathon.utils.constants import DEFAULT_MODEL_REVISION
+from weathon.utils.constants.metainfo import Trainers
+from weathon.utils.hub.utils import read_config
+from weathon.utils.pipeline_utils import is_official_hub_path, normalize_model_input
+from weathon.utils.plugins import register_plugins_repo, register_modelhub_repo
 
 TRAINERS = Registry('trainers')
 
 
-def build_trainer(name: str = Trainers.default, default_args: dict = None):
+def build_trainer(cfg:ConfigDict,task_name:str=None, default_args: dict = None):
     """ build trainer given a trainer name
 
     Args:
         name (str, optional):  Trainer name, if None, default trainer
             will be used.
         default_args (dict, optional): Default initialization arguments.
     """
-    cfg = dict(type=name)
+    # TODO: 
+    cfg["type"] = default_args.get("type", cfg.get("type", Trainers.default))
+    cfg = cfg.to_dict()
     model = default_args.get('model', None)
     model_revision = default_args.get('model_revision', DEFAULT_MODEL_REVISION)
 
-    if isinstance(model, str) \
-            or (isinstance(model, list) and isinstance(model[0], str)):
+    if isinstance(model, str) or (isinstance(model, list) and isinstance(model[0], str)):
         if is_official_hub_path(model, revision=model_revision):
             # read config file from hub and parse
-            configuration = read_config(
-                model, revision=model_revision) if isinstance(
-                    model, str) else read_config(
-                        model[0], revision=model_revision)
+            configuration = read_config(model, revision=model_revision) if isinstance(model, str) else read_config(model[0], revision=model_revision)
             model_dir = normalize_model_input(model, model_revision)
             register_plugins_repo(configuration.safe_get('plugins'))
-            register_modelhub_repo(model_dir,
-                                   configuration.get('allow_remote', False))
-    return build_from_cfg(cfg, TRAINERS, default_args=default_args)
+            register_modelhub_repo(model_dir, configuration.get('allow_remote', False))
+    return build_from_cfg(cfg, TRAINERS, group_key=task_name, default_args=default_args)
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cli_argument_parser.py` & `weathon-0.0.0.14/weathon/trainers/cli_argument_parser.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/__init__.py` & `weathon-0.0.0.14/weathon/trainers/cv/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .image_instance_segmentation_trainer import \
         ImageInstanceSegmentationTrainer
     from .image_portrait_enhancement_trainer import ImagePortraitEnhancementTrainer
     from .movie_scene_segmentation_trainer import MovieSceneSegmentationTrainer
     from .image_inpainting_trainer import ImageInpaintingTrainer
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/action_detection_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/action_detection_trainer.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import os.path as osp
 from typing import Callable, Dict, Optional
 
 import torch
 from detectron2.checkpoint import DetectionCheckpointer
 from detectron2.data import (build_detection_test_loader,
@@ -14,24 +12,24 @@
 from detectron2.solver import LRMultiplier, WarmupParamScheduler
 from detectron2.solver.build import get_default_optimizer_params
 from detectron2.utils import comm
 from detectron2.utils.file_io import PathManager
 from detectron2.utils.logger import setup_logger
 from fvcore.common.param_scheduler import CosineParamScheduler
 
-from modelscope.hub.check_model import check_local_model_is_latest
-from modelscope.hub.snapshot_download import snapshot_download
-from modelscope.metainfo import Trainers
-from modelscope.metrics.action_detection_evaluator import DetEvaluator
-from modelscope.models.cv.action_detection.modules.action_detection_pytorch import \
+from weathon.base import BaseTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModelFile, Invoke
+from weathon.utils.constants.metainfo import Trainers
+from weathon.metrics.action_detection_evaluator import DetEvaluator
+from weathon.models.cv.action_detection.modules.action_detection_pytorch import \
     build_action_detection_model
-from modelscope.preprocessors.cv.action_detection_mapper import VideoDetMapper
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import Invoke, ModelFile, Tasks
+from weathon.preprocessors.cv.action_detection_mapper import VideoDetMapper
+from weathon.utils.hub.check_model import check_local_model_is_latest
+from weathon.utils.hub.utils import snapshot_download
 
 
 @TRAINERS.register_module(module_name=Trainers.action_detection)
 class ActionDetectionTrainer(BaseTrainer):
 
     def __init__(self,
                  model_id,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/card_detection_scrfd_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/card_detection_scrfd_trainer.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.metainfo import Trainers
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.cv.face_detection_scrfd_trainer import \
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.trainers.cv.face_detection_scrfd_trainer import \
     FaceDetectionScrfdTrainer
 
 
 @TRAINERS.register_module(module_name=Trainers.card_detection_scrfd)
 class CardDetectionScrfdTrainer(FaceDetectionScrfdTrainer):
 
     def __init__(self, cfg_file: str, *args, **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/cartoon_translation_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/cartoon_translation_trainer.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import os.path as osp
 from typing import Dict, Optional
 
 import numpy as np
 import tensorflow as tf
 from packaging import version
 from tqdm import tqdm
 
-from modelscope.models.cv.cartoon import (CartoonModel, all_file,
+from weathon.base import BaseTrainer
+from weathon.models.cv.cartoon import (CartoonModel, all_file,
                                           simple_superpixel, tf_data_loader,
                                           write_batch_image)
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 if version.parse(tf.__version__) < version.parse('2'):
     pass
 else:
     logger.info(
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/face_detection_scrfd_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/face_detection_scrfd_trainer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import copy
 import os
 import os.path as osp
 import time
 from typing import Callable, Dict, Optional
 
-from modelscope.metainfo import Trainers
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
+from weathon.base import BaseTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
 
 
 @TRAINERS.register_module(module_name=Trainers.face_detection_scrfd)
 class FaceDetectionScrfdTrainer(BaseTrainer):
 
     def __init__(self,
                  cfg_file: str,
@@ -28,22 +27,22 @@
         from mmcv.runner import get_dist_info, init_dist
         from mmcv.utils import get_git_hash
         from mmdet.utils import collect_env, get_root_logger
         from mmdet.apis import set_random_seed
         from mmdet.models import build_detector
         from mmdet.datasets import build_dataset
         from mmdet import __version__
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets import RetinaFaceDataset
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import DefaultFormatBundleV2
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import LoadAnnotationsV2
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import RotateV2
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import RandomSquareCrop
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones import ResNetV1e
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.dense_heads import SCRFDHead
-        from modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors import SCRFD
+        from weathon.models.cv.face_detection.scrfd.mmdet_patch.datasets import RetinaFaceDataset
+        from weathon.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import DefaultFormatBundleV2
+        from weathon.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import LoadAnnotationsV2
+        from weathon.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import RotateV2
+        from weathon.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines import RandomSquareCrop
+        from weathon.models.cv.face_detection.scrfd.mmdet_patch.models.backbones import ResNetV1e
+        from weathon.models.cv.face_detection.scrfd.mmdet_patch.models.dense_heads import SCRFDHead
+        from weathon.models.cv.face_detection.scrfd.mmdet_patch.models.detectors import SCRFD
         super().__init__(cfg_file)
         cfg = self.cfg
         if 'work_dir' in kwargs:
             cfg.work_dir = kwargs['work_dir']
         else:
             # use config filename as default work_dir if work_dir is None
             cfg.work_dir = osp.join('./work_dirs',
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/image_classifition_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/image_classifition_trainer.py`

 * *Files 10% similar despite different names*

```diff
@@ -2,28 +2,24 @@
 # publicly available at https://github.com/open-mmlab/mmclassification
 import copy
 import os
 import os.path as osp
 import time
 from typing import Callable, Dict, Optional, Tuple, Union
 
-import numpy as np
 import torch
 from torch import nn
 from torch.utils.data import Dataset
 
-from modelscope.hub.snapshot_download import snapshot_download
-from modelscope.metainfo import Trainers
-from modelscope.models.base import TorchModel
-from modelscope.msdatasets.ms_dataset import MsDataset
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, Invoke, ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.registry import TRAINERS
+from weathon.utils.constants import DEFAULT_MODEL_REVISION, ModelFile
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BasePreprocessor, BaseTrainer, TorchModel
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.logger import get_logger
 
 
 def train_model(model,
                 dataset,
                 cfg,
                 distributed=False,
                 val_dataset=None,
@@ -32,16 +28,14 @@
                 meta=None):
     import torch
     import warnings
     from mmcv.runner import (DistSamplerSeedHook, Fp16OptimizerHook,
                              build_optimizer, build_runner, get_dist_info)
     from mmcls.core import DistEvalHook, DistOptimizerHook, EvalHook
     from mmcls.datasets import build_dataloader
-    from mmcls.utils import (wrap_distributed_model,
-                             wrap_non_distributed_model)
     from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
 
     logger = get_logger()
 
     # prepare data loaders
     dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]
     sampler_cfg = cfg.train.get('sampler', None)
@@ -163,18 +157,18 @@
     def __init__(
             self,
             model: Optional[Union[TorchModel, nn.Module, str]] = None,
             cfg_file: Optional[str] = None,
             arg_parse_fn: Optional[Callable] = None,
             data_collator: Optional[Union[Callable, Dict[str,
                                                          Callable]]] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            preprocessor: Optional[Union[Preprocessor,
-                                         Dict[str, Preprocessor]]] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            preprocessor: Optional[Union[BasePreprocessor,
+                                         Dict[str, BasePreprocessor]]] = None,
             optimizers: Tuple[torch.optim.Optimizer,
                               torch.optim.lr_scheduler._LRScheduler] = (None,
                                                                         None),
             model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
             seed: int = 0,
             cfg_modify_fn: Optional[Callable] = None,
             **kwargs):
@@ -183,21 +177,19 @@
         Args:
             model: model id
             model_version: model version, default is None.
             cfg_modify_fn: An input fn which is used to modify the cfg read out of the file.
         """
         import torch
         import mmcv
-        from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, get_classes
         from mmcls.models import build_classifier
         from mmcv.runner import get_dist_info, init_dist
         from mmcls.apis import set_random_seed
         from mmcls.utils import collect_env
         from mmcv.utils import get_logger as mmcv_get_logger
-        import modelscope.models.cv.image_classification.backbones
 
         self._seed = seed
         set_random_seed(self._seed)
         if isinstance(model, str):
             self.model_dir = self.get_or_download_model_dir(
                 model, model_revision=model_revision)
             if cfg_file is None:
@@ -328,15 +320,15 @@
         self.distributed = distributed
         self.timestamp = timestamp
         self.meta = meta
         self.logger = logger
 
     def train(self, *args, **kwargs):
         from mmcls import __version__
-        from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform
+        from weathon.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform
         from mmcls.utils import setup_multi_processes
 
         if self.train_dataset is None:
             raise ValueError(
                 "Not found train dataset, please set the 'train_dataset' parameter!"
             )
 
@@ -401,24 +393,22 @@
             device='cpu' if self.device == 'cpu' else 'cuda',
             meta=self.meta)
 
     def evaluate(self,
                  checkpoint_path: str = None,
                  *args,
                  **kwargs) -> Dict[str, float]:
-        import warnings
         import torch
-        from modelscope.models.cv.image_classification.utils import (
+        from weathon.models.cv.image_classification.utils import (
             get_ms_dataset_root, MmDataset, preprocess_transform,
             get_trained_checkpoints_name)
         from mmcls.datasets import build_dataloader
         from mmcv.runner import get_dist_info, load_checkpoint, wrap_fp16_model
         from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
         from mmcls.apis import multi_gpu_test, single_gpu_test
-        from mmcls.utils import setup_multi_processes
 
         if self.eval_dataset is None:
             raise ValueError(
                 "Not found evaluate dataset, please set the 'eval_dataset' parameter!"
             )
 
         self.cfg.model.mm_model.pretrained = None
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/image_defrcn_fewshot_detection_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/image_defrcn_fewshot_detection_trainer.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,22 +16,21 @@
                                    verify_results)
 from detectron2.evaluation.testing import print_csv_format
 from detectron2.solver.build import build_lr_scheduler, build_optimizer
 from detectron2.utils import comm
 from torch import nn
 from torch.nn.parallel import DistributedDataParallel
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model, TorchModel
-from modelscope.models.cv.image_defrcn_fewshot.evaluation.evaluator import \
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModelFile, DEFAULT_MODEL_REVISION
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, TorchModel, BaseTrainer
+from weathon.models.cv.image_defrcn_fewshot.evaluation.evaluator import \
     inference_on_dataset
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 
 class DefaultTrainer(SimpleTrainer):
     """
     Trainer inherit from detectron2 SimpleTrainer, use detectron2 framework to train.
     """
 
@@ -143,19 +142,19 @@
     def build_evaluator(cls, cfg, dataset_name, output_folder=None):
 
         if output_folder is None:
             output_folder = os.path.join(cfg.OUTPUT_DIR, 'inference')
         evaluator_list = []
         evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type
         if evaluator_type == 'coco':
-            from modelscope.models.cv.image_defrcn_fewshot.evaluation.coco_evaluation import COCOEvaluator
+            from weathon.models.cv.image_defrcn_fewshot.evaluation.coco_evaluation import COCOEvaluator
             evaluator_list.append(
                 COCOEvaluator(dataset_name, True, output_folder))
         if evaluator_type == 'pascal_voc':
-            from modelscope.models.cv.image_defrcn_fewshot.evaluation.pascal_voc_evaluation import PascalVOCEvaluator
+            from weathon.models.cv.image_defrcn_fewshot.evaluation.pascal_voc_evaluation import PascalVOCEvaluator
             return PascalVOCEvaluator(dataset_name)
         if len(evaluator_list) == 0:
             raise NotImplementedError(
                 'no Evaluator for the dataset {} with the type {}'.format(
                     dataset_name, evaluator_type))
         if len(evaluator_list) == 1:
             return evaluator_list[0]
@@ -290,9 +289,9 @@
                       data_type='pascal_voc',
                       method='remove',
                       params_name=[
                           'model.roi_heads.box_predictor.cls_score',
                           'model.roi_heads.box_predictor.bbox_pred'
                       ]):
 
-        from modelscope.models.cv.image_defrcn_fewshot.utils.model_surgery_op import model_surgery as _model_surgery
+        from weathon.models.cv.image_defrcn_fewshot.utils.model_surgery_op import model_surgery as _model_surgery
         _model_surgery(src_path, save_dir, data_type, method, params_name)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/image_detection_damoyolo_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/image_detection_damoyolo_trainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,42 +1,38 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import datetime
 import math
 import os
 import time
 from typing import Dict
 
 import torch
 import torch.distributed as dist
 import torch.multiprocessing as mp
 import torch.nn as nn
 from easydict import EasyDict as easydict
 from torch.nn.parallel import DistributedDataParallel as DDP
 
-from modelscope.metainfo import Trainers
-from modelscope.models.cv.tinynas_detection.damo.apis.detector_evaluater import \
+from weathon.base import BaseTrainer
+from weathon.datasets.custom_datasets.damoyolo import build_dataset, build_dataloader
+from weathon.utils.constants import DEFAULT_MODEL_REVISION, ThirdParty, ModelFile
+from weathon.utils.constants.metainfo import Trainers
+from weathon.models.cv.tinynas_detection.damo.apis.detector_evaluater import \
     Evaluater
-from modelscope.models.cv.tinynas_detection.damo.apis.detector_inference import \
+from weathon.models.cv.tinynas_detection.damo.apis.detector_inference import \
     inference
-from modelscope.models.cv.tinynas_detection.damo.base_models.losses.distill_loss import \
+from weathon.models.cv.tinynas_detection.damo.base_models.losses.distill_loss import \
     FeatureLoss
-from modelscope.models.cv.tinynas_detection.damo.detectors.detector import (
+from weathon.models.cv.tinynas_detection.damo.detectors.detector import (
     build_ddp_model, build_local_model)
-from modelscope.models.cv.tinynas_detection.damo.utils import (
+from weathon.models.cv.tinynas_detection.damo.utils import (
     cosine_scheduler, ema_model)
-from modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo import (
-    build_dataloader, build_dataset)
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.checkpoint import save_checkpoint
-from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, ModelFile,
-                                       ThirdParty)
-from modelscope.utils.logger import get_logger
-from modelscope.utils.metric import MeterBuffer
-from modelscope.utils.torch_utils import get_rank, synchronize
+from weathon.utils.checkpoint import save_checkpoint
+from weathon.utils.logger import get_logger
+from weathon.utils.metric import MeterBuffer
+from weathon.utils.torch_utils import get_rank, synchronize
 
 
 @TRAINERS.register_module(module_name=Trainers.tinynas_damoyolo)
 class ImageDetectionDamoyoloTrainer(BaseTrainer):
 
     def __init__(self,
                  model: str = None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/image_inpainting_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/image_inpainting_trainer.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import time
 from collections.abc import Mapping
 
 from torch import distributed as dist
 
-from modelscope.metainfo import Trainers
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.trainer import EpochBasedTrainer
-from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, ConfigFields,
-                                       ConfigKeys, Hubs, ModeKeys, ModelFile,
-                                       Tasks, TrainerStages)
-from modelscope.utils.data_utils import to_device
-from modelscope.utils.file_utils import func_receive_dict_inputs
+from weathon.base import EpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import TrainerStages, ModeKeys
+from weathon.utils.constants.metainfo import Trainers
+from weathon.utils.data_utils import to_device
+from weathon.utils.fileio.file_utils import func_receive_dict_inputs
 
 
 @TRAINERS.register_module(module_name=Trainers.image_inpainting)
 class ImageInpaintingTrainer(EpochBasedTrainer):
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/image_instance_segmentation_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/movie_scene_segmentation_trainer.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.metainfo import Trainers
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.trainer import EpochBasedTrainer
+from weathon.base import EpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
 
 
-@TRAINERS.register_module(module_name=Trainers.image_instance_segmentation)
-class ImageInstanceSegmentationTrainer(EpochBasedTrainer):
+@TRAINERS.register_module(module_name=Trainers.movie_scene_segmentation)
+class MovieSceneSegmentationTrainer(EpochBasedTrainer):
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
-    def collate_fn(self, data):
-        # we skip this func due to some special data type, e.g., BitmapMasks
-        return data
-
     def train(self, *args, **kwargs):
         super().train(*args, **kwargs)
 
     def evaluate(self, *args, **kwargs):
         metric_values = super().evaluate(*args, **kwargs)
         return metric_values
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/image_portrait_enhancement_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/image_portrait_enhancement_trainer.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from collections.abc import Mapping
 
 import torch
 from torch import distributed as dist
 
-from modelscope.metainfo import Trainers
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.optimizer.builder import build_optimizer
-from modelscope.trainers.trainer import EpochBasedTrainer
-from modelscope.utils.constant import ModeKeys
-from modelscope.utils.logger import get_logger
+from weathon.base import EpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.utils.logger import get_logger
 
 
 @TRAINERS.register_module(module_name=Trainers.image_portrait_enhancement)
 class ImagePortraitEnhancementTrainer(EpochBasedTrainer):
 
     def train_step(self, model, inputs):
         """ Perform a training step on a batch of inputs.
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/nerf_recon_acc_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/nerf_recon_acc_trainer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,35 +1,32 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import glob
 import os
 import os.path as osp
 import random
 import time
-from datetime import datetime
 from typing import Dict, Optional
 
 import cv2
 import numpy as np
 import torch
 import torch.nn.functional as F
 import tqdm
 
-from modelscope.metainfo import Trainers
-from modelscope.models.cv.nerf_recon_acc import NeRFReconPreprocessor
-from modelscope.models.cv.nerf_recon_acc.dataloader.nerf_dataset import (
+from weathon.base import BaseTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.models.cv.nerf_recon_acc import NeRFReconPreprocessor
+from weathon.models.cv.nerf_recon_acc.dataloader.nerf_dataset import (
     BlenderDataset, ColmapDataset)
-from modelscope.models.cv.nerf_recon_acc.network.nerf import NeRFModel
-from modelscope.models.cv.nerf_recon_acc.network.segmenter import \
+from weathon.models.cv.nerf_recon_acc.network.nerf import NeRFModel
+from weathon.models.cv.nerf_recon_acc.network.segmenter import \
     ObjectSegmenter
-from modelscope.models.cv.nerf_recon_acc.network.utils import PSNR
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.models.cv.nerf_recon_acc.network.utils import PSNR
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @TRAINERS.register_module(module_name=Trainers.nerf_recon_acc)
 class NeRFReconAccTrainer(BaseTrainer):
     """initialize the acceleration version of nerf reconstruction model for object.
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/ocr_detection_db_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/ocr_detection_db_trainer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import copy
 import datetime
 import math
 import os
 import time
 from typing import Callable, Dict, Optional
 
@@ -10,26 +9,25 @@
 import torch
 import torch.distributed as dist
 import torch.multiprocessing as mp
 import torch.nn as nn
 from easydict import EasyDict as easydict
 from tqdm import tqdm
 
-from modelscope.metainfo import Trainers
-from modelscope.models.cv.ocr_detection.modules.dbnet import (DBModel,
+from weathon.base import BaseTrainer
+from weathon.datasets.custom_datasets import ImageDataset, DataLoader, QuadMeasurer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import DEFAULT_MODEL_REVISION
+from weathon.utils.constants.metainfo import Trainers
+from weathon.models.cv.ocr_detection.modules.dbnet import (DBModel,
                                                               DBModel_v2)
-from modelscope.models.cv.ocr_detection.utils import (boxes_from_bitmap,
+from weathon.models.cv.ocr_detection.utils import (boxes_from_bitmap,
                                                       polygons_from_bitmap)
-from modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection import (
-    DataLoader, ImageDataset, QuadMeasurer)
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, ModelFile
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import get_rank, synchronize
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import get_rank, synchronize
 
 
 @TRAINERS.register_module(module_name=Trainers.ocr_detection_db)
 class OCRDetectionDBTrainer(BaseTrainer):
 
     def __init__(self,
                  model: str = None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/ocr_recognition_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/ocr_recognition_trainer.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,22 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import time
-from collections.abc import Mapping
-
 import torch
 from torch import distributed as dist
 
-from modelscope.metainfo import Trainers
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.trainer import EpochBasedTrainer
-from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, ConfigFields,
-                                       ConfigKeys, Hubs, ModeKeys, ModelFile,
-                                       Tasks, TrainerStages)
-from modelscope.utils.data_utils import to_device
-from modelscope.utils.file_utils import func_receive_dict_inputs
+from weathon.base import EpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModeKeys
+from weathon.utils.constants.metainfo import Trainers
 
 
 @TRAINERS.register_module(module_name=Trainers.ocr_recognition)
 class OCRRecognitionTrainer(EpochBasedTrainer):
 
     def evaluate(self, *args, **kwargs):
         metric_values = super().evaluate(*args, **kwargs)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/cv/vision_efficient_tuning_trainer.py` & `weathon-0.0.0.14/weathon/trainers/cv/vision_efficient_tuning_trainer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,15 @@
 # Copyright 2022-2023 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Union
 
 from torch import nn
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model, TorchModel
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.default_config import merge_hooks
-from modelscope.trainers.trainer import EpochBasedTrainer
-from modelscope.utils.constant import ModeKeys
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, TorchModel, EpochBasedTrainer
 
 
 @TRAINERS.register_module(module_name=Trainers.vision_efficient_tuning)
 class VisionEfficientTuningTrainer(EpochBasedTrainer):
     """ Vision Efficient Tuning Trainer based on EpochBasedTrainer
 
     The trainer freezes the parameters of the pre-trained model and
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/default_config.py` & `weathon-0.0.0.14/weathon/utils/config/default_config.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import Dict, List, Optional, Tuple
 
-from modelscope.utils.config import Config
+from weathon.utils.config.config import Config
 
 DEFAULT_HOOKS_CONFIG = {
     'train.hooks': [{
         'type': 'CheckpointHook',
         'interval': 1
     }, {
         'type': 'TextLoggerHook',
@@ -21,20 +19,18 @@
     'CheckpointHook': 'train.checkpoint.period',
     'BestCkptSaverHook': 'train.checkpoint.best',
     'EvaluationHook': 'evaluation.period',
 }
 
 
 def merge_cfg(cfg: Config):
-    """Merge the default config into the input cfg.
-
-    This function will pop the default CheckpointHook when the BestCkptSaverHook exists in the input cfg.
-
+    """
+    "BestCkptSaverHook","CheckpointHook"
     Aegs:
-        cfg: The input cfg to be merged into.
+        cfg: 
     """
     cfg.merge_from_dict(DEFAULT_HOOKS_CONFIG, force=False)
 
 
 def merge_hooks(cfg: Config) -> List[Dict]:
     hooks = getattr(cfg.train, 'hooks', []).copy()
     for hook_type, key_chain in _HOOK_KEY_CHAIN_MAP.items():
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/__init__.py` & `weathon-0.0.0.14/weathon/hooks/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .builder import HOOKS, build_hook
     from .early_stop_hook import EarlyStopHook
     from .compression import SparsityHook
     from .evaluation_hook import EvaluationHook
     from .hook import Hook
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/checkpoint/checkpoint_hook.py` & `weathon-0.0.0.14/weathon/hooks/checkpoint/checkpoint_hook.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,38 +1,34 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import random
 import time
 from typing import Optional
 
 import numpy as np
 import torch
 
-from modelscope.hub.check_model import check_model_is_id
-from modelscope.hub.push_to_hub import push_to_hub_async
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.trainers.hooks.checkpoint.checkpoint_processor import \
-    CheckpointProcessor
-from modelscope.trainers.hooks.hook import Hook
-from modelscope.trainers.hooks.priority import Priority
-from modelscope.utils.constant import (DEFAULT_REPOSITORY_REVISION, LogKeys,
-                                       ModelFile)
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import is_master
+from weathon.base import BaseHook
+from weathon.hooks.checkpoint.checkpoint_processor import CheckpointProcessor
+from weathon.registry import HOOKS
+from weathon.utils.constants import Priority, DEFAULT_REPOSITORY_REVISION, ModelFile, LogKeys
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.hub.check_model import check_model_is_id
+from weathon.utils.hub.push_to_hub import push_to_hub_async
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import is_master
 
 
 class CheckpointStrategy:
     by_epoch = 'by_epoch'
     by_step = 'by_step'
     no = 'no'
 
 
 @HOOKS.register_module(module_name=Hooks.CheckpointHook)
-class CheckpointHook(Hook):
+class CheckpointHook(BaseHook):
     """Save checkpoints periodically.
 
     Args:
         save_strategy(str): The strategy to save checkpoint, can be `by_epoch`, `by_step` or `no`
         interval (int): The frequency to save model. If `by_epoch=True`,
             it means the number of epochs, else means the number of iterations
         save_dir (str): The directory to save checkpoints. If is None, use `trainer.work_dir`
@@ -109,16 +105,15 @@
         if not self.save_dir:
             self.save_dir = trainer.work_dir
         if not self.output_dir:
             if self.output_sub_dir:
                 self.output_dir = os.path.join(self.save_dir,
                                                self.output_sub_dir)
             else:
-                self.output_dir = os.path.join(self.save_dir,
-                                               ModelFile.TRAIN_OUTPUT_DIR)
+                self.output_dir = os.path.join(self.save_dir,ModelFile.TRAIN_OUTPUT_DIR)
 
         if not os.path.exists(self.save_dir):
             os.makedirs(self.save_dir, exist_ok=True)
 
         if not hasattr(trainer, 'logger'):
             self.logger = get_logger()
         else:
@@ -181,26 +176,25 @@
 
     def _push_to_hub(self, trainer, prefix):
         if self.is_model_id is None:
             self.is_model_id = check_model_is_id(trainer.input_model_id,
                                                  self.hub_token)
         self.tag += 1
         return push_to_hub_async(
-            self.hub_repo_id,
-            self.output_dir,
-            token=self.hub_token,
-            private=self.private_hub,
-            commit_message=prefix,
-            tag=f'v1.{self.tag}',
-            revision=self.hub_revision,
-            source_repo=trainer.input_model_id if self.is_model_id else '')
+                                self.hub_repo_id,
+                                self.output_dir,
+                                token=self.hub_token,
+                                private=self.private_hub,
+                                commit_message=prefix,
+                                tag=f'v1.{self.tag}',
+                                revision=self.hub_revision,
+                                source_repo=trainer.input_model_id if self.is_model_id else '')
 
     def save_evaluate_results(self, trainer):
-        with open(os.path.join(self.output_dir, self.EVAL_RESULT_FILE),
-                  'w') as f:
+        with open(os.path.join(self.output_dir, self.EVAL_RESULT_FILE),'w') as f:
             f.write(str(trainer.metric_values))
 
     def _save_checkpoint(self, trainer, prefix):
         """Save checkpoint files and remove obsolete ones
         """
         checkpoint_path_prefix = os.path.join(self.save_dir, prefix)
         meta = self._create_training_state(trainer)
@@ -208,16 +202,15 @@
                                         self.output_dir, meta)
         self.save_evaluate_results(trainer)
         self.history_checkpoints.append(checkpoint_path_prefix)
         self._remove_obsolete_checkpoints(trainer)
         return prefix
 
     def _remove_obsolete_checkpoints(self, trainer):
-        if self.max_checkpoint_num is not None and \
-                len(self.history_checkpoints) > self.max_checkpoint_num:
+        if self.max_checkpoint_num is not None and len(self.history_checkpoints) > self.max_checkpoint_num:
             history_checkpoints = [ckpt for ckpt in self.history_checkpoints]
             self.history_checkpoints.clear()
             for i, checkpoint_path_prefix in enumerate(history_checkpoints):
                 if i < len(history_checkpoints) - self.max_checkpoint_num:
                     self.logger.info(
                         f'deleting checkpoint: {checkpoint_path_prefix}')
                     self.processor.remove_checkpoints(
@@ -239,33 +232,32 @@
                            self.interval) or (self.save_last
                                               and check_last(trainer)):
             return True
         return False
 
     def _create_training_state(self, trainer):
         self.rng_state = {
-            'random': random.getstate(),
-            'numpy': np.random.get_state(),
-            'cpu': torch.random.get_rng_state(),
-            'cuda': torch.cuda.get_rng_state_all(),
-        }
+                            'random': random.getstate(),
+                            'numpy': np.random.get_state(),
+                            'cpu': torch.random.get_rng_state(),
+                            'cuda': torch.cuda.get_rng_state_all(),
+                        }
 
         # keep epoch/iter/inner_iter/random_state
         meta = {
-            'epoch': trainer.epoch,
-            'iter': trainer.iter + 1,
-            'inner_iter': trainer.inner_iter + 1,
-            'rng_state': self.rng_state,
-        }
+                    'epoch': trainer.epoch,
+                    'iter': trainer.iter + 1,
+                    'inner_iter': trainer.inner_iter + 1,
+                    'rng_state': self.rng_state,
+                }
 
         # keep hooks state
         i = 0
         for hook in trainer.hooks:
-            if hasattr(hook, 'state_dict') and getattr(hook, '_should_save',
-                                                       True):
+            if hasattr(hook, 'state_dict') and getattr(hook, '_should_save',True):
                 meta[f'{hook.__class__}-{i}'] = hook.state_dict()
                 i += 1
 
         return meta
 
 
 @HOOKS.register_module(module_name=Hooks.BestCkptSaverHook)
@@ -320,27 +312,27 @@
         self._best_metric = None
         self._best_ckpt_file = None
         self.save_file_name = save_file_name
         self.restore_best = restore_best
         self.history_checkpoints = set()
 
     def after_train_epoch(self, trainer):
-        from modelscope.trainers.hooks import EvaluationHook
+        from weathon.hooks import EvaluationHook
         eval_hook = trainer.get_hook(EvaluationHook)
         if len(eval_hook) == 0:
             self.logger.error(
                 'Trying to save the best checkpoint, but there is no evaluation, skipping.'
             )
 
         if eval_hook[0].last_eval_tag == (
                 'epoch', trainer.epoch) and self._should_save(trainer):
             self._do_save(trainer, 'by_epoch')
 
     def after_train_iter(self, trainer):
-        from modelscope.trainers.hooks import EvaluationHook
+        from weathon.hooks import EvaluationHook
         eval_hook = trainer.get_hook(EvaluationHook)
         if len(eval_hook) == 0:
             self.logger.error(
                 'Trying to save the best checkpoint, but there is no evaluation, skipping.'
             )
 
         if eval_hook[0].last_eval_tag == (
@@ -427,9 +419,9 @@
                 'The state_dict is not available, the best metric value will be affected.'
             )
 
     def after_run(self, trainer):
         if self.restore_best:
             # If restore_best is True, will call the LoadCheckpointHook to load the best checkpoint
             # for later evaluation or prediction.
-            from modelscope.trainers.hooks.checkpoint.load_checkpoint_hook import LoadCheckpointHook
+            from weathon.hooks import LoadCheckpointHook
             LoadCheckpointHook.load_checkpoint(self._best_ckpt_file, trainer)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/checkpoint/checkpoint_processor.py` & `weathon-0.0.0.14/weathon/hooks/checkpoint/checkpoint_processor.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import re
 import shutil
 
-from modelscope.metainfo import Pipelines
-from modelscope.utils.checkpoint import (load_checkpoint, save_checkpoint,
+from weathon.utils.constants import ModelFile
+from weathon.utils.constants.metainfo import Pipelines
+from weathon.utils.checkpoint import (load_checkpoint, save_checkpoint,
                                          save_configuration)
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import is_master
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import is_master
 
 
 class CheckpointProcessor:
 
     TRAINER_STATE_SUFFIX = '_trainer_state.pth'
 
     MODEL_STATE_SUFFIX = '.pth'
@@ -34,16 +33,15 @@
         if config['task'] in [
                 getattr(Pipelines, attr) for attr in dir(Pipelines)
                 if not attr.startswith('__')
         ]:
             # TODO a temp fix to avoid pipeline_name and task mismatch
             config['pipeline'] = {'type': config['task']}
 
-        self.copy_files_and_dump_config(trainer, output_dir, config,
-                                        self._bin_file(model))
+        self.copy_files_and_dump_config(trainer, output_dir, config, self._bin_file(model))
 
     @staticmethod
     def copy_files_and_dump_config(trainer, output_dir, config, bin_file):
         """Copy useful files to target output folder and dumps the target configuration.json.
         """
         model = trainer.unwrap_module(trainer.model)
 
@@ -68,41 +66,32 @@
             if config.safe_get('train.checkpoint.best.' + pop_key) is not None:
                 config.safe_get('train.checkpoint.best').pop(pop_key)
 
         save_config_fn = SaveConfig(output_dir, config)
 
         if hasattr(model, 'save_pretrained'):
             # Save pretrained of model, skip saving checkpoint
-            model.save_pretrained(
-                output_dir,
-                bin_file,
-                save_function=lambda *args, **kwargs: None,
-                config=save_config_fn.config,
-                save_config_function=save_config_fn)
+            model.save_pretrained(output_dir,
+                                  bin_file,
+                                  save_function=lambda *args, **kwargs: None,
+                                  config=save_config_fn.config,
+                                  save_config_function=save_config_fn)
 
         if trainer.train_preprocessor is not None:
-            trainer.train_preprocessor.save_pretrained(
-                output_dir,
-                save_config_fn.config,
-                save_config_function=save_config_fn)
+            trainer.train_preprocessor.save_pretrained(output_dir, save_config_fn.config, save_config_function=save_config_fn)
         if trainer.eval_preprocessor is not None:
-            trainer.eval_preprocessor.save_pretrained(
-                output_dir,
-                save_config_fn.config,
-                save_config_function=save_config_fn)
+            trainer.eval_preprocessor.save_pretrained(output_dir, save_config_fn.config, save_config_function=save_config_fn)
         save_config_fn.save_config()
 
     @staticmethod
     def _bin_file(model):
         """Get bin file path.
         """
         default_bin_file = ModelFile.TORCH_MODEL_BIN_FILE
-        if hasattr(model,
-                   'model_dir') and ModelFile.TORCH_MODEL_FILE in os.listdir(
-                       model.model_dir):
+        if hasattr(model, 'model_dir') and ModelFile.TORCH_MODEL_FILE in os.listdir(model.model_dir):
             default_bin_file = ModelFile.TORCH_MODEL_FILE
         return default_bin_file
 
     def save_checkpoints(self,
                          trainer,
                          checkpoint_path_prefix,
                          output_dir,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/checkpoint/load_checkpoint_hook.py` & `weathon-0.0.0.14/weathon/hooks/checkpoint/load_checkpoint_hook.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import random
 from typing import Optional
 
 import numpy as np
 import torch
 from packaging import version
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.trainers.hooks.checkpoint.checkpoint_processor import \
-    CheckpointProcessor
-from modelscope.trainers.hooks.hook import Hook
-from modelscope.trainers.hooks.priority import Priority
-from modelscope.utils.logger import get_logger
+from weathon.base import BaseHook
+from weathon.hooks.checkpoint.checkpoint_processor import CheckpointProcessor
+from weathon.registry import HOOKS
+from weathon.utils.constants import Priority
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.logger import get_logger
 
 
 @HOOKS.register_module(module_name=Hooks.LoadCheckpointHook)
-class LoadCheckpointHook(Hook):
+class LoadCheckpointHook(BaseHook):
     """Load a checkpoint file at the beginning of training or evaluating.
 
     This hook does not need to be configured or saved in the config file.
     User should use it by:
     >>> trainer.train('some-checkpoint', load_all_state=True)
     or
     >>> trainer.evaluate('some-checkpoint')
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/compression/sparsity_hook.py` & `weathon-0.0.0.14/weathon/hooks/compression/sparsity_hook.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.trainers.hooks.hook import Hook
-from modelscope.trainers.hooks.priority import Priority
-from modelscope.utils.checkpoint import save_checkpoint
-from modelscope.utils.torch_utils import is_master
+from weathon.base import BaseHook
+from weathon.registry import HOOKS
+from weathon.utils.constants import Priority
+from weathon.utils.constants.metainfo import Hooks
+
+from weathon.utils.checkpoint import save_checkpoint
+from weathon.utils.torch_utils import is_master
 
 
 @HOOKS.register_module(module_name=Hooks.SparsityHook)
-class SparsityHook(Hook):
+class SparsityHook(BaseHook):
 
     PRIORITY = Priority.HIGHEST
 
     def __init__(self, pruning_method, config={}, save_dir=None):
         self.pruning_method = pruning_method
         self.save_dir = save_dir
 
@@ -38,39 +38,37 @@
 
         from .utils import SparseLinear, convert_sparse_network
 
         if self.save_dir is None:
             self.save_dir = trainer.work_dir
 
         if len(self.compress_module) == 0:
-            convert_sparse_network(
-                trainer.model,
-                pruning_method=self.pruning_method,
-                weight_rank=self.weight_rank,
-                weight_beta=self.weight_beta,
-                mask_rank=self.mask_rank,
-                mask_alpha1=self.mask_alpha1,
-                mask_alpha2=self.mask_alpha2,
-                logger=trainer.logger,
-            )
+            convert_sparse_network(trainer.model,
+                                    pruning_method=self.pruning_method,
+                                    weight_rank=self.weight_rank,
+                                    weight_beta=self.weight_beta,
+                                    mask_rank=self.mask_rank,
+                                    mask_alpha1=self.mask_alpha1,
+                                    mask_alpha2=self.mask_alpha2,
+                                    logger=trainer.logger,)
         else:
             for cm in self.compress_module:
                 for name, module in trainer.model.named_modules():
                     if name != cm:
                         continue
                     convert_sparse_network(
-                        module,
-                        pruning_method=self.pruning_method,
-                        weight_rank=self.weight_rank,
-                        weight_beta=self.weight_beta,
-                        mask_rank=self.mask_rank,
-                        mask_alpha1=self.mask_alpha1,
-                        mask_alpha2=self.mask_alpha2,
-                        logger=trainer.logger,
-                    )
+                                            module,
+                                            pruning_method=self.pruning_method,
+                                            weight_rank=self.weight_rank,
+                                            weight_beta=self.weight_beta,
+                                            mask_rank=self.mask_rank,
+                                            mask_alpha1=self.mask_alpha1,
+                                            mask_alpha2=self.mask_alpha2,
+                                            logger=trainer.logger,
+                                        )
 
         for i in range(len(trainer.optimizer.param_groups)):
             new_train_params = []
             for param in trainer.optimizer.param_groups[i]['params']:
                 is_find = False
                 for name, module in trainer.model.named_modules():
                     if isinstance(module, SparseLinear):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/compression/utils.py` & `weathon-0.0.0.14/weathon/hooks/compression/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn as nn
 
-from modelscope.utils.torch_utils import is_master
+from weathon.utils.torch_utils import is_master
 
 
 class SparseBinarizer(torch.autograd.Function):
 
     @staticmethod
     def forward(ctx, mask_scores, sparsity):
         num_prune = int(mask_scores.numel() * sparsity)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/distributed/ddp_hook.py` & `weathon-0.0.0.14/weathon/hooks/distributed/ddp_hook.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.trainers.hooks.hook import Hook
-from modelscope.trainers.hooks.priority import Priority
-from modelscope.utils.constant import DistributedParallelType
-from modelscope.utils.device import create_device
-from modelscope.utils.torch_utils import get_local_rank, init_dist
+from weathon.base import BaseHook
+from weathon.registry import HOOKS
+from weathon.utils.constants import Priority, DistributedParallelType
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.device import create_device
+from weathon.utils.torch_utils import get_local_rank, init_dist
 
 
 @HOOKS.register_module(module_name=Hooks.DDPHook)
-class DDPHook(Hook):
+class DDPHook(BaseHook):
 
     PRIORITY = Priority.LOW
 
     def __init__(self, launcher):
         """The DDP Hook for data parallel
 
         Args:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/distributed/deepspeed_hook.py` & `weathon-0.0.0.14/weathon/hooks/distributed/deepspeed_hook.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import shutil
 
 import deepspeed
 import torch
 from deepspeed import DeepSpeedEngine
 from megatron_util import mpu, print_rank_0
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks import LoadCheckpointHook
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.trainers.hooks.checkpoint.checkpoint_hook import (
-    BestCkptSaverHook, CheckpointHook)
-from modelscope.trainers.hooks.hook import Hook
-from modelscope.trainers.hooks.priority import Priority
-from modelscope.utils.checkpoint import save_checkpoint
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.checkpoint import save_checkpoint
+from weathon.utils.logger import get_logger
+from .. import CheckpointHook, BestCkptSaverHook, LoadCheckpointHook
 from ..checkpoint.checkpoint_processor import CheckpointProcessor
 from ..lr_scheduler_hook import LrSchedulerProcessor
 from ..optimizer.base import OptimizerHook, OptimizerProcessor
+from ...base import BaseHook
+from ...registry import HOOKS
+from ...utils.constants import Priority
 
 
 class DeepspeedProcessor(CheckpointProcessor, LrSchedulerProcessor,
                          OptimizerProcessor):
 
     _BIN_FILE_DIR = 'model'
 
@@ -135,15 +132,15 @@
         pass
 
     def step(self, trainer):
         pass
 
 
 @HOOKS.register_module(module_name=Hooks.DeepspeedHook)
-class DeepspeedHook(Hook):
+class DeepspeedHook(BaseHook):
     PRIORITY = Priority.VERY_HIGH
 
     def __init__(self,
                  deepspeed_activation_checkpointing=True,
                  save_zero_checkpoint=False,
                  with_mpu=True):
         self.save_zero_checkpoint = save_zero_checkpoint
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/distributed/megatron_hook.py` & `weathon-0.0.0.14/weathon/hooks/distributed/megatron_hook.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,27 +1,25 @@
 import os
 import shutil
 
 import torch
 from megatron_util import mpu
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers import EpochBasedTrainer
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.trainers.hooks.checkpoint.checkpoint_hook import (
-    BestCkptSaverHook, CheckpointHook, CheckpointProcessor)
-from modelscope.trainers.hooks.checkpoint.load_checkpoint_hook import \
-    LoadCheckpointHook
-from modelscope.trainers.hooks.hook import Hook
-from modelscope.utils.checkpoint import load_checkpoint, save_checkpoint
-from modelscope.utils.constant import DistributedParallelType
-from modelscope.utils.device import create_device
-from modelscope.utils.logger import get_logger
-from modelscope.utils.megatron_utils import is_megatron_initialized
-from modelscope.utils.torch_utils import get_local_rank
+from weathon.base import EpochBasedTrainer, BaseHook
+from weathon.hooks import LoadCheckpointHook, CheckpointHook, BestCkptSaverHook
+from weathon.hooks.checkpoint.checkpoint_processor import CheckpointProcessor
+from weathon.registry import HOOKS
+from weathon.utils.constants import DistributedParallelType
+from weathon.utils.constants.metainfo import Hooks
+
+from weathon.utils.checkpoint import load_checkpoint, save_checkpoint
+from weathon.utils.device import create_device
+from weathon.utils.logger import get_logger
+from weathon.utils.megatron_utils import is_megatron_initialized
+from weathon.utils.torch_utils import get_local_rank
 
 
 class MpuProcessor(CheckpointProcessor):
 
     _BIN_FILE_DIR = 'model'
 
     def rank_name(self):
@@ -123,47 +121,41 @@
 
             model_file = os.path.join(save_dir, prefix + '_' + bin_file)
             load_checkpoint(model_file, model, None, None)
             return meta
 
 
 @HOOKS.register_module(module_name=Hooks.MegatronHook)
-class MegatronHook(Hook):
+class MegatronHook(BaseHook):
 
     _BIN_FILE_DIR = 'model'
 
     def __init__(self):
         self.wrapped = False
 
     def register_processor(self, trainer: EpochBasedTrainer):
         processor = MpuProcessor()
         ckpt_hook = trainer.get_hook(CheckpointHook)
-        if len(ckpt_hook) > 0 and not isinstance(ckpt_hook[0].processor,
-                                                 MpuProcessor):
+        if len(ckpt_hook) > 0 and not isinstance(ckpt_hook[0].processor,MpuProcessor):
             ckpt_hook[0].set_processor(processor)
         best_ckpt_hook = trainer.get_hook(BestCkptSaverHook)
-        if len(best_ckpt_hook) > 0 and not isinstance(
-                best_ckpt_hook[0].processor, MpuProcessor):
+        if len(best_ckpt_hook) > 0 and not isinstance(best_ckpt_hook[0].processor, MpuProcessor):
             best_ckpt_hook[0].set_processor(processor)
         load_ckpt_hook = trainer.get_hook(LoadCheckpointHook)
-        if len(load_ckpt_hook) > 0 and not isinstance(
-                load_ckpt_hook[0].processor, MpuProcessor):
+        if len(load_ckpt_hook) > 0 and not isinstance(load_ckpt_hook[0].processor, MpuProcessor):
             load_ckpt_hook[0].set_processor(processor)
 
     def after_init(self, trainer):
         assert is_megatron_initialized()
         local_rank = get_local_rank()
         trainer.device = create_device(f'cuda:{local_rank}')
         trainer.model.to(trainer.device)
-        trainer.parallel_groups[
-            DistributedParallelType.DP] = mpu.get_data_parallel_group()
-        trainer.parallel_groups[DistributedParallelType.
-                                TP] = mpu.get_tensor_model_parallel_group()
-        trainer.parallel_groups[DistributedParallelType.
-                                PP] = mpu.get_pipeline_model_parallel_group()
+        trainer.parallel_groups[DistributedParallelType.DP] = mpu.get_data_parallel_group()
+        trainer.parallel_groups[DistributedParallelType.TP] = mpu.get_tensor_model_parallel_group()
+        trainer.parallel_groups[DistributedParallelType.PP] = mpu.get_pipeline_model_parallel_group()
 
     def before_run(self, trainer):
         self.wrap_module(trainer)
 
     def before_val(self, trainer):
         self.wrap_module(trainer)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/early_stop_hook.py` & `weathon-0.0.0.14/weathon/hooks/early_stop_hook.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import numpy as np
 
-from modelscope.metainfo import Hooks
-from modelscope.utils.logger import get_logger
-from .builder import HOOKS
-from .hook import Hook
-from .priority import Priority
+from weathon.models.cv.image_colorization.unet.utils import Hook
+from weathon.registry import HOOKS
+from weathon.utils.constants import Priority
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.logger import get_logger
 
 
 class EarlyStopStrategy:
     by_epoch = 'by_epoch'
     by_step = 'by_step'
     no = 'no'
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/evaluation_hook.py` & `weathon-0.0.0.14/weathon/hooks/evaluation_hook.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,24 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from collections import OrderedDict
 from typing import Optional
 
-from modelscope.metainfo import Hooks
-from .builder import HOOKS
-from .hook import Hook
+from weathon.base import BaseHook
+from weathon.registry import HOOKS
+from weathon.utils.constants.metainfo import Hooks
 
 
 class EvaluationStrategy:
     by_epoch = 'by_epoch'
     by_step = 'by_step'
     no = 'no'
 
 
 @HOOKS.register_module(module_name=Hooks.EvaluationHook)
-class EvaluationHook(Hook):
+class EvaluationHook(BaseHook):
     """
     Evaluation hook.
 
     Args:
         interval (int): Evaluation interval.
         by_epoch (bool): Evaluate by epoch or by iteration.
         start_idx (int or None, optional): The epoch or iterations validation begins.
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/hook.py` & `weathon-0.0.0.14/weathon/base/hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,14 @@
-# Copyright (c) OpenMMLab. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from functools import wraps
 
-from modelscope.utils.constant import TrainerStages
-from modelscope.utils.import_utils import is_method_overridden
-from .priority import Priority
+from weathon.utils.constants import TrainerStages, Priority
+from weathon.utils.import_utils import is_method_overridden
 
 
-class Hook:
+class BaseHook:
     """
     The Hook base class of any modelscope trainer. You can build your own hook inherited from this class.
     """
 
     stages = (TrainerStages.after_init, TrainerStages.before_run,
               TrainerStages.before_val, TrainerStages.before_train_epoch,
               TrainerStages.before_train_iter, TrainerStages.after_train_iter,
@@ -244,18 +241,18 @@
         Whether to reach the last iteration in the entire training process
         Returns: bool
         """
         return trainer.iter + 1 == trainer.max_iters
 
     def get_triggered_stages(self):
         trigger_stages = set()
-        for stage in Hook.stages:
-            if is_method_overridden(stage, Hook, self):
+        for stage in BaseHook.stages:
+            if is_method_overridden(stage, BaseHook, self):
                 trigger_stages.add(stage)
 
-        return [stage for stage in Hook.stages if stage in trigger_stages]
+        return [stage for stage in BaseHook.stages if stage in trigger_stages]
 
     def state_dict(self):
         return {}
 
     def load_state_dict(self, state_dict):
         pass
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/iter_timer_hook.py` & `weathon-0.0.0.14/weathon/hooks/iter_timer_hook.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import time
 
-from modelscope.metainfo import Hooks
-from modelscope.utils.constant import LogKeys
-from .builder import HOOKS
-from .hook import Hook
-from .priority import Priority
+from weathon.base import BaseHook
+from weathon.registry import HOOKS
+from weathon.utils.constants import Priority, LogKeys
+from weathon.utils.constants.metainfo import Hooks
+
 
 
 @HOOKS.register_module(module_name=Hooks.IterTimerHook)
-class IterTimerHook(Hook):
+class IterTimerHook(BaseHook):
     PRIORITY = Priority.LOW
 
     def before_epoch(self, trainer):
         self.start_time = time.time()
 
     def before_iter(self, trainer):
-        trainer.log_buffer.update(
-            {LogKeys.DATA_LOAD_TIME: time.time() - self.start_time})
+        trainer.log_buffer.update({LogKeys.DATA_LOAD_TIME: time.time() - self.start_time})
 
     def after_iter(self, trainer):
         trainer.log_buffer.update(
             {LogKeys.ITER_TIME: time.time() - self.start_time})
         self.start_time = time.time()
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/logger/base.py` & `weathon-0.0.0.14/weathon/hooks/logger/base.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,21 +1,19 @@
 # Copyright (c) OpenMMLab. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import numbers
 from abc import ABCMeta, abstractmethod
 
 import numpy as np
 import torch
 
-from modelscope.trainers.hooks.hook import Hook
-from modelscope.trainers.hooks.priority import Priority
-from modelscope.utils.constant import ModeKeys
+from weathon.base import BaseHook
+from weathon.utils.constants import Priority, ModeKeys
 
 
-class LoggerHook(Hook):
+class LoggerHook(BaseHook):
     """Base class for logger hooks.
 
     Args:
         interval (int): Logging interval (every k iterations). It is interval of iterations even by_epoch is true.
         ignore_last (bool): Ignore the log of last iterations in each epoch
             if less than `interval`.
         reset_flag (bool): Whether to clear the output buffer after logging.
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/logger/tensorboard_hook.py` & `weathon-0.0.0.14/weathon/hooks/logger/tensorboard_hook.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
 import numpy as np
 import torch
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.utils.constant import LogKeys
-from modelscope.utils.torch_utils import master_only
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.torch_utils import master_only
 from .base import LoggerHook
+from ...registry import HOOKS
+from ...utils.constants import LogKeys
 
 
 @HOOKS.register_module(module_name=Hooks.TensorboardHook)
 class TensorboardHook(LoggerHook):
     """
     TensorBoard hook for visualization.
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/logger/text_logger_hook.py` & `weathon-0.0.0.14/weathon/hooks/logger/text_logger_hook.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import datetime
 import os
 import os.path as osp
 from collections import OrderedDict
 
 import json
 import torch
 from torch import distributed as dist
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.utils.constant import LogKeys, ModeKeys
-from modelscope.utils.json_utils import EnhancedEncoder
-from modelscope.utils.torch_utils import is_master
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.fileio.format.json_utils import EnhancedEncoder
+from weathon.utils.torch_utils import is_master
 from .base import LoggerHook
+from ...registry import HOOKS
+from ...utils.constants import LogKeys, ModeKeys
 
 
 @HOOKS.register_module(module_name=Hooks.TextLoggerHook)
 class TextLoggerHook(LoggerHook):
     """Logger hook in text, Output log to both console and local json file.
 
     Args:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/lr_scheduler_hook.py` & `weathon-0.0.0.14/weathon/hooks/lr_scheduler_hook.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+from weathon.base import BaseHook
+from weathon.registry import HOOKS, build_lr_scheduler
+from weathon.utils.constants import Priority, LogKeys
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import is_master
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers.lrscheduler.builder import build_lr_scheduler
-from modelscope.utils.constant import LogKeys
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import is_master
-from .builder import HOOKS
-from .hook import Hook
-from .priority import Priority
 
 
 class LrSchedulerProcessor:
 
     def __init__(self):
         self.lr_strategy = None
         self.warmup_lr_scheduler = None
@@ -43,15 +40,15 @@
 class LrStrategy:
     by_epoch = 'by_epoch'
     by_step = 'by_step'
     no = 'no'
 
 
 @HOOKS.register_module(module_name=Hooks.LrSchedulerHook)
-class LrSchedulerHook(Hook):
+class LrSchedulerHook(BaseHook):
     """Lr scheduler.
 
     Args:
         by_epoch (bool): Whether lr changes by epoch
         warmup (dict): warm up config
     """
     PRIORITY = Priority.LOW
@@ -73,17 +70,15 @@
     def set_processor(self, processor):
         self.processor = processor
 
     def before_run(self, trainer):
         self.processor.set_lr_strategy(self.lr_strategy)
         if self.warmup is not None:
             assert isinstance(self.warmup, dict) and 'type' in self.warmup
-            self.warmup_lr_scheduler = build_lr_scheduler(
-                cfg=self.warmup,
-                default_args={'base_scheduler': trainer.lr_scheduler})
+            self.warmup_lr_scheduler = build_lr_scheduler(cfg=self.warmup, default_args={'base_scheduler': trainer.lr_scheduler})
             self.processor.set_warmup_lr_scheduler(self.warmup_lr_scheduler)
 
         self.processor.initialize_lr_scheduler(trainer)
 
     def get_current_lr(self, trainer):
         import torch
 
@@ -146,15 +141,15 @@
             if self.warmup_lr_scheduler is not None:
                 self.warmup_lr_scheduler.step(metrics=metrics)
             else:
                 trainer.lr_scheduler.step(metrics=metrics)
 
 
 @HOOKS.register_module(module_name=Hooks.PlateauLrSchedulerHook)
-class PlateauLrSchedulerHook(Hook):
+class PlateauLrSchedulerHook(BaseHook):
     """Lr scheduler hook for `ReduceLROnPlateau`.
 
     Args:
         metric_key (str): Metric key returned from `trainer.metric_values`,
             get the value of metric key and pass it to `ReduceLROnPlateau.step`.
     """
     PRIORITY = Priority.LOW  # should be after EvaluationHook
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/__init__.py` & `weathon-0.0.0.14/weathon/hooks/optimizer/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .apex_optimizer_hook import ApexAMPOptimizerHook
     from .base import OptimizerHook, NoneOptimizerHook
     from .torch_optimizer_hook import TorchAMPOptimizerHook
 else:
     _import_structure = {
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/apex_optimizer_hook.py` & `weathon-0.0.0.14/weathon/hooks/optimizer/apex_optimizer_hook.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import logging
 
 import torch
 from packaging import version
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks import Hook
-from modelscope.trainers.hooks.builder import HOOKS
+from weathon.utils.constants.metainfo import Hooks
 from .base import OptimizerHook, OptimizerProcessor
+from ...base import BaseHook
+from ...registry import HOOKS
 
 
 class ApexOptimizerProcessor(OptimizerProcessor):
 
     def __init__(self, opt_level):
         self.opt_level = opt_level
 
@@ -38,25 +37,25 @@
 
         from apex import amp
         for k in loss_keys:
             with amp.scale_loss(trainer.train_outputs[k],
                                 trainer.optimizer) as scaled_loss:
                 scaled_loss.backward()
 
-        if Hook.every_n_iters(trainer, cumulative_iters):
+        if BaseHook.every_n_iters(trainer, cumulative_iters):
             if grad_clip is not None:
                 OptimizerProcessor.clip_grads(trainer.model.parameters(),
                                               **grad_clip)
 
             trainer.optimizer.step()
             trainer.optimizer.zero_grad()
 
 
 @HOOKS.register_module(module_name=Hooks.ApexAMPOptimizerHook)
-class ApexAMPOptimizerHook(Hook):
+class ApexAMPOptimizerHook(BaseHook):
     """
     Fp16 optimizer, if torch version is less than 1.6.0,
     you must install apex (https://www.github.com/nvidia/apex) else use torch.cuda.amp by default
 
     Args:
         opt_level (str): "O0" and "O3" are not true mixed precision,
             but they are useful for establishing accuracy and speed baselines, respectively.
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/base.py` & `weathon-0.0.0.14/weathon/hooks/optimizer/base.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-import logging
-
 from torch.nn.utils import clip_grad
 
-from modelscope.metainfo import Hooks
-from modelscope.outputs import OutputKeys
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.trainers.hooks.hook import Hook
-from modelscope.trainers.hooks.priority import Priority
+from weathon.base import BaseHook
+from weathon.registry import HOOKS
+from weathon.utils.constants import Priority
+from weathon.utils.constants.metainfo import Hooks
+from weathon.utils.constants.output_constant import OutputKeys
 
 
 class OptimizerProcessor:
 
     def initialize_optimizer(self, trainer):
         """Initialize the optimizer.
 
@@ -33,31 +30,30 @@
             cumulative_iters(`int`): The cumulative iters for gradients.
             grad_clip(`dict`): The grad clipping options.
         """
         for k in loss_keys:
             trainer.train_outputs[k] /= cumulative_iters
             trainer.train_outputs[k].backward()
 
-        if Hook.every_n_iters(trainer, cumulative_iters):
+        if BaseHook.every_n_iters(trainer, cumulative_iters):
             if grad_clip is not None:
                 self.clip_grads(trainer.model.parameters(), **grad_clip)
 
             trainer.optimizer.step()
             trainer.optimizer.zero_grad()
 
     @staticmethod
     def clip_grads(params, **clip_args):
-        params = list(
-            filter(lambda p: p.requires_grad and p.grad is not None, params))
+        params = list(filter(lambda p: p.requires_grad and p.grad is not None, params))
         if len(params) > 0:
             return clip_grad.clip_grad_norm_(params, **clip_args)
 
 
 @HOOKS.register_module(module_name=Hooks.OptimizerHook)
-class OptimizerHook(Hook):
+class OptimizerHook(BaseHook):
     """Optimizer hook
 
     Args:
         cumulative_iters (int): interval of gradients accumulation. Default: 1
         grad_clip (dict): Default None. Containing keys:
             max_norm (float or int): max norm of the gradients
             norm_type (float or int): type of the used p-norm. Can be ``'inf'`` for infinity norm.
@@ -96,16 +92,15 @@
 
 
 @HOOKS.register_module(module_name=Hooks.NoneOptimizerHook)
 class NoneOptimizerHook(OptimizerHook):
 
     def __init__(self, cumulative_iters=1, grad_clip=None, loss_keys='loss'):
 
-        super(NoneOptimizerHook, self).__init__(
-            grad_clip=grad_clip, loss_keys=loss_keys)
+        super(NoneOptimizerHook, self).__init__(grad_clip=grad_clip, loss_keys=loss_keys)
         self.cumulative_iters = cumulative_iters
 
     def before_run(self, trainer):
         return
 
     def after_train_iter(self, trainer):
         return
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/optimizer/torch_optimizer_hook.py` & `weathon-0.0.0.14/weathon/hooks/optimizer/torch_optimizer_hook.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import logging
 
-from modelscope.metainfo import Hooks
-from modelscope.trainers.hooks import Hook
-from modelscope.trainers.hooks.builder import HOOKS
+from weathon.utils.constants.metainfo import Hooks
 from .base import OptimizerHook, OptimizerProcessor
+from ...base import BaseHook
+from ...registry import HOOKS
 
 
 class TorchAMPOptimizerProcessor(OptimizerProcessor):
 
     def __init__(self, scaler, scale_update_param):
         self.scaler = scaler
         self.scale_update_param = scale_update_param
@@ -28,29 +27,29 @@
     def backward(self, trainer, loss_keys, cumulative_iters, grad_clip):
         for k in loss_keys:
             trainer.train_outputs[k] /= cumulative_iters
 
         for k in loss_keys:
             self.scaler.scale(trainer.train_outputs[k]).backward()
 
-        if Hook.every_n_iters(trainer, cumulative_iters):
+        if BaseHook.every_n_iters(trainer, cumulative_iters):
             self.scaler.unscale_(trainer.optimizer)
             if grad_clip is not None:
                 OptimizerProcessor.clip_grads(trainer.model.parameters(),
                                               **grad_clip)
 
             self.scaler.step(trainer.optimizer)
             self.scaler.update(self.scale_update_param)
             trainer.optimizer.zero_grad()
 
         setattr(self._model, 'forward', self._ori_model_forward)
 
 
 @HOOKS.register_module(module_name=Hooks.TorchAMPOptimizerHook)
-class TorchAMPOptimizerHook(Hook):
+class TorchAMPOptimizerHook(BaseHook):
     """
     Fp16 optimizer, if torch version is less than 1.6.0,
     you must install apex (https://www.github.com/nvidia/apex) else use torch.cuda.amp by default
 
     Args:
         cumulative_iters (int): interval of gradients accumulation. Default: 1
         grad_clip (dict): Default None. Containing keys:
@@ -80,13 +79,9 @@
         else:
             raise ValueError(
                 '`loss_scale` type must be in [float, dict], but got {loss_scale}'
             )
 
     def register_processor(self, trainer):
         optimizer_hook = trainer.get_hook(OptimizerHook)
-        if len(optimizer_hook) > 0 and type(
-                optimizer_hook[0].processor) in (type(None),
-                                                 OptimizerProcessor):
-            optimizer_hook[0].set_processor(
-                TorchAMPOptimizerProcessor(self.scaler,
-                                           self._scale_update_param))
+        if len(optimizer_hook) > 0 and type(optimizer_hook[0].processor) in (type(None), OptimizerProcessor):
+            optimizer_hook[0].set_processor(TorchAMPOptimizerProcessor(self.scaler, self._scale_update_param))
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/hooks/priority.py` & `weathon-0.0.0.14/weathon/utils/constants/hook_priority.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) OpenMMLab. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from enum import Enum
 from typing import Union
 
 
 class Priority(Enum):
     """Hook priority levels.
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/builder.py` & `weathon-0.0.0.14/weathon/registry/lr_scheduler.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import inspect
 
 import torch
 from packaging import version
 
-from modelscope.utils.config import ConfigDict
-from modelscope.utils.registry import Registry, build_from_cfg, default_group
+from weathon.utils.config.config import ConfigDict
+from weathon.registry.registry import Registry, build_from_cfg, default_group
 
 LR_SCHEDULER = Registry('lr_scheduler')
 
 
-def build_lr_scheduler(cfg: ConfigDict, default_args: dict = None):
+def build_lr_scheduler(cfg: ConfigDict,task_name:str=default_group, default_args: dict = None):
     """ build lr scheduler from given lr scheduler config dict
 
     Args:
         cfg (:obj:`ConfigDict`): config dict for lr scheduler object.
         default_args (dict, optional): Default initialization arguments.
     """
     if cfg['type'].lower().endswith('warmup'):
@@ -28,27 +27,25 @@
         # build lr scheduler without warmup
         if not hasattr(cfg, 'optimizer'):
             if default_args is None or ('optimizer' not in default_args):
                 raise ValueError(
                     'Must provide ``optimizer`` which is an instance of ``torch.optim.Optimizer`` '
                     'for build lr scheduler')
 
-    return build_from_cfg(
-        cfg, LR_SCHEDULER, group_key=default_group, default_args=default_args)
+    return build_from_cfg(cfg, LR_SCHEDULER, group_key=task_name, default_args=default_args)
 
 
 def register_torch_lr_scheduler():
     from torch.optim import lr_scheduler
     if version.parse(torch.__version__) < version.parse('2.0.0.dev'):
         from torch.optim.lr_scheduler import _LRScheduler
     else:
         from torch.optim.lr_scheduler import LRScheduler as _LRScheduler
 
     members = inspect.getmembers(lr_scheduler)
 
     for name, obj in members:
-        if (inspect.isclass(obj) and issubclass(
-                obj, _LRScheduler)) or name in ['ReduceLROnPlateau']:
+        if (inspect.isclass(obj) and issubclass(obj, _LRScheduler)) or name in ['ReduceLROnPlateau']:
             LR_SCHEDULER.register_module(module_name=name, module_cls=obj)
 
 
 register_torch_lr_scheduler()
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/warmup/base.py` & `weathon-0.0.0.14/weathon/base/lr_scheduler.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from torch.optim.lr_scheduler import _LRScheduler
 
 
 class BaseWarmup(_LRScheduler):
     """Base warmup scheduler
 
     Args:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/lrscheduler/warmup/warmup.py` & `weathon-0.0.0.14/weathon/lrscheduler/warmup.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from modelscope.metainfo import LR_Schedulers
-from modelscope.trainers.lrscheduler.builder import LR_SCHEDULER
-from .base import BaseWarmup
-
+from weathon.base import BaseWarmup
+from weathon.registry import LR_SCHEDULER
+from weathon.utils.constants.metainfo import LR_Schedulers
 
 @LR_SCHEDULER.register_module(module_name=LR_Schedulers.ConstantWarmup)
 class ConstantWarmup(BaseWarmup):
     """Linear warmup scheduler.
 
     Args:
         base_scheduler (torch.optim._LRScheduler): an instance of torch.optim._LRScheduler type
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/multi_modal/clip/clip_trainer.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/clip/clip_trainer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,31 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 import os
 from typing import Callable, Dict, Optional, Tuple, Union
 
 import torch
 from torch import distributed as dist
 from torch import nn
 from torch.utils.data import Dataset
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model, TorchModel
-from modelscope.models.multi_modal.clip.model import convert_models_to_fp32
-from modelscope.msdatasets.ms_dataset import MsDataset
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.multi_modal import CLIPPreprocessor
-from modelscope.trainers import EpochBasedTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.default_config import merge_cfg, update_cfg
-from modelscope.trainers.optimizer.builder import build_optimizer
-from modelscope.utils.config import Config
-from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, ConfigKeys,
-                                       Invoke, ModeKeys, ModelFile, ThirdParty)
+from weathon.registry import TRAINERS, build_optimizer
+from weathon.utils.constants import DEFAULT_MODEL_REVISION, ThirdParty, ModelFile, Invoke, ConfigKeys, ModeKeys
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, TorchModel, EpochBasedTrainer
+from weathon.models.multi_modal.clip.model import convert_models_to_fp32
+from weathon.base import BasePreprocessor
+from weathon.preprocessors.multi_modal import CLIPPreprocessor
+from weathon.utils.config.default_config import merge_cfg, update_cfg
+from weathon.utils.config.config import Config
+from weathon.utils.dataset.dataset import WtDataset
 from .clip_trainer_utils import get_loss, get_optimizer_params, get_schedule
 
 
 def exclude(n):
     return 'bn' in n or 'ln' in n or 'bias' in n or 'logit_scale' in n
 
 
@@ -40,18 +35,17 @@
             self,
             model: Optional[Union[TorchModel, nn.Module, str]] = None,
             cfg_file: Optional[str] = None,
             cfg_modify_fn: Optional[Callable] = None,
             arg_parse_fn: Optional[Callable] = None,
             data_collator: Optional[Union[Callable, Dict[str,
                                                          Callable]]] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            preprocessor: Optional[Union[Preprocessor,
-                                         Dict[str, Preprocessor]]] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            preprocessor: Optional[Union[BasePreprocessor, Dict[str, BasePreprocessor]]] = None,
             optimizers: Tuple[torch.optim.Optimizer,
                               torch.optim.lr_scheduler._LRScheduler] = (None,
                                                                         None),
             model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
             seed: int = 42,
             **kwargs):
         if isinstance(model, str):
@@ -74,15 +68,15 @@
         merge_cfg(self.cfg)
         self.cfg = self.rebuild_config(self.cfg)
         if 'cfg_options' in kwargs:
             self.cfg.merge_from_dict(kwargs['cfg_options'])
         self.cfg = update_cfg(self.cfg)
         cfg = self.cfg
 
-        model = Model.from_pretrained(
+        model = BaseModel.from_pretrained(
             model, revision=model_revision, invoked_by=Invoke.TRAINER)
         # for training & eval, we convert the model from FP16 back to FP32
         # to compatible with modelscope amp training
         convert_models_to_fp32(model)
 
         if 'work_dir' not in kwargs or len(kwargs['work_dir']) == 0:
             work_dir = cfg.train.work_dir
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/multi_modal/clip/clip_trainer_utils.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/clip/clip_trainer_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 from functools import partial
 from inspect import unwrap
 
 import torch
 import torch.distributed as dist
 from torch.optim.lr_scheduler import LambdaLR
 
-from modelscope.outputs import OutputKeys
+from weathon.utils.constants.output_constant import OutputKeys
 
 
 def get_optimizer_params(model_name, cfg):
     # get default params
     # Params from paper (https://arxiv.org/pdf/2103.00020.pdf)
     # base model
     if model_name in ['damo/multi-modal_clip-vit-base-patch16_zh']:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 # Copyright 2022-2023 The Alibaba Fundamental Vision Team Authors. All rights reserved.
 from typing import Union
 
 import torch
 from torch import nn
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model, TorchModel
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.optimizer.builder import build_optimizer
-from modelscope.trainers.trainer import EpochBasedTrainer
-from modelscope.utils.config import Config, ConfigDict
+from weathon.registry import TRAINERS, build_optimizer
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, TorchModel, EpochBasedTrainer
+from weathon.utils.config.config import Config, ConfigDict
 
 
 @TRAINERS.register_module(module_name=Trainers.efficient_diffusion_tuning)
 class EfficientDiffusionTuningTrainer(EpochBasedTrainer):
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
@@ -21,15 +19,15 @@
     def build_model(self) -> Union[nn.Module, TorchModel]:
         """ Instantiate a pytorch model and return.
 
         By default, we will create a model using config from configuration file. You can
         override this method in a subclass.
 
         """
-        model = Model.from_pretrained(self.model_dir, cfg_dict=self.cfg)
+        model = BaseModel.from_pretrained(self.model_dir, cfg_dict=self.cfg)
         if not isinstance(model, nn.Module) and hasattr(model, 'model'):
             return model.model
         elif isinstance(model, nn.Module):
             return model
 
     def build_optimizer(self, cfg: ConfigDict, default_args: dict = None):
         try:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/multi_modal/mgeo_ranking_trainer.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/mgeo_ranking_trainer.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,24 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from dataclasses import dataclass
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 import torch
 from torch import nn
 from torch.utils.data import Dataset
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import TorchModel
-from modelscope.msdatasets.ms_dataset import MsDataset
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.nlp_trainer import NlpEpochBasedTrainer
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION
-from modelscope.utils.logger import get_logger
+from weathon.base.trainer import NlpEpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import DEFAULT_MODEL_REVISION
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BasePreprocessor, TorchModel
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @dataclass
 class GroupCollator():
     """
@@ -157,17 +154,17 @@
     def __init__(
             self,
             model: Optional[Union[TorchModel, nn.Module, str]] = None,
             cfg_file: Optional[str] = None,
             cfg_modify_fn: Optional[Callable] = None,
             arg_parse_fn: Optional[Callable] = None,
             data_collator: Optional[Callable] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            preprocessor: Optional[Preprocessor] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            preprocessor: Optional[BasePreprocessor] = None,
             optimizers: Tuple[torch.optim.Optimizer,
                               torch.optim.lr_scheduler._LRScheduler] = (None,
                                                                         None),
             model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
             **kwargs):
 
         if data_collator is None:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/multi_modal/ofa/ofa_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/document_grounded_dialog_generate_trainer.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,232 +1,284 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
-import math
 import os
-import shutil
-import tempfile
-from functools import partial
-from shutil import ignore_patterns
-from typing import Callable, Dict, Optional, Tuple, Union
+import re
+import string
+from collections import Counter
 
 import json
+import sacrebleu
 import torch
-from torch import distributed as dist
-from torch import nn
-from torch.utils.data import Dataset
-
-from modelscope.hub.file_download import model_file_download
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model, TorchModel
-from modelscope.msdatasets.ms_dataset import MsDataset
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.preprocessors.multi_modal import OfaPreprocessor
-from modelscope.preprocessors.ofa.utils.collate import collate_fn
-from modelscope.trainers import EpochBasedTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.optimizer.builder import build_optimizer
-from modelscope.trainers.parallel.utils import is_parallel
-from modelscope.utils.config import Config
-from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, ConfigKeys,
-                                       Invoke, ModeKeys, ModelFile)
-from .ofa_trainer_utils import (AdjustLabelSmoothedCrossEntropyCriterion,
-                                get_schedule, recursive_overwrite)
-
-
-@TRAINERS.register_module(module_name=Trainers.ofa)
-class OFATrainer(EpochBasedTrainer):
-    r"""
-    OFA trainer for MaaS.
-
-    Args:
-        model (`str`): A model dir or a model id to be loaded
-        cfg_file (`str`, **optional**, default to `None`):
-            A config dir
-        cfg_modify_fn (`Callable`, **optional**, default to `None`):
-            A function which can rebuild the config file.
-        arg_parse_fn (`Callable`, **optional**, default to `None`):
-            Same as ``parse_fn`` in :obj:`Config.to_args`.
-        data_collator (`Callable`, **optional**, default to `None`):
-            The function to use to form a batch from a list of elements
-            of `train_dataset` or `eval_dataset`.
-        train_dataset (:obj:`MsDataset` or :obj:`Dataset`, **optional**, default to `None`):
-            Dataset for training.
-        eval_dataset (:obj:`MsDataset` or :obj:`Dataset`, **optional**, default to `None`):
-            Dataset for evaluation.
-        preprocessor (:obj:`Preprocessor`, **optional**, default to `None`):
-            The optional preprocessor.
-            NOTE: If the preprocessor has been called before the dataset fed into this trainer by user's custom code,
-            this parameter should be None, meanwhile remove the 'preprocessor' key from the cfg_file.
-            Else the preprocessor will be instantiated from the cfg_file or assigned from this parameter and
-            this preprocessing action will be executed every time the dataset's __getitem__ is called.
-        model_revision (`str`, **optional**, default to `None`):
-            The revision used when the model_name_or_path is
-                a model id of the remote hub. default `None`.
-        seed (`int`, **optional**, default to `42`):
-            The optional random seed for torch, cuda, numpy and random.
-    """
-
-    def __init__(
-            self,
-            model: Optional[Union[TorchModel, nn.Module, str]] = None,
-            cfg_file: Optional[str] = None,
-            cfg_modify_fn: Optional[Callable] = None,
-            arg_parse_fn: Optional[Callable] = None,
-            data_collator: Optional[Union[Callable, Dict[str,
-                                                         Callable]]] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            preprocessor: Optional[Union[Preprocessor,
-                                         Dict[str, Preprocessor]]] = None,
-            optimizers: Tuple[torch.optim.Optimizer,
-                              torch.optim.lr_scheduler._LRScheduler] = (None,
-                                                                        None),
-            model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
-            seed: int = 42,
-            **kwargs):
-        model = Model.from_pretrained(
-            model, revision=model_revision, invoked_by=Invoke.TRAINER)
-        model_dir = model.model_dir
-        self.cfg_modify_fn = cfg_modify_fn
-
-        work_dir = kwargs.get('work_dir', 'workspace')
-        os.makedirs(work_dir, exist_ok=True)
-        ignore_file_set = set()
-        if cfg_file is not None:
-            cfg_file = self.get_config_file(cfg_file)
-            dst = os.path.abspath(
-                os.path.join(work_dir, ModelFile.CONFIGURATION))
-            src = os.path.abspath(cfg_file)
-            if src != dst:
-                shutil.copy(src, work_dir)
-            ignore_file_set.add(ModelFile.CONFIGURATION)
-        recursive_overwrite(
-            model_dir, work_dir, ignore=ignore_patterns(*ignore_file_set))
-        cfg_file = os.path.join(work_dir, ModelFile.CONFIGURATION)
-        cfg = self.rebuild_config(Config.from_file(cfg_file))
-        if cfg_modify_fn is not None:
-            cfg = self.cfg_modify_fn(cfg)
-            with open(cfg_file, 'w') as writer:
-                json.dump(dict(cfg), fp=writer, indent=4)
-        if preprocessor is None:
-            preprocessor = {
-                ConfigKeys.train:
-                OfaPreprocessor(
-                    model_dir=work_dir, mode=ModeKeys.TRAIN, no_collate=True),
-                ConfigKeys.val:
-                OfaPreprocessor(
-                    model_dir=work_dir, mode=ModeKeys.EVAL, no_collate=True),
-            }
-        # use torchrun launch
-        world_size = int(os.environ.get('WORLD_SIZE', 1))
-        epoch_steps = math.ceil(
-            len(train_dataset) /  # noqa
-            (cfg.train.dataloader.batch_size_per_gpu * world_size))  # noqa
-        cfg.train.lr_scheduler.num_train_steps = epoch_steps * cfg.train.max_epochs
-        cfg.train.criterion.tokenizer = model.tokenizer
-        self.criterion = AdjustLabelSmoothedCrossEntropyCriterion(
-            cfg.train.criterion)
-        if optimizers[0] is None:
-            optimizer = build_optimizer(model, cfg=cfg.train.optimizer)
-        else:
-            optimizer = optimizers[0]
-        if optimizers[1] is None:
-            scheduler_class, scheduler_args = get_schedule(
-                cfg.train.lr_scheduler)
-            if scheduler_class is not None:
-                lr_scheduler = scheduler_class(**{'optimizer': optimizer},
-                                               **scheduler_args)
-            else:
-                lr_scheduler = None
-        else:
-            lr_scheduler = optimizers[1]
-        optimizers = (optimizer, lr_scheduler)
-        if data_collator is None:
-            data_collator = partial(
-                collate_fn,
-                pad_idx=model.tokenizer.pad_token_id,
-                eos_idx=model.tokenizer.eos_token_id,
-            )
-        if 'launcher' not in kwargs and cfg.train.get('launcher', None):
-            kwargs['launcher'] = cfg.train.launcher
-        if 'use_fp16' not in kwargs and cfg.train.get('use_fp16', False):
-            kwargs['use_fp16'] = cfg.train.use_fp16
-        kwargs['to_tensor'] = False
-        super().__init__(
-            model=model,
-            cfg_file=cfg_file,
-            arg_parse_fn=arg_parse_fn,
-            cfg_modify_fn=cfg_modify_fn,
-            data_collator=data_collator,
-            train_dataset=train_dataset,
-            eval_dataset=eval_dataset,
-            preprocessor=preprocessor,
-            optimizers=optimizers,
-            seed=seed,
-            **kwargs,
-        )
-
-    def rebuild_config(self, cfg: Config):
-        r"""
-        rebuild config if `cfg_modify_fn` is not `None`.
+import tqdm
+from rouge import Rouge
+from torch.cuda.amp import GradScaler, autocast
+from torch.utils.data import DataLoader
+from transformers import AdamW, get_scheduler
+
+from weathon.base import EpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModeKeys
+from weathon.utils.constants.metainfo import Trainers
+from weathon.preprocessors import DocumentGroundedDialogGeneratePreprocessor
+from weathon.utils.logger import get_logger
+
+logger = get_logger()
+
+
+def collate(batch):
+    query = [item['query'] for item in batch]
+    context = [json.loads(item['rerank']) for item in batch]
+    label = [item['response'] for item in batch]
+    return query, context, label
+
+
+def prepare_optimizer(model, lr, weight_decay, eps):
+    no_decay = ['bias', 'LayerNorm.weight']
+    optimizer_grouped_parameters = [{
+        'params': [
+            p for n, p in model.named_parameters()
+            if not any(nd in n for nd in no_decay)
+        ],
+        'weight_decay':
+        weight_decay,
+    }, {
+        'params': [
+            p for n, p in model.named_parameters()
+            if any(nd in n for nd in no_decay)
+        ],
+        'weight_decay':
+        0.0,
+    }]
+    optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=eps)
+    return optimizer
+
+
+def prepare_scheduler(optimizer, epochs, steps_per_epoch, warmup_rate):
+    total_steps = epochs * steps_per_epoch
+    warmup_steps = int(total_steps * warmup_rate)
+    scheduler = get_scheduler(
+        name='linear',
+        optimizer=optimizer,
+        num_warmup_steps=warmup_steps,
+        num_training_steps=total_steps)
+    return scheduler
+
+
+def normalize_answer(s):
+    """Lower text and remove punctuation, articles and extra whitespace."""
+
+    def remove_articles(text):
+        return re.sub(r'\b(a|an|the)\b', ' ', text)
+
+    def white_space_fix(text):
+        return ' '.join(text.split())
+
+    def remove_punc(text):
+        exclude = set(string.punctuation)
+        return ''.join(ch for ch in text if ch not in exclude)
+
+    def lower(text):
+        return text.lower()
+
+    return white_space_fix(remove_articles(remove_punc(lower(s))))
+
+
+def f1_score(prediction, ground_truth):
+    prediction_tokens = normalize_answer(prediction).split()
+    ground_truth_tokens = normalize_answer(ground_truth).split()
+    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)
+    num_same = sum(common.values())
+    if num_same == 0:
+        return 0
+    precision = 1.0 * num_same / len(prediction_tokens)
+    recall = 1.0 * num_same / len(ground_truth_tokens)
+    f1 = (2 * precision * recall) / (precision + recall)
+    return f1
+
+
+def exact_match_score(prediction, ground_truth):
+    return normalize_answer(prediction) == normalize_answer(ground_truth)
+
+
+def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):
+    scores_for_ground_truths = []
+    for ground_truth in ground_truths:
+        score = metric_fn(prediction, ground_truth)
+        scores_for_ground_truths.append(score)
+    return max(scores_for_ground_truths)
+
+
+def matching_evaluate(references, predictions):
+    f1 = em = total = 0
+    for ref_text, prediction in zip(references, predictions):
+        total += 1
+        ground_truths = [ref_text]
+        f1 += metric_max_over_ground_truths(f1_score, prediction,
+                                            ground_truths)
+        em += metric_max_over_ground_truths(exact_match_score, prediction,
+                                            ground_truths)
+    f1 = 100.0 * f1 / total
+    em = 100.0 * em / total
+
+    return f1, em
+
+
+def measure_result(result_dict):
+    meters = dict()
+
+    hypothesis_list = [
+        x.split('<response>')[-1].strip() for x in result_dict['outputs']
+    ]
+    hypothesis_list = [x if x else '@' for x in hypothesis_list]
+    reference_list = [
+        x.split('<response>')[-1].strip() for x in result_dict['targets']
+    ]
+    instance_num = len(reference_list)
+
+    # F1
+    f1, em = matching_evaluate(reference_list, hypothesis_list)
+    meters['f1'] = f1
+
+    # SacreBleu
+    bleu_score = [
+        sacrebleu.sentence_bleu(hypothesis, [reference]).score
+        for hypothesis, reference in zip(hypothesis_list, reference_list)
+    ]
+    bleu_score = sum(bleu_score) / instance_num
+    meters['bleu'] = bleu_score
+
+    # Rouge-L
+    rouge_func = Rouge()
+    rouge_score = [
+        x['rouge-l']['f']
+        for x in rouge_func.get_scores(hypothesis_list, reference_list)
+    ]
+    rouge_score = (sum(rouge_score) / instance_num) * 100
+    meters['rouge'] = rouge_score
+
+    return meters
+
+
+@TRAINERS.register_module(module_name=Trainers.document_grounded_dialog_generate_trainer)
+class DocumentGroundedDialogGenerateTrainer(EpochBasedTrainer):
+
+    def __init__(self, model: str, revision='v1.0.0', *args, **kwargs):
+        self.model = Model.from_pretrained(model, revision=revision)
+        self.preprocessor = DocumentGroundedDialogGeneratePreprocessor(
+            model_dir=self.model.model_dir)
+        self.device = self.preprocessor.device
+        self.model.model.to(self.device)
+        self.train_dataset = kwargs['train_dataset']
+        self.eval_dataset = kwargs['eval_dataset']
+
+    def train(self,
+              total_epoches=10,
+              batch_size=16,
+              accumulation_steps=1,
+              learning_rate=1e-4,
+              warmup_ratio=0.1,
+              weight_decay=0.1,
+              eps=1e-06,
+              loss_log_freq=40):
+        """
+        Fine-tuning trainsets
         """
-        if self.cfg_modify_fn is not None:
-            cfg = self.cfg_modify_fn(cfg)
-        return cfg
-
-    def get_config_file(self, config_file: str):
-        r"""
-        support local file/ url or model_id with revision
+        # obtain train loader
+        train_loader = DataLoader(
+            dataset=self.train_dataset,
+            batch_size=batch_size,
+            shuffle=True,
+            collate_fn=collate)
+
+        optimizer = prepare_optimizer(self.model.model, learning_rate,
+                                      weight_decay, eps)
+        steps_per_epoch = len(train_loader) // accumulation_steps
+        scheduler = prepare_scheduler(optimizer, total_epoches,
+                                      steps_per_epoch, warmup_ratio)
+        scaler = GradScaler()
+        best_score = 0.0
+        for epoch in range(total_epoches):
+            self.model.model.train()
+            losses = []
+            for index, payload in enumerate(tqdm.tqdm(train_loader)):
+                query, context, label = payload
+                processed = self.preprocessor(
+                    {
+                        'query': query,
+                        'context': context,
+                        'label': label
+                    },
+                    invoke_mode=ModeKeys.TRAIN)
+                with autocast():
+                    outputs = self.model.forward(processed)
+                    loss = outputs.loss.mean()
+
+                if accumulation_steps > 1:
+                    loss = loss / accumulation_steps
+
+                scaler.scale(loss).backward()
+
+                if (index + 1) % accumulation_steps == 0:
+                    scaler.step(optimizer)
+                    scaler.update()
+                    scheduler.step()
+                    optimizer.zero_grad()
+                losses.append(loss.item())
+                if (index + 1) % loss_log_freq == 0:
+                    logger.info(
+                        f'epoch: {epoch} \t batch: {batch_size * index} \t loss: {sum(losses) / len(losses)}'
+                    )
+                    losses = []
+            if losses:
+                logger.info(
+                    f'epoch: {epoch} \t batch: last \t loss: {sum(losses) / len(losses)}'
+                )
+
+            meters = self.evaluate(batch_size=batch_size)
+            total_score = sum([x for x in meters.values()])
+            if total_score >= best_score:
+                best_score = total_score
+                model_path = os.path.join(self.model.model_dir,
+                                          'finetuned_model.bin')
+                state_dict = self.model.model.state_dict()
+                torch.save(state_dict, model_path)
+                logger.info(
+                    'epoch %d obtain max score: %.4f, saving model to %s' %
+                    (epoch, total_score, model_path))
+
+    def evaluate(self, batch_size=16, checkpoint_path=None):
         """
-        if os.path.exists(config_file):
-            return config_file
-        else:
-            temp_name = tempfile.TemporaryDirectory().name
-            if len(config_file.split('#')) == 2:
-                model_id = config_file.split('#')[0]
-                revision = config_file.split('#')[-1].split('=')[-1]
-            else:
-                model_id = config_file
-                revision = DEFAULT_MODEL_REVISION
-            file_name = model_file_download(
-                model_id,
-                file_path=ModelFile.CONFIGURATION,
-                revision=revision,
-                cache_dir=temp_name)
-            return file_name
-
-    def train_step(self, model, inputs):
-        r"""
-        A single training step.
-
-        step 1. Let the model in a trainable state.
-        step 2. Execute the criterion function.
-        step 3. Update the logging variable's value.
-        step 4. Update the training result.
-
-        Args:
-            model (:obj:`torch.nn.Module` or :obj:`TorchModel`): The model to be run.
-            inputs (`dict`): model inputs.
+        Evaluate testsets
         """
-        model = model.module if self._dist or is_parallel(model) else model
-        model.train()
-        loss, sample_size, logging_output = self.criterion(model, inputs)
-        train_outputs = {'loss': loss}
-        # add model output info to log
-        if 'log_vars' not in train_outputs:
-            default_keys_pattern = ['loss']
-            match_keys = set([])
-            for key_p in default_keys_pattern:
-                match_keys.update(
-                    [key for key in train_outputs.keys() if key_p in key])
-            log_vars = {}
-            for key in match_keys:
-                value = train_outputs.get(key, None)
-                if value is not None:
-                    if dist.is_available() and dist.is_initialized():
-                        value = value.data.clone()
-                        dist.all_reduce(value.div_(dist.get_world_size()))
-                    log_vars.update({key: value.item()})
-            self.log_buffer.update(log_vars)
-        else:
-            self.log_buffer.update(train_outputs['log_vars'])
-        self.train_outputs = train_outputs
+        if checkpoint_path is not None:
+            state_dict = torch.load(checkpoint_path)
+            self.model.model.load_state_dict(state_dict)
+
+        valid_loader = DataLoader(
+            dataset=self.eval_dataset,
+            batch_size=batch_size,
+            collate_fn=collate)
+        self.model.model.eval()
+        with torch.no_grad():
+            results = {'outputs': [], 'targets': []}
+            for index, payload in enumerate(tqdm.tqdm(valid_loader)):
+                query, context, label = payload
+                processed = self.preprocessor(
+                    {
+                        'query': query,
+                        'context': context,
+                    },
+                    invoke_mode=ModeKeys.INFERENCE)
+                outputs = self.model.generate(processed)
+                predictions = self.preprocessor.generation_tokenizer.batch_decode(
+                    outputs,
+                    skip_special_tokens=True,
+                    clean_up_tokenization_spaces=False)
+                label = self.preprocessor.generation_tokenizer.batch_decode(
+                    self.preprocessor.generation_tokenizer.batch_encode_plus(
+                        label, add_special_tokens=False).input_ids,
+                    skip_special_tokens=True,
+                    clean_up_tokenization_spaces=False)
+
+                results['outputs'] += predictions
+                results['targets'] += label
+            meters = measure_result(results)
+        logger.info(meters)
+        return meters
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/multi_modal/ofa/ofa_trainer_utils.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/ofa/ofa_trainer_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/multi_modal/team/team_trainer.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/team/team_trainer.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,28 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from collections import OrderedDict
 from typing import Callable, Dict, Optional
 
 import numpy as np
 import torch
 import torch.nn as nn
 from sklearn.metrics import confusion_matrix
 from torch.utils.data import DataLoader, Dataset
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.multi_modal.team.team_trainer_utils import \
+from weathon.registry import TRAINERS
+from weathon.utils.constants import Invoke
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, BaseTrainer
+from weathon.trainers.multi_modal.team.team_trainer_utils import \
     get_optimizer
-from modelscope.utils.config import Config
-from modelscope.utils.constant import Invoke
-from modelscope.utils.logger import get_logger
+from weathon.utils.config.config import Config
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @TRAINERS.register_module(module_name=Trainers.image_classification_team)
 class TEAMImgClsTrainer(BaseTrainer):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/multi_modal/team/team_trainer_utils.py` & `weathon-0.0.0.14/weathon/trainers/multi_modal/team/team_trainer_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,13 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import torch
 import torchvision.transforms as transforms
 from PIL import Image
 from torch.optim import AdamW
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 train_transforms = transforms.Compose([
     transforms.RandomResizedCrop(224),
     transforms.RandomHorizontalFlip(),
     transforms.ToTensor(),
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/__init__.py` & `weathon-0.0.0.14/weathon/trainers/nlp/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,10 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import TYPE_CHECKING
 
-from modelscope.utils.import_utils import LazyImportModule
+from weathon.utils.import_utils import LazyImportModule
 
 if TYPE_CHECKING:
     from .sequence_classification_trainer import SequenceClassificationTrainer
     from .csanmt_translation_trainer import CsanmtTranslationTrainer
     from .text_ranking_trainer import TextRankingTrainer
     from .text_generation_trainer import TextGenerationTrainer
     from .sentence_embedding_trainer import SentenceEmbeddingTrainer
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/csanmt_translation_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/csanmt_translation_trainer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,18 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os.path as osp
 import time
 from typing import Dict, Optional
 
 import tensorflow as tf
 
-from modelscope.hub.snapshot_download import snapshot_download
-from modelscope.models.nlp import CsanmtForTranslation
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.base import BaseTrainer
+from weathon.models.nlp import CsanmtForTranslation
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
     tf.disable_eager_execution()
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/document_grounded_dialog_generate_trainer.py` & `weathon-0.0.0.14/weathon/models/nlp/backbone/mglm/tasks/eval_utils.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,287 +1,249 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
+# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+"""Evaluation utilities."""
+
+import datetime
 import os
-import re
-import string
-from collections import Counter
+import random
+import time
+from collections import OrderedDict
+from typing import List
 
-import json
-import sacrebleu
 import torch
-import tqdm
-from rouge import Rouge
-from torch.cuda.amp import GradScaler, autocast
-from torch.utils.data import DataLoader
-from transformers import AdamW, get_scheduler
-
-from modelscope.metainfo import Trainers
-from modelscope.models import Model
-from modelscope.preprocessors import DocumentGroundedDialogGeneratePreprocessor
-from modelscope.trainers import EpochBasedTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import ModeKeys
-from modelscope.utils.logger import get_logger
-
-logger = get_logger()
-
-
-def collate(batch):
-    query = [item['query'] for item in batch]
-    context = [json.loads(item['rerank']) for item in batch]
-    label = [item['response'] for item in batch]
-    return query, context, label
-
-
-def prepare_optimizer(model, lr, weight_decay, eps):
-    no_decay = ['bias', 'LayerNorm.weight']
-    optimizer_grouped_parameters = [{
-        'params': [
-            p for n, p in model.named_parameters()
-            if not any(nd in n for nd in no_decay)
-        ],
-        'weight_decay':
-        weight_decay,
-    }, {
-        'params': [
-            p for n, p in model.named_parameters()
-            if any(nd in n for nd in no_decay)
-        ],
-        'weight_decay':
-        0.0,
-    }]
-    optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=eps)
-    return optimizer
-
-
-def prepare_scheduler(optimizer, epochs, steps_per_epoch, warmup_rate):
-    total_steps = epochs * steps_per_epoch
-    warmup_steps = int(total_steps * warmup_rate)
-    scheduler = get_scheduler(
-        name='linear',
-        optimizer=optimizer,
-        num_warmup_steps=warmup_steps,
-        num_training_steps=total_steps)
-    return scheduler
-
-
-def normalize_answer(s):
-    """Lower text and remove punctuation, articles and extra whitespace."""
-
-    def remove_articles(text):
-        return re.sub(r'\b(a|an|the)\b', ' ', text)
-
-    def white_space_fix(text):
-        return ' '.join(text.split())
-
-    def remove_punc(text):
-        exclude = set(string.punctuation)
-        return ''.join(ch for ch in text if ch not in exclude)
-
-    def lower(text):
-        return text.lower()
-
-    return white_space_fix(remove_articles(remove_punc(lower(s))))
-
-
-def f1_score(prediction, ground_truth):
-    prediction_tokens = normalize_answer(prediction).split()
-    ground_truth_tokens = normalize_answer(ground_truth).split()
-    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)
-    num_same = sum(common.values())
-    if num_same == 0:
-        return 0
-    precision = 1.0 * num_same / len(prediction_tokens)
-    recall = 1.0 * num_same / len(ground_truth_tokens)
-    f1 = (2 * precision * recall) / (precision + recall)
-    return f1
-
-
-def exact_match_score(prediction, ground_truth):
-    return normalize_answer(prediction) == normalize_answer(ground_truth)
-
-
-def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):
-    scores_for_ground_truths = []
-    for ground_truth in ground_truths:
-        score = metric_fn(prediction, ground_truth)
-        scores_for_ground_truths.append(score)
-    return max(scores_for_ground_truths)
-
-
-def matching_evaluate(references, predictions):
-    f1 = em = total = 0
-    for ref_text, prediction in zip(references, predictions):
-        total += 1
-        ground_truths = [ref_text]
-        f1 += metric_max_over_ground_truths(f1_score, prediction,
-                                            ground_truths)
-        em += metric_max_over_ground_truths(exact_match_score, prediction,
-                                            ground_truths)
-    f1 = 100.0 * f1 / total
-    em = 100.0 * em / total
-
-    return f1, em
-
-
-def measure_result(result_dict):
-    meters = dict()
-
-    hypothesis_list = [
-        x.split('<response>')[-1].strip() for x in result_dict['outputs']
-    ]
-    hypothesis_list = [x if x else '@' for x in hypothesis_list]
-    reference_list = [
-        x.split('<response>')[-1].strip() for x in result_dict['targets']
-    ]
-    instance_num = len(reference_list)
-
-    # F1
-    f1, em = matching_evaluate(reference_list, hypothesis_list)
-    meters['f1'] = f1
-
-    # SacreBleu
-    bleu_score = [
-        sacrebleu.sentence_bleu(hypothesis, [reference]).score
-        for hypothesis, reference in zip(hypothesis_list, reference_list)
-    ]
-    bleu_score = sum(bleu_score) / instance_num
-    meters['bleu'] = bleu_score
-
-    # Rouge-L
-    rouge_func = Rouge()
-    rouge_score = [
-        x['rouge-l']['f']
-        for x in rouge_func.get_scores(hypothesis_list, reference_list)
-    ]
-    rouge_score = (sum(rouge_score) / instance_num) * 100
-    meters['rouge'] = rouge_score
-
-    return meters
-
-
-@TRAINERS.register_module(
-    module_name=Trainers.document_grounded_dialog_generate_trainer)
-class DocumentGroundedDialogGenerateTrainer(EpochBasedTrainer):
-
-    def __init__(self, model: str, revision='v1.0.0', *args, **kwargs):
-        self.model = Model.from_pretrained(model, revision=revision)
-        self.preprocessor = DocumentGroundedDialogGeneratePreprocessor(
-            model_dir=self.model.model_dir)
-        self.device = self.preprocessor.device
-        self.model.model.to(self.device)
-        self.train_dataset = kwargs['train_dataset']
-        self.eval_dataset = kwargs['eval_dataset']
-
-    def train(self,
-              total_epoches=10,
-              batch_size=16,
-              accumulation_steps=1,
-              learning_rate=1e-4,
-              warmup_ratio=0.1,
-              weight_decay=0.1,
-              eps=1e-06,
-              loss_log_freq=40):
-        """
-        Fine-tuning trainsets
-        """
-        # obtain train loader
-        train_loader = DataLoader(
-            dataset=self.train_dataset,
-            batch_size=batch_size,
-            shuffle=True,
-            collate_fn=collate)
-
-        optimizer = prepare_optimizer(self.model.model, learning_rate,
-                                      weight_decay, eps)
-        steps_per_epoch = len(train_loader) // accumulation_steps
-        scheduler = prepare_scheduler(optimizer, total_epoches,
-                                      steps_per_epoch, warmup_ratio)
-        scaler = GradScaler()
-        best_score = 0.0
-        for epoch in range(total_epoches):
-            self.model.model.train()
-            losses = []
-            for index, payload in enumerate(tqdm.tqdm(train_loader)):
-                query, context, label = payload
-                processed = self.preprocessor(
-                    {
-                        'query': query,
-                        'context': context,
-                        'label': label
-                    },
-                    invoke_mode=ModeKeys.TRAIN)
-                with autocast():
-                    outputs = self.model.forward(processed)
-                    loss = outputs.loss.mean()
-
-                if accumulation_steps > 1:
-                    loss = loss / accumulation_steps
-
-                scaler.scale(loss).backward()
-
-                if (index + 1) % accumulation_steps == 0:
-                    scaler.step(optimizer)
-                    scaler.update()
-                    scheduler.step()
-                    optimizer.zero_grad()
-                losses.append(loss.item())
-                if (index + 1) % loss_log_freq == 0:
-                    logger.info(
-                        f'epoch: {epoch} \t batch: {batch_size * index} \t loss: {sum(losses) / len(losses)}'
-                    )
-                    losses = []
-            if losses:
-                logger.info(
-                    f'epoch: {epoch} \t batch: last \t loss: {sum(losses) / len(losses)}'
-                )
-
-            meters = self.evaluate(batch_size=batch_size)
-            total_score = sum([x for x in meters.values()])
-            if total_score >= best_score:
-                best_score = total_score
-                model_path = os.path.join(self.model.model_dir,
-                                          'finetuned_model.bin')
-                state_dict = self.model.model.state_dict()
-                torch.save(state_dict, model_path)
-                logger.info(
-                    'epoch %d obtain max score: %.4f, saving model to %s' %
-                    (epoch, total_score, model_path))
-
-    def evaluate(self, batch_size=16, checkpoint_path=None):
-        """
-        Evaluate testsets
-        """
-        if checkpoint_path is not None:
-            state_dict = torch.load(checkpoint_path)
-            self.model.model.load_state_dict(state_dict)
-
-        valid_loader = DataLoader(
-            dataset=self.eval_dataset,
-            batch_size=batch_size,
-            collate_fn=collate)
-        self.model.model.eval()
-        with torch.no_grad():
-            results = {'outputs': [], 'targets': []}
-            for index, payload in enumerate(tqdm.tqdm(valid_loader)):
-                query, context, label = payload
-                processed = self.preprocessor(
-                    {
-                        'query': query,
-                        'context': context,
-                    },
-                    invoke_mode=ModeKeys.INFERENCE)
-                outputs = self.model.generate(processed)
-                predictions = self.preprocessor.generation_tokenizer.batch_decode(
-                    outputs,
-                    skip_special_tokens=True,
-                    clean_up_tokenization_spaces=False)
-                label = self.preprocessor.generation_tokenizer.batch_decode(
-                    self.preprocessor.generation_tokenizer.batch_encode_plus(
-                        label, add_special_tokens=False).input_ids,
-                    skip_special_tokens=True,
-                    clean_up_tokenization_spaces=False)
-
-                results['outputs'] += predictions
-                results['targets'] += label
-            meters = measure_result(results)
-        logger.info(meters)
-        return meters
+from finetune_glm import process_batch
+from megatron_util import mpu
+from sklearn.metrics import f1_score
+from tasks.data_utils import InputExample, build_data_loader
+from utils import debug_finetune_data, get_spare_port, print_rank_0
+
+
+def accuracy_metric(predictions, labels, examples):
+    count = 0
+    num_predictions = max(len(predictions), 1)
+    assert len(predictions) == len(labels)
+    for prediction, label in zip(predictions, labels):
+        count += prediction == label
+    return count * 100.0 / num_predictions
+
+
+def f1_metric(predictions, labels, examples):
+    return f1_score(labels, predictions)
+
+
+def f1_macro_metric(predictions, labels, examples):
+    return f1_score(labels, predictions, average='macro')
+
+
+global_tokenizer = None
+
+
+def accuracy_func_provider(single_dataset_provider,
+                           metric_dict,
+                           args,
+                           is_test=False,
+                           eval_func=None,
+                           output_func=None,
+                           only_rank0=True,
+                           tokenizer=None):
+    """Provide function that calculates accuracies."""
+    # Build dataloaders.
+    global global_tokenizer
+    global_tokenizer = tokenizer
+    if only_rank0 and torch.distributed.is_initialized(
+    ) and torch.distributed.get_rank() != 0:
+        return None
+    if is_test and not args.eval_valid:
+        datapaths = args.test_data if args.test_data is not None else ['test']
+    else:
+        datapaths = args.valid_data if args.valid_data is not None else ['dev']
+    if eval_func is None:
+        eval_func = multichoice_evaluate
+    dataloaders = []
+    eval_batch_size = args.eval_batch_size if args.eval_batch_size else args.batch_size
+    for datapath in datapaths:
+        dataset = single_dataset_provider(datapath)
+        dataloader = build_data_loader(
+            dataset,
+            eval_batch_size,
+            num_workers=args.num_workers,
+            drop_last=False,
+            shuffle=False,
+            only_rank0=only_rank0)
+        dataloaders.append((dataset.dataset_name, dataloader))
+
+    def metrics_func(model,
+                     epoch,
+                     output_predictions=False,
+                     summary_writer=None):
+        print_rank_0('calculating metrics ...')
+        score_dict = OrderedDict([(key, 0.0) for key in metric_dict
+                                  ]) if isinstance(metric_dict, dict) else {
+                                      metric_dict: 0.0
+                                  }  # noqa
+        total = 0
+        for name, dataloader in dataloaders:
+            example_dict = None
+            if hasattr(dataloader.dataset, 'examples'):
+                example_dict = dataloader.dataset.examples
+            start_time = time.time()
+            predictions, labels, examples = eval_func(model, dataloader,
+                                                      example_dict, args)
+            elapsed_time = time.time() - start_time
+            if output_predictions and torch.distributed.get_rank() == 0:
+                filename = os.path.join(args.log_dir, name + '.jsonl')
+                output_func(predictions, examples, filename)
+            total_count = len(predictions)
+            single_dict = {
+                key: metric(predictions, labels, examples)
+                for key, metric in metric_dict.items()
+            }
+            output_str = ' > |epoch: {}| metrics for {}: total {}'.format(
+                epoch, name, total_count)
+            for key, value in single_dict.items():
+                output_str += ' {} = {:.4f} %'.format(key, value)
+                if summary_writer is not None and epoch >= 0 and not is_test and len(
+                        dataloaders) > 1:
+                    summary_writer.add_scalar(f'Train/valid_{name}_{key}',
+                                              value, epoch)
+            output_str += ' elapsed time (sec): {:.3f}'.format(elapsed_time)
+            if len(dataloaders) > 1:
+                print_rank_0(output_str)
+            for key in score_dict:
+                score_dict[key] += single_dict[key] * total_count
+            total += total_count
+        score_dict = {
+            key: score / float(total)
+            for key, score in score_dict.items()
+        }
+        output_str = ' >> |epoch: {}| overall: total = {}'.format(epoch, total)
+        for key, score in score_dict.items():
+            output_str += ' {} = {:.4f}'.format(key, score)
+            if summary_writer is not None and epoch >= 0 and not is_test:
+                summary_writer.add_scalar(f'Train/valid_{key}', score, epoch)
+        print_rank_0(output_str)
+        return score_dict
+
+    return metrics_func
+
+
+segment_length = 10
+
+
+def multichoice_evaluate(model, dataloader, example_dict, args):
+    """Calculate correct over total answers and return prediction if the
+    `output_predictions` is true."""
+    model.eval()
+    port = get_spare_port(args)
+    print_rank_0(f'Using port {port}')
+    store = torch.distributed.TCPStore(args.master_ip, port,
+                                       torch.distributed.get_world_size(),
+                                       torch.distributed.get_rank() == 0,
+                                       datetime.timedelta(seconds=30))
+    # file_path = os.path.join("/cache", args.experiment_name + "_store")
+    # print_rank_0(f"Using file store at {file_path}")
+    # store = torch.distributed.FileStore(file_path, torch.distributed.get_world_size())
+    with torch.no_grad():
+        # For all the batches in the dataset.
+        for _, batch in enumerate(dataloader):
+            # Run the model forward.
+            data = process_batch(batch, args)
+            if args.pretrained_bert:
+                tokens, types, labels_, attention_mask = data['text'], data[
+                    'types'], data['label'], data['padding_mask']
+                inputs = [tokens, types, attention_mask]
+            elif args.cloze_eval:
+                tokens, labels_, position_ids = data['text'], data[
+                    'label'], data['position']
+                attention_mask, target_ids, logit_mask = data['mask'], data[
+                    'target'], data['logit_mask']
+                if not args.fast_decode:
+                    inputs = [
+                        tokens, position_ids, attention_mask, target_ids,
+                        logit_mask
+                    ]
+                    if args.continuous_prompt:
+                        prompt_pos = data['prompt_pos']
+                        inputs.append(prompt_pos)
+                else:
+                    dec_input_ids, dec_position_ids, dec_attention_mask = data[
+                        'dec_text'], data['dec_position'], data['dec_mask']
+                    dec_target_ids, dec_logit_mask = data['dec_target'], data[
+                        'dec_logit_mask']
+                    inputs = [
+                        tokens, position_ids, attention_mask, dec_input_ids,
+                        dec_position_ids, dec_attention_mask, dec_target_ids,
+                        dec_logit_mask
+                    ]
+            else:
+                tokens, labels_, position_ids, attention_mask = data[
+                    'text'], data['label'], data['position'], data['mask']
+                inputs = [tokens, position_ids, attention_mask]
+            if len(inputs[0].shape
+                   ) == 3 and inputs[0].size(1) > segment_length:
+                logit_list = []
+                for i in range((inputs[0].size(1) - 1) // segment_length + 1):
+                    input_batch = [
+                        arg[:, i * segment_length:(i + 1) * segment_length]
+                        for arg in inputs
+                    ]
+                    if args.pretrained_bert:
+                        logits = model(*input_batch)
+                    else:
+                        logits, *mems = model(*input_batch)
+                    logit_list.append(logits)
+                logits = torch.cat(logit_list, dim=1)
+            elif args.cloze_eval and args.fast_decode:
+                logit_list = []
+                num_choices = inputs[3].size(1)
+                for i in range((num_choices - 1) // segment_length + 1):
+                    input_batch = inputs[:3] + [
+                        arg[:, i * segment_length:(i + 1) * segment_length]
+                        for arg in inputs[3:]
+                    ]
+                    logits, *mems = model(*input_batch)
+                    logit_list.append(logits)
+                logits = torch.cat(logit_list, dim=1)
+            else:
+                if args.pretrained_bert:
+                    logits = model(*inputs)
+                else:
+                    logits, *mems = model(*inputs)
+            if 'segment_id' in data:
+                from torch_scatter import scatter_sum
+                if 'loss_mask' in data:
+                    logits = logits * data['loss_mask']
+                logits = scatter_sum(logits, data['segment_id'], dim=1)
+            elif 'loss_mask' in data:
+                loss_mask = data['loss_mask']
+                logits = logits * loss_mask - 10000.0 * (1.0 - loss_mask)
+            uid_list = batch['uid']
+            if isinstance(uid_list, torch.Tensor):
+                uid_list = uid_list.cpu().numpy().tolist()
+            predicted = torch.argmax(logits, dim=-1).tolist()
+            labels = labels_.tolist()
+            if args.task.lower() == 'wsc':
+                predicted = [1 if pred == 0 else 0 for pred in predicted]
+            if mpu.get_model_parallel_rank() == 0:
+                for uid, prediction, label in zip(uid_list, predicted, labels):
+                    store.set(uid, str((prediction, label)))
+    model.train()
+    torch.distributed.barrier()
+    predictions, labels, examples = [], [], []
+    for uid, example in example_dict.items():
+        prediction, label = eval(store.get(uid))
+        predictions.append(prediction)
+        labels.append(label)
+        examples.append(example)
+    torch.distributed.barrier()
+    return predictions, labels, examples
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/document_grounded_dialog_rerank_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/document_grounded_dialog_rerank_trainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,26 +5,24 @@
 
 import numpy as np
 import torch
 import torch.cuda
 import torch.nn.functional as F
 from transformers import AdamW, get_linear_schedule_with_warmup
 
-from modelscope.metainfo import Trainers
-from modelscope.models import Model
-from modelscope.preprocessors import DocumentGroundedDialogRerankPreprocessor
-from modelscope.trainers import EpochBasedTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.logger import get_logger
+from weathon.base import EpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.preprocessors import DocumentGroundedDialogRerankPreprocessor
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
-@TRAINERS.register_module(
-    module_name=Trainers.document_grounded_dialog_rerank_trainer)
+@TRAINERS.register_module(module_name=Trainers.document_grounded_dialog_rerank_trainer)
 class DocumentGroundedDialogRerankTrainer(EpochBasedTrainer):
 
     def __init__(self, model, dataset, **args):
         args = args['args']
         set_seed(args['seed'])
         self.positive_pids = ''
         self.instances_size = 1
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/document_grounded_dialog_retrieval_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/document_grounded_dialog_retrieval_trainer.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 
 import faiss
 import json
 import numpy as np
 import torch
 import tqdm
 from torch.utils.data import DataLoader
 from transformers import AdamW, get_scheduler
 
-from modelscope.metainfo import Trainers
-from modelscope.models import Model
-from modelscope.preprocessors import \
+from weathon.base import EpochBasedTrainer, BaseModel
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModeKeys
+from weathon.utils.constants.metainfo import Trainers
+from weathon.preprocessors import \
     DocumentGroundedDialogRetrievalPreprocessor
-from modelscope.trainers import EpochBasedTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import ModeKeys
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def collate(batch):
     query = [item['query'] for item in batch]
     positive = [item['positive'] for item in batch]
@@ -71,20 +69,19 @@
             else:
                 meters[f'R@{k}'].append(0)
     for k, v in meters.items():
         meters[k] = sum(v) / len(v)
     return meters
 
 
-@TRAINERS.register_module(
-    module_name=Trainers.document_grounded_dialog_retrieval_trainer)
+@TRAINERS.register_module(module_name=Trainers.document_grounded_dialog_retrieval_trainer)
 class DocumentGroundedDialogRetrievalTrainer(EpochBasedTrainer):
 
     def __init__(self, model: str, revision='v1.0.0', *args, **kwargs):
-        self.model = Model.from_pretrained(model, revision=revision)
+        self.model = BaseModel.from_pretrained(model, revision=revision)
         self.preprocessor = DocumentGroundedDialogRetrievalPreprocessor(
             model_dir=self.model.model_dir)
         self.device = self.preprocessor.device
         self.model.model.to(self.device)
         self.train_dataset = kwargs['train_dataset']
         self.eval_dataset = kwargs['eval_dataset']
         self.all_passages = kwargs['all_passages']
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/faq_question_answering_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/faq_question_answering_trainer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,32 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import contextlib
 from collections import defaultdict
 from dataclasses import dataclass
 from distutils.version import LooseVersion
 from functools import partial
 from typing import Callable, Dict, List, Optional, Tuple, Union
 
 import numpy as np
 import torch
 from torch import nn
 from torch.utils.data import DataLoader, Dataset
-from torch.utils.data.distributed import DistributedSampler
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import TorchModel
-from modelscope.msdatasets import MsDataset
-from modelscope.preprocessors import Preprocessor
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.nlp_trainer import EpochBasedTrainer
-from modelscope.trainers.trainer import worker_init_fn
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, ModeKeys
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import get_dist_info
+from weathon.base import BasePreprocessor, EpochBasedTrainer, TorchModel
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModeKeys, DEFAULT_MODEL_REVISION
+from weathon.utils.constants.metainfo import Trainers
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import get_dist_info
+from weathon.utils.trainer_utils import worker_init_fn
 
 logger = get_logger()
 
 
 @contextlib.contextmanager
 def numpy_seed(seed, *addl_seeds):
     """Context manager which seeds the NumPy PRNG with the specified seed and
@@ -180,15 +175,15 @@
     def __len__(self):
         return self.episode
 
 
 @dataclass
 class FewShotCollator():
 
-    def __init__(self, preprocessor: Preprocessor, k_shot):
+    def __init__(self, preprocessor: BasePreprocessor, k_shot):
         self.preprocessor = preprocessor
         self.k_shot = k_shot
         self.label_field = 'label'
         self.text_field = 'text'
         self.domain_field = 'domain'
 
     def _get_field(self, obj, key, default=None):
@@ -243,18 +238,17 @@
             self,
             model: Optional[Union[TorchModel, nn.Module, str]] = None,
             cfg_file: Optional[str] = None,
             cfg_modify_fn: Optional[Callable] = None,
             arg_parse_fn: Optional[Callable] = None,
             data_collator: Optional[Union[Callable, Dict[str,
                                                          Callable]]] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset, List]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset, List]] = None,
-            preprocessor: Optional[Union[Preprocessor,
-                                         Dict[str, Preprocessor]]] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset, List]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset, List]] = None,
+            preprocessor: Optional[Union[BasePreprocessor, Dict[str, BasePreprocessor]]] = None,
             optimizers: Tuple[torch.optim.Optimizer,
                               torch.optim.lr_scheduler._LRScheduler] = (None,
                                                                         None),
             model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
             seed: int = 42,
             **kwargs):
         if isinstance(train_dataset, list):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/gpt3_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/gpt3_trainer.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from copy import deepcopy
 from typing import Any, Dict, List, Union
 
 import torch
 from torch import nn
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model, TorchModel
-from modelscope.models.nlp import GPT3ForTextGeneration
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.nlp_trainer import NlpEpochBasedTrainer
-from modelscope.trainers.parallel.builder import build_parallel
-from modelscope.utils.config import Config
-from modelscope.utils.megatron_utils import is_megatron_initialized
+from weathon.base.trainer import NlpEpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, TorchModel
+from weathon.models.nlp import GPT3ForTextGeneration
+from weathon.trainers.parallel.builder import build_parallel
+from weathon.utils.config.config import Config
+from weathon.utils.megatron_utils import is_megatron_initialized
 
 
 @TRAINERS.register_module(module_name=Trainers.gpt3_trainer)
 class GPT3Trainer(NlpEpochBasedTrainer):
 
     def rebuild_config(self, cfg: Config):
         cfg = super().rebuild_config(cfg)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/gpt_moe_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/gpt_moe_trainer.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,22 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from collections.abc import Mapping
 from typing import List
 
 import torch
 from megatron_util import mpu
 
-from modelscope.metainfo import Trainers
-from modelscope.models import TorchModel
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.nlp_trainer import NlpEpochBasedTrainer
-from modelscope.utils.config import Config
-from modelscope.utils.file_utils import func_receive_dict_inputs
+from weathon.base.trainer import NlpEpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import TorchModel
+from weathon.utils.config.config import Config
+from weathon.utils.fileio.file_utils import func_receive_dict_inputs
 
 
 @TRAINERS.register_module(module_name=Trainers.gpt_moe_trainer)
 class GPTMoETrainer(NlpEpochBasedTrainer):
 
     def rebuild_config(self, cfg: Config):
         super().rebuild_config(cfg)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/plug_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/plug_trainer.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,22 +2,22 @@
 from typing import Union
 
 import torch
 from deepspeed import DeepSpeedEngine
 from megatron_util import mpu
 from torch import nn
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import TorchModel
-from modelscope.models.nlp.plug import DistributedPlug
-from modelscope.models.nlp.plug.backbone import BertLayerNorm
-from modelscope.models.nlp.plug.generator import TextGenerator
-from modelscope.utils.constant import ModeKeys
-from ..base import TRAINERS
-from ..nlp_trainer import NlpEpochBasedTrainer
+from weathon.base import TorchModel
+from weathon.base.trainer import NlpEpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModeKeys
+from weathon.utils.constants.metainfo import Trainers
+from weathon.models.nlp.plug import DistributedPlug
+from weathon.models.nlp.plug.backbone import BertLayerNorm
+from weathon.models.nlp.plug.generator import TextGenerator
 
 
 @TRAINERS.register_module(module_name=Trainers.nlp_plug_trainer)
 class PlugTrainer(NlpEpochBasedTrainer):
 
     def build_model(self) -> Union[nn.Module, TorchModel]:
         rank = int(os.environ.get('LOCAL_RANK', -1))
@@ -29,15 +29,15 @@
             master_ip=master_ip,
             master_port=master_port,
             **self.cfg.model)
         self.unwrap_module(model.model).model_dir = self.model_dir
         return model.model
 
     def to_parallel(self, model) -> Union[nn.Module, TorchModel]:
-        from modelscope.utils.nlp.distributed import DistributedDataParallel as DDP
+        from weathon.utils.nlp.distributed import DistributedDataParallel as DDP
         return DDP(model)
 
     def _get_params_for_weight_decay_optimization(self, module):
 
         weight_decay_params = {'params': []}
         no_weight_decay_params = {'params': [], 'weight_decay': 0.0}
         for module_ in module.modules():
@@ -89,15 +89,15 @@
             weight_decay=optimizer_cfg.weight_decay)
 
         lr_scheduler_cfg = self.cfg.train.get('lr_scheduler', None)
 
         if lr_scheduler_cfg is not None:
             assert optimizer is not None
             lr_options = lr_scheduler_cfg.pop('options', {})
-        from modelscope.models.nlp.plug.AnnealingLR import AnnealingLR
+        from weathon.models.nlp.plug.AnnealingLR import AnnealingLR
         num_iters = self.max_iters
         lr_scheduler = AnnealingLR(
             optimizer,
             start_lr=optimizer_cfg.lr,
             warmup_iter=lr_scheduler_cfg.warmup * num_iters,
             num_iters=num_iters,
             decay_style=lr_scheduler_cfg.decay_style,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/sentence_embedding_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/sentence_embedding_trainer.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,29 +1,28 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import time
 from dataclasses import dataclass
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 import numpy as np
 import torch
 from torch import nn
 from torch.utils.data import DataLoader, Dataset
 from tqdm import tqdm
 from transformers import DataCollatorWithPadding
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model, TorchModel
-from modelscope.models.nlp import BertForTextRanking
-from modelscope.msdatasets.ms_dataset import MsDataset
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.nlp_trainer import NlpEpochBasedTrainer
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION
-from modelscope.utils.logger import get_logger
+from weathon.base.trainer import NlpEpochBasedTrainer
+from weathon.models.cv.video_single_object_tracking.utils.utils import Preprocessor
+from weathon.registry import TRAINERS
+from weathon.utils.constants import DEFAULT_MODEL_REVISION
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, TorchModel
+from weathon.models.nlp import BertForTextRanking
+from weathon.base import BasePreprocessor
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @dataclass
 class SentenceEmbeddingCollator(DataCollatorWithPadding):
     """
@@ -60,16 +59,16 @@
     def __init__(
             self,
             model: Optional[Union[TorchModel, nn.Module, str]] = None,
             cfg_file: Optional[str] = None,
             cfg_modify_fn: Optional[Callable] = None,
             arg_parse_fn: Optional[Callable] = None,
             data_collator: Optional[Callable] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
             preprocessor: Optional[Preprocessor] = None,
             optimizers: Tuple[torch.optim.Optimizer,
                               torch.optim.lr_scheduler._LRScheduler] = (None,
                                                                         None),
             model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
             **kwargs):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/sequence_classification_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/sequence_classification_trainer.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import time
 from typing import Dict, Optional, Tuple, Union
 
 import numpy as np
 
-from modelscope.metainfo import Trainers
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.logger import get_logger
+from weathon.base import BaseTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.utils.logger import get_logger
 
 PATH = None
 logger = get_logger(PATH)
 
 
 @TRAINERS.register_module(module_name=Trainers.bert_sentiment_analysis)
 class SequenceClassificationTrainer(BaseTrainer):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/siamese_uie_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/siamese_uie_trainer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,31 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import random
 import time
 from collections import defaultdict
 from math import ceil
 from typing import Callable, Dict, List, Optional, Tuple, Union
 
 import json
 import numpy as np
 import torch
 from torch import distributed as dist
 from torch import nn
 from torch.utils.data import Dataset
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import TorchModel
-from modelscope.msdatasets import MsDataset
-from modelscope.pipelines import pipeline
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.trainers import EpochBasedTrainer, NlpEpochBasedTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.optimizer.builder import build_optimizer
-from modelscope.utils.config import Config
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION, ModeKeys, Tasks
-from modelscope.utils.file_utils import func_receive_dict_inputs
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.metainfo import Trainers
+from weathon.pipelines import pipeline
+from weathon.base import BasePreprocessor, EpochBasedTrainer, TorchModel
+from weathon.utils.config.config import Config
+from weathon.utils.fileio.file_utils import func_receive_dict_inputs
+from weathon.utils.logger import get_logger
 from ..parallel.utils import is_parallel
+from ...registry import TRAINERS
+from ...utils.constants import DEFAULT_MODEL_REVISION, ModeKeys, Tasks
+from ...utils.dataset.dataset import WtDataset
 
 PATH = None
 logger = get_logger(PATH)
 
 os.environ['TOKENIZERS_PARALLELISM'] = 'true'
 
 
@@ -38,18 +33,18 @@
 class SiameseUIETrainer(EpochBasedTrainer):
 
     def __init__(
             self,
             model: Optional[Union[TorchModel, nn.Module, str]] = None,
             cfg_file: Optional[str] = None,
             cfg_modify_fn: Optional[Callable] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            preprocessor: Optional[Union[Preprocessor,
-                                         Dict[str, Preprocessor]]] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            preprocessor: Optional[Union[BasePreprocessor,
+                                         Dict[str, BasePreprocessor]]] = None,
             optimizers: Tuple[torch.optim.Optimizer,
                               torch.optim.lr_scheduler._LRScheduler] = (None,
                                                                         None),
             model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
             seed: int = 42,
             negative_sampling_rate=1,
             slide_len=352,
@@ -103,19 +98,19 @@
             preprocessor=preprocessor,
             optimizers=optimizers,
             model_revision=model_revision,
             seed=seed,
             **kwargs)
 
     def build_dataset(self,
-                      datasets: Union[torch.utils.data.Dataset, MsDataset,
+                      datasets: Union[torch.utils.data.Dataset, WtDataset,
                                       List[torch.utils.data.Dataset]],
                       model_cfg: Config,
                       mode: str,
-                      preprocessor: Optional[Preprocessor] = None,
+                      preprocessor: Optional[BasePreprocessor] = None,
                       **kwargs):
         if mode == ModeKeys.TRAIN:
             datasets = self.load_dataset(datasets)
         return super(SiameseUIETrainer, self).build_dataset(
             datasets=datasets,
             model_cfg=self.cfg,
             mode=mode,
@@ -326,15 +321,15 @@
         Returns:
             Dict[str, float]: the results about the evaluation
             Example:
             {"accuracy": 0.5091743119266054, "f1": 0.673780487804878}
         """
         pipeline_uie = pipeline(Tasks.siamese_uie, self.model)
         if checkpoint_path is not None and os.path.isfile(checkpoint_path):
-            from modelscope.trainers.hooks import LoadCheckpointHook
+            from weathon.hooks import LoadCheckpointHook
             LoadCheckpointHook.load_checkpoint(checkpoint_path, self)
         self.model.eval()
         self._mode = ModeKeys.EVAL
         self.eval_dataloader = self.train_dataloader
         num_pred = num_recall = num_correct = 1e-10
         self.eval_dataset.preprocessor = None
         for sample in self.eval_dataset:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/space/dialog_intent_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/space/dialog_intent_trainer.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,27 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from typing import Callable, Dict, Optional
 
 import numpy as np
 
-from modelscope.metainfo import Trainers
-from modelscope.models.nlp.space.model.generator import SpaceGenerator
-from modelscope.models.nlp.space.model.model_base import SpaceModelBase
-from modelscope.preprocessors.nlp.space.data_loader import \
+from weathon.base import BaseTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile
+from weathon.utils.constants.metainfo import Trainers
+from weathon.models.nlp.space.model.generator import SpaceGenerator
+from weathon.models.nlp.space.model.model_base import SpaceModelBase
+from weathon.preprocessors.nlp.space.data_loader import \
     get_sequential_data_loader
-from modelscope.preprocessors.nlp.space.fields.intent_field import \
+from weathon.preprocessors.nlp.space.fields.intent_field import \
     IntentBPETextField
-from modelscope.preprocessors.nlp.space.preprocess import intent_preprocess
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.nlp.space.trainer.intent_trainer import IntentTrainer
-from modelscope.utils.config import Config, ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.preprocessors.nlp.space.preprocess import intent_preprocess
+from weathon.trainers.nlp.space.trainer.intent_trainer import IntentTrainer
+from weathon.utils.logger import get_logger
 
 PATH = None
 logger = get_logger(PATH)
 
 
 @TRAINERS.register_module(module_name=Trainers.dialog_intent_trainer)
 class DialogIntentTrainer(BaseTrainer):
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/space/dialog_modeling_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/space/dialog_modeling_trainer.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import time
 from typing import Callable, Dict, Optional, Tuple, Union
 
 import numpy as np
 
-from modelscope.metainfo import Trainers
-from modelscope.models.nlp.space.model.generator import SpaceGenerator
-from modelscope.models.nlp.space.model.model_base import SpaceModelBase
-from modelscope.preprocessors.nlp import MultiWOZBPETextField
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.nlp.space.eval import MultiWOZEvaluator
-from modelscope.trainers.nlp.space.trainer.gen_trainer import MultiWOZTrainer
-from modelscope.utils.config import Config, ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.base import BaseTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile
+from weathon.utils.constants.metainfo import Trainers
+from weathon.models.nlp.space.model.generator import SpaceGenerator
+from weathon.models.nlp.space.model.model_base import SpaceModelBase
+from weathon.preprocessors.nlp import MultiWOZBPETextField
+from weathon.trainers.nlp.space.eval import MultiWOZEvaluator
+from weathon.trainers.nlp.space.trainer.gen_trainer import MultiWOZTrainer
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def setup_seed(seed: int):
     import random
     import torch
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/space/eval.py` & `weathon-0.0.0.14/weathon/trainers/nlp/space/eval.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,16 +17,16 @@
 from collections import Counter
 
 import json
 import numpy as np
 from nltk.util import ngrams
 from sklearn.metrics import f1_score
 
-from modelscope.utils.nlp.space import ontology, utils
-from modelscope.utils.nlp.space.clean_dataset import clean_slot_values
+from weathon.utils.nlp.space import ontology, utils
+from weathon.utils.nlp.space.clean_dataset import clean_slot_values
 
 
 def similar(a, b):
     return a == b or a in b or b in a or a.split()[0] == b.split(
     )[0] or a.split()[-1] == b.split()[-1]
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/space/metrics/metrics_tracker.py` & `weathon-0.0.0.14/weathon/trainers/nlp/space/metrics/metrics_tracker.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import math
 from collections import defaultdict
 
 
 class MetricsTracker(object):
     """ Tracking metrics. """
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/space/trainer/gen_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/space/trainer/gen_trainer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import time
 from collections import OrderedDict
 
 import json
 import numpy as np
 import torch
 from tqdm import tqdm
 from transformers.optimization import AdamW, get_linear_schedule_with_warmup
 
-from modelscope.trainers.nlp.space.metrics.metrics_tracker import \
+from weathon.trainers.nlp.space.metrics.metrics_tracker import \
     MetricsTracker
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
-from modelscope.utils.nlp.space import ontology
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
+from weathon.utils.nlp.space import ontology
 
 
 class Trainer(object):
 
     def __init__(self,
                  model,
                  to_tensor,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/space/trainer/intent_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/space/trainer/intent_trainer.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,23 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import time
 from collections import OrderedDict
 
 import json
 import numpy as np
 import torch
 from tqdm import tqdm
 from transformers.optimization import AdamW, get_linear_schedule_with_warmup
 
-from modelscope.trainers.nlp.space.metrics.metrics_tracker import \
+from weathon.trainers.nlp.space.metrics.metrics_tracker import \
     MetricsTracker
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import ModelFile
+from weathon.utils.logger import get_logger
 
 
 class Trainer(object):
 
     def __init__(self,
                  model,
                  to_tensor,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/table_question_answering_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/table_question_answering_trainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,38 +1,29 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
-import os.path as osp
-import time
-from typing import Dict, Optional
 
-import json
 import numpy
 import torch
 import tqdm
 from torch.optim.lr_scheduler import LambdaLR
 from torch.utils.data import DataLoader
 
-from modelscope.metainfo import Trainers
-from modelscope.models import Model
-from modelscope.models.nlp.space_T_cn.table_question_answering import \
-    TableQuestionAnswering
-from modelscope.trainers.base import BaseTrainer
-from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.constant import ModelFile
-from modelscope.utils.logger import get_logger
+from weathon.base import BaseTrainer, BaseModel
+from weathon.registry import TRAINERS
+from weathon.utils.constants.metainfo import Trainers
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @TRAINERS.register_module(module_name=Trainers.table_question_answering_trainer
                           )
 class TableQuestionAnsweringTrainer(BaseTrainer):
 
     def __init__(self, model: str, cfg_file: str = None, *args, **kwargs):
-        self.model = Model.from_pretrained(model)
+        self.model = BaseModel.from_pretrained(model)
         self.train_dataset = kwargs['train_dataset']
         self.eval_dataset = kwargs['eval_dataset']
 
     def get_linear_schedule_with_warmup(self,
                                         optimizer,
                                         num_warmup_steps,
                                         num_training_steps,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/text_ranking_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/text_ranking_trainer.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import time
 from dataclasses import dataclass
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 import numpy as np
 import torch
 from torch import nn
 from torch.utils.data import DataLoader, Dataset
 from tqdm import tqdm
 
-from modelscope.metainfo import Trainers
-from modelscope.models.base import Model, TorchModel
-from modelscope.models.nlp import BertForTextRanking
-from modelscope.msdatasets.ms_dataset import MsDataset
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.nlp_trainer import NlpEpochBasedTrainer
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION
-from modelscope.utils.logger import get_logger
+from weathon.base.trainer import NlpEpochBasedTrainer
+from weathon.registry import TRAINERS
+from weathon.utils.constants import DEFAULT_MODEL_REVISION
+from weathon.utils.constants.metainfo import Trainers
+from weathon.base import BaseModel, TorchModel
+from weathon.models.nlp import BertForTextRanking
+from weathon.base import BasePreprocessor
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 @dataclass
 class GroupCollator():
     """
@@ -49,17 +47,17 @@
     def __init__(
             self,
             model: Optional[Union[TorchModel, nn.Module, str]] = None,
             cfg_file: Optional[str] = None,
             cfg_modify_fn: Optional[Callable] = None,
             arg_parse_fn: Optional[Callable] = None,
             data_collator: Optional[Callable] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            preprocessor: Optional[Preprocessor] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            preprocessor: Optional[BasePreprocessor] = None,
             optimizers: Tuple[torch.optim.Optimizer,
                               torch.optim.lr_scheduler._LRScheduler] = (None,
                                                                         None),
             model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
             **kwargs):
 
         if data_collator is None:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/nlp/translation_evaluation_trainer.py` & `weathon-0.0.0.14/weathon/trainers/nlp/translation_evaluation_trainer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,44 +1,27 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """PyTorch trainer for UniTE model."""
 
 import os.path as osp
-import random
-from math import ceil
-from os import mkdir
-from typing import Any, Callable, Dict, List, Optional, Tuple, Union
+from functools import partial
+from typing import Any, Dict, List, Optional, Tuple, Union
 
 import torch
-from pandas import DataFrame
 from torch.nn.functional import pad
-from torch.nn.utils import clip_grad_norm_
 from torch.optim import AdamW, Optimizer
-from torch.utils.data import (BatchSampler, DataLoader, Dataset, Sampler,
+from torch.utils.data import (BatchSampler, DataLoader, Sampler,
                               SequentialSampler, SubsetRandomSampler)
-from torch.utils.tensorboard import SummaryWriter
-from tqdm import tqdm
-from transformers import AutoTokenizer
-
-from modelscope.metainfo import Metrics, Trainers
-from modelscope.metrics import Metric
-from modelscope.metrics.builder import MetricKeys, build_metric
-from modelscope.models.base import TorchModel
-from modelscope.models.nlp.unite.configuration import InputFormat
-from modelscope.models.nlp.unite.translation_evaluation import (
-    UniTEForTranslationEvaluation, combine_input_sentences)
-from modelscope.msdatasets import MsDataset
-from modelscope.preprocessors import Preprocessor
-from modelscope.trainers.builder import TRAINERS
-from modelscope.trainers.hooks import Hook
-from modelscope.trainers.trainer import EpochBasedTrainer
-from modelscope.utils.config import ConfigDict
-from modelscope.utils.constant import (ConfigKeys, Fields, ModeKeys, ModelFile,
-                                       TrainerStages)
-from modelscope.utils.device import create_device
-from modelscope.utils.logger import get_logger
+
+from weathon.base import BasePreprocessor, EpochBasedTrainer, TorchModel
+from weathon.registry import TRAINERS
+from weathon.utils.constants import ModeKeys, ConfigKeys, TrainerStages
+from weathon.utils.constants.metainfo import Trainers
+from weathon.models.nlp.backbone.unite import InputFormat
+from weathon.utils.config.config import ConfigDict
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 class TranslationEvaluationTrainingSampler(Sampler):
 
     def __init__(self, num_of_samples: int,
@@ -127,28 +110,28 @@
 
     def __len__(self) -> int:
         return self.num_of_samples_for_each_input_format // self.batch_size_for_each_input_format
 
 
 def convert_csv_dict_to_input(
         batch: List[Dict[str, Any]],
-        preprocessor: Preprocessor) -> Tuple[List[torch.Tensor]]:
+        preprocessor: BasePreprocessor) -> Tuple[List[torch.Tensor]]:
 
     input_dict = dict()
 
     for key in batch[0].keys():
         input_dict[key] = list(x[key] for x in batch)
 
     input_dict = preprocessor(input_dict)
 
     return input_dict
 
 
 def data_collate_fn(batch: List[Dict[str, Any]], batch_size: int,
-                    preprocessor: Preprocessor) -> List[Dict[str, Any]]:
+                    preprocessor: BasePreprocessor) -> List[Dict[str, Any]]:
 
     output_dict = dict()
     output_dict['input_format'] = list()
 
     if preprocessor.mode == ModeKeys.TRAIN:
         for input_format_index, input_format in \
                 enumerate((InputFormat.SRC_REF, InputFormat.SRC, InputFormat.REF)):
@@ -293,15 +276,15 @@
 
     def get_train_dataloader(self) -> DataLoader:
         logger.info('Building dataloader for training ...')
 
         if self.train_dataset is None:
             logger.info('Reading train csv file from %s ...'
                         % self.cfg.dataset.train.name)
-            self.train_dataset = MsDataset.load(
+            self.train_dataset = WtDataset.load(
                 osp.join(self.model_dir, self.cfg.dataset.train.name),
                 split=self.cfg.dataset.train.split)
 
         train_dataloader = DataLoader(
             self.train_dataset,
             batch_sampler=TranslationEvaluationTrainingSampler(
                 len(self.train_dataset),
@@ -318,15 +301,15 @@
     def get_eval_data_loader(self) -> DataLoader:
         logger.info('Building dataloader for evaluating ...')
 
         if self.eval_dataset is None:
             logger.info('Reading eval csv file from %s ...'
                         % self.cfg.dataset.valid.name)
 
-            self.eval_dataset = MsDataset.load(
+            self.eval_dataset = WtDataset.load(
                 osp.join(self.model_dir, self.cfg.dataset.valid.name),
                 split=self.cfg.dataset.valid.split)
 
         eval_dataloader = DataLoader(
             self.eval_dataset,
             batch_sampler=BatchSampler(
                 SequentialSampler(range(0, len(self.eval_dataset))),
@@ -360,29 +343,29 @@
         metric_values = dict()
 
         for input_format in (InputFormat.SRC_REF, InputFormat.SRC,
                              InputFormat.REF):
             self.eval_preprocessor.change_input_format(input_format)
 
             if self._dist:
-                from modelscope.trainers.utils.inference import multi_gpu_test
+                from weathon.inference.inference import multi_gpu_test
                 # list of batched result and data samples
                 metric_values.update(
                     multi_gpu_test(
                         self,
                         data_loader,
                         device=self.device,
                         metric_classes=metric_classes,
                         vis_closure=vis_closure,
                         tmpdir=self.cfg.evaluation.get('cache_dir', None),
                         gpu_collect=self.cfg.evaluation.get(
                             'gpu_collect', False),
                         data_loader_iters_per_gpu=self._eval_iters_per_epoch))
             else:
-                from modelscope.trainers.utils.inference import single_gpu_test
+                from weathon.inference.inference import single_gpu_test
                 metric_values.update(
                     single_gpu_test(
                         self,
                         data_loader,
                         device=self.device,
                         metric_classes=metric_classes,
                         vis_closure=vis_closure,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/optimizer/builder.py` & `weathon-0.0.0.14/weathon/registry/optimizer.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,51 +1,37 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import inspect
-from typing import Iterable, Union
+from typing import Union, Iterable
 
 import torch
 
-from modelscope.utils.config import ConfigDict
-from modelscope.utils.registry import Registry, build_from_cfg, default_group
+from weathon.utils.config.config import ConfigDict
+from weathon.registry.registry import Registry, default_group, build_from_cfg
 
 OPTIMIZERS = Registry('optimizer')
 
+for name, module in inspect.getmembers(torch.optim):
+    if name.startswith('__'):
+        continue
+    if inspect.isclass(module) and issubclass(module, torch.optim.Optimizer):
+        OPTIMIZERS.register_module(default_group, module_name=name, module_cls=module)
 
-def build_optimizer(model: Union[torch.nn.Module,
-                                 Iterable[torch.nn.parameter.Parameter]],
-                    cfg: ConfigDict,
-                    default_args: dict = None):
+
+def build_optimizer(model: Union[torch.nn.Module, Iterable[torch.nn.parameter.Parameter]],cfg: ConfigDict,task_name: str = default_group,default_args: dict = None):
     """ build optimizer from optimizer config dict
 
     Args:
         model: A torch.nn.Module or an iterable of parameters.
         cfg (:obj:`ConfigDict`): config dict for optimizer object.
         default_args (dict, optional): Default initialization arguments.
     """
     if default_args is None:
         default_args = {}
 
-    if isinstance(model, torch.nn.Module) or (hasattr(
-            model, 'module') and isinstance(model.module, torch.nn.Module)):
+    if isinstance(model, torch.nn.Module) or (hasattr(model, 'module') and isinstance(model.module, torch.nn.Module)):
         if hasattr(model, 'module'):
             model = model.module
-
         default_args['params'] = model.parameters()
     else:
         # Input is a iterable of parameters, this case fits for the scenario of user-defined parameter groups.
         default_args['params'] = model
 
-    return build_from_cfg(
-        cfg, OPTIMIZERS, group_key=default_group, default_args=default_args)
-
-
-def register_torch_optimizers():
-    for name, module in inspect.getmembers(torch.optim):
-        if name.startswith('__'):
-            continue
-        if inspect.isclass(module) and issubclass(module,
-                                                  torch.optim.Optimizer):
-            OPTIMIZERS.register_module(
-                default_group, module_name=name, module_cls=module)
-
-
-register_torch_optimizers()
+    return build_from_cfg(cfg, OPTIMIZERS, group_key=task_name, default_args=default_args)
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/optimizer/child_tuning_adamw_optimizer.py` & `weathon-0.0.0.14/weathon/optimizer/child_tuning_adamw_optimizer.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,16 +17,17 @@
 from typing import Callable, Iterable, Tuple
 
 import numpy as np
 import torch
 from torch.distributions.bernoulli import Bernoulli
 from torch.optim import Optimizer
 
-from modelscope.utils.logger import get_logger
-from .builder import OPTIMIZERS, default_group
+from weathon.registry import OPTIMIZERS
+from weathon.registry.registry import default_group
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 __all__ = ['calculate_fisher', 'ChildTuningAdamW']
 
 
 def calculate_fisher(model: torch.nn.Module,
@@ -68,16 +69,15 @@
     print('Polar => {}'.format(polar))
 
     # TODO: pytorch: torch.kthvalue
 
     return gradient_mask
 
 
-@OPTIMIZERS.register_module(
-    group_key=default_group, module_name='ChildTuningAdamW')
+@OPTIMIZERS.register_module(group_key=default_group, module_name='ChildTuningAdamW')
 class ChildTuningAdamW(Optimizer):
 
     def __init__(self,
                  params: Iterable[torch.nn.parameter.Parameter],
                  lr: float = 1e-3,
                  betas: Tuple[float, float] = (0.9, 0.999),
                  eps: float = 1e-6,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/parallel/builder.py` & `weathon-0.0.0.14/weathon/registry/parallel.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from torch.nn.parallel.distributed import DistributedDataParallel
 
-from modelscope.utils.config import ConfigDict
-from modelscope.utils.registry import Registry, build_from_cfg
+from weathon.registry.registry import Registry, build_from_cfg
+from weathon.utils.config.config import ConfigDict
 
 PARALLEL = Registry('parallel')
-PARALLEL.register_module(
-    module_name='DistributedDataParallel', module_cls=DistributedDataParallel)
+PARALLEL.register_module(module_name='DistributedDataParallel', module_cls=DistributedDataParallel)
 
 
 def build_parallel(cfg: ConfigDict, default_args: dict = None):
     """ build parallel
 
     Args:
         cfg (:obj:`ConfigDict`): config dict for parallel object.
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/parallel/utils.py` & `weathon-0.0.0.14/weathon/trainers/parallel/utils.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-from .builder import PARALLEL
+from weathon.registry import PARALLEL
 
 
 def is_parallel(module):
     """Check if a module is wrapped by parallel object.
 
     The following modules are regarded as parallel object:
      - torch.nn.parallel.DataParallel
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/trainer.py` & `weathon-0.0.0.14/weathon/base/trainer.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,133 +1,196 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import inspect
+import json
 import os
-from collections.abc import Mapping
+import time
+from abc import ABC, abstractmethod
 from copy import deepcopy
+from distutils import dist
 from distutils.version import LooseVersion
 from functools import partial
-from typing import Callable, Dict, List, Optional, Tuple, Union
+from typing import Callable, Dict, Optional, Union, Tuple, List, Mapping
 
-import json
+import numpy as np
 import torch
 from torch import distributed as dist
 from torch import nn
 from torch.utils.data import DataLoader, Dataset, Sampler
 from torch.utils.data.dataloader import default_collate
 from torch.utils.data.distributed import DistributedSampler
 
-from modelscope.metainfo import Trainers
-from modelscope.metrics import build_metric, task_default_metrics
-from modelscope.metrics.prediction_saving_wrapper import \
-    PredictionSavingWrapper
-from modelscope.models.base import Model, TorchModel
-from modelscope.msdatasets.dataset_cls.custom_datasets import \
-    TorchCustomDataset
-from modelscope.msdatasets.dataset_cls.custom_datasets.builder import \
-    build_custom_dataset
-from modelscope.msdatasets.ms_dataset import MsDataset
-from modelscope.outputs import ModelOutputBase
-from modelscope.preprocessors.base import Preprocessor
-from modelscope.trainers.hooks.builder import HOOKS
-from modelscope.trainers.hooks.priority import Priority, get_priority
-from modelscope.trainers.lrscheduler.builder import build_lr_scheduler
-from modelscope.trainers.optimizer.builder import build_optimizer
-from modelscope.utils.config import Config, ConfigDict, JSONIteratorEncoder
-from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, ConfigFields,
-                                       ConfigKeys, DistributedParallelType,
-                                       ModeKeys, ModelFile, ThirdParty,
-                                       TrainerStages)
-from modelscope.utils.data_utils import to_device
-from modelscope.utils.device import create_device
-from modelscope.utils.file_utils import func_receive_dict_inputs
-from modelscope.utils.logger import get_logger
-from modelscope.utils.registry import build_from_cfg
-from modelscope.utils.torch_utils import (compile_model, get_dist_info,
-                                          get_local_rank, init_dist, is_dist,
-                                          is_master, set_random_seed)
-from .base import BaseTrainer
-from .builder import TRAINERS
-from .default_config import merge_cfg, merge_hooks, update_cfg
-from .hooks.hook import Hook
-from .parallel.builder import build_parallel
-from .parallel.utils import is_parallel
+from .model import TorchModel, BaseModel
+from .modeloutput import BaseModelOutput
+from .preprocessor import BasePreprocessor
+from .hook import BaseHook
+from .dataset import TorchCustomDataset
+
+from weathon.registry import TRAINERS, build_custom_dataset, build_metric, build_optimizer, build_lr_scheduler, HOOKS, \
+    build_parallel
+from weathon.datasets.custom_datasets import VecoDataset
+from weathon.metrics.prediction_saving_wrapper import PredictionSavingWrapper
+from weathon.registry.registry import build_from_cfg
+from weathon.trainers.parallel.utils import is_parallel
+from weathon.utils.config.default_config import merge_cfg, update_cfg, merge_hooks
+from weathon.utils.constants.metric_constant import task_default_metrics
+from weathon.utils.data_utils import to_device
+from weathon.utils.dataset.dataset import WtDataset
+from weathon.utils.device import create_device
+from weathon.utils.fileio.file_utils import func_receive_dict_inputs
+from weathon.utils.fileio.format.json_utils import JSONIteratorEncoder
+from weathon.utils.logger.log_buffer import LogBuffer
+from weathon.utils.config.config import Config, ConfigDict
+from weathon.utils.constants import Invoke, ThirdParty, DEFAULT_MODEL_REVISION, ModeKeys, TrainerStages, ConfigKeys, \
+    ConfigFields, DistributedParallelType, ModelFile, Priority, get_priority
+from weathon.utils.constants.metainfo import Trainers
+from weathon.utils.hub.check_model import check_local_model_is_latest
+from weathon.utils.hub.utils import snapshot_download
+from weathon.utils.torch_utils import set_random_seed, compile_model, init_dist, get_dist_info, is_dist, get_local_rank, \
+    is_master
+from weathon.utils.logger import get_logger
+from weathon.utils.trainer_utils import worker_init_fn
+
+logger = get_logger()
+
+
+class BaseTrainer(ABC):
+    """ , 
+    , , .
+    """
+
+    def __init__(self, cfg_file: str, arg_parse_fn: Optional[Callable] = None):
+        """ Trainer basic init, should be called in derived class
+
+        Args:
+            cfg_file: .
+            arg_parse_fn: Same as ``parse_fn`` in :obj:`Config.to_args`.
+        """
+        self.cfg = Config.from_file(cfg_file)
+        if arg_parse_fn:
+            self.args = self.cfg.to_args(arg_parse_fn)
+        else:
+            self.args = None
+        self.log_buffer = LogBuffer()
+        self.visualization_buffer = LogBuffer()
+        self.timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())
+
+    def get_or_download_model_dir(self, model, model_revision: Optional[str] = None,
+                                  third_party: Optional[str] = None) -> str:
+        """ ,,.
+            
+        Args:
+            model (str): id(model id) 
+            model_revision  (str, optional): .
+            third_party (str, optional): .
+        """
+        if os.path.exists(model):
+            model_cache_dir = model if os.path.isdir(model) else os.path.dirname(model)
+            user_agent = {Invoke.KEY: Invoke.LOCAL_TRAINER, ThirdParty.KEY: third_party}
+            check_local_model_is_latest(model_cache_dir, user_agent=user_agent)
+        else:
+            user_agent = {Invoke.KEY: Invoke.TRAINER, ThirdParty.KEY: third_party}
+            model_cache_dir = snapshot_download(model, revision=model_revision, user_agent=user_agent)
+        return model_cache_dir
+
+    @abstractmethod
+    def train(self, *args, **kwargs):
+        """ 
+        , "__init__",
+        """
+        pass
+
+    @abstractmethod
+    def evaluate(self, checkpoint_path: str, *args, **kwargs) -> Dict[str, float]:
+        """ 
+        , "__init__",
+        """
+        pass
+
+
+@TRAINERS.register_module(module_name='dummy')
+class DummyTrainer(BaseTrainer):
+
+    def __init__(self, cfg_file: str, *args, **kwargs):
+        """ Dummy Trainer.
+
+        Args:
+            cfg_file: Path to configuration file.
+        """
+        super().__init__(cfg_file)
+
+    def train(self, *args, **kwargs):
+        """ 
+        """
+        cfg = self.cfg.train
+        print(f'train cfg {cfg}')
+
+    def evaluate(self, checkpoint_path: str = None, *args, **kwargs) -> Dict[str, float]:
+        """ 
+        """
+        cfg = self.cfg.evaluation
+        print(f'eval cfg {cfg}')
+        print(f'checkpoint_path {checkpoint_path}')
 
 
 @TRAINERS.register_module(module_name=Trainers.default)
 class EpochBasedTrainer(BaseTrainer):
-    """Epoch based Trainer, a training helper for PyTorch.
+    """ epoch, PyTorch
 
     Args:
-        cfg_file(str): The local config file.
-        model (:obj:`torch.nn.Module` or :obj:`TorchModel` or `str`): The model to be run, or a valid model dir
-            or a model id. If model is None, build_model method will be called.
-        data_collator (`Callable`, *optional*):
-            The function to use to form a batch from a list of elements of `train_dataset` or `eval_dataset`.
-        train_dataset (`MsDataset` or `torch.utils.data.Dataset`, *optional*):
-            The dataset to use for training.
-
-            Note that if it's a `torch.utils.data.IterableDataset` with some randomization and you are training in a
-            distributed fashion, your iterable dataset should either use a internal attribute `generator` that is a
-            `torch.Generator` for the randomization that must be identical on all processes (and the Trainer will
-            manually set the seed of this `generator` at each epoch) or have a `set_epoch()` method that internally
-            sets the seed of the RNGs used.
-        eval_dataset (`MsDataset` or `torch.utils.data.Dataset`, *optional*): The dataset to use for evaluation.
-        preprocessor (:obj:`Preprocessor`, *optional*): The optional preprocessor.
-            NOTE: If the preprocessor has been called before the dataset fed into this trainer by user's custom code,
-            this parameter should be None, meanwhile remove the 'preprocessor' key from the cfg_file.
-            Else the preprocessor will be instantiated from the cfg_file or assigned from this parameter and
-            this preprocessing action will be executed every time the dataset's __getitem__ is called.
-        optimizers (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]`, *optional*): A tuple
-            containing the optimizer and the scheduler to use.
-        seed (int): The optional random seed for torch, cuda, numpy and random.
-        max_epochs: (int, optional): Total training epochs.
-        cfg_modify_fn: An input fn which is used to modify the cfg read out of the file.
-        remove_unused_data: Automatically remove unused data keys in mini-batches.
-            The remove action based on the `inspect` on the model's forward method, the removed columns will be
-            moved to the mini-batch's attributes.
-        compile (bool, optional): Compile the model with torch 2.0, default False
-        compile_options (dict, optional): The compile options if compile=True,
-            default None to use the default params of 'TorchModel.compile'.
-        efficient_tuners (dict, optional): The tuners to use to train the model
-        samplers: (:obj:`Sampler` or `Dict[Sampler]`, *optional*): samplers used in the train/eval DataLoader.
+        model (:obj:`torch.nn.Module` or :obj:`TorchModel` or `str`): model id. None, build_model. 
+        cfg_file(str): .
+        data_collator (`Callable`, *optional*): `train_dataset` or `eval_dataset`batch.
+        train_dataset (`MsDataset` or `torch.utils.data.Dataset`, *optional*): 
+            NOTE: `torch.utils.data.IterableDataset`,
+            "generator","torch.Generator",(epoch`generator` )
+            `set_epoch()`
+        eval_dataset (`MsDataset` or `torch.utils.data.Dataset`, *optional*): .
+        preprocessor (:obj:`Preprocessor`, *optional*): ().
+            NOTE: ,None,'preprocessor'.
+            preprocessor,'__getitem__'.
+        optimizers (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]`, *optional*): (optimizer,lr_scheduler).
+        seed (int): torchcudanumpyrandom.
+        max_epochs: (int, optional):epoch.
+        remove_unused_data: mini-batches. model's forward method, mini-batch
+        compile (bool, optional): torch2.0, False.
+        compile_options (dict, optional): compile=True,'TorchModel.compile'.
+        efficient_tuners (dict, optional): .
+        samplers: (:obj:`Sampler` or `Dict[Sampler]`, *optional*): train/eval dataloader.
+
+        cfg_modify_fn: ().
         Examples of cfg_modify_fn:
             >>> def cfg_modify_fn(cfg):
             >>>     cfg.preprocessor.first_sequence= 'text1'
             >>>     cfg.preprocessor.second_sequence='text2'
             >>>     return cfg
     """
 
     def __init__(
             self,
             model: Optional[Union[TorchModel, nn.Module, str]] = None,
             cfg_file: Optional[str] = None,
             cfg_modify_fn: Optional[Callable] = None,
             arg_parse_fn: Optional[Callable] = None,
-            data_collator: Optional[Union[Callable, Dict[str,
-                                                         Callable]]] = None,
-            train_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            eval_dataset: Optional[Union[MsDataset, Dataset]] = None,
-            preprocessor: Optional[Union[Preprocessor,
-                                         Dict[str, Preprocessor]]] = None,
-            optimizers: Tuple[torch.optim.Optimizer,
-                              torch.optim.lr_scheduler._LRScheduler] = (None,
-                                                                        None),
+            data_collator: Optional[Union[Callable, Dict[str, Callable]]] = None,
+            train_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            eval_dataset: Optional[Union[WtDataset, Dataset]] = None,
+            preprocessor: Optional[Union[BasePreprocessor, Dict[str, BasePreprocessor]]] = None,
+            optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler] = (None, None),
             model_revision: Optional[str] = DEFAULT_MODEL_REVISION,
             seed: int = 42,
-            callbacks: Optional[List[Hook]] = None,
+            callbacks: Optional[List[BaseHook]] = None,
             samplers: Optional[Union[Sampler, Dict[str, Sampler]]] = None,
             efficient_tuners: List[Dict] = None,
             **kwargs):
 
         self._seed = seed
         set_random_seed(self._seed)
         self._metric_values = None
         self.optimizers = optimizers
         self._mode = ModeKeys.TRAIN
-        self._hooks: List[Hook] = []
+        self._hooks: List[BaseHook] = []
         self._epoch = 0
         self._iter = 0
         self._inner_iter = 0
         self._stop_training = False
         self._compile = kwargs.get('compile', False)
 
         self.train_dataloader = None
@@ -136,102 +199,94 @@
         self._samplers = samplers
 
         if isinstance(model, str):
             third_party = kwargs.get(ThirdParty.KEY)
             if third_party is not None:
                 kwargs.pop(ThirdParty.KEY)
 
-            self.model_dir = self.get_or_download_model_dir(
-                model, model_revision, third_party)
+            self.model_dir = self.get_or_download_model_dir(model, model_revision, third_party)
             if cfg_file is None:
-                cfg_file = os.path.join(self.model_dir,
-                                        ModelFile.CONFIGURATION)
+                cfg_file = os.path.join(self.model_dir, ModelFile.CONFIGURATION)
             self.input_model_id = model
-        else:
+        else:  # , ,
             assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'
             self.model_dir = os.path.dirname(cfg_file)
             self.input_model_id = None
 
         super().__init__(cfg_file, arg_parse_fn)
         self.cfg_modify_fn = cfg_modify_fn
-        # add default config
-        merge_cfg(self.cfg)
-        self.cfg = self.rebuild_config(self.cfg)
+
+        merge_cfg(self.cfg)  # hook
+        self.cfg = self.rebuild_config(self.cfg)  # "cfg_modify_fn"
         if 'cfg_options' in kwargs:
-            self.cfg.merge_from_dict(kwargs['cfg_options'])
+            self.cfg.merge_from_dict(kwargs['cfg_options'])  # 'cfg_options'
         self.cfg = update_cfg(self.cfg)
 
+        # 
         if isinstance(model, (TorchModel, nn.Module)):
             self.model = model
         else:
             self.model = self.build_model()
 
         if self._compile:
-            # Compile the model with torch 2.0
+            #  torch 2.0 
             compile_options = kwargs.get('compile_options')
             if compile_options is None:
                 compile_options = {}
             self.model = compile_model(self.model, **compile_options)
 
+        # 
         if 'work_dir' in kwargs:
             self.work_dir = kwargs['work_dir']
         else:
             self.work_dir = self.cfg.train.get('work_dir', './work_dir')
 
-        self.train_preprocessor, self.eval_preprocessor = self.get_preprocessors(
-            preprocessor)
+        # 
+        self.train_preprocessor, self.eval_preprocessor = self.get_preprocessors(preprocessor)
 
         if not os.path.exists(self.work_dir):
             # TODO duplicate makedirs may cause errors in dlc envs.
             os.makedirs(self.work_dir, exist_ok=True)
 
         # init logger after distribution init
         log_file = os.path.join(self.work_dir, '{}.log'.format(self.timestamp))
-        self.logger = get_logger(
-            log_file=log_file, log_level=self.cfg.get('log_level', 'INFO'))
+        self.logger = get_logger(log_file=log_file, log_level=self.cfg.get('log_level', 'INFO'))
 
         # Get train datasets
-        self.train_dataset = self.build_dataset(
-            datasets=train_dataset,
-            model_cfg=self.cfg,
-            mode=ModeKeys.TRAIN,
-            preprocessor=self.train_preprocessor,
-            **kwargs)
+        self.train_dataset = self.build_dataset(datasets=train_dataset,
+                                                cfg=self.cfg,
+                                                mode=ModeKeys.TRAIN,
+                                                preprocessor=self.train_preprocessor,
+                                                **kwargs)
         # Get evaluation datasets
-        self.eval_dataset = self.build_dataset(
-            datasets=eval_dataset,
-            model_cfg=self.cfg,
-            mode=ModeKeys.EVAL,
-            preprocessor=self.eval_preprocessor,
-            **kwargs)
-
-        self.train_data_collator, self.eval_data_collator = self.get_data_collator(
-            data_collator,
-            remove_unused_data=kwargs.get('remove_unused_data', False))
-        self._max_epochs = kwargs.get('max_epochs',
-                                      self.cfg.safe_get('train.max_epochs'))
-        assert self._max_epochs is not None, 'max_epochs should be provided by the init arguments or configured ' \
-                                             'in the `train.max_epochs` key in the configuration file.'
-        self._train_iters_per_epoch = kwargs.get(
-            'train_iters_per_epoch',
-            self.cfg.safe_get('train.train_iters_per_epoch'))
-        self._eval_iters_per_epoch = kwargs.get(
-            'val_iters_per_epoch',
-            self.cfg.safe_get('evaluation.val_iters_per_epoch'))
+        self.eval_dataset = self.build_dataset(datasets=eval_dataset,
+                                               cfg=self.cfg,
+                                               mode=ModeKeys.EVAL,
+                                               preprocessor=self.eval_preprocessor,
+                                               **kwargs)
+
+        self.train_data_collator, self.eval_data_collator = self.get_data_collator(data_collator,
+                                                                                   remove_unused_data=kwargs.get(
+                                                                                       'remove_unused_data', False))
+        self._max_epochs = kwargs.get('max_epochs', self.cfg.safe_get('train.max_epochs'))
+        assert self._max_epochs is not None, 'max_epochs should be provided by the init arguments or configured  in the `train.max_epochs` key in the configuration file.'
+        self._train_iters_per_epoch = kwargs.get('train_iters_per_epoch',
+                                                 self.cfg.safe_get('train.train_iters_per_epoch'))
+        self._eval_iters_per_epoch = kwargs.get('val_iters_per_epoch',
+                                                self.cfg.safe_get('evaluation.val_iters_per_epoch'))
         self.use_fp16 = kwargs.get('use_fp16', False)
         self.launcher = kwargs.get('launcher')
         self.device = kwargs.get('device')
         self.tune_module(efficient_tuners)
 
         # The parallel_groups field will be initialized in the hooks' after_init stage.
         # Please check the DDPHook and MegatronHook for details.
         self.parallel_groups = {}
 
-        if self.launcher is not None and not self.cfg.safe_get(
-                'train.hooks.DDPHook'):
+        if self.launcher is not None and not self.cfg.safe_get('train.hooks.DDPHook'):
             # A logic to fit the current code
             # Put a DDPHook in if launcher is provided.
             if 'hooks' not in self.cfg.train:
                 self.cfg.train['hooks'] = ConfigDict([])
             self.cfg.train['hooks'].append({
                 'type': 'DDPHook',
                 'launcher': self.launcher
@@ -243,16 +298,15 @@
         if callable(callbacks):
             callbacks = [callbacks]
         for callback in callbacks or []:
             self.register_hook(callback)
         self.invoke_hook(TrainerStages.after_init)
 
         # _dist represents for if dp is initialized and its world_size > 1
-        self._dist = self.is_dp_group_available() and dist.get_world_size(
-            self.dp_group) > 1
+        self._dist = self.is_dp_group_available() and dist.get_world_size(self.dp_group) > 1
 
         self.metrics = self.get_metrics()
 
         if not self.parallel_groups:
             # If not working in parallel scenario, put model to device as a default logic.
             device_name = self.device if self.device is not None else 'gpu'
             self.device = create_device(device_name)
@@ -262,15 +316,15 @@
         self.print_cfg()
 
     def tune_module(self, efficient_tuners):
         if efficient_tuners is not None:
             for tuner in efficient_tuners:
                 type = tuner.pop('type')
                 if type == 'lora':
-                    from modelscope.tuners.lora import LoRATuner
+                    from weathon.tuners.lora import LoRATuner
                     LoRATuner.tune(self.model, **tuner)
 
     def place_model(self):
         """Place model to device, or to DDP
         """
         if self.device.type == 'cuda':
             self.model.to(self.device)
@@ -297,25 +351,23 @@
                 eval_data_collator = data_collator[ConfigKeys.val]
         else:
             collate_fn = default_collate if data_collator is None else data_collator
             train_data_collator = collate_fn
             eval_data_collator = collate_fn
 
         if remove_unused_data:
-            from modelscope.utils.data_collators import RemoveColumnsCollator
+            from weathon.utils.data_collators import RemoveColumnsCollator
 
             def _set_signature_columns_if_needed():
                 signature = inspect.signature(self.model.forward)
                 return list(signature.parameters.keys())
 
             model_inputs = _set_signature_columns_if_needed()
-            train_data_collator = RemoveColumnsCollator(
-                train_data_collator, model_inputs)
-            eval_data_collator = RemoveColumnsCollator(eval_data_collator,
-                                                       model_inputs)
+            train_data_collator = RemoveColumnsCollator(train_data_collator, model_inputs)
+            eval_data_collator = RemoveColumnsCollator(eval_data_collator, model_inputs)
         return train_data_collator, eval_data_collator
 
     def init_dist(self, launcher=None):
         """Init dist and returns the dist information.
 
         Args:
             launcher: The launcher info.
@@ -342,50 +394,47 @@
         device_name = device if device is not None else 'gpu'
         if is_dist():
             local_rank = get_local_rank()
             device_name = f'cuda:{local_rank}'
 
         return create_device(device_name)
 
-    def get_preprocessors(self, preprocessor):
-        """Get the preprocessors information.
-
+    def get_preprocessors(self, preprocessor: Union[BasePreprocessor, Mapping, Config]) -> Optional[BasePreprocessor]:
+        """
         Args:
             preprocessor: The input preprocessor info.
 
         Returns:
             The train_preprocessor and eval_preprocessor, can be None.
         """
         train_preprocessor = None
         eval_preprocessor = None
-        if isinstance(preprocessor, Preprocessor):
+
+        if isinstance(preprocessor, BasePreprocessor):
             train_preprocessor = preprocessor
             eval_preprocessor = preprocessor
         elif isinstance(preprocessor, Mapping):
             if ConfigKeys.train in preprocessor:
                 assert isinstance(preprocessor[ConfigKeys.train], Callable)
                 train_preprocessor = preprocessor[ConfigKeys.train]
             if ConfigKeys.val in preprocessor:
                 assert isinstance(preprocessor[ConfigKeys.val], Callable)
                 eval_preprocessor = preprocessor[ConfigKeys.val]
-        elif hasattr(self.cfg, ConfigFields.preprocessor
-                     ) and self.cfg.preprocessor is not None:
+        elif hasattr(self.cfg, ConfigFields.preprocessor) and self.cfg.preprocessor is not None:
             train_preprocessor, eval_preprocessor = self.build_preprocessor()
 
         if train_preprocessor is not None:
             train_preprocessor.mode = ModeKeys.TRAIN
         if eval_preprocessor is not None:
             eval_preprocessor.mode = ModeKeys.EVAL
         return train_preprocessor, eval_preprocessor
 
     def rebuild_config(self, cfg: Config):
-        """A method used to rebuild the config, any subclass can override this method.
-
+        """ "cfg_modify_fn". 
         Returns: The rebuilt config
-
         """
         if hasattr(self, 'cfg_modify_fn') and self.cfg_modify_fn is not None:
             cfg = self.cfg_modify_fn(cfg)
         return cfg
 
     @property
     def dp_group(self):
@@ -427,15 +476,15 @@
         return DistributedParallelType.PP in self.parallel_groups
 
     @property
     def mode(self):
         return self._mode
 
     @property
-    def hooks(self) -> List[Hook]:
+    def hooks(self) -> List[BaseHook]:
         """list[:obj:`Hook`]: A list of registered hooks."""
         return self._hooks
 
     @property
     def epoch(self) -> int:
         """int: Current epoch."""
         return self._epoch
@@ -481,97 +530,140 @@
                 return _get_data_len(self.train_dataloader)
         elif self.mode == ModeKeys.EVAL:
             if self._eval_iters_per_epoch is not None:
                 return self._eval_iters_per_epoch
             else:
                 return _get_data_len(self.eval_dataloader)
 
+    # def build_dataset(self, datasets: Union[Dataset, WtDataset, List[Dataset]], cfg: Config,
+    #                   mode: str, preprocessor: Optional[BasePreprocessor] = None, **kwargs):
+    #     """ ,
+    #     Args:
+    #         datasets (Union[Dataset, MsDataset, List[Dataset]]): .
+    #         cfg (Config): .
+    #         mode (str): `train`, `eval` or `inference`. See weathon.utils.constant.ModeKeys
+    #         preprocessor (Preprocessor, Optional): The preprocessor for input data samples.
+    #
+    #     Returns:
+    #         Preprocessed datasets.
+    #     """
+    #     try:
+    #         if not datasets:
+    #             dataset_cfg = cfg.safe_get(f'dataset.{mode}')
+    #             if dataset_cfg:
+    #                 custom_dataset = build_custom_dataset(dataset_cfg, task_name=dataset_cfg.task,
+    #                                                       default_args=dict(preprocessor=preprocessor))
+    #                 custom_dataset.trainer = self
+    #                 return custom_dataset
+    #
+    #             return EpochBasedTrainer.build_dataset_from_cfg(model_cfg=cfg, mode=mode, preprocessor=preprocessor)
+    #
+    #         if isinstance(datasets, TorchCustomDataset):
+    #             return datasets
+    #         elif isinstance(datasets, WtDataset):
+    #             if not datasets.is_custom:
+    #                 datasets.to_custom_dataset(custom_cfg=cfg, preprocessor=preprocessor, mode=mode, **kwargs)
+    #             return datasets.ds_instance
+    #         elif isinstance(datasets, List) and isinstance(datasets[0], WtDataset):
+    #             custom_datasets = []
+    #             for dataset in datasets:
+    #                 if not dataset.is_custom:
+    #                     dataset.to_custom_dataset(custom_cfg=cfg, preprocessor=preprocessor, mode=mode, **kwargs)
+    #                 custom_datasets.append(dataset.ds_instance)
+    #             torch_custom_dataset = TorchCustomDataset(datasets=custom_datasets, mode=mode, preprocessor=None,
+    #                                                       **kwargs)
+    #             torch_custom_dataset.trainer = self
+    #             return torch_custom_dataset
+    #         else:
+    #             dataset_mode_key = 'train' if mode == ModeKeys.TRAIN else 'val'
+    #             data_config = cfg.safe_get(f'dataset.{dataset_mode_key}')
+    #             if data_config is None:
+    #                 # adapt to some special models
+    #                 data_config = {}
+    #             # avoid add no str value datasets, preprocessors in cfg
+    #             data_build_config = ConfigDict(type=cfg.model.type, mode=mode, datasets=datasets,
+    #                                            preprocessor=preprocessor)
+    #             data_build_config.update(data_config)
+    #             custom_dataset = build_custom_dataset(data_build_config, cfg.task)
+    #             custom_dataset.trainer = self
+    #             return custom_dataset
+    #     except Exception as e:
+    #         print('** build_dataset error log:', e)
+    #         if isinstance(datasets, (List, Tuple)) or preprocessor is not None:
+    #             custom_dataset = TorchCustomDataset(datasets, mode=mode, preprocessor=preprocessor, **(
+    #                 dict(type=cfg.model.type) if hasattr(cfg, 'model') else {}))
+    #             custom_dataset.trainer = self
+    #             return custom_dataset
+    #         else:
+    #             return datasets
+
     def build_dataset(self,
-                      datasets: Union[Dataset, MsDataset, List[Dataset]],
+                      datasets: Union[Dataset, WtDataset, List[Dataset]],
                       model_cfg: Config,
                       mode: str,
-                      preprocessor: Optional[Preprocessor] = None,
+                      preprocessor: Optional[BasePreprocessor] = None,
                       **kwargs):
         """Build input datasets by given model configuration and preprocessor.
 
         Args:
             datasets (Union[Dataset, MsDataset, List[Dataset]]): The input datasets.
             model_cfg (Config): The model configuration.
             mode (str): `train`, `eval` or `inference`. See modelscope.utils.constant.ModeKeys
             preprocessor (Preprocessor, Optional): The preprocessor for input data samples.
 
         Returns:
             Preprocessed datasets.
         """
         try:
             if not datasets:
-                return EpochBasedTrainer.build_dataset_from_cfg(
-                    model_cfg=model_cfg, mode=mode, preprocessor=preprocessor)
+                return EpochBasedTrainer.build_dataset_from_cfg(model_cfg=model_cfg, mode=mode,
+                                                                preprocessor=preprocessor)
 
             if isinstance(datasets, TorchCustomDataset):
                 return datasets
-            elif isinstance(datasets, MsDataset):
+            elif isinstance(datasets, WtDataset):
                 if not datasets.is_custom:
-                    datasets.to_custom_dataset(
-                        custom_cfg=model_cfg,
-                        preprocessor=preprocessor,
-                        mode=mode,
-                        **kwargs)
+                    datasets.to_custom_dataset(custom_cfg=model_cfg, preprocessor=preprocessor, mode=mode, **kwargs)
                 return datasets.ds_instance
-            elif isinstance(datasets, List) and isinstance(
-                    datasets[0], MsDataset):
+            elif isinstance(datasets, List) and isinstance(datasets[0], WtDataset):
                 custom_datasets = []
                 for dataset in datasets:
                     if not dataset.is_custom:
-                        dataset.to_custom_dataset(
-                            custom_cfg=model_cfg,
-                            preprocessor=preprocessor,
-                            mode=mode,
-                            **kwargs)
+                        dataset.to_custom_dataset(custom_cfg=model_cfg, preprocessor=preprocessor, mode=mode, **kwargs)
                     custom_datasets.append(dataset.ds_instance)
-                torch_custom_dataset = TorchCustomDataset(
-                    datasets=custom_datasets,
-                    mode=mode,
-                    preprocessor=None,
-                    **kwargs)
+                torch_custom_dataset = TorchCustomDataset(datasets=custom_datasets, mode=mode, preprocessor=None,
+                                                          **kwargs)
                 torch_custom_dataset.trainer = self
                 return torch_custom_dataset
             else:
                 dataset_mode_key = 'train' if mode == ModeKeys.TRAIN else 'val'
                 data_config = model_cfg.safe_get(f'dataset.{dataset_mode_key}')
                 if data_config is None:
                     # adapt to some special models
                     data_config = {}
                 # avoid add no str value datasets, preprocessors in cfg
-                data_build_config = ConfigDict(
-                    type=model_cfg.model.type,
-                    mode=mode,
-                    datasets=datasets,
-                    preprocessor=preprocessor)
+                data_build_config = ConfigDict(type=model_cfg.model.type, mode=mode, datasets=datasets,
+                                               preprocessor=preprocessor)
                 data_build_config.update(data_config)
                 custom_dataset = build_custom_dataset(data_build_config,
                                                       model_cfg.task)
                 custom_dataset.trainer = self
                 return custom_dataset
         except Exception as e:
             print('** build_dataset error log:', e)
             if isinstance(datasets, (List, Tuple)) or preprocessor is not None:
-                custom_dataset = TorchCustomDataset(
-                    datasets,
-                    mode=mode,
-                    preprocessor=preprocessor,
-                    **(dict(type=model_cfg.model.type) if hasattr(
-                        model_cfg, 'model') else {}))
+                custom_dataset = TorchCustomDataset(datasets, mode=mode, preprocessor=preprocessor, **(
+                    dict(type=model_cfg.model.type) if hasattr(model_cfg, 'model') else {}))
                 custom_dataset.trainer = self
                 return custom_dataset
             else:
                 return datasets
 
     def to_task_dataset(self, dataset: Dataset, mode: str,
-                        preprocessor: Preprocessor,
+                        preprocessor: BasePreprocessor,
                         **kwargs) -> TorchCustomDataset:
         r"""
         @deprecated
         This method is deprecated and may be removed in future releases, please use `build_dataset()` instead. Could be
         compatible with methods that override the to_task_dataset in other classes.
         """
         self.logger.warning(
@@ -580,81 +672,67 @@
 
         task_dataset = TorchCustomDataset(
             dataset, mode=mode, preprocessor=preprocessor, **kwargs)
         task_dataset.trainer = self
         return task_dataset
 
     @staticmethod
-    def build_dataset_from_cfg(model_cfg: Config,
-                               mode: str,
-                               preprocessor: Preprocessor = None):
+    def build_dataset_from_cfg(model_cfg: Config, mode: str, preprocessor: BasePreprocessor = None):
         dataset = None
         dataset_name = model_cfg.safe_get('dataset.name')
         subset_name = model_cfg.safe_get('dataset.subset', default='default')
         split_name = model_cfg.safe_get(f'dataset.split_{mode}')
         if not dataset_name or not split_name:
             return dataset
-        dataset = MsDataset.load(
-            dataset_name=dataset_name,
-            subset_name=subset_name,
-            split=split_name,
-            custom_cfg=model_cfg)
+        dataset = WtDataset.load(dataset_name=dataset_name, subset_name=subset_name, split=split_name,
+                                 custom_cfg=model_cfg)
         if not dataset.is_custom:
-            dataset.to_custom_dataset(
-                custom_cfg=model_cfg, preprocessor=preprocessor, mode=mode)
-
+            dataset.to_custom_dataset(custom_cfg=model_cfg, preprocessor=preprocessor, mode=mode)
         return dataset.ds_instance
 
-    def build_preprocessor(self) -> Tuple[Preprocessor, Preprocessor]:
+    def build_preprocessor(self) -> Tuple[BasePreprocessor, BasePreprocessor]:
         """Build train and eval preprocessor.
 
         User can override this method to implement custom logits.
 
         Returns: The train preprocessor and eval preprocessor instance.
 
         """
-        train_preprocessor = Preprocessor.from_pretrained(
-            self.model_dir,
-            cfg_dict=self.cfg,
-            preprocessor_mode=ModeKeys.TRAIN)
-        eval_preprocessor = Preprocessor.from_pretrained(
-            self.model_dir, cfg_dict=self.cfg, preprocessor_mode=ModeKeys.EVAL)
+        train_preprocessor = BasePreprocessor.from_pretrained(self.model_dir, cfg_dict=self.cfg,
+                                                              preprocessor_mode=ModeKeys.TRAIN)
+        eval_preprocessor = BasePreprocessor.from_pretrained(self.model_dir, cfg_dict=self.cfg,
+                                                             preprocessor_mode=ModeKeys.EVAL)
         return train_preprocessor, eval_preprocessor
 
     def get_metrics(self) -> List[Union[str, Dict]]:
         """Get the metric class types.
 
         The first choice will be the metrics configured in the config file, if not found, the default metrics will be
         used.
         If no metrics is found and the eval dataset exists, the method will raise an error.
 
         Returns: The metric types.
 
         """
-        metrics = self.cfg.evaluation.metrics if hasattr(
-            self.cfg, 'evaluation') and hasattr(self.cfg.evaluation,
-                                                'metrics') else None
-        metrics = metrics if metrics is not None else task_default_metrics.get(
-            self.cfg.task)
+        metrics = self.cfg.evaluation.metrics if hasattr(self.cfg, 'evaluation') and hasattr(self.cfg.evaluation,
+                                                                                             'metrics') else None
+        metrics = metrics if metrics is not None else task_default_metrics.get(self.cfg.task)
         if metrics is None and self.eval_dataset is not None:
             raise ValueError(
                 f'Metrics are needed in evaluation, please try to either '
                 f'add metrics in configuration.json or add the default metric for {self.cfg.task}.'
             )
         if isinstance(metrics, (str, Mapping)):
             metrics = [metrics]
         return metrics
 
-    def set_checkpoint_file_to_hook(self, checkpoint_path, load_all_state,
-                                    strict):
+    def set_checkpoint_file_to_hook(self, checkpoint_path, load_all_state, strict):
         if checkpoint_path is not None:
-            from modelscope.trainers.hooks import LoadCheckpointHook
-            load_ckpt_hooks = list(
-                filter(lambda hook: isinstance(hook, LoadCheckpointHook),
-                       self.hooks))
+            from weathon.hooks import LoadCheckpointHook
+            load_ckpt_hooks = list(filter(lambda hook: isinstance(hook, LoadCheckpointHook), self.hooks))
             if len(load_ckpt_hooks) == 0:
                 load_ckpt_hook = LoadCheckpointHook()
                 self.register_hook(load_ckpt_hook)
                 load_ckpt_hooks.append(load_ckpt_hook)
             load_ckpt_hooks[0].checkpoint_file = checkpoint_path
             load_ckpt_hooks[0].load_all_state = load_all_state
             load_ckpt_hooks[0].strict = strict
@@ -678,16 +756,15 @@
 
         self._mode = ModeKeys.TRAIN
         self.train_dataloader = self.get_train_dataloader()
         self.data_loader = self.train_dataloader
         self.register_optimizers_hook()
         self.register_processors()
         self.print_hook_info()
-        self.set_checkpoint_file_to_hook(checkpoint_path, load_all_state,
-                                         kwargs.get('strict', False))
+        self.set_checkpoint_file_to_hook(checkpoint_path, load_all_state, kwargs.get('strict', False))
         self.model.train()
 
         self.train_loop(self.train_dataloader)
 
     def predict(self,
                 predict_datasets: Union[Dataset, List[Dataset]],
                 saving_fn,
@@ -719,15 +796,15 @@
                 generated by this trainer.
 
             strict(`boolean`): If strict, any unmatched keys will cause an error.
         """
         self.register_processors()
         self.print_hook_info()
         if checkpoint_path is not None:
-            from modelscope.trainers.hooks import LoadCheckpointHook
+            from weathon.hooks import LoadCheckpointHook
             LoadCheckpointHook.load_checkpoint(
                 checkpoint_path, self, strict=strict)
         self.model.eval()
         self._mode = ModeKeys.EVAL
         predict_dataloader = self.get_predict_dataloader(predict_datasets)
         metric_classes = [PredictionSavingWrapper(saving_fn=saving_fn)]
 
@@ -758,17 +835,16 @@
                 >>>                 f.writelines(f'{id}, {pred}')
             kwargs:
                 strict(`boolean`): If strict, any unmatched keys will cause an error.
         """
         self.register_processors()
         self.print_hook_info()
         if checkpoint_path is not None:
-            from modelscope.trainers.hooks import LoadCheckpointHook
-            LoadCheckpointHook.load_checkpoint(
-                checkpoint_path, self, strict=kwargs.get('strict', False))
+            from weathon.hooks import LoadCheckpointHook
+            LoadCheckpointHook.load_checkpoint(checkpoint_path, self, strict=kwargs.get('strict', False))
         self.model.eval()
         self._mode = ModeKeys.EVAL
         self.eval_dataloader = self.get_eval_data_loader()
         self.data_loader = self.eval_dataloader
         metric_classes = [build_metric(metric) for metric in self.metrics]
         if saving_fn is not None:
             metric_classes.append(PredictionSavingWrapper(saving_fn=saving_fn))
@@ -782,32 +858,28 @@
         return metric_values
 
     @property
     def metric_values(self):
         return self._metric_values
 
     def build_model(self) -> Union[nn.Module, TorchModel]:
-        """ Instantiate a pytorch model and return.
-
-        By default, we will create a model using config from configuration file. You can
-        override this method in a subclass.
-
+        """ pytorch
+        ,.
         """
-        model = Model.from_pretrained(self.model_dir, cfg_dict=self.cfg)
+        model = BaseModel.from_pretrained(self.model_dir, cfg_dict=self.cfg)
         if not isinstance(model, nn.Module) and hasattr(model, 'model'):
             return model.model
         elif isinstance(model, nn.Module):
             return model
 
     def to_parallel(self, model) -> Union[nn.Module, TorchModel]:
         # config format to reserve custom ddp
         if self.cfg.get('parallel', None) is not None:
             dp_cfg = deepcopy(self.cfg['parallel'])
-            dp_cfg.update(
-                dict(module=model, device_ids=[torch.cuda.current_device()]))
+            dp_cfg.update(dict(module=model, device_ids=[torch.cuda.current_device()]))
             return build_parallel(dp_cfg)
 
         dp_cfg = dict(
             type='DistributedDataParallel',
             module=model,
             find_unused_parameters=True,
             device_ids=[torch.cuda.current_device()],
@@ -853,26 +925,25 @@
             self.unwrap_module(self.model).forward)
 
         if isinstance(inputs, Mapping) and not receive_dict_inputs:
             train_outputs = model.forward(**inputs)
         else:
             train_outputs = model.forward(inputs)
 
-        if isinstance(train_outputs, ModelOutputBase):
+        if isinstance(train_outputs, BaseModelOutput):
             train_outputs = train_outputs.to_dict()
         if not isinstance(train_outputs, dict):
             raise TypeError('"model.forward()" must return a dict')
 
         # add model output info to log
         if 'log_vars' not in train_outputs:
             default_keys_pattern = ['loss']
             match_keys = set([])
             for key_p in default_keys_pattern:
-                match_keys.update(
-                    [key for key in train_outputs.keys() if key_p in key])
+                match_keys.update([key for key in train_outputs.keys() if key_p in key])
 
             log_vars = {}
             for key in match_keys:
                 value = train_outputs.get(key, None)
                 if value is not None:
                     if is_dist():
                         value = value.data.clone().to('cuda')
@@ -898,24 +969,23 @@
         (or `get_train_dataloader` in a subclass.
         """
         if self.train_dataset is None:
             raise 'The train_dataset cannot be None.'
 
         sampler_cfg = {}
         if self._samplers is not None:
-            sampler_cfg['sampler'] = self._samplers[
-                ConfigKeys.train] if isinstance(self._samplers,
-                                                dict) else self._samplers
-        data_loader = self._build_dataloader_with_dataset(
-            self.train_dataset,
-            dist=self._dist,
-            seed=self._seed,
-            collate_fn=self.train_data_collator,
-            **sampler_cfg,
-            **self.cfg.train.get('dataloader', {}))
+            sampler_cfg['sampler'] = self._samplers[ConfigKeys.train] if isinstance(self._samplers,
+                                                                                    dict) else self._samplers
+        data_loader = self._build_dataloader_with_dataset(self.train_dataset,
+                                                          dist=self._dist,
+                                                          seed=self._seed,
+                                                          collate_fn=self.train_data_collator,
+                                                          **sampler_cfg,
+                                                          **self.cfg.train.get('dataloader', {})
+                                                          )
         return data_loader
 
     def get_eval_data_loader(self):
         """ Builder torch dataloader for evaluation.
 
         We provide a reasonable default that works well. If you want to use something else, you can change
         the config for dataset.eval in configuration file, or subclass and override this method in a subclass.
@@ -923,62 +993,54 @@
         """
         if self.eval_dataset is None:
             raise 'The eval_dataset cannot be None.'
 
         sampler_cfg = {}
         if self._samplers is not None:
             sampler_cfg['sampler'] = self._samplers[
-                ConfigKeys.val] if isinstance(self._samplers,
-                                              dict) else self._samplers
+                ConfigKeys.val] if isinstance(self._samplers, dict) else self._samplers
         default_config = {'shuffle': False}
         default_config.update(self.cfg.evaluation.get('dataloader', {}))
-        data_loader = self._build_dataloader_with_dataset(
-            self.eval_dataset,
-            dist=self._dist,
-            seed=self._seed,
-            collate_fn=self.eval_data_collator,
-            **sampler_cfg,
-            **default_config)
+        data_loader = self._build_dataloader_with_dataset(self.eval_dataset,
+                                                          dist=self._dist,
+                                                          seed=self._seed,
+                                                          collate_fn=self.eval_data_collator,
+                                                          **sampler_cfg,
+                                                          **default_config
+                                                          )
         return data_loader
 
-    def get_predict_dataloader(self, predict_datasets: Union[Dataset,
-                                                             List[Dataset]]):
+    def get_predict_dataloader(self, predict_datasets: Union[Dataset, List[Dataset]]):
         """ Builder torch dataloader for prediction with the config of evaluation.
 
         Args:
             predict_datasets(Union[Dataset, List[Dataset]]): The datasets used to predict ground truth.
         """
-        dataset = self.build_dataset(
-            datasets=predict_datasets,
-            model_cfg=self.cfg,
-            mode=ModeKeys.EVAL,
-            preprocessor=self.eval_preprocessor)
+        dataset = self.build_dataset(datasets=predict_datasets,
+                                     model_cfg=self.cfg,
+                                     mode=ModeKeys.EVAL,
+                                     preprocessor=self.eval_preprocessor)
 
         sampler_cfg = {}
         if self._samplers is not None:
-            sampler_cfg['sampler'] = self._samplers[
-                ConfigKeys.val] if isinstance(self._samplers,
-                                              dict) else self._samplers
+            sampler_cfg['sampler'] = self._samplers[ConfigKeys.val] if isinstance(self._samplers,
+                                                                                  dict) else self._samplers
         default_config = {'shuffle': False}
         default_config.update(self.cfg.evaluation.get('dataloader', {}))
-        data_loader = self._build_dataloader_with_dataset(
-            dataset,
-            dist=self._dist,
-            seed=self._seed,
-            collate_fn=self.eval_data_collator,
-            **sampler_cfg,
-            **default_config)
+        data_loader = self._build_dataloader_with_dataset(dataset,
+                                                          dist=self._dist,
+                                                          seed=self._seed,
+                                                          collate_fn=self.eval_data_collator,
+                                                          **sampler_cfg,
+                                                          **default_config)
         return data_loader
 
     def build_optimizer(self, cfg: ConfigDict, default_args: dict = None):
         try:
-            return build_optimizer(
-                self.unwrap_module(self.model),
-                cfg=cfg,
-                default_args=default_args)
+            return build_optimizer(self.unwrap_module(self.model), cfg=cfg, default_args=default_args)
         except KeyError as e:
             self.logger.error(
                 f'Build optimizer error, the optimizer {cfg} is a torch native component, '
                 f'please check if your torch with version: {torch.__version__} matches the config.'
             )
             raise e
 
@@ -1015,47 +1077,43 @@
         else:
             lr_scheduler_cfg = None
 
         lr_options = {}
         if lr_scheduler_cfg is not None:
             assert optimizer is not None
             lr_options = lr_scheduler_cfg.pop('options', {})
-            lr_scheduler = self.build_lr_scheduler(
-                cfg=lr_scheduler_cfg, default_args={'optimizer': optimizer})
+            lr_scheduler = self.build_lr_scheduler(cfg=lr_scheduler_cfg, default_args={'optimizer': optimizer})
 
         self.optimizer = optimizer
         self.lr_scheduler = lr_scheduler
         return self.optimizer, self.lr_scheduler, optim_options, lr_options
 
     def register_optimizers_hook(self):
         """ Register optimizer hook and lr scheduler hook.
         """
-        _, lr_scheduler, optim_options, lr_options = self.create_optimizer_and_scheduler(
-        )
+        _, lr_scheduler, optim_options, lr_options = self.create_optimizer_and_scheduler()
 
         optim_hook = self.cfg.train.get('optimizer_hook', {})
         lr_hook = self.cfg.train.get('lr_scheduler_hook', {})
 
         # adapt to `ReduceLROnPlateau`
         from torch.optim.lr_scheduler import ReduceLROnPlateau
         if isinstance(lr_scheduler, ReduceLROnPlateau) and not lr_hook:
             plateau_cfg = {
                 'train': {
                     'lr_scheduler_hook': {
                         'type': 'PlateauLrSchedulerHook',
                         'metric_key':
-                        'Metric Key used for PlateauLrSchedulerHook'
+                            'Metric Key used for PlateauLrSchedulerHook'
                     }
                 }
             }
-            plateau_cfg = json.dumps(
-                plateau_cfg, sort_keys=False, indent=4, separators=(',', ':'))
+            plateau_cfg = json.dumps(plateau_cfg, sort_keys=False, indent=4, separators=(',', ':'))
             raise ValueError(
-                'Must add `lr_scheduler_hook` to configuration for `ReduceLROnPlateau` lr scheduler as follows:'
-                + '\n' + plateau_cfg)
+                'Must add `lr_scheduler_hook` to configuration for `ReduceLROnPlateau` lr scheduler as follows:' + '\n' + plateau_cfg)
 
         def _fit_to_old_keys():
             """This function used to fit `optimizer_hook` key and `lr_scheduler_hook` key for easycv configs.
 
             The logic is:
                 If the optimizer_hook is provided and it's not TorchAMPOptimizerHook or ApexAMPOptimizerHook,
                 (which means the hook is a complete one for optimization, which does not need the OptimizerHook),
@@ -1076,36 +1134,115 @@
                 lr_hook.pop('type', None)
                 _lr_options = {**lr_options, **lr_hook}
 
             if optim_hook:
                 self.register_hook_from_cfg([optim_hook])
 
             _optim_options = None
-            if optim_hook.get('type') in ('TorchAMPOptimizerHook',
-                                          'ApexAMPOptimizerHook'):
+            if optim_hook.get('type') in ('TorchAMPOptimizerHook', 'ApexAMPOptimizerHook'):
                 self.use_fp16 = False
             if not optim_hook or optim_hook.get('type') in (
                     'TorchAMPOptimizerHook', 'ApexAMPOptimizerHook'):
                 optim_hook.pop('type', None)
                 _optim_options = {**optim_options, **optim_hook}
 
             return _optim_options, _lr_options
 
         optim_options, lr_options = _fit_to_old_keys()
 
         if optim_options is not None:
-            self.register_hook_from_cfg(
-                [dict(type='OptimizerHook', **optim_options)])
+            self.register_hook_from_cfg([dict(type='OptimizerHook', **optim_options)])
         if lr_options is not None:
-            self.register_hook_from_cfg(
-                [dict(type='LrSchedulerHook', **lr_options)])
+            self.register_hook_from_cfg([dict(type='LrSchedulerHook', **lr_options)])
         if self.use_fp16:
-            self.register_hook_from_cfg(
-                [dict(type='TorchAMPOptimizerHook', **optim_options)])
+            self.register_hook_from_cfg([dict(type='TorchAMPOptimizerHook', **optim_options)])
 
+    # def _build_dataloader_with_dataset(self,
+    #                                    dataset: Dataset,
+    #                                    batch_size_per_gpu: int,
+    #                                    workers_per_gpu: int,
+    #                                    dist: bool = False,
+    #                                    shuffle: bool = True,
+    #                                    seed: int = 0,
+    #                                    persistent_workers=False,
+    #                                    **kwargs) -> DataLoader:
+    #     """Build dataloader using input dataset and cfg. Used by `EpochBasedTrainer.train()`
+    #     and `EpochBasedTrainer.evaluate()`.
+    #
+    #     In distributed training, each GPU/process has a dataloader.
+    #     In non-distributed training, there is only one dataloader for all GPUs.
+    #
+    #     Args:
+    #         dataset (Dataset): A PyTorch dataset.
+    #         batch_size_per_gpu (int): Number of training samples on each GPU, i.e.,
+    #             batch size of each GPU.
+    #         workers_per_gpu (int): How many subprocesses to use for data loading
+    #             for each GPU.
+    #         dist (bool): Distributed training/test or not. Default: True.
+    #         shuffle (bool): Whether to shuffle the data at every epoch.
+    #             Default: True.
+    #         seed (int, Optional): Seed to be used. Default: 0.
+    #         runner_type (str): Type of runner. Default: `EpochBasedRunner`
+    #         persistent_workers (bool): If True, the data loader will not shutdown
+    #             the worker processes after a dataset has been consumed once.
+    #             This allows to maintain the workers `Dataset` instances alive.
+    #             This argument is only valid when PyTorch>=1.7.0. Default: False.
+    #         kwargs: any keyword argument to be used to initialize DataLoader
+    #
+    #     Returns:
+    #         DataLoader: A PyTorch dataloader.
+    #     """
+    #     rank = 0
+    #     world_size = 1
+    #     if self.is_dp_group_available():
+    #         rank = torch.distributed.get_rank(self.dp_group)
+    #         world_size = torch.distributed.get_world_size(self.dp_group)
+    #
+    #     if dist:
+    #         # When model is :obj:`DistributedDataParallel`,
+    #         # `batch_size` of :obj:`dataloader` is the
+    #         # number of training samples on each GPU.
+    #         batch_size = batch_size_per_gpu
+    #         num_workers = workers_per_gpu
+    #     else:
+    #         batch_size = batch_size_per_gpu
+    #         num_workers = workers_per_gpu
+    #
+    #     sampler = kwargs.pop('sampler', None)
+    #     if sampler is None:
+    #         if dist and not isinstance(dataset, torch.utils.data.IterableDataset):
+    #             sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=shuffle)
+    #         else:
+    #             sampler = None
+    #             if not isinstance(dataset, torch.utils.data.IterableDataset):
+    #                 kwargs['shuffle'] = shuffle
+    #
+    #     batch_sampler = None
+    #
+    #     init_fn = partial(worker_init_fn, num_workers=num_workers, rank=rank, seed=seed) if seed is not None else None
+    #
+    #     if LooseVersion(torch.__version__) >= LooseVersion('1.7.0'):
+    #         kwargs['persistent_workers'] = persistent_workers
+    #     elif persistent_workers is True:
+    #         self.logger.warning('persistent_workers is invalid because your pytorch version is lower than 1.7.0')
+    #     cfg_dataloader = self.cfg.safe_get(f"{self.mode}.dataloader")
+    #     cfg_dataloader.setdefault("batch_size", batch_size)
+    #     cfg_dataloader.setdefault("sampler", sampler)
+    #     cfg_dataloader.setdefault("num_workers", num_workers)
+    #     cfg_dataloader.setdefault("batch_sampler", batch_sampler)
+    #     cfg_dataloader.setdefault("pin_memory", kwargs.pop('pin_memory', False))
+    #     cfg_dataloader.setdefault("worker_init_fn", init_fn)
+    #     cfg_dataloader.setdefault("collate_fn", kwargs.pop("collate_fn", None))
+    #     cfg_dataloader.setdefault("persistent_workers", kwargs.pop("persistent_workers", False))
+    #     cfg_dataloader.setdefault("num_gpus", kwargs.pop("num_gpus", 0))
+    #     kwargs.setdefault("distributed", False)
+    #     is_train = (self.mode == ModeKeys.TRAIN)
+    #     data_loader = DataLoader(dataset, cfg_dataloader=cfg_dataloader, is_train=is_train, **kwargs)
+    #
+    #     return data_loader
     def _build_dataloader_with_dataset(self,
                                        dataset: Dataset,
                                        batch_size_per_gpu: int,
                                        workers_per_gpu: int,
                                        dist: bool = False,
                                        shuffle: bool = True,
                                        seed: int = 0,
@@ -1151,48 +1288,33 @@
             num_workers = workers_per_gpu
         else:
             batch_size = batch_size_per_gpu
             num_workers = workers_per_gpu
 
         sampler = kwargs.pop('sampler', None)
         if sampler is None:
-            if dist and not isinstance(dataset,
-                                       torch.utils.data.IterableDataset):
-                sampler = DistributedSampler(
-                    dataset,
-                    num_replicas=world_size,
-                    rank=rank,
-                    shuffle=shuffle)
+            if dist and not isinstance(dataset, torch.utils.data.IterableDataset):
+                sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=shuffle)
             else:
                 sampler = None
                 if not isinstance(dataset, torch.utils.data.IterableDataset):
                     kwargs['shuffle'] = shuffle
 
         batch_sampler = None
 
-        init_fn = partial(
-            worker_init_fn, num_workers=num_workers, rank=rank,
-            seed=seed) if seed is not None else None
+        init_fn = partial(worker_init_fn, num_workers=num_workers, rank=rank, seed=seed) if seed is not None else None
 
         if LooseVersion(torch.__version__) >= LooseVersion('1.7.0'):
             kwargs['persistent_workers'] = persistent_workers
         elif persistent_workers is True:
-            self.logger.warning(
-                'persistent_workers is invalid because your pytorch '
-                'version is lower than 1.7.0')
-
-        data_loader = DataLoader(
-            dataset,
-            batch_size=batch_size,
-            sampler=sampler,
-            num_workers=num_workers,
-            batch_sampler=batch_sampler,
-            pin_memory=kwargs.pop('pin_memory', False),
-            worker_init_fn=init_fn,
-            **kwargs)
+            self.logger.warning('persistent_workers is invalid because your pytorch version is lower than 1.7.0')
+
+        data_loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler, num_workers=num_workers,
+                                 batch_sampler=batch_sampler, pin_memory=kwargs.pop('pin_memory', False),
+                                 worker_init_fn=init_fn, **kwargs)
 
         return data_loader
 
     def train_loop(self, data_loader):
         """ Training loop used by `EpochBasedTrainer.train()`
         """
         self.invoke_hook(TrainerStages.before_run)
@@ -1230,16 +1352,15 @@
         """Perform a training step on a batch of inputs.
 
         Subclass and override to inject custom behavior.
 
         """
         self.model.eval()
 
-        receive_dict_inputs = func_receive_dict_inputs(
-            self.unwrap_module(self.model).forward)
+        receive_dict_inputs = func_receive_dict_inputs(self.unwrap_module(self.model).forward)
 
         with torch.no_grad():
             if isinstance(data, Mapping) and not receive_dict_inputs:
                 result = self.model.forward(**data)
             else:
                 result = self.model.forward(data)
         return result
@@ -1252,34 +1373,33 @@
         if hasattr(self.cfg.evaluation, 'visualization'):
             vis_cfg = self.cfg.evaluation.visualization
             vis_closure = partial(
                 self.visualization, dataset=self.eval_dataset, **vis_cfg)
 
         self.invoke_hook(TrainerStages.before_val)
         if self._dist:
-            from modelscope.trainers.utils.inference import multi_gpu_test
+            # from weathon.trainers.utils.inference import multi_gpu_test
             # list of batched result and data samples
-            metric_values = multi_gpu_test(
-                self,
-                data_loader,
-                device=self.device,
-                metric_classes=metric_classes,
-                vis_closure=vis_closure,
-                tmpdir=self.cfg.evaluation.get('cache_dir', None),
-                gpu_collect=self.cfg.evaluation.get('gpu_collect', False),
-                data_loader_iters_per_gpu=self._eval_iters_per_epoch)
+            from weathon.inference.inference import multi_gpu_test
+            metric_values = multi_gpu_test(self,
+                                           data_loader,
+                                           device=self.device,
+                                           metric_classes=metric_classes,
+                                           vis_closure=vis_closure,
+                                           tmpdir=self.cfg.evaluation.get('cache_dir', None),
+                                           gpu_collect=self.cfg.evaluation.get('gpu_collect', False),
+                                           data_loader_iters_per_gpu=self._eval_iters_per_epoch)
         else:
-            from modelscope.trainers.utils.inference import single_gpu_test
-            metric_values = single_gpu_test(
-                self,
-                data_loader,
-                device=self.device,
-                metric_classes=metric_classes,
-                vis_closure=vis_closure,
-                data_loader_iters=self._eval_iters_per_epoch)
+            from weathon.inference.inference import single_gpu_test
+            metric_values = single_gpu_test(self,
+                                            data_loader,
+                                            device=self.device,
+                                            metric_classes=metric_classes,
+                                            vis_closure=vis_closure,
+                                            data_loader_iters=self._eval_iters_per_epoch)
 
         self.invoke_hook(TrainerStages.after_val)
         return metric_values
 
     def visualization(self, batch_result, dataset, **kwargs):
         """ visualization function for evaluation results.
 
@@ -1295,34 +1415,32 @@
             >>> self.visualization_buffer.output['eval_vis'] = vis_results
 
         Args:
             results (list(dict)):  a list of result dict.
             dataset (Dataset): torch dataset object to access original data.
         """
         # TODO @wenmeng.zwm add visualization support for cv evaluation
-        raise NotImplementedError(
-            'visualization for evaluation will be supported in the future')
+        raise NotImplementedError('visualization for evaluation will be supported in the future')
 
-    def register_hook(self, hook: Hook) -> None:
+    def register_hook(self, hook: BaseHook) -> None:
         """Register a hook into the hook list.
 
         The hook will be inserted into a priority queue, with the specified
         priority (See :class:`Priority` for details of priorities).
         For hooks with the same priority, they will be triggered in the same
         order as they are registered.
 
         Args:
             hook (:obj:`Hook`): The hook to be registered.
         """
         # insert the hook to a sorted list
         inserted = False
         for i in range(len(self._hooks) - 1, -1, -1):
             p = hook.PRIORITY if hasattr(hook, 'PRIORITY') else Priority.NORMAL
-            p_i = self._hooks[i].PRIORITY if hasattr(
-                self._hooks[i], 'PRIORITY') else Priority.NORMAL
+            p_i = self._hooks[i].PRIORITY if hasattr(self._hooks[i], 'PRIORITY') else Priority.NORMAL
 
             if get_priority(p) > get_priority(p_i):
                 self._hooks.insert(i + 1, hook)
                 inserted = True
                 break
         if not inserted:
             self._hooks.insert(0, hook)
@@ -1371,52 +1489,215 @@
             if hasattr(hook, fn_name):
                 getattr(hook, fn_name)(self)
 
     def print_cfg(self):
         if is_master():
             cfg = deepcopy(self.cfg)
             cfg.train.work_dir = self.work_dir
-            self.logger.info(
-                '==========================Training Config Start=========================='
-            )
-            self.logger.info(
-                json.dumps(cfg._cfg_dict, indent=4, cls=JSONIteratorEncoder))
-            self.logger.info(
-                '===========================Training Config End==========================='
-            )
+            self.logger.info('==========================Training Config Start==========================')
+            self.logger.info(json.dumps(cfg._cfg_dict, indent=4, cls=JSONIteratorEncoder))
+            self.logger.info('===========================Training Config End===========================')
 
     def print_hook_info(self):
         if is_master() and not getattr(self, '_hook_info_printed', False):
             self.logger.info(self.get_hook_info())
             self._hook_info_printed = True
 
     def get_hook_info(self) -> str:
         # Get hooks info in each stage
-        stage_hook_map: Dict[str, list] = {stage: [] for stage in Hook.stages}
+        stage_hook_map: Dict[str, list] = {stage: [] for stage in BaseHook.stages}
         for hook in self.hooks:
             try:
                 priority = Priority(hook.PRIORITY).name  # type: ignore
             except Exception:
                 priority = Priority.NORMAL  # type: ignore
             classname = hook.__class__.__name__
             hook_info = f'({priority:<12}) {classname:<35}'
             if hasattr(hook, 'get_triggered_stages'):
                 for trigger_stage in hook.get_triggered_stages():
                     stage_hook_map[trigger_stage].append(hook_info)
 
         stage_hook_infos = []
-        for stage in Hook.stages:
+        for stage in BaseHook.stages:
             hook_infos = stage_hook_map[stage]
             if len(hook_infos) > 0:
                 info = f'Stage: {stage}:\n    '
                 info += '\n    '.join(hook_infos)
                 info += '\n -------------------- '
                 stage_hook_infos.append(info)
         stage_hook_infos = '\n'.join(stage_hook_infos)
         return stage_hook_infos
 
 
-def worker_init_fn(worker_id, num_workers, rank, seed):
-    # The seed of each worker equals to
-    # num_worker * rank + worker_id + user_seed
-    worker_seed = num_workers * rank + worker_id + seed
-    set_random_seed(worker_seed)
+@TRAINERS.register_module(module_name=Trainers.nlp_base_trainer)
+class NlpEpochBasedTrainer(EpochBasedTrainer):
+    """Add code to adapt with nlp models.
+
+    This trainer will accept the information of labels&text keys in the cfg, and then initialize
+    the nlp models/preprocessors with this information.
+
+    Labels&text key information may be carried in the cfg like this:
+
+    >>> cfg = {
+    >>>     ...
+    >>>     "dataset": {
+    >>>         "train": {
+    >>>             "first_sequence": "text1",
+    >>>             "second_sequence": "text2",
+    >>>             "label": "label",
+    >>>             "labels": [1, 2, 3, 4],
+    >>>         },
+    >>>         "val": {
+    >>>             "first_sequence": "text3",
+    >>>             "second_sequence": "text4",
+    >>>             "label": "label2",
+    >>>         },
+    >>>     }
+    >>> }
+
+    To view some actual finetune examples, please check the test files listed below:
+    tests/trainers/test_finetune_sequence_classification.py
+    tests/trainers/test_finetune_token_classification.py
+    """
+
+    def __init__(self, *args, **kwargs):
+        self.label2id = None
+        self.id2label = None
+        self.num_labels = None
+        self.train_keys = None
+        self.eval_keys = None
+        super().__init__(*args, **kwargs)
+
+    def prepare_labels(self, cfg):
+        try:
+            labels = cfg.dataset.train.labels
+            self.label2id = {label: idx for idx, label in enumerate(labels)}
+            self.id2label = {idx: label for idx, label in enumerate(labels)}
+            self.num_labels = len(labels)
+        except AttributeError:
+            pass
+
+        def build_dataset_keys(cfg):
+            if cfg is not None:
+                input_keys = {
+                    'first_sequence': getattr(cfg, 'first_sequence', None),
+                    'second_sequence': getattr(cfg, 'second_sequence', None),
+                    'label': getattr(cfg, 'label', None),
+                }
+            else:
+                input_keys = {}
+
+            return {k: v for k, v in input_keys.items() if v is not None}
+
+        self.train_keys = build_dataset_keys(cfg.safe_get('dataset.train'))
+        self.eval_keys = build_dataset_keys(cfg.safe_get('dataset.val'))
+        if len(self.eval_keys) == 0:
+            self.eval_keys = self.train_keys
+
+    def rebuild_config(self, cfg: Config):
+        if self.cfg_modify_fn is not None:
+            cfg = self.cfg_modify_fn(cfg)
+        self.prepare_labels(cfg)
+        if not hasattr(cfg.model, 'label2id') and not hasattr(cfg.model, 'id2label'):
+            if self.id2label is not None:
+                cfg.model['id2label'] = self.id2label
+            if self.label2id is not None:
+                cfg.model['label2id'] = self.label2id
+        return cfg
+
+    def build_model(self) -> Union[nn.Module, TorchModel]:
+        """ Instantiate a pytorch model and return.
+
+        By default, we will create a model using config from configuration file. You can
+        override this method in a subclass.
+
+        """
+        model_args = {} if self.num_labels is None else {'num_labels': self.num_labels}
+        model = BaseModel.from_pretrained(self.model_dir, cfg_dict=self.cfg, **model_args)
+        if not isinstance(model, nn.Module) and hasattr(model, 'model'):
+            return model.model
+        elif isinstance(model, nn.Module):
+            return model
+
+    def build_preprocessor(self) -> Tuple[BasePreprocessor, BasePreprocessor]:
+        """Build the preprocessor.
+
+        User can override this method to implement custom logits.
+
+        Returns: The preprocessor instance.
+
+        """
+
+        # Compatible with old logic
+        extra_args = {} if self.label2id is None else {'label2id': self.label2id}
+
+        train_preprocessor = BasePreprocessor.from_pretrained(self.model_dir,
+                                                              cfg_dict=self.cfg,
+                                                              preprocessor_mode=ModeKeys.TRAIN,
+                                                              **extra_args,
+                                                              **self.train_keys,
+                                                              mode=ModeKeys.TRAIN,
+                                                              use_fast=True)
+        eval_preprocessor = BasePreprocessor.from_pretrained(self.model_dir,
+                                                             cfg_dict=self.cfg,
+                                                             preprocessor_mode=ModeKeys.EVAL,
+                                                             **extra_args,
+                                                             **self.eval_keys,
+                                                             mode=ModeKeys.EVAL,
+                                                             use_fast=True)
+        return train_preprocessor, eval_preprocessor
+
+
+@TRAINERS.register_module(module_name=Trainers.nlp_veco_trainer)
+class VecoTrainer(NlpEpochBasedTrainer):
+
+    def evaluate(self, checkpoint_path=None):
+        """Veco evaluates the datasets one by one.
+
+        """
+
+        if checkpoint_path is not None:
+            from weathon.hooks import LoadCheckpointHook
+            LoadCheckpointHook.load_checkpoint(checkpoint_path, self)
+        self.model.eval()
+        self._mode = ModeKeys.EVAL
+        metric_values = {}
+
+        if self.eval_dataset is None:
+            self.eval_dataset = self.build_dataset_from_cfg(model_cfg=self.cfg, mode=self._mode,
+                                                            preprocessor=self.eval_preprocessor)
+
+        idx = 0
+        dataset_cnt = 1
+        if isinstance(self.eval_dataset, VecoDataset):
+            self.eval_dataset.switch_dataset(idx)
+            dataset_cnt = len(self.eval_dataset.datasets)
+
+        while True:
+            self.eval_dataloader = self._build_dataloader_with_dataset(self.eval_dataset,
+                                                                       **self.cfg.evaluation.get('dataloader', {}))
+            self.data_loader = self.eval_dataloader
+
+            metric_classes = [build_metric(metric) for metric in self.metrics]
+            for m in metric_classes:
+                m.trainer = self
+            self.evaluation_loop(self.eval_dataloader, metric_classes)
+
+            for m_idx, metric_cls in enumerate(metric_classes):
+                if f'eval_dataset[{idx}]' not in metric_values:
+                    metric_values[f'eval_dataset[{idx}]'] = {}
+                metric_values[f'eval_dataset[{idx}]'][
+                    self.metrics[m_idx]] = metric_cls.evaluate()
+
+            idx += 1
+            if idx < dataset_cnt:
+                self.eval_dataset.switch_dataset(idx)
+            else:
+                break
+
+        for metric_name in self.metrics:
+            all_metrics = [m[metric_name] for m in metric_values.values()]
+            for key in all_metrics[0].keys():
+                metric_values[key] = np.average(
+                    [metric[key] for metric in all_metrics])
+
+        return metric_values
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/training_args.py` & `weathon-0.0.0.14/weathon/trainers/training_args.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,17 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import re
 from copy import deepcopy
 from dataclasses import dataclass, field, fields
 from typing import List, Union
 
 import addict
 import json
 
-from modelscope.trainers.cli_argument_parser import CliArgumentParser
-from modelscope.utils.config import Config
+from weathon.trainers.cli_argument_parser import CliArgumentParser
+from weathon.utils.config.config import Config
 
 
 def set_flatten_value(values: Union[str, List[str]]):
     pairs = values.split(',') if isinstance(values, str) else values
     _params = {}
     for kv in pairs or []:
         if len(kv.strip()) == 0:
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/utils/inference.py` & `weathon-0.0.0.14/weathon/inference/inference.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,22 +1,19 @@
-# Copyright (c) OpenMMLab. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import logging
 import os
 import pickle
 import shutil
 from collections.abc import Mapping
 
 import torch
 from torch import distributed as dist
 from tqdm import tqdm
 
-from modelscope.utils.data_utils import to_device
-from modelscope.utils.torch_utils import (broadcast, get_dist_info, is_dist,
-                                          is_master, make_tmp_dir)
+from weathon.utils.data_utils import to_device
+from weathon.utils.torch_utils import (broadcast, get_dist_info, is_dist, is_master, make_tmp_dir)
 
 
 def single_gpu_test(trainer,
                     data_loader,
                     device,
                     metric_classes=None,
                     vis_closure=None,
```

### Comparing `weathon-0.0.0.13/weathon/dl/trainers/utils/log_buffer.py` & `weathon-0.0.0.14/weathon/utils/logger/log_buffer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) OpenMMLab. All rights reserved.
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from collections import OrderedDict
 
 import numpy as np
 
 
 class LogBuffer:
```

### Comparing `weathon-0.0.0.13/weathon/dl/tuners/control_sd_lora.py` & `weathon-0.0.0.14/weathon/tuners/control_sd_lora.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/tuners/lora.py` & `weathon-0.0.0.14/weathon/tuners/lora.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License (MIT). See LICENSE in the repo root for license information.
 import logging
 import math
 import os.path
 import types
 from typing import Dict, List
```

### Comparing `weathon-0.0.0.13/weathon/dl/tuners/sd_lora.py` & `weathon-0.0.0.14/weathon/tuners/sd_lora.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/utils/ast_utils.py` & `weathon-0.0.0.14/weathon/utils/ast_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,52 +1,59 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import ast
 import hashlib
 import os
 import os.path as osp
 import time
 import traceback
 from functools import reduce
 from pathlib import Path
 from typing import Union
 
 import gast
 import json
 
-from modelscope.fileio.file import LocalStorage
-from modelscope.metainfo import (CustomDatasets, Heads, Hooks, LR_Schedulers,
-                                 Metrics, Models, Optimizers, Pipelines,
-                                 Preprocessors, TaskModels, Trainers)
-from modelscope.utils.constant import Fields, Tasks
-from modelscope.utils.file_utils import get_default_cache_dir
-from modelscope.utils.logger import get_logger
-from modelscope.utils.registry import default_group
+from weathon.utils.constants import Tasks,Fields,Datasets
+from weathon.registry.registry import default_group
+from weathon.utils.fileio import LocalStorage
+from weathon.utils.fileio.file_utils import get_default_cache_dir
+from weathon.utils.constants.metainfo import (Trainers, 
+                                              Models,
+                                              TaskModels,
+                                              Heads,
+                                              Preprocessors,
+                                              Metrics,
+                                              Pipelines,
+                                              CustomDatasets,
+                                              Hooks,
+                                              LR_Schedulers,
+                                              )
+
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 storage = LocalStorage()
 p = Path(__file__)
 
-# get the path of package 'modelscope'
+# get the path of package 'weathon'
 SKIP_FUNCTION_SCANNING = True
-MODELSCOPE_PATH = p.resolve().parents[1]
+WEATHON_PATH = p.resolve().parents[1]
 INDEXER_FILE_DIR = get_default_cache_dir()
 REGISTER_MODULE = 'register_module'
-IGNORED_PACKAGES = ['modelscope', '.']
+IGNORED_PACKAGES = ['weathon', '.']
 SCAN_SUB_FOLDERS = [
-    'models', 'metrics', 'pipelines', 'preprocessors', 'trainers',
-    'msdatasets', 'exporters'
+    'base','datasets','errors','exporters','hooks','inference','lrscheduler', 'models', 'metrics','optimizer',
+    'pipelines', 'preprocessors','registry','trainers', 'tuners', 'utils' 
 ]
 INDEXER_FILE = 'ast_indexer'
 DECORATOR_KEY = 'decorators'
 EXPRESS_KEY = 'express'
 FROM_IMPORT_KEY = 'from_imports'
 IMPORT_KEY = 'imports'
 FILE_NAME_KEY = 'filepath'
-MODELSCOPE_PATH_KEY = 'modelscope_path'
+WEATHON_PATH_KEY = 'weathon_path'
 VERSION_KEY = 'version'
 MD5_KEY = 'md5'
 INDEX_KEY = 'index'
 FILES_MTIME_KEY = 'files_mtime'
 REQUIREMENT_KEY = 'requirements'
 MODULE_KEY = 'module'
 CLASS_NAME = 'class_name'
@@ -113,18 +120,18 @@
         self.result_express = []
 
     def scan_ast(self, node: Union[ast.AST, None, str]):
         self._setup_global()
         self.scan_import(node, indent='  ', show_offsets=False)
 
     def scan_import(
-        self,
-        node: Union[ast.AST, None, str],
-        show_offsets: bool = True,
-        parent_node_name: str = '',
+            self,
+            node: Union[ast.AST, None, str],
+            show_offsets: bool = True,
+            parent_node_name: str = '',
     ) -> tuple:
         if node is None:
             return node
         elif self._is_leaf(node):
             return self._leaf(node, show_offsets=show_offsets)
         else:
 
@@ -196,18 +203,18 @@
                                 ]
 
                     if type(node).__name__ == 'Import':
                         final_dict = outputs[field]['alias']
                         if isinstance(final_dict, list):
                             for item in final_dict:
                                 self.result_import[item['alias']
-                                                   ['name']] = item['alias']
+                                ['name']] = item['alias']
                         else:
                             self.result_import[outputs[field]['alias']
-                                               ['name']] = final_dict
+                            ['name']] = final_dict
 
                 if 'decorator_list' == field and attr != []:
                     for item in attr:
                         setattr(item, CLASS_NAME, node.name)
                     self.result_decorator.extend(attr)
 
                 if attr != [] and type(
@@ -253,15 +260,15 @@
                     if type(attribute_node).__name__ == 'Str':
                         result.append((getattr(node,
                                                'arg'), attribute_node.s, None))
                     elif type(attribute_node).__name__ == 'Constant':
                         result.append(
                             (getattr(node, 'arg'), attribute_node.value, None))
                     else:
-                        result.append((getattr(node, 'arg'), )
+                        result.append((getattr(node, 'arg'),)
                                       + _get_attribute_item(attribute_node))
             return result
 
         functions = _get_attribute_item(node.func)
         args_list = _get_args_name(node.args)
         keyword_list = _get_keyword_name(node.keywords)
         return functions, args_list, keyword_list
@@ -381,15 +388,15 @@
                            current_path: str = None) -> str:
         """
         Args:
             import_package (str): relative import or abs import
             current_path (str): path/to/current/file
         """
         if import_package.startswith(IGNORED_PACKAGES[0]):
-            return MODELSCOPE_PATH + '/' + '/'.join(
+            return WEATHON_PATH + '/' + '/'.join(
                 import_package.split('.')[1:]) + '.py'
         elif import_package.startswith(IGNORED_PACKAGES[1]):
             current_path_list = current_path.split('/')
             import_package_list = import_package.split('.')
             level = 0
             for index, item in enumerate(import_package_list):
                 if item != '':
@@ -399,27 +406,27 @@
             abs_path_list = current_path_list[0:-level]
             abs_path_list.extend(import_package_list[index:])
             return '/' + '/'.join(abs_path_list) + '.py'
         else:
             return current_path
 
     def _traversal_import(
-        self,
-        import_abs_path,
+            self,
+            import_abs_path,
     ):
         pass
 
     def parse_import(self, scan_result: dict) -> list:
         """parse import and from import dicts to a third party package list
 
         Args:
             scan_result (dict): including the import and from import result
 
         Returns:
-            list: a list of package ignored 'modelscope' and relative path import
+            list: a list of package ignored 'weathon' and relative path import
         """
         output = []
         output.extend(list(scan_result[IMPORT_KEY].keys()))
         output.extend(list(scan_result[FROM_IMPORT_KEY].keys()))
 
         # get the package name
         for index, item in enumerate(output):
@@ -494,15 +501,15 @@
             del inverted_index[('OPTIMIZERS', 'default', 'name')]
         if ('LR_SCHEDULER', 'default', 'name') in inverted_index:
             del inverted_index[('LR_SCHEDULER', 'default', 'name')]
         return inverted_index
 
     def get_files_scan_results(self,
                                target_file_list=None,
-                               target_dir=MODELSCOPE_PATH,
+                               target_dir=WEATHON_PATH,
                                target_folders=SCAN_SUB_FOLDERS):
         """the entry method of the ast scan method
 
         Args:
             target_file_list can override the dir and folders combine
             target_dir (str, optional): the absolute path of the target directory to be scanned. Defaults to None.
             target_folder (list, optional): the list of
@@ -513,45 +520,41 @@
             dict: indexer of registry
         """
         start = time.time()
         if target_file_list is not None:
             self.file_dirs = target_file_list
         else:
             self.traversal_files(target_dir, target_folders)
-        logger.info(
-            f'AST-Scanning the path "{target_dir}" with the following sub folders {target_folders}'
-        )
+        logger.info(f'AST-Scanning the path "{target_dir}" with the following sub folders {target_folders}')
 
         result = dict()
         for file in self.file_dirs:
-            filepath = file[file.rfind('modelscope'):]
+            filepath = file[file.rfind('weathon'):]
             module_name = filepath.replace(osp.sep, '.').replace('.py', '')
-            decorator_list, import_list = self._get_single_file_scan_result(
-                file)
+            decorator_list, import_list = self._get_single_file_scan_result(file)
             result[file] = {
                 DECORATOR_KEY: decorator_list,
                 IMPORT_KEY: import_list,
                 MODULE_KEY: module_name
             }
         inverted_index_with_results = self._inverted_index(result)
-        inverted_index_with_results = self._ignore_useless_keys(
-            inverted_index_with_results)
+        inverted_index_with_results = self._ignore_useless_keys(inverted_index_with_results)
         module_import = self._module_import(result)
         index = {
             INDEX_KEY: inverted_index_with_results,
             REQUIREMENT_KEY: module_import
         }
         logger.info(
             f'Scanning done! A number of {len(inverted_index_with_results)} '
-            f'components indexed or updated! Time consumed {time.time()-start}s'
+            f'components indexed or updated! Time consumed {time.time() - start}s'
         )
         return index
 
     def files_mtime_md5(self,
-                        target_path=MODELSCOPE_PATH,
+                        target_path=WEATHON_PATH,
                         target_subfolder=SCAN_SUB_FOLDERS,
                         file_list=None):
         self.file_dirs = []
         if file_list and isinstance(file_list, list):
             self.file_dirs = file_list
         else:
             self.traversal_files(target_path, target_subfolder)
@@ -568,35 +571,35 @@
 
 file_scanner = FilesAstScanning()
 
 
 def _save_index(index, file_path, file_list=None, with_template=False):
     # convert tuple key to str key
     index[INDEX_KEY] = {str(k): v for k, v in index[INDEX_KEY].items()}
-    from modelscope.version import __version__
+    from weathon import __version__
     index[VERSION_KEY] = __version__
     index[MD5_KEY], index[FILES_MTIME_KEY] = file_scanner.files_mtime_md5(
         file_list=file_list)
-    index[MODELSCOPE_PATH_KEY] = MODELSCOPE_PATH.as_posix()
+    index[WEATHON_PATH_KEY] = WEATHON_PATH.as_posix()
     json_index = json.dumps(index)
     if with_template:
-        json_index = json_index.replace(MODELSCOPE_PATH.as_posix(),
+        json_index = json_index.replace(WEATHON_PATH.as_posix(),
                                         TEMPLATE_PATH)
     storage.write(json_index.encode(), file_path)
     index[INDEX_KEY] = {
         ast.literal_eval(k): v
         for k, v in index[INDEX_KEY].items()
     }
 
 
 def _load_index(file_path, with_template=False):
     bytes_index = storage.read(file_path)
     if with_template:
         bytes_index = bytes_index.decode().replace(TEMPLATE_PATH,
-                                                   MODELSCOPE_PATH.as_posix())
+                                                   WEATHON_PATH.as_posix())
     wrapped_index = json.loads(bytes_index)
     # convert str key to tuple key
     wrapped_index[INDEX_KEY] = {
         ast.literal_eval(k): v
         for k, v in wrapped_index[INDEX_KEY].items()
     }
     return wrapped_index
@@ -633,83 +636,81 @@
     # add new index
     updated_index = file_scanner.get_files_scan_results(updated_files)
     index[INDEX_KEY].update(updated_index[INDEX_KEY])
     index[REQUIREMENT_KEY].update(updated_index[REQUIREMENT_KEY])
 
 
 def load_index(
-    file_list=None,
-    force_rebuild=False,
-    indexer_file_dir=INDEXER_FILE_DIR,
-    indexer_file=INDEXER_FILE,
+        file_list=None,
+        force_rebuild=False,
+        indexer_file_dir=INDEXER_FILE_DIR,
+        indexer_file=INDEXER_FILE,
 ):
     """get the index from scan results or cache
 
     Args:
         file_list: load indexer only from the file lists if provided, default as None
         force_rebuild: If set true, rebuild and load index, default as False,
         indexer_file_dir: The dir where the indexer file saved, default as INDEXER_FILE_DIR
         indexer_file: The indexer file name, default as INDEXER_FILE
     Returns:
         dict: the index information for all registered modules, including key:
-        index, requirements, files last modified time, modelscope home path,
+        index, requirements, files last modified time, weathon home path,
         version and md5, the detail is shown below example: {
             'index': {
                 ('MODELS', 'nlp', 'bert'):{
                     'filepath' : 'path/to/the/registered/model', 'imports':
                     ['os', 'torch', 'typing'] 'module':
-                    'modelscope.models.nlp.bert'
+                    'weathon.models.nlp.bert'
                 },
                 ...
             }, 'requirements': {
-                'modelscope.models.nlp.bert': ['os', 'torch', 'typing'],
-                'modelscope.models.nlp.structbert': ['os', 'torch', 'typing'],
+                'weathon.models.nlp.bert': ['os', 'torch', 'typing'],
+                'weathon.models.nlp.structbert': ['os', 'torch', 'typing'],
                 ...
             }, 'files_mtime' : {
-                '/User/Path/To/Your/Modelscope/modelscope/preprocessors/nlp/text_generation_preprocessor.py':
+                '/User/Path/To/Your/Weathon/weathon/preprocessors/nlp/text_generation_preprocessor.py':
                 16554565445, ...
             },'version': '0.2.3', 'md5': '8616924970fe6bc119d1562832625612',
-            'modelscope_path': '/User/Path/To/Your/Modelscope'
+            'weathon_path': '/User/Path/To/Your/Weathon'
         }
     """
     # env variable override
-    cache_dir = os.getenv('MODELSCOPE_CACHE', indexer_file_dir)
-    index_file = os.getenv('MODELSCOPE_INDEX_FILE', indexer_file)
+    cache_dir = os.getenv('WEATHON_CACHE', indexer_file_dir)
+    index_file = os.getenv('WEATHON_INDEX_FILE', indexer_file)
     file_path = os.path.join(cache_dir, index_file)
     logger.info(f'Loading ast index from {file_path}')
     index = None
     local_changed = False
     if not force_rebuild and os.path.exists(file_path):
         wrapped_index = _load_index(file_path)
         md5, files_mtime = file_scanner.files_mtime_md5(file_list=file_list)
-        from modelscope.version import __version__
+        from weathon import __version__
         if (wrapped_index[VERSION_KEY] == __version__):
             index = wrapped_index
             if (wrapped_index[MD5_KEY] != md5):
                 local_changed = True
     full_index_flag = False
 
     if index is None:
         full_index_flag = True
     elif index and local_changed and FILES_MTIME_KEY not in index:
         full_index_flag = True
-    elif index and local_changed and MODELSCOPE_PATH_KEY not in index:
+    elif index and local_changed and WEATHON_PATH_KEY not in index:
         full_index_flag = True
     elif index and local_changed and index[
-            MODELSCOPE_PATH_KEY] != MODELSCOPE_PATH.as_posix():
+        WEATHON_PATH_KEY] != WEATHON_PATH.as_posix():
         full_index_flag = True
 
     if full_index_flag:
         if force_rebuild:
             logger.info('Force rebuilding ast index from scanning every file!')
             index = file_scanner.get_files_scan_results(file_list)
         else:
-            logger.info(
-                f'No valid ast index found from {file_path}, generating ast index from prebuilt!'
-            )
+            logger.info(f'No valid ast index found from {file_path}, generating ast index from prebuilt!')
             index = load_from_prebuilt()
             if index is None:
                 index = file_scanner.get_files_scan_results(file_list)
         _save_index(index, file_path, file_list)
     elif local_changed and not full_index_flag:
         logger.info(
             'Updating the files for the changes of local files, '
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/audio/audio_utils.py` & `weathon-0.0.0.14/weathon/utils/audio/audio_utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,23 +1,20 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import re
-import shutil
 import struct
 import sys
 import tempfile
 from typing import Union
 from urllib.parse import urlparse
 
 import numpy as np
 
-from modelscope.fileio.file import HTTPStorage
-from modelscope.hub.utils.utils import get_cache_dir
-from modelscope.utils.hub import snapshot_download
-from modelscope.utils.logger import get_logger
+from weathon.utils.fileio.file import HTTPStorage
+from weathon.utils.hub.utils import get_cache_dir, snapshot_download
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 SEGMENT_LENGTH_TRAIN = 16000
 SUPPORT_AUDIO_TYPE_SETS = ('.flac', '.mp3', '.ogg', '.opus', '.wav', '.pcm')
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/audio/tts_exceptions.py` & `weathon-0.0.0.14/weathon/utils/audio/tts_exceptions.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 """
 Define TTS exceptions
 """
 
 
 class TtsException(Exception):
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/checkpoint.py` & `weathon-0.0.0.14/weathon/utils/checkpoint.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import io
 import os
 import re
 import time
 from collections import OrderedDict
 from shutil import copytree, ignore_patterns, rmtree
 from typing import Callable, Dict, Optional, Union
 
 import json
 import torch
 from torch import nn
 from torch.optim import Optimizer
-from torch.optim.lr_scheduler import _LRScheduler
+from torch.optim.lr_scheduler import LRScheduler
 
-from modelscope.fileio import File, LocalStorage
-from modelscope.utils.config import Config, JSONIteratorEncoder
-from modelscope.utils.constant import ConfigFields, ModelFile
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import is_master
+from weathon.utils.constants import ConfigFields, ModelFile
+from weathon.utils.fileio import LocalStorage, File
+from weathon.utils.fileio.format.json_utils import JSONIteratorEncoder
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import is_master
 
 logger = get_logger()
 
 storage = LocalStorage()
 
 
 def weights_to_cpu(state_dict):
@@ -41,15 +39,15 @@
     state_dict_cpu._metadata = getattr(state_dict, '_metadata', OrderedDict())
     return state_dict_cpu
 
 
 def save_checkpoint(model: torch.nn.Module,
                     filename: str,
                     optimizer: Optional[Optimizer] = None,
-                    lr_scheduler: Optional[_LRScheduler] = None,
+                    lr_scheduler: Optional[LRScheduler] = None,
                     meta: Optional[dict] = None,
                     with_meta: bool = True,
                     with_model: bool = True) -> None:
     """Save checkpoint to file.
 
     The checkpoint will have 3 fields: ``meta``, ``state_dict`` and
     ``optimizer``. By default, ``meta`` will contain version and time info.
@@ -70,15 +68,15 @@
 
     if with_meta:
         if meta is None:
             meta = {}
         elif not isinstance(meta, dict):
             raise TypeError(
                 f'meta must be a dict or None, but got {type(meta)}')
-        from modelscope import __version__
+        from weathon import __version__
         meta.update(modelscope=__version__, time=time.asctime())
 
         if isinstance(model, torch.nn.parallel.DistributedDataParallel):
             model = model.module
 
         if hasattr(model, 'CLASSES') and model.CLASSES is not None:
             # save class name to the meta
@@ -112,15 +110,15 @@
         torch.save(checkpoint, f)
         File.write(f.getvalue(), filename)
 
 
 def load_checkpoint(filename,
                     model,
                     optimizer: Optimizer = None,
-                    lr_scheduler: _LRScheduler = None):
+                    lr_scheduler: LRScheduler = None):
     if not os.path.exists(filename):
         raise ValueError(f'Checkpoint file {filename} does not exist!')
     checkpoint = torch.load(filename, map_location='cpu')
 
     if optimizer is not None:
         if 'optimizer' in checkpoint:
             if isinstance(optimizer, Optimizer):
@@ -566,14 +564,15 @@
         'unexpected_keys': unexpected_keys,
         'mismatched_keys': mismatched_keys,
         'error_msgs': error_msgs,
     }
 
 
 def save_configuration(target_folder, config: Dict):
+    from weathon.utils.config.config import Config
     if isinstance(config, Config):
         config = config.to_dict()
     if ConfigFields.pipeline not in config:
         config[ConfigFields.pipeline] = {'type': config[ConfigFields.task]}
     cfg_str = json.dumps(config, indent=4, cls=JSONIteratorEncoder)
     config_file = os.path.join(target_folder, ModelFile.CONFIGURATION)
     storage.write(cfg_str.encode(), config_file)
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/chinese_utils.py` & `weathon-0.0.0.14/weathon/utils/chinese_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import re
 import string
 
 CHINESE_PUNCTUATION = '\u3000'
 ENGLISH_PUNCTUATION = string.punctuation
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/config.py` & `weathon-0.0.0.14/weathon/utils/config/config.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,24 +7,20 @@
 import os.path as osp
 import platform
 import shutil
 import sys
 import tempfile
 import types
 from pathlib import Path
-from types import FunctionType
 from typing import Dict, Union
 
 import addict
-import json
 from yapf.yapflib.yapf_api import FormatCode
 
-from modelscope.utils.constant import ConfigFields, ModelFile
-from modelscope.utils.import_utils import import_modules_from_file
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 BASE_KEY = '_base_'
 DELETE_KEY = '_delete_'
 DEPRECATION_KEY = '_deprecation_'
 RESERVED_KEYS = ['filename', 'text', 'pretty_text']
@@ -97,27 +93,28 @@
                 dir=tmp_cfg_dir, suffix=fileExtname)
             if platform.system() == 'Windows':
                 tmp_cfg_file.close()
             tmp_cfg_name = osp.basename(tmp_cfg_file.name)
             shutil.copyfile(filename, tmp_cfg_file.name)
 
             if filename.endswith('.py'):
+                from weathon.utils.import_utils import import_modules_from_file
                 module_nanme, mod = import_modules_from_file(
                     osp.join(tmp_cfg_dir, tmp_cfg_name))
                 cfg_dict = {}
                 for name, value in mod.__dict__.items():
                     if not name.startswith('__') and \
                        not isinstance(value, types.ModuleType) and \
                        not isinstance(value, types.FunctionType):
                         cfg_dict[name] = value
 
                 # delete imported module
                 del sys.modules[module_nanme]
             elif filename.endswith(('.yml', '.yaml', '.json')):
-                from modelscope.fileio import load
+                from weathon.utils.fileio import load
                 cfg_dict = load(tmp_cfg_file.name)
             # close temp file
             tmp_cfg_file.close()
 
         cfg_text = filename + '\n'
         with open(filename, 'r', encoding='utf-8') as f:
             # Setting encoding explicitly to resolve coding issue on windows
@@ -397,15 +394,15 @@
             >>> dump_file = "a.py"
             >>> cfg.dump(dump_file)
 
         Args:
             file (str, optional): Path of the output file where the config
                 will be dumped. Defaults to None.
         """
-        from modelscope.fileio import dump
+        from weathon.utils.fileio import dump
         cfg_dict = super(Config, self).__getattribute__('_cfg_dict').to_dict()
         if file is None:
             if self.filename is None or self.filename.endswith('.py'):
                 return self.pretty_text
             else:
                 file_format = self.filename.split('.')[-1]
                 return dump(cfg_dict, file_format=file_format)
@@ -418,50 +415,42 @@
 
     def merge_from_dict(self, options, allow_list_keys=True, force=True):
         """Merge dict into cfg_dict.
 
         Merge the dict parsed by MultipleKVAction into this cfg.
 
         Examples:
-            >>> options = {'model.backbone.depth': 50,
-            ...            'model.backbone.with_cp':True}
+            >>> options = {'model.backbone.depth': 50, 'model.backbone.with_cp':True}
             >>> cfg = Config(dict(model=dict(backbone=dict(type='ResNet'))))
             >>> cfg.merge_from_dict(options)
             >>> cfg_dict = super(Config, self).__getattribute__('_cfg_dict')
-            >>> assert cfg_dict == dict(
-            ...     model=dict(backbone=dict(type='ResNet', depth=50, with_cp=True)))
+            >>> assert cfg_dict == dict(model=dict(backbone=dict(type='ResNet', depth=50, with_cp=True)))
 
             >>> # Merge list element for replace target index
-            >>> cfg = Config(dict(pipeline=[
-            ...     dict(type='Resize'), dict(type='RandomDistortion')]))
+            >>> cfg = Config(dict(pipeline=[dict(type='Resize'), dict(type='RandomDistortion')]))
             >>> options = dict(pipeline={'0': dict(type='MyResize')})
             >>> cfg.merge_from_dict(options, allow_list_keys=True)
             >>> cfg_dict = super(Config, self).__getattribute__('_cfg_dict')
-            >>> assert cfg_dict == dict(pipeline=[
-            ...     dict(type='MyResize'), dict(type='RandomDistortion')])
+            >>> assert cfg_dict == dict(pipeline=[dict(type='MyResize'), dict(type='RandomDistortion')])
 
             >>> # Merge list element for replace args and add to list, only support list of type dict with key ``type``,
             >>> # if you add new list element, the list does not guarantee the order,
             >>> # it is only suitable for the case where the order of the list is not concerned.
-            >>> cfg = Config(dict(pipeline=[
-            ...     dict(type='Resize', size=224), dict(type='RandomDistortion')]))
+            >>> cfg = Config(dict(pipeline=[dict(type='Resize', size=224), dict(type='RandomDistortion')]))
             >>> options = dict(pipeline=[dict(type='Resize', size=256), dict(type='RandomFlip')])
             >>> cfg.merge_from_dict(options, allow_list_keys=True)
             >>> cfg_dict = super(Config, self).__getattribute__('_cfg_dict')
-            >>> assert cfg_dict == dict(pipeline=[
-            ...     dict(type='Resize', size=256), dict(type='RandomDistortion'), dict(type='RandomFlip')])
+            >>> assert cfg_dict == dict(pipeline=[dict(type='Resize', size=256), dict(type='RandomDistortion'), dict(type='RandomFlip')])
 
             >>> # force usage
-            >>> options = {'model.backbone.depth': 18,
-            ...            'model.backbone.with_cp':True}
+            >>> options = {'model.backbone.depth': 18, 'model.backbone.with_cp':True}
             >>> cfg = Config(dict(model=dict(backbone=dict(type='ResNet', depth=50))))
             >>> cfg.merge_from_dict(options, force=False)
             >>> cfg_dict = super(Config, self).__getattribute__('_cfg_dict')
-            >>> assert cfg_dict == dict(
-            ...     model=dict(backbone=dict(type='ResNet', depth=50, with_cp=True)))
+            >>> assert cfg_dict == dict(model=dict(backbone=dict(type='ResNet', depth=50, with_cp=True)))
 
         Args:
             options (dict): dict of configs to merge from.
             allow_list_keys (bool): If True, int string keys (e.g. '0', '1')
               are allowed in ``options`` and will replace the element of the
               corresponding index in the config if the config is a list.
               Or you can directly replace args for list or add new list element,
@@ -479,21 +468,15 @@
             for subkey in key_list[:-1]:
                 d.setdefault(subkey, ConfigDict())
                 d = d[subkey]
             subkey = key_list[-1]
             d[subkey] = v
 
         cfg_dict = super(Config, self).__getattribute__('_cfg_dict')
-        super(Config, self).__setattr__(
-            '_cfg_dict',
-            Config._merge_a_into_b(
-                option_cfg_dict,
-                cfg_dict,
-                allow_list_keys=allow_list_keys,
-                force=force))
+        super(Config, self).__setattr__('_cfg_dict', Config._merge_a_into_b(option_cfg_dict, cfg_dict, allow_list_keys=allow_list_keys, force=force))
 
     @staticmethod
     def _merge_a_into_b(a, b, allow_list_keys=False, force=True):
         """merge dict ``a`` into dict ``b`` (non-inplace).
 
         Values in ``a`` will overwrite ``b``. ``b`` is copied first to avoid
         in-place modifications.
@@ -569,39 +552,28 @@
                                         a_lj,
                                         b_li,
                                         allow_list_keys,
                                         force=force))
                                 added_index_v.append(j)
                                 added_index_bk.append(i)
                                 break
-                    rest_bk = [
-                        b[k][i] for i in range(len(b[k]))
-                        if i not in added_index_bk
-                    ]
-                    rest_v = [
-                        v[i] for i in range(len(v)) if i not in added_index_v
-                    ]
+                    rest_bk = [ b[k][i] for i in range(len(b[k])) if i not in added_index_bk  ]
+                    rest_v = [ v[i] for i in range(len(v)) if i not in added_index_v ]
                     rest = rest_bk + rest_v
-                    res_list += [
-                        Config._merge_a_into_b(
-                            rest[i], {}, allow_list_keys, force=force)
-                        for i in range(len(rest))
-                    ]
+                    res_list += [ Config._merge_a_into_b( rest[i], {}, allow_list_keys, force=force) for i in range(len(rest)) ]
                     b[k] = res_list
-            elif isinstance(v,
-                            dict) and k in b and not v.pop(DELETE_KEY, False):
+            elif isinstance(v, dict) and k in b and not v.pop(DELETE_KEY, False):
                 allowed_types = (dict, list) if allow_list_keys else dict
                 if not isinstance(b[k], allowed_types):
                     raise TypeError(
                         f'{k}={v} in child config cannot inherit from base '
                         f'because {k} is a dict in the child config but is of '
                         f'type {type(b[k])} in base config. You may set '
                         f'`{DELETE_KEY}=True` to ignore the base config')
-                b[k] = Config._merge_a_into_b(
-                    v, b[k], allow_list_keys, force=force)
+                b[k] = Config._merge_a_into_b( v, b[k], allow_list_keys, force=force)
             else:
                 if k not in b or force:
                     b[k] = v
         return b
 
     def to_dict(self) -> Dict:
         """ Convert Config object to python dict
@@ -646,50 +618,10 @@
                     'type in config file which supported to be '
                     'converted to args should be either bool, '
                     f'int, str, float or list of them but got type {v}')
 
         return parse_fn(args)
 
 
-def check_config(cfg: Union[str, ConfigDict], is_training=False):
-    """ Check whether configuration file is valid, If anything wrong, exception will be raised.
-
-    Args:
-        cfg (str or ConfigDict): Config file path or config object.
-        is_training: indicate if checking training related elements
-    """
-
-    if isinstance(cfg, str):
-        cfg = Config.from_file(cfg)
 
-    def check_attr(attr_name, msg=''):
-        assert hasattr(cfg, attr_name), f'Attribute {attr_name} is missing from ' \
-            f'{ModelFile.CONFIGURATION}. {msg}'
-
-    check_attr(ConfigFields.framework)
-    check_attr(ConfigFields.task)
-    check_attr(ConfigFields.pipeline)
-
-    if is_training:
-        check_attr(ConfigFields.model)
-        check_attr(ConfigFields.train)
-        check_attr(ConfigFields.preprocessor)
-        check_attr(ConfigFields.evaluation)
-
-
-class JSONIteratorEncoder(json.JSONEncoder):
-    """Implement this method in order that supporting arbitrary iterators, it returns
-        a serializable object for ``obj``, or calls the base implementation
-        (to raise a ``TypeError``).
 
-    """
 
-    def default(self, obj):
-        if isinstance(obj, FunctionType):
-            return None
-        try:
-            iterable = iter(obj)
-        except TypeError:
-            pass
-        else:
-            return list(iterable)
-        return json.JSONEncoder.default(self, obj)
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/config_ds.py` & `weathon-0.0.0.14/weathon/utils/constants/dataset_constant.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,26 +1,22 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 from pathlib import Path
 
 # Cache location
-from modelscope.hub.constants import DEFAULT_MODELSCOPE_DATA_ENDPOINT
+
+MODELSCOPE_URL_SCHEME = 'http://'
+DEFAULT_MODELSCOPE_DOMAIN = 'www.modelscope.cn'
+DEFAULT_MODELSCOPE_DATA_ENDPOINT = MODELSCOPE_URL_SCHEME + DEFAULT_MODELSCOPE_DOMAIN
 
 DEFAULT_CACHE_HOME = Path.home().joinpath('.cache')
 CACHE_HOME = os.getenv('CACHE_HOME', DEFAULT_CACHE_HOME)
-DEFAULT_MS_CACHE_HOME = os.path.join(CACHE_HOME, 'modelscope', 'hub')
-MS_CACHE_HOME = os.path.expanduser(
-    os.getenv('MS_CACHE_HOME', DEFAULT_MS_CACHE_HOME))
+DEFAULT_MS_CACHE_HOME = os.path.join(CACHE_HOME, 'weathon', 'hub')
+MS_CACHE_HOME = os.path.expanduser(os.getenv('MS_CACHE_HOME', DEFAULT_MS_CACHE_HOME))
 
 DEFAULT_MS_DATASETS_CACHE = os.path.join(MS_CACHE_HOME, 'datasets')
-MS_DATASETS_CACHE = Path(
-    os.getenv('MS_DATASETS_CACHE', DEFAULT_MS_DATASETS_CACHE))
+MS_DATASETS_CACHE = Path(os.getenv('MS_DATASETS_CACHE', DEFAULT_MS_DATASETS_CACHE))
 
 DOWNLOADED_DATASETS_DIR = 'downloads'
-DEFAULT_DOWNLOADED_DATASETS_PATH = os.path.join(MS_DATASETS_CACHE,
-                                                DOWNLOADED_DATASETS_DIR)
-DOWNLOADED_DATASETS_PATH = Path(
-    os.getenv('DOWNLOADED_DATASETS_PATH', DEFAULT_DOWNLOADED_DATASETS_PATH))
+DEFAULT_DOWNLOADED_DATASETS_PATH = os.path.join(MS_DATASETS_CACHE,DOWNLOADED_DATASETS_DIR)
+DOWNLOADED_DATASETS_PATH = Path(os.getenv('DOWNLOADED_DATASETS_PATH', DEFAULT_DOWNLOADED_DATASETS_PATH))
 
-HUB_DATASET_ENDPOINT = os.environ.get('HUB_DATASET_ENDPOINT',
-                                      DEFAULT_MODELSCOPE_DATA_ENDPOINT)
+HUB_DATASET_ENDPOINT = os.environ.get('HUB_DATASET_ENDPOINT',DEFAULT_MODELSCOPE_DATA_ENDPOINT)
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/constant.py` & `weathon-0.0.0.14/weathon/utils/constants/hub_constant.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import enum
 
 
 class Fields(object):
     """ Names for different application fields
     """
     cv = 'cv'
     nlp = 'nlp'
     audio = 'audio'
     multi_modal = 'multi-modal'
     science = 'science'
 
 
+
 class CVTasks(object):
     # ocr
     ocr_detection = 'ocr-detection'
     ocr_recognition = 'ocr-recognition'
     table_recognition = 'table-recognition'
     lineless_table_recognition = 'lineless-table-recognition'
     license_plate_detection = 'license-plate-detection'
@@ -373,14 +373,15 @@
     DatasetFormations.native: ['.json'],
     DatasetFormations.hf_compatible: ['.py'],
 }
 
 
 class ModelFile(object):
     CONFIGURATION = 'configuration.json'
+    CONFIGURATION_YAML = 'configuration.yaml'
     README = 'README.md'
     TF_SAVED_MODEL_FILE = 'saved_model.pb'
     TF_GRAPH_FILE = 'tf_graph.pb'
     TF_CHECKPOINT_FOLDER = 'tf_ckpts'
     TF_CKPT_PREFIX = 'ckpt-'
     TORCH_MODEL_FILE = 'pytorch_model.pt'
     TORCH_MODEL_BIN_FILE = 'pytorch_model.bin'
@@ -458,14 +459,15 @@
 DEFAULT_DATASET_NAMESPACE = 'modelscope'
 DEFAULT_DATA_ACCELERATION_ENDPOINT = 'https://oss-accelerate.aliyuncs.com'
 
 
 class ModeKeys:
     TRAIN = 'train'
     EVAL = 'eval'
+    VALID = 'valid'
     INFERENCE = 'inference'
 
 
 class LogKeys:
     ITER = 'iter'
     ITER_TIME = 'iter_time'
     EPOCH = 'epoch'
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/cv/image_utils.py` & `weathon-0.0.0.14/weathon/utils/cv/image_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 
 import cv2
 import matplotlib
 import matplotlib.cm as cm
 import matplotlib.pyplot as plt
 import numpy as np
 from PIL import Image
 
-from modelscope.outputs import OutputKeys
-from modelscope.preprocessors.image import load_image
-from modelscope.utils import logger as logging
+from weathon.preprocessors.image import load_image
+from weathon.utils import logger as logging
+from weathon.utils.constants.output_constant import OutputKeys
 
 logger = logging.get_logger()
 
 
 def numpy_to_cv2img(img_array):
     """to convert a np.array with shape(h, w) to cv2 img
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/cv/motion_utils/motion_process.py` & `weathon-0.0.0.14/weathon/utils/cv/motion_utils/motion_process.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/utils/cv/motion_utils/plot_script.py` & `weathon-0.0.0.14/weathon/utils/cv/motion_utils/plot_script.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/utils/cv/motion_utils/rotation_conversions.py` & `weathon-0.0.0.14/weathon/utils/cv/motion_utils/rotation_conversions.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/utils/data_collators.py` & `weathon-0.0.0.14/weathon/utils/data_collators.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Part of the implementation is borrowed from huggingface/transformers.
 
 from collections import OrderedDict
 from collections.abc import Mapping
 from typing import Any, List, Optional, Tuple
 
 from .logger import get_logger
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/data_utils.py` & `weathon-0.0.0.14/weathon/utils/data_utils.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from collections.abc import Mapping
 
 import torch
 
-from modelscope.outputs import ModelOutputBase
+from weathon.base import BaseModelOutput
 
 
 def to_device(batch, device, non_blocking=False):
     """Put the data to the target cuda device just before the forward function.
     Args:
         batch: The batch data out of the dataloader.
         device: (str | torch.device): The target device for the data.
 
     Returns: The data to the target device.
 
     """
-    if isinstance(batch, ModelOutputBase):
+    if isinstance(batch, BaseModelOutput):
         for idx in range(len(batch)):
             batch[idx] = to_device(batch[idx], device)
         return batch
     elif isinstance(batch, dict) or isinstance(batch, Mapping):
         if hasattr(batch, '__setitem__'):
             # Reuse mini-batch to keep attributes for prediction.
             for k, v in batch.items():
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/device.py` & `weathon-0.0.0.14/weathon/utils/device.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 from contextlib import contextmanager
 
-from modelscope.utils.constant import Devices, Frameworks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants import Devices, Frameworks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def verify_device(device_name):
     """ Verify device is valid, device should be either cpu, cuda, gpu, cuda:X or gpu:X.
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/error.py` & `weathon-0.0.0.14/weathon/errors/error.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 # docstyle-ignore
 AUDIO_IMPORT_ERROR = """
 Audio model import failed: {0}, if you want to use audio related function, please execute
 `pip install modelscope[audio] -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html`
 """
 
 # docstyle-ignore
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/file_utils.py` & `weathon-0.0.0.14/weathon/utils/fileio/file_utils.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import inspect
 from pathlib import Path
 
 
 # TODO: remove this api, unify to flattened args
 def func_receive_dict_inputs(func):
     """to decide if a func could recieve dict inputs or not
@@ -29,15 +27,15 @@
     return False
 
 
 def get_default_cache_dir():
     """
     default base dir: '~/.cache/modelscope'
     """
-    default_cache_dir = Path.home().joinpath('.cache', 'modelscope')
+    default_cache_dir = Path.home().joinpath('.cache', 'weathon')
     return default_cache_dir
 
 
 def read_file(path):
 
     with open(path, 'r') as f:
         text = f.read()
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/import_utils.py` & `weathon-0.0.0.14/weathon/utils/import_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Part of the implementation is borrowed from huggingface/transformers.
 import ast
 import functools
 import importlib
 import os
 import os.path as osp
 import sys
@@ -11,18 +10,17 @@
 from itertools import chain
 from pathlib import Path
 from types import ModuleType
 from typing import Any
 
 from packaging import version
 
-from modelscope.utils.ast_utils import (INDEX_KEY, MODULE_KEY, REQUIREMENT_KEY,
-                                        load_index)
-from modelscope.utils.error import *  # noqa
-from modelscope.utils.logger import get_logger
+from weathon.utils.ast_utils import (INDEX_KEY, MODULE_KEY, REQUIREMENT_KEY, load_index)
+from weathon.errors.error import *  # noqa
+from weathon.utils.logger import get_logger
 
 if sys.version_info < (3, 8):
     import importlib_metadata
 else:
     import importlib.metadata as importlib_metadata
 
 logger = get_logger()
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/input_output.py` & `weathon-0.0.0.14/weathon/utils/input_output.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,30 +1,25 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import ast
 import base64
 import importlib
 import inspect
 from io import BytesIO
 from typing import Any
 from urllib.parse import urlparse
 
 import numpy as np
 
-from modelscope.hub.api import HubApi
-from modelscope.hub.errors import NotExistError
-from modelscope.hub.file_download import model_file_download
-from modelscope.outputs.outputs import (TASK_OUTPUTS, OutputKeys, OutputTypes,
-                                        OutputTypeSchema)
-from modelscope.pipeline_inputs import (INPUT_TYPE, INPUT_TYPE_SCHEMA,
-                                        TASK_INPUTS, InputType)
-from modelscope.pipelines import pipeline
-from modelscope.pipelines.base import Pipeline
-from modelscope.utils.config import Config
-from modelscope.utils.constant import ModelFile, Tasks
-from modelscope.utils.logger import get_logger
+from weathon.utils.constants.output_constant import TASK_OUTPUTS, OutputTypeSchema, OutputTypes, OutputKeys
+from weathon.utils.hub.file_download import model_file_download
+from weathon.utils.constants.pipeline_inputs import (INPUT_TYPE, INPUT_TYPE_SCHEMA, TASK_INPUTS, InputType)
+from weathon.pipelines import pipeline
+from weathon.base import BasePipeline
+from weathon.utils.config.config import Config
+from weathon.utils.constants import ModelFile, Tasks
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 """Support webservice integration pipeline
 
 This module provides a support library when webservice uses pipeline,
 converts webservice input into pipeline input, and converts pipeline
 output into webservice output, which automatically encodes and
@@ -405,15 +400,15 @@
         prop = {'type': meta_type_schema_map[param_type]}
         if has_default:
             prop['default'] = default_value
         parameters_schema['properties'][name] = prop
     return parameters_schema
 
 
-def get_pipeline_information_by_pipeline(pipeline: Pipeline, ):
+def get_pipeline_information_by_pipeline(pipeline: BasePipeline, ):
     """Get pipeline input output schema.
 
     Args:
         pipeline (Pipeline): The pipeline object.
     """
     task_name = pipeline.group_key
     pipeline_class = pipeline.__class__.__name__
@@ -580,15 +575,15 @@
     InputType.DICT: return_origin,
     InputType.LIST: return_origin,
     InputType.NUMBER: return_origin,
 }
 
 
 def call_pipeline_with_json(pipeline_info: PipelineInfomation,
-                            pipeline: Pipeline, body: str):
+                            pipeline: BasePipeline, body: str):
     """Call pipeline with json input.
 
     Args:
         pipeline_info (PipelineInfomation): The pipeline information object.
         pipeline (Pipeline): The pipeline object.
         body (Dict): The input object, include input and parameters
     """
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/logger.py` & `weathon-0.0.0.14/weathon/utils/logger/logger.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,30 +1,24 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import importlib
 import logging
 from typing import Optional
 
 init_loggers = {}
 
 formatter = logging.Formatter(
     '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
 
 
-def get_logger(log_file: Optional[str] = None,
-               log_level: int = logging.INFO,
-               file_mode: str = 'w'):
+def get_logger(log_file: Optional[str] = None, log_level: int = logging.INFO, file_mode: str = 'w'):
     """ Get logging logger
 
     Args:
-        log_file: Log filename, if specified, file handler will be added to
-            logger
+        log_file: ,,logger.
         log_level: Logging level.
-        file_mode: Specifies the mode to open the file, if filename is
-            specified (if filemode is unspecified, it defaults to 'w').
+        file_mode: "log_file",,"w".
     """
 
     logger_name = __name__.split('.')[0]
     logger = logging.getLogger(logger_name)
 
     if logger_name in init_loggers:
         add_file_handler_if_needed(logger, log_file, file_mode, log_level)
@@ -41,15 +35,15 @@
         if type(handler) is logging.StreamHandler:
             handler.setLevel(logging.ERROR)
 
     stream_handler = logging.StreamHandler()
     handlers = [stream_handler]
 
     if importlib.util.find_spec('torch') is not None:
-        from modelscope.utils.torch_utils import is_master
+        from weathon.utils.torch_utils import is_master
         is_worker0 = is_master()
     else:
         is_worker0 = True
 
     if is_worker0 and log_file is not None:
         file_handler = logging.FileHandler(log_file, file_mode)
         handlers.append(file_handler)
@@ -71,15 +65,15 @@
 
 def add_file_handler_if_needed(logger, log_file, file_mode, log_level):
     for handler in logger.handlers:
         if isinstance(handler, logging.FileHandler):
             return
 
     if importlib.util.find_spec('torch') is not None:
-        from modelscope.utils.torch_utils import is_master
+        from weathon.utils.torch_utils import is_master
         is_worker0 = is_master()
     else:
         is_worker0 = True
 
     if is_worker0 and log_file is not None:
         file_handler = logging.FileHandler(log_file, file_mode)
         file_handler.setFormatter(formatter)
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/megatron_utils.py` & `weathon-0.0.0.14/weathon/utils/megatron_utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 import os
 import shutil
 from typing import Dict, List, Union
 
 import torch
 from torch import nn
 
-from modelscope.utils.logger import get_logger
-from modelscope.utils.torch_utils import is_master
+from weathon.utils.logger import get_logger
+from weathon.utils.torch_utils import is_master
 
 logger = get_logger()
 
 _DEFAULT_CFG_WITH_MODEL_TYPE = {
     'gpt-moe': {
         'version': 'moe',
         'world_size': 8
@@ -39,15 +38,15 @@
     If argument `megatron_cfg` is not specified, then the megatorn_cfg will be load
     from configuration.json file in the model_dir.
 
     Args:
         megatron_cfg (Dict, optional): Megatron Config will be send to megatron_util.
         model_dir (str, optional): The model path for configuration. Defaults to None.
     """
-    from modelscope.utils.hub import read_config
+    from weathon.utils.hub.utils import read_config
     from megatron_util import initialize_megatron
 
     assert not (megatron_cfg is None and model_dir is None), \
         'cfg and model_dir cannot both be None when initializing megatron_util'
     if megatron_cfg is None:
         cfg = read_config(model_dir)
         try:
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/metric.py` & `weathon-0.0.0.14/weathon/utils/metric.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/utils/model_tag.py` & `weathon-0.0.0.14/weathon/utils/model_tag.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import logging
 import os
 
 import json
 import requests
 
-from modelscope.version import __version__
+from weathon import __version__
 
 
 # 
 class ModelTag(object):
     _URL = os.environ.get('MODEL_TAG_URL', None)
 
     # 
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/distributed.py` & `weathon-0.0.0.14/weathon/utils/nlp/distributed.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/load_checkpoint.py` & `weathon-0.0.0.14/weathon/utils/nlp/load_checkpoint.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/space/args.py` & `weathon-0.0.0.14/weathon/utils/nlp/space/args.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import argparse
 
 import json
 
 
 def str2bool(v):
     if v.lower() in ('yes', 'true', 't', 'y', '1'):
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/space/clean_dataset.py` & `weathon-0.0.0.14/weathon/utils/nlp/space/clean_dataset.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import re
 
 from . import ontology
 
 
 def clean_text_split_dot(text):
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/space/criterions.py` & `weathon-0.0.0.14/weathon/utils/nlp/space/criterions.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import torch
 import torch.nn.functional as F
 from torch.nn.modules.loss import _Loss
 
 
 def compute_kl_loss(p, q, filter_scores=None):
     p_loss = F.kl_div(
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/space/db_ops.py` & `weathon-0.0.0.14/weathon/utils/nlp/space/db_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import os
 import random
 import sqlite3
 
 import json
 
 from .ontology import all_domains, db_domains
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/space/ontology.py` & `weathon-0.0.0.14/weathon/utils/nlp/space/ontology.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 all_domains = [
     'restaurant', 'hotel', 'attraction', 'train', 'taxi', 'police', 'hospital'
 ]
 all_domains_with_bracket = ['[{}]'.format(item) for item in all_domains]
 db_domains = ['restaurant', 'hotel', 'attraction', 'train']
 placeholder_tokens = [
     '<go_r>', '<go_b>', '<go_a>', '<go_d>', '<eos_u>', '<eos_r>', '<eos_b>',
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/space/utils.py` & `weathon-0.0.0.14/weathon/utils/nlp/space/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import logging
 from collections import OrderedDict
 
 import json
 import numpy as np
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 from . import ontology
 
 logger = get_logger()
 
 
 def max_lens(X):
     lens = [len(X)]
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/space/utils_dst.py` & `weathon-0.0.0.14/weathon/utils/nlp/space/utils_dst.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,12 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 from typing import List
 
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.nlp import DialogStateTrackingPipeline
+from weathon.pipelines.nlp import DialogStateTrackingPipeline
+from weathon.utils.constants.output_constant import OutputKeys
 
 
 def tracking_and_print_dialog_states(
         test_case, pipelines: List[DialogStateTrackingPipeline]):
     import json
     pipelines_len = len(pipelines)
     history_states = [{}]
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/space_T_en/utils.py` & `weathon-0.0.0.14/weathon/utils/nlp/space_T_en/utils.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from typing import List
 
-from modelscope.outputs import OutputKeys
-from modelscope.pipelines.nlp import ConversationalTextToSqlPipeline
+from weathon.pipelines.nlp import ConversationalTextToSqlPipeline
+from weathon.utils.constants.output_constant import OutputKeys
 
 
 def text2sql_tracking_and_print_results(
         test_case, pipelines: List[ConversationalTextToSqlPipeline]):
     for p in pipelines:
         last_sql, history = '', []
         for item in test_case['utterance']:
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/nlp/utils.py` & `weathon-0.0.0.14/weathon/utils/nlp/utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 import os.path as osp
 
-from modelscope.utils.hub import parse_label_mapping
+from weathon.utils.hub.utils import parse_label_mapping
 
 
 def import_external_nltk_data(nltk_data_dir, package_name):
     """import external nltk_data, and extract nltk zip package.
 
     Args:
         nltk_data_dir (str): external nltk_data dir path, eg. /home/xx/nltk_data
@@ -40,22 +40,17 @@
     """
     label2id = kwargs.pop('label2id', None)
     id2label = kwargs.pop('id2label', None)
     num_labels = kwargs.pop('num_labels', None)
     if label2id is None and id2label is not None:
         label2id = {label: id for id, label in id2label.items()}
     if label2id is None:
-        if cfg is not None and cfg.safe_get(
-                'dataset.train.labels') is not None:
+        if cfg is not None and cfg.safe_get('dataset.train.labels') is not None:
             # An extra logic to parse labels from the dataset area.
-            label2id = {
-                label: idx
-                for idx, label in enumerate(
-                    cfg.safe_get('dataset.train.labels'))
-            }
+            label2id = { label: idx for idx, label in enumerate(cfg.safe_get('dataset.train.labels')) }
         elif model_dir is not None:
             label2id = parse_label_mapping(model_dir)
 
     if num_labels is None and label2id is not None:
         num_labels = len(label2id)
     if id2label is None and label2id is not None:
         id2label = {id: label for label, id in label2id.items()}
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/plugins.py` & `weathon-0.0.0.14/weathon/utils/plugins.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # This file is adapted from the AllenNLP library at https://github.com/allenai/allennlp
 # Part of the implementation is borrowed from wimglenn/johnnydep
 
 import copy
 import importlib
 import os
 import pkgutil
@@ -13,38 +12,37 @@
 from fnmatch import fnmatch
 from pathlib import Path
 from typing import Any, Iterable, List, Optional, Set, Union
 
 import json
 import pkg_resources
 
-from modelscope.fileio.file import LocalStorage
-from modelscope.utils.ast_utils import FilesAstScanning
-from modelscope.utils.constant import DEFAULT_MODEL_REVISION
-from modelscope.utils.file_utils import get_default_cache_dir
-from modelscope.utils.hub import read_config, snapshot_download
-from modelscope.utils.logger import get_logger
+from weathon.utils.ast_utils import FilesAstScanning
+from weathon.utils.constants import DEFAULT_MODEL_REVISION
+from weathon.utils.fileio import LocalStorage
+from weathon.utils.fileio.file_utils import get_default_cache_dir
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 storage = LocalStorage()
 
 MODELSCOPE_FILE_DIR = get_default_cache_dir()
-PLUGINS_FILENAME = '.modelscope_plugins'
+PLUGINS_FILENAME = '.weathon_plugins'
 OFFICIAL_PLUGINS = [
     {
         'name': 'adaseq',
         'desc':
         'Provide hundreds of additions NERs algorithms, check: https://github.com/modelscope/AdaSeq',
         'version': '',
         'url': ''
     },
 ]
 
-LOCAL_PLUGINS_FILENAME = '.modelscope_plugins'
-GLOBAL_PLUGINS_FILENAME = os.path.join(Path.home(), '.modelscope', 'plugins')
+LOCAL_PLUGINS_FILENAME = '.weathon_plugins'
+GLOBAL_PLUGINS_FILENAME = os.path.join(Path.home(), '.weathon', 'plugins')
 DEFAULT_PLUGINS = []
 
 
 @contextmanager
 def pushd(new_dir: str, verbose: bool = False):
     """
     Changes the current directory to the given path and prepends it to `sys.path`.
@@ -138,15 +136,15 @@
         },
         exclude={
             'modelscope.metrics.*',
             'modelscope.models.*',
             'modelscope.pipelines.*',
             'modelscope.preprocessors.*',
             'modelscope.trainers.*',
-            'modelscope.msdatasets',
+            'modelscope.datasets',
             'modelscope.utils',
             'modelscope.exporters',
         })
 
     imported_plugins: List[str] = []
 
     imported_plugins.extend(import_plugins(DEFAULT_PLUGINS))
@@ -1065,14 +1063,16 @@
         """
 
         Args:
             model_id:  id of the model, not dir
             model_revision: revision of the model, default as master
             cache_dir: the system modelscope cache dir
         """
+        from weathon.utils.hub.utils import snapshot_download, read_config
+
         cache_dir = os.getenv('MODELSCOPE_CACHE', cache_dir)
         self.env_dir = os.path.join(cache_dir, EnvsManager.name, model_id)
         model_dir = snapshot_download(model_id, revision=model_revision)
         cfg = read_config(model_dir)
         self.plugins = cfg.get('plugins', [])
         self.allow_remote = cfg.get('allow_remote', False)
         self.env_builder = venv.EnvBuilder(
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/registry.py` & `weathon-0.0.0.14/weathon/registry/registry.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,11 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import importlib
 import inspect
-from typing import List, Tuple, Union
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 TYPE_NAME = 'type'
 default_group = 'default'
 logger = get_logger()
 AST_INDEX = None
 
 
@@ -49,141 +46,112 @@
 
     def get(self, module_key, group_key=default_group):
         if group_key not in self._modules:
             return None
         else:
             return self._modules[group_key].get(module_key, None)
 
-    def _register_module(self,
-                         group_key=default_group,
-                         module_name=None,
-                         module_cls=None,
-                         force=False):
-        assert isinstance(group_key,
-                          str), 'group_key is required and must be str'
+    def _register_module(self, group_key=default_group, module_name=None, module_cls=None, force=False):
+        assert isinstance(group_key, str), 'group_key is required and must be str'
 
         if group_key not in self._modules:
             self._modules[group_key] = dict()
 
         # Some registered module_cls can be function type.
         # if not inspect.isclass(module_cls):
         #     raise TypeError(f'module is not a class type: {type(module_cls)}')
 
         if module_name is None:
             module_name = module_cls.__name__
 
         if module_name in self._modules[group_key] and not force:
-            raise KeyError(f'{module_name} is already registered in '
-                           f'{self._name}[{group_key}]')
+            raise KeyError(f'{module_name} is already registered in {self._name}[{group_key}]')
         self._modules[group_key][module_name] = module_cls
         module_cls.group_key = group_key
 
-    def register_module(self,
-                        group_key: str = default_group,
-                        module_name: str = None,
-                        module_cls: type = None,
-                        force=False):
+    def register_module(self,group_key: str = default_group,module_name: str = None,module_cls: type = None,force=False):
         """ Register module
 
         Example:
             >>> models = Registry('models')
             >>> @models.register_module('image-classification', 'SwinT')
             >>> class SwinTransformer:
             >>>     pass
 
             >>> @models.register_module('SwinDefault')
             >>> class SwinTransformerDefaultGroup:
             >>>     pass
 
             >>> class SwinTransformer2:
             >>>     pass
-            >>> MODELS.register_module('image-classification',
-                                        module_name='SwinT2',
-                                        module_cls=SwinTransformer2)
+            >>> MODELS.register_module('image-classification', module_name='SwinT2', module_cls=SwinTransformer2)
 
         Args:
             group_key: Group name of which module will be registered,
                 default group name is 'default'
             module_name: Module name
             module_cls: Module class object
             force (bool, optional): Whether to override an existing class with
                 the same name. Default: False.
 
         """
         if not (module_name is None or isinstance(module_name, str)):
-            raise TypeError(f'module_name must be either of None, str,'
-                            f'got {type(module_name)}')
+            raise TypeError(f'module_name must be either of None, str,got {type(module_name)}')
         if module_cls is not None:
-            self._register_module(
-                group_key=group_key,
-                module_name=module_name,
-                module_cls=module_cls,
-                force=force)
+            self._register_module(group_key=group_key, module_name=module_name, module_cls=module_cls, force=force)
             return module_cls
 
         # if module_cls is None, should return a decorator function
         def _register(module_cls):
-            self._register_module(
-                group_key=group_key,
-                module_name=module_name,
-                module_cls=module_cls,
-                force=force)
+            self._register_module(group_key=group_key,module_name=module_name,module_cls=module_cls,force=force)
             return module_cls
 
         return _register
 
 
-def build_from_cfg(cfg,
-                   registry: Registry,
-                   group_key: str = default_group,
-                   default_args: dict = None) -> object:
-    """Build a module from config dict when it is a class configuration, or
+def build_from_cfg(cfg,registry: Registry,group_key: str = default_group,default_args: dict = None) -> object:
+    """
+    Build a module from config dict when it is a class configuration, or
     call a function from config dict when it is a function configuration.
 
     Example:
         >>> models = Registry('models')
         >>> @models.register_module('image-classification', 'SwinT')
         >>> class SwinTransformer:
         >>>     pass
-        >>> swint = build_from_cfg(dict(type='SwinT'), MODELS,
-        >>>     'image-classification')
+        >>> swint = build_from_cfg(dict(type='SwinT'), MODELS, 'image-classification')
         >>> # Returns an instantiated object
         >>>
         >>> @MODELS.register_module()
         >>> def swin_transformer():
         >>>     pass
         >>>       = build_from_cfg(dict(type='swin_transformer'), MODELS)
         >>> # Return a result of the calling function
 
     Args:
-        cfg (dict): Config dict. It should at least contain the key "type".
-        registry (:obj:`Registry`): The registry to search the type from.
-        group_key (str, optional): The name of registry group from which
-            module should be searched.
+        cfg (dict): Config dict.  "type".
+        registry (:obj:`Registry`): "type".
+        group_key (str, optional): The name of registry group from which module should be searched.
         default_args (dict, optional): Default initialization arguments.
         type_name (str, optional): The name of the type in the config.
     Returns:
         object: The constructed object.
     """
     if not isinstance(cfg, dict):
         raise TypeError(f'cfg must be a dict, but got {type(cfg)}')
     if TYPE_NAME not in cfg:
         if default_args is None or TYPE_NAME not in default_args:
-            raise KeyError(
-                f'`cfg` or `default_args` must contain the key "{TYPE_NAME}", '
-                f'but got {cfg}\n{default_args}')
+            raise KeyError(f'`cfg` or `default_args` must contain the key "{TYPE_NAME}", but got {cfg}\n{default_args}')
     if not isinstance(registry, Registry):
-        raise TypeError('registry must be an modelscope.Registry object, '
-                        f'but got {type(registry)}')
+        raise TypeError(f'registry must be an modelscope.Registry object, but got {type(registry)}')
     if not (isinstance(default_args, dict) or default_args is None):
-        raise TypeError('default_args must be a dict or None, '
-                        f'but got {type(default_args)}')
+        raise TypeError(f'default_args must be a dict or None, but got {type(default_args)}')
 
-    # dynamic load installation requirements for this module
-    from modelscope.utils.import_utils import LazyImportModule
+    #  
+    from weathon.utils.import_utils import LazyImportModule
     sig = (registry.name.upper(), group_key, cfg['type'])
     LazyImportModule.import_module(sig)
 
     args = cfg.copy()
     if default_args is not None:
         for name, value in default_args.items():
             args.setdefault(name, value)
@@ -191,24 +159,20 @@
     if group_key is None:
         group_key = default_group
 
     obj_type = args.pop(TYPE_NAME)
     if isinstance(obj_type, str):
         obj_cls = registry.get(obj_type, group_key=group_key)
         if obj_cls is None:
-            raise KeyError(
-                f'{obj_type} is not in the {registry.name}'
-                f' registry group {group_key}. Please make'
-                f' sure the correct version of ModelScope library is used.')
+            raise KeyError(f'{obj_type} is not in the {registry.name} registry group {group_key}. Please make sure the correct version of ModelScope library is used.')
         obj_cls.group_key = group_key
     elif inspect.isclass(obj_type) or inspect.isfunction(obj_type):
         obj_cls = obj_type
     else:
-        raise TypeError(
-            f'type must be a str or valid type, but got {type(obj_type)}')
+        raise TypeError(f'type must be a str or valid type, but got {type(obj_type)}')
     try:
         if hasattr(obj_cls, '_instantiate'):
             return obj_cls._instantiate(**args)
         else:
             return obj_cls(**args)
     except Exception as e:
         # Normal TypeError does not print class name.
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/regress_test_utils.py` & `weathon-0.0.0.14/weathon/utils/test_utils/regress_test_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import contextlib
 import hashlib
 import os
 import pickle
 import random
 import re
 import shutil
@@ -458,15 +456,15 @@
         if p1.data.ne(p2.data).sum() > 0:
             return False
     return True
 
 
 def numpify_tensor_nested(tensors, reduction=None, clip_value=10000):
     try:
-        from modelscope.outputs import ModelOutputBase
+        from weathon.outputs import ModelOutputBase
     except ImportError:
         ModelOutputBase = dict
     "Numpify `tensors` (even if it's a nested list/tuple of tensors)."
     if isinstance(tensors, (Mapping, ModelOutputBase)):
         return OrderedDict({
             k: numpify_tensor_nested(t, reduction, clip_value)
             for k, t in tensors.items()
@@ -488,15 +486,15 @@
             return t.mean(dtype=float)
         return t
     return tensors
 
 
 def detach_tensor_nested(tensors):
     try:
-        from modelscope.outputs import ModelOutputBase
+        from weathon.outputs import ModelOutputBase
     except ImportError:
         ModelOutputBase = dict
     "Detach `tensors` (even if it's a nested list/tuple of tensors)."
     if isinstance(tensors, (Mapping, ModelOutputBase)):
         return OrderedDict(
             {k: detach_tensor_nested(t)
              for k, t in tensors.items()})
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/service_utils.py` & `weathon-0.0.0.14/weathon/utils/service_utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,17 +2,17 @@
 import mimetypes
 from io import BytesIO
 
 import json
 import numpy as np
 import requests
 
-from modelscope.outputs import TASK_OUTPUTS, OutputKeys
-from modelscope.pipeline_inputs import TASK_INPUTS, InputType
-from modelscope.utils.url_utils import valid_url
+from weathon.utils.constants.output_constant import TASK_OUTPUTS, OutputKeys
+from weathon.utils.constants.pipeline_inputs import TASK_INPUTS, InputType
+from weathon.utils.url_utils import valid_url
 
 
 # service data decoder func decodes data from network and convert it to pipeline's input
 # for example
 def ExampleDecoder(data):
     # Assuming the pipeline inputs is a dict contains an image and a text,
     # to decode the data from network we decode the image as base64
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/task_utils.py` & `weathon-0.0.0.14/weathon/utils/task_utils.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,9 @@
-from modelscope.metainfo import TaskModels
-from modelscope.utils import registry
-from modelscope.utils.constant import Tasks
+from weathon.utils.constants.metainfo import TaskModels
+from weathon.utils.constants import Tasks
 
 SUB_TASKS = 'sub_tasks'
 PARENT_TASK = 'parent_task'
 TASK_MODEL = 'task_model'
 
 DEFAULT_TASKS_LEVEL = {
     Tasks.text_classification: {
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/tensor_utils.py` & `weathon-0.0.0.14/weathon/utils/tensor_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Part of the implementation is borrowed from huggingface/transformers.
 from collections.abc import Mapping
 
 
 def torch_nested_numpify(tensors):
     """ Numpify nested torch tensors.
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/test_utils.py` & `weathon-0.0.0.14/weathon/utils/test_utils/test_utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,8 @@
 #!/usr/bin/env python
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 import copy
 import os
 import pickle
 import shutil
 import socket
 import subprocess
 import sys
@@ -14,16 +12,16 @@
 from collections import OrderedDict
 from collections.abc import Mapping
 from os.path import expanduser
 
 import numpy as np
 import requests
 
-from modelscope.hub.constants import DEFAULT_CREDENTIALS_PATH
-from modelscope.utils.import_utils import is_tf_available, is_torch_available
+from weathon.utils.constants.constants import DEFAULT_CREDENTIALS_PATH
+from weathon.utils.import_utils import is_tf_available, is_torch_available
 
 TEST_LEVEL = 2
 TEST_LEVEL_STR = 'TEST_LEVEL'
 
 # for user citest and sdkdev
 TEST_ACCESS_TOKEN1 = os.environ.get('TEST_ACCESS_TOKEN_CITEST', None)
 TEST_ACCESS_TOKEN2 = os.environ.get('TEST_ACCESS_TOKEN_SDKDEV', None)
@@ -106,15 +104,15 @@
     status_code, result = subprocess.getstatusoutput(
         'grep -rn "damo/" tests/  | grep -v ".pyc" | grep -v "Binary file" | grep -v run.py '
     )
     lines = result.split('\n')
     test_cases = OrderedDict()
     model_cases = OrderedDict()
     for line in lines:
-        # "tests/msdatasets/test_ms_dataset.py:92:        model_id = 'damo/bert-base-sst2'"
+        # "tests/datasets/test_ms_dataset.py:92:        model_id = 'damo/bert-base-sst2'"
         line = line.strip()
         elements = line.split(':')
         test_file = elements[0]
         model_pos = line.find('damo')
         left_quote = line[model_pos - 1]
         rquote_idx = line.rfind(left_quote)
         model_name = line[model_pos:rquote_idx]
@@ -219,15 +217,15 @@
 
 _DIST_SCRIPT_TEMPLATE = """
 import ast
 import argparse
 import pickle
 import torch
 from torch import distributed as dist
-from modelscope.utils.torch_utils import get_dist_info
+from weathon.utils.torch_utils import get_dist_info
 import {}
 
 parser = argparse.ArgumentParser()
 parser.add_argument('--save_all_ranks', type=ast.literal_eval, help='save all ranks results')
 parser.add_argument('--save_file', type=str, help='save file')
 parser.add_argument('--local_rank', type=int, default=0)
 args = parser.parse_args()
@@ -252,15 +250,15 @@
 
 
 class DistributedTestCase(unittest.TestCase):
     """Distributed TestCase for test function with distributed mode.
     Examples:
         >>> import torch
         >>> from torch import distributed as dist
-        >>> from modelscope.utils.torch_utils import init_dist
+        >>> from weathon.utils.torch_utils import init_dist
 
         >>> def _test_func(*args, **kwargs):
         >>>     init_dist(launcher='pytorch')
         >>>     rank = dist.get_rank()
         >>>     if rank == 0:
         >>>         value = torch.tensor(1.0).cuda()
         >>>     else:
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/timer.py` & `weathon-0.0.0.14/weathon/utils/timer.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/dl/utils/torch_utils.py` & `weathon-0.0.0.14/weathon/utils/torch_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
 # Following code is partialy borrowed from openmmlab/mmcv
 import functools
 import os
 import pickle
 import random
 import socket
 import subprocess
@@ -126,15 +125,15 @@
     Args:
         group: The parallel group, default None, for the global group
 
     Returns:
         A tuple of the current rank and world_size of the group
     """
     if is_dist():
-        from modelscope.utils.megatron_utils import is_megatron_initialized
+        from weathon.utils.megatron_utils import is_megatron_initialized
         if group is None and is_megatron_initialized():
             from megatron_util import mpu
             group = mpu.get_data_parallel_group()
         rank = dist.get_rank(group)
         world_size = dist.get_world_size(group)
     else:
         rank = 0
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/trie.py` & `weathon-0.0.0.14/weathon/utils/trie.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from collections import defaultdict
 
 
 class TreeNode:
 
     def __init__(self):
         self.child = defaultdict(TreeNode)
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/type_assert.py` & `weathon-0.0.0.14/weathon/utils/type_assert.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from functools import wraps
 from inspect import signature
 
 
 def type_assert(*ty_args, **ty_kwargs):
     """a decorator which is used to check the types of arguments in a function or class
     Examples:
```

### Comparing `weathon-0.0.0.13/weathon/dl/utils/url_utils.py` & `weathon-0.0.0.14/weathon/utils/url_utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,14 +1,12 @@
-# Copyright (c) Alibaba, Inc. and its affiliates.
-
 from urllib.parse import urlparse
 
 import pandas as pd
 
-from modelscope.utils.logger import get_logger
+from weathon.utils.logger import get_logger
 
 logger = get_logger()
 
 
 def valid_url(url) -> bool:
     try:
         result = urlparse(url)
```

### Comparing `weathon-0.0.0.13/weathon/utils/__init__.py` & `weathon-0.0.0.14/weathon/utils_/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,61 +1,48 @@
-from weathon.utils.json_utils import JsonUtils  # Json 
-from weathon.utils.label_studio_utils import LabelStudioUtils  # Label Studio 
-from weathon.utils.gpu_utils import GPUUtils  # GPU
-from weathon.utils.file_utils import FileUtils  # 
-from weathon.utils.file_utils import FileDecomposeUtils  # 
-from weathon.utils.union_find import UnionFind  # 
-from weathon.utils.ip_utils import IpUtils  # IP
-from weathon.utils.email_utils import EmailUtils  # 
-from weathon.utils.pdf_utils import PDFUtils  # pdf 
-# --------------------------------------------- constants ---------------------------------------------
-from weathon.utils.constants import number2melody, emoji_face
-
-# --------------------------------------------- string ---------------------------------------------
-from weathon.utils.dictionary import Dictionary  # 
-from weathon.utils.number_utils import NumberUtils  # 
-from weathon.utils.word_finder import AhoCorasick  # AC:
-from weathon.utils.word_finder import WordFinder  # levensthein
-from weathon.utils.word_discover import WordDiscoverer  #  
-from weathon.utils.keyword_extract import TFIDF, TextRank, Rake  # TFIDF, TextRank 
-from weathon.utils.minjoin import MinJoin  # 
-from weathon.utils.encrypt_utils import EncryptUtils  # 
-from weathon.utils.char_utils import CharUtils  # 
-from weathon.utils.string_utils import StringUtils  # 
-
-# --------------------------------------------- deep learning ---------------------------------------------
-# transformers 
-from weathon.utils.transformer_utils import TransformerUtils
-
-# 
-from weathon.utils.environment_utils import EnvironmentUtils  # 
-from weathon.utils.sampler import ImbalancedDatasetSampler  # 
-from weathon.utils.optimizer_utils import OptimizerUtils  # 
-from weathon.utils.schedule_utils import ScheduleUtils  #  scheduler
-from weathon.utils.loss_utils import LossUtils  # 
-from weathon.utils.attack import FGM, PGD  # trick
-from weathon.utils.ema import EMA  # trick
-
-# 
-from weathon.utils.model_ensemble import ModelEnsemble  # 
-
-# 
-from weathon.utils.ner_utils import NERUtils  # 
-
-# --------------------------------------------- music utils ---------------------------------------------
-#    :
-#   1. : Recorder,
-#   2. : OnsetFrameSplitter , 
-#   3. : NotePoltter
-
-from weathon.utils.sound_recorder import Recorder
-from weathon.utils.nextpow2 import next_pow2, get_next_power_2  # 
-from weathon.utils.noise_reduction import NoiseReduction        # 
-from weathon.utils.onset_frames_split import OnsetFrameSplitter # 
-from weathon.utils.wav_utils import WaveProperties
-from weathon.utils.sound_plot_utils import SoundPlotUtils
-from weathon.utils.midi_detector import MIDIDetector            # 
-from weathon.utils.note_plotter import NotePlotter              # 
-from weathon.utils.music import Music
-
-
-# TODO: 2.  3.  4. 
+# from weathon.utils.fileio.format.json_utils import JsonUtils  # Json 
+# from weathon.utils.label_studio_utils import LabelStudioUtils  # Label Studio 
+# from weathon.utils.fileio.file_utils import FileUtils  # 
+# from weathon.utils.ip_utils import IpUtils  # IP
+# # --------------------------------------------- constants ---------------------------------------------
+#
+# # --------------------------------------------- string ---------------------------------------------
+# from weathon.utils.number_utils import NumberUtils  # 
+# from weathon.utils.word_finder import AhoCorasick  # AC:
+# from weathon.utils.word_discover import WordDiscoverer  #  
+# from weathon.utils.encrypt_utils import EncryptUtils  # 
+# from weathon.utils.char_utils import CharUtils  # 
+# from weathon.utils.string_utils import StringUtils  # 
+#
+# # --------------------------------------------- deep learning ---------------------------------------------
+# # transformers 
+# from weathon.utils.transformer_utils import TransformerUtils
+#
+# # 
+# from weathon.utils.sampler import ImbalancedDatasetSampler  # 
+# from weathon.utils.optimizer_utils import OptimizerUtils  # 
+# from weathon.utils.schedule_utils import ScheduleUtils  #  scheduler
+# from weathon.utils.loss_utils import LossUtils  # 
+# from weathon.utils.attack import FGM, PGD  # trick
+# from weathon.utils.ema import EMA  # trick
+#
+# # 
+#
+# # 
+# from weathon.utils.ner_utils import NERUtils  # 
+#
+# # --------------------------------------------- music utils ---------------------------------------------
+# #    :
+# #   1. : Recorder,
+# #   2. : OnsetFrameSplitter , 
+# #   3. : NotePoltter
+#
+# from weathon.utils.nextpow2 import next_pow2, get_next_power_2  # 
+# from weathon.utils.noise_reduction import NoiseReduction        # 
+# from weathon.utils.onset_frames_split import OnsetFrameSplitter # 
+# from weathon.utils.wav_utils import WaveProperties
+# from weathon.utils.sound_plot_utils import SoundPlotUtils
+# from weathon.utils.midi_detector import MIDIDetector            # 
+# from weathon.utils.note_plotter import NotePlotter              # 
+# from weathon.utils.music import Music
+#
+#
+# # TODO: 2.  3.  4. 
```

### Comparing `weathon-0.0.0.13/weathon/utils/attack.py` & `weathon-0.0.0.14/weathon/utils_/attack.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/char_utils.py` & `weathon-0.0.0.14/weathon/utils_/char_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/conlleval.py` & `weathon-0.0.0.14/weathon/utils_/conlleval.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/constants.py` & `weathon-0.0.0.14/weathon/utils_/constants.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/data_utils.py` & `weathon-0.0.0.14/weathon/utils_/data_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/dictionary.py` & `weathon-0.0.0.14/weathon/utils_/dictionary.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/ema.py` & `weathon-0.0.0.14/weathon/utils_/ema.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/email_utils.py` & `weathon-0.0.0.14/weathon/utils_/email_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/encrypt_utils.py` & `weathon-0.0.0.14/weathon/utils_/encrypt_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/environment_utils.py` & `weathon-0.0.0.14/weathon/utils_/environment_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/file_utils.py` & `weathon-0.0.0.14/weathon/utils_/file_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/gpu_utils.py` & `weathon-0.0.0.14/weathon/utils_/gpu_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/ip_utils.py` & `weathon-0.0.0.14/weathon/utils_/ip_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/json_utils.py` & `weathon-0.0.0.14/weathon/utils_/json_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/keyword_extract.py` & `weathon-0.0.0.14/weathon/utils_/keyword_extract.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/label_studio_utils.py` & `weathon-0.0.0.14/weathon/utils_/label_studio_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/loss_utils.py` & `weathon-0.0.0.14/weathon/utils_/loss_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/midi_detector.py` & `weathon-0.0.0.14/weathon/utils_/midi_detector.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/minjoin.py` & `weathon-0.0.0.14/weathon/utils_/minjoin.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/model_ensemble.py` & `weathon-0.0.0.14/weathon/utils_/model_ensemble.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/music.py` & `weathon-0.0.0.14/weathon/utils_/music.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/ner_utils.py` & `weathon-0.0.0.14/weathon/utils_/ner_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/nextpow2.py` & `weathon-0.0.0.14/weathon/utils_/nextpow2.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/noise_reduction.py` & `weathon-0.0.0.14/weathon/utils_/noise_reduction.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/note_plotter.py` & `weathon-0.0.0.14/weathon/utils_/note_plotter.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/number_utils.py` & `weathon-0.0.0.14/weathon/utils_/number_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/onset_frames_split.py` & `weathon-0.0.0.14/weathon/utils_/onset_frames_split.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/optimizer_utils.py` & `weathon-0.0.0.14/weathon/utils_/optimizer_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/pdf_utils.py` & `weathon-0.0.0.14/weathon/utils_/pdf_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/prune.py` & `weathon-0.0.0.14/weathon/utils_/prune.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/sampler.py` & `weathon-0.0.0.14/weathon/utils_/sampler.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/schedule_utils.py` & `weathon-0.0.0.14/weathon/utils_/schedule_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/semantic_scholar.py` & `weathon-0.0.0.14/weathon/utils_/semantic_scholar.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/sound_plot_utils.py` & `weathon-0.0.0.14/weathon/utils_/sound_plot_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/sound_recorder.py` & `weathon-0.0.0.14/weathon/utils_/sound_recorder.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 import logging
 import datetime
 import os
 import wave
 from pathlib import Path
 from threading import Thread
 
-from weathon.utils.file_utils import FileUtils
+from weathon.utils.fileio.file_utils import FileUtils
 
 from pyaudio import PyAudio, paInt16
 
 
 class Recorder:
 
     def __init__(self, chunk=2048, n_channels=1, rate=44100):
```

### Comparing `weathon-0.0.0.13/weathon/utils/states_machine.py` & `weathon-0.0.0.14/weathon/utils_/states_machine.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/string_converter.py` & `weathon-0.0.0.14/weathon/utils_/string_converter.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/string_similarity.py` & `weathon-0.0.0.14/weathon/utils_/string_similarity.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/string_utils.py` & `weathon-0.0.0.14/weathon/utils_/string_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/text_cluster.py` & `weathon-0.0.0.14/weathon/utils_/text_cluster.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/textrank.py` & `weathon-0.0.0.14/weathon/utils_/textrank.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/transformer_utils.py` & `weathon-0.0.0.14/weathon/utils_/transformer_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/union_find.py` & `weathon-0.0.0.14/weathon/utils_/union_find.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/wav_note.py` & `weathon-0.0.0.14/weathon/utils_/wav_note.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/wav_utils.py` & `weathon-0.0.0.14/weathon/utils_/wav_utils.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/word_discover.py` & `weathon-0.0.0.14/weathon/utils_/word_discover.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon/utils/word_finder.py` & `weathon-0.0.0.14/weathon/utils_/word_finder.py`

 * *Files identical despite different names*

### Comparing `weathon-0.0.0.13/weathon.egg-info/PKG-INFO` & `weathon-0.0.0.14/weathon.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: weathon
-Version: 0.0.0.13
+Version: 0.0.0.14
 Summary: weathon: a personal Weapon Depot for python, so called weathon.
 Home-page: https://github.com/LiZhen0628
 Author: LiZhen
 Author-email: 16621660628@163.com
 License: UNKNOWN
 Description: # weathon_package
         a personal Weapon Depot for python, so called weathon.
```


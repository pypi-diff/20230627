# Comparing `tmp/testflows.core-1.9.230315.1003122.tar.gz` & `tmp/testflows.core-1.9.230627.1151633.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "testflows.core-1.9.230315.1003122.tar", last modified: Wed Mar 15 00:31:22 2023, max compression
+gzip compressed data, was "testflows.core-1.9.230627.1151633.tar", last modified: Tue Jun 27 15:16:33 2023, max compression
```

## Comparing `testflows.core-1.9.230315.1003122.tar` & `testflows.core-1.9.230627.1151633.tar`

### file list

```diff
@@ -1,530 +1,530 @@
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/
--rw-rw-r--   0 user      (1000) user      (1000)      630 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/LICENSE
--rw-rw-r--   0 user      (1000) user      (1000)      763 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/PKG-INFO
--rw-rw-r--   0 user      (1000) user      (1000)      212 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/README.md
--rw-rw-r--   0 user      (1000) user      (1000)       38 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/setup.cfg
--rw-rw-r--   0 user      (1000) user      (1000)     3722 2023-03-15 00:31:22.000000 testflows.core-1.9.230315.1003122/setup.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.347275 testflows.core-1.9.230315.1003122/testflows/
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/
--rw-rw-r--   0 user      (1000) user      (1000)     1669 2023-03-15 00:31:22.000000 testflows.core-1.9.230315.1003122/testflows/_core/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     4837 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/baseobject.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/bin/
--rwxrwxr-x   0 user      (1000) user      (1000)     2403 2023-03-15 00:25:55.000000 testflows.core-1.9.230315.1003122/testflows/_core/bin/tfs
--rw-rw-r--   0 user      (1000) user      (1000)     5031 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/bin/tfs-worker
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/cli/
--rw-rw-r--   0 user      (1000) user      (1000)      654 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     4422 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/common.py
--rw-rw-r--   0 user      (1000) user      (1000)     1570 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/exit.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     2105 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/convert.py
--rw-rw-r--   0 user      (1000) user      (1000)     1873 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/handler.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/new/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/new/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     1420 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/new/handler.py
--rw-rw-r--   0 user      (1000) user      (1000)     2335 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/new/requirements.py
--rw-rw-r--   0 user      (1000) user      (1000)     2355 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/toc.py
--rw-rw-r--   0 user      (1000) user      (1000)      971 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/handler.py
--rw-rw-r--   0 user      (1000) user      (1000)     1992 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/log.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)    15502 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/command.py
--rw-rw-r--   0 user      (1000) user      (1000)     1586 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/handler.py
--rw-rw-r--   0 user      (1000) user      (1000)     5192 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/metrics.py
--rw-rw-r--   0 user      (1000) user      (1000)     1890 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/results.py
--rw-rw-r--   0 user      (1000) user      (1000)     1012 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/copyright.py
--rw-rw-r--   0 user      (1000) user      (1000)    16799 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/coverage.py
--rw-rw-r--   0 user      (1000) user      (1000)     2299 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/handler.py
--rw-rw-r--   0 user      (1000) user      (1000)     4020 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/metrics.py
--rw-rw-r--   0 user      (1000) user      (1000)    17799 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/results.py
--rw-rw-r--   0 user      (1000) user      (1000)     9857 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/specification.py
--rw-rw-r--   0 user      (1000) user      (1000)     8845 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/srs_coverage.py
--rw-rw-r--   0 user      (1000) user      (1000)     8387 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/tracebility.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/requirement/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/requirement/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     1709 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/requirement/generate.py
--rw-rw-r--   0 user      (1000) user      (1000)     1445 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/requirement/handler.py
--rw-rw-r--   0 user      (1000) user      (1000)     5943 2023-01-31 04:15:47.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/run.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     3080 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/arguments.py
--rw-rw-r--   0 user      (1000) user      (1000)     3084 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/attributes.py
--rw-rw-r--   0 user      (1000) user      (1000)     1718 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/coverage.py
--rw-rw-r--   0 user      (1000) user      (1000)     3082 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/description.py
--rw-rw-r--   0 user      (1000) user      (1000)     2850 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/details.py
--rw-rw-r--   0 user      (1000) user      (1000)     3076 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/examples.py
--rw-rw-r--   0 user      (1000) user      (1000)     1842 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/fails.py
--rw-rw-r--   0 user      (1000) user      (1000)     4028 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/handler.py
--rw-rw-r--   0 user      (1000) user      (1000)     3302 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/messages.py
--rw-rw-r--   0 user      (1000) user      (1000)     3072 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/metrics.py
--rw-rw-r--   0 user      (1000) user      (1000)     1725 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/passing.py
--rw-rw-r--   0 user      (1000) user      (1000)     2961 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/procedure.py
--rw-rw-r--   0 user      (1000) user      (1000)     3092 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/requirements.py
--rw-rw-r--   0 user      (1000) user      (1000)     3069 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/result.py
--rw-rw-r--   0 user      (1000) user      (1000)     1718 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/results.py
--rw-rw-r--   0 user      (1000) user      (1000)     3100 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/specifications.py
--rw-rw-r--   0 user      (1000) user      (1000)     3060 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/tags.py
--rw-rw-r--   0 user      (1000) user      (1000)     3067 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/tests.py
--rw-rw-r--   0 user      (1000) user      (1000)     1715 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/totals.py
--rw-rw-r--   0 user      (1000) user      (1000)     1725 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/unstable.py
--rw-rw-r--   0 user      (1000) user      (1000)     1729 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/version.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     1724 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/brisk.py
--rw-rw-r--   0 user      (1000) user      (1000)     1742 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/classic.py
--rw-rw-r--   0 user      (1000) user      (1000)     2080 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/compact.py
--rw-rw-r--   0 user      (1000) user      (1000)     1733 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/compress.py
--rw-rw-r--   0 user      (1000) user      (1000)     1706 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/decompress.py
--rw-rw-r--   0 user      (1000) user      (1000)     1719 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/dots.py
--rw-rw-r--   0 user      (1000) user      (1000)     1858 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/fails.py
--rw-rw-r--   0 user      (1000) user      (1000)     3375 2023-02-22 21:35:02.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/handler.py
--rw-rw-r--   0 user      (1000) user      (1000)     1729 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/manual.py
--rw-rw-r--   0 user      (1000) user      (1000)     1719 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/nice.py
--rw-rw-r--   0 user      (1000) user      (1000)     1755 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/pnice.py
--rw-rw-r--   0 user      (1000) user      (1000)     1714 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/raw.py
--rw-rw-r--   0 user      (1000) user      (1000)     1724 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/short.py
--rw-rw-r--   0 user      (1000) user      (1000)     1724 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/slick.py
--rw-rw-r--   0 user      (1000) user      (1000)     3713 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/parser.py
--rw-rw-r--   0 user      (1000) user      (1000)     7837 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/type.py
--rw-rw-r--   0 user      (1000) user      (1000)     4679 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/colors.py
--rw-rw-r--   0 user      (1000) user      (1000)     1896 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/cli/text.py
--rw-rw-r--   0 user      (1000) user      (1000)     8047 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/compress.py
--rw-rw-r--   0 user      (1000) user      (1000)      755 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/constants.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/
--rw-rw-r--   0 user      (1000) user      (1000)      653 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/aiomsg/
--rw-rw-r--   0 user      (1000) user      (1000)    46147 2023-01-10 18:07:24.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/aiomsg/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     1179 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/aiomsg/header.py
--rw-rw-r--   0 user      (1000) user      (1000)     1030 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/aiomsg/msgproto.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/
--rw-rw-r--   0 user      (1000) user      (1000)    62569 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     2853 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/cleanpeg.py
--rw-rw-r--   0 user      (1000) user      (1000)     6682 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/export.py
--rw-rw-r--   0 user      (1000) user      (1000)    10645 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/peg.py
--rw-rw-r--   0 user      (1000) user      (1000)      416 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/utils.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/cloudpickle/
--rw-rw-r--   0 user      (1000) user      (1000)      333 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/cloudpickle/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)    35841 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/cloudpickle/cloudpickle.py
--rw-rw-r--   0 user      (1000) user      (1000)    32278 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/cloudpickle/cloudpickle_fast.py
--rw-rw-r--   0 user      (1000) user      (1000)      354 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/cloudpickle/compat.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/markdown2/
--rw-rw-r--   0 user      (1000) user      (1000)       25 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/markdown2/__init__.py
--rwxrwxr-x   0 user      (1000) user      (1000)   111514 2022-12-23 06:55:28.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/markdown2/markdown2.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/
--rw-rw-r--   0 user      (1000) user      (1000)      175 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/
--rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/ber/
--rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/ber/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)    59972 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/ber/decoder.py
--rw-rw-r--   0 user      (1000) user      (1000)    27957 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/ber/encoder.py
--rw-rw-r--   0 user      (1000) user      (1000)      674 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/ber/eoo.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/cer/
--rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/cer/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     3841 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/cer/decoder.py
--rw-rw-r--   0 user      (1000) user      (1000)     9529 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/cer/encoder.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/der/
--rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/der/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     2770 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/der/decoder.py
--rw-rw-r--   0 user      (1000) user      (1000)     3145 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/der/encoder.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/native/
--rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/native/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     7839 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/native/decoder.py
--rw-rw-r--   0 user      (1000) user      (1000)     8170 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/native/encoder.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/
--rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)      698 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/binary.py
--rw-rw-r--   0 user      (1000) user      (1000)      379 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/calling.py
--rw-rw-r--   0 user      (1000) user      (1000)      482 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/dateandtime.py
--rw-rw-r--   0 user      (1000) user      (1000)     3012 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/integer.py
--rw-rw-r--   0 user      (1000) user      (1000)     1359 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/octets.py
--rw-rw-r--   0 user      (1000) user      (1000)      505 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/string.py
--rw-rw-r--   0 user      (1000) user      (1000)     3798 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/debug.py
--rw-rw-r--   0 user      (1000) user      (1000)     2257 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/error.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.355275 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/
--rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)    22506 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/base.py
--rw-rw-r--   0 user      (1000) user      (1000)    11469 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/char.py
--rw-rw-r--   0 user      (1000) user      (1000)    22156 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/constraint.py
--rw-rw-r--   0 user      (1000) user      (1000)      270 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/error.py
--rw-rw-r--   0 user      (1000) user      (1000)    16440 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/namedtype.py
--rw-rw-r--   0 user      (1000) user      (1000)     4910 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/namedval.py
--rw-rw-r--   0 user      (1000) user      (1000)     2848 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/opentype.py
--rw-rw-r--   0 user      (1000) user      (1000)     9510 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/tag.py
--rw-rw-r--   0 user      (1000) user      (1000)     3022 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/tagmap.py
--rw-rw-r--   0 user      (1000) user      (1000)   109185 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/univ.py
--rw-rw-r--   0 user      (1000) user      (1000)     5512 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/useful.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.359276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/
--rw-rw-r--   0 user      (1000) user      (1000)     3211 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)      416 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/__main__.py
--rw-rw-r--   0 user      (1000) user      (1000)    19789 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/cmdline.py
--rw-rw-r--   0 user      (1000) user      (1000)     1721 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/console.py
--rw-rw-r--   0 user      (1000) user      (1000)     2038 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/filter.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.359276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/filters/
--rw-rw-r--   0 user      (1000) user      (1000)    11669 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/filters/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     2996 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatter.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.359276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/
--rw-rw-r--   0 user      (1000) user      (1000)     5229 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/__init__.py
--rwxrwxr-x   0 user      (1000) user      (1000)     6238 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/_mapping.py
--rw-rw-r--   0 user      (1000) user      (1000)     3362 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/bbcode.py
--rw-rw-r--   0 user      (1000) user      (1000)    32759 2023-01-31 02:12:31.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/html.py
--rw-rw-r--   0 user      (1000) user      (1000)    19886 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/img.py
--rw-rw-r--   0 user      (1000) user      (1000)     5941 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/irc.py
--rw-rw-r--   0 user      (1000) user      (1000)    17854 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/latex.py
--rw-rw-r--   0 user      (1000) user      (1000)     5236 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/other.py
--rw-rw-r--   0 user      (1000) user      (1000)     5098 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/rtf.py
--rw-rw-r--   0 user      (1000) user      (1000)     5888 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/svg.py
--rw-rw-r--   0 user      (1000) user      (1000)     5093 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/terminal.py
--rw-rw-r--   0 user      (1000) user      (1000)    11140 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/terminal256.py
--rw-rw-r--   0 user      (1000) user      (1000)    31818 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexer.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.367276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/
--rw-rw-r--   0 user      (1000) user      (1000)    11505 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)    27311 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_asy_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    14018 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_cl_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    40001 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_cocoa_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    17504 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_csound_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)   134534 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_lasso_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)     8340 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_lua_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    68999 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_mapping.py
--rw-rw-r--   0 user      (1000) user      (1000)    24737 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_mql_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    48362 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_openedge_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)   154429 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_php_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    11234 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_postgres_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    52429 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_scilab_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    27137 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_sourcemod_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    10481 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_stan_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    25228 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_stata_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    15484 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_tsql_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)     4249 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_vbscript_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    57090 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_vim_builtins.py
--rw-rw-r--   0 user      (1000) user      (1000)    11229 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/actionscript.py
--rw-rw-r--   0 user      (1000) user      (1000)     1140 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/agile.py
--rw-rw-r--   0 user      (1000) user      (1000)     7249 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/algebra.py
--rw-rw-r--   0 user      (1000) user      (1000)     2605 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ambient.py
--rw-rw-r--   0 user      (1000) user      (1000)     4171 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ampl.py
--rw-rw-r--   0 user      (1000) user      (1000)     3222 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/apl.py
--rw-rw-r--   0 user      (1000) user      (1000)    11184 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/archetype.py
--rw-rw-r--   0 user      (1000) user      (1000)    29951 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/asm.py
--rw-rw-r--   0 user      (1000) user      (1000)    19688 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/automation.py
--rw-rw-r--   0 user      (1000) user      (1000)    27648 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/basic.py
--rw-rw-r--   0 user      (1000) user      (1000)     4773 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/bibtex.py
--rw-rw-r--   0 user      (1000) user      (1000)     3990 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/boa.py
--rw-rw-r--   0 user      (1000) user      (1000)    27737 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/business.py
--rw-rw-r--   0 user      (1000) user      (1000)    10584 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/c_cpp.py
--rw-rw-r--   0 user      (1000) user      (1000)    25176 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/c_like.py
--rw-rw-r--   0 user      (1000) user      (1000)     2242 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/capnproto.py
--rw-rw-r--   0 user      (1000) user      (1000)     3872 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/chapel.py
--rw-rw-r--   0 user      (1000) user      (1000)     6410 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/clean.py
--rw-rw-r--   0 user      (1000) user      (1000)     1865 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/compiled.py
--rw-rw-r--   0 user      (1000) user      (1000)    32231 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/configs.py
--rw-rw-r--   0 user      (1000) user      (1000)     4168 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/console.py
--rw-rw-r--   0 user      (1000) user      (1000)    16893 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/crystal.py
--rw-rw-r--   0 user      (1000) user      (1000)    16883 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/csound.py
--rw-rw-r--   0 user      (1000) user      (1000)    31581 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/css.py
--rw-rw-r--   0 user      (1000) user      (1000)     9578 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/d.py
--rw-rw-r--   0 user      (1000) user      (1000)     4468 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/dalvik.py
--rw-rw-r--   0 user      (1000) user      (1000)    19104 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/data.py
--rw-rw-r--   0 user      (1000) user      (1000)     4921 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/diff.py
--rw-rw-r--   0 user      (1000) user      (1000)    27719 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/dotnet.py
--rw-rw-r--   0 user      (1000) user      (1000)    35884 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/dsls.py
--rw-rw-r--   0 user      (1000) user      (1000)    10450 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/dylan.py
--rw-rw-r--   0 user      (1000) user      (1000)     5923 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ecl.py
--rw-rw-r--   0 user      (1000) user      (1000)     2530 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/eiffel.py
--rw-rw-r--   0 user      (1000) user      (1000)     3045 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/elm.py
--rw-rw-r--   0 user      (1000) user      (1000)     5303 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/email.py
--rw-rw-r--   0 user      (1000) user      (1000)    19024 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/erlang.py
--rw-rw-r--   0 user      (1000) user      (1000)     9537 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/esoteric.py
--rw-rw-r--   0 user      (1000) user      (1000)     3092 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ezhil.py
--rw-rw-r--   0 user      (1000) user      (1000)    17912 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/factor.py
--rw-rw-r--   0 user      (1000) user      (1000)    10030 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/fantom.py
--rw-rw-r--   0 user      (1000) user      (1000)     9456 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/felix.py
--rw-rw-r--   0 user      (1000) user      (1000)     2715 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/floscript.py
--rw-rw-r--   0 user      (1000) user      (1000)     7227 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/forth.py
--rw-rw-r--   0 user      (1000) user      (1000)     9889 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/fortran.py
--rw-rw-r--   0 user      (1000) user      (1000)    26284 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/foxpro.py
--rw-rw-r--   0 user      (1000) user      (1000)    27182 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/freefem.py
--rw-rw-r--   0 user      (1000) user      (1000)      818 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/functional.py
--rw-rw-r--   0 user      (1000) user      (1000)     3749 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/go.py
--rw-rw-r--   0 user      (1000) user      (1000)     6377 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/grammar_notation.py
--rw-rw-r--   0 user      (1000) user      (1000)     2804 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/graph.py
--rw-rw-r--   0 user      (1000) user      (1000)    38331 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/graphics.py
--rw-rw-r--   0 user      (1000) user      (1000)    32168 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/haskell.py
--rw-rw-r--   0 user      (1000) user      (1000)    31007 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/haxe.py
--rw-rw-r--   0 user      (1000) user      (1000)    18227 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/hdl.py
--rw-rw-r--   0 user      (1000) user      (1000)     3555 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/hexdump.py
--rw-rw-r--   0 user      (1000) user      (1000)    19448 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/html.py
--rw-rw-r--   0 user      (1000) user      (1000)    15034 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/idl.py
--rw-rw-r--   0 user      (1000) user      (1000)    30965 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/igor.py
--rw-rw-r--   0 user      (1000) user      (1000)     3165 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/inferno.py
--rw-rw-r--   0 user      (1000) user      (1000)    12914 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/installers.py
--rw-rw-r--   0 user      (1000) user      (1000)    55827 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/int_fiction.py
--rw-rw-r--   0 user      (1000) user      (1000)     1953 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/iolang.py
--rw-rw-r--   0 user      (1000) user      (1000)     4575 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/j.py
--rw-rw-r--   0 user      (1000) user      (1000)    60360 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/javascript.py
--rw-rw-r--   0 user      (1000) user      (1000)    14251 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/julia.py
--rw-rw-r--   0 user      (1000) user      (1000)    70443 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/jvm.py
--rw-rw-r--   0 user      (1000) user      (1000)   143705 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/lisp.py
--rw-rw-r--   0 user      (1000) user      (1000)     7398 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/make.py
--rw-rw-r--   0 user      (1000) user      (1000)    20896 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/markup.py
--rw-rw-r--   0 user      (1000) user      (1000)      868 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/math.py
--rw-rw-r--   0 user      (1000) user      (1000)    30416 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/matlab.py
--rw-rw-r--   0 user      (1000) user      (1000)     8071 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/mime.py
--rw-rw-r--   0 user      (1000) user      (1000)    27925 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ml.py
--rw-rw-r--   0 user      (1000) user      (1000)    13505 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/modeling.py
--rw-rw-r--   0 user      (1000) user      (1000)    52633 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/modula2.py
--rw-rw-r--   0 user      (1000) user      (1000)     6355 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/monte.py
--rw-rw-r--   0 user      (1000) user      (1000)    64034 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ncl.py
--rw-rw-r--   0 user      (1000) user      (1000)     5222 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/nimrod.py
--rw-rw-r--   0 user      (1000) user      (1000)     2791 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/nit.py
--rw-rw-r--   0 user      (1000) user      (1000)     4079 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/nix.py
--rw-rw-r--   0 user      (1000) user      (1000)     3781 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/oberon.py
--rw-rw-r--   0 user      (1000) user      (1000)    22909 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/objective.py
--rw-rw-r--   0 user      (1000) user      (1000)     3047 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ooc.py
--rw-rw-r--   0 user      (1000) user      (1000)     2320 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/other.py
--rw-rw-r--   0 user      (1000) user      (1000)     2785 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/parasail.py
--rw-rw-r--   0 user      (1000) user      (1000)    27854 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/parsers.py
--rw-rw-r--   0 user      (1000) user      (1000)    32741 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/pascal.py
--rw-rw-r--   0 user      (1000) user      (1000)     8117 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/pawn.py
--rw-rw-r--   0 user      (1000) user      (1000)    32084 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/perl.py
--rw-rw-r--   0 user      (1000) user      (1000)    10941 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/php.py
--rw-rw-r--   0 user      (1000) user      (1000)     3317 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/pony.py
--rw-rw-r--   0 user      (1000) user      (1000)    12340 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/praat.py
--rw-rw-r--   0 user      (1000) user      (1000)    12453 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/prolog.py
--rw-rw-r--   0 user      (1000) user      (1000)    47495 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/python.py
--rw-rw-r--   0 user      (1000) user      (1000)     6145 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/qvt.py
--rw-rw-r--   0 user      (1000) user      (1000)     6327 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/r.py
--rw-rw-r--   0 user      (1000) user      (1000)    14656 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/rdf.py
--rw-rw-r--   0 user      (1000) user      (1000)    18672 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/rebol.py
--rw-rw-r--   0 user      (1000) user      (1000)     2974 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/resource.py
--rw-rw-r--   0 user      (1000) user      (1000)     2038 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/rnc.py
--rw-rw-r--   0 user      (1000) user      (1000)     2118 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/roboconf.py
--rw-rw-r--   0 user      (1000) user      (1000)    18808 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/robotframework.py
--rw-rw-r--   0 user      (1000) user      (1000)    22240 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ruby.py
--rw-rw-r--   0 user      (1000) user      (1000)     7786 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/rust.py
--rw-rw-r--   0 user      (1000) user      (1000)     9497 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/sas.py
--rw-rw-r--   0 user      (1000) user      (1000)     2031 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/scdoc.py
--rw-rw-r--   0 user      (1000) user      (1000)    67884 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/scripting.py
--rw-rw-r--   0 user      (1000) user      (1000)     2072 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/sgf.py
--rw-rw-r--   0 user      (1000) user      (1000)    33942 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/shell.py
--rw-rw-r--   0 user      (1000) user      (1000)     8594 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/slash.py
--rw-rw-r--   0 user      (1000) user      (1000)     7263 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/smalltalk.py
--rw-rw-r--   0 user      (1000) user      (1000)     2850 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/smv.py
--rw-rw-r--   0 user      (1000) user      (1000)     2804 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/snobol.py
--rw-rw-r--   0 user      (1000) user      (1000)     3303 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/solidity.py
--rw-rw-r--   0 user      (1000) user      (1000)     3224 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/special.py
--rw-rw-r--   0 user      (1000) user      (1000)    31926 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/sql.py
--rw-rw-r--   0 user      (1000) user      (1000)     6529 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/stata.py
--rw-rw-r--   0 user      (1000) user      (1000)     3564 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/supercollider.py
--rw-rw-r--   0 user      (1000) user      (1000)     5470 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/tcl.py
--rw-rw-r--   0 user      (1000) user      (1000)    73849 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/templates.py
--rw-rw-r--   0 user      (1000) user      (1000)     6358 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/teraterm.py
--rw-rw-r--   0 user      (1000) user      (1000)     1565 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/testflows.py
--rw-rw-r--   0 user      (1000) user      (1000)    10800 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/testing.py
--rw-rw-r--   0 user      (1000) user      (1000)     1294 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/text.py
--rw-rw-r--   0 user      (1000) user      (1000)     6188 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/textedit.py
--rw-rw-r--   0 user      (1000) user      (1000)    13898 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/textfmts.py
--rw-rw-r--   0 user      (1000) user      (1000)    18950 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/theorem.py
--rw-rw-r--   0 user      (1000) user      (1000)     1594 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/trafficscript.py
--rw-rw-r--   0 user      (1000) user      (1000)     8272 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/typoscript.py
--rw-rw-r--   0 user      (1000) user      (1000)    18049 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/unicon.py
--rw-rw-r--   0 user      (1000) user      (1000)     5798 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/urbi.py
--rw-rw-r--   0 user      (1000) user      (1000)     7313 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/varnish.py
--rw-rw-r--   0 user      (1000) user      (1000)     3753 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/verification.py
--rw-rw-r--   0 user      (1000) user      (1000)     1086 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/web.py
--rw-rw-r--   0 user      (1000) user      (1000)    40077 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/webmisc.py
--rw-rw-r--   0 user      (1000) user      (1000)     4060 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/whiley.py
--rw-rw-r--   0 user      (1000) user      (1000)     2013 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/x10.py
--rw-rw-r--   0 user      (1000) user      (1000)      935 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/xorg.py
--rw-rw-r--   0 user      (1000) user      (1000)     4195 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/zig.py
--rw-rw-r--   0 user      (1000) user      (1000)     1010 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/modeline.py
--rw-rw-r--   0 user      (1000) user      (1000)     1734 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/plugin.py
--rw-rw-r--   0 user      (1000) user      (1000)     3094 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/regexopt.py
--rw-rw-r--   0 user      (1000) user      (1000)     3123 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/scanner.py
--rw-rw-r--   0 user      (1000) user      (1000)     4729 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/sphinxext.py
--rw-rw-r--   0 user      (1000) user      (1000)     5806 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/style.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/
--rw-rw-r--   0 user      (1000) user      (1000)     2966 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)      799 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/abap.py
--rw-rw-r--   0 user      (1000) user      (1000)     2311 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/algol.py
--rw-rw-r--   0 user      (1000) user      (1000)     2326 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/algol_nu.py
--rw-rw-r--   0 user      (1000) user      (1000)     4540 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/arduino.py
--rw-rw-r--   0 user      (1000) user      (1000)     2192 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/autumn.py
--rw-rw-r--   0 user      (1000) user      (1000)     1610 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/borland.py
--rw-rw-r--   0 user      (1000) user      (1000)     1403 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/bw.py
--rw-rw-r--   0 user      (1000) user      (1000)     2826 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/colorful.py
--rw-rw-r--   0 user      (1000) user      (1000)     2580 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/default.py
--rw-rw-r--   0 user      (1000) user      (1000)     2534 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/emacs.py
--rw-rw-r--   0 user      (1000) user      (1000)     2563 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/friendly.py
--rw-rw-r--   0 user      (1000) user      (1000)     1346 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/fruity.py
--rw-rw-r--   0 user      (1000) user      (1000)      787 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/igor.py
--rw-rw-r--   0 user      (1000) user      (1000)     2395 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/inkpot.py
--rw-rw-r--   0 user      (1000) user      (1000)     3221 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/lovelace.py
--rw-rw-r--   0 user      (1000) user      (1000)     2422 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/manni.py
--rw-rw-r--   0 user      (1000) user      (1000)     5134 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/monokai.py
--rw-rw-r--   0 user      (1000) user      (1000)     2799 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/murphy.py
--rw-rw-r--   0 user      (1000) user      (1000)     1986 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/native.py
--rw-rw-r--   0 user      (1000) user      (1000)     5689 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/paraiso_dark.py
--rw-rw-r--   0 user      (1000) user      (1000)     5693 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/paraiso_light.py
--rw-rw-r--   0 user      (1000) user      (1000)     2521 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/pastie.py
--rw-rw-r--   0 user      (1000) user      (1000)     2223 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/perldoc.py
--rw-rw-r--   0 user      (1000) user      (1000)     2528 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/rainbow_dash.py
--rw-rw-r--   0 user      (1000) user      (1000)      900 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/rrt.py
--rw-rw-r--   0 user      (1000) user      (1000)     1489 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/sas.py
--rw-rw-r--   0 user      (1000) user      (1000)     3795 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/solarized.py
--rw-rw-r--   0 user      (1000) user      (1000)     1293 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/stata_dark.py
--rw-rw-r--   0 user      (1000) user      (1000)     1322 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/stata_light.py
--rw-rw-r--   0 user      (1000) user      (1000)     7144 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/tango.py
--rw-rw-r--   0 user      (1000) user      (1000)     1981 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/trac.py
--rw-rw-r--   0 user      (1000) user      (1000)     2024 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/vim.py
--rw-rw-r--   0 user      (1000) user      (1000)     1121 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/vs.py
--rw-rw-r--   0 user      (1000) user      (1000)     1549 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/xcode.py
--rw-rw-r--   0 user      (1000) user      (1000)     6490 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/token.py
--rw-rw-r--   0 user      (1000) user      (1000)    64749 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/unistring.py
--rw-rw-r--   0 user      (1000) user      (1000)    11924 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/util.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/
--rw-rw-r--   0 user      (1000) user      (1000)     1536 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     1486 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/_compat.py
--rw-rw-r--   0 user      (1000) user      (1000)     1779 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/asn1.py
--rw-rw-r--   0 user      (1000) user      (1000)     9947 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/cli.py
--rw-rw-r--   0 user      (1000) user      (1000)     4668 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/common.py
--rw-rw-r--   0 user      (1000) user      (1000)     1661 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/core.py
--rw-rw-r--   0 user      (1000) user      (1000)    26191 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/key.py
--rw-rw-r--   0 user      (1000) user      (1000)     2361 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/parallel.py
--rw-rw-r--   0 user      (1000) user      (1000)     3976 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/pem.py
--rw-rw-r--   0 user      (1000) user      (1000)    15539 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/pkcs1.py
--rw-rw-r--   0 user      (1000) user      (1000)     3448 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/pkcs1_v2.py
--rw-rw-r--   0 user      (1000) user      (1000)     5136 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/prime.py
--rw-rw-r--   0 user      (1000) user      (1000)     2695 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/randnum.py
--rw-rw-r--   0 user      (1000) user      (1000)     2200 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/transform.py
--rw-rw-r--   0 user      (1000) user      (1000)     2994 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/util.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/schema/
--rw-rw-r--   0 user      (1000) user      (1000)    28963 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/schema/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/snowflake/
--rw-rw-r--   0 user      (1000) user      (1000)      201 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/snowflake/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     4096 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/snowflake/snowflake.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/x256/
--rw-rw-r--   0 user      (1000) user      (1000)        0 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/x256/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     4519 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/x256/x256.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/
--rw-rw-r--   0 user      (1000) user      (1000)    13170 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     4883 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/composer.py
--rw-rw-r--   0 user      (1000) user      (1000)    28639 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/constructor.py
--rw-rw-r--   0 user      (1000) user      (1000)     3851 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/cyaml.py
--rw-rw-r--   0 user      (1000) user      (1000)     2837 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/dumper.py
--rw-rw-r--   0 user      (1000) user      (1000)    43006 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/emitter.py
--rw-rw-r--   0 user      (1000) user      (1000)     2533 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/error.py
--rw-rw-r--   0 user      (1000) user      (1000)     2445 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/events.py
--rw-rw-r--   0 user      (1000) user      (1000)     2061 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/loader.py
--rw-rw-r--   0 user      (1000) user      (1000)     1440 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/nodes.py
--rw-rw-r--   0 user      (1000) user      (1000)    25495 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/parser.py
--rw-rw-r--   0 user      (1000) user      (1000)     6794 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/reader.py
--rw-rw-r--   0 user      (1000) user      (1000)    14184 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/representer.py
--rw-rw-r--   0 user      (1000) user      (1000)     8999 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/resolver.py
--rw-rw-r--   0 user      (1000) user      (1000)    51277 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/scanner.py
--rw-rw-r--   0 user      (1000) user      (1000)     4165 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/serializer.py
--rw-rw-r--   0 user      (1000) user      (1000)     2573 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/tokens.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/document/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/document/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     2357 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/document/convert.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/document/new/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/document/new/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     3667 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/document/new/requirements.md
--rw-rw-r--   0 user      (1000) user      (1000)    12955 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/document/srs.py
--rw-rw-r--   0 user      (1000) user      (1000)    40891 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/document/style.css
--rw-rw-r--   0 user      (1000) user      (1000)     5244 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/document/toc.py
--rw-rw-r--   0 user      (1000) user      (1000)      694 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/exceptions.py
--rw-rw-r--   0 user      (1000) user      (1000)     1398 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/filters.py
--rw-rw-r--   0 user      (1000) user      (1000)     5016 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/flags.py
--rw-rw-r--   0 user      (1000) user      (1000)    14178 2023-01-23 18:05:16.000000 testflows.core-1.9.230315.1003122/testflows/_core/funcs.py
--rw-rw-r--   0 user      (1000) user      (1000)     4659 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/has.py
--rw-rw-r--   0 user      (1000) user      (1000)     7686 2023-01-10 00:32:30.000000 testflows.core-1.9.230315.1003122/testflows/_core/init.py
--rw-rw-r--   0 user      (1000) user      (1000)    17506 2023-02-23 01:59:54.000000 testflows.core-1.9.230315.1003122/testflows/_core/io.py
--rw-rw-r--   0 user      (1000) user      (1000)     1702 2023-01-19 00:49:14.000000 testflows.core-1.9.230315.1003122/testflows/_core/message.py
--rw-rw-r--   0 user      (1000) user      (1000)    10447 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/name.py
--rw-rw-r--   0 user      (1000) user      (1000)    30528 2023-03-02 00:34:47.000000 testflows.core-1.9.230315.1003122/testflows/_core/objects.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/parallel/
--rw-rw-r--   0 user      (1000) user      (1000)     8105 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/parallel/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     2461 2023-01-10 18:07:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/parallel/asyncio.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/
--rw-rw-r--   0 user      (1000) user      (1000)      673 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     9285 2023-01-10 18:05:45.000000 testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/asyncio.py
--rw-rw-r--   0 user      (1000) user      (1000)     1179 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/future.py
--rw-rw-r--   0 user      (1000) user      (1000)    15747 2023-01-10 01:04:41.000000 testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/process.py
--rw-rw-r--   0 user      (1000) user      (1000)     6381 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/thread.py
--rw-rw-r--   0 user      (1000) user      (1000)    33938 2023-01-10 01:53:11.000000 testflows.core-1.9.230315.1003122/testflows/_core/parallel/service.py
--rw-rw-r--   0 user      (1000) user      (1000)     1928 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/serialize.py
--rw-rw-r--   0 user      (1000) user      (1000)     1171 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/templog.py
--rw-rw-r--   0 user      (1000) user      (1000)   119123 2023-03-15 00:27:41.000000 testflows.core-1.9.230315.1003122/testflows/_core/test.py
--rw-rw-r--   0 user      (1000) user      (1000)     1277 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/testtype.py
--rw-rw-r--   0 user      (1000) user      (1000)     8143 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/tracing.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.371276 testflows.core-1.9.230315.1003122/testflows/_core/transform/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)    18060 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/brisk.py
--rw-rw-r--   0 user      (1000) user      (1000)     5341 2023-03-15 00:22:26.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/classic.py
--rw-rw-r--   0 user      (1000) user      (1000)      822 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/collect.py
--rw-rw-r--   0 user      (1000) user      (1000)     3241 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/dots.py
--rw-rw-r--   0 user      (1000) user      (1000)     4922 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/fails.py
--rw-rw-r--   0 user      (1000) user      (1000)    13258 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/flat.py
--rw-rw-r--   0 user      (1000) user      (1000)    17289 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/manual.py
--rw-rw-r--   0 user      (1000) user      (1000)    17177 2023-01-09 22:17:54.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/nice.py
--rw-rw-r--   0 user      (1000) user      (1000)     1168 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/parse.py
--rw-rw-r--   0 user      (1000) user      (1000)    22334 2023-01-26 01:49:43.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/pipeline.py
--rw-rw-r--   0 user      (1000) user      (1000)     1541 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/procedure.py
--rw-rw-r--   0 user      (1000) user      (1000)     3992 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/progress.py
--rw-rw-r--   0 user      (1000) user      (1000)     5037 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/quiet.py
--rw-rw-r--   0 user      (1000) user      (1000)      910 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/raw.py
--rw-rw-r--   0 user      (1000) user      (1000)     1685 2023-01-26 17:25:52.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/read.py
--rw-rw-r--   0 user      (1000) user      (1000)     1716 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/read_and_filter.py
--rw-rw-r--   0 user      (1000) user      (1000)     1479 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/read_raw.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)     7826 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/coverage.py
--rw-rw-r--   0 user      (1000) user      (1000)     4045 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/fails.py
--rw-rw-r--   0 user      (1000) user      (1000)     1472 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/metrics.py
--rw-rw-r--   0 user      (1000) user      (1000)     3426 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/passing.py
--rw-rw-r--   0 user      (1000) user      (1000)     5301 2023-01-19 00:50:41.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/results.py
--rw-rw-r--   0 user      (1000) user      (1000)    13420 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/totals.py
--rw-rw-r--   0 user      (1000) user      (1000)     4283 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/unstable.py
--rw-rw-r--   0 user      (1000) user      (1000)     1562 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/version.py
--rw-rw-r--   0 user      (1000) user      (1000)    14838 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/short.py
--rw-rw-r--   0 user      (1000) user      (1000)     7069 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/slick.py
--rw-rw-r--   0 user      (1000) user      (1000)      991 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/sort.py
--rw-rw-r--   0 user      (1000) user      (1000)      838 2023-01-26 06:02:55.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/stop.py
--rw-rw-r--   0 user      (1000) user      (1000)      985 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/tests.py
--rw-rw-r--   0 user      (1000) user      (1000)      810 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/values.py
--rw-rw-r--   0 user      (1000) user      (1000)      989 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/transform/log/write.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/testflows/_core/utils/
--rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/utils/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)      770 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/utils/enum.py
--rw-rw-r--   0 user      (1000) user      (1000)     1139 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/utils/format.py
--rw-rw-r--   0 user      (1000) user      (1000)     1152 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/utils/sort.py
--rw-rw-r--   0 user      (1000) user      (1000)      853 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/_core/utils/string.py
--rw-rw-r--   0 user      (1000) user      (1000)     1596 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/utils/strip.py
--rw-rw-r--   0 user      (1000) user      (1000)     3619 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/utils/timefuncs.py
--rw-rw-r--   0 user      (1000) user      (1000)     1364 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/_core/utils/timer.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/testflows/core/
--rw-rw-r--   0 user      (1000) user      (1000)     4063 2023-01-23 16:32:57.000000 testflows.core-1.9.230315.1003122/testflows/core/__init__.py
--rw-rw-r--   0 user      (1000) user      (1000)      695 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/core/exceptions.py
--rw-rw-r--   0 user      (1000) user      (1000)      906 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/core/name.py
--rw-rw-r--   0 user      (1000) user      (1000)      819 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/core/objects.py
--rw-rw-r--   0 user      (1000) user      (1000)     1261 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/core/parallel.py
--rw-rw-r--   0 user      (1000) user      (1000)      701 2022-12-28 17:03:42.000000 testflows.core-1.9.230315.1003122/testflows/core/utils.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/testflows/exceptions/
--rw-rw-r--   0 user      (1000) user      (1000)     2434 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/exceptions/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.375276 testflows.core-1.9.230315.1003122/testflows/settings/
--rw-rw-r--   0 user      (1000) user      (1000)     1530 2023-01-06 01:18:17.000000 testflows.core-1.9.230315.1003122/testflows/settings/__init__.py
-drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-03-15 00:31:22.351276 testflows.core-1.9.230315.1003122/testflows.core.egg-info/
--rwxrwxr-x   0 user      (1000) user      (1000)      763 2023-03-15 00:31:22.000000 testflows.core-1.9.230315.1003122/testflows.core.egg-info/PKG-INFO
--rwxrwxr-x   0 user      (1000) user      (1000)    22086 2023-03-15 00:31:22.000000 testflows.core-1.9.230315.1003122/testflows.core.egg-info/SOURCES.txt
--rwxrwxr-x   0 user      (1000) user      (1000)        1 2023-03-15 00:31:22.000000 testflows.core-1.9.230315.1003122/testflows.core.egg-info/dependency_links.txt
--rwxrwxr-x   0 user      (1000) user      (1000)        1 2022-12-23 06:55:29.000000 testflows.core-1.9.230315.1003122/testflows.core.egg-info/not-zip-safe
--rwxrwxr-x   0 user      (1000) user      (1000)        7 2023-03-15 00:31:22.000000 testflows.core-1.9.230315.1003122/testflows.core.egg-info/requires.txt
--rwxrwxr-x   0 user      (1000) user      (1000)       10 2023-03-15 00:31:22.000000 testflows.core-1.9.230315.1003122/testflows.core.egg-info/top_level.txt
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/
+-rw-rw-r--   0 user      (1000) user      (1000)      630 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/LICENSE
+-rw-rw-r--   0 user      (1000) user      (1000)      763 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/PKG-INFO
+-rw-rw-r--   0 user      (1000) user      (1000)      212 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/README.md
+-rw-rw-r--   0 user      (1000) user      (1000)       38 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/setup.cfg
+-rw-rw-r--   0 user      (1000) user      (1000)     3670 2023-06-27 15:16:33.000000 testflows.core-1.9.230627.1151633/setup.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.632509 testflows.core-1.9.230627.1151633/testflows/
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/
+-rw-rw-r--   0 user      (1000) user      (1000)     1669 2023-06-27 15:16:33.000000 testflows.core-1.9.230627.1151633/testflows/_core/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4898 2023-06-23 21:23:00.000000 testflows.core-1.9.230627.1151633/testflows/_core/baseobject.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/bin/
+-rwxrwxr-x   0 user      (1000) user      (1000)     2403 2023-03-15 00:25:55.000000 testflows.core-1.9.230627.1151633/testflows/_core/bin/tfs
+-rw-rw-r--   0 user      (1000) user      (1000)     5031 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/bin/tfs-worker
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4536 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/common.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1579 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/exit.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2449 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/convert.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1932 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/handler.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/new/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/new/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1487 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/new/handler.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2764 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/new/requirements.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2648 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/toc.py
+-rw-rw-r--   0 user      (1000) user      (1000)      971 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/handler.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2116 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/log.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)    16566 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/command.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1662 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/handler.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5795 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/metrics.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1958 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/results.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1014 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/copyright.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18199 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/coverage.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2394 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/handler.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4345 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/metrics.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18714 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/results.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10802 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/specification.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9794 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/srs_coverage.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8758 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/tracebility.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/requirement/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/requirement/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1891 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/requirement/generate.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1512 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/requirement/handler.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5943 2023-01-31 04:15:47.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/run.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.636509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3297 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/arguments.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3301 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/attributes.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1901 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/coverage.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3299 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/description.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3146 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/details.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3293 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/examples.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2095 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/fails.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4122 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/handler.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3618 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/messages.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3289 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/metrics.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1907 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/passing.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3207 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/procedure.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3309 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/requirements.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3286 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/result.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1901 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/results.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3317 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/specifications.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3277 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/tags.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3284 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/tests.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1897 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/totals.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1907 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/unstable.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1911 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/version.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1907 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/brisk.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1925 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/classic.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2411 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/compact.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1916 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/compress.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1889 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/decompress.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1902 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/dots.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2112 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/fails.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3486 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/handler.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1912 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/manual.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1902 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/nice.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1937 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/pnice.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1897 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/raw.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1907 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/short.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1907 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/slick.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3784 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/parser.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7940 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/type.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4694 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/colors.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1902 2023-06-23 21:21:32.000000 testflows.core-1.9.230627.1151633/testflows/_core/cli/text.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8522 2023-06-23 21:23:01.000000 testflows.core-1.9.230627.1151633/testflows/_core/compress.py
+-rw-rw-r--   0 user      (1000) user      (1000)      756 2023-06-23 21:23:00.000000 testflows.core-1.9.230627.1151633/testflows/_core/constants.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/
+-rw-rw-r--   0 user      (1000) user      (1000)      653 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/aiomsg/
+-rw-rw-r--   0 user      (1000) user      (1000)    46147 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/aiomsg/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1179 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/aiomsg/header.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1030 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/aiomsg/msgproto.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/
+-rw-rw-r--   0 user      (1000) user      (1000)    62569 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2853 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/cleanpeg.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6682 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/export.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10645 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/peg.py
+-rw-rw-r--   0 user      (1000) user      (1000)      416 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/utils.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/cloudpickle/
+-rw-rw-r--   0 user      (1000) user      (1000)      333 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/cloudpickle/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)    35841 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/cloudpickle/cloudpickle.py
+-rw-rw-r--   0 user      (1000) user      (1000)    32278 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/cloudpickle/cloudpickle_fast.py
+-rw-rw-r--   0 user      (1000) user      (1000)      354 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/cloudpickle/compat.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/markdown2/
+-rw-rw-r--   0 user      (1000) user      (1000)       25 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/markdown2/__init__.py
+-rwxrwxr-x   0 user      (1000) user      (1000)   111514 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/markdown2/markdown2.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/
+-rw-rw-r--   0 user      (1000) user      (1000)      175 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/
+-rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/ber/
+-rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/ber/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)    59972 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/ber/decoder.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27957 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/ber/encoder.py
+-rw-rw-r--   0 user      (1000) user      (1000)      674 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/ber/eoo.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/cer/
+-rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/cer/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3841 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/cer/decoder.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9529 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/cer/encoder.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/der/
+-rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/der/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2770 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/der/decoder.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3145 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/der/encoder.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/native/
+-rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/native/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7839 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/native/decoder.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8170 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/native/encoder.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/
+-rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)      698 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/binary.py
+-rw-rw-r--   0 user      (1000) user      (1000)      379 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/calling.py
+-rw-rw-r--   0 user      (1000) user      (1000)      482 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/dateandtime.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3012 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/integer.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1359 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/octets.py
+-rw-rw-r--   0 user      (1000) user      (1000)      505 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/string.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3798 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/debug.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2257 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/error.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/
+-rw-rw-r--   0 user      (1000) user      (1000)       59 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)    22506 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/base.py
+-rw-rw-r--   0 user      (1000) user      (1000)    11469 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/char.py
+-rw-rw-r--   0 user      (1000) user      (1000)    22156 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/constraint.py
+-rw-rw-r--   0 user      (1000) user      (1000)      270 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/error.py
+-rw-rw-r--   0 user      (1000) user      (1000)    16440 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/namedtype.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4910 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/namedval.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2848 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/opentype.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9510 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/tag.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3022 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/tagmap.py
+-rw-rw-r--   0 user      (1000) user      (1000)   109185 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/univ.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5512 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/useful.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/
+-rw-rw-r--   0 user      (1000) user      (1000)     3211 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)      416 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/__main__.py
+-rw-rw-r--   0 user      (1000) user      (1000)    19789 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/cmdline.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1721 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/console.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2038 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/filter.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.640509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/filters/
+-rw-rw-r--   0 user      (1000) user      (1000)    11669 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/filters/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2996 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatter.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.644509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/
+-rw-rw-r--   0 user      (1000) user      (1000)     5229 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/__init__.py
+-rwxrwxr-x   0 user      (1000) user      (1000)     6238 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/_mapping.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3362 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/bbcode.py
+-rw-rw-r--   0 user      (1000) user      (1000)    32759 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/html.py
+-rw-rw-r--   0 user      (1000) user      (1000)    19886 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/img.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5941 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/irc.py
+-rw-rw-r--   0 user      (1000) user      (1000)    17854 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/latex.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5236 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/other.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5098 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/rtf.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5888 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/svg.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5093 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/terminal.py
+-rw-rw-r--   0 user      (1000) user      (1000)    11140 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/terminal256.py
+-rw-rw-r--   0 user      (1000) user      (1000)    31818 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexer.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.652509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/
+-rw-rw-r--   0 user      (1000) user      (1000)    11505 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27311 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_asy_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    14018 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_cl_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    40001 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_cocoa_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    17504 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_csound_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)   134534 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_lasso_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8340 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_lua_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    68999 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_mapping.py
+-rw-rw-r--   0 user      (1000) user      (1000)    24737 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_mql_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    48362 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_openedge_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)   154429 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_php_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    11234 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_postgres_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    52429 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_scilab_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27137 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_sourcemod_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10481 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_stan_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    25228 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_stata_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    15484 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_tsql_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4249 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_vbscript_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    57090 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_vim_builtins.py
+-rw-rw-r--   0 user      (1000) user      (1000)    11229 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/actionscript.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1140 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/agile.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7249 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/algebra.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2605 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ambient.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4171 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ampl.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3222 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/apl.py
+-rw-rw-r--   0 user      (1000) user      (1000)    11184 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/archetype.py
+-rw-rw-r--   0 user      (1000) user      (1000)    29951 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/asm.py
+-rw-rw-r--   0 user      (1000) user      (1000)    19688 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/automation.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27648 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/basic.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4773 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/bibtex.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3990 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/boa.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27737 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/business.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10584 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/c_cpp.py
+-rw-rw-r--   0 user      (1000) user      (1000)    25176 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/c_like.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2242 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/capnproto.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3872 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/chapel.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6410 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/clean.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1865 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/compiled.py
+-rw-rw-r--   0 user      (1000) user      (1000)    32231 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/configs.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4168 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/console.py
+-rw-rw-r--   0 user      (1000) user      (1000)    16893 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/crystal.py
+-rw-rw-r--   0 user      (1000) user      (1000)    16883 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/csound.py
+-rw-rw-r--   0 user      (1000) user      (1000)    31581 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/css.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9578 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/d.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4468 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/dalvik.py
+-rw-rw-r--   0 user      (1000) user      (1000)    19104 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/data.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4921 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/diff.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27719 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/dotnet.py
+-rw-rw-r--   0 user      (1000) user      (1000)    35884 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/dsls.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10450 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/dylan.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5923 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ecl.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2530 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/eiffel.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3045 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/elm.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5303 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/email.py
+-rw-rw-r--   0 user      (1000) user      (1000)    19024 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/erlang.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9537 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/esoteric.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3092 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ezhil.py
+-rw-rw-r--   0 user      (1000) user      (1000)    17912 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/factor.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10030 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/fantom.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9456 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/felix.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2715 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/floscript.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7227 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/forth.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9889 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/fortran.py
+-rw-rw-r--   0 user      (1000) user      (1000)    26284 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/foxpro.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27182 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/freefem.py
+-rw-rw-r--   0 user      (1000) user      (1000)      818 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/functional.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3749 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/go.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6377 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/grammar_notation.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2804 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/graph.py
+-rw-rw-r--   0 user      (1000) user      (1000)    38331 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/graphics.py
+-rw-rw-r--   0 user      (1000) user      (1000)    32168 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/haskell.py
+-rw-rw-r--   0 user      (1000) user      (1000)    31007 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/haxe.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18227 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/hdl.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3555 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/hexdump.py
+-rw-rw-r--   0 user      (1000) user      (1000)    19448 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/html.py
+-rw-rw-r--   0 user      (1000) user      (1000)    15034 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/idl.py
+-rw-rw-r--   0 user      (1000) user      (1000)    30965 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/igor.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3165 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/inferno.py
+-rw-rw-r--   0 user      (1000) user      (1000)    12914 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/installers.py
+-rw-rw-r--   0 user      (1000) user      (1000)    55827 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/int_fiction.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1953 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/iolang.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4575 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/j.py
+-rw-rw-r--   0 user      (1000) user      (1000)    60360 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/javascript.py
+-rw-rw-r--   0 user      (1000) user      (1000)    14251 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/julia.py
+-rw-rw-r--   0 user      (1000) user      (1000)    70443 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/jvm.py
+-rw-rw-r--   0 user      (1000) user      (1000)   143705 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/lisp.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7398 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/make.py
+-rw-rw-r--   0 user      (1000) user      (1000)    20896 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/markup.py
+-rw-rw-r--   0 user      (1000) user      (1000)      868 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/math.py
+-rw-rw-r--   0 user      (1000) user      (1000)    30416 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/matlab.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8071 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/mime.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27925 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ml.py
+-rw-rw-r--   0 user      (1000) user      (1000)    13505 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/modeling.py
+-rw-rw-r--   0 user      (1000) user      (1000)    52633 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/modula2.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6355 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/monte.py
+-rw-rw-r--   0 user      (1000) user      (1000)    64034 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ncl.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5222 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/nimrod.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2791 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/nit.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4079 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/nix.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3781 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/oberon.py
+-rw-rw-r--   0 user      (1000) user      (1000)    22909 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/objective.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3047 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ooc.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2320 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/other.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2785 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/parasail.py
+-rw-rw-r--   0 user      (1000) user      (1000)    27854 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/parsers.py
+-rw-rw-r--   0 user      (1000) user      (1000)    32741 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/pascal.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8117 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/pawn.py
+-rw-rw-r--   0 user      (1000) user      (1000)    32084 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/perl.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10941 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/php.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3317 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/pony.py
+-rw-rw-r--   0 user      (1000) user      (1000)    12340 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/praat.py
+-rw-rw-r--   0 user      (1000) user      (1000)    12453 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/prolog.py
+-rw-rw-r--   0 user      (1000) user      (1000)    47495 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/python.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6145 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/qvt.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6327 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/r.py
+-rw-rw-r--   0 user      (1000) user      (1000)    14656 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/rdf.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18672 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/rebol.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2974 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/resource.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2038 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/rnc.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2118 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/roboconf.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18808 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/robotframework.py
+-rw-rw-r--   0 user      (1000) user      (1000)    22240 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ruby.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7786 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/rust.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9497 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/sas.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2031 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/scdoc.py
+-rw-rw-r--   0 user      (1000) user      (1000)    67884 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/scripting.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2072 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/sgf.py
+-rw-rw-r--   0 user      (1000) user      (1000)    33942 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/shell.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8594 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/slash.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7263 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/smalltalk.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2850 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/smv.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2804 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/snobol.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3303 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/solidity.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3224 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/special.py
+-rw-rw-r--   0 user      (1000) user      (1000)    31926 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/sql.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6529 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/stata.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3564 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/supercollider.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5470 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/tcl.py
+-rw-rw-r--   0 user      (1000) user      (1000)    73849 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/templates.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6358 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/teraterm.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1565 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/testflows.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10800 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/testing.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1294 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/text.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6188 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/textedit.py
+-rw-rw-r--   0 user      (1000) user      (1000)    13898 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/textfmts.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18950 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/theorem.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1594 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/trafficscript.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8272 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/typoscript.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18049 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/unicon.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5798 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/urbi.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7313 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/varnish.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3753 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/verification.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1086 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/web.py
+-rw-rw-r--   0 user      (1000) user      (1000)    40077 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/webmisc.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4060 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/whiley.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2013 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/x10.py
+-rw-rw-r--   0 user      (1000) user      (1000)      935 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/xorg.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4195 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/zig.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1010 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/modeline.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1734 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/plugin.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3094 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/regexopt.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3123 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/scanner.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4729 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/sphinxext.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5806 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/style.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/
+-rw-rw-r--   0 user      (1000) user      (1000)     2966 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)      799 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/abap.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2311 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/algol.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2326 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/algol_nu.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4540 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/arduino.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2192 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/autumn.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1610 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/borland.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1403 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/bw.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2826 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/colorful.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2580 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/default.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2534 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/emacs.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2563 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/friendly.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1346 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/fruity.py
+-rw-rw-r--   0 user      (1000) user      (1000)      787 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/igor.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2395 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/inkpot.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3221 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/lovelace.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2422 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/manni.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5134 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/monokai.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2799 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/murphy.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1986 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/native.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5689 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/paraiso_dark.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5693 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/paraiso_light.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2521 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/pastie.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2223 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/perldoc.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2528 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/rainbow_dash.py
+-rw-rw-r--   0 user      (1000) user      (1000)      900 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/rrt.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1489 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/sas.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3795 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/solarized.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1293 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/stata_dark.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1322 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/stata_light.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7144 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/tango.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1981 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/trac.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2024 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/vim.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1121 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/vs.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1549 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/xcode.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6490 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/token.py
+-rw-rw-r--   0 user      (1000) user      (1000)    64749 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/unistring.py
+-rw-rw-r--   0 user      (1000) user      (1000)    11924 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/util.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/
+-rw-rw-r--   0 user      (1000) user      (1000)     1536 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1486 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/_compat.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1779 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/asn1.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9947 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/cli.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4668 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/common.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1661 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/core.py
+-rw-rw-r--   0 user      (1000) user      (1000)    26191 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/key.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2361 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/parallel.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3976 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/pem.py
+-rw-rw-r--   0 user      (1000) user      (1000)    15539 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/pkcs1.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3448 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/pkcs1_v2.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5136 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/prime.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2695 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/randnum.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2200 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/transform.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2994 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/util.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/schema/
+-rw-rw-r--   0 user      (1000) user      (1000)    28963 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/schema/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/snowflake/
+-rw-rw-r--   0 user      (1000) user      (1000)      201 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/snowflake/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4096 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/snowflake/snowflake.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/x256/
+-rw-rw-r--   0 user      (1000) user      (1000)        0 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/x256/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4519 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/x256/x256.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/
+-rw-rw-r--   0 user      (1000) user      (1000)    13170 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4883 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/composer.py
+-rw-rw-r--   0 user      (1000) user      (1000)    28639 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/constructor.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3851 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/cyaml.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2837 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/dumper.py
+-rw-rw-r--   0 user      (1000) user      (1000)    43006 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/emitter.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2533 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/error.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2445 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/events.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2061 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/loader.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1440 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/nodes.py
+-rw-rw-r--   0 user      (1000) user      (1000)    25495 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/parser.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6794 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/reader.py
+-rw-rw-r--   0 user      (1000) user      (1000)    14184 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/representer.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8999 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/resolver.py
+-rw-rw-r--   0 user      (1000) user      (1000)    51277 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/scanner.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4165 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/serializer.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2573 2023-06-24 00:21:03.000000 testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/tokens.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/document/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/document/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2402 2023-06-23 21:23:06.000000 testflows.core-1.9.230627.1151633/testflows/_core/document/convert.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/document/new/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/document/new/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3667 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/document/new/requirements.md
+-rw-rw-r--   0 user      (1000) user      (1000)    13924 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/document/srs.py
+-rw-rw-r--   0 user      (1000) user      (1000)    40891 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/document/style.css
+-rw-rw-r--   0 user      (1000) user      (1000)     5288 2023-06-23 21:23:06.000000 testflows.core-1.9.230627.1151633/testflows/_core/document/toc.py
+-rw-rw-r--   0 user      (1000) user      (1000)      695 2023-06-23 21:23:06.000000 testflows.core-1.9.230627.1151633/testflows/_core/exceptions.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1386 2023-06-23 21:23:06.000000 testflows.core-1.9.230627.1151633/testflows/_core/filters.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5464 2023-06-23 21:23:06.000000 testflows.core-1.9.230627.1151633/testflows/_core/flags.py
+-rw-rw-r--   0 user      (1000) user      (1000)    14500 2023-06-24 01:24:24.000000 testflows.core-1.9.230627.1151633/testflows/_core/funcs.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4489 2023-06-23 21:23:06.000000 testflows.core-1.9.230627.1151633/testflows/_core/has.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7725 2023-06-23 21:44:14.000000 testflows.core-1.9.230627.1151633/testflows/_core/init.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18029 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/io.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1672 2023-06-23 21:23:06.000000 testflows.core-1.9.230627.1151633/testflows/_core/message.py
+-rw-rw-r--   0 user      (1000) user      (1000)    10492 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/name.py
+-rw-rw-r--   0 user      (1000) user      (1000)    32127 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/objects.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/parallel/
+-rw-rw-r--   0 user      (1000) user      (1000)     8200 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/parallel/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     2475 2023-06-23 21:23:06.000000 testflows.core-1.9.230627.1151633/testflows/_core/parallel/asyncio.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/
+-rw-rw-r--   0 user      (1000) user      (1000)      673 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     9857 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/asyncio.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1181 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/future.py
+-rw-rw-r--   0 user      (1000) user      (1000)    16850 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/process.py
+-rw-rw-r--   0 user      (1000) user      (1000)     6726 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/thread.py
+-rw-rw-r--   0 user      (1000) user      (1000)    38297 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/parallel/service.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1914 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/serialize.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1258 2023-06-23 21:45:19.000000 testflows.core-1.9.230627.1151633/testflows/_core/temp.py
+-rw-rw-r--   0 user      (1000) user      (1000)   128883 2023-06-24 14:34:19.000000 testflows.core-1.9.230627.1151633/testflows/_core/test.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1280 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/testtype.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8137 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/tracing.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.656509 testflows.core-1.9.230627.1151633/testflows/_core/transform/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)    19312 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/brisk.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5383 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/classic.py
+-rw-rw-r--   0 user      (1000) user      (1000)      818 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/collect.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3242 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/dots.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4968 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/fails.py
+-rw-rw-r--   0 user      (1000) user      (1000)    14796 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/flat.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18981 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/manual.py
+-rw-rw-r--   0 user      (1000) user      (1000)    18385 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/nice.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1164 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/parse.py
+-rw-rw-r--   0 user      (1000) user      (1000)    21957 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/pipeline.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1532 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/procedure.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4025 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/progress.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5088 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/quiet.py
+-rw-rw-r--   0 user      (1000) user      (1000)      905 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/raw.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1686 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/read.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1731 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/read_and_filter.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1479 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/read_raw.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)     8339 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/coverage.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4072 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/fails.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1471 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/metrics.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3448 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/passing.py
+-rw-rw-r--   0 user      (1000) user      (1000)     5391 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/results.py
+-rw-rw-r--   0 user      (1000) user      (1000)    13531 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/totals.py
+-rw-rw-r--   0 user      (1000) user      (1000)     4319 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/unstable.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1698 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/version.py
+-rw-rw-r--   0 user      (1000) user      (1000)    16275 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/short.py
+-rw-rw-r--   0 user      (1000) user      (1000)     7093 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/slick.py
+-rw-rw-r--   0 user      (1000) user      (1000)      987 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/sort.py
+-rw-rw-r--   0 user      (1000) user      (1000)      838 2023-01-26 06:02:55.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/stop.py
+-rw-rw-r--   0 user      (1000) user      (1000)      981 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/tests.py
+-rw-rw-r--   0 user      (1000) user      (1000)      810 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/values.py
+-rw-rw-r--   0 user      (1000) user      (1000)      989 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/_core/transform/log/write.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/testflows/_core/utils/
+-rw-rw-r--   0 user      (1000) user      (1000)      655 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/_core/utils/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)      772 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/utils/enum.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1142 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/utils/format.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1151 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/utils/sort.py
+-rw-rw-r--   0 user      (1000) user      (1000)      855 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/utils/string.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1590 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/utils/strip.py
+-rw-rw-r--   0 user      (1000) user      (1000)     3597 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/utils/timefuncs.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1367 2023-06-23 21:23:07.000000 testflows.core-1.9.230627.1151633/testflows/_core/utils/timer.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/testflows/core/
+-rw-rw-r--   0 user      (1000) user      (1000)     4509 2023-06-24 03:06:09.000000 testflows.core-1.9.230627.1151633/testflows/core/__init__.py
+-rw-rw-r--   0 user      (1000) user      (1000)      695 2023-01-06 01:18:17.000000 testflows.core-1.9.230627.1151633/testflows/core/exceptions.py
+-rw-rw-r--   0 user      (1000) user      (1000)      943 2023-06-23 21:23:32.000000 testflows.core-1.9.230627.1151633/testflows/core/name.py
+-rw-rw-r--   0 user      (1000) user      (1000)      844 2023-06-23 21:23:32.000000 testflows.core-1.9.230627.1151633/testflows/core/objects.py
+-rw-rw-r--   0 user      (1000) user      (1000)     1317 2023-06-23 21:23:32.000000 testflows.core-1.9.230627.1151633/testflows/core/parallel.py
+-rw-rw-r--   0 user      (1000) user      (1000)      701 2022-12-28 17:03:42.000000 testflows.core-1.9.230627.1151633/testflows/core/utils.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/testflows/exceptions/
+-rw-rw-r--   0 user      (1000) user      (1000)     2403 2023-06-23 21:23:42.000000 testflows.core-1.9.230627.1151633/testflows/exceptions/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.660509 testflows.core-1.9.230627.1151633/testflows/settings/
+-rw-rw-r--   0 user      (1000) user      (1000)     1531 2023-06-23 21:23:47.000000 testflows.core-1.9.230627.1151633/testflows/settings/__init__.py
+drwxrwxr-x   0 user      (1000) user      (1000)        0 2023-06-27 15:16:33.632509 testflows.core-1.9.230627.1151633/testflows.core.egg-info/
+-rw-rw-r--   0 user      (1000) user      (1000)      763 2023-06-27 15:16:33.000000 testflows.core-1.9.230627.1151633/testflows.core.egg-info/PKG-INFO
+-rw-rw-r--   0 user      (1000) user      (1000)    22083 2023-06-27 15:16:33.000000 testflows.core-1.9.230627.1151633/testflows.core.egg-info/SOURCES.txt
+-rw-rw-r--   0 user      (1000) user      (1000)        1 2023-06-27 15:16:33.000000 testflows.core-1.9.230627.1151633/testflows.core.egg-info/dependency_links.txt
+-rw-rw-r--   0 user      (1000) user      (1000)        1 2023-06-23 21:33:10.000000 testflows.core-1.9.230627.1151633/testflows.core.egg-info/not-zip-safe
+-rw-rw-r--   0 user      (1000) user      (1000)        7 2023-06-27 15:16:33.000000 testflows.core-1.9.230627.1151633/testflows.core.egg-info/requires.txt
+-rw-rw-r--   0 user      (1000) user      (1000)       10 2023-06-27 15:16:33.000000 testflows.core-1.9.230627.1151633/testflows.core.egg-info/top_level.txt
```

### Comparing `testflows.core-1.9.230315.1003122/LICENSE` & `testflows.core-1.9.230627.1151633/LICENSE`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/PKG-INFO` & `testflows.core-1.9.230627.1151633/PKG-INFO`

 * *Files 21% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: testflows.core
-Version: 1.9.230315.1003122
+Version: 1.9.230627.1151633
 Summary: TestFlows - Core
 Home-page: https://github.com/testflows/testflows-core
 Author: Vitaliy Zakaznikov
 Author-email: vzakaznikov@testflows.com
 License: Apache-2.0
 Classifier: Development Status :: 2 - Pre-Alpha
 Classifier: Programming Language :: Python :: 3
```

### Comparing `testflows.core-1.9.230315.1003122/setup.py` & `testflows.core-1.9.230627.1151633/setup.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 from setuptools import setup
 
 with open("README.md", "r", encoding="utf-8") as fd:
     long_description = fd.read()
 
 setup(
     name="testflows.core",
-    version="1.9.230315.1003122",
+    version="1.9.230627.1151633",
     description="TestFlows - Core",
     author="Vitaliy Zakaznikov",
     author_email="vzakaznikov@testflows.com",
     long_description=long_description,
     long_description_content_type="text/markdown",
     url="https://github.com/testflows/testflows-core",
     classifiers=[
@@ -75,25 +75,18 @@
         "testflows._core.cli.arg.handlers",
         "testflows._core.cli.arg.handlers.report",
         "testflows._core.cli.arg.handlers.report.compare",
         "testflows._core.cli.arg.handlers.transform",
         "testflows._core.cli.arg.handlers.document",
         "testflows._core.cli.arg.handlers.document.new",
         "testflows._core.cli.arg.handlers.requirement",
-        "testflows._core.cli.arg.handlers.show"
-        ],
+        "testflows._core.cli.arg.handlers.show",
+    ],
     package_data={
         "testflows._core.document": ["*.css"],
         "testflows._core.document.new": ["*.md"],
     },
-    scripts=[
-        "testflows/_core/bin/tfs",
-        "testflows/_core/bin/tfs-worker"
-    ],
+    scripts=["testflows/_core/bin/tfs", "testflows/_core/bin/tfs-worker"],
     zip_safe=False,
-    install_requires=[
-    ],
-    extras_require={
-        "dev": [
-        ]
-    }
+    install_requires=[],
+    extras_require={"dev": []},
 )
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -11,17 +11,17 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from datetime import datetime
 
 __author__ = "Vitaliy Zakaznikov"
-__version__ = "1.9.230315.1003122"
+__version__ = "1.9.230627.1151633"
 __repository__ = "https://github.com/testflows/TestFlows-Core.git"
-__commit__ = "4e67fd4923ae3d59ccc770c62e1045bcd8b06f68"
+__commit__ = "989dc1d764a4ae8cc8c16651f1bd8cb413efd2e8"
 __branch__ = "master"
 __license__ = f"""
 Copyright 2019-{datetime.now().year} Katteli Inc.
 TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/baseobject.py` & `testflows.core-1.9.230627.1151633/testflows/_core/baseobject.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,78 +13,84 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from hashlib import sha1
 from collections import namedtuple
 
 InitArgs = namedtuple("InitArgs", "args kwargs")
 
+
 def namedtuple_with_defaults(*args, defaults=()):
     nt = namedtuple(*args)
     nt.__new__.__defaults__ = defaults
     [setattr(nt, f"_{field}", idx) for idx, field in enumerate(nt._fields)]
     return nt
 
+
 def get(a, b):
-    """a if not a is None else b.
-    """
+    """a if not a is None else b."""
     return a if a is not None else b
 
+
 def hash(*s, short=False):
     """Calculate standard hash.
 
     :param s: strings
     :param short: short version, default: False
     """
-    value = sha1(''.join(s).encode("utf-8")).hexdigest()[:32]
+    value = sha1("".join(s).encode("utf-8")).hexdigest()[:32]
     if short:
         return value[-16:]
     return value
 
 
 class TestObject(object):
-    """Base class for all the test objects.
-    """
+    """Base class for all the test objects."""
+
     #: object fields used to represent state of the object
     _fields = ()
     #: defaults for the fields
     _defaults = ()
 
     def __new__(cls, *args, **kwargs):
         obj = super(TestObject, cls).__new__(cls)
-        obj.initargs=InitArgs(
-            args=[a for a in args],
-            kwargs={k: v for k,v in kwargs.items()})
+        obj.initargs = InitArgs(
+            args=[a for a in args], kwargs={k: v for k, v in kwargs.items()}
+        )
         return obj
 
     @property
     def id(self):
-        return hash(*[repr(getattr(self, field)) for field in self._fields if field != "id"])
+        return hash(
+            *[repr(getattr(self, field)) for field in self._fields if field != "id"]
+        )
 
     def __iter__(self):
         return iter([getattr(self, field) for field in self._fields])
 
     def __repr__(self):
-        """Custom object representation.
-        """
+        """Custom object representation."""
         args = ",".join([repr(arg) for arg in self.initargs.args])
-        kwargs = ",".join([name + "=" + repr(value) for name, value in self.initargs.kwargs.items()])
+        kwargs = ",".join(
+            [name + "=" + repr(value) for name, value in self.initargs.kwargs.items()]
+        )
         name = self.__class__.__name__
         if args and kwargs:
             args += ","
         return "%s(%s%s)" % (name, args, kwargs)
 
 
 class TestArg(TestObject):
-    """Base class for all test argument object.
-    """
+    """Base class for all test argument object."""
+
     pass
 
+
 class Table(tuple, TestObject):
     _fields = ("header", "rows", "row_format")
-    _defaults = (None, ) * 3
+    _defaults = (None,) * 3
     _row_type_name = "Row"
 
     def __new__(cls, header=None, rows=None, row_format=None, _row_type=None):
         if rows is None:
             rows = []
         if header is None:
             header = ""
@@ -100,24 +106,24 @@
                 return s.split("(", 1)[-1].rstrip(")") or s
 
             @property
             def __dict__(self):
                 return self._asdict()
 
         obj = super(Table, cls).__new__(cls, [Row(*row) for row in rows])
-        obj.initargs=InitArgs(
-            args=[header, rows, row_format],
-            kwargs={})
+        obj.initargs = InitArgs(args=[header, rows, row_format], kwargs={})
         obj.header = header
         obj.rows = obj
         obj.row_type = row_type
         if row_format:
             row_format % tuple(obj.header.split(" "))
         else:
-            row_format = Table.default_row_format(row_type._fields, obj[0] if obj else None)
+            row_format = Table.default_row_format(
+                row_type._fields, obj[0] if obj else None
+            )
         obj.row_format = row_format
         return obj
 
     @staticmethod
     def default_row_format(fields, row):
         # if no row_formatter is given then use the header as an example
         # or first row, whichever is longer
@@ -134,18 +140,20 @@
         return "\n".join(s)
 
     @staticmethod
     def __str_row__(row, row_format):
         return row_format % row
 
     def __str__(self):
-        """Return markdown-styled table representation.
-        """
+        """Return markdown-styled table representation."""
         s = [Table.__str_header__(self.row_type._fields, self.row_format)]
         s += [Table.__str_row__(row, self.row_format) for row in self]
         return "\n".join(s)
 
     @classmethod
     def from_table(cls, table):
-        """Creates table from a table.
-        """
-        return cls(header=" ".join(table.row_type._fields), rows=table, row_format=table.row_format)
+        """Creates table from a table."""
+        return cls(
+            header=" ".join(table.row_type._fields),
+            rows=table,
+            row_format=table.row_format,
+        )
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/bin/tfs` & `testflows.core-1.9.230627.1151633/testflows/_core/bin/tfs`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/bin/tfs-worker` & `testflows.core-1.9.230627.1151633/testflows/_core/bin/tfs-worker`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -7,8 +7,8 @@
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
-# limitations under the License.
+# limitations under the License
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/common.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/common.py`

 * *Files 5% similar despite different names*

```diff
@@ -17,49 +17,51 @@
 
 from datetime import datetime
 from argparse import RawDescriptionHelpFormatter as HelpFormatterBase
 
 from testflows._core import __version__
 from testflows._core.cli.colors import color, white, blue, cyan
 
+
 class HelpFormatter(HelpFormatterBase):
     """
     Corrected _max_action_length for the indenting of subactions
     """
-    def __init__(self,
-            prog,
-            indent_increment=2,
-            max_help_position=50,
-            width=100):
-        super(HelpFormatter, self).__init__(prog=prog, indent_increment=indent_increment,
-            max_help_position=max_help_position, width=width)
+
+    def __init__(self, prog, indent_increment=2, max_help_position=50, width=100):
+        super(HelpFormatter, self).__init__(
+            prog=prog,
+            indent_increment=indent_increment,
+            max_help_position=max_help_position,
+            width=width,
+        )
 
     def add_argument(self, action):
         if action.help is not argparse.SUPPRESS:
 
             # find all invocations
             get_invocation = self._format_action_invocation
             invocations = [get_invocation(action)]
             current_indent = self._current_indent
             for subaction in self._iter_indented_subactions(action):
                 # compensate for the indent that will be added
                 indent_chg = self._current_indent - current_indent
-                added_indent = 'x'*indent_chg
-                invocations.append(added_indent+get_invocation(subaction))
+                added_indent = "x" * indent_chg
+                invocations.append(added_indent + get_invocation(subaction))
             # print('inv', invocations)
 
             # update the maximum item length
             invocation_length = max([len(s) for s in invocations])
             action_length = invocation_length + self._current_indent
-            self._action_max_length = max(self._action_max_length,
-                                          action_length)
+            self._action_max_length = max(self._action_max_length, action_length)
 
             # add the item to the list
             self._add_item(self._format_action, [action])
 
+
 def description(description=None, prog=None, version=None):
     if version is None:
         version = __version__
 
     """Return argument parser description.
           ---- o o o ----
          |   o       o   |
@@ -80,24 +82,47 @@
     bold_cyan = functools.partial(cyan, attrs=["bold"])
 
     if description is None:
         description = ""
     if prog is None:
         prog = "Open-Source Software Testing Framework"
 
-    desc =  dim_white("  ---- ") + bold_blue("o o o") + dim_white(" ----") + "\n"
+    desc = dim_white("  ---- ") + bold_blue("o o o") + dim_white(" ----") + "\n"
     desc += dim_white(" |   ") + bold_blue("o       o") + dim_white("   |") + "\n"
-    desc += (dim_white(" | ") + bold_white("1") + bold_blue(" o ") + bold_white("10010")
-                + bold_blue(" o ") + bold_white("0 ") + dim_white("|") + "\n")
-    desc += (dim_white(" |   ") + bold_blue("o       o") + dim_white("   |")
-             + dim_white("    TestFlows.com %s v%s" % (prog, version)) + "\n")
-    desc += (dim_white("  ---  ") + bold_blue("o o o") + bold_cyan("xx ") + dim_white("--") + "\n")
-    desc += (dim_white(" /           ") + bold_cyan("xx") + dim_white("   \\") + "\n")
-    desc += (dim_white("/  ^^^        ") + bold_cyan("xx") + dim_white("   \\") + "\n")
-    desc += (dim_white(" ------------------") + "\n")
+    desc += (
+        dim_white(" | ")
+        + bold_white("1")
+        + bold_blue(" o ")
+        + bold_white("10010")
+        + bold_blue(" o ")
+        + bold_white("0 ")
+        + dim_white("|")
+        + "\n"
+    )
+    desc += (
+        dim_white(" |   ")
+        + bold_blue("o       o")
+        + dim_white("   |")
+        + dim_white("    TestFlows.com %s v%s" % (prog, version))
+        + "\n"
+    )
+    desc += (
+        dim_white("  ---  ")
+        + bold_blue("o o o")
+        + bold_cyan("xx ")
+        + dim_white("--")
+        + "\n"
+    )
+    desc += dim_white(" /           ") + bold_cyan("xx") + dim_white("   \\") + "\n"
+    desc += dim_white("/  ^^^        ") + bold_cyan("xx") + dim_white("   \\") + "\n"
+    desc += dim_white(" ------------------") + "\n"
     if description:
         desc += "\n\n" + description
     return desc
 
+
 def epilog():
     """Return argument parser epilog"""
-    return white(f"TestFlows.com Open-Source Software Testing Framework. Copyright (c) {datetime.now().year} Katteli Inc.\nSee contrib folder in sources for lincenses of each third-party module.", attrs=["dim"])
+    return white(
+        f"TestFlows.com Open-Source Software Testing Framework. Copyright (c) {datetime.now().year} Katteli Inc.\nSee contrib folder in sources for lincenses of each third-party module.",
+        attrs=["dim"],
+    )
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/exit.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/exit.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,31 +10,39 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License
 __all__ = ["ExitException", "ExitWithError", "ExitWithWarning", "ExitWithSuccess"]
 
+
 class ExitException(Exception):
     """Base class for all exit exceptions.
 
     :param exitcode: exit code
     """
+
     def __init__(self, exitcode, message):
         self.exitcode = exitcode
         self.message = message
         super(ExitException, self).__init__(message)
 
+
 class ExitWithError(ExitException):
     """Exit with error exception."""
+
     def __init__(self, message, exitcode=1):
         super(ExitWithError, self).__init__(exitcode, message)
 
+
 class ExitWithWarning(ExitException):
     """Exit with warning exception."""
+
     def __init__(self, message, exitcode=0):
         super(ExitWithWarning, self).__init__(exitcode, message)
 
+
 class ExitWithSuccess(ExitException):
     """Exit with success exception."""
+
     def __init__(self, message, exitcode=0):
-        super(ExitWithSuccess, self).__init__(exitcode, message)
+        super(ExitWithSuccess, self).__init__(exitcode, message)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/convert.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/dots.py`

 * *Files 17% similar despite different names*

```diff
@@ -13,30 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.document.convert import generate, stylesheet
-from testflows._core.contrib.markdown2 import Markdown
+from testflows._core.transform.log.pipeline import DotsLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("convert", help="convert document", epilog=epilog(),
-            description="Convert markdown document.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.file("r", bufsize=1, encoding="utf-8"),
-            nargs="?", help="input file, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-            nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("-f", "--format", metavar="format", type=str, help="format, default: html",
-            choices=["html"], default="html")
-        parser.add_argument("-s", "--stylesheet", metavar="css", type=argtype.file("r", bufsize=1, encoding="utf-8"),
-            help="custom stylesheet", default=stylesheet)
+        parser = commands.add_parser(
+            "dots",
+            help="dots transform",
+            epilog=epilog(),
+            description="Transform log into a dots format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        generate(args.input, args.output, args.stylesheet, args.format)
+        DotsLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/handler.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/handler.py`

 * *Files 9% similar despite different names*

```diff
@@ -15,25 +15,32 @@
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.cli.arg.handlers.document.convert import Handler as convert_handler
 from testflows._core.cli.arg.handlers.document.toc import Handler as toc_handler
 from testflows._core.cli.arg.handlers.document.new.handler import Handler as new_handler
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("document", help="document processing", epilog=epilog(),
+        parser = commands.add_parser(
+            "document",
+            help="document processing",
+            epilog=epilog(),
             description="Work with a document.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        document_commands = parser.add_subparsers(title="commands", metavar="command",
-            description=None, help=None)
+        document_commands = parser.add_subparsers(
+            title="commands", metavar="command", description=None, help=None
+        )
         document_commands.required = True
         convert_handler.add_command(document_commands)
         toc_handler.add_command(document_commands)
         new_handler.add_command(document_commands)
         try:
             from testflows.texts.run import Handler as run_handler
+
             run_handler.add_command(document_commands)
         except ImportError:
             pass
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/new/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/new/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/new/handler.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/new/handler.py`

 * *Files 5% similar despite different names*

```diff
@@ -11,21 +11,29 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.cli.arg.handlers.document.new.requirements import Handler as requirements_handler
+from testflows._core.cli.arg.handlers.document.new.requirements import (
+    Handler as requirements_handler,
+)
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("new", help="create new document", epilog=epilog(),
+        parser = commands.add_parser(
+            "new",
+            help="create new document",
+            epilog=epilog(),
             description="Create new document.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        new_commands = parser.add_subparsers(title="commands", metavar="command",
-            description=None, help=None)
+        new_commands = parser.add_subparsers(
+            title="commands", metavar="command", description=None, help=None
+        )
         new_commands.required = True
 
         requirements_handler.add_command(new_commands)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/new/requirements.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/fails.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,48 +1,61 @@
-# Copyright 2020 Katteli Inc.
+# Copyright 2019 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import os
-import datetime
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
+from testflows._core.transform.log.pipeline import FailsReportLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("requirements", help="software requirements specification", epilog=epilog(),
-            description="Create new software requirements specification document.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-            nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("--number", metavar="number", type=str, help="document number", default="001")
-        parser.add_argument("--title", metavar="name", type=str, help="document title", default="Template")
-        parser.add_argument("--author", metavar="name", type=str, help="name of the author", default="*[author]*")
-        parser.add_argument("--date", metavar="date", type=str, help="document date", default=f"{datetime.datetime.now():%B %d, %Y}")
+        parser = commands.add_parser(
+            "fails",
+            help="fails",
+            epilog=epilog(),
+            description="Show only failed tests.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "-n",
+            "--new",
+            action="store_true",
+            help="show only new fails",
+            default=False,
+        )
+
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        template_dir = os.path.join(os.path.dirname(__file__), "..", "..", "..", "..", "..", "document", "new")
-
-        with open(os.path.join(template_dir, "requirements.md")) as fd:
-            template = fd.read()
-
-        args.output.write(template.format(
-            number=args.number,
-            title=args.title,
-            author=args.author,
-            date=args.date))
+        FailsReportLogPipeline(args.input, args.output, only_new=args.new).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/document/toc.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/requirement/generate.py`

 * *Files 18% similar despite different names*

```diff
@@ -8,42 +8,47 @@
 #      http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import tempfile
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.document.toc import generate
+from testflows._core.document.srs import generate
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("toc", help="generate table of contents", epilog=epilog(),
-            description="Genarate table of contents for a document.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.file("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input file, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=str,
-                nargs="?", help='output file, default: stdout', default="-")
-
-        parser.add_argument("--heading", metavar="name", type=str, default="Table of Contents",
-                help="table of contents heading name, default: 'Table of Contents'")
-        parser.add_argument("-u", "--update", action="store_true", default=False,
-                help="output original document with an updated table of contents")
+        parser = commands.add_parser(
+            "generate",
+            help="generate requirements",
+            epilog=epilog(),
+            description="Generate requirements from an SRS document.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.file("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input file, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        with tempfile.TemporaryFile("w+", encoding="utf-8") as temporary_file:
-            generate(args.input, temporary_file, args.heading, args.update)
-            output = argtype.file("w", encoding="utf-8")(args.output)
-            temporary_file.flush()
-            temporary_file.seek(0)
-            output.write(temporary_file.read())
-            output.flush()
+        generate(args.input, args.output)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/handler.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/handler.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/log.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/log.py`

 * *Files 13% similar despite different names*

```diff
@@ -10,41 +10,56 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import glob
-import tempfile
 
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.templog import parser as templog_parser, dirname as templog_dirname, ppid_glob as templog_glob
+from testflows._core.temp import (
+    parser as temp_parser,
+    dirname as temp_dirname,
+    ppid_glob as temp_glob,
+)
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("log", help="retrieve last temporary test log", epilog=epilog(),
+        parser = commands.add_parser(
+            "log",
+            help="retrieve last temporary test log",
+            epilog=epilog(),
             description="Retrieve last temporary test log.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("output", metavar="output", type=argtype.file("wb"), help='output file, stdout: \'-\'')
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("wb"),
+            help="output file, stdout: '-'",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
         ppid = os.getppid()
 
         found = False
 
-        for file in sorted(glob.glob(os.path.join(templog_dirname(), templog_glob(ppid))), reverse=True):
-            match = templog_parser.match(file)
+        for file in sorted(
+            glob.glob(os.path.join(temp_dirname(), temp_glob(ppid))), reverse=True
+        ):
+            match = temp_parser(extension="log").match(file)
             if not match:
                 continue
 
             found = True
             with argtype.file("rb")(file) as fd:
                 args.output.write(fd.read())
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/document/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/command.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/command.py`

 * *Files 6% similar despite different names*

```diff
@@ -52,39 +52,42 @@
 
 ---
 Generated by {testflows} Open-Source Test Framework
 
 [<span class="logo-test">Test</span><span class="logo-flows">Flows</span>]: https://testflows.com
 """
 
+
 class Formatter:
     def format_logo(self, data):
         if not data["company"].get("logo"):
             return ""
         data = base64.b64encode(data["company"]["logo"]).decode("utf-8")
-        return '\n<p>' + logo % {"data": data} + "</p>\n"
+        return "\n<p>" + logo % {"data": data} + "</p>\n"
 
     def format_confidential(self, data):
         if not data["company"].get("confidential"):
             return ""
         return f'\n<p class="confidential">Document status - Confidential</p>\n'
 
     def format_copyright(self, data):
         if not data["company"].get("name"):
             return ""
-        return (f'\n<p class="copyright">\n'
+        return (
+            f'\n<p class="copyright">\n'
             f'{copyright(data["company"]["name"])}\n'
-            "</p>\n")
+            "</p>\n"
+        )
 
     def format_metadata(self, data):
         metadata = data["metadata"]
         s = (
             "\n\n"
             f"||**Date**||{localfromtimestamp(metadata['date']):%b %d, %Y %-H:%M}||\n"
-            f'||**Framework**||'
+            f"||**Framework**||"
             f'{testflows} {metadata["version"]}||\n'
         )
         if metadata.get("order-by"):
             s += f'||**Order By**||{metadata["order-by"].capitalize()}||\n'
         if metadata.get("sort"):
             s += f'||**Sort**||{"Ascending" if metadata["sort"] == "asc" else "Descending"}||\n'
         if metadata.get("filter"):
@@ -106,17 +109,28 @@
         s = "\n\n## Comparison\n\n"
         # comparison table
         s += " | ".join(table["header"]) + "\n"
         s += " | ".join(["---"] * len(table["header"])) + "\n"
         span = '<span class="result result-%(cls)s">%(name)s</span>'
         for row in table["rows"]:
             name, *results = row
-            s += " | ".join([name] + [
-                span % {'cls': result["result_type"].lower() if result else 'na', 'name': result["result_type"] if result else '-'} for result in results
-            ]) + "\n"
+            s += (
+                " | ".join(
+                    [name]
+                    + [
+                        span
+                        % {
+                            "cls": result["result_type"].lower() if result else "na",
+                            "name": result["result_type"] if result else "-",
+                        }
+                        for result in results
+                    ]
+                )
+                + "\n"
+            )
         return s
 
     def format_chart(self, data):
         script = """
         window.onload = function() {
             window.chart = c3.generate({
                 bindto: '#data-chart',
@@ -169,78 +183,122 @@
             });
         };
         """
         script = script % {
             "ok": ",".join([str(c) for c in data["chart"]["ok"]]),
             "fail": ",".join([str(c) for c in data["chart"]["fail"]]),
             "known": ",".join([str(c) for c in data["chart"]["known"]]),
-            "values": ",".join([f"'{str(c)}'" for c in data["chart"]["x"]])
+            "values": ",".join([f"'{str(c)}'" for c in data["chart"]["x"]]),
         }
 
         s = (
-            '\n\n## Chart\n\n'
+            "\n\n## Chart\n\n"
             '<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/5.15.0/d3.min.js"></script>\n'
             '<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/c3/0.7.12/c3.min.css">\n'
             '<script src="https://cdnjs.cloudflare.com/ajax/libs/c3/0.7.12/c3.min.js"></script>\n'
             '<div><div id="data-chart"></div></div>\n'
-            '<script>\n'
-            f'{script}\n'
-            '</script>'
+            "<script>\n"
+            f"{script}\n"
+            "</script>"
         )
         return s
 
     def format(self, data):
         body = self.format_metadata(data)
         body += self.format_reference(data)
         body += self.format_chart(data)
         body += self.format_table(data)
         return template.strip() % {
             "title": "Results",
             "logo": self.format_logo(data),
             "confidential": self.format_confidential(data),
             "copyright": self.format_copyright(data),
-            "body": body
+            "body": body,
         }
 
+
 class Handler(HandlerBase):
     Formatter = NotImplementedError
 
     @classmethod
     def add_arguments(cls, parser):
-        parser.add_argument("--log", metavar="pattern", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-            nargs="+", help="log file pattern", required=True)
-        parser.add_argument("--log-link", metavar="attribute",
+        parser.add_argument(
+            "--log",
+            metavar="pattern",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="+",
+            help="log file pattern",
+            required=True,
+        )
+        parser.add_argument(
+            "--log-link",
+            metavar="attribute",
             help="attribute that is used as a link for the log, default: job.url",
-            type=str, default="job.url")
-        parser.add_argument("--only", metavar="pattern", nargs="+",
-            help="compare only selected tests", type=str, required=False)
-        parser.add_argument("--order-by", metavar="attribute", type=str,
-            help="attribute that is used to order the logs")
-        parser.add_argument("--sort", metavar="direction", type=str,
-            help="sort direction. Either 'asc' or 'desc', default: asc", choices=["asc", "desc"], default="asc")
-        parser.add_argument("--format", metavar="type", type=str,
-            help="output format, default: md (Markdown)", choices=["md"], default="md")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-            nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("--copyright", metavar="name", help="add copyright notice", type=str)
-        parser.add_argument("--confidential", help="mark as confidential", action="store_true")
-        parser.add_argument("--logo", metavar="path", type=argtype.file("rb"),
-                help='use logo image (.png)')
+            type=str,
+            default="job.url",
+        )
+        parser.add_argument(
+            "--only",
+            metavar="pattern",
+            nargs="+",
+            help="compare only selected tests",
+            type=str,
+            required=False,
+        )
+        parser.add_argument(
+            "--order-by",
+            metavar="attribute",
+            type=str,
+            help="attribute that is used to order the logs",
+        )
+        parser.add_argument(
+            "--sort",
+            metavar="direction",
+            type=str,
+            help="sort direction. Either 'asc' or 'desc', default: asc",
+            choices=["asc", "desc"],
+            default="asc",
+        )
+        parser.add_argument(
+            "--format",
+            metavar="type",
+            type=str,
+            help="output format, default: md (Markdown)",
+            choices=["md"],
+            default="md",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "--copyright", metavar="name", help="add copyright notice", type=str
+        )
+        parser.add_argument(
+            "--confidential", help="mark as confidential", action="store_true"
+        )
+        parser.add_argument(
+            "--logo",
+            metavar="path",
+            type=argtype.file("rb"),
+            help="use logo image (.png)",
+        )
 
     def chart(self, counts):
-        chart = {
-            "ok": [],
-            "fail": [],
-            "known": [],
-            "x": []
-        }
+        chart = {"ok": [], "fail": [], "known": [], "x": []}
         for counts in reversed(list(counts.values())):
             chart["ok"].append(counts.ok)
             chart["fail"].append(counts.fail + counts.error + counts.null)
-            chart["known"].append(counts.xok + counts.xfail + counts.xerror + counts.xnull)
+            chart["known"].append(
+                counts.xok + counts.xfail + counts.xerror + counts.xnull
+            )
             chart["x"].append(counts.reference)
         return chart
 
     def get_attribute(self, result, name, default=None):
         tests = list(result["tests"].values())
 
         if not tests:
@@ -307,66 +365,81 @@
 
         if direction == "desc":
             key_order = reversed(key_order)
 
         for i, key in enumerate(key_order):
             _results[key] = results[key]
             ref = order_key(key)
-            ref[-1] = f'{localfromtimestamp(ref[-1]):%b %d, %-H:%M}'
+            ref[-1] = f"{localfromtimestamp(ref[-1]):%b %d, %-H:%M}"
             if order_by:
-                ref = f'{ref[0]}, {ref[-1]}'
+                ref = f"{ref[0]}, {ref[-1]}"
             else:
                 ref = ref[-1]
             _results[key]["reference"] = ref
         return _results
 
     def tests(self, results):
         tests = []
         for r in results.values():
             for uname, test in r["tests"].items():
                 if getattr(TestType, test["test"]["test_type"]) < TestType.Test:
                     continue
                 if test["test"].get("test_parent_type"):
-                    if getattr(TestType, test["test"]["test_parent_type"]) < TestType.Suite:
+                    if (
+                        getattr(TestType, test["test"]["test_parent_type"])
+                        < TestType.Suite
+                    ):
                         continue
                 if Flags(test["test"]["test_cflags"]) & RETRY:
                     continue
                 tests.append(uname)
         return human(list(set(tests)))
 
     def table(self, tests, results, ref_link=None):
         table = {
-            "header": ["Test Name"] + [f'<a href="#ref-{results[r]["reference"]}">{results[r]["reference"]}</a>' for r in results],
+            "header": ["Test Name"]
+            + [
+                f'<a href="#ref-{results[r]["reference"]}">{results[r]["reference"]}</a>'
+                for r in results
+            ],
             "rows": [],
             "reference": {
                 "header": ["Reference", "Link"],
-                "rows": [[f'<span id="ref-{results[r]["reference"]}"><strong>{results[r]["reference"]}</strong></span>', self.get_attribute(results[r], str(ref_link), r)] for r in results]
+                "rows": [
+                    [
+                        f'<span id="ref-{results[r]["reference"]}"><strong>{results[r]["reference"]}</strong></span>',
+                        self.get_attribute(results[r], str(ref_link), r),
+                    ]
+                    for r in results
+                ],
             },
         }
 
         if not tests:
             table["rows"].append([""] * len(results.values()))
 
         for test in tests:
             row = [test]
             for result in results.values():
-                if result["tests"].get(test) and result["tests"].get(test).get("result"):
+                if result["tests"].get(test) and result["tests"].get(test).get(
+                    "result"
+                ):
                     row.append(result["tests"].get(test)["result"])
                 else:
                     row.append(None)
             table["rows"].append(row)
         return table
 
     def metadata(self, only, order_by, direction):
         return {
             "date": time.time(),
             "version": __version__,
             "order-by": order_by,
             "sort": direction,
-            "filter": (" ".join(only) if only else "None")
+            "filter": (" ".join(only) if only else "None"),
         }
 
     def company(self, args):
         d = {}
         if args.copyright:
             d["name"] = args.copyright
         if args.confidential:
@@ -384,17 +457,15 @@
         d["chart"] = self.chart(d["counts"])
         d["metadata"] = self.metadata(args.only, args.order_by, args.sort)
         d["company"] = self.company(args)
         return d
 
     def generate(self, formatter, results, args):
         output = args.output
-        output.write(
-            formatter.format(self.data(results, args))
-        )
+        output.write(formatter.format(self.data(results, args)))
         output.write("\n")
 
     def handle(self, args):
         results = {}
         threads = []
 
         def thread_worker(log, results):
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/handler.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/handler.py`

 * *Files 17% similar despite different names*

```diff
@@ -11,23 +11,33 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.cli.arg.handlers.report.compare.results import Handler as results_handler
-from testflows._core.cli.arg.handlers.report.compare.metrics import Handler as metrics_handler
+from testflows._core.cli.arg.handlers.report.compare.results import (
+    Handler as results_handler,
+)
+from testflows._core.cli.arg.handlers.report.compare.metrics import (
+    Handler as metrics_handler,
+)
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("compare", help="comparison report", epilog=epilog(),
+        parser = commands.add_parser(
+            "compare",
+            help="comparison report",
+            epilog=epilog(),
             description="Generate comparison report between runs.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        report_commands = parser.add_subparsers(title="commands", metavar="command",
-            description=None, help=None)
+        report_commands = parser.add_subparsers(
+            title="commands", metavar="command", description=None, help=None
+        )
         report_commands.required = True
 
         results_handler.add_command(report_commands)
         metrics_handler.add_command(report_commands)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/metrics.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/metrics.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,26 +13,31 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import datetime
 
 from testflows._core.utils.format import bytesize
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
-from testflows._core.cli.arg.handlers.report.compare.command import Handler as HandlerBase
-from testflows._core.cli.arg.handlers.report.compare.command import Formatter as FormatterBase
+from testflows._core.cli.arg.handlers.report.compare.command import (
+    Handler as HandlerBase,
+)
+from testflows._core.cli.arg.handlers.report.compare.command import (
+    Formatter as FormatterBase,
+)
 from testflows._core.cli.arg.handlers.report.compare.command import template, testflows
 from testflows._core.utils.timefuncs import localfromtimestamp, strftimedelta
 
+
 class Formatter(FormatterBase):
     def format_metadata(self, data):
         metadata = data["metadata"]
         s = (
             "\n\n"
             f"||**Date**||{localfromtimestamp(metadata['date']):%b %d, %Y %-H:%M}||\n"
-            f'||**Framework**||'
+            f"||**Framework**||"
             f'{testflows} {metadata["version"]}||\n'
         )
         if metadata.get("metrics"):
             s += f'||**Metrics**||{", ".join(metadata["metrics"])}||\n'
         if metadata.get("order-by"):
             s += f'||**Order By**||{metadata["order-by"].capitalize()}||\n'
         if metadata.get("sort"):
@@ -46,17 +51,28 @@
         s = "\n\n## Comparison\n\n"
         # comparison table
         s += " | ".join(table["header"]) + "\n"
         s += " | ".join(["---"] * len(table["header"])) + "\n"
         span = '<span class="result result-%(cls)s">%(value)s</span>'
         for row in table["rows"]:
             name, *results = row
-            s += " | ".join([name] + [
-                span % {'cls': result["result_type"].lower() if result else 'na', 'value': table["value"](result) if result else '-'} for result in results
-            ]) + "\n"
+            s += (
+                " | ".join(
+                    [name]
+                    + [
+                        span
+                        % {
+                            "cls": result["result_type"].lower() if result else "na",
+                            "value": table["value"](result) if result else "-",
+                        }
+                        for result in results
+                    ]
+                )
+                + "\n"
+            )
         return s
 
     def format_chart(self, data):
         return ""
 
     def format(self, data):
         body = self.format_metadata(data)
@@ -64,28 +80,39 @@
         body += self.format_chart(data)
         body += self.format_table(data)
         return template.strip() % {
             "title": "Metrics",
             "logo": self.format_logo(data),
             "confidential": self.format_confidential(data),
             "copyright": self.format_copyright(data),
-            "body": body
+            "body": body,
         }
 
+
 class Handler(HandlerBase):
     Formatter = Formatter
 
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("metrics", help="metrics report", epilog=epilog(),
+        parser = commands.add_parser(
+            "metrics",
+            help="metrics report",
+            epilog=epilog(),
             description="Generate metrics comparison report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
         cls.add_arguments(parser)
-        parser.add_argument("--name", metavar="name", type=str,
-            nargs="+", help="metrics name, default: test-time", default=["test-time"])
+        parser.add_argument(
+            "--name",
+            metavar="name",
+            type=str,
+            nargs="+",
+            help="metrics name, default: test-time",
+            default=["test-time"],
+        )
         parser.set_defaults(func=cls())
 
     def metadata(self, only, order_by, direction, metrics):
         m = super(Handler, self).metadata(only, order_by, direction)
         m["metrics"] = metrics
         return m
 
@@ -99,21 +126,27 @@
         d["metadata"] = self.metadata(args.only, args.order_by, args.sort, args.name)
         d["company"] = self.company(args)
 
         def table_value(result):
             metrics = []
             for name in args.name:
                 if name == "test-time":
-                   metrics.append(strftimedelta(result["message_rtime"]))
+                    metrics.append(strftimedelta(result["message_rtime"]))
                 else:
                     for metric in result["metrics"]:
                         if metric["metric_name"] == name:
                             if metric["metric_units"] == "ms":
-                                metrics.append(f'{(int(metric["metric_value"]) / 1000.0)}s')
+                                metrics.append(
+                                    f'{(int(metric["metric_value"]) / 1000.0)}s'
+                                )
                             elif metric["metric_units"] == "bytes":
-                                metrics.append(f'{bytesize(int(metric["metric_value"]))}')
+                                metrics.append(
+                                    f'{bytesize(int(metric["metric_value"]))}'
+                                )
                             else:
-                                metrics.append(f'{metric["metric_value"]} {metric["metric_units"]}')
+                                metrics.append(
+                                    f'{metric["metric_value"]} {metric["metric_units"]}'
+                                )
             return str("<br>".join(metrics)) if metrics else "-"
 
         d["table"]["value"] = table_value
         return d
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/compare/results.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/compare/results.py`

 * *Files 7% similar despite different names*

```diff
@@ -10,35 +10,45 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
-from testflows._core.cli.arg.handlers.report.compare.command import Handler as HandlerBase
-from testflows._core.cli.arg.handlers.report.compare.command import Formatter as FormatterBase
+from testflows._core.cli.arg.handlers.report.compare.command import (
+    Handler as HandlerBase,
+)
+from testflows._core.cli.arg.handlers.report.compare.command import (
+    Formatter as FormatterBase,
+)
 from testflows._core.cli.arg.handlers.report.compare.command import template
 
+
 class Formatter(FormatterBase):
     def format(self, data):
         body = self.format_metadata(data)
         body += self.format_reference(data)
         body += self.format_chart(data)
         body += self.format_table(data)
         return template.strip() % {
             "title": "Results",
             "logo": self.format_logo(data),
             "confidential": self.format_confidential(data),
             "copyright": self.format_copyright(data),
-            "body": body
+            "body": body,
         }
 
+
 class Handler(HandlerBase):
     Formatter = Formatter
 
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("results", help="results report", epilog=epilog(),
+        parser = commands.add_parser(
+            "results",
+            help="results report",
+            epilog=epilog(),
             description="Generate results comparison report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
         cls.add_arguments(parser)
         parser.set_defaults(func=cls())
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/copyright.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/copyright.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,17 +10,18 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from datetime import datetime
 
+
 def copyright(name):
     return f"""
 Copyright {datetime.now().year}, {name}. All Rights Reserved.
 
 All information contained herein is, and remains
 the property of {name}.
 Any dissemination of this information or
 reproduction of this material is strictly forbidden
 unless prior written permission is obtained from {name}.
-"""
+"""
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/coverage.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/coverage.py`

 * *Files 11% similar despite different names*

```diff
@@ -80,51 +80,50 @@
                 item.nextElementSibling.classList.toggle('show');
                 item.classList.toggle('active');
             });
         });
 }
 """
 
+
 class Formatter:
-    utf_icons = {
-        "satisfied": "\u2714",
-        "unsatisfied": "\u2718",
-        "untested": "\u270E"
-    }
+    utf_icons = {"satisfied": "\u2714", "unsatisfied": "\u2718", "untested": "\u270E"}
 
     icon_colors = {
         "satisfied": "color-ok",
         "unsatisfied": "color-fail",
-        "untested": "color-error"
+        "untested": "color-error",
     }
 
     def format_logo(self, data):
         if not data["company"].get("logo"):
             return ""
         data = base64.b64encode(data["company"]["logo"]).decode("utf-8")
-        return '\n<p>' + logo % {"data": data} + "</p>\n"
+        return "\n<p>" + logo % {"data": data} + "</p>\n"
 
     def format_confidential(self, data):
         if not data["company"].get("confidential"):
             return ""
         return f'\n<p class="confidential">Document status - Confidential</p>\n'
 
     def format_copyright(self, data):
         if not data["company"].get("name"):
             return ""
-        return (f'\n<p class="copyright">\n'
+        return (
+            f'\n<p class="copyright">\n'
             f'{copyright(data["company"]["name"])}\n'
-            "</p>\n")
+            "</p>\n"
+        )
 
     def format_metadata(self, data):
         metadata = data["metadata"]
         s = (
             "\n\n"
             f"||**Date**||{localfromtimestamp(metadata['date']):%b %d, %Y %-H:%M}||\n"
-            f'||**Framework**||'
+            f"||**Framework**||"
             f'{testflows} {metadata["version"]}||\n'
         )
         return s + "\n"
 
     def format_summary(self, data):
         counts = data["counts"]
 
@@ -132,59 +131,76 @@
             p_value = value / float(units) * 100
             if p_value > 1:
                 value = f"{p_value:.1f}".rstrip("0").rstrip(".") + "%"
             else:
                 value = f"<1%"
             return (
                 f'<div class="c100 p{math.floor(p_value):.0f} {color} smaller-title">'
-                    f'<span>{value}</span>'
-                    f'<span class="title">{title}</span>'
-                    '<div class="slice">'
-                        '<div class="bar"></div>'
-                        '<div class="fill"></div>'
-                    '</div>'
-                '</div>\n')
+                f"<span>{value}</span>"
+                f'<span class="title">{title}</span>'
+                '<div class="slice">'
+                '<div class="bar"></div>'
+                '<div class="fill"></div>'
+                "</div>"
+                "</div>\n"
+            )
 
         s = "\n## Summary\n"
         if counts.units <= 0:
             s += "No tests"
         else:
             s += '<div class="chart">'
             if counts.satisfied > 0:
                 s += template(counts.satisfied, counts.units, "Satisfied", "green")
             if counts.unsatisfied > 0:
                 s += template(counts.unsatisfied, counts.units, "Unsatisfied", "red")
             if counts.untested > 0:
                 s += template(counts.untested, counts.units, "Untested", "orange")
-            s += '</div>\n'
+            s += "</div>\n"
         return s
 
     def format_statistics(self, data):
         counts = data["counts"]
-        result_map = {
-            "OK": "Satisfied",
-            "Fail": "Unsatisfied",
-            "Error": "Untested"
-        }
+        result_map = {"OK": "Satisfied", "Fail": "Unsatisfied", "Error": "Untested"}
         s = "\n\n## Statistics\n"
-        s += "||" + "||".join(
-            ["<span></span>", "Units"]
-            + [f'<span class="result result-{k.lower()}">{v}</span>' for k, v in result_map.items()]
-        ) + "||\n"
-        s += "||" + "||".join([f"<center>{i}</center>" for i in ["**Requirements**",
-                str(counts.units), str(counts.satisfied),
-                str(counts.unsatisfied), str(counts.untested)]]) + "||\n"
+        s += (
+            "||"
+            + "||".join(
+                ["<span></span>", "Units"]
+                + [
+                    f'<span class="result result-{k.lower()}">{v}</span>'
+                    for k, v in result_map.items()
+                ]
+            )
+            + "||\n"
+        )
+        s += (
+            "||"
+            + "||".join(
+                [
+                    f"<center>{i}</center>"
+                    for i in [
+                        "**Requirements**",
+                        str(counts.units),
+                        str(counts.satisfied),
+                        str(counts.unsatisfied),
+                        str(counts.untested),
+                    ]
+                ]
+            )
+            + "||\n"
+        )
         return s + "\n"
 
     def format_table(self, data):
         reqs = data["requirements"]
         s = "\n\n## Coverage\n"
         for r in reqs.values():
             s += f'\n<section class="requirement"><span class="requirement-inline"><i class="utf-icon {self.icon_colors[r["status"]]}">{self.utf_icons[r["status"]]}</i>{r["requirement"].name}</span></section>'
-            description = r["requirement"].description.replace("\\n","\n")
+            description = r["requirement"].description.replace("\\n", "\n")
             if description:
                 s += f'\n<div markdown="1" class="requirement-description hidden">\n{description}\n</div>'
             for test in r["tests"]:
                 result = test["result"]
                 cls = result["result_type"].lower()
                 s += f'\n<div class="test"><span class="result result-inline result-{cls}">{result["result_type"]}</span><span class="time time-inline">{strftimedelta(result["message_rtime"])}</span>{test["test"]["test_name"]}</div>'
                 s += f'\n<div class="test-procedure hidden">\n```testflows\n{test["messages"]}\n```\n</div>'
@@ -206,58 +222,113 @@
         body += self.format_table(data)
         return template.strip() % {
             "logo": self.format_logo(data),
             "confidential": self.format_confidential(data),
             "copyright": self.format_copyright(data),
             "body": body,
             "script": script,
-            "title": self.format_title(data)
+            "title": self.format_title(data),
         }
 
+
 class Counts(object):
     def __init__(self, name, units, satisfied, unsatisfied, untested):
         self.name = name
         self.units = units
         self.satisfied = satisfied
         self.unsatisfied = unsatisfied
         self.untested = untested
 
     def __bool__(self):
         return self.units > 0
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("coverage", help="requirements coverage report", epilog=epilog(),
+        parser = commands.add_parser(
+            "coverage",
+            help="requirements coverage report",
+            epilog=epilog(),
             description="Generate requirements coverage report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("requirements", metavar="requirements", type=partial(argtype.path, special=["-"]),
-                help="requirements source file, default: '-' (from input log)", nargs="?", default="-")
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("--show", metavar="status", type=str, nargs="+", help="verification status. Choices: 'satisfied', 'unsatisfied', 'untested'",
+        parser.add_argument(
+            "requirements",
+            metavar="requirements",
+            type=partial(argtype.path, special=["-"]),
+            help="requirements source file, default: '-' (from input log)",
+            nargs="?",
+            default="-",
+        )
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "--show",
+            metavar="status",
+            type=str,
+            nargs="+",
+            help="verification status. Choices: 'satisfied', 'unsatisfied', 'untested'",
             choices=["satisfied", "unsatisfied", "untested"],
-            default=["satisfied", "unsatisfied", "untested"])
-        parser.add_argument("--input-link", metavar="attribute",
+            default=["satisfied", "unsatisfied", "untested"],
+        )
+        parser.add_argument(
+            "--input-link",
+            metavar="attribute",
             help="attribute that is used as a link to the input log, default: job.url",
-            type=str, default="job.url")
-        parser.add_argument("--format", metavar="type", type=str,
-            help="output format, default: md (Markdown)", choices=["md"], default="md")
-        parser.add_argument("--copyright", metavar="name", help="add copyright notice", type=str)
-        parser.add_argument("--confidential", help="mark as confidential", action="store_true")
-        parser.add_argument("--logo", metavar="path", type=argtype.file("rb"),
-                help='use logo image (.png)')
+            type=str,
+            default="job.url",
+        )
+        parser.add_argument(
+            "--format",
+            metavar="type",
+            type=str,
+            help="output format, default: md (Markdown)",
+            choices=["md"],
+            default="md",
+        )
+        parser.add_argument(
+            "--copyright", metavar="name", help="add copyright notice", type=str
+        )
+        parser.add_argument(
+            "--confidential", help="mark as confidential", action="store_true"
+        )
+        parser.add_argument(
+            "--logo",
+            metavar="path",
+            type=argtype.file("rb"),
+            help="use logo image (.png)",
+        )
         parser.add_argument("--title", metavar="name", help="custom title", type=str)
-        parser.add_argument("--only", metavar="name", type=str, default=[], nargs="+",
-                help=("name of one or more specifications for which to generate coverage report"
-                    ", default: include all specifications. Only a unique part of the name can be specified."
-            ))
+        parser.add_argument(
+            "--only",
+            metavar="name",
+            type=str,
+            default=[],
+            nargs="+",
+            help=(
+                "name of one or more specifications for which to generate coverage report"
+                ", default: include all specifications. Only a unique part of the name can be specified."
+            ),
+        )
 
         parser.set_defaults(func=cls())
 
     def get_attribute(self, result, name, default=None):
         tests = list(result["tests"].values())
 
         if not tests:
@@ -296,15 +367,18 @@
                         if name in spec["specification_name"]:
                             matched = True
                             break
                     if not matched:
                         continue
                 _specs.append(spec)
                 for req in spec["specification_requirements"]:
-                    _requirements[req["name"]] = {"requirement": Requirement(**req), "tests": []}
+                    _requirements[req["name"]] = {
+                        "requirement": Requirement(**req),
+                        "tests": [],
+                    }
         else:
             spec = importlib.util.spec_from_file_location("requirements", path)
             module = importlib.util.module_from_spec(spec)
             spec.loader.exec_module(module)
 
             for name, value in vars(module).items():
                 if not isinstance(value, Requirement):
@@ -313,36 +387,47 @@
 
         return (_specs, _requirements)
 
     def add_test_messages(self, test, idx, tests, tests_by_parent, tests_by_id):
         started = test["test"]["message_time"]
         ended = test["result"]["message_time"]
 
-        messages = [format_test(test["test"], "", tests_by_parent, tests_by_id, no_colors=True)]
+        messages = [
+            format_test(test["test"], "", tests_by_parent, tests_by_id, no_colors=True)
+        ]
 
         if getattr(TestType, test["test"]["test_type"]) > TestType.Test:
-            for t in tests[idx + 1:]:
+            for t in tests[idx + 1 :]:
                 flags = Flags(t["test"]["test_flags"])
                 if flags & SKIP and settings.show_skipped is False:
                     continue
                 if t["test"]["message_time"] > ended:
                     break
-                if getattr(TestType, t["test"]["test_type"]) >= TestType.Test \
-                        and t["test"]["test_id"].startswith(test["test"]["test_id"]):
-                    messages.append(format_test(t["test"], "", tests_by_parent, tests_by_id, no_colors=True))
+                if getattr(TestType, t["test"]["test_type"]) >= TestType.Test and t[
+                    "test"
+                ]["test_id"].startswith(test["test"]["test_id"]):
+                    messages.append(
+                        format_test(
+                            t["test"], "", tests_by_parent, tests_by_id, no_colors=True
+                        )
+                    )
                     messages.append(format_result(t["result"], no_colors=True))
         else:
-            for t in tests[idx + 1:]:
+            for t in tests[idx + 1 :]:
                 flags = Flags(t["test"]["test_flags"])
                 if flags & SKIP and settings.show_skipped is False:
                     continue
                 if t["test"]["message_time"] > ended:
                     break
                 if t["test"]["test_id"].startswith(test["test"]["test_id"]):
-                    messages.append(format_test(t["test"], "", tests_by_parent, tests_by_id, no_colors=True))
+                    messages.append(
+                        format_test(
+                            t["test"], "", tests_by_parent, tests_by_id, no_colors=True
+                        )
+                    )
                     messages.append(format_result(t["result"], no_colors=True))
 
         messages.append(format_result(test["result"], no_colors=True))
 
         test["messages"] = "".join(messages)
         return test
 
@@ -353,15 +438,23 @@
 
             if flags & SKIP and settings.show_skipped is False:
                 continue
             result = test["result"]
 
             for requirement in test["test"]["requirements"]:
                 if requirement["requirement_name"] in requirements:
-                    requirements[requirement["requirement_name"]]["tests"].append(self.add_test_messages(test, i, tests, results["tests_by_parent"], results["tests_by_id"]))
+                    requirements[requirement["requirement_name"]]["tests"].append(
+                        self.add_test_messages(
+                            test,
+                            i,
+                            tests,
+                            results["tests_by_parent"],
+                            results["tests_by_id"],
+                        )
+                    )
 
         return requirements
 
     def counts(self, requirements):
         counts = Counts("requirements", *([0] * 4))
 
         for req in requirements.values():
@@ -408,17 +501,15 @@
         d["counts"] = self.counts(d["requirements"])
         d["company"] = self.company(args)
         counts = d["counts"]
         return d
 
     def generate(self, formatter, results, args):
         output = args.output
-        output.write(
-            formatter.format(self.data(args.requirements, results, args))
-        )
+        output.write(formatter.format(self.data(args.requirements, results, args)))
         output.write("\n")
 
     def handle(self, args):
         results = {}
         formatter = Formatter()
         ResultsLogPipeline(args.input, results).run()
         self.generate(formatter, results, args)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/handler.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/handler.py`

 * *Files 9% similar despite different names*

```diff
@@ -11,32 +11,46 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.cli.arg.handlers.report.srs_coverage import Handler as srs_coverage_handler
+from testflows._core.cli.arg.handlers.report.srs_coverage import (
+    Handler as srs_coverage_handler,
+)
 from testflows._core.cli.arg.handlers.report.results import Handler as results_handler
-from testflows._core.cli.arg.handlers.report.compare.handler import Handler as compare_handler
+from testflows._core.cli.arg.handlers.report.compare.handler import (
+    Handler as compare_handler,
+)
 from testflows._core.cli.arg.handlers.report.coverage import Handler as coverage_handler
 from testflows._core.cli.arg.handlers.report.metrics import Handler as metrics_handler
-from testflows._core.cli.arg.handlers.report.specification import Handler as specification_handler
-from testflows._core.cli.arg.handlers.report.tracebility import Handler as tracebility_handler
+from testflows._core.cli.arg.handlers.report.specification import (
+    Handler as specification_handler,
+)
+from testflows._core.cli.arg.handlers.report.tracebility import (
+    Handler as tracebility_handler,
+)
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("report", help="generate report", epilog=epilog(),
+        parser = commands.add_parser(
+            "report",
+            help="generate report",
+            epilog=epilog(),
             description="Generate report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        report_commands = parser.add_subparsers(title="commands", metavar="command",
-            description=None, help=None)
+        report_commands = parser.add_subparsers(
+            title="commands", metavar="command", description=None, help=None
+        )
         report_commands.required = True
         results_handler.add_command(report_commands)
         specification_handler.add_command(report_commands)
         tracebility_handler.add_command(report_commands)
         coverage_handler.add_command(report_commands)
         compare_handler.add_command(report_commands)
         metrics_handler.add_command(report_commands)
-        #srs_coverage_handler.add_command(report_commands)
+        # srs_coverage_handler.add_command(report_commands)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/metrics.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/metrics.py`

 * *Files 16% similar despite different names*

```diff
@@ -18,14 +18,15 @@
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.transform.log.pipeline import MetricsLogPipeline
 from testflows._core.message import dumps
 
+
 class OpenMetricsFormatter:
     def format_metric_name(self, name):
         return name.replace(" ", "_")
 
     def format_metric(self, metric):
         metric_name = self.format_metric_name(metric["metric_name"])
         metric_value = metric["metric_value"]
@@ -34,65 +35,94 @@
         test_name = metric["test_name"]
 
         return f"{metric_name}{{test={dumps(test_name)},units={dumps(metric_units)}}} {metric_value} {int(metric_time)}\n"
 
     def format(self, data):
         body = ""
         for metric in data["metrics"]:
-             body += self.format_metric(metric)
+            body += self.format_metric(metric)
         return body
 
+
 class CSVMetricsFormatter:
     def format_metric_name(self, name):
         return name.replace(" ", "_")
 
     def format_metric(self, writer, metric):
         metric_name = self.format_metric_name(metric["metric_name"])
         metric_value = metric["metric_value"]
         metric_units = metric["metric_units"]
         metric_time = metric["message_time"]
         test_name = metric["test_name"]
-        writer.writerow((test_name, metric_name, metric_units, metric_value, int(metric_time)))
+        writer.writerow(
+            (test_name, metric_name, metric_units, metric_value, int(metric_time))
+        )
 
     def format(self, data):
         body = io.StringIO()
-        header = "test_name", "metric_name", "metric_units", "metric_value", "metric_time"
+        header = (
+            "test_name",
+            "metric_name",
+            "metric_units",
+            "metric_value",
+            "metric_time",
+        )
         writer = csv.writer(body, quoting=csv.QUOTE_NONNUMERIC)
         writer.writerow(header)
         for metric in data["metrics"]:
-             self.format_metric(writer, metric)
+            self.format_metric(writer, metric)
         return body.getvalue()
 
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("metrics", help="metrics report", epilog=epilog(),
+        parser = commands.add_parser(
+            "metrics",
+            help="metrics report",
+            epilog=epilog(),
             description="Generate metrics report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("--format", metavar="type", type=str,
-            help="output format choices: 'openmetrics', 'csv' default: openmetrics", choices=["openmetrics", "csv"], default="openmetrics")
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "--format",
+            metavar="type",
+            type=str,
+            help="output format choices: 'openmetrics', 'csv' default: openmetrics",
+            choices=["openmetrics", "csv"],
+            default="openmetrics",
+        )
 
         parser.set_defaults(func=cls())
 
     def data(self, metrics, args):
         d = dict()
         d["metrics"] = metrics
         return d
 
     def generate(self, formatter, metrics, args):
         output = args.output
-        output.write(
-            formatter.format(self.data(metrics, args))
-        )
+        output.write(formatter.format(self.data(metrics, args)))
 
     def handle(self, args):
         metrics = []
         MetricsLogPipeline(args.input, metrics).run()
         if args.format == "openmetrics":
             formatter = OpenMetricsFormatter()
         elif args.format == "csv":
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/results.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/results.py`

 * *Files 5% similar despite different names*

```diff
@@ -48,46 +48,61 @@
 
 ---
 Generated by {testflows} Open-Source Test Framework v%(generated_by_version)s
 
 [<span class="logo-test">Test</span><span class="logo-flows">Flows</span>]: https://testflows.com
 """
 
-results_order =  ["Skip", "OK", "Fail", "Error", "Null", "XOK", "XFail", "XError", "XNull", "Retried"]
+results_order = [
+    "Skip",
+    "OK",
+    "Fail",
+    "Error",
+    "Null",
+    "XOK",
+    "XFail",
+    "XError",
+    "XNull",
+    "Retried",
+]
+
 
 class JSONFormatter:
-    """JSON formatter.
-    """
+    """JSON formatter."""
+
     class Encoder(JSONEncoder):
         def default(self, o):
             return vars(o)
 
     def format(self, data):
         return json.dumps(data, indent=2, cls=JSONFormatter.Encoder)
 
+
 class MarkdownFormatter:
-    """Markdown formatter.
-    """
+    """Markdown formatter."""
+
     def format_logo(self, data):
         if not data["company"].get("logo"):
             return ""
         data = base64.b64encode(data["company"]["logo"]).decode("utf-8")
-        return '\n<p>' + logo % {"data": data} + "</p>\n"
+        return "\n<p>" + logo % {"data": data} + "</p>\n"
 
     def format_confidential(self, data):
         if not data["company"].get("confidential"):
             return ""
         return f'\n<p class="confidential">Document status - Confidential</p>\n'
 
     def format_copyright(self, data):
         if not data["company"].get("name"):
             return ""
-        return (f'\n<p class="copyright">\n'
+        return (
+            f'\n<p class="copyright">\n'
             f'{copyright(data["company"]["name"])}\n'
-            "</p>\n")
+            "</p>\n"
+        )
 
     def format_artifacts(self, data):
         if not data["artifacts"]:
             return ""
         s = "\n## Artifacts\n"
         link = data["artifacts"]["link"]
         name = link.lstrip("./")
@@ -104,17 +119,17 @@
         duration = strftimedelta(metadata["duration"]) if metadata["duration"] else ""
         date = metadata["date"]
         version = metadata["version"]
 
         s = (
             "\n\n"
             f"||**Date**||{localfromtimestamp(date):%b %d, %Y %-H:%M}||\n"
-            f'||**Duration**||{duration}||\n'
-            f'||**Framework**||'
-            f'{testflows} {version}||\n'
+            f"||**Duration**||{duration}||\n"
+            f"||**Framework**||"
+            f"{testflows} {version}||\n"
             "\n"
         )
         return s
 
     def format_summary(self, data):
         counts = data["counts"]
 
@@ -139,21 +154,22 @@
             p_value = value / float(units) * 100
             if p_value > 1:
                 value = f"{p_value:.1f}".rstrip("0").rstrip(".") + "%"
             else:
                 value = f"<1%"
             return (
                 f'<div class="c100 p{math.floor(p_value):.0f} {color}">'
-                    f'<span>{value}</span>'
-                    f'<span class="title">{title}</span>'
-                    '<div class="slice">'
-                        '<div class="bar"></div>'
-                        '<div class="fill"></div>'
-                    '</div>'
-                '</div>\n')
+                f"<span>{value}</span>"
+                f'<span class="title">{title}</span>'
+                '<div class="slice">'
+                '<div class="bar"></div>'
+                '<div class="fill"></div>'
+                "</div>"
+                "</div>\n"
+            )
 
         s = "\n## Summary\n"
 
         if units <= 0:
             s += "No tests"
         else:
             s += '<div class="chart">'
@@ -168,22 +184,22 @@
                 s += template(failed, units, "Fail", "red")
             if errored > 0:
                 s += template(errored, units, "Error", "orange")
             if nulled > 0:
                 s += template(nulled, units, "Null", "purple")
             if retried > 0:
                 s += template(retried, units, "Retried", "cyan")
-            s += '</div>'
+            s += "</div>"
         return s
 
     def format_statistics(self, data):
         s = "\n\n## Statistics\n"
         counts = data["counts"]
 
-        statistics = {"types":{}}
+        statistics = {"types": {}}
 
         if counts["module"]:
             statistics["types"]["module"] = counts["module"].__data__()
         if counts["suite"]:
             statistics["types"]["suite"] = counts["suite"].__data__()
         if counts["test"]:
             statistics["types"]["test"] = counts["test"].__data__()
@@ -212,35 +228,44 @@
             fields = fields.union(set(k["counts"].keys()))
         statistics["result_fields"] = []
 
         for r in results_order:
             if r in fields:
                 statistics["result_fields"].append(r)
 
-        fields = ["<span></span>", "Units"] + [f'<span class="result result-{f.lower()}">{f}</span>'for f in statistics["result_fields"]]
+        fields = ["<span></span>", "Units"] + [
+            f'<span class="result result-{f.lower()}">{f}</span>'
+            for f in statistics["result_fields"]
+        ]
         s += " | ".join(fields) + "\n"
         s += " | ".join(["---"] * len(fields)) + "\n"
         for t in statistics["types"]:
             type_data = statistics["types"][t]
-            c = [f'{t.capitalize()}s', f'<center>{str(type_data["units"])}</center>']
+            c = [f"{t.capitalize()}s", f'<center>{str(type_data["units"])}</center>']
             for r in statistics["result_fields"]:
                 if type_data["counts"].get(r):
                     c.append(f'<center>{str(type_data["counts"][r])}</center>')
                 else:
                     c.append("")
             s += " | ".join(c) + "\n"
         return s + "\n"
 
     def format_attributes_and_tags(self, data):
         s = ""
 
         if data["attributes"]:
             s += "\n\n### Attributes\n"
             for attr in data["attributes"]:
-                s += "||" + "||".join([f"**{attr['attribute_name']}**", f"{attr['attribute_value']}"]) + "||\n"
+                s += (
+                    "||"
+                    + "||".join(
+                        [f"**{attr['attribute_name']}**", f"{attr['attribute_value']}"]
+                    )
+                    + "||\n"
+                )
             s += "\n"
 
         if data["tags"]:
             s += "\n\n### Tags\n"
             for i, tag in enumerate(data["tags"]):
                 if i > 0 and i % 3 == 0:
                     s += "||\n"
@@ -258,22 +283,27 @@
             result = test["result"]
             flags = Flags(result["test_flags"])
             cflags = Flags(result["test_cflags"])
             if flags & SKIP and settings.show_skipped is False:
                 continue
             if result["result_type"] in FailResults:
                 cls = result["result_type"].lower()
-                s += ("<tr>" +
-                    f'<td>{result["result_test"]}</td>' +
-                    f'<td><span class="result result-{cls}">{result["result_type"]}</span>  ' + strftimedelta(result["message_rtime"]) + '</td>' +
-                    '<td><div style="max-width: 30vw; overflow-x: auto;"><pre>' + str(result["result_message"]).replace("|", "\|") + '</pre></div></td>'
+                s += (
+                    "<tr>"
+                    + f'<td>{result["result_test"]}</td>'
+                    + f'<td><span class="result result-{cls}">{result["result_type"]}</span>  '
+                    + strftimedelta(result["message_rtime"])
+                    + "</td>"
+                    + '<td><div style="max-width: 30vw; overflow-x: auto;"><pre>'
+                    + str(result["result_message"]).replace("|", "\|")
+                    + "</pre></div></td>"
                 ) + "</tr>\n"
                 has_fails = True
-        s += '<tbody>\n'
-        s += '</table>\n'
+        s += "<tbody>\n"
+        s += "</table>\n"
         if not has_fails:
             return ""
         return s
 
     def format_xfails(self, data):
         s = "\n\n## Known Fails\n"
         s += '<table class="stripped primary">\n'
@@ -283,22 +313,29 @@
         for test in data["tests"]:
             result = test["result"]
             flags = Flags(result["test_flags"])
             if flags & SKIP and settings.show_skipped is False:
                 continue
             if result["result_type"] in XoutResults:
                 cls = result["result_type"].lower()
-                s += ("<tr>" +
-                    f'<td>{result["result_test"]}</td>' +
-                    f'<td><span class="result result-{cls}">{result["result_type"]}</span> ' + strftimedelta(result["message_rtime"]) + '<br>' + str(result["result_reason"]).replace("|", "\|") + '</td>' +
-                    '<td><div style="max-width: 30vw; overflow-x: auto;"><pre>' + str(result["result_message"]).replace("|", "\|") + '</pre></div></td>'
+                s += (
+                    "<tr>"
+                    + f'<td>{result["result_test"]}</td>'
+                    + f'<td><span class="result result-{cls}">{result["result_type"]}</span> '
+                    + strftimedelta(result["message_rtime"])
+                    + "<br>"
+                    + str(result["result_reason"]).replace("|", "\|")
+                    + "</td>"
+                    + '<td><div style="max-width: 30vw; overflow-x: auto;"><pre>'
+                    + str(result["result_message"]).replace("|", "\|")
+                    + "</pre></div></td>"
                 ) + "</tr>\n"
                 has_xfails = True
-        s += '<tbody>\n'
-        s += '</table>\n'
+        s += "<tbody>\n"
+        s += "</table>\n"
         if not has_xfails:
             return ""
         return s
 
     def format_results(self, data):
         s = "\n## Results\n"
         s += (
@@ -308,15 +345,24 @@
         for test in data["tests"]:
             result = test["result"]
             flags = Flags(result["test_flags"])
             cflags = Flags(result["test_cflags"])
             if flags & SKIP and settings.show_skipped is False:
                 continue
             cls = result["result_type"].lower()
-            s += " | ".join([result["result_test"], f'<span class="result result-{cls}">{result["result_type"]}</span>', strftimedelta(result["message_rtime"])]) + "\n"
+            s += (
+                " | ".join(
+                    [
+                        result["result_test"],
+                        f'<span class="result result-{cls}">{result["result_type"]}</span>',
+                        strftimedelta(result["message_rtime"]),
+                    ]
+                )
+                + "\n"
+            )
         return s
 
     def format(self, data):
         body = ""
         body += self.format_metadata(data)
         body += self.format_artifacts(data)
         body += self.format_attributes_and_tags(data)
@@ -327,48 +373,77 @@
         body += self.format_results(data)
         return template.strip() % {
             "logo": self.format_logo(data),
             "confidential": self.format_confidential(data),
             "copyright": self.format_copyright(data),
             "body": body,
             "name": data["name"],
-            "generated_by_version": data["metadata"]["generated"]["version"]
-            }
+            "generated_by_version": data["metadata"]["generated"]["version"],
+        }
 
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("results", help="results report", epilog=epilog(),
+        parser = commands.add_parser(
+            "results",
+            help="results report",
+            epilog=epilog(),
             description="Generate results report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("-a", "--artifacts", metavar="link", type=str, help='link to the artifacts')
-        parser.add_argument("--format", metavar="type", type=str,
-            help="output format choices: 'md', 'json', default: md (Markdown)", choices=["md", "json"], default="md")
-        parser.add_argument("--copyright", metavar="name", help="add copyright notice", type=str)
-        parser.add_argument("--confidential", help="mark as confidential", action="store_true")
-        parser.add_argument("--logo", metavar="path", type=argtype.file("rb"),
-                help='use logo image (.png)')
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "-a", "--artifacts", metavar="link", type=str, help="link to the artifacts"
+        )
+        parser.add_argument(
+            "--format",
+            metavar="type",
+            type=str,
+            help="output format choices: 'md', 'json', default: md (Markdown)",
+            choices=["md", "json"],
+            default="md",
+        )
+        parser.add_argument(
+            "--copyright", metavar="name", help="add copyright notice", type=str
+        )
+        parser.add_argument(
+            "--confidential", help="mark as confidential", action="store_true"
+        )
+        parser.add_argument(
+            "--logo",
+            metavar="path",
+            type=argtype.file("rb"),
+            help="use logo image (.png)",
+        )
         parser.add_argument("--title", metavar="name", help="custom title", type=str)
 
         parser.set_defaults(func=cls())
 
     def artifacts(self, link):
         if not link:
             return {}
         else:
-            return {
-                "name": link.lstrip("./"),
-                "link": link
-            }
+            return {"name": link.lstrip("./"), "link": link}
 
     def attributes(self, results):
         if not results["tests"]:
             return []
         test = next(iter(results["tests"].values()), None)["test"]
 
         if test["attributes"]:
@@ -410,15 +485,15 @@
         return {
             "duration": duration,
             "date": results["started"],
             "version": results["version"],
             "generated": {
                 "date": time.time(),
                 "version": __version__,
-            }
+            },
         }
 
     def counts(self, results):
         return results["counts"]
 
     def tests(self, results):
         tests = []
@@ -444,17 +519,15 @@
         d["tags"] = self.tags(results)
         d["artifacts"] = self.artifacts(args.artifacts)
         d["tests"] = self.tests(results)
         return d
 
     def generate(self, formatter, results, args):
         output = args.output
-        output.write(
-            formatter.format(self.data(results, args))
-        )
+        output.write(formatter.format(self.data(results, args)))
         output.write("\n")
 
     def handle(self, args):
         results = {}
         ResultsLogPipeline(args.input, results).run()
         formatter = MarkdownFormatter()
         if args.format == "json":
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/specification.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/specification.py`

 * *Files 11% similar despite different names*

```diff
@@ -52,32 +52,35 @@
 
 ---
 Generated by {testflows} Open-Source Test Framework
 
 [<span class="logo-test">Test</span><span class="logo-flows">Flows</span>]: https://testflows.com
 """
 
+
 class Formatter(object):
     def format_logo(self, data):
         if not data["company"].get("logo"):
             return ""
         data = base64.b64encode(data["company"]["logo"]).decode("utf-8")
-        return '\n<p>' + logo % {"data": data} + "</p>\n"
+        return "\n<p>" + logo % {"data": data} + "</p>\n"
 
     def format_confidential(self, data):
         if not data["company"].get("confidential"):
             return ""
         return f'\n<p class="confidential">Document status - Confidential</p>\n'
 
     def format_copyright(self, data):
         if not data["company"].get("name"):
             return ""
-        return (f'\n<p class="copyright">\n'
+        return (
+            f'\n<p class="copyright">\n'
             f'{copyright(data["company"]["name"])}\n'
-            "</p>\n")
+            "</p>\n"
+        )
 
     def format_multiline(self, text, indent=None):
         first, rest = (text.rstrip() + "\n").split("\n", 1)
         first = first.strip()
         if first:
             first += "\n"
         out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
@@ -90,103 +93,157 @@
         s = []
         s.append("## 2. Procedures\n")
         s.append("\n")
         s.append("This section includes procedures for all the executed tests.\n")
         ss.append("\n".join(s))
 
         def anchor(heading):
-            return re.sub(r"\s+", "-", re.sub(r"[^a-zA-Z0-9-_\s]+", "", heading.lower()))
+            return re.sub(
+                r"\s+", "-", re.sub(r"[^a-zA-Z0-9-_\s]+", "", heading.lower())
+            )
 
         for test in data["tests"]:
             s = []
 
-            id = ".".join(["1" if i == 0 else str(int(p) + 1) for i, p in enumerate(test["id"].split(sep)[1:])])
+            id = ".".join(
+                [
+                    "1" if i == 0 else str(int(p) + 1)
+                    for i, p in enumerate(test["id"].split(sep)[1:])
+                ]
+            )
             s.append(f"### 2.{id} {test['keyword'].upper()} **{test['name']}**\n")
             heading = s[-1].lstrip("# ").strip()
             name = f"{test['keyword'].upper()} {test['name']}"
             s.append(f"**Name** `{test['path']}`\n")
 
             if test["attributes"]:
                 s.append("**Attributes**  \n")
                 for attr in test["attributes"]:
-                    s.append(f'||**{attr["attribute_name"]}**||{attr["attribute_value"]}||')
+                    s.append(
+                        f'||**{attr["attribute_name"]}**||{attr["attribute_value"]}||'
+                    )
                 s.append("\n")
 
             if test["tags"]:
                 t = []
                 for tag in test["tags"]:
                     t.append(f'`{tag["tag_value"]}`')
                 s.append(f"**Tags**  {', '.join(t)}")
                 s.append("\n")
 
             if test["description"]:
                 s.append("##### DESCRIPTION\n")
-                s.append(self.format_multiline(test['description']) if test['description'] else "")
+                s.append(
+                    self.format_multiline(test["description"])
+                    if test["description"]
+                    else ""
+                )
                 s.append("\n")
 
             if test["requirements"]:
                 s.append("##### REQUIREMENTS\n")
                 for req in test["requirements"]:
                     s.append(f'* **{req["requirement_name"]}**')
-                    s.append(textwrap.indent(f'<div markdown="1" class="text-small">\nversion: {req["requirement_version"]}</div>', "  "))
-                    s.append(textwrap.indent(f'<div markdown="1" class="test-description">\n{(req["requirement_description"] or "").strip()}</div>', "  "))
+                    s.append(
+                        textwrap.indent(
+                            f'<div markdown="1" class="text-small">\nversion: {req["requirement_version"]}</div>',
+                            "  ",
+                        )
+                    )
+                    s.append(
+                        textwrap.indent(
+                            f'<div markdown="1" class="test-description">\n{(req["requirement_description"] or "").strip()}</div>',
+                            "  ",
+                        )
+                    )
                 s.append("\n")
 
             def add_steps(s, test, level):
                 for step in test["steps"]:
                     s.append(f"{'  ' * level}* **{step['keyword']}**  {step['name']}  ")
                     if step["description"]:
-                        s.append(textwrap.indent(f'<div markdown="1" class="test-description">\n{step["description"].strip()}</div>', "    " * level).rstrip())
+                        s.append(
+                            textwrap.indent(
+                                f'<div markdown="1" class="test-description">\n{step["description"].strip()}</div>',
+                                "    " * level,
+                            ).rstrip()
+                        )
                     if getattr(TestType, step["type"]) < TestType.Test:
                         if step["steps"]:
                             add_steps(s, step, level + 1)
                 if not test["steps"]:
                     s.append("* None")
 
             s.append("##### PROCEDURE\n")
             add_steps(s, test, 1)
             s.append("\n")
             ss.append("\n".join(s))
 
-            toc.append(f"{len(id.split('.')) * '  '}* 2.{id} [{name}](#{anchor(heading)})")
+            toc.append(
+                f"{len(id.split('.')) * '  '}* 2.{id} [{name}](#{anchor(heading)})"
+            )
 
         return "\n---\n".join(ss)
 
     def format(self, data):
         toc = []
         toc.append("* 1 [Overview](#1-overview)")
         toc.append("* 2 [Procedures](#2-procedures)")
         body = self.format_tests(data, toc)
         return template.strip() % {
             "title": data["title"],
             "table_of_contents": "\n".join(toc),
             "logo": self.format_logo(data),
             "confidential": self.format_confidential(data),
             "copyright": self.format_copyright(data),
-            "body": body
+            "body": body,
         }
 
 
 class Handler(HandlerBase):
     Formatter = Formatter
 
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("specification", help="specification report", epilog=epilog(),
+        parser = commands.add_parser(
+            "specification",
+            help="specification report",
+            epilog=epilog(),
             description="Generate specifiction report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("--copyright", metavar="name", help="add copyright notice", type=str)
-        parser.add_argument("--confidential", help="mark as confidential", action="store_true")
-        parser.add_argument("--logo", metavar="path", type=argtype.file("rb"),
-                help='use logo image (.png)')
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "--copyright", metavar="name", help="add copyright notice", type=str
+        )
+        parser.add_argument(
+            "--confidential", help="mark as confidential", action="store_true"
+        )
+        parser.add_argument(
+            "--logo",
+            metavar="path",
+            type=argtype.file("rb"),
+            help="use logo image (.png)",
+        )
         parser.add_argument("--title", metavar="name", help="custom title", type=str)
 
         parser.set_defaults(func=cls())
 
     def company(self, args):
         d = {}
         if args.copyright:
@@ -209,15 +266,15 @@
         t = {}
         t["path"] = test["test_name"]
         t["level"] = test["test_level"]
         t["keyword"] = test["test_type"]
         t["type"] = test["test_type"]
         t["subtype"] = test["test_subtype"]
         if test["test_subtype"]:
-                t["keyword"] = test["test_subtype"]
+            t["keyword"] = test["test_subtype"]
         t["description"] = test["test_description"]
         t["attributes"] = test["attributes"]
         t["tags"] = test["tags"]
         t["requirements"] = test["requirements"]
         t["name"] = basename(test["test_name"])
         t["id"] = test["test_id"]
 
@@ -242,17 +299,15 @@
         d["title"] = args.title or self.title(results)
         d["tests"] = self.tests(results)
         d["company"] = self.company(args)
         return d
 
     def generate(self, formatter, results, args):
         output = args.output
-        output.write(
-            formatter.format(self.data(results, args))
-        )
+        output.write(formatter.format(self.data(results, args)))
         output.write("\n")
 
     def handle(self, args):
         results = OrderedDict()
         ResultsLogPipeline(args.input, results).run()
         formatter = self.Formatter()
         self.generate(formatter, results, args)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/srs_coverage.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/srs_coverage.py`

 * *Files 11% similar despite different names*

```diff
@@ -20,48 +20,54 @@
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.document.srs import Parser, visit_parse_tree
 from testflows._core.document.toc import Visitor as VisitorBase
 from testflows._core.transform.log.pipeline import ResultsLogPipeline
 from testflows._core.utils.timefuncs import strftimedelta
 
+
 def color_secondary():
     return functools.partial(color, color="white", attrs=["dim"])
 
+
 def color_primary():
     return functools.partial(color, color="white")
 
+
 def result_priority(result):
     if result.startswith("X"):
         return 2
     elif result == "OK":
         return 1
     elif result == "Skip":
         return 3
     # Error, Fail, Null
     return 4
 
+
 def color_result(result):
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=["bold"])
     elif result == "OK":
         return functools.partial(color, color="green", attrs=["bold"])
     elif result == "Skip":
         return functools.partial(color, color="cyan", attrs=["bold"])
     # Error, Fail, Null
     return functools.partial(color, color="red", attrs=["bold"])
 
+
 def color_counts(result):
     if result == "Satisfied":
         return functools.partial(color, color="green", attrs=["bold"])
     elif result == "Unsatisfied":
         return functools.partial(color, color="grey", attrs=["bold"])
     # Unverified
     return functools.partial(color, color="red", attrs=["bold"])
 
+
 class Counts(object):
     def __init__(self, name, units, ok, nok, untested):
         self.name = name
         self.units = units
         self.ok = ok
         self.nok = nok
         self.untested = untested
@@ -70,54 +76,69 @@
         return self.units > 0
 
     def __str__(self):
         s = f"{self.units} {self.name if self.units != 1 else self.name.rstrip('s')} ("
         s = color(s, "white", attrs=["bold"])
         r = []
         if self.ok > 0:
-            r.append(color_counts("Satisfied")(f"{self.ok} satisfied {(self.ok / self.units) * 100:.1f}%"))
+            r.append(
+                color_counts("Satisfied")(
+                    f"{self.ok} satisfied {(self.ok / self.units) * 100:.1f}%"
+                )
+            )
         if self.nok > 0:
-            r.append(color_counts("Unsatisfied")(f"{self.nok} unsatisfied {(self.nok / self.units) * 100:.1f}%"))
+            r.append(
+                color_counts("Unsatisfied")(
+                    f"{self.nok} unsatisfied {(self.nok / self.units) * 100:.1f}%"
+                )
+            )
         if self.untested > 0:
-            r.append(color_counts("Untested")(f"{self.untested} untested {(self.untested / self.units) * 100:.1f}%"))
+            r.append(
+                color_counts("Untested")(
+                    f"{self.untested} untested {(self.untested / self.units) * 100:.1f}%"
+                )
+            )
         s += color(", ", "white", attrs=["bold"]).join(r)
         s += color(")\n", "white", attrs=["bold"])
         return s
 
+
 class Heading(object):
     def __init__(self, name, level, num):
         self.name = name
         self.level = level
         self.num = num
 
+
 class Requirement(Heading):
     def __init__(self, name, version, uid, level, num):
         self.version = version
         self.uid = uid
         return super(Requirement, self).__init__(name, level, num)
 
+
 class Visitor(VisitorBase):
     def __init__(self, *args, **kwargs):
         self.headings = []
         super(Visitor, self).__init__(*args, **kwargs)
 
     def visit_line(self, node, children):
         pass
 
     def visit_requirement(self, node, children):
         name = node.requirement_heading.requirement_name.value
         description = None
         uid = None
         version = None
         try:
-            uid = f"\"{node.uid.word}\""
+            uid = f'"{node.uid.word}"'
         except:
             pass
         try:
-            version = f"\"{node.version.word}\""
+            version = f'"{node.version.word}"'
         except:
             pass
         res = self.process_heading(node, children)
         if res:
             level, num = res
             self.headings.append(Requirement(name, version, uid, level, num))
 
@@ -127,52 +148,87 @@
             level, num = res
             name = node.heading_name.value
             self.headings.append(Heading(name, level, num))
 
     def visit_document(self, node, children):
         return self.headings
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("srs-coverage", help="SRS (Software Requirements Specification) coverage report", epilog=epilog(),
+        parser = commands.add_parser(
+            "srs-coverage",
+            help="SRS (Software Requirements Specification) coverage report",
+            epilog=epilog(),
             description="Generate SRS (Software Requirements Specification) coverage report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("srs", metavar="srs", type=argtype.file("r", bufsize=1, encoding="utf-8"),
-                nargs=1, help="source file")
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("--only", metavar="status", type=str, nargs="+", help="verification status",
+        parser.add_argument(
+            "srs",
+            metavar="srs",
+            type=argtype.file("r", bufsize=1, encoding="utf-8"),
+            nargs=1,
+            help="source file",
+        )
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "--only",
+            metavar="status",
+            type=str,
+            nargs="+",
+            help="verification status",
             choices=["satisfied", "unsatisfied", "untested"],
-            default=["satisfied", "unsatisfied", "untested"])
+            default=["satisfied", "unsatisfied", "untested"],
+        )
         parser.set_defaults(func=cls())
 
     def generate(self, output, headings, tested, only):
         counts = Counts("requirements", *([0] * 4))
 
         for heading in headings:
             indent = "  " * (heading.level - 1)
             if isinstance(heading, Requirement):
                 counts.units += 1
                 if tested.get(heading.name) is None:
                     counts.untested += 1
                     if "untested" in only:
-                        output.write(color(f"{indent}\u270E ", "grey", attrs=["bold"]) + color_primary()(f"{heading.num} {heading.name}\n"))
-                        output.write(color(f"{indent}  no tests\n", "white", attrs=["dim"]))
+                        output.write(
+                            color(f"{indent}\u270E ", "grey", attrs=["bold"])
+                            + color_primary()(f"{heading.num} {heading.name}\n")
+                        )
+                        output.write(
+                            color(f"{indent}  no tests\n", "white", attrs=["dim"])
+                        )
                 else:
                     _tests = []
                     _color = None
                     _priority = 0
                     for test, result in tested.get(heading.name):
-                        _tests.append(f"{indent}  [ {color_result(result['result_type'])(result['result_type'])} ] "
+                        _tests.append(
+                            f"{indent}  [ {color_result(result['result_type'])(result['result_type'])} ] "
                             f"{color_secondary()(strftimedelta(result['message_rtime']))} "
-                            f"{color_secondary()(test['test_name'])}\n")
+                            f"{color_secondary()(test['test_name'])}\n"
+                        )
                         if result_priority(result["result_type"]) > _priority:
                             _color = color_result(result["result_type"])
                             _priority = result_priority(result["result_type"])
                     icon = "\u2714"
                     _include = True
                     if _priority > 2:
                         icon = "\u2718"
@@ -181,18 +237,28 @@
                             _include = False
                     else:
                         if "satisfied" not in only:
                             _include = False
                         counts.ok += 1
 
                     if _include:
-                        output.write(_color(f"{indent}{icon} ") + color_primary()(f"{heading.num} {heading.name}\n") + "".join(_tests))
+                        output.write(
+                            _color(f"{indent}{icon} ")
+                            + color_primary()(f"{heading.num} {heading.name}\n")
+                            + "".join(_tests)
+                        )
 
             else:
-                output.write(color(f"{indent}\u27e5 {heading.num} {heading.name}\n", "white", attrs=["dim"]))
+                output.write(
+                    color(
+                        f"{indent}\u27e5 {heading.num} {heading.name}\n",
+                        "white",
+                        attrs=["dim"],
+                    )
+                )
 
         # print summary
         output.write(f"\n{counts}\n")
 
     def handle(self, args):
         parser = Parser()
         with args.srs[0] as requirements:
@@ -210,8 +276,7 @@
             for req in test["requirements"]:
                 if tested.get(req["requirement_name"]) is None:
                     tested[req["requirement_name"]] = []
                 tested[req["requirement_name"]].append((test, result))
         # generate report
         with args.output as output:
             self.generate(output, headings, tested, args.only)
-
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/report/tracebility.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/tracebility.py`

 * *Files 11% similar despite different names*

```diff
@@ -10,15 +10,16 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import re
-#import pwd
+
+# import pwd
 import base64
 import textwrap
 import datetime
 
 from collections import OrderedDict
 
 import testflows._core.cli.arg.type as argtype
@@ -58,32 +59,35 @@
 <br>
 ---
 Generated by {testflows} Open-Source Test Framework
 
 [<span class="logo-test">Test</span><span class="logo-flows">Flows</span>]: https://testflows.com
 """
 
+
 class Formatter(object):
     def format_logo(self, data):
         if not data["company"].get("logo"):
             return ""
         data = base64.b64encode(data["company"]["logo"]).decode("utf-8")
-        return '\n<p>' + logo % {"data": data} + "</p>\n"
+        return "\n<p>" + logo % {"data": data} + "</p>\n"
 
     def format_confidential(self, data):
         if not data["company"].get("confidential"):
             return ""
         return f'\n<p class="confidential">Document status - Confidential</p>\n'
 
     def format_copyright(self, data):
         if not data["company"].get("name"):
             return ""
-        return (f'\n<p class="copyright">\n'
+        return (
+            f'\n<p class="copyright">\n'
             f'{copyright(data["company"]["name"])}\n'
-            "</p>\n")
+            "</p>\n"
+        )
 
     def format_multiline(self, text, indent=None):
         first, rest = (text.rstrip() + "\n").split("\n", 1)
         first = first.strip()
         if first:
             first += "\n"
         out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
@@ -96,32 +100,35 @@
         s = []
         s.append("## 2. Traceability Table\n")
         s.append("\n")
         s.append("This section includes requirements traceability table.")
         ss.append("\n".join(s))
 
         def anchor(heading):
-            return re.sub(r"\s+", "-", re.sub(r"[^a-zA-Z0-9-_\s]+", "", heading.lower()))
-
+            return re.sub(
+                r"\s+", "-", re.sub(r"[^a-zA-Z0-9-_\s]+", "", heading.lower())
+            )
 
         names = human(list(data["requirements"].keys()))
 
         for idx, name in enumerate(names):
             s = []
 
             rq = data["requirements"][name]
             version = rq["requirement"]["requirement_version"]
             description = rq["requirement"]["requirement_description"]
             tests = rq["tests"]
 
-            s.append(f'<div markdown="1" class="compact stripped" style="font-size: smaller; padding: 1em; border-top: 1px solid #3fdc84; border-bottom: 1px solid #3fdc84; {"border-top: none" if idx != 0 else ""}">')
+            s.append(
+                f'<div markdown="1" class="compact stripped" style="font-size: smaller; padding: 1em; border-top: 1px solid #3fdc84; border-bottom: 1px solid #3fdc84; {"border-top: none" if idx != 0 else ""}">'
+            )
             s.append(f"### {name}\n")
             heading = s[-1].lstrip("# ").strip()
 
-            s.append(f'version **{version}**')
+            s.append(f"version **{version}**")
 
             s.append("###### DESCRIPTION\n")
             s.append(f'{(description or "").strip()}')
             s.append("\n")
 
             if tests:
                 s.append("###### TESTS\n")
@@ -144,36 +151,60 @@
         return template.strip() % {
             "title": data["title"],
             "table_of_contents": "\n".join(toc),
             "logo": self.format_logo(data),
             "confidential": self.format_confidential(data),
             "copyright": self.format_copyright(data),
             "body": body,
-            #"date": f"{datetime.datetime.now():%b %d,%Y}",
-            #"author": pwd.getpwuid(os.getuid()).pw_name
+            # "date": f"{datetime.datetime.now():%b %d,%Y}",
+            # "author": pwd.getpwuid(os.getuid()).pw_name
         }
 
 
 class Handler(HandlerBase):
     Formatter = Formatter
 
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("traceability", help="requirements traceability report", epilog=epilog(),
+        parser = commands.add_parser(
+            "traceability",
+            help="requirements traceability report",
+            epilog=epilog(),
             description="Generate requirements traceability report.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("--copyright", metavar="name", help="add copyright notice", type=str)
-        parser.add_argument("--confidential", help="mark as confidential", action="store_true")
-        parser.add_argument("--logo", metavar="path", type=argtype.file("rb"),
-                help='use logo image (.png)')
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "--copyright", metavar="name", help="add copyright notice", type=str
+        )
+        parser.add_argument(
+            "--confidential", help="mark as confidential", action="store_true"
+        )
+        parser.add_argument(
+            "--logo",
+            metavar="path",
+            type=argtype.file("rb"),
+            help="use logo image (.png)",
+        )
         parser.add_argument("--title", metavar="name", help="custom title", type=str)
 
         parser.set_defaults(func=cls())
 
     def company(self, args):
         d = {}
         if args.copyright:
@@ -197,31 +228,31 @@
         for uname, test in results["tests"].items():
             if getattr(TestType, test["test"]["test_type"]) < TestType.Test:
                 continue
             for requirement in test["test"]["requirements"]:
                 if requirements.get(requirement["requirement_name"]) is None:
                     requirements[requirement["requirement_name"]] = {
                         "requirement": requirement,
-                        "tests": []
+                        "tests": [],
                     }
-                requirements[requirement["requirement_name"]]["tests"].append(test["test"])
+                requirements[requirement["requirement_name"]]["tests"].append(
+                    test["test"]
+                )
         return requirements
 
     def data(self, results, args):
         d = OrderedDict()
         d["requirements"] = self.requirements(results)
         d["title"] = args.title or self.title(results)
         d["company"] = self.company(args)
         return d
 
     def generate(self, formatter, results, args):
         output = args.output
-        output.write(
-            formatter.format(self.data(results, args))
-        )
+        output.write(formatter.format(self.data(results, args)))
         output.write("\n")
 
     def handle(self, args):
         results = OrderedDict()
         ResultsLogPipeline(args.input, results).run()
         formatter = self.Formatter()
         self.generate(formatter, results, args)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/requirement/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/report/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/requirement/generate.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/version.py`

 * *Files 20% similar despite different names*

```diff
@@ -13,25 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.document.srs import generate
+from testflows._core.transform.log.pipeline import VersionReportLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("generate", help="generate requirements", epilog=epilog(),
-            description="Generate requirements from an SRS document.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.file("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input file, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "version",
+            help="version",
+            epilog=epilog(),
+            description="Show used framework version.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        generate(args.input, args.output)
+        VersionReportLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/requirement/handler.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/requirement/handler.py`

 * *Files 7% similar despite different names*

```diff
@@ -11,20 +11,28 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.cli.arg.handlers.requirement.generate import Handler as generate_handler
+from testflows._core.cli.arg.handlers.requirement.generate import (
+    Handler as generate_handler,
+)
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("requirements", help="requirement processing", epilog=epilog(),
+        parser = commands.add_parser(
+            "requirements",
+            help="requirement processing",
+            epilog=epilog(),
             description="Work with requirements.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        requirement_commands = parser.add_subparsers(title="commands", metavar="command",
-            description=None, help=None)
+        requirement_commands = parser.add_subparsers(
+            title="commands", metavar="command", description=None, help=None
+        )
         requirement_commands.required = True
         generate_handler.add_command(requirement_commands)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/run.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/run.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/requirement/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/arguments.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/examples.py`

 * *Files 8% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
 from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("arguments", help="arguments", epilog=epilog(),
-            description="Show arguments.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "examples",
+            help="examples",
+            epilog=epilog(),
+            description="Show examples.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.ARGUMENT.name
-            ]
+            message_types = [Message.EXAMPLE.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
                 flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/attributes.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/attributes.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
 from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("attributes", help="attributes", epilog=epilog(),
+        parser = commands.add_parser(
+            "attributes",
+            help="attributes",
+            epilog=epilog(),
             description="Show attributes.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.ATTRIBUTE.name
-            ]
+            message_types = [Message.ATTRIBUTE.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
                 flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/coverage.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/coverage.py`

 * *Files 14% similar despite different names*

```diff
@@ -15,23 +15,40 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.transform.log.pipeline import CoverageReportLogPipeline
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("coverage", help="coverage", epilog=epilog(),
+        parser = commands.add_parser(
+            "coverage",
+            help="coverage",
+            epilog=epilog(),
             description="Show coverage.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        CoverageReportLogPipeline(args.input, args.output).run()
+        CoverageReportLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/description.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/specifications.py`

 * *Files 7% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
 from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("description", help="description", epilog=epilog(),
-            description="Show description.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "specifications",
+            help="specifications",
+            epilog=epilog(),
+            description="Show specifications.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.TEST.name
-            ]
+            message_types = [Message.SPECIFICATION.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
                 flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/details.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/details.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,44 +15,70 @@
 import threading
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
 from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("details", help="details", epilog=epilog(),
+        parser = commands.add_parser(
+            "details",
+            help="details",
+            epilog=epilog(),
             description="Show details.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("name", metavar="name", type=str, help="test name", default=".*?", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default=".*?", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            command = "grep -E '\"message_object\":1,.+\"test_name\":\"%s\"'" % name.replace("'", r"'\''")
+            command = (
+                'grep -E \'"message_object":1,.+"test_name":"%s"\''
+                % name.replace("'", r"'\''")
+            )
             steps = [
-                read_and_filter_transform(input, command=command, tail=tail, stop=stop_event),
+                read_and_filter_transform(
+                    input, command=command, tail=tail, stop=stop_event
+                ),
                 parse_transform(),
                 flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/examples.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/requirements.py`

 * *Files 8% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
 from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("examples", help="examples", epilog=epilog(),
-            description="Show examples.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "requirements",
+            help="requirements",
+            epilog=epilog(),
+            description="Show requirements.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.EXAMPLE.name
-            ]
+            message_types = [Message.REQUIREMENT.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
                 flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/fails.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/slick.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2019 Katteli Inc.
+# Copyright 2020 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -13,26 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import FailsReportLogPipeline
+from testflows._core.transform.log.pipeline import SlickLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("fails", help="fails", epilog=epilog(),
-            description="Show only failed tests.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
-        parser.add_argument("-n", "--new", action="store_true", help="show only new fails", default=False)
+        parser = commands.add_parser(
+            "slick",
+            help="slick transform",
+            epilog=epilog(),
+            description="Transform log into a slick format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        FailsReportLogPipeline(args.input, args.output, only_new=args.new).run()
+        SlickLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/handler.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/handler.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,33 +22,47 @@
 from testflows._core.cli.arg.handlers.show.version import Handler as version_handler
 from testflows._core.cli.arg.handlers.show.coverage import Handler as coverage_handler
 from testflows._core.cli.arg.handlers.show.results import Handler as results_handler
 from testflows._core.cli.arg.handlers.show.details import Handler as details_handler
 from testflows._core.cli.arg.handlers.show.metrics import Handler as metrics_handler
 from testflows._core.cli.arg.handlers.show.procedure import Handler as procedure_handler
 from testflows._core.cli.arg.handlers.show.arguments import Handler as arguments_handler
-from testflows._core.cli.arg.handlers.show.requirements import Handler as requirements_handler
-from testflows._core.cli.arg.handlers.show.attributes import Handler as attributes_handler
+from testflows._core.cli.arg.handlers.show.requirements import (
+    Handler as requirements_handler,
+)
+from testflows._core.cli.arg.handlers.show.attributes import (
+    Handler as attributes_handler,
+)
 from testflows._core.cli.arg.handlers.show.tags import Handler as tags_handler
-from testflows._core.cli.arg.handlers.show.description import Handler as description_handler
+from testflows._core.cli.arg.handlers.show.description import (
+    Handler as description_handler,
+)
 from testflows._core.cli.arg.handlers.show.result import Handler as result_handler
 from testflows._core.cli.arg.handlers.show.examples import Handler as examples_handler
-from testflows._core.cli.arg.handlers.show.specifications import Handler as specifications_handler
+from testflows._core.cli.arg.handlers.show.specifications import (
+    Handler as specifications_handler,
+)
 from testflows._core.cli.arg.handlers.show.messages import Handler as messages_handler
 from testflows._core.cli.arg.handlers.show.tests import Handler as tests_handler
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("show", help="show test data", epilog=epilog(),
+        parser = commands.add_parser(
+            "show",
+            help="show test data",
+            epilog=epilog(),
             description="Show test data.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        show_commands = parser.add_subparsers(title="commands", metavar="command",
-            description=None, help=None)
+        show_commands = parser.add_subparsers(
+            title="commands", metavar="command", description=None, help=None
+        )
         show_commands.required = True
         results_handler.add_command(show_commands)
         passing_handler.add_command(show_commands)
         fails_handler.add_command(show_commands)
         unstable_handler.add_command(show_commands)
         totals_handler.add_command(show_commands)
         coverage_handler.add_command(show_commands)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/messages.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/messages.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,54 +19,84 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.nice import transform as nice_transform
 from testflows._core.transform.log.parse import transform as parse_transform
 from testflows._core.transform.log.write import transform as write_transform
 from testflows._core.transform.log.stop import transform as stop_transform
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("messages", help="messages", epilog=epilog(),
+        parser = commands.add_parser(
+            "messages",
+            help="messages",
+            epilog=epilog(),
             description="Show messages.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("name", metavar="name", type=str, help="test name", default=".*?", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default=".*?", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
         format_choices = ["nice", "raw"]
-        parser.add_argument("--format", "-f", metavar="name", type=str, choices=format_choices,
-            default="nice", help=f"output format, choices are {format_choices}, default: nice")
+        parser.add_argument(
+            "--format",
+            "-f",
+            metavar="name",
+            type=str,
+            choices=format_choices,
+            default="nice",
+            help=f"output format, choices are {format_choices}, default: nice",
+        )
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, format=None, tail=False):
             stop_event = threading.Event()
-            command = f"grep -E \',\"test_name\":\"%s'" % name
+            command = f'grep -E \',"test_name":"%s\'' % name
 
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail)
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                )
             ]
 
             if format != "raw":
                 steps += [parse_transform()]
 
             if format == "nice":
-                steps += [
-                    nice_transform()
-                ]
+                steps += [nice_transform()]
 
             steps.append(write_transform(output))
             steps.append(stop_transform(stop_event))
 
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
-        self.Pipeline(args.name.replace("'", r"'\''"), args.log, args.output, args.format).run()
+        self.Pipeline(
+            args.name.replace("'", r"'\''"), args.log, args.output, args.format
+        ).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/metrics.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/result.py`

 * *Files 7% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
 from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("metrics", help="metrics", epilog=epilog(),
-            description="Show metrics.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "result",
+            help="result",
+            epilog=epilog(),
+            description="Show result.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.METRIC.name
-            ]
+            message_types = [Message.RESULT.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
                 flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/passing.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/classic.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2019 Katteli Inc.
+# Copyright 2020 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -13,25 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import PassingReportLogPipeline
+from testflows._core.transform.log.pipeline import ClassicLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("passing", help="passing", epilog=epilog(),
-            description="Show only passing tests.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "classic",
+            help="classic transform",
+            epilog=epilog(),
+            description="Transform log into a classic summary format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        PassingReportLogPipeline(args.input, args.output).run()
+        ClassicLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/procedure.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/metrics.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2019 Katteli Inc.
+# Copyright 2021 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -16,45 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
-from testflows._core.transform.log.procedure import transform as procedure_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
+from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
-from testflows._core.transform.log.write import transform as write_transform
 from testflows._core.transform.log.stop import transform as stop_transform
+from testflows._core.transform.log.write import transform as write_transform
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("procedure", help="procedure", epilog=epilog(),
-            description="Show procedure.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "metrics",
+            help="metrics",
+            epilog=epilog(),
+            description="Show metrics.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            command = "grep -E '^\\{\"message_keyword\":\"%s\"" % Message.TEST.name
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            message_types = [Message.METRIC.name]
+
+            command = 'grep -E \'^\\{"message_keyword":"'
+            command = f"{command}({'|'.join(message_types)})\""
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
-                procedure_transform(),
+                flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
-        self.Pipeline(args.name, args.log, args.output).run()
+        self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/requirements.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/tests.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
-from testflows._core.transform.log.flat import transform as flat_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
+from testflows._core.transform.log.tests import transform as tests_transform
 from testflows._core.transform.log.parse import transform as parse_transform
-from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
+from testflows._core.transform.log.stop import transform as stop_transform
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("requirements", help="requirements", epilog=epilog(),
-            description="Show requirements.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "tests",
+            help="tests",
+            epilog=epilog(),
+            description="Show tests.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.REQUIREMENT.name
-            ]
+            message_types = [Message.TEST.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
-                flat_transform(),
+                tests_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/result.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/tags.py`

 * *Files 17% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
-from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
+from testflows._core.transform.log.stop import transform as stop_transform
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("result", help="result", epilog=epilog(),
-            description="Show result.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "tags",
+            help="tags",
+            epilog=epilog(),
+            description="Show tags.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.RESULT.name
-            ]
+            message_types = [Message.TAG.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
                 flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/results.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/raw.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2020 Katteli Inc.
+# Copyright 2019 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -13,25 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import ResultsReportLogPipeline
+from testflows._core.transform.log.pipeline import RawLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("results", help="results", epilog=epilog(),
-            description="Show test results.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "raw",
+            help="raw transform",
+            epilog=epilog(),
+            description="Transform log into a raw format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        ResultsReportLogPipeline(args.input, args.output).run()
+        RawLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/specifications.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/procedure.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2021 Katteli Inc.
+# Copyright 2019 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -16,50 +16,68 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
-from testflows._core.transform.log.flat import transform as flat_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
+from testflows._core.transform.log.procedure import transform as procedure_transform
 from testflows._core.transform.log.parse import transform as parse_transform
-from testflows._core.transform.log.stop import transform as stop_transform
 from testflows._core.transform.log.write import transform as write_transform
+from testflows._core.transform.log.stop import transform as stop_transform
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("specifications", help="specifications", epilog=epilog(),
-            description="Show specifications.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "procedure",
+            help="procedure",
+            epilog=epilog(),
+            description="Show procedure.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.SPECIFICATION.name
-            ]
-
-            command = "grep -E '^\\{\"message_keyword\":\""
-            command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command = 'grep -E \'^\\{"message_keyword":"%s"' % Message.TEST.name
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
-                flat_transform(),
+                procedure_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
-        self.Pipeline(args.name, args.log, args.output, tail=True).run()
+        self.Pipeline(args.name, args.log, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/tags.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/arguments.py`

 * *Files 12% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
 from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
-from testflows._core.transform.log.write import transform as write_transform
 from testflows._core.transform.log.stop import transform as stop_transform
+from testflows._core.transform.log.write import transform as write_transform
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("tags", help="tags", epilog=epilog(),
-            description="Show tags.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "arguments",
+            help="arguments",
+            epilog=epilog(),
+            description="Show arguments.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.TAG.name
-            ]
+            message_types = [Message.ARGUMENT.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
                 flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/tests.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/description.py`

 * *Files 20% similar despite different names*

```diff
@@ -16,50 +16,71 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.message import Message
 from testflows._core.transform.log.pipeline import Pipeline as PipelineBase
-from testflows._core.transform.log.read_and_filter import transform as read_and_filter_transform
-from testflows._core.transform.log.tests import transform as tests_transform
+from testflows._core.transform.log.read_and_filter import (
+    transform as read_and_filter_transform,
+)
+from testflows._core.transform.log.flat import transform as flat_transform
 from testflows._core.transform.log.parse import transform as parse_transform
-from testflows._core.transform.log.write import transform as write_transform
 from testflows._core.transform.log.stop import transform as stop_transform
+from testflows._core.transform.log.write import transform as write_transform
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("tests", help="tests", epilog=epilog(),
-            description="Show tests.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("name", metavar="name", type=str, help="test name", default="", nargs="?")
-        parser.add_argument("--log", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("--output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output, default: stdout', default="-")
+        parser = commands.add_parser(
+            "description",
+            help="description",
+            epilog=epilog(),
+            description="Show description.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "name", metavar="name", type=str, help="test name", default="", nargs="?"
+        )
+        parser.add_argument(
+            "--log",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "--output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     class Pipeline(PipelineBase):
         def __init__(self, name, input, output, tail=False):
             stop_event = threading.Event()
 
-            message_types = [
-                Message.TEST.name
-            ]
+            message_types = [Message.TEST.name]
 
-            command = "grep -E '^\\{\"message_keyword\":\""
+            command = 'grep -E \'^\\{"message_keyword":"'
             command = f"{command}({'|'.join(message_types)})\""
-            command += ".+,\"test_name\":\"%s.*?\",'" % name.replace("'", r"'\''")
+            command += '.+,"test_name":"%s.*?",\'' % name.replace("'", r"'\''")
             steps = [
-                read_and_filter_transform(input, command=command, stop=stop_event, tail=tail),
+                read_and_filter_transform(
+                    input, command=command, stop=stop_event, tail=tail
+                ),
                 parse_transform(),
-                tests_transform(),
+                flat_transform(),
                 write_transform(output),
-                stop_transform(stop_event)
+                stop_transform(stop_event),
             ]
             super(Handler.Pipeline, self).__init__(steps, stop=stop_event)
 
     def handle(self, args):
         self.Pipeline(args.name, args.log, args.output, tail=True).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/totals.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/totals.py`

 * *Files 16% similar despite different names*

```diff
@@ -15,23 +15,40 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.transform.log.pipeline import TotalsReportLogPipeline
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("totals", help="totals", epilog=epilog(),
+        parser = commands.add_parser(
+            "totals",
+            help="totals",
+            epilog=epilog(),
             description="Show total counts.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
         TotalsReportLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/show/unstable.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/unstable.py`

 * *Files 20% similar despite different names*

```diff
@@ -15,23 +15,40 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.transform.log.pipeline import UnstableReportLogPipeline
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("unstable", help="unstable", epilog=epilog(),
+        parser = commands.add_parser(
+            "unstable",
+            help="unstable",
+            epilog=epilog(),
             description="Show unstable tests.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
         UnstableReportLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/brisk.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/brisk.py`

 * *Files 14% similar despite different names*

```diff
@@ -15,23 +15,40 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.transform.log.pipeline import BriskLogPipeline
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("brisk", help="brisk transform", epilog=epilog(),
+        parser = commands.add_parser(
+            "brisk",
+            help="brisk transform",
+            epilog=epilog(),
             description="Transform log into a brisk format.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        BriskLogPipeline(args.input, args.output).run()
+        BriskLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/classic.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/nice.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2020 Katteli Inc.
+# Copyright 2019 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -13,25 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import ClassicLogPipeline
+from testflows._core.transform.log.pipeline import NiceLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("classic", help="classic transform", epilog=epilog(),
-            description="Transform log into a classic summary format.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "nice",
+            help="nice transform",
+            epilog=epilog(),
+            description="Transform log into a nice format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        ClassicLogPipeline(args.input, args.output).run()
+        NiceLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/compact.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/decompress.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2019 Katteli Inc.
+# Copyright 2020 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -13,28 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import CompactRawLogPipeline
+from testflows._core.transform.log.pipeline import ReadRawLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("compact", help="compact transform", epilog=epilog(),
-            description="Transform log into compact raw log containing only test results.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("--with-steps", action="store_true", help="include test steps, default: True", default=True)
-        parser.add_argument("--without-steps", action="store_true", help="exclude test steps, default: False", default=False)
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.logfile("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "decompress",
+            help="decompress transform",
+            epilog=epilog(),
+            description="Transform file into a decompressed format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("rb"),
+            nargs="?",
+            help="input file, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("wb"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        with args.output:
-            CompactRawLogPipeline(args.input, args.output, steps=(not args.without_steps)).run()
+        ReadRawLogPipeline(args.input, args.output, encoding=None).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/compress.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/compress.py`

 * *Files 22% similar despite different names*

```diff
@@ -15,24 +15,41 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.transform.log.pipeline import ReadRawLogPipeline
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("compress", help="compress transform", epilog=epilog(),
+        parser = commands.add_parser(
+            "compress",
+            help="compress transform",
+            epilog=epilog(),
             description="Transform file into a compressed format.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("rb"),
-                nargs="?", help="input file, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.logfile("wb"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("rb"),
+            nargs="?",
+            help="input file, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.logfile("wb"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
         with args.output:
-            ReadRawLogPipeline(args.input, args.output, encoding=None).run()
+            ReadRawLogPipeline(args.input, args.output, encoding=None).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/dots.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/pnice.py`

 * *Files 27% similar despite different names*

```diff
@@ -13,25 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import DotsLogPipeline
+from testflows._core.transform.log.pipeline import ParallelNiceLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("dots", help="dots transform", epilog=epilog(),
-            description="Transform log into a dots format.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "pnice",
+            help="parallel nice transform",
+            epilog=epilog(),
+            description="Transform log into a parallel nice format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        DotsLogPipeline(args.input, args.output).run()
+        ParallelNiceLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/handler.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/handler.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,37 +16,53 @@
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.cli.arg.handlers.transform.nice import Handler as nice_handler
 from testflows._core.cli.arg.handlers.transform.pnice import Handler as pnice_handler
 from testflows._core.cli.arg.handlers.transform.brisk import Handler as brisk_handler
 from testflows._core.cli.arg.handlers.transform.short import Handler as short_handler
 from testflows._core.cli.arg.handlers.transform.dots import Handler as dots_handler
-from testflows._core.cli.arg.handlers.transform.compact import Handler as compact_handler
+from testflows._core.cli.arg.handlers.transform.compact import (
+    Handler as compact_handler,
+)
 from testflows._core.cli.arg.handlers.transform.slick import Handler as slick_handler
-from testflows._core.cli.arg.handlers.transform.classic import Handler as classic_handler
+from testflows._core.cli.arg.handlers.transform.classic import (
+    Handler as classic_handler,
+)
 from testflows._core.cli.arg.handlers.transform.manual import Handler as manual_handler
 from testflows._core.cli.arg.handlers.transform.fails import Handler as fails_handler
 from testflows._core.cli.arg.handlers.transform.raw import Handler as raw_handler
-from testflows._core.cli.arg.handlers.transform.compress import Handler as compress_handler
-from testflows._core.cli.arg.handlers.transform.decompress import Handler as decompress_handler
+from testflows._core.cli.arg.handlers.transform.compress import (
+    Handler as compress_handler,
+)
+from testflows._core.cli.arg.handlers.transform.decompress import (
+    Handler as decompress_handler,
+)
 
 try:
-    from testflows.enterprise._core.cli.transform.handler import Handler as enterprise_handler
+    from testflows.enterprise._core.cli.transform.handler import (
+        Handler as enterprise_handler,
+    )
 except:
     enterprise_handler = None
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("transform", help="log file transformation", epilog=epilog(),
+        parser = commands.add_parser(
+            "transform",
+            help="log file transformation",
+            epilog=epilog(),
             description="Transform log files.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        transform_commands = parser.add_subparsers(title="commands", metavar="command",
-            description=None, help=None)
+        transform_commands = parser.add_subparsers(
+            title="commands", metavar="command", description=None, help=None
+        )
         transform_commands.required = True
         raw_handler.add_command(transform_commands)
         nice_handler.add_command(transform_commands)
         pnice_handler.add_command(transform_commands)
         brisk_handler.add_command(transform_commands)
         short_handler.add_command(transform_commands)
         slick_handler.add_command(transform_commands)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/manual.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/manual.py`

 * *Files 12% similar despite different names*

```diff
@@ -15,23 +15,40 @@
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
 from testflows._core.transform.log.pipeline import ManualLogPipeline
 
+
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("manual", help="manual transform", epilog=epilog(),
+        parser = commands.add_parser(
+            "manual",
+            help="manual transform",
+            epilog=epilog(),
             description="Transform log into a manual format.",
-            formatter_class=HelpFormatter)
+            formatter_class=HelpFormatter,
+        )
 
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        ManualLogPipeline(args.input, args.output).run()
+        ManualLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/nice.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/short.py`

 * *Files 20% similar despite different names*

```diff
@@ -13,25 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import NiceLogPipeline
+from testflows._core.transform.log.pipeline import ShortLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("nice", help="nice transform", epilog=epilog(),
-            description="Transform log into a nice format.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "short",
+            help="short transform",
+            epilog=epilog(),
+            description="Transform log into a short format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        NiceLogPipeline(args.input, args.output).run()
+        ShortLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/pnice.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/results.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2019 Katteli Inc.
+# Copyright 2020 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -13,25 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import ParallelNiceLogPipeline
+from testflows._core.transform.log.pipeline import ResultsReportLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("pnice", help="parallel nice transform", epilog=epilog(),
-            description="Transform log into a parallel nice format.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "results",
+            help="results",
+            epilog=epilog(),
+            description="Show test results.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        ParallelNiceLogPipeline(args.input, args.output).run()
+        ResultsReportLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/raw.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/show/passing.py`

 * *Files 22% similar despite different names*

```diff
@@ -13,25 +13,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import RawLogPipeline
+from testflows._core.transform.log.pipeline import PassingReportLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("raw", help="raw transform", epilog=epilog(),
-            description="Transform log into a raw format.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "passing",
+            help="passing",
+            epilog=epilog(),
+            description="Show only passing tests.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        RawLogPipeline(args.input, args.output).run()
+        PassingReportLogPipeline(args.input, args.output).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/short.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/fails.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2019 Katteli Inc.
+# Copyright 2020 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -13,25 +13,49 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import ShortLogPipeline
+from testflows._core.transform.log.pipeline import FailsLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("short", help="short transform", epilog=epilog(),
-            description="Transform log into a short format.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "fails",
+            help="fails transform",
+            epilog=epilog(),
+            description="Transform log into a fails summary format.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.file("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
+        parser.add_argument(
+            "-n",
+            "--new",
+            action="store_true",
+            help="show only new fails",
+            default=False,
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        ShortLogPipeline(args.input, args.output).run()
+        FailsLogPipeline(args.input, args.output, only_new=args.new).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/handlers/transform/slick.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/compact.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2020 Katteli Inc.
+# Copyright 2019 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
@@ -13,25 +13,57 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.cli.arg.type as argtype
 
 from testflows._core.cli.arg.common import epilog
 from testflows._core.cli.arg.common import HelpFormatter
 from testflows._core.cli.arg.handlers.handler import Handler as HandlerBase
-from testflows._core.transform.log.pipeline import SlickLogPipeline
+from testflows._core.transform.log.pipeline import CompactRawLogPipeline
+
 
 class Handler(HandlerBase):
     @classmethod
     def add_command(cls, commands):
-        parser = commands.add_parser("slick", help="slick transform", epilog=epilog(),
-            description="Transform log into a slick format.",
-            formatter_class=HelpFormatter)
-
-        parser.add_argument("input", metavar="input", type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
-                nargs="?", help="input log, default: stdin", default="-")
-        parser.add_argument("output", metavar="output", type=argtype.file("w", bufsize=1, encoding="utf-8"),
-                nargs="?", help='output file, default: stdout', default="-")
+        parser = commands.add_parser(
+            "compact",
+            help="compact transform",
+            epilog=epilog(),
+            description="Transform log into compact raw log containing only test results.",
+            formatter_class=HelpFormatter,
+        )
+
+        parser.add_argument(
+            "--with-steps",
+            action="store_true",
+            help="include test steps, default: True",
+            default=True,
+        )
+        parser.add_argument(
+            "--without-steps",
+            action="store_true",
+            help="exclude test steps, default: False",
+            default=False,
+        )
+        parser.add_argument(
+            "input",
+            metavar="input",
+            type=argtype.logfile("r", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="input log, default: stdin",
+            default="-",
+        )
+        parser.add_argument(
+            "output",
+            metavar="output",
+            type=argtype.logfile("w", bufsize=1, encoding="utf-8"),
+            nargs="?",
+            help="output file, default: stdout",
+            default="-",
+        )
 
         parser.set_defaults(func=cls())
 
     def handle(self, args):
-        SlickLogPipeline(args.input, args.output).run()
+        with args.output:
+            CompactRawLogPipeline(
+                args.input, args.output, steps=(not args.without_steps)
+            ).run()
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/parser.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/parser.py`

 * *Files 19% similar despite different names*

```diff
@@ -32,49 +32,83 @@
 try:
     from testflows.database.cli.handler import Handler as database_handler
 except:
     database_handler = None
 
 try:
     from testflows.enterprise._core.cli.handler import Handler as enterprise_handler
-    from testflows.enterprise._core.cli.parser import argument_parser as enterprise_parser
+    from testflows.enterprise._core.cli.parser import (
+        argument_parser as enterprise_parser,
+    )
 except:
     enterprise_handler = None
     enterprise_parser = None
 
 from testflows._core import __version__, __license__
 
+
 class ArgumentParser(ArgumentParserBase):
-    """Customized argument parser.
-    """
+    """Customized argument parser."""
+
     def __init__(self, *args, **kwargs):
         description_prog = kwargs.pop("description_prog", None)
         kwargs["epilog"] = kwargs.pop("epilog", epilog())
-        kwargs["description"] = description(textwrap.dedent(kwargs.pop("description", None) or ""), prog=description_prog)
+        kwargs["description"] = description(
+            textwrap.dedent(kwargs.pop("description", None) or ""),
+            prog=description_prog,
+        )
         kwargs["formatter_class"] = kwargs.pop("formatter_class", HelpFormatter)
         return super(ArgumentParser, self).__init__(*args, **kwargs)
 
+
 parser = ArgumentParser(prog="tfs")
 
-parser.add_argument("--debug", dest="debug", action="store_true",
-                    help="enable debugging mode", default=False)
-parser.add_argument("--no-colors", dest="no_colors", action="store_true",
-                    help="disable terminal color highlighting", default=False)
-parser.add_argument("--show-skipped", dest="show_skipped", action="store_true",
-                    help="show skipped tests, default: False", default=False)
-parser.add_argument("--trim-results", dest="trim_results", type=onoff_type,
-                    help="enable or disable trimming of result messages, default: on",
-                    metavar=onoff_type.metavar, default="on")
+parser.add_argument(
+    "--debug",
+    dest="debug",
+    action="store_true",
+    help="enable debugging mode",
+    default=False,
+)
+parser.add_argument(
+    "--no-colors",
+    dest="no_colors",
+    action="store_true",
+    help="disable terminal color highlighting",
+    default=False,
+)
+parser.add_argument(
+    "--show-skipped",
+    dest="show_skipped",
+    action="store_true",
+    help="show skipped tests, default: False",
+    default=False,
+)
+parser.add_argument(
+    "--trim-results",
+    dest="trim_results",
+    type=onoff_type,
+    help="enable or disable trimming of result messages, default: on",
+    metavar=onoff_type.metavar,
+    default="on",
+)
 parser.add_argument("-v", "--version", action="version", version=f"{__version__}")
-parser.add_argument("--license", action="version", help="show program's license and exit", version=f"{__license__}")
+parser.add_argument(
+    "--license",
+    action="version",
+    help="show program's license and exit",
+    version=f"{__license__}",
+)
 
 if enterprise_parser:
     enterprise_parser(parser)
 
-commands = parser.add_subparsers(title='commands', metavar='command', description=None, help=None)
+commands = parser.add_subparsers(
+    title="commands", metavar="command", description=None, help=None
+)
 commands.required = True
 
 log_handler.add_command(commands)
 report_handler.add_command(commands)
 transform_handler.add_command(commands)
 requirement_handler.add_command(commands)
 document_handler.add_command(commands)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/arg/type.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/type.py`

 * *Files 4% similar despite different names*

```diff
@@ -26,71 +26,75 @@
 from testflows._core.tracing import logging
 
 import testflows._core.contrib.rsa as rsa
 
 KeyValue = namedtuple("KeyValue", "key value")
 NoneValue = "__none__"
 
+
 class FileType(object):
-    def __init__(self, mode='r', bufsize=-1, encoding=None, errors=None, safe=False):
+    def __init__(self, mode="r", bufsize=-1, encoding=None, errors=None, safe=False):
         self._mode = mode
         self._bufsize = bufsize
         self._encoding = encoding
         self._errors = errors
         self._safe = safe
 
     def __call__(self, string):
         # the special argument "-" means sys.std{in,out}
-        if string == '-':
-            if 'r' in self._mode:
-                if 'b' in self._mode:
+        if string == "-":
+            if "r" in self._mode:
+                if "b" in self._mode:
                     return sys.stdin.buffer
                 return sys.stdin
-            elif 'w' in self._mode:
-                if 'b' in self._mode:
+            elif "w" in self._mode:
+                if "b" in self._mode:
                     return sys.stdout.buffer
                 return sys.stdout
             else:
                 msg = argparse._('argument "-" with mode %r') % self._mode
                 raise ValueError(msg)
 
         # all other arguments are used as file names
         try:
             if self._safe and os.path.exists(string):
-                raise FileExistsError(f"File '{string}' already exists, please delete it first.")
+                raise FileExistsError(
+                    f"File '{string}' already exists, please delete it first."
+                )
 
-            return open(string, self._mode, self._bufsize, self._encoding,
-                        self._errors)
+            return open(string, self._mode, self._bufsize, self._encoding, self._errors)
         except OSError as e:
             message = argparse._("can't open '%s': %s")
             raise ArgumentTypeError(message % (string, e))
 
     def __repr__(self):
         args = self._mode, self._bufsize
-        kwargs = [('encoding', self._encoding), ('errors', self._errors)]
-        args_str = ', '.join([repr(arg) for arg in args if arg != -1] +
-                             ['%s=%r' % (kw, arg) for kw, arg in kwargs
-                              if arg is not None])
-        return '%s(%s)' % (type(self).__name__, args_str)
+        kwargs = [("encoding", self._encoding), ("errors", self._errors)]
+        args_str = ", ".join(
+            [repr(arg) for arg in args if arg != -1]
+            + ["%s=%r" % (kw, arg) for kw, arg in kwargs if arg is not None]
+        )
+        return "%s(%s)" % (type(self).__name__, args_str)
+
 
 class LogFileType(object):
-    def __init__(self, mode='r', bufsize=-1, encoding=None, errors=None):
+    def __init__(self, mode="r", bufsize=-1, encoding=None, errors=None):
         self._mode = mode
         self._encoding = encoding
         self._errors = errors
 
     def __call__(self, string):
         # the special argument "-" means sys.std{in,out}
-        if string == '-':
-            if 'r' in self._mode:
+        if string == "-":
+            if "r" in self._mode:
                 fp = CompressedFile(sys.stdin.buffer, self._mode)
                 if self._encoding:
                     return io.TextIOWrapper(fp, self._encoding, self._errors)
                 return fp
-            elif 'w' in self._mode:
+            elif "w" in self._mode:
                 fp = CompressedFile(sys.stdout.buffer, self._mode)
                 if self._encoding:
                     return io.TextIOWrapper(fp, self._encoding, self._errors)
                 return fp
             else:
                 msg = argparse._('argument "-" with mode %r') % self._mode
                 raise ValueError(msg)
@@ -103,118 +107,142 @@
             return fp
         except OSError as e:
             message = argparse._("can't open '%s': %s")
             raise ArgumentTypeError(message % (string, e))
 
     def __repr__(self):
         args = self._mode
-        kwargs = [('encoding', self._encoding), ('errors', self._errors)]
-        args_str = ', '.join([repr(arg) for arg in args if arg != -1] +
-                             ['%s=%r' % (kw, arg) for kw, arg in kwargs
-                              if arg is not None])
-        return '%s(%s)' % (type(self).__name__, args_str)
+        kwargs = [("encoding", self._encoding), ("errors", self._errors)]
+        args_str = ", ".join(
+            [repr(arg) for arg in args if arg != -1]
+            + ["%s=%r" % (kw, arg) for kw, arg in kwargs if arg is not None]
+        )
+        return "%s(%s)" % (type(self).__name__, args_str)
+
 
 def path(p, special=""):
     if p in special or []:
         return p
     if not os.path.exists(os.path.abspath(p)):
         raise ArgumentTypeError(f"path does not exist: '{os.path.abspath(p)}'")
     return p
 
+
 def file(*args, **kwargs):
     """File type."""
     return FileType(*args, **kwargs)
 
+
 def logfile(*args, **kwargs):
     """Log file type."""
     return LogFileType(*args, **kwargs)
 
+
 def rsa_private_key_pem_file(p):
-    """RSA private key PEM file type.
-    """
+    """RSA private key PEM file type."""
     with open(p, mode="rb") as pem_file:
         return rsa.PrivateKey.load_pkcs1(pem_file.read())
 
-def key_value(s, sep='='):
-    """Parse a key, value pair using a seperator (default: '=').
-    """
+
+def key_value(s, sep="="):
+    """Parse a key, value pair using a seperator (default: '=')."""
     if sep not in s:
         raise ArgumentTypeError(f"invalid format of key{sep}value")
-    key, value= s.split(sep, 1)
+    key, value = s.split(sep, 1)
     return KeyValue(key.strip(), value.strip())
 
+
 def count(value):
     try:
         value = int(value)
         assert value >= 0
     except:
         raise ArgumentTypeError(f"{value} is not a positive number")
     return value
 
+
 def repeat(value):
     try:
         fields = list(csv.reader([value], "unix"))[-1]
         until = "fail"
         if len(fields) > 2:
             pattern, count, until = fields
         else:
             pattern, count = fields
         option = Repeat(count=count, pattern=pattern, until=until)
     except Exception as e:
         raise ArgumentTypeError(f"'{value}' is invalid")
     return option
 
+
 def retry(value):
     try:
         fields = list(csv.reader([value], "unix"))[-1]
-        jitter = None # can't be specified
+        jitter = None  # can't be specified
         if len(fields) < 2:
             raise ValueError("needs at least 2 values")
-        pattern, count, timeout, delay, backoff = [*fields, *["", None, None, 0, 1][len(fields):]]
+        pattern, count, timeout, delay, backoff = [
+            *fields,
+            *["", None, None, 0, 1][len(fields) :],
+        ]
         if not pattern:
             pattern = ""
         if not count:
             count = None
         if not timeout:
             timeout = None
         if not delay:
             delay = 0
         if not backoff:
             backoff = 1
-        option = Retry(count=count, timeout=timeout, delay=delay, backoff=backoff, jitter=jitter, pattern=pattern)
+        option = Retry(
+            count=count,
+            timeout=timeout,
+            delay=delay,
+            backoff=backoff,
+            jitter=jitter,
+            pattern=pattern,
+        )
     except Exception as e:
         raise ArgumentTypeError(f"'{value}' is invalid")
     return option
 
+
 def tags_filter(value):
     try:
         type, cvstags = value.split(":", 1)
         assert type in ["test", "suite", "module", "feature", "scenario", "any"]
         tags = list(csv.reader([cvstags], "unix"))[-1]
         if type == "scenario":
             type = "test"
         elif type == "feature":
             type = "suite"
         option = (type, tuple(tags))
     except Exception as e:
         raise ArgumentTypeError(f"'{value}' is invalid")
     return option
 
+
 def onoff(value):
     if value.lower() in ["yes", "1", "on"]:
         return True
     elif value.lower() in ["no", "0", "off"]:
         return False
     elif value == NoneValue:
         return NoneValue
     raise ArgumentTypeError(f"'{value}' is invalid")
 
-onoff.metavar = str(set(["yes", "1", "on", "no", "0", "off"])).replace(" ","").replace("'","")
+
+onoff.metavar = (
+    str(set(["yes", "1", "on", "no", "0", "off"])).replace(" ", "").replace("'", "")
+)
+
 
 def trace_level(value):
     if value.lower() in ["debug", "info", "warning", "error", "critical"]:
         return getattr(logging, value.upper())
     else:
         raise ArgumentTypeError(f"'{value}' is invalid")
 
+
 trace_level.choices = ["debug", "info", "warning", "error", "critical"]
-trace_level.metavar = str(set(trace_level.choices)).replace(" ","").replace("'","")
+trace_level.metavar = str(set(trace_level.choices)).replace(" ", "").replace("'", "")
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/colors.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/colors.py`

 * *Files 8% similar despite different names*

```diff
@@ -22,94 +22,107 @@
 
 """ANSII Color formatting for output in terminal."""
 
 import testflows.settings as settings
 
 from testflows._core.contrib.x256 import x256
 
-__ALL__ = [ 'colored', 'cprint' ]
+__ALL__ = ["colored", "cprint"]
 
 ATTRIBUTES = dict(
-        list(zip([
-            'bold',
-            'dim',
-            '',
-            'underline',
-            'blink',
-            '',
-            'reverse',
-            'concealed'
-            ],
-            list(range(1, 9))
-            ))
+    list(
+        zip(
+            ["bold", "dim", "", "underline", "blink", "", "reverse", "concealed"],
+            list(range(1, 9)),
         )
-del ATTRIBUTES['']
+    )
+)
+del ATTRIBUTES[""]
 
 
 HIGHLIGHTS = dict(
-        list(zip([
-            'on_grey',
-            'on_red',
-            'on_green',
-            'on_yellow',
-            'on_blue',
-            'on_magenta',
-            'on_cyan',
-            'on_white'
+    list(
+        zip(
+            [
+                "on_grey",
+                "on_red",
+                "on_green",
+                "on_yellow",
+                "on_blue",
+                "on_magenta",
+                "on_cyan",
+                "on_white",
             ],
-            list(range(40, 48))
-            ))
+            list(range(40, 48)),
         )
+    )
+)
 
 
 COLORS = dict(
-        list(zip([
-            'grey',
-            'red',
-            'green',
-            'yellow',
-            'blue',
-            'magenta',
-            'cyan',
-            'white',
+    list(
+        zip(
+            [
+                "grey",
+                "red",
+                "green",
+                "yellow",
+                "blue",
+                "magenta",
+                "cyan",
+                "white",
             ],
-            list(range(30, 38))
-            ))
+            list(range(30, 38)),
         )
+    )
+)
+
 
 def reset(no_colors=False):
-    return '\033[0m' if not (no_colors and settings.no_colors) else ''
+    return "\033[0m" if not (no_colors and settings.no_colors) else ""
+
 
 def cursor_hide(no_colors=False):
-    return '\033[?25l' if not (no_colors and settings.no_colors) else ''
+    return "\033[?25l" if not (no_colors and settings.no_colors) else ""
+
 
 def cursor_up(no_colors=False):
-    return '\033[A' if not (no_colors and settings.no_colors) else ''
+    return "\033[A" if not (no_colors and settings.no_colors) else ""
+
 
 def clear_screen(no_colors=False):
-    return chr(27) + "[2J" + '\033[0;0H'  if not (no_colors and settings.no_colors) else ''
+    return (
+        chr(27) + "[2J" + "\033[0;0H" if not (no_colors and settings.no_colors) else ""
+    )
+
 
 def red(text, on_color=None, attrs=None, no_colors=False):
     return color(text, "red", on_color=on_color, attrs=attrs, no_colors=no_colors)
 
+
 def green(text, on_color=None, attrs=None, no_colors=False):
     return color(text, "green", on_color=on_color, attrs=attrs, no_colors=no_colors)
 
+
 def yellow(text, on_color=None, attrs=None, no_colors=False):
     return color(text, "yellow", on_color=on_color, attrs=attrs, no_colors=no_colors)
 
+
 def blue(text, on_color=None, attrs=None, no_colors=False):
     return color(text, "blue", on_color=on_color, attrs=attrs, no_colors=no_colors)
 
+
 def cyan(text, on_color=None, attrs=None, no_colors=False):
     return color(text, "cyan", on_color=on_color, attrs=attrs, no_colors=no_colors)
 
+
 def white(text, on_color=None, attrs=None, no_colors=False):
     return color(text, "white", on_color=on_color, attrs=attrs, no_colors=no_colors)
 
+
 def color(text, color=None, on_color=None, attrs=None, no_colors=False):
     """Colorize text.
 
     Available text colors:
         red, green, yellow, blue, magenta, cyan, white.
 
     Available text highlights:
@@ -121,20 +134,20 @@
     Example:
         colored('Hello, World!', 'red', 'on_grey', ['blue', 'blink'])
         colored('Hello, World!', 'green')
     """
     if no_colors or settings.no_colors:
         pass
     else:
-        fmt_str = '\033[%dm%s'
+        fmt_str = "\033[%dm%s"
         if color is not None:
             if type(color) in (tuple, list):
                 # convert RGB to closest x256
                 color_256 = x256.from_rgb(*color)
-                text = '\x1b[38;5;%dm%s' % (color_256, text)
+                text = "\x1b[38;5;%dm%s" % (color_256, text)
             else:
                 text = fmt_str % (COLORS[color], text)
 
         if on_color is not None:
             text = fmt_str % (HIGHLIGHTS[on_color], text)
 
         if attrs is not None:
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/cli/text.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/text.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,54 +10,60 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.cli.colors import color
 
+
 def primary(text, eol="\n", bold=True, dim=False):
     attrs = []
     if bold:
         attrs.append("bold")
     if dim:
         attrs.append("dim")
     return color(text + eol, "white", attrs=attrs)
 
+
 def secondary(text, eol="\n", bold=False, dim=True):
     attrs = []
     if bold:
         attrs.append("bold")
     if dim:
         attrs.append("dim")
     return color(text + eol, "white", attrs=attrs)
 
+
 def danger(text, eol="\n", bold=True, dim=False):
     attrs = []
     if bold:
         attrs.append("bold")
     if dim:
         attrs.append("dim")
     return color(text + eol, "red", attrs=attrs)
 
+
 def success(text, eol="\n", bold=True, dim=False):
     attrs = []
     if bold:
         attrs.append("bold")
     if dim:
         attrs.append("dim")
     return color(text + eol, "green", attrs=attrs)
 
+
 def warning(text, eol="\n", bold=True, dim=False):
     attrs = []
     if bold:
         attrs.append("bold")
     if dim:
         attrs.append("dim")
     return color(text + eol, "yellow", attrs=attrs)
 
+
 def info(text, eol="\n", bold=True, dim=False):
     attrs = []
     if bold:
         attrs.append("bold")
     if dim:
         attrs.append("dim")
     return color(text + eol, "blue", attrs=attrs)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/compress.py` & `testflows.core-1.9.230627.1151633/testflows/_core/compress.py`

 * *Files 5% similar despite different names*

```diff
@@ -21,47 +21,47 @@
 import _compression
 
 from lzma import compress, decompress
 
 Compressor = lzma.LZMACompressor
 Decompressor = lzma.LZMADecompressor
 
-class TailingDecompressReader(_compression.DecompressReader):
 
+class TailingDecompressReader(_compression.DecompressReader):
     def __init__(self, *args, **kwargs):
         self._tail = kwargs.pop("tail", True)
         self._tail_sleep = float(kwargs.pop("tail_sleep", 0.15))
         # default compressed file marker '.7zXZ'
         self._COMPRESSED_FILE_MARKER = b"\xfd\x37\x7a\x58\x5a"
         # default uncompressed file marker is start of the message
-        self._UNCOMPRESSED_FILE_MARKER = "{\"message_keyword\"".encode("utf-8")
+        self._UNCOMPRESSED_FILE_MARKER = '{"message_keyword"'.encode("utf-8")
 
         super(TailingDecompressReader, self).__init__(*args, **kwargs)
 
     def read(self, size=-1, _tail_sleep=0.15):
         if size < 0:
             return self.readall()
 
         if not size or self._eof:
             return b""
         data = None  # Default if EOF is encountered
         # Depending on the input data, our call to the decompressor may not
         # return any data. In this case, try again after reading another block.
         while True:
             if self._decompressor.eof:
-                self.rawblock = (self._decompressor.unused_data or
-                            self._fp.read1(_compression.BUFFER_SIZE))
+                self.rawblock = self._decompressor.unused_data or self._fp.read1(
+                    _compression.BUFFER_SIZE
+                )
                 if not self.rawblock:
                     if not self._tail:
                         break
                     time.sleep(self._tail_sleep)
                     continue
                 # Continue to next stream.
-                self._decompressor = self._decomp_factory(
-                    **self._decomp_args)
+                self._decompressor = self._decomp_factory(**self._decomp_args)
                 try:
                     data = self._decompressor.decompress(self.rawblock, size)
                 except self._trailing_error:
                     # Trailing data isn't a valid compressed stream; ignore it.
                     break
             else:
                 if self._decompressor.needs_input:
@@ -83,22 +83,30 @@
                             raw_data = self._fp.read1(65536)
                             # abort on EOF if not tailing
                             if not raw_data:
                                 if not self._tail:
                                     raise
                             self.rawblock += raw_data
                             # try to find compressed file marker
-                            compressed_file_marker_idx = self.rawblock.find(self._COMPRESSED_FILE_MARKER)
+                            compressed_file_marker_idx = self.rawblock.find(
+                                self._COMPRESSED_FILE_MARKER
+                            )
                             if compressed_file_marker_idx >= 0:
-                                self.rawblock = self.rawblock[compressed_file_marker_idx:]
+                                self.rawblock = self.rawblock[
+                                    compressed_file_marker_idx:
+                                ]
                                 break
                             # try to find uncompressed file marker
-                            uncompressed_file_marker_idx = self.rawblock.find(self._UNCOMPRESSED_FILE_MARKER)
+                            uncompressed_file_marker_idx = self.rawblock.find(
+                                self._UNCOMPRESSED_FILE_MARKER
+                            )
                             if uncompressed_file_marker_idx >= 0:
-                                self.rawblock = self.rawblock[uncompressed_file_marker_idx:]
+                                self.rawblock = self.rawblock[
+                                    uncompressed_file_marker_idx:
+                                ]
                                 raise
                         # decompress compressed raw block that we found
                         self._decompressor = self._decomp_factory(**self._decomp_args)
                         return self._decompressor.decompress(self.rawblock, size)
             if data:
                 break
 
@@ -107,38 +115,52 @@
             self._size = self._pos
             return b""
         self._pos += len(data)
         return data
 
 
 class CompressedFile(lzma.LZMAFile):
-    def __init__(self, filename=None, mode="r", *,
-            format=None, check=-1, preset=None, filters=None, tail=False):
+    def __init__(
+        self,
+        filename=None,
+        mode="r",
+        *,
+        format=None,
+        check=-1,
+        preset=None,
+        filters=None,
+        tail=False
+    ):
         self._fp = None
         self._closefp = False
         self._mode = lzma._MODE_CLOSED
         self._raw_mode = False
         self._tail = tail
 
         if mode in ("r", "rb"):
             if check != -1:
-                raise ValueError("Cannot specify an integrity check "
-                                 "when opening a file for reading")
+                raise ValueError(
+                    "Cannot specify an integrity check "
+                    "when opening a file for reading"
+                )
             if preset is not None:
-                raise ValueError("Cannot specify a preset compression "
-                                 "level when opening a file for reading")
+                raise ValueError(
+                    "Cannot specify a preset compression "
+                    "level when opening a file for reading"
+                )
             if format is None:
                 format = lzma.FORMAT_AUTO
             mode_code = lzma._MODE_READ
         elif mode in ("w", "wb", "a", "ab", "x", "xb"):
             if format is None:
                 format = lzma.FORMAT_XZ
             mode_code = lzma._MODE_WRITE
-            self._compressor = lzma.LZMACompressor(format=format, check=check,
-                preset=preset, filters=filters)
+            self._compressor = lzma.LZMACompressor(
+                format=format, check=check, preset=preset, filters=filters
+            )
             self._pos = 0
         else:
             raise ValueError("Invalid mode: {!r}".format(mode))
 
         if filename is sys.stdin.buffer:
             self._fp = filename
             self._closefp = False
@@ -152,16 +174,22 @@
         elif hasattr(filename, "read") or hasattr(filename, "write"):
             self._fp = filename
             self._mode = mode_code
         else:
             raise TypeError("filename must be a str, bytes, file or PathLike object")
 
         if self._mode == lzma._MODE_READ:
-            self.raw = TailingDecompressReader(self._fp, lzma.LZMADecompressor,
-                trailing_error=lzma.LZMAError, format=format, filters=filters, tail=self._tail)
+            self.raw = TailingDecompressReader(
+                self._fp,
+                lzma.LZMADecompressor,
+                trailing_error=lzma.LZMAError,
+                format=format,
+                filters=filters,
+                tail=self._tail,
+            )
             self._buffer = io.BufferedReader(self.raw)
 
     @property
     def name(self):
         return getattr(self._fp, "name", None)
 
     def read(self, size=-1):
@@ -186,8 +214,8 @@
         try:
             return self._buffer.read1(size)
         except lzma.LZMAError as e:
             # fall back to raw mode if we can't decompress data
             if "Input format not supported by decoder" in str(e):
                 self._raw_mode = True
                 return self.raw.rawblock
-            raise
+            raise
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/constants.py` & `testflows.core-1.9.230627.1151633/testflows/_core/constants.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -13,8 +13,8 @@
 # See the License for the specific language governing permissions and
 # limitations under the License
 #: end of message
 end_of_message = "\n"
 #: name separator
 name_sep = "/"
 #: id separator
-id_sep = "/"
+id_sep = "/"
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/cli/arg/handlers/transform/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,8 +7,8 @@
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
-# limitations under the License
+# limitations under the License.
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/aiomsg/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/aiomsg/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/aiomsg/header.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/aiomsg/header.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/aiomsg/msgproto.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/aiomsg/msgproto.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/cleanpeg.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/cleanpeg.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/export.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/export.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/arpeggio/peg.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/arpeggio/peg.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/cloudpickle/cloudpickle.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/cloudpickle/cloudpickle.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/cloudpickle/cloudpickle_fast.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/cloudpickle/cloudpickle_fast.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/markdown2/markdown2.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/markdown2/markdown2.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/ber/decoder.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/ber/decoder.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/ber/encoder.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/ber/encoder.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/ber/eoo.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/ber/eoo.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/cer/decoder.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/cer/decoder.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/cer/encoder.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/cer/encoder.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/der/decoder.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/der/decoder.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/der/encoder.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/der/encoder.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/native/decoder.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/native/decoder.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/codec/native/encoder.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/codec/native/encoder.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/binary.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/binary.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/integer.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/integer.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/compat/octets.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/compat/octets.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/debug.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/debug.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/error.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/error.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/base.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/base.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/char.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/char.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/constraint.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/constraint.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/namedtype.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/namedtype.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/namedval.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/namedval.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/opentype.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/opentype.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/tag.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/tag.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/tagmap.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/tagmap.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/univ.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/univ.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pyasn1/type/useful.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pyasn1/type/useful.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/cmdline.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/cmdline.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/console.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/console.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/filter.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/filter.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/filters/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/filters/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatter.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatter.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/_mapping.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/_mapping.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/bbcode.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/bbcode.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/html.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/html.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/img.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/img.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/irc.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/irc.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/latex.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/latex.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/other.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/other.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/rtf.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/rtf.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/svg.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/svg.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/terminal.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/terminal.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/formatters/terminal256.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/formatters/terminal256.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexer.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexer.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_asy_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_asy_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_cl_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_cl_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_cocoa_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_cocoa_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_csound_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_csound_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_lasso_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_lasso_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_lua_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_lua_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_mapping.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_mapping.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_mql_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_mql_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_openedge_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_openedge_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_php_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_php_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_postgres_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_postgres_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_scilab_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_scilab_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_sourcemod_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_sourcemod_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_stan_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_stan_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_stata_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_stata_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_tsql_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_tsql_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_vbscript_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_vbscript_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/_vim_builtins.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/_vim_builtins.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/actionscript.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/actionscript.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/agile.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/agile.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/algebra.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/algebra.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ambient.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ambient.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ampl.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ampl.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/apl.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/apl.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/archetype.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/archetype.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/asm.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/asm.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/automation.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/automation.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/basic.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/basic.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/bibtex.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/bibtex.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/boa.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/boa.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/business.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/business.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/c_cpp.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/c_cpp.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/c_like.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/c_like.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/capnproto.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/capnproto.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/chapel.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/chapel.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/clean.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/clean.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/compiled.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/compiled.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/configs.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/configs.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/console.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/console.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/crystal.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/crystal.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/csound.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/csound.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/css.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/css.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/d.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/d.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/dalvik.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/dalvik.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/data.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/data.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/diff.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/diff.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/dotnet.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/dotnet.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/dsls.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/dsls.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/dylan.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/dylan.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ecl.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ecl.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/eiffel.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/eiffel.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/elm.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/elm.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/email.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/email.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/erlang.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/erlang.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/esoteric.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/esoteric.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ezhil.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ezhil.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/factor.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/factor.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/fantom.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/fantom.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/felix.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/felix.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/floscript.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/floscript.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/forth.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/forth.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/fortran.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/fortran.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/foxpro.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/foxpro.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/freefem.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/freefem.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/functional.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/functional.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/go.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/go.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/grammar_notation.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/grammar_notation.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/graph.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/graph.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/graphics.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/graphics.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/haskell.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/haskell.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/haxe.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/haxe.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/hdl.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/hdl.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/hexdump.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/hexdump.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/html.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/html.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/idl.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/idl.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/igor.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/igor.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/inferno.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/inferno.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/installers.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/installers.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/int_fiction.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/int_fiction.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/iolang.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/iolang.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/j.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/j.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/javascript.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/javascript.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/julia.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/julia.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/jvm.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/jvm.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/lisp.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/lisp.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/make.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/make.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/markup.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/markup.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/math.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/math.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/matlab.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/matlab.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/mime.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/mime.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ml.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ml.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/modeling.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/modeling.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/modula2.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/modula2.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/monte.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/monte.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ncl.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ncl.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/nimrod.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/nimrod.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/nit.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/nit.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/nix.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/nix.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/oberon.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/oberon.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/objective.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/objective.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ooc.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ooc.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/other.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/other.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/parasail.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/parasail.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/parsers.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/parsers.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/pascal.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/pascal.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/pawn.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/pawn.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/perl.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/perl.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/php.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/php.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/pony.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/pony.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/praat.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/praat.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/prolog.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/prolog.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/python.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/python.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/qvt.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/qvt.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/r.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/r.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/rdf.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/rdf.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/rebol.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/rebol.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/resource.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/resource.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/rnc.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/rnc.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/roboconf.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/roboconf.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/robotframework.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/robotframework.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/ruby.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/ruby.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/rust.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/rust.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/sas.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/sas.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/scdoc.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/scdoc.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/scripting.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/scripting.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/sgf.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/sgf.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/shell.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/shell.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/slash.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/slash.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/smalltalk.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/smalltalk.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/smv.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/smv.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/snobol.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/snobol.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/solidity.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/solidity.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/special.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/special.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/sql.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/sql.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/stata.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/stata.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/supercollider.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/supercollider.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/tcl.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/tcl.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/templates.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/templates.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/teraterm.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/teraterm.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/testflows.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/testflows.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/testing.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/testing.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/text.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/text.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/textedit.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/textedit.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/textfmts.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/textfmts.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/theorem.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/theorem.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/trafficscript.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/trafficscript.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/typoscript.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/typoscript.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/unicon.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/unicon.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/urbi.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/urbi.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/varnish.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/varnish.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/verification.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/verification.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/web.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/web.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/webmisc.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/webmisc.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/whiley.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/whiley.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/x10.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/x10.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/xorg.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/xorg.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/lexers/zig.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/lexers/zig.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/modeline.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/modeline.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/plugin.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/plugin.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/regexopt.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/regexopt.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/scanner.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/scanner.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/sphinxext.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/sphinxext.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/style.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/style.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/abap.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/abap.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/algol.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/algol.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/algol_nu.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/algol_nu.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/arduino.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/arduino.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/autumn.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/autumn.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/borland.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/borland.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/bw.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/bw.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/colorful.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/colorful.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/default.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/default.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/emacs.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/emacs.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/friendly.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/friendly.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/fruity.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/fruity.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/igor.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/igor.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/inkpot.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/inkpot.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/lovelace.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/lovelace.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/manni.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/manni.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/monokai.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/monokai.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/murphy.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/murphy.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/native.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/native.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/paraiso_dark.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/paraiso_dark.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/paraiso_light.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/paraiso_light.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/pastie.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/pastie.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/perldoc.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/perldoc.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/rainbow_dash.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/rainbow_dash.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/rrt.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/rrt.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/sas.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/sas.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/solarized.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/solarized.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/stata_dark.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/stata_dark.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/stata_light.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/stata_light.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/tango.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/tango.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/trac.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/trac.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/vim.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/vim.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/vs.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/vs.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/styles/xcode.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/styles/xcode.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/token.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/token.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/unistring.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/unistring.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/pygments/util.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/pygments/util.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/_compat.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/_compat.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/asn1.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/asn1.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/cli.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/cli.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/common.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/common.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/core.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/core.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/key.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/key.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/parallel.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/parallel.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/pem.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/pem.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/pkcs1.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/pkcs1.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/pkcs1_v2.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/pkcs1_v2.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/prime.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/prime.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/randnum.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/randnum.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/transform.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/transform.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/rsa/util.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/rsa/util.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/schema/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/schema/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/snowflake/snowflake.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/snowflake/snowflake.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/x256/x256.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/x256/x256.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/composer.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/composer.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/constructor.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/constructor.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/cyaml.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/cyaml.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/dumper.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/dumper.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/emitter.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/emitter.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/error.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/error.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/events.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/events.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/loader.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/loader.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/nodes.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/nodes.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/parser.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/parser.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/reader.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/reader.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/representer.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/representer.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/resolver.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/resolver.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/scanner.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/scanner.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/serializer.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/serializer.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/contrib/yaml/tokens.py` & `testflows.core-1.9.230627.1151633/testflows/_core/contrib/yaml/tokens.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/document/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/document/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/document/convert.py` & `testflows.core-1.9.230627.1151633/testflows/_core/document/convert.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,33 +13,34 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import re
 
 from testflows._core.contrib.markdown2 import Markdown
 
-link_patterns = [
-    (re.compile(r'((https?|ftp|file)://[^\s]+)'), r"\1")
-]
-
-md = Markdown(extras={
-    "header-ids":None,
-    "fenced-code-blocks":{"cssclass":"highlight"},
-    "footnotes":None,
-    "reference-style-links": None,
-    "target-blank-links": None,
-    "nofollow": None,
-    "noopener": None,
-    "link-patterns": None,
-    "noreferrer": None,
-    "code-friendly": None,
-    "tables": None,
-    "wiki-tables": None,
-    "markdown-in-html": None
-}, link_patterns=link_patterns)
+link_patterns = [(re.compile(r"((https?|ftp|file)://[^\s]+)"), r"\1")]
+
+md = Markdown(
+    extras={
+        "header-ids": None,
+        "fenced-code-blocks": {"cssclass": "highlight"},
+        "footnotes": None,
+        "reference-style-links": None,
+        "target-blank-links": None,
+        "nofollow": None,
+        "noopener": None,
+        "link-patterns": None,
+        "noreferrer": None,
+        "code-friendly": None,
+        "tables": None,
+        "wiki-tables": None,
+        "markdown-in-html": None,
+    },
+    link_patterns=link_patterns,
+)
 
 template = """
 <!DOCTYPE html>
 <html lang="en">
 <head>
 <meta charset="utf-8">
 <link href="https://fonts.googleapis.com/css?family=Open+Sans&display=swap" rel="stylesheet"> 
@@ -68,14 +69,12 @@
 </script>
 </html>
 """.strip()
 
 file_dir = os.path.dirname(os.path.abspath(__file__))
 stylesheet = os.path.join(file_dir, "style.css")
 
+
 def generate(source, destination, stylesheet, format=None):
     body = md.convert(source.read())
-    document = template % {
-        "body": body,
-        "style": stylesheet.read()
-    }
+    document = template % {"body": body, "style": stylesheet.read()}
     destination.write(document)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/document/new/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/document/new/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/document/new/requirements.md` & `testflows.core-1.9.230627.1151633/testflows/_core/document/new/requirements.md`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/document/srs.py` & `testflows.core-1.9.230627.1151633/testflows/_core/document/srs.py`

 * *Files 5% similar despite different names*

```diff
@@ -59,27 +59,28 @@
     link=%(link)s,
     level=%(level)s,
     num=%(num)s
 )
 
 """
 
+
 class Visitor(PTNodeVisitor):
     def __init__(self, source_data, *args, **kwargs):
         self.source_data = source_data
         self.output = (
             "# These requirements were auto generated\n"
             "# from software requirements specification (SRS)\n"
             f"# document by TestFlows v{__version__}.\n"
             "# Do not edit by hand but re-generate instead\n"
-            "# using \'tfs requirements generate\' command.\n"
+            "# using 'tfs requirements generate' command.\n"
             "from testflows.core import Specification\n"
             "from testflows.core import Requirement\n\n"
             "Heading = Specification.Heading\n\n"
-            )
+        )
         self.levels = [0]
         self.current_level = 0
         self.requirements = []
         self.headings = []
         self.specification = None
         self.pyname_fmt = re.compile(r"[^a-zA-Z0-9]")
         super(Visitor, self).__init__(*args, **kwargs)
@@ -88,20 +89,20 @@
         pass
 
     def process_heading(self, node, children):
         level = node[0].value.count("#")
         # normalize header level
         level -= 1
         if self.current_level < level:
-            self.levels = self.levels[:level - 1]
+            self.levels = self.levels[: level - 1]
         if len(self.levels) < level:
             self.levels += [0] * (level - len(self.levels))
         self.current_level = level
         self.levels[self.current_level - 1] += 1
-        num = '.'.join([str(l) for l in self.levels[:self.current_level]])
+        num = ".".join([str(l) for l in self.levels[: self.current_level]])
         return level, num
 
     def visit_heading(self, node, children):
         level, num = self.process_heading(node, children)
         name = node.heading_name.value
         self.headings.append(Specification.Heading(name=name, level=level, num=num))
 
@@ -132,50 +133,76 @@
         except:
             pass
         try:
             version = str(node.specification_version.words).strip()
         except:
             pass
         try:
-            status = str(node.specification_approval.specification_approval_status.words).strip()
+            status = str(
+                node.specification_approval.specification_approval_status.words
+            ).strip()
         except:
             pass
         try:
-            approved_version = str(node.specification_approval.specification_approval_version.words).strip()
+            approved_version = str(
+                node.specification_approval.specification_approval_version.words
+            ).strip()
         except:
             pass
         try:
-            approved_date = str(node.specification_approval.specification_approval_date.words).strip()
+            approved_date = str(
+                node.specification_approval.specification_approval_date.words
+            ).strip()
         except:
             pass
         try:
-            approved_by = str(node.specification_approval.specification_approval_by.words).strip()
+            approved_by = str(
+                node.specification_approval.specification_approval_by.words
+            ).strip()
         except:
             pass
 
         self.specification = Specification(
-            name=name, description=description, author=author,
-            date=date, status=status, approved_by=approved_by,
-            approved_date=approved_date, approved_version=approved_version,
-            version=version, group=group, type=type,
-            link=link, uid=uid, parent=parent, children=children, content=None)
+            name=name,
+            description=description,
+            author=author,
+            date=date,
+            status=status,
+            approved_by=approved_by,
+            approved_date=approved_date,
+            approved_version=approved_version,
+            version=version,
+            group=group,
+            type=type,
+            link=link,
+            uid=uid,
+            parent=parent,
+            children=children,
+            content=None,
+        )
 
     def visit_requirement(self, node, children):
         level, num = self.process_heading(node, children)
         name = node.requirement_heading.requirement_name.value
         version = str(node.requirement_version.word)
         description = None
         group = None
         priority = None
         type = None
         uid = None
         link = None
 
         try:
-            description = "\n".join([f'{"":8}{repr(line.value)}' for lines in node.requirement_description for line in lines])
+            description = "\n".join(
+                [
+                    f'{"":8}{repr(line.value)}'
+                    for lines in node.requirement_description
+                    for line in lines
+                ]
+            )
             description = wstrip(description, f"{'':8}'\\n'\n")
             description = f"(\n{description}\n{'':4})"
         except:
             description = "None"
         try:
             priority = str(node.requirement_priority.word)
         except:
@@ -190,18 +217,28 @@
             pass
         try:
             uid = str(node.requirement_uid.word)
         except:
             pass
 
         self.headings.append(Specification.Heading(name=name, level=level, num=num))
-        self.requirements.append(Requirement(
-            name=name, version=version, description=description,
-            priority=priority, group=group, type=type,
-            uid=uid, link=link, level=level, num=num))
+        self.requirements.append(
+            Requirement(
+                name=name,
+                version=version,
+                description=description,
+                priority=priority,
+                group=group,
+                type=type,
+                uid=uid,
+                link=link,
+                level=level,
+                num=num,
+            )
+        )
 
     def visit_document(self, node, children):
         requirements = []
 
         for rq in self.requirements:
             pyname = re.sub(r"_+", "_", self.pyname_fmt.sub("_", rq.name))
 
@@ -212,23 +249,25 @@
                 "description": rq.description,
                 "priority": repr(rq.priority),
                 "group": repr(rq.group),
                 "type": repr(rq.type),
                 "uid": repr(rq.uid),
                 "link": repr(rq.link),
                 "level": repr(rq.level),
-                "num": repr(rq.num)
+                "num": repr(rq.num),
             }
 
             requirements.append(pyname)
 
         sep = ",\n" + "    " * 2
 
         self.output += specification_template.lstrip() % {
-            "pyname": re.sub(r"_+", "_", self.pyname_fmt.sub("_", self.specification.name)),
+            "pyname": re.sub(
+                r"_+", "_", self.pyname_fmt.sub("_", self.specification.name)
+            ),
             "name": repr(self.specification.name),
             "description": repr(self.specification.description),
             "author": repr(self.specification.author),
             "date": repr(self.specification.date),
             "status": repr(self.specification.status),
             "approved_by": repr(self.specification.approved_by),
             "approved_date": repr(self.specification.approved_date),
@@ -238,36 +277,41 @@
             "type": repr(self.specification.type),
             "link": repr(self.specification.link),
             "uid": repr(self.specification.uid),
             "parent": repr(self.specification.parent),
             "children": repr(self.specification.children),
             "headings": f"(\n{'    ' * 2}{sep.join(f'{heading}' for heading in self.headings)}{sep})",
             "requirements": f"(\n{'    ' * 2}{sep.join(rq for rq in requirements)}{sep})",
-            "content": "'''\n%s\n'''" % self.source_data.replace("'''", "\'\'\'").rstrip()
+            "content": "'''\n%s\n'''" % self.source_data.replace("'''", "'''").rstrip(),
         }
 
         return self.output.rstrip() + "\n"
 
+
 def Parser():
-    """Returns markdown requirements parser.
-    """
+    """Returns markdown requirements parser."""
+
     def line():
         return _(r"[^\n]*\n?")
 
     def empty_line():
         return _(r"[ \t]*\n")
 
     def heading():
         return _(r"#+[ \t]+"), heading_name, _(r"\n")
 
     def inline_heading():
         return heading()
 
     def toc_heading():
-        return _(r"#+[ \t]+"), _(r"[Tt][Aa][Bb][Ll][Ee] [Oo][Ff] [Cc][Oo][Nn][Tt][Ee][Nn][Tt][Ss]"), _(r"[ \t]*\n")
+        return (
+            _(r"#+[ \t]+"),
+            _(r"[Tt][Aa][Bb][Ll][Ee] [Oo][Ff] [Cc][Oo][Nn][Tt][Ee][Nn][Tt][Ss]"),
+            _(r"[ \t]*\n"),
+        )
 
     def heading_name():
         return _(r"[^\n]+")
 
     def not_heading():
         return Not(heading)
 
@@ -334,38 +378,57 @@
     def specification_approval_date():
         return _(r"\*?\*?[Dd]ate:\*?\*?[ \t]*"), words, _(r"\n")
 
     def specification_approval_other():
         return _(r"\*?\*?[^\*\n]+:\*?\*?[ \t]*"), words, _(r"\n")
 
     def specification_approval():
-        return specification_approval_heading, ZeroOrMore([
-            specification_approval_status,
-            specification_approval_version,
-            specification_approval_by,
-            specification_approval_date,
-            specification_approval_other,
-            empty_line
-        ])
+        return specification_approval_heading, ZeroOrMore(
+            [
+                specification_approval_status,
+                specification_approval_version,
+                specification_approval_by,
+                specification_approval_date,
+                specification_approval_other,
+                empty_line,
+            ]
+        )
 
     def specification():
-        return specification_heading, ZeroOrMore(inline_heading), ZeroOrMore([
-            specification_author,
-            specification_date,
-            specification_version,
-            specification_other,
-            specification_approval,
-            empty_line,
-            _(r"[ \t]*[^\*#\n][^\n]*\n")
-        ]), [toc_heading, heading]
+        return (
+            specification_heading,
+            ZeroOrMore(inline_heading),
+            ZeroOrMore(
+                [
+                    specification_author,
+                    specification_date,
+                    specification_version,
+                    specification_other,
+                    specification_approval,
+                    empty_line,
+                    _(r"[ \t]*[^\*#\n][^\n]*\n"),
+                ]
+            ),
+            [toc_heading, heading],
+        )
 
     def requirement():
-        return requirement_heading, requirement_version, ZeroOrMore([
-                requirement_priority, requirement_type, requirement_group, requirement_uid
-            ]), Optional(requirement_description)
+        return (
+            requirement_heading,
+            requirement_version,
+            ZeroOrMore(
+                [
+                    requirement_priority,
+                    requirement_type,
+                    requirement_group,
+                    requirement_uid,
+                ]
+            ),
+            Optional(requirement_description),
+        )
 
     def document():
         return Optional(OneOrMore([specification, requirement, heading, line])), EOF
 
     return PEGParser(document, skipws=False)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/document/style.css` & `testflows.core-1.9.230627.1151633/testflows/_core/document/style.css`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/document/toc.py` & `testflows.core-1.9.230627.1151633/testflows/_core/document/toc.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 import re
 
 from testflows._core.contrib.arpeggio import RegExMatch as _
 from testflows._core.contrib.arpeggio import OneOrMore, ZeroOrMore, EOF, Optional, Not
 from testflows._core.contrib.arpeggio import ParserPython as PEGParser
 from testflows._core.contrib.arpeggio import PTNodeVisitor, visit_parse_tree
 
+
 class Visitor(PTNodeVisitor):
     def __init__(self, *args, **kwargs):
         self.header_ids = {}
         self.start_after = kwargs.pop("start_after", None)
         self.started = True
         if self.start_after is not None:
             self.started = False
@@ -41,20 +42,20 @@
                 self.started = True
                 return None
         if not self.started:
             return None
         # normalize header level
         level -= 1
         if self.current_level < level:
-            self.levels = self.levels[:level - 1]
+            self.levels = self.levels[: level - 1]
         if len(self.levels) < level:
             self.levels += [0] * (level - len(self.levels))
         self.current_level = level
         self.levels[self.current_level - 1] += 1
-        num = '.'.join([str(l) for l in self.levels[:self.current_level]])
+        num = ".".join([str(l) for l in self.levels[: self.current_level]])
         return level, num
 
     def visit_heading(self, node, children):
         res = self.process_heading(node, children)
         if not res:
             return
         level, num = res
@@ -63,15 +64,17 @@
         # handle duplicate header ids
         if self.header_ids.get(anchor) is None:
             self.header_ids[anchor] = 1
         else:
             anchor = f"{anchor}{str(self.header_ids[anchor])}"
             self.header_ids[anchor] += 1
         indent = "  " * (level - 1)
-        self.output.append(f"{indent}* {'.'.join([str(l) for l in self.levels[:self.current_level]])} [{name}](#{anchor})")
+        self.output.append(
+            f"{indent}* {'.'.join([str(l) for l in self.levels[:self.current_level]])} [{name}](#{anchor})"
+        )
 
     def visit_document(self, node, children):
         self.output = "\n".join(self.output)
         if self.output:
             self.output += "\n"
         return self.output or None
 
@@ -103,23 +106,23 @@
 
     def visit_document(self, node, children):
         self.output = "".join(self.output)
         return self.output or None
 
 
 def Parser():
-    """Returns markdown heading parser.
-    """
+    """Returns markdown heading parser."""
+
     def line():
         return _(r"[^\n]*\n")
 
     def heading():
         return [
             (_(r"\s*#+\s+"), heading_name, _(r"\n?")),
-            (heading_name, _(r"\n?[-=]+\n?"))
+            (heading_name, _(r"\n?[-=]+\n?")),
         ]
 
     def heading_name():
         return _(r"[^\n]+")
 
     def document():
         return Optional(OneOrMore([heading, line])), EOF
@@ -137,12 +140,14 @@
     """
     parser = Parser()
     source_data = source.read()
     tree = parser.parse(source_data)
     toc = visit_parse_tree(tree, Visitor(start_after=heading))
     destination_data = ""
     if update:
-        destination_data = visit_parse_tree(tree, UpdateVisitor(heading=heading, toc=toc))
+        destination_data = visit_parse_tree(
+            tree, UpdateVisitor(heading=heading, toc=toc)
+        )
     else:
         destination_data = toc
     if destination_data:
         destination.write(destination_data)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/exceptions.py` & `testflows.core-1.9.230627.1151633/testflows/_core/exceptions.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -8,8 +8,8 @@
 #      http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from testflows.exceptions import *
+from testflows.exceptions import *
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/filters.py` & `testflows.core-1.9.230627.1151633/testflows/_core/filters.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,29 +13,29 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # to the end flag
 from .name import absname, match
 from .baseobject import TestObject
 from .testtype import TestType
 
+
 class The(TestObject):
-    """The `only`, `skip`, `start` and `end` test filer object.
-    """
+    """The `only`, `skip`, `start` and `end` test filer object."""
+
     _fields = ("pattern",)
 
     def __init__(self, pattern):
         self.pattern = pattern
         super(The, self).__init__()
 
     def __str__(self):
         return self.pattern
 
     def at(self, at):
-        """Anchor filter by converting all patterns to be absolute.
-        """
+        """Anchor filter by converting all patterns to be absolute."""
         self.pattern = absname(self.pattern, at)
         return self
 
     def set(self, pattern):
         self.pattern = pattern
 
     def match(self, name, prefix=True):
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/flags.py` & `testflows.core-1.9.230627.1151633/testflows/_core/flags.py`

 * *Files 14% similar despite different names*

```diff
@@ -92,36 +92,107 @@
 EANY = EOK | EFAIL | ESKIP
 # crossed out result
 XRESULT = XOK | XFAIL | XERROR | XNULL
 # not counted
 NOT_COUNTED = FAIL_NOT_COUNTED
 NOT_COUNTED_ANY = FAIL_NOT_COUNTED | ERROR_NOT_COUNTED | NULL_NOT_COUNTED
 # cumulative flags
-CFLAGS = UT | MANDATORY | MANUAL | PARALLEL | NO_PARALLEL | NOT_REPEATABLE | RETRY | NESTED_RETRY | SETUP | CLEANUP
+CFLAGS = (
+    UT
+    | MANDATORY
+    | MANUAL
+    | PARALLEL
+    | NO_PARALLEL
+    | NOT_REPEATABLE
+    | RETRY
+    | NESTED_RETRY
+    | SETUP
+    | CLEANUP
+)
+
 
 class Flags(object):
     """Test flags."""
+
     all = [
-            TE, UT, SKIP, EOK, EFAIL, EERROR, ESKIP,
-            XOK, XFAIL, XERROR, XNULL,
-            FAIL_NOT_COUNTED, ERROR_NOT_COUNTED, NULL_NOT_COUNTED,
-            PAUSE_BEFORE, PAUSE_AFTER, MANUAL, AUTO,
-            REPORT, DOCUMENT, MANDATORY, PARALLEL, NO_PARALLEL, CLEAR,
-            ASYNC, REPEATED, NOT_REPEATABLE, RETRIED, LAST_RETRY,
-            PAUSE_ON_PASS, PAUSE_ON_FAIL, REMOTE, SETUP, CLEANUP, RETRY, NESTED_RETRY
-        ]
+        TE,
+        UT,
+        SKIP,
+        EOK,
+        EFAIL,
+        EERROR,
+        ESKIP,
+        XOK,
+        XFAIL,
+        XERROR,
+        XNULL,
+        FAIL_NOT_COUNTED,
+        ERROR_NOT_COUNTED,
+        NULL_NOT_COUNTED,
+        PAUSE_BEFORE,
+        PAUSE_AFTER,
+        MANUAL,
+        AUTO,
+        REPORT,
+        DOCUMENT,
+        MANDATORY,
+        PARALLEL,
+        NO_PARALLEL,
+        CLEAR,
+        ASYNC,
+        REPEATED,
+        NOT_REPEATABLE,
+        RETRIED,
+        LAST_RETRY,
+        PAUSE_ON_PASS,
+        PAUSE_ON_FAIL,
+        REMOTE,
+        SETUP,
+        CLEANUP,
+        RETRY,
+        NESTED_RETRY,
+    ]
     all_str = [
-            "TE", "UT", "SKIP", "EOK", "EFAIL", "EERROR", "ESKIP",
-            "XOK", "XFAIL", "XERROR", "XNULL",
-            "FAIL_NOT_COUNTED", "ERROR_NOT_COUNTED", "NULL_NOT_COUNTED",
-            "PAUSE_BEFORE", "PAUSE_AFTER", "MANUAL", "AUTO",
-            "REPORT", "DOCUMENT", "MANDATORY", "PARALLEL", "NO_PARALLEL", "CLEAR",
-            "ASYNC", "REPEATED", "NOT_REPEATABLE", "RETRIED", "LAST_RETRY",
-            "PAUSE_ON_PASS", "PAUSE_ON_FAIL", "REMOTE", "SETUP", "CLEANUP", "RETRY", "NESTED_RETRY"
-        ]
+        "TE",
+        "UT",
+        "SKIP",
+        "EOK",
+        "EFAIL",
+        "EERROR",
+        "ESKIP",
+        "XOK",
+        "XFAIL",
+        "XERROR",
+        "XNULL",
+        "FAIL_NOT_COUNTED",
+        "ERROR_NOT_COUNTED",
+        "NULL_NOT_COUNTED",
+        "PAUSE_BEFORE",
+        "PAUSE_AFTER",
+        "MANUAL",
+        "AUTO",
+        "REPORT",
+        "DOCUMENT",
+        "MANDATORY",
+        "PARALLEL",
+        "NO_PARALLEL",
+        "CLEAR",
+        "ASYNC",
+        "REPEATED",
+        "NOT_REPEATABLE",
+        "RETRIED",
+        "LAST_RETRY",
+        "PAUSE_ON_PASS",
+        "PAUSE_ON_FAIL",
+        "REMOTE",
+        "SETUP",
+        "CLEANUP",
+        "RETRY",
+        "NESTED_RETRY",
+    ]
 
     def __init__(self, flags=0):
         if flags is None:
             flags = 0
         if type(flags) is str:
             self.flags = 0
             if flags:
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/funcs.py` & `testflows.core-1.9.230627.1151633/testflows/_core/funcs.py`

 * *Files 8% similar despite different names*

```diff
@@ -26,41 +26,46 @@
 from .message import Message, dumps
 from .name import basename
 from .objects import OK, Fail, Error, Skip, Null
 from .objects import XOK, XFail, XError, XNull
 from .objects import Value, Metric, Ticket, Attribute, Tag, Requirement, Node
 from .parallel import top, current, previous
 
+
 def current_dir(frame=None):
-    """Return directory of the current source file.
-    """
+    """Return directory of the current source file."""
     if frame is None:
         frame = inspect.currentframe().f_back
     return os.path.dirname(os.path.abspath(frame.f_globals["__file__"]))
 
+
 def current_module(frame=None):
-    """Return reference to the current module.
-    """
+    """Return reference to the current module."""
     if frame is None:
         frame = inspect.currentframe().f_back
     return sys.modules[frame.f_globals["__name__"]]
 
+
 def load_module(name, package=None):
-    """Load module by name.
-    """
+    """Load module by name."""
     return importlib.import_module(name, package=package)
 
+
 def load_submodules(name, package=None):
     """Load all submodules for a given module specified by name.
 
     :param name: module name
     :param package: package if module name is relative (optional)
     """
     module = load_module(name, package=package)
-    return [module_info[0].find_module(module_info[1]).load_module(module_info[1]) for module_info in pkgutil.iter_modules(module.__path__)]
+    return [
+        module_info[0].find_module(module_info[1]).load_module(module_info[1])
+        for module_info in pkgutil.iter_modules(module.__path__)
+    ]
+
 
 def load(name, test=None, package=None, frame=None):
     """Load test by name from module.
 
     :param name: module name or module
     :param test: test class or method name to load (optional)
     :param package: package if module name is relative (optional)
@@ -79,105 +84,145 @@
         test = getattr(module, "TestCase", None)
     if test is None:
         test = getattr(module, "TestSuite", None)
     if test is None:
         test = getattr(module, "Test", None)
     return test
 
+
 def append_path(pathlist, path, *rest, **kwargs):
     """Append path relative to the caller
     to the path list.
 
     :param pathlist: path list
     :param path: path relative to the caller
     :param *rest: rest of the path
     :param pos: insert at given position,
        default: append to the end of the list
     """
     pos = kwargs.pop("pos", None)
     frame = inspect.currentframe().f_back
-    dir = os.path.join(os.path.dirname(os.path.abspath(frame.f_globals["__file__"])), path, *rest)
+    dir = os.path.join(
+        os.path.dirname(os.path.abspath(frame.f_globals["__file__"])), path, *rest
+    )
     if dir not in pathlist:
         if pos is None:
             pathlist.append(dir)
         else:
             pathlist.insert(pos, dir)
     return pathlist
 
+
 def main(frame=None):
     """Return true if caller is the main module.
 
     :param frame: caller frame
     """
     if frame is None:
         frame = inspect.currentframe().f_back
     return frame.f_globals["__name__"] == "__main__"
 
+
 class args(dict):
     pass
 
+
 def attribute(name, value, type=None, group=None, uid=None, base=Attribute, test=None):
     obj = base(name=name, value=value, type=type, group=group, uid=uid)
     if test is None:
         test = current()
     if test.attributes.get(obj.name, None) is not None:
         raise NameError(f"attribute named '{obj.name}' already exists")
     test.attributes[obj.name] = obj
     test.io.output.attribute(obj)
 
-def requirement(name, version, description=None, link=None,
-        priority=None, type=None, group=None, uid=None, base=Requirement, test=None):
-    obj = base(name=name, version=version, description=description, link=link,
-        priority=priority, type=type, group=group, uid=uid)
+
+def requirement(
+    name,
+    version,
+    description=None,
+    link=None,
+    priority=None,
+    type=None,
+    group=None,
+    uid=None,
+    base=Requirement,
+    test=None,
+):
+    obj = base(
+        name=name,
+        version=version,
+        description=description,
+        link=link,
+        priority=priority,
+        type=type,
+        group=group,
+        uid=uid,
+    )
     if test is None:
         test = current()
     if test.requirements.get(obj.name, None) is not None:
         raise NameError(f"requirement named '{obj.name}' already exists")
     test.requirements[obj.name] = obj
     test.io.output.requirement(obj)
 
+
 def tag(value, test=None):
     value = str(value)
     if test is None:
         test = current()
     test.tags.add(value)
     test.io.output.tag(Tag(value))
 
+
 def metric(name, value, units, type=None, group=None, uid=None, base=Metric, test=None):
     obj = base(name=name, value=value, units=units, type=type, group=group, uid=uid)
     if test is None:
         test = current()
     test.result.metrics.append(obj)
     test.io.output.metric(obj)
 
+
 def ticket(name, link=None, type=None, group=None, uid=None, base=Ticket, test=None):
     obj = base(name=name, link=link, type=type, group=group, uid=uid)
     if test is None:
         test = current()
     test.result.tickets.append(obj)
     test.io.output.ticket(obj)
 
+
 def value(name, value, type=None, group=None, uid=None, base=Value, test=None):
     obj = base(name=name, value=value, type=type, group=group, uid=uid)
     if test is None:
         test = current()
     test.result.values.append(obj)
     test.io.output.value(obj)
     return value
 
+
 def private_key(value=None, test=None):
     if test is None:
         test = current()
     if value is not None:
         test.private_key = value
     else:
         value = test.private_key
     return value
 
-def text(*message, start="", end="\n", format=None, dedent=True, strip=False, file=None, test=None):
+
+def text(
+    *message,
+    start="",
+    end="\n",
+    format=None,
+    dedent=True,
+    strip=False,
+    file=None,
+    test=None,
+):
     if test is None:
         test = current()
 
     text = "\n".join(message)
 
     if file is None:
         file = getattr(current().context, "file", None)
@@ -194,39 +239,45 @@
     text = f"{start}{text}{end}"
 
     if file:
         file.write(text)
 
     test.io.output.text(text)
 
+
 def note(message, test=None):
     if test is None:
         test = current()
     test.io.output.note(message)
 
+
 def debug(message, test=None):
     if test is None:
         test = current()
     test.io.output.debug(message)
 
+
 def trace(message, test=None):
     if test is None:
         test = current()
     test.io.output.trace(message)
 
+
 def message(message, test=None, stream=None):
     if test is None:
         test = current()
     test.io.output.message(Message.NONE, {"message": str(message)}, stream=stream)
 
+
 def exception(exc_type=None, exc_value=None, exc_traceback=None, test=None):
     if test is None:
         test = current()
     test.io.output.exception(exc_type, exc_value, exc_traceback)
 
+
 def result(type, *args, test=None):
     if type is OK:
         return ok(*args, test=test)
     elif type is Fail:
         return fail(*args, test=test)
     elif type is Skip:
         return skip(*args, test=test)
@@ -238,94 +289,106 @@
         return xok(*args, test=test)
     elif type is XFail:
         return xfail(*args, test=test)
     elif type is XNull:
         return xnull(*args, test=test)
     raise TypeError(f"invalid result type {type}")
 
+
 def cleanup(func, *args, test=None, context=None, **kwargs):
     if context is None:
         if test is None:
             test = current()
         context = test.context
     context.cleanup(func, *args, **kwargs)
 
+
 def ok(message=None, reason=None, test=None):
     if test is None:
         test = current()
     test.result = test.result(OK(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def fail(message=None, reason=None, test=None, type=None):
     if test is None:
         test = current()
 
     if type is not None:
         if not message:
             raise ValueError("message must be specified")
         with type(message):
-           fail(reason=reason)
+            fail(reason=reason)
 
     test.result = test.result(Fail(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def skip(message=None, reason=None, test=None):
     if test is None:
         test = current()
     test.result = test.result(Skip(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def err(message=None, reason=None, test=None):
     if test is None:
         test = current()
     test.result = test.result(Error(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def null(message=None, reason=None, test=None):
     if test is None:
         test = current()
     test.result = test.result(Null(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def xok(message=None, reason=None, test=None):
     if test is None:
         test = current()
     test.result = test.result(XOK(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def xfail(message=None, reason=None, test=None):
     if test is None:
         test = current()
     test.result = test.result(XFail(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def xerr(message=None, reason=None, test=None):
     if test is None:
         test = current()
     test.result = test.result(XError(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def xnull(message=None, reason=None, test=None):
     if test is None:
         test = current()
     test.result = test.result(XNull(test=test.name, message=message, reason=reason))
     raise test.result
 
+
 def pause(message=None, test=None):
     if test is None:
         test = current()
     if message is None:
         message = ", e"
     else:
         message = message.strip()
         message = f", {message[:1].lower() + message[1:]}\nE"
     test.io.output.prompt(f"Paused{message}nter any key to continue...")
     builtins.input()
     test.io.output.input("")
 
+
 def input(type, multiline=False, choices=None, confirm=True, test=None):
     nl = "\n"
 
     if test is None:
         test = current()
 
     def confirmed():
@@ -338,20 +401,22 @@
     def multilined():
         lines = []
         while True:
             try:
                 lines.append(builtins.input())
             except EOFError:
                 break
-        return '\n'.join(lines)
+        return "\n".join(lines)
 
     if builtins.type(type) is str:
         while True:
-            test.io.output.prompt(f"{type.strip()}{(nl + '(Press Enter then Ctrl-D to finish)') if multiline else ''}\n\n"
-                f"{('[' + ','.join([repr(c) for c in choices]) + ']' + nl*2) if choices else ''}")
+            test.io.output.prompt(
+                f"{type.strip()}{(nl + '(Press Enter then Ctrl-D to finish)') if multiline else ''}\n\n"
+                f"{('[' + ','.join([repr(c) for c in choices]) + ']' + nl*2) if choices else ''}"
+            )
             if multiline:
                 text = multilined()
             else:
                 text = builtins.input()
 
             test.io.output.input(text)
 
@@ -401,31 +466,32 @@
             message_or_reason = input_result.split(" ", 1)[-1]
 
         input_results_map.get(input_result.split(" ", 1)[0].lower())(message_or_reason)
 
     else:
         raise ValueError(f"invalid type {type}")
 
+
 def getsattr(obj, name, *default):
-    """Get attribute or set it to the default value.
-    """
+    """Get attribute or set it to the default value."""
     value = getattr(obj, name, *default)
     setattr(obj, name, value)
     return value
 
+
 def current_time(test=None):
-    """Return current execution time.
-    """
+    """Return current execution time."""
     if test is None:
         test = current()
 
     if test.test_time is None:
-       return time.time() - test.start_time
+        return time.time() - test.start_time
     else:
-       return test.test_time
+        return test.test_time
+
 
 def aslice(iterator, *args, **kwargs):
     """Return an iterator whose next() method returns
     a slice that only contains selected  values from an iterable.
 
     aslice(iterable, stop)
     aslice(iterable, start, stop[, step])
@@ -438,22 +504,28 @@
 
     This is just a wrapper for itertools.islice standard library function.
 
     :returns: islice object
     """
     return itertools.islice(iterator, *args, **kwargs)
 
+
 def chunks(iterator, n):
     """Converts iterator into an iterable over sub-iterables
     chunks with n elements each.
 
     :param n: chunk size
     """
     while True:
         try:
             chunk = list()
             for _ in range(n):
                 chunk.append(next(iterator))
         except StopIteration:
             break
         finally:
-            yield chunk
+            yield chunk
+
+
+def always(test):
+    """Always True condition that can be used with 'when' clauses."""
+    return True
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/has.py` & `testflows.core-1.9.230627.1151633/testflows/_core/has.py`

 * *Files 17% similar despite different names*

```diff
@@ -13,169 +13,179 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import re
 import operator
 
 from .flags import Flags
 
+
 class Filter:
-    """Base filter.
-    """
+    """Base filter."""
+
     def __init__(self, _op=None):
         self._op = _op
 
     def __call__(self, test):
         if self._op:
             return self._op(test)
         return True
 
     def __or__(self, other):
         def op(test):
             return operator.or_(self(test), other(test))
+
         return Filter(_op=op)
 
     def __and__(self, other):
         def op(test):
             return operator.and_(self(test), other(test))
+
         return Filter(_op=op)
 
     def __invert__(self):
         def op(test):
             return operator.not_(self(test))
+
         return Filter(_op=op)
 
+
 class StringFilter(Filter):
-    """Generic filter for string types.
-    """
+    """Generic filter for string types."""
+
     parameter = None
 
     def __init__(self, s):
         self.s = s
 
     @classmethod
     def getattr(cls, test):
         return [getattr(p, cls.__name__) for p in getattr(test, cls.parameter, [])]
 
     @classmethod
     def startingwith(cls, s):
         def op(test):
             return len([a for a in cls.getattr(test) if a.startswith(s)]) > 0
+
         return Filter(_op=op)
 
     @classmethod
     def endingwith(cls, s):
         def op(test):
             return len([a for a in cls.getattr(test) if a.endswith(s)]) > 0
+
         return Filter(_op=op)
 
     @classmethod
     def containing(cls, s):
         def op(test):
             return len([a for a in cls.getattr(test) if s in a]) > 0
+
         return Filter(_op=op)
 
     @classmethod
     def matching(cls, pattern):
         pattern = re.compile(pattern)
+
         def op(test):
             return len([a for a in cls.getattr(test) if pattern.match(a)]) > 0
+
         return Filter(_op=op)
 
     def __call__(self, test):
         return self.s in self.getattr(test)
 
 
 class has:
     """Class that contains filters that can be used
     to filter tests by their `name`, `flags`, `tags`,
     `attributes` and `requirements`.
     """
+
     class tag(StringFilter):
-        """Test tag filter.
-        """
+        """Test tag filter."""
+
         @staticmethod
         def getattr(test):
             return getattr(test, "tags", set())
 
     class name(StringFilter):
-        """Test name filter.
-        """
+        """Test name filter."""
+
         @staticmethod
         def getattr(test):
             return [getattr(test, "name")]
 
     class flag(Filter):
-        """Test flag filter.
-        """
+        """Test flag filter."""
+
         def __init__(self, flag):
             self.flag = Flags(flag)
 
         def __call__(self, test):
             return self.flag in Flags(getattr(test, "flags", None))
 
     class attribute:
-        """Test attribute filter.
-        """
+        """Test attribute filter."""
+
         class BaseFilter(StringFilter):
             parameter = "attributes"
 
         class name(BaseFilter):
-            """Test attribute name filter.
-            """
+            """Test attribute name filter."""
+
             pass
 
         class uid(BaseFilter):
-            """Test attribute uid filter.
-            """
+            """Test attribute uid filter."""
+
             pass
 
         class value(BaseFilter):
-            """Test attribute value filter.
-            """
+            """Test attribute value filter."""
+
             pass
 
         class type(BaseFilter):
-            """Test attribute type filter.
-            """
+            """Test attribute type filter."""
+
             pass
 
         class group(BaseFilter):
-            """Test attribute group filter.
-            """
+            """Test attribute group filter."""
+
             pass
 
     class requirement:
-        """Test requirement filter.
-        """
+        """Test requirement filter."""
 
         class BaseFilter(StringFilter):
             parameter = "requirements"
 
         class name(BaseFilter):
-            """Test requirement name filter.
-            """
+            """Test requirement name filter."""
+
             pass
 
         class uid(BaseFilter):
-            """Test requirement uid filter.
-            """
+            """Test requirement uid filter."""
+
             pass
 
         class version(BaseFilter):
-            """Test requirement version filter.
-            """
+            """Test requirement version filter."""
+
             pass
 
         class priority(BaseFilter):
-            """Test requirement group filter.
-            """
+            """Test requirement group filter."""
+
             pass
 
         class type(BaseFilter):
-            """Test requirement type filter.
-            """
+            """Test requirement type filter."""
+
             pass
 
         class group(BaseFilter):
-            """Test requirement group filter.
-            """
+            """Test requirement group filter."""
+
             pass
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/init.py` & `testflows.core-1.9.230627.1151633/testflows/_core/init.py`

 * *Files 2% similar despite different names*

```diff
@@ -30,171 +30,192 @@
 from .transform.log.pipeline import ProgressLogPipeline
 from .transform.log.pipeline import ShortLogPipeline
 from .transform.log.pipeline import SlickLogPipeline
 from .transform.log.pipeline import ClassicLogPipeline
 from .transform.log.pipeline import FailsLogPipeline
 from .transform.log.pipeline import ManualLogPipeline
 from .transform.log.pipeline import QuietLogPipeline
-from .templog import glob as templog_glob, parser as templog_parser, dirname as templog_dirname
+from .temp import glob as temp_glob, parser as temp_parser, dirname as temp_dirname
 from .parallel import top
 from .objects import Error
 
 _handlers = []
 
+
 def _at_exit():
     for handler in _handlers:
         handler.join()
 
+
 atexit.register(_at_exit)
 
 _ctrl_c = 0
 
+
 def sigint_handler(signal, frame):
     global _ctrl_c
     _ctrl_c += 1
 
     if _ctrl_c > 1:
         raise KeyboardInterrupt()
 
     if top():
         top().terminate(result=Error, reason="KeyboardInterrupt")
 
+
 def cleanup():
-    """Clean up old temporary log files.
-    """
+    """Clean up old temporary log files."""
+
     def pid_exists(pid):
-        if pid < 0: return False
+        if pid < 0:
+            return False
         try:
             os.kill(pid, 0)
         except ProcessLookupError:
             return False
         except PermissionError:
             return True
         else:
             return True
 
-    for file in glob.glob(os.path.join(templog_dirname(), templog_glob)):
-        match = templog_parser.match(file)
+    for file in glob.glob(os.path.join(temp_dirname(), temp_glob)):
+        match = temp_parser(extension="*").match(file)
         if not match:
             continue
-        pid = int(match.groupdict()['pid'])
+        pid = int(match.groupdict()["pid"])
         if not pid_exists(pid):
             try:
                 os.remove(file)
             except FileNotFoundError:
                 pass
             except PermissionError:
                 pass
             except OSError:
                 raise
 
+
 def stdout_raw_handler():
     """Handler to output messages to sys.stdout
     using "raw" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         RawLogPipeline(log, sys.stdout, tail=True).run()
 
+
 def stdout_slick_handler():
     """Handler to output messages to sys.stdout
     using "slick" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         SlickLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_classic_handler():
     """Handler to output messages to sys.stdout
     using "classic" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         ClassicLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_fails_handler():
     """Handler to output messages to sys.stdout
     using "fails" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         FailsLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_new_fails_handler():
     """Handler to output messages to sys.stdout
     using "fails" format that shows only new fails.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
-        FailsLogPipeline(log, sys.stdout, tail=True, only_new=True, show_input=False).run()
+        FailsLogPipeline(
+            log, sys.stdout, tail=True, only_new=True, show_input=False
+        ).run()
+
 
 def stdout_short_handler():
     """Handler to output messages to sys.stdout
     using "short" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         ShortLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_nice_handler():
     """Handler to output messages to sys.stdout
     using "nice" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         NiceLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_pnice_handler():
     """Handler to output messages to sys.stdout
     using "pnice" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         ParallelNiceLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_brisk_handler():
     """Handler to output messages to sys.stdout
     using "brisk" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         BriskLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_manual_handler():
     """Handler to output messages to sys.stdout
     using "manual" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         ManualLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_dots_handler():
     """Handler to output messages to sys.stdout
     using "dots" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         DotsLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_progress_handler():
     """Handler to output messages to sys.stdout
     using "progress" format.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         ProgressLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def stdout_quiet_handler():
     """Handler that prints no output to sys.stdout unless
     top level test fails.
     """
     with CompressedFile(settings.read_logfile, tail=True) as log:
         log.seek(0)
         QuietLogPipeline(log, sys.stdout, tail=True, show_input=False).run()
 
+
 def start_output_handler():
     output_handler_map = {
         "raw": stdout_raw_handler,
         "slick": stdout_slick_handler,
         "classic": stdout_classic_handler,
         "manual": stdout_manual_handler,
         "fails": stdout_fails_handler,
@@ -209,28 +230,29 @@
     }
 
     handler = threading.Thread(target=output_handler_map[settings.output_format])
     handler.name = "tfs-output"
     handler.start()
     _handlers.append(handler)
 
+
 def start_database_handler():
     if not settings.database:
         return
 
     from testflows.database import database_handler
 
     handler = threading.Thread(target=database_handler)
-    handler.name = 'tfs-database'
+    handler.name = "tfs-database"
     handler.start()
     _handlers.append(handler)
 
+
 def init():
-    """Initialization before we run the first test.
-    """
+    """Initialization before we run the first test."""
     if threading.current_thread() is not threading.main_thread():
         raise RuntimeError("top level test was not started in main thread")
     signal.signal(signal.SIGINT, sigint_handler)
     cleanup()
     start_output_handler()
     start_database_handler()
     return True
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/io.py` & `testflows.core-1.9.230627.1151633/testflows/_core/io.py`

 * *Files 4% similar despite different names*

```diff
@@ -26,44 +26,55 @@
 from .message import Message, MessageObjectType, dumps
 from .objects import Tag, ExamplesRow
 from . import __version__
 from .parallel.service import BaseServiceObject
 
 tracer = tracing.getLogger(__name__)
 
+
 def object_fields(obj, prefix):
-    return {f"{prefix}{'_' if prefix else ''}{field}":getattr(obj, field) for field in obj._fields}
+    return {
+        f"{prefix}{'_' if prefix else ''}{field}": getattr(obj, field)
+        for field in obj._fields
+    }
+
 
 def str_or_repr(v):
     try:
         return str(v)
     except:
         return repr(v)
 
+
 class TestOutput(object):
     """Test output protocol.
 
     :param io: message IO
     """
+
     protocol_version = "TFSPv2.1"
 
     def __init__(self, test, io):
         self.io = io
         self.test = test
         self.msg_hash = ""
         self.msg_count = 0
         self.prefix = {
             "test_type": str(self.test.type),
-            "test_subtype": str(self.test.subtype) if self.test.subtype is not None else None,
+            "test_subtype": str(self.test.subtype)
+            if self.test.subtype is not None
+            else None,
             "test_id": self.test.id_str,
             "test_name": self.test.name,
             "test_flags": int(self.test.flags),
             "test_cflags": int(self.test.cflags),
             "test_level": len(self.test.id),
-            "test_parent_type": str(self.test.parent_type) if self.test.parent_type is not None else None
+            "test_parent_type": str(self.test.parent_type)
+            if self.test.parent_type is not None
+            else None,
         }
 
     def message(self, keyword, message, object_type=0, stream=None):
         """Output message.
 
         :param keyword: keyword
         :param message: message
@@ -74,58 +85,69 @@
             "message_keyword": str(keyword),
             "message_hash": self.msg_hash,
             "message_object": object_type,
             "message_num": self.msg_count,
             "message_stream": stream,
             "message_level": (
                 len(self.test.id) + 1
-                if keyword not in (Message.TEST, Message.RESULT, Message.PROTOCOL, Message.VERSION)
+                if keyword
+                not in (Message.TEST, Message.RESULT, Message.PROTOCOL, Message.VERSION)
                 else len(self.test.id)
             ),
             "message_time": round(msg_time, settings.time_resolution),
-            "message_rtime": round(msg_time - self.test.start_time, settings.time_resolution)
+            "message_rtime": round(
+                msg_time - self.test.start_time, settings.time_resolution
+            ),
         }
         msg.update(self.prefix)
 
         if settings.secrets_registry:
             if not settings.secrets_registry.is_empty():
                 if "message" in message and message["message"]:
-                    message["message"] = settings.secrets_registry.filter(message["message"])
+                    message["message"] = settings.secrets_registry.filter(
+                        message["message"]
+                    )
                 if "result_message" in message and message["result_message"]:
-                    message["result_message"] = settings.secrets_registry.filter(message["result_message"])
+                    message["result_message"] = settings.secrets_registry.filter(
+                        message["result_message"]
+                    )
                 if "test_description" in message and message["test_description"]:
-                    message["test_description"] = settings.secrets_registry.filter(message["test_description"])
+                    message["test_description"] = settings.secrets_registry.filter(
+                        message["test_description"]
+                    )
                 if "argument_value" in message and message["argument_value"]:
-                    message["argument_value"] = settings.secrets_registry.filter(message["argument_value"])
+                    message["argument_value"] = settings.secrets_registry.filter(
+                        message["argument_value"]
+                    )
 
         msg.update(message)
-        self.test.tracer.debug("test message", extra={"test_message":msg})
+        self.test.tracer.debug("test message", extra={"test_message": msg})
 
         msg = dumps(msg)
 
-        self.msg_hash = settings.hash_func(msg.encode("utf-8")).hexdigest()[:settings.hash_length]
+        self.msg_hash = settings.hash_func(msg.encode("utf-8")).hexdigest()[
+            : settings.hash_length
+        ]
         self.msg_count += 1
 
-        parts = msg.split(",",2)
-        parts[1] = f"\"message_hash\":\"{self.msg_hash}\""
+        parts = msg.split(",", 2)
+        parts[1] = f'"message_hash":"{self.msg_hash}"'
         self.io.write(f"{parts[0]},{parts[1]},{parts[2]}{end_of_message}")
 
     def stop(self):
         """Output stop message."""
         self.message(Message.STOP, {})
 
     def protocol(self):
-        """Output protocol version message.
-        """
+        """Output protocol version message."""
         msg = {"protocol_version": self.protocol_version}
         self.message(Message.PROTOCOL, msg)
 
     def version(self):
-        """Output framework version message.
-        """
+        """Output framework version message."""
         msg = {"framework_version": __version__}
         self.message(Message.VERSION, msg)
 
     def prompt(self, message):
         """Output prompt message.
 
         :param message: message
@@ -146,31 +168,37 @@
 
         Note: must be called from within finally block
         """
         msg = {"message": get_exception(exc_type, exc_value, exc_traceback)}
         self.message(Message.EXCEPTION, msg)
 
     def test_message(self):
-        """Output test message.
-        """
+        """Output test message."""
         msg = {
             "test_name": self.test.name,
             "test_module": self.test.module,
             "test_uid": str(self.test.uid or "") or None,
             "test_description": str(self.test.description or "") or None,
         }
 
         self.message(Message.TEST, msg, object_type=MessageObjectType.TEST)
 
         [self.attribute(attr) for attr in self.test.attributes.values()]
         [self.specification(spec) for spec in self.test.specifications.values()]
         [self.requirement(req) for req in self.test.requirements.values()]
         [self.argument(arg) for arg in self.test.args.values()]
         [self.tag(Tag(tag)) for tag in self.test.tags]
-        [self.example(ExamplesRow(row._idx, row._fields, [str(f) for f in row], row._row_format)) for row in self.test.examples]
+        [
+            self.example(
+                ExamplesRow(
+                    row._idx, row._fields, [str(f) for f in row], row._row_format
+                )
+            )
+            for row in self.test.examples
+        ]
         [self.map(mapping) for mapping in self.test.maps]
 
     def attribute(self, attribute, object_type=MessageObjectType.TEST):
         msg = object_fields(attribute, "attribute")
         value = msg["attribute_value"]
         if value is not None:
             msg["attribute_value"] = str_or_repr(value)
@@ -225,15 +253,15 @@
 
         :param result: result object
         """
         msg = {
             "result_message": result.message,
             "result_reason": result.reason,
             "result_type": str(result.type),
-            "result_test": result.test
+            "result_test": result.test,
         }
         self.message(Message.RESULT, msg, object_type=MessageObjectType.TEST)
 
     def text(self, message):
         """Output text message.
 
         :param message: message
@@ -261,25 +289,26 @@
         """Output trace message.
 
         :param message: message
         """
         msg = {"message": str(message)}
         self.message(Message.TRACE, msg)
 
+
 class TestInput(object):
-    """Test input.
-    """
+    """Test input."""
+
     def __init__(self, test, io):
         self.test = test
         self.io = io
 
 
 class TestIO(object):
-    """Test input and output protocol.
-    """
+    """Test input and output protocol."""
+
     def __init__(self, test):
         self.io = MessageIO(LogIO())
         self.output = TestOutput(test, self.io)
         self.input = TestInput(test, self.io)
 
     def message_io(self, name=None):
         """Return named line buffered message io.
@@ -300,22 +329,23 @@
         """Write line buffered message.
 
         :param msg: line buffered message
         :param stream: name of the stream
         """
         if not msg:
             return
-        self.output.message(Message.NONE, {"message":str(msg).rstrip()}, stream=stream)
+        self.output.message(Message.NONE, {"message": str(msg).rstrip()}, stream=stream)
 
     def flush(self):
         self.io.flush()
 
     def close(self, flush=False, final=False):
         self.io.close(flush=flush, final=final)
 
+
 class MessageIO(object):
     """Message input and output.
 
     :param io: io stream to write and read
     """
 
     def __init__(self, io):
@@ -346,23 +376,23 @@
             for message in messages[:-1]:
                 self.io.write(f"{message}\n")
             self.buffer = messages[-1]
         else:
             self.buffer += msg
 
     def flush(self):
-        """Flush output buffer.
-        """
+        """Flush output buffer."""
         if self.buffer:
             self.io.write(f"{self.buffer}\n")
         self.buffer = ""
 
     def close(self, flush=False, final=False):
         self.io.close(flush=flush, final=final)
 
+
 class NamedMessageIO(MessageIO):
     """Message input and output.
 
     :param io: io stream to write and read
     :param name: name of the stream, default: None
     """
 
@@ -385,24 +415,23 @@
             messages = self.buffer.split("\n")
             # last message is incomplete
             for message in messages[:-1]:
                 self.io.write(f"{message}\n", stream=self.stream)
             self.buffer = messages[-1]
 
     def flush(self):
-        """Flush output buffer.
-        """
+        """Flush output buffer."""
         if self.buffer:
             self.io.write(f"{self.buffer}\n", stream=self.stream)
         self.buffer = ""
 
 
 class ProtectedFile:
-    """Thread lock wrapped file descriptor.
-    """
+    """Thread lock wrapped file descriptor."""
+
     def __init__(self, fd):
         self.fd = fd
         self.lock = threading.Lock()
 
     def write(self, *args, **kwargs):
         with self.lock:
             return self.fd.write(*args, **kwargs)
@@ -425,25 +454,27 @@
 
     def seek(self, *args, **kwargs):
         with self.lock:
             return self.fd.seek(*args, **kwargs)
 
 
 class LogReader(object):
-    """Read messages from the log.
-    """
+    """Read messages from the log."""
+
     lock = threading.Lock()
     fd = None
 
     def __new__(cls, *args, **kwargs):
         fd = kwargs.pop("fd", None)
 
         with cls.lock:
             if not cls.fd:
-                cls.fd = fd or ProtectedFile(open(settings.read_logfile, "rb", buffering=0))
+                cls.fd = fd or ProtectedFile(
+                    open(settings.read_logfile, "rb", buffering=0)
+                )
 
             return object.__new__(LogReader)
 
     def __init__(self, fd=None):
         self.fd = fd or self.__class__.fd
 
     def tell(self):
@@ -457,32 +488,36 @@
 
     def close(self, final=False):
         if final:
             self.fd.close()
 
 
 class LogWriter(object):
-    """Singleton log file writer.
-    """
+    """Singleton log file writer."""
+
     lock = threading.Lock()
     instance = None
     auto_flush_interval = 0.15
 
     def __new__(cls, *args, **kwargs):
         fd = kwargs.pop("fd", None)
 
         with cls.lock:
             if not cls.instance:
                 self = object.__new__(LogWriter)
-                self.fd = fd or ProtectedFile(open(settings.write_logfile, "ab", buffering=0))
+                self.fd = fd or ProtectedFile(
+                    open(settings.write_logfile, "ab", buffering=0)
+                )
                 self.lock = threading.Lock()
                 self.buffer = []
                 self.pool = Pool(1)
                 self.cancel = False
-                self.pool.apply_async(self.flush, (), dict(sleep=cls.auto_flush_interval, force=True))
+                self.pool.apply_async(
+                    self.flush, (), dict(sleep=cls.auto_flush_interval, force=True)
+                )
                 cls.instance = self
             return cls.instance
 
     def __init__(self, *args, **kwargs):
         pass
 
     def write(self, msg):
@@ -505,15 +540,17 @@
             if self.buffer:
                 self.fd.write(compress(b"".join(self.buffer)))
                 self.fd.flush()
                 del self.buffer[:]
 
             if not final and threading.main_thread().is_alive():
                 self.cancel = False
-                self.pool.apply_async(self.flush, (), dict(sleep=self.auto_flush_interval, force=True))
+                self.pool.apply_async(
+                    self.flush, (), dict(sleep=self.auto_flush_interval, force=True)
+                )
 
     def close(self, flush=False, final=False):
         if final:
             self.pool.close()
             self.flush(force=True, final=True)
             self.fd.close()
             self.pool.join()
@@ -523,14 +560,15 @@
 
 class LogIO(object):
     """Log file reader and writer.
 
     :param read: file descriptor for read
     :param write: file descriptor for write
     """
+
     def __init__(self):
         if isinstance(settings.write_logfile, BaseServiceObject):
             self.writer = LogWriter(fd=settings.write_logfile)
         else:
             self.writer = LogWriter()
 
         if isinstance(settings.read_logfile, BaseServiceObject):
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/message.py` & `testflows.core-1.9.230627.1151633/testflows/_core/message.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 import json
 
 from collections import namedtuple
 
 from .utils.enum import IntEnum
 from .baseobject import namedtuple_with_defaults
 
+
 class Message(IntEnum):
     NONE = 0
     #
     TEST = 1
     RESULT = 2
     #
     EXCEPTION = 3
@@ -49,27 +50,31 @@
     STOP = 20
     #
     SPECIFICATION = 21
     PROMPT = 22
     #
     TEXT = 23
 
+
 class MessageObjectType(IntEnum):
     NONE = 0
     TEST = 1 << 0
 
+
 MessageMap = namedtuple(
-        "MessageMap",
-        "NONE "
-        "TEST RESULT "
-        "EXCEPTION NOTE DEBUG TRACE "
-        "VERSION PROTOCOL "
-        "INPUT "
-        "VALUE METRIC TICKET ARGUMENT TAG ATTRIBUTE REQUIREMENT "
-        "MAP STOP SPECIFICATION PROMPT TEXT"
-    )
+    "MessageMap",
+    "NONE "
+    "TEST RESULT "
+    "EXCEPTION NOTE DEBUG TRACE "
+    "VERSION PROTOCOL "
+    "INPUT "
+    "VALUE METRIC TICKET ARGUMENT TAG ATTRIBUTE REQUIREMENT "
+    "MAP STOP SPECIFICATION PROMPT TEXT",
+)
+
 
 def dumps(o):
     return json.dumps(o, separators=(",", ":"), ensure_ascii=False)
 
+
 def loads(s):
     return json.loads(s)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/name.py` & `testflows.core-1.9.230627.1151633/testflows/_core/name.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,14 +6,15 @@
 sep = "/"
 empty = ""
 dot = "."
 dotdot = ".."
 pardir = dotdot
 curdir = dot
 
+
 def match(name, pat, prefix=False):
     """Test whether FILENAME matches PATTERN.
 
     Patterns are modified Unix shell style:
 
     *       matches everything
     :       matches everything but path separator '/'
@@ -26,25 +27,26 @@
     if the operating system requires it.
     If you don't want this, use matchcase(FILENAME, PATTERN).
     """
     name = normcase(name)
     pat = normcase(pat)
     return matchcase(name, pat, prefix=prefix)
 
+
 def filter(names, pat, prefix=False):
-    """Return the subset of the list NAMES that match PAT.
-    """
+    """Return the subset of the list NAMES that match PAT."""
     result = []
     match = _compile_pattern(pat, prefix=prefix).match
     # normcase is NOP. Optimize it away from the loop.
     for name in names:
         if match(name):
             result.append(name)
     return result
 
+
 def matchcase(name, pat, prefix=False):
     """Test whether FILENAME matches PATTERN, including case.
 
     Patterns are modified Unix shell style:
 
     *       matches everything
     :       matches everything but path separator '/'
@@ -54,19 +56,21 @@
 
     This is a version of fnmatch() which doesn't case-normalize
     its arguments.
     """
     match = _compile_pattern(pat, prefix=prefix).match
     return match(name) is not None
 
+
 @functools.lru_cache(maxsize=256, typed=True)
 def _compile_pattern(pat, prefix=False):
     res = translate(pat, prefix=prefix)
     return re.compile(res)
 
+
 def translate(pat, prefix=False):
     """Translate a shell PATTERN to a regular expression.
 
     If prefix is set to True, then translates a shell
     PATTERN to a regular expression that matches
     longest prefix of the path.
 
@@ -82,51 +86,53 @@
 
     There is no way to quote meta-characters.
     """
     if prefix:
         return _translate_prefix(pat)
     return _translate(pat)
 
+
 def _translate(pat):
     """Translate a shell PATTERN to a regular expression.
 
     There is no way to quote meta-characters.
     """
     i, n = 0, len(pat)
-    res = ''
+    res = ""
     while i < n:
         c = pat[i]
-        i = i+1
-        if c == '*':
-            res = res + '.*'
-        elif c == ':':
-            res = res + '[^/]+'
-        elif c == '?':
-            res = res + '.'
-        elif c == '[':
+        i = i + 1
+        if c == "*":
+            res = res + ".*"
+        elif c == ":":
+            res = res + "[^/]+"
+        elif c == "?":
+            res = res + "."
+        elif c == "[":
             j = i
-            if j < n and pat[j] == '!':
-                j = j+1
-            if j < n and pat[j] == ']':
-                j = j+1
-            while j < n and pat[j] != ']':
-                j = j+1
+            if j < n and pat[j] == "!":
+                j = j + 1
+            if j < n and pat[j] == "]":
+                j = j + 1
+            while j < n and pat[j] != "]":
+                j = j + 1
             if j >= n:
-                res = res + '\\['
+                res = res + "\\["
             else:
-                stuff = pat[i:j].replace('\\','\\\\')
-                i = j+1
-                if stuff[0] == '!':
-                    stuff = '^' + stuff[1:]
-                elif stuff[0] == '^':
-                    stuff = '\\' + stuff
-                res = '%s[%s]' % (res, stuff)
+                stuff = pat[i:j].replace("\\", "\\\\")
+                i = j + 1
+                if stuff[0] == "!":
+                    stuff = "^" + stuff[1:]
+                elif stuff[0] == "^":
+                    stuff = "\\" + stuff
+                res = "%s[%s]" % (res, stuff)
         else:
             res = res + re.escape(c)
-    return r'(?s:%s)\Z' % res
+    return r"(?s:%s)\Z" % res
+
 
 def _translate_prefix(pat):
     """Translate a shell PATTERN to a regular expression
     that matches longest prefix of the path.
 
     For example the pattern  'A/B/C' would match
     'A', 'A/B' , 'A/B/C'
@@ -138,81 +144,86 @@
     If you need to match such path you need to
     rstrip() the '/' before matching.
 
     There is no way to quote meta-characters.
     """
 
     i, n = 0, len(pat)
-    res = ''
+    res = ""
     level = 0
     while i < n:
         c = pat[i]
-        i = i+1
-        if c == '/':
+        i = i + 1
+        if c == "/":
             level += 1
-            res = res + '(/'
-        elif c == '*':
+            res = res + "(/"
+        elif c == "*":
             level += 1
-            res = res + '(.*'
-        elif c == ':':
+            res = res + "(.*"
+        elif c == ":":
             level += 1
-            res = res + '([^/]+'
-        elif c == '?':
+            res = res + "([^/]+"
+        elif c == "?":
             level += 1
-            res = res + '(.'
-        elif c == '[':
+            res = res + "(."
+        elif c == "[":
             has = False
             j = i
-            if j < n and pat[j] == '!':
-                j = j+1
-            if j < n and pat[j] == ']':
-                j = j+1
-            while j < n and pat[j] != ']':
-                if pat[j] == '/':
+            if j < n and pat[j] == "!":
+                j = j + 1
+            if j < n and pat[j] == "]":
+                j = j + 1
+            while j < n and pat[j] != "]":
+                if pat[j] == "/":
                     has = True
-                j = j+1
+                j = j + 1
             if j >= n:
-                res = res + '\\['
+                res = res + "\\["
             else:
-                stuff = pat[i:j].replace('\\','\\\\')
-                i = j+1
-                if stuff[0] == '!':
-                    stuff = '^' + stuff[1:]
-                elif stuff[0] == '^':
-                    stuff = '\\' + stuff
+                stuff = pat[i:j].replace("\\", "\\\\")
+                i = j + 1
+                if stuff[0] == "!":
+                    stuff = "^" + stuff[1:]
+                elif stuff[0] == "^":
+                    stuff = "\\" + stuff
                 if has:
                     level += 1
-                    res = '%s([%s]' % (res, stuff)
+                    res = "%s([%s]" % (res, stuff)
                 else:
-                    res = '%s[%s]' % (res, stuff)
+                    res = "%s[%s]" % (res, stuff)
         else:
             res = res + re.escape(c)
     for l in range(level):
-        res = res + ')?'
-    return r'(?s:%s)\Z' % res
+        res = res + ")?"
+    return r"(?s:%s)\Z" % res
+
 
 # Normalize a path, e.g. A//B, A/./B and A/foo/../B all become A/B.
 def normname(name):
     comps = name.split(sep)
     new_comps = []
     initial_slashes = name.startswith(sep)
     for comp in comps:
         if comp in (empty, dot):
             continue
-        if (comp != dotdot or (not initial_slashes and not new_comps) or
-             (new_comps and new_comps[-1] == dotdot)):
+        if (
+            comp != dotdot
+            or (not initial_slashes and not new_comps)
+            or (new_comps and new_comps[-1] == dotdot)
+        ):
             new_comps.append(comp)
         elif new_comps:
             new_comps.pop()
     comps = new_comps
     name = sep.join(comps)
     if initial_slashes:
         name = sep * initial_slashes + name
     return name or dot
 
+
 # Join pathnames.
 # Ignore the previous parts if a part is absolute.
 # Insert a '/' unless the first part is empty or already ends in '/'.
 def join(a, *p):
     """Join two or more name components, inserting '/' as needed.
     If any component is an absolute name, all previous name components
     will be discarded.  An empty last part will result in a name that
@@ -225,63 +236,66 @@
             name = b
         elif not name or name.endswith(sep):
             name += b
         else:
             name += sep + b
     return name
 
+
 def isabs(name):
-    """Test whether a name is absolute.
-    """
+    """Test whether a name is absolute."""
     return name.startswith(sep)
 
+
 def absname(n, at):
     """Return an absolute name relative
     to the name specified in the `at`.
     """
     if not isabs(n):
         n = join(at, n)
     return normname(n)
 
+
 # Return the tail (basename) part of a name, same as split(name)[1].
 def basename(name):
-    """Returns the final component of a name.
-    """
+    """Returns the final component of a name."""
     i = name.rfind(sep) + 1
     return name[i:]
 
+
 # Return the head (dirname) part of a name, same as split(name)[0].
 def parentname(name):
-    """Returns the directory component of a name.
-    """
+    """Returns the directory component of a name."""
     i = name.rfind(sep) + 1
     head = name[:i]
     if head and head != sep * len(head):
         head = head.rstrip(sep)
     return head
 
+
 def depth(name):
-    """Return depth of the path.
-    """
+    """Return depth of the path."""
     return name.count(sep)
 
+
 # Split a path in head (everything up to the last '/') and tail (the
 # rest).  If the path ends in '/', tail will be empty.  If there is no
 # '/' in the path, head  will be empty.
 # Trailing '/'es are stripped from head unless it is the root.
 def split(name):
     """Split a name.  Returns tuple "(head, tail)" where "tail" is
     everything after the final slash.  Either part may be empty.
     """
     i = name.rfind(sep) + 1
     head, tail = name[:i], name[i:]
     if head and head != sep * len(head):
         head = head.rstrip(sep)
     return head, tail
 
+
 def relname(name, at, start=None):
     """Return a relative version of a name
     relative to the `at`.
     """
     if not name:
         raise ValueError("no name specified")
 
@@ -289,52 +303,52 @@
         start = curdir
 
     start_list = [x for x in absname(start, at).split(sep) if x]
     name_list = [x for x in absname(name, at).split(sep) if x]
     # Work out how much of the filepath is shared by start and path.
     i = len(commonprefix([start_list, name_list]))
 
-    rel_list = [pardir] * (len(start_list)-i) + name_list[i:]
+    rel_list = [pardir] * (len(start_list) - i) + name_list[i:]
     if not rel_list:
         return curdir
     return join(*rel_list)
 
+
 # Return the longest prefix of all list elements.
 def commonprefix(m):
-    """Given a list of pathnames, returns the longest common leading component.
-    """
-    if not m: return ''
+    """Given a list of pathnames, returns the longest common leading component."""
+    if not m:
+        return ""
     # Some people pass in a list of pathname parts to operate in an OS-agnostic
     # fashion; don't try to translate in that case as that's an abuse of the
     # API and they are already doing what they need to be OS-agnostic and so
     # they most likely won't be using an os.PathLike object in the sublists.
     if not isinstance(m[0], (list, tuple)):
         m = tuple(m)
     s1 = min(m)
     s2 = max(m)
     for i, c in enumerate(s1):
         if c != s2[i]:
             return s1[:i]
     return s1
 
+
 # Return the longest common sub-path of the sequence of paths given as input.
 # The paths are not normalized before comparing them (this is the
 # responsibility of the caller). Any trailing separator is stripped from the
 # returned path.
 def commonname(names):
-    """Given a sequence of names, returns the longest common sub-name.
-    """
+    """Given a sequence of names, returns the longest common sub-name."""
     if not names:
-        raise ValueError('names is an empty sequence')
-
+        raise ValueError("names is an empty sequence")
 
     split_names = [name.split(sep) for name in names]
 
     try:
-        isabs, = set(n[:1] == sep for n in names)
+        (isabs,) = set(n[:1] == sep for n in names)
     except ValueError:
         raise ValueError("can't mix absolute and relative names") from None
 
     split_names = [[c for c in s if c and c != curdir] for s in split_names]
     s1 = min(split_names)
     s2 = max(split_names)
     common = s1
@@ -342,11 +356,11 @@
         if c != s2[i]:
             common = s1[:i]
             break
 
     prefix = sep if isabs else sep[:0]
     return prefix + sep.join(common)
 
+
 def normcase(s):
-    """Normalize case of pathname.
-    """
+    """Normalize case of pathname."""
     return s
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/objects.py` & `testflows.core-1.9.230627.1151633/testflows/_core/objects.py`

 * *Files 8% similar despite different names*

```diff
@@ -24,14 +24,15 @@
 from .exceptions import SpecificationError, RequirementError, ResultException
 from .baseobject import TestObject, Table
 from .baseobject import get, hash
 from .testtype import TestType
 
 import testflows._core.contrib.rsa as rsa
 
+
 class Result(TestObject, ResultException):
     _fields = ("message", "reason", "type", "test")
     _defaults = (None,) * 6
     metrics = []
     tickets = []
     values = []
     type = None
@@ -46,16 +47,28 @@
         XFail = 7
         XError = 8
         XNull = 9
 
         def __repr__(self):
             return f"Result.Type.{self._name_}"
 
-    def __init__(self, message=None, reason=None, type=None, test=None, metrics=None, tickets=None, values=None, start_time=None, test_time=None):
+    def __init__(
+        self,
+        message=None,
+        reason=None,
+        type=None,
+        test=None,
+        metrics=None,
+        tickets=None,
+        values=None,
+        start_time=None,
+        test_time=None,
+    ):
         from .funcs import current
+
         self.test = test if test is not None else current().name
         if not isinstance(self.test, str):
             raise TypeError("test must be of 'str' type")
         self.type = get(type, self.type)
         if self.type is None:
             raise TypeError("type must be defined")
         self.message = message
@@ -64,15 +77,28 @@
         self.tickets = get(tickets, list(self.tickets))
         self.values = get(values, list(self.values))
         self.start_time = start_time
         self.test_time = test_time
         return super(Result, self).__init__()
 
     def __reduce__(self):
-        return (self.__class__, (self.message, self.reason, self.type, self.test, self.metrics, self.tickets, self.values, self.start_time, self.test_time))
+        return (
+            self.__class__,
+            (
+                self.message,
+                self.reason,
+                self.type,
+                self.test,
+                self.metrics,
+                self.tickets,
+                self.values,
+                self.start_time,
+                self.test_time,
+            ),
+        )
 
     @property
     def value(self):
         return self.values[-1].value if self.values else None
 
     def __call__(self, result=None):
         if result is None:
@@ -98,102 +124,115 @@
 
     def __eq__(self, o):
         return self.type == o.type
 
     def __ne__(self, o):
         return not self == o
 
+
 class XResult(Result):
     pass
 
+
 class OK(Result):
     type = Result.Type.OK
 
     def xout(self, reason):
         return self(XOK(test=self.test, message=self.message, reason=reason))
 
+
 class XOK(XResult):
     type = Result.Type.XOK
 
 
 class Fail(Result):
     type = Result.Type.Fail
 
     def xout(self, reason):
         return self(XFail(test=self.test, message=self.message, reason=reason))
 
     def __bool__(self):
         return False
 
+
 class XFail(XResult):
     type = Result.Type.XFail
 
+
 class Skip(Result):
     type = Result.Type.Skip
 
+
 class Error(Result):
     type = Result.Type.Error
 
     def xout(self, reason):
         return self(XError(test=self.test, message=self.message, reason=reason))
 
     def __bool__(self):
         return False
 
+
 class XError(XResult):
     type = Result.Type.XError
 
+
 class Null(Result):
     type = Result.Type.Null
 
     def xout(self, reason):
         return self(XNull(test=self.test, message=self.message, reason=reason))
 
     def __bool__(self):
         return False
 
+
 class XNull(XResult):
     type = Result.Type.XNull
 
+
 XoutResults = (XOK, XFail, XError, XNull)
 FailResults = (Fail, Error, Null)
 PassResults = (OK,) + XoutResults
 NonFailResults = (Skip,) + PassResults
 
+
 class Node(TestObject):
     _fields = ("map", "name", "module", "uid", "nexts", "ins", "outs")
     _defaults = (None,) * 3
 
     def __init__(self, map, module, nexts=None, ins=None, outs=None):
         self.map = map
         self.name = module.rsplit(".", 1)[-1]
         self.module = module
         self.uid = self.get_uid(None, module)
         self.nexts = get(nexts, [])
         self.ins = get(ins, [])
-        self.outs =get(outs, [])
+        self.outs = get(outs, [])
         return super(Node, self).__init__()
 
     @classmethod
     def get_uid(cls, test, module=None):
         if module is None:
             module = test.module
         return hash(module, short=True)
 
+
 class Tag(TestObject):
     _fields = ("value",)
     _defaults = ()
 
     def __init__(self, value):
         self.value = value
         return super(Tag, self).__init__()
 
     def __str__(self):
         return str(self.value)
 
+
 class Argument(TestObject):
     _fields = ("name", "value", "type", "group", "uid")
     _defaults = (None,) * 4
     uid = None
     type = None
     group = None
 
@@ -201,14 +240,15 @@
         self.name = name
         self.value = value
         self.type = get(type, self.type)
         self.group = get(group, self.group)
         self.uid = get(uid, self.uid)
         return super(Argument, self).__init__()
 
+
 class Attribute(TestObject):
     _fields = ("name", "value", "type", "group", "uid")
     _defaults = (None,) * 3
     uid = None
     type = None
     group = None
 
@@ -216,43 +256,68 @@
         self.name = name
         self.value = value
         self.type = get(type, self.type)
         self.group = get(group, self.group)
         self.uid = get(uid, self.uid)
         return super(Attribute, self).__init__()
 
+
 class Requirement(TestObject):
-    _fields = ("name", "version", "description",
-            "link", "priority", "type", "group", "uid", "level", "num")
+    _fields = (
+        "name",
+        "version",
+        "description",
+        "link",
+        "priority",
+        "type",
+        "group",
+        "uid",
+        "level",
+        "num",
+    )
     _defaults = (None,) * 8
     uid = None
     link = None
     priority = None
     type = None
     group = None
 
-    def __init__(self, name, version, description=None, link=None,
-            priority=None, type=None, group=None, uid=None, level=None, num=None):
+    def __init__(
+        self,
+        name,
+        version,
+        description=None,
+        link=None,
+        priority=None,
+        type=None,
+        group=None,
+        uid=None,
+        level=None,
+        num=None,
+    ):
         self.name = name
         self.version = version
         self.description = get(description, self.__doc__)
         self.link = get(link, self.link)
         self.priority = get(priority, self.priority)
         self.type = get(type, self.type)
         self.group = get(group, self.group)
         self.uid = get(uid, self.uid)
         self.level = level
         self.num = num
         return super(Requirement, self).__init__()
 
     def __call__(self, *version):
         if not self.version in version:
-            raise RequirementError("requirement version %s is not in %s" % (self.version, list(version)))
+            raise RequirementError(
+                "requirement version %s is not in %s" % (self.version, list(version))
+            )
         return self
 
+
 class Metric(TestObject):
     _fields = ("name", "value", "units", "type", "group", "uid")
     _defaults = (None,) * 3
     uid = None
     type = None
     group = None
 
@@ -261,14 +326,15 @@
         self.value = value
         self.units = units
         self.type = get(type, self.type)
         self.group = get(group, self.group)
         self.uid = get(uid, self.uid)
         return super(Metric, self).__init__()
 
+
 class Value(TestObject):
     _fields = ("name", "value", "type", "group", "uid")
     _defaults = (None,) * 3
     uid = None
     type = None
     group = None
 
@@ -276,14 +342,15 @@
         self.name = name
         self.value = str(value)
         self.type = get(type, self.type)
         self.group = get(group, self.group)
         self.uid = get(uid, self.uid)
         return super(Value, self).__init__()
 
+
 class Ticket(TestObject):
     _fields = ("name", "link", "type", "group", "uid")
     _defaults = (None,) * 4
     uid = None
     link = None
     type = None
     group = None
@@ -292,30 +359,65 @@
         self.name = name
         self.link = get(link, self.link)
         self.type = get(type, self.type)
         self.group = get(group, self.group)
         self.uid = get(uid, self.uid)
         return super(Ticket, self).__init__()
 
+
 class Specification(TestObject):
-    _fields = ("name", "content", "description", "link", "author", "version",
-        "date", "status", "approved_by", "approved_date", "approved_version",
-        "type", "group", "uid", "parent", "children", "headings", "requirements")
+    _fields = (
+        "name",
+        "content",
+        "description",
+        "link",
+        "author",
+        "version",
+        "date",
+        "status",
+        "approved_by",
+        "approved_date",
+        "approved_version",
+        "type",
+        "group",
+        "uid",
+        "parent",
+        "children",
+        "headings",
+        "requirements",
+    )
     _defaults = (None,) * 16
     uid = None
     link = None
     type = None
     group = None
 
     Heading = namedtuple("Heading", "name level num")
 
-    def __init__(self, name, content, description=None, link=None, author=None, version=None,
-        date=None, status=None, approved_by=None, approved_date=None, approved_version=None,
-        type=None, group=None, uid=None, parent=None, children=None, headings=None,
-        requirements=None):
+    def __init__(
+        self,
+        name,
+        content,
+        description=None,
+        link=None,
+        author=None,
+        version=None,
+        date=None,
+        status=None,
+        approved_by=None,
+        approved_date=None,
+        approved_version=None,
+        type=None,
+        group=None,
+        uid=None,
+        parent=None,
+        children=None,
+        headings=None,
+        requirements=None,
+    ):
         self.name = name
         self.content = content
         self.description = description
         self.author = author
         self.version = version
         self.date = date
         self.status = status
@@ -329,90 +431,98 @@
         self.parent = parent
         self.children = children
         self.headings = headings
         self.requirements = requirements
 
     def __call__(self, *version):
         if not self.version in version:
-            raise SpecificationError("specification version %s is not in %s" % (self.version, list(version)))
+            raise SpecificationError(
+                "specification version %s is not in %s" % (self.version, list(version))
+            )
         return self
 
+
 class ExamplesRow(TestObject):
     _fields = ("row", "columns", "values", "row_format")
     _defaults = (None,)
+
     def __init__(self, row, columns, values, row_format=None):
         self.row = row
         self.columns = columns
         self.values = [str(value) for value in values]
         self.row_format = row_format
 
+
 class Secrets:
-    """Secrets registry.
-    """
+    """Secrets registry."""
+
     def __init__(self, secrets=None):
         self._secrets = secrets or {}
         self._filter_regex = re.compile(r"")
         self._filter_secrets = []
         self._lock = threading.Lock()
         self._update_filter()
 
     def __reduce__(self):
         return (Secrets, (self._secrets,))
 
     def is_empty(self):
-        """Return True if registry is empty.
-        """
+        """Return True if registry is empty."""
         with self._lock:
             return not bool(self._filter_secrets)
 
     def register(self, secret):
-        """Register secret object.
-        """
+        """Register secret object."""
         with self._lock:
             if secret.name in self._secrets:
                 raise ValueError(f"secret '{secret.name}' already registered")
             self._secrets[secret.name] = secret
             self._update_filter()
 
     def unregister(self, secret):
-        """Unregister secret object.
-        """
+        """Unregister secret object."""
         with self._lock:
             self._secrets.pop(secret.name, None)
             self._update_filter()
 
     def _update_filter(self):
-        """Update filter regex.
-        """
+        """Update filter regex."""
         self._filter_secrets = [s for s in self._secrets.values() if s.is_set()]
-        self._filter_regex = re.compile("|".join([f"(?P<{s.name}>{re.escape(s.value)})" for s in self._filter_secrets]))
+        self._filter_regex = re.compile(
+            "|".join(
+                [f"(?P<{s.name}>{re.escape(s.value)})" for s in self._filter_secrets]
+            )
+        )
 
     def filter(self, message):
-        """Filter all secret values from message.
-        """
+        """Filter all secret values from message."""
+
         def _filter(s):
             if not isinstance(s, str):
                 return message
-            return self._filter_regex.sub(lambda m: f"[masked]:{self._filter_secrets[m.lastindex-1]}", s)
+            return self._filter_regex.sub(
+                lambda m: f"[masked]:{self._filter_secrets[m.lastindex-1]}", s
+            )
 
         with self._lock:
             if isinstance(message, (list, tuple)):
                 for i, e in enumerate(message):
                     message[i] = self.filter(e)
                 return message
             elif isinstance(message, dict):
                 _message = {}
                 for k, v in message.items():
                     _message[filter(k)] = filter(v)
                 return _message
             return _filter(message)
 
+
 class Secret(TestObject):
-    """Secret value.
-    """
+    """Secret value."""
+
     _fields = ("name", "type", "group", "uid")
     _defaults = (None,) * 4
 
     uid = None
     type = None
     name = None
     group = None
@@ -422,15 +532,17 @@
 
         if self.name is None:
             raise TypeError("name must be specified")
         else:
             try:
                 re.compile(rf"(?P<{self.name}>)")
             except re.error as e:
-                raise ValueError("invalid secret name, " + str(e).replace("group name ", "")) from None
+                raise ValueError(
+                    "invalid secret name, " + str(e).replace("group name ", "")
+                ) from None
 
         self.type = get(type, self.type)
         self.group = get(group, self.group)
         self.uid = get(uid, self.uid)
         self._value = None
 
     def __enter__(self):
@@ -452,53 +564,60 @@
             if not settings.secrets_registry:
                 raise RuntimeError("no secrets registry")
             settings.secrets_registry.register(self)
 
         return self
 
     def is_set(self):
-        """Return true if value has been set.
-        """
+        """Return true if value has been set."""
         return self._value is not None
 
     @property
     def value(self):
-        """Return plaintext value of the secret.
-        """
+        """Return plaintext value of the secret."""
         if self._value is None:
             raise ValueError("no value")
         return self._value
 
     def __str__(self):
         return self.__repr__()
 
     def __repr__(self):
-        """Custom object representation.
-        """
+        """Custom object representation."""
         kwargs = []
         for field in self._fields:
             value = getattr(self, field)
             if value is None:
                 continue
             kwargs.append(f"{field}={repr(value)}")
 
         return f"Secret({','.join(kwargs)})"
 
+
 class RSASecret(Secret):
-    """RSA encrypted secret value.
-    """
-    _fields = ("name", "type", "group", "uid", "code", "pubkey_id",)
+    """RSA encrypted secret value."""
+
+    _fields = (
+        "name",
+        "type",
+        "group",
+        "uid",
+        "code",
+        "pubkey_id",
+    )
     _defaults = (None,) * 6
     uid = None
     name = None
     type = None
     group = None
     encoding = "utf-8"
 
-    def __init__(self, name=None, type=None, group=None, uid=None, code=None, pubkey_id=None):
+    def __init__(
+        self, name=None, type=None, group=None, uid=None, code=None, pubkey_id=None
+    ):
         self.name = get(name, None)
         self.type = get(type, self.type)
         self.group = get(group, self.group)
         self.uid = get(uid, self.uid)
         self.pubkey_id = get(pubkey_id, None)
         if self.pubkey_id is not None:
             self.pubkey_id = base64.b64decode(pubkey_id.encode(self.encoding))
@@ -533,28 +652,28 @@
             if self.code is None:
                 raise ValueError("no code")
             self._value = rsa.decrypt(self.code, private_key).decode(self.encoding)
 
         return self
 
     def __repr__(self):
-        """Custom object representation.
-        """
+        """Custom object representation."""
         kwargs = []
         for field in self._fields:
             value = getattr(self, field)
             if value is None:
                 continue
             if field in ("code", "pubkey_id"):
                 kwargs.append(f"{field}='{base64.b64encode(value).decode('utf-8')}'")
             else:
                 kwargs.append(f"{field}={repr(value)}")
 
         return f"Secret({','.join(kwargs)})"
 
+
 class ExamplesTable(Table):
     _row_type_name = "Example"
 
     def __new__(cls, header=None, rows=None, row_format=None, args=None):
         if rows is None:
             rows = []
         if header is None:
@@ -568,37 +687,42 @@
 
         class ExampleRow(row_type):
             def __new__(cls, *args):
                 _args = {}
                 args = list(args)
                 len_header = len(header.split(" "))
                 if len(args) > len_header:
-                    _args = {k:v for arg in args[len_header:] for k, v in dict(arg).items()}
+                    _args = {
+                        k: v for arg in args[len_header:] for k, v in dict(arg).items()
+                    }
 
                     if "type" in args:
                         raise TypeError("can't specify 'type' using example arguments")
                     if "args" in args:
                         raise TypeError("can't specify 'args' using example arguments")
 
                     del args[len_header:]
 
                 obj = super(ExampleRow, cls).__new__(cls, *args)
                 obj._args = _args
                 return obj
 
-        obj = super(ExamplesTable, cls).__new__(cls, header, rows, row_format, ExampleRow)
+        obj = super(ExamplesTable, cls).__new__(
+            cls, header, rows, row_format, ExampleRow
+        )
 
         for idx, row in enumerate(obj):
             row._idx = idx
             row._row_format = obj.row_format
 
         obj.args = args
 
         return obj
 
+
 class NamedValue(object):
     name = None
 
     def __init__(self, value):
         self.value = value
 
     def keys(self):
@@ -609,18 +733,20 @@
             return self.value
         raise KeyError(key)
 
     def __call__(self, func):
         setattr(func, self.name, self.value)
         return func
 
+
 class NamedString(NamedValue):
     def __str__(self):
         return str(self.value)
 
+
 class NamedList(list):
     name = None
 
     def __init__(self, *items):
         super(NamedList, self).__init__(items)
 
     def keys(self):
@@ -631,97 +757,111 @@
             return list(self)
         return super(NamedList, self).__getitem__(key)
 
     def __call__(self, func):
         setattr(func, self.name, list(self))
         return func
 
+
 class Onlys(NamedList):
     """only container.
 
     ```python
     @Only(
         pattern,
         ...
     )
     ```
     """
+
     name = "only"
 
     def __init__(self, *items):
         super(Onlys, self).__init__(*items)
 
+
 class Skips(NamedList):
     """skip container.
 
     ```python
     @Skips(
         pattern,
         ...
     )
     ```
     """
+
     name = "skip"
 
     def __init__(self, *items):
         super(Skips, self).__init__(*items)
 
+
 class _FilterTags(NamedValue):
-    """filter tags object.
-    """
+    """filter tags object."""
+
     def __init__(self, test=None, suite=None, module=None, any=None):
         test = set(test) if test is not None else set()
         suite = set(suite) if suite is not None else set()
         module = set(module) if module is not None else set()
         any = set(any) if any is not None else set()
         if any:
             test = test.union(any)
             suite = suite.union(any)
             module = module.union(any)
-        super(_FilterTags, self).__init__({TestType.Test: test, TestType.Suite: suite, TestType.Module: module})
+        super(_FilterTags, self).__init__(
+            {TestType.Test: test, TestType.Suite: suite, TestType.Module: module}
+        )
+
 
 class OnlyTags(_FilterTags):
     """only_tags filter object.
 
     ```python
     @OnlyTags(
        test=[tagA,(tagA,tagB),...],
        suite=[...],
        module=[...],
        any=[...]
     )
     ```
     """
+
     name = "only_tags"
 
+
 class SkipTags(_FilterTags):
     """skip_tags filter object.
 
     ```python
     @SkipTags(
        test=[tagA,(tagA,tagB),...],
        suite=[...],
        module=[...],
        any=[...]
     )
     ```
     """
+
     name = "skip_tags"
 
+
 class Setup(NamedValue):
     name = "setup"
 
+
 class XFails(NamedValue):
     """xfails container.
 
     xfails = {
         "pattern": [("result", "reason"[, when][, result_message])],
         ...
         }
     """
+
     name = "xfails"
 
     def __init__(self, value):
         super(XFails, self).__init__(dict(value))
 
     def items(self):
         return self.value.items()
@@ -732,22 +872,24 @@
         :param pattern: test name pattern to match
         :param *results: one or more results to cross out
             where each result is a two-tuple or three-tuple or four-tuple of (result, reason[, when][, result_message])
         """
         self.value[pattern] = results
         return self
 
+
 class FFails(NamedValue):
     """ffails (forced fails) container.
 
     ffails = {
         "pattern": (result, "reason"[, when]),
         ...
         }
     """
+
     name = "ffails"
 
     def __init__(self, value):
         value = dict(value)
         value = {p: list(FFail(*v).value.values())[0] for p, v in value.items()}
         super(FFails, self).__init__(value)
 
@@ -763,73 +905,94 @@
         :param when: when filter
         """
         if when is not None and not callable(when):
             raise TypeError(f"invalid when type '{type(when)}'; must be callable")
         self.value[pattern] = (result, reason, when)
         return self
 
+
 class FFail(NamedValue):
-    """ffails (forced fails) container with single result.
-    """
+    """ffails (forced fails) container with single result."""
+
     name = "ffails"
 
     def __init__(self, result, reason, when=None, pattern=""):
         if not issubclass(result, Result):
             raise TypeError(f"invalid result '{result}' type")
         if not type(reason) in (str,):
             raise TypeError(f"reason '{type(reason)}' must be str")
         if when is not None and not callable(when):
             raise TypeError(f"when '{type(when)}' must be callable")
 
         super(FFail, self).__init__({pattern: (result, reason, when)})
 
+
 class Skipped(FFail):
-    """ffails (forced fails) container with single Skip result.
-    """
+    """ffails (forced fails) container with single Skip result."""
+
     def __init__(self, reason, when=None, pattern=""):
-        super(Skipped, self).__init__(reason=reason, when=when, pattern=pattern, result=Skip)
+        super(Skipped, self).__init__(
+            reason=reason, when=when, pattern=pattern, result=Skip
+        )
+
 
 class Failed(FFail):
-    """ffails (forced fails) container with single Fail result.
-    """
+    """ffails (forced fails) container with single Fail result."""
+
     def __init__(self, reason, when=None, pattern=""):
-        super(Failed, self).__init__(reason=reason, when=when, pattern=pattern, result=Fail)
+        super(Failed, self).__init__(
+            reason=reason, when=when, pattern=pattern, result=Fail
+        )
+
 
 class XFailed(FFail):
-    """ffails (forced fails) container with single XFail result.
-    """
+    """ffails (forced fails) container with single XFail result."""
+
     def __init__(self, reason, when=None, pattern=""):
-        super(XFailed, self).__init__(reason=reason, when=when, pattern=pattern, result=XFail)
+        super(XFailed, self).__init__(
+            reason=reason, when=when, pattern=pattern, result=XFail
+        )
+
 
 class XErrored(FFail):
-    """ffails (forced fails) container with single XError result.
-    """
+    """ffails (forced fails) container with single XError result."""
+
     def __init__(self, reason, when=None, pattern=""):
-        super(XErrored, self).__init__(reason=reason, when=when, pattern=pattern, result=XError)
+        super(XErrored, self).__init__(
+            reason=reason, when=when, pattern=pattern, result=XError
+        )
+
 
 class Okayed(FFail):
-    """ffails (forced fails) container with single OK result.
-    """
+    """ffails (forced fails) container with single OK result."""
+
     def __init__(self, reason, when=None, pattern=""):
-        super(Okayed, self).__init__(reason=reason, when=when, pattern=pattern, result=OK)
+        super(Okayed, self).__init__(
+            reason=reason, when=when, pattern=pattern, result=OK
+        )
+
 
 class XOkayed(FFail):
-    """ffails (forced fails) container with single XOK result.
-    """
+    """ffails (forced fails) container with single XOK result."""
+
     def __init__(self, reason, when=None, pattern=""):
-        super(XOkayed, self).__init__(reason=reason, when=when, pattern=pattern, result=XOK)
+        super(XOkayed, self).__init__(
+            reason=reason, when=when, pattern=pattern, result=XOK
+        )
+
 
 class XFlags(NamedValue):
     """xflags container.
 
     xflags = {
         "filter": (set_flags, clear_flags[, when]),
         ...
     }
     """
+
     name = "xflags"
 
     def __init__(self, value):
         super(XFlags, self).__init__(dict(value))
 
     def items(self):
         return self.value.items()
@@ -841,78 +1004,105 @@
         :param set_flags: flags to set
         :param clear_flags: flags to clear, default: None
         :param when: condition function, default: None
         """
         self.value[pattern] = [Flags(set_flags), Flags(clear_flags), when]
         return self
 
+
 class Repeats(NamedValue):
     """repeats containers.
 
     repeats={
         "pattern": (count, [until[,count[,timeout[,delay[,backoff[,jitter]]]]]])
         ...
     }
     """
+
     name = "repeats"
 
     def __init__(self, value):
         value = dict(value)
         value = {p: list(Repeat(*r).value.values())[0] for p, r in value.items()}
         super(Repeats, self).__init__(value)
 
+
 class Repeat(NamedValue):
-    """single repetition container.
-    """
+    """single repetition container."""
+
     name = "repeats"
 
-    def __init__(self, count, until="complete", pattern="", delay=0, backoff=1, jitter=None):
+    def __init__(
+        self, count, until="complete", pattern="", delay=0, backoff=1, jitter=None
+    ):
         """
         :param count: number of iterations, default: None
         :param until: stop condition, either 'pass', 'fail', or 'complete', default: 'complete'
         :param delay: delay in sec between iterations, default: 0 sec
         :param backoff: backoff multiplier that is applied to the delay, default: 1
         :param jitter: jitter added to delay between iterationsspecified as
                    a tuple(min, max), default: (0,0)
         """
         self.count = int(count)
         self.pattern = str(pattern)
         self.until = str(until)
         self.delay = float(delay)
         self.backoff = float(backoff)
-        self.jitter =  tuple(jitter) if jitter else tuple([0, 0])
+        self.jitter = tuple(jitter) if jitter else tuple([0, 0])
 
         if self.count < 1:
             raise ValueError("count must be > 0")
         if self.until not in ("fail", "pass", "complete"):
             raise ValueError("invalid until value")
 
-        return super(Repeat, self).__init__({self.pattern: (self.count, self.until, self.delay, self.backoff, self.jitter)})
+        return super(Repeat, self).__init__(
+            {
+                self.pattern: (
+                    self.count,
+                    self.until,
+                    self.delay,
+                    self.backoff,
+                    self.jitter,
+                )
+            }
+        )
+
 
 class Retries(NamedValue):
     """retries containers.
 
     retries={
         "pattern": count[,timeout[,delay[,backoff[,jitter]]]] ,
         ...
     }
     """
+
     name = "retries"
 
     def __init__(self, value):
         value = dict(value)
         value = {p: list(Retry(*r).value.values())[0] for p, r in value.items()}
         super(Retries, self).__init__(value)
 
+
 class Retry(NamedValue):
-    """single retry container.
-    """
+    """single retry container."""
+
     name = "retries"
 
-    def __init__(self, count=None, timeout=None, delay=0, backoff=1, jitter=None, pattern="", initial_delay=0):
+    def __init__(
+        self,
+        count=None,
+        timeout=None,
+        delay=0,
+        backoff=1,
+        jitter=None,
+        pattern="",
+        initial_delay=0,
+    ):
         """
         :param count: number of retries, default: None
         :param timeout: timeout in sec, default: None
         :param delay: delay in sec between retries, default: 0 sec
         :param backoff: backoff multiplier that is applied to the delay, default: 1
         :param jitter: jitter added to delay between retries specified as
                    a tuple(min, max), default: (0,0)
@@ -929,84 +1119,111 @@
 
         if self.count is not None and self.count < 1:
             raise ValueError("count must be > 0")
 
         if self.timeout is not None and self.timeout < 0:
             raise ValueError("timeout must be >= 0")
 
-        return super(Retry, self).__init__({self.pattern: (self.count, self.timeout, self.delay, self.backoff, self.jitter, self.initial_delay)})
+        return super(Retry, self).__init__(
+            {
+                self.pattern: (
+                    self.count,
+                    self.timeout,
+                    self.delay,
+                    self.backoff,
+                    self.jitter,
+                    self.initial_delay,
+                )
+            }
+        )
+
 
 class Args(dict):
     def __init__(self, **args):
         super(Args, self).__init__(**args)
 
     def __call__(self, func):
         for k, v in self.items():
             if not k.startswith("_"):
                 setattr(func, k, v)
         return func
 
+
 class Attributes(NamedList):
     name = "attributes"
 
     def __init__(self, *attributes):
         super(Attributes, self).__init__(*[Attribute(*a) for a in attributes])
 
+
 class Requirements(NamedList):
     name = "requirements"
 
     def __init__(self, *requirements):
         super(Requirements, self).__init__(*[Requirement(*r) for r in requirements])
 
+
 class Specifications(NamedList):
     name = "specifications"
 
     def __init__(self, *specifications):
-        super(Specifications, self).__init__(*[Specification(*r) for r in specifications])
+        super(Specifications, self).__init__(
+            *[Specification(*r) for r in specifications]
+        )
+
 
 class Tags(NamedList):
     name = "tags"
 
     def __init__(self, *tags):
         super(Tags, self).__init__(*tags)
 
+
 class Uid(NamedString):
     name = "uid"
 
+
 class Parallel(NamedValue):
     name = "parallel"
 
     def __init__(self, value):
         self.value = bool(value)
 
+
 class Executor(NamedValue):
     name = "executor"
 
     def __init__(self, executor):
         self.value = executor
 
+
 class ArgumentParser(NamedValue):
     name = "argparser"
 
     def __init__(self, parser):
         self.value = parser
 
+
 class Name(NamedString):
     name = "name"
 
+
 class Description(NamedString):
     name = "description"
 
+
 class Examples(ExamplesTable):
     def __new__(cls, header, rows, row_format=None, args=None):
-        return super(Examples, cls).__new__(cls, header=header,
-            rows=rows, row_format=row_format, args=args)
+        return super(Examples, cls).__new__(
+            cls, header=header, rows=rows, row_format=row_format, args=args
+        )
 
     def __call__(self, func):
         func.examples = self
         return func
 
+
 class Maps(NamedList):
     name = "maps"
 
     def __init__(self, *mappings):
         super(Maps, self).__init__(*mappings)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/parallel/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/parallel/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,50 +23,53 @@
 
 from .asyncio import asyncio, wrap_future, OptionalFuture
 from .asyncio import Future as AsyncFuture
 from .asyncio import is_running_in_event_loop
 from .asyncio import TimeoutError as AsyncTimeoutError
 from .asyncio import CancelledError as AsyncCancelledError
 
+
 def Context(**kwargs):
     """Convenience function to create
     a namedtuple to store parallel context variables.
     """
     return namedtuple("ParallelContext", " ".join(kwargs.keys()))(*kwargs.values())
 
+
 context = Context(
-    current=contextvars.ContextVar('_testflows_current', default=None),
-    previous=contextvars.ContextVar('_testflows_previous', default=None),
-    top=contextvars.ContextVar('_testflows_top', default=None),
-    is_valid=contextvars.ContextVar('_testflows_is_valid', default=None),
+    current=contextvars.ContextVar("_testflows_current", default=None),
+    previous=contextvars.ContextVar("_testflows_previous", default=None),
+    top=contextvars.ContextVar("_testflows_top", default=None),
+    is_valid=contextvars.ContextVar("_testflows_is_valid", default=None),
 )
 
 # set current parallel context as valid
 context.is_valid.set(True)
 
 ContextVar = contextvars.ContextVar
 copy_context = contextvars.copy_context
 
+
 def convert_result_to_concurrent_future(fn, args=None, kwargs=None):
-    """Make concurrent future out of result of a function call.
-    """
+    """Make concurrent future out of result of a function call."""
     if args is None:
         args = ()
     if kwargs is None:
         kwargs = {}
 
     future = ConcurrentFuture()
     future.set_running_or_notify_cancel()
     try:
         future.set_result(fn(*args, **kwargs))
     except BaseException as exc:
         future.set_exception(exc)
 
     return future
 
+
 def _get_parallel_context():
     """Return parallel context based on contextvars
     with all the user context variables cleared
     to None.
     """
     ctx = contextvars.copy_context()
     # clear any user context variables to None
@@ -74,45 +77,54 @@
         if not var.name.startswith("_testflows_"):
             # in Python 3.8 ContextVar can't be cleared
             # and therefore the best we can do is to set
             # user context variable to None
             var.set(None)
     return ctx
 
+
 def _check_parallel_context():
-    """Check if parallel parallel context is valid.
-    """
+    """Check if parallel parallel context is valid."""
     if not context.is_valid.get():
         raise RuntimeError("parallel context was not set")
 
+
 def top(value=None):
-    """Highest level test.
-    """
+    """Highest level test."""
     if value is not None:
         context.top.set(value)
     return context.top.get()
 
+
 def current(value=None, set_value=False):
-    """Currently executing test.
-    """
+    """Currently executing test."""
     if value is not None or set_value:
         context.current.set(value)
     return context.current.get()
 
+
 def previous(value=None):
-    """Last executed test.
-    """
+    """Last executed test."""
     if value is not None:
         context.previous.set(value)
     return context.previous.get()
 
-def join(*future, futures=None, test=None, filter=None, all=False, no_async=False, cancel_pending=False):
+
+def join(
+    *future,
+    futures=None,
+    test=None,
+    filter=None,
+    all=False,
+    no_async=False,
+    cancel_pending=False
+):
     """Wait for parallel test futures to complete.
     Returns a list of completed tests.
-    
+
     Terminates current test if any of the parallel
     tests raise an exception.
 
     If no futures specified uses test.futures().
     If test is not specified test is set to current().
 
     :param *future: one or more futures (optional)
@@ -120,15 +132,22 @@
     :param test: current test, default: current()
     :param filter: filter function, default: None
     :param all: wait and join all the tests, default: False
     :param no_async: force non async join while running in event loop
     :param cancel_pending: cancel any pending futures
     """
     if no_async is False and is_running_in_event_loop():
-        return _async_join(*future, futures=futures, test=test, filter=filter, all=all, cancel_pending=cancel_pending)
+        return _async_join(
+            *future,
+            futures=futures,
+            test=test,
+            filter=filter,
+            all=all,
+            cancel_pending=cancel_pending
+        )
 
     if test is None:
         test = current()
 
     futures = list(future) or futures or test.futures
     tests = []
     exception = None
@@ -174,18 +193,21 @@
                 futures.append(future)
             raise
 
     if exception is not None:
         raise exception
     return tests
 
-async def _async_join(*future, futures=None, test=None, filter=None, all=False, cancel_pending=False):
+
+async def _async_join(
+    *future, futures=None, test=None, filter=None, all=False, cancel_pending=False
+):
     """Wait for async parallel test futures to complete.
     Returns a list of completed tests.
-    
+
     Terminates current test if any of the parallel
     tests raise an exception.
 
     If no futures specified uses test.futures().
     If test is not specified test is set to current().
 
     :param *future: one or more futures (optional)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/parallel/asyncio.py` & `testflows.core-1.9.230627.1151633/testflows/_core/parallel/asyncio.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,71 +15,82 @@
 import sys
 import inspect
 import asyncio
 import concurrent
 
 from asyncio import *
 
+
 async def async_await(coroutine):
     r = coroutine
     while inspect.isawaitable(r):
         r = await r
     return r
 
+
 async def async_next(async_iterator):
     return await async_iterator.__anext__()
 
+
 def is_running_in_event_loop():
-    """Check if running in async event loop.
-    """
+    """Check if running in async event loop."""
     try:
         asyncio.get_running_loop()
         return True
     except RuntimeError:
         pass
     return False
 
+
 class LoopMixin:
     def __init__(self, *args, loop=None, **kwargs):
         self._loop_mixin = loop
-        if sys.version_info < (3,10,0):
+        if sys.version_info < (3, 10, 0):
             kwargs["loop"] = self._loop_mixin
         super(LoopMixin, self).__init__(*args, **kwargs)
 
     def _get_loop(self):
         if self._loop_mixin is not None:
             return self._loop_mixin
-        if sys.version_info >= (3,10,0):
+        if sys.version_info >= (3, 10, 0):
             return super(LoopMixin, self)._get_loop()
         return self._loop
 
+
 class Future(LoopMixin, asyncio.Future):
     pass
 
+
 class OptionalFuture(Future):
     """Future that will not complain about any
     exceptions not being retrieved.
     """
+
     def __del__(self):
         return
 
+
 def wrap_future(future, *, loop=None, new_future=None):
     """Wrap concurrent.futures.Future object."""
     if isfuture(future):
         return future
-    assert isinstance(future, concurrent.futures.Future), \
-        f'concurrent.futures.Future is expected, got {future!r}'
+    assert isinstance(
+        future, concurrent.futures.Future
+    ), f"concurrent.futures.Future is expected, got {future!r}"
     if loop is None:
         loop = asyncio.events.get_event_loop()
     if new_future is None:
         new_future = loop.create_future()
     asyncio.futures._chain_future(future, new_future)
     return new_future
 
+
 class Event(LoopMixin, asyncio.Event):
     pass
 
+
 class Queue(LoopMixin, asyncio.Queue):
     pass
 
+
 class Lock(LoopMixin, asyncio.Lock):
     pass
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/asyncio.py` & `testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/asyncio.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,36 +18,46 @@
 import weakref
 import itertools
 import threading
 import concurrent.futures.thread as _base
 
 from .future import Future
 from .. import _get_parallel_context
-from ..asyncio import is_running_in_event_loop, asyncio, Event as asyncio_Event, Queue as asyncio_Queue
+from ..asyncio import (
+    is_running_in_event_loop,
+    asyncio,
+    Event as asyncio_Event,
+    Queue as asyncio_Queue,
+)
 from .. import current, join as parallel_join
 
 _tasks_queues = weakref.WeakKeyDictionary()
 _shutdown = False
 
+
 def _python_exit():
     global _shutdown
     _shutdown = True
     # FIXME: debug leaked
-    #import sys
-    #import gc
-    #for k in (list(_tasks_queues.keys())):
+    # import sys
+    # import gc
+    # for k in (list(_tasks_queues.keys())):
     #    print(f"{k} {sys.getrefcount(k)} {gc.get_referrers(k)}")
     for work_queue in _tasks_queues.values():
         if work_queue._get_loop().is_running():
-            asyncio.run_coroutine_threadsafe(work_queue.put(None), loop=work_queue._get_loop())
+            asyncio.run_coroutine_threadsafe(
+                work_queue.put(None), loop=work_queue._get_loop()
+            )
     for task in _tasks_queues.keys():
         task.result()
 
+
 atexit.register(_python_exit)
 
+
 class _AsyncWorkItem(_base._WorkItem):
     async def run(self):
         if not self.future.set_running_or_notify_cancel():
             return
         try:
             result = self.fn(*self.args, **self.kwargs)
             if asyncio.iscoroutine(result):
@@ -79,74 +89,81 @@
                     await work_queue.put(None)
                     return
             finally:
                 del executor
 
 
 async def _loop_send_stop_event(stop_event):
-    """Set stop event to stop event loop.
-    """
+    """Set stop event to stop event loop."""
     stop_event.set()
 
 
 async def _loop_main(stop_event):
     """Event loop main function
     that blocks until stop event is set.
     """
     await stop_event.wait()
 
 
 def _async_loop_thread(loop, stop_event):
-    """Async loop thread.
-    """
+    """Async loop thread."""
     asyncio.set_event_loop(loop)
 
     loop.run_until_complete(_loop_main(stop_event))
 
     tasks = [task for task in asyncio.all_tasks(loop=loop)]
     for task in tasks:
         task.cancel()
 
     loop.run_until_complete(asyncio.gather(*tasks, return_exceptions=True))
     loop.close()
 
 
 class AsyncPoolExecutor(_base._base.Executor):
-    """Async pool executor.
-    """
+    """Async pool executor."""
+
     _counter = itertools.count().__next__
 
-    def __init__(self, max_workers=1024, task_name_prefix="",
-            loop=None, _check_max_workers=True, join_on_shutdown=True):
+    def __init__(
+        self,
+        max_workers=1024,
+        task_name_prefix="",
+        loop=None,
+        _check_max_workers=True,
+        join_on_shutdown=True,
+    ):
         if _check_max_workers and int(max_workers) <= 0:
             raise ValueError("max_workers must be greater than 0")
         self._open = False
         self._max_workers = max_workers
         self._loop = loop or asyncio.new_event_loop()
         self._loop_stop_event = asyncio_Event(loop=self._loop)
         self._work_queue = asyncio_Queue(loop=self._loop)
         self._tasks = set()
         self._shutdown = False
         self._shutdown_lock = threading.Lock()
-        self._task_name_prefix = (task_name_prefix or
-            ("AsyncPoolExecutor-%d" % self._counter()))
+        self._task_name_prefix = task_name_prefix or (
+            "AsyncPoolExecutor-%d" % self._counter()
+        )
         self._async_loop_thread = None
         self._uid = str(uuid.uuid1())
         self._join_on_shutdown = join_on_shutdown
 
     @property
     def open(self):
         return bool(self._open)
 
     def __enter__(self):
         with self._shutdown_lock:
             if not self._open:
-                self._async_loop_thread = threading.Thread(target=_async_loop_thread,
+                self._async_loop_thread = threading.Thread(
+                    target=_async_loop_thread,
                     kwargs={"loop": self._loop, "stop_event": self._loop_stop_event},
-                    daemon=True)
+                    daemon=True,
+                )
                 self._async_loop_thread.start()
                 self._open = True
             return self
 
     def submit(self, fn, args=None, kwargs=None, block=True):
         if args is None:
             args = ()
@@ -155,29 +172,36 @@
 
         with self._shutdown_lock:
             if not self._open:
                 raise RuntimeError("cannot schedule new futures before pool is opened")
             if self._shutdown:
                 raise RuntimeError("cannot schedule new futures after shutdown")
             if _shutdown:
-                raise RuntimeError("cannot schedule new futures after interpreter shutdown")
+                raise RuntimeError(
+                    "cannot schedule new futures after interpreter shutdown"
+                )
 
             future = Future()
             future._executor_uid = self._uid
 
             ctx = _get_parallel_context()
             args = fn, *args
             work_item = _AsyncWorkItem(future, ctx.run, args, kwargs)
 
             idle_workers = self._adjust_task_count()
 
             if (idle_workers or block) and self._max_workers > 0:
-                if is_running_in_event_loop() and asyncio.get_event_loop() is self._loop:
+                if (
+                    is_running_in_event_loop()
+                    and asyncio.get_event_loop() is self._loop
+                ):
                     raise RuntimeError("deadlock detected")
-                asyncio.run_coroutine_threadsafe(self._work_queue.put(work_item), loop=self._loop).result()
+                asyncio.run_coroutine_threadsafe(
+                    self._work_queue.put(work_item), loop=self._loop
+                ).result()
 
         if (not block and not idle_workers) or self._max_workers < 1:
             if is_running_in_event_loop() and asyncio.get_event_loop() is self._loop:
                 raise RuntimeError("deadlock detected")
             asyncio.run_coroutine_threadsafe(work_item.run(), loop=self._loop).result()
 
         return future
@@ -187,71 +211,88 @@
         Returns `True` if worker is immediately available
         to handle the work item or `False` otherwise.
         """
         if len(self._tasks) - self._work_queue._unfinished_tasks > 0:
             return True
 
         def weakref_cb(_, work_queue=self._work_queue):
-            asyncio.run_coroutine_threadsafe(work_queue.put(None), loop=self._loop).result()
+            asyncio.run_coroutine_threadsafe(
+                work_queue.put(None), loop=self._loop
+            ).result()
 
         num_tasks = len(self._tasks)
         if num_tasks < self._max_workers:
             task_name = "%s_%d" % (self._task_name_prefix or self, num_tasks)
-            task = asyncio.run_coroutine_threadsafe(_worker(weakref.ref(self, weakref_cb), self._work_queue), loop=self._loop)
+            task = asyncio.run_coroutine_threadsafe(
+                _worker(weakref.ref(self, weakref_cb), self._work_queue),
+                loop=self._loop,
+            )
             self._tasks.add(task)
             _tasks_queues[task] = self._work_queue
             return True
 
         return False
 
     def shutdown(self, wait=True, test=None):
         with self._shutdown_lock:
             if self._shutdown:
                 return
             self._shutdown = True
             if not self._loop.is_running():
                 return
             asyncio.run_coroutine_threadsafe(
-                self._work_queue.put(None), loop=self._loop).result()
+                self._work_queue.put(None), loop=self._loop
+            ).result()
 
         if wait:
             if test is None:
                 test = current()
             try:
                 if test:
                     if self._join_on_shutdown:
-                        parallel_join(no_async=True, test=test, filter=lambda future: hasattr(future, "_executor_uid") and future._executor_uid == self._uid, cancel_pending=True)
+                        parallel_join(
+                            no_async=True,
+                            test=test,
+                            filter=lambda future: hasattr(future, "_executor_uid")
+                            and future._executor_uid == self._uid,
+                            cancel_pending=True,
+                        )
             finally:
                 exc = None
                 for task in self._tasks:
                     try:
                         task.result()
                     except BaseException as e:
                         exc = e
                 try:
                     if exc is not None:
                         raise exc
                 finally:
                     asyncio.run_coroutine_threadsafe(
-                            _loop_send_stop_event(self._loop_stop_event), loop=self._loop
-                        ).result()
+                        _loop_send_stop_event(self._loop_stop_event), loop=self._loop
+                    ).result()
                     if self._async_loop_thread is not None:
                         self._async_loop_thread.join()
 
 
 class SharedAsyncPoolExecutor(AsyncPoolExecutor):
-    """Shared async pool executor.
-    """
+    """Shared async pool executor."""
+
     def __init__(self, max_workers, task_name_prefix="", join_on_shutdown=True):
         self.initargs = (max_workers, task_name_prefix, join_on_shutdown)
 
         if int(max_workers) < 0:
             raise ValueError("max_workers must be positive or 0")
         super(SharedAsyncPoolExecutor, self).__init__(
-            max_workers=max_workers-1, task_name_prefix=task_name_prefix,
-            _check_max_workers=False, join_on_shutdown=join_on_shutdown)
+            max_workers=max_workers - 1,
+            task_name_prefix=task_name_prefix,
+            _check_max_workers=False,
+            join_on_shutdown=join_on_shutdown,
+        )
 
     def submit(self, fn, args=None, kwargs=None, block=False):
-        return super(SharedAsyncPoolExecutor, self).submit(fn=fn, args=args, kwargs=kwargs, block=block)
+        return super(SharedAsyncPoolExecutor, self).submit(
+            fn=fn, args=args, kwargs=kwargs, block=block
+        )
 
 
 GlobalAsyncPoolExecutor = SharedAsyncPoolExecutor
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/future.py` & `testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/future.py`

 * *Files 10% similar despite different names*

```diff
@@ -11,19 +11,21 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # to the end flag
 from concurrent.futures import Future as _FutureBase
 
+
 class Future(_FutureBase):
     """concurrent.futures.Future that
     fixes __get_result() when exception
     implements its own custom __bool__()
     """
+
     def __get_result(self):
         if self._exception is not None:
             try:
                 raise self._exception
             finally:
                 # Break a reference cycle with the exception in self._exception
                 self = None
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/process.py` & `testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/process.py`

 * *Files 5% similar despite different names*

```diff
@@ -43,50 +43,60 @@
 from ...tracing import logging
 
 _shutdown = False
 _worker_pids = {}
 
 WORKER_READY = "_tfs_worker__ready__\n"
 
+
 class Process:
-    """Process for asyncio.subprocess_exec.
-    """
+    """Process for asyncio.subprocess_exec."""
+
     def __init__(self, transport, protocol):
         self.transport = transport
         self.protocol = protocol
 
+
 ProcessError = subprocess.SubprocessError
 
+
 def async_wait_for(aw, loop, timeout=None):
-    return asyncio.run_coroutine_threadsafe(asyncio.wait_for(aw, timeout), loop=loop).result()
+    return asyncio.run_coroutine_threadsafe(
+        asyncio.wait_for(aw, timeout), loop=loop
+    ).result()
+
 
 def is_running(pid):
     try:
         os.getpgid(pid)
     except BaseException as e:
         return False
     return True
 
+
 def _atexit():
     for pid in list(_worker_pids.keys()):
         try:
             _worker_pids.pop(pid)
             os.kill(pid, signal.SIGTERM)
         except Exception:
             pass
 
+
 atexit.register(_atexit)
 
 WorkQueue = ServiceObjectType("WorkQueue", auto_expose(queue.Queue()))
 WorkQueue.Empty = queue.Empty
 
+
 class WorkerSettings:
     """Remote service object that is used to pass settings
     to the worker process.
     """
+
     def __init__(self):
         self.debug = settings.debug
         self.time_resolution = settings.debug
         self.hash_length = settings.hash_length
         self.hash_func = settings.hash_func
         self.no_colors = settings.no_colors
         self.test_id = settings.test_id
@@ -95,57 +105,64 @@
         self.read_logfile = self._set_service_object(current().io.io.io.reader.fd)
         self.database = settings.database
         self.show_skipped = settings.show_skipped
         self.trim_results = settings.trim_results
         self.random_order = settings.random_order
         self.service_timeout = settings.service_timeout
         self.global_thread_pool = (
+            (
                 settings.global_thread_pool.__class__,
-                settings.global_thread_pool.initargs
-            ) if settings.global_thread_pool is not None else None
+                settings.global_thread_pool.initargs,
+            )
+            if settings.global_thread_pool is not None
+            else None
+        )
         self.global_async_pool = (
-                settings.global_async_pool.__class__,
-                settings.global_async_pool.initargs
-            ) if settings.global_async_pool is not None else None
-        self.global_process_pool = self._set_service_object(settings.global_process_pool)
+            (settings.global_async_pool.__class__, settings.global_async_pool.initargs)
+            if settings.global_async_pool is not None
+            else None
+        )
+        self.global_process_pool = self._set_service_object(
+            settings.global_process_pool
+        )
         self.secrets_registry = settings.secrets_registry
         self.trace = settings.trace
 
     def _set_service_object(self, obj):
         if obj is None:
             return obj
         if not isinstance(obj, BaseServiceObject):
             obj = process_service().register(obj, sync=True, awaited=False)
         return obj
 
 
 class _WorkItem(object):
-    """Work item for the remote worker.
-    """
-    def __init__(self, settings, current_test, previous_test, top_test, future, fn, args, kwargs):
+    """Work item for the remote worker."""
+
+    def __init__(
+        self, settings, current_test, previous_test, top_test, future, fn, args, kwargs
+    ):
         self.settings = settings
         self.current_test = current_test
         self.previous_test = previous_test
         self.top_test = top_test
         self.future = future
         self.fn = fn
         self.args = args
         self.kwargs = kwargs
 
     def run(self, local=False):
-        """This function will be run in worker process.
-        """
+        """This function will be run in worker process."""
         if not self.future.set_running_or_notify_cancel():
             return
 
         ctx = _get_parallel_context()
 
         def set_settings(work_settings):
-            """Set global test settings for this work item.
-            """
+            """Set global test settings for this work item."""
             settings.debug = work_settings.debug
             settings.time_resolution = work_settings.time_resolution
             settings.hash_length = work_settings.hash_length
             settings.hash_func = work_settings.hash_func
             settings.no_colors = work_settings.no_colors
             settings.test_id = work_settings.test_id
             settings.output_format = work_settings.output_format
@@ -179,66 +196,78 @@
                     previous(self.previous_test)
                     current(self.current_test)
 
                     set_settings(self.settings)
 
                     # global thread and async pool are local to each work item
                     with (settings.global_thread_pool or contextlib.nullcontext()), (
-                            settings.global_async_pool or contextlib.nullcontext()):
+                        settings.global_async_pool or contextlib.nullcontext()
+                    ):
                         result = self.fn(*self.args, **self.kwargs)
                 else:
                     result = self.fn(*self.args, **self.kwargs)
 
             except BaseException as exc:
                 if not isinstance(exc, Result):
                     exc_type, exc_value, exc_tb = sys.exc_info()
-                    exc = exc_type(str(exc_value) + "\n\nWorker Traceback (most recent call last):\n" + "".join(traceback.format_tb(exc_tb)).rstrip())
+                    exc = exc_type(
+                        str(exc_value)
+                        + "\n\nWorker Traceback (most recent call last):\n"
+                        + "".join(traceback.format_tb(exc_tb)).rstrip()
+                    )
                 self.future.set_exception(exc)
                 # Break a reference cycle with the exception 'exc'
                 self = None
 
             else:
                 try:
                     self.future.set_result(result)
                 except TypeError:
-                    self.future.set_result(process_service().register(result, sync=True, awaited=False))
+                    self.future.set_result(
+                        process_service().register(result, sync=True, awaited=False)
+                    )
 
         ctx.run(runner, self)
 
 
 class WorkerProtocol(asyncio.SubprocessProtocol):
     """Worker process protocol that set exit_future
     on process exit and logs all output on stdout
     and stderr to message_io.
     """
+
     def __init__(self, test_io, io_prefix, loop, encoding="utf-8", errors=None):
         self.decoder = codecs.getincrementaldecoder(encoding)(errors=errors)
         self.test_io = test_io
         self.io_prefix = io_prefix
         self.ready_future = asyncio_Future(loop=loop)
-        self.buffer = ''
+        self.buffer = ""
         self.transport = None
         self.stdout_io = None
         self.stderr_io = None
         self.pid = None
 
     def connection_made(self, transport):
         self.transport = transport
         self.pid = self.transport.get_pid()
-        self.stdout_io = self.test_io.message_io(f"{self.io_prefix}-worker-{self.pid}:stdout")
-        self.stderr_io = self.test_io.message_io(f"{self.io_prefix}-worker-{self.pid}:stderr")
+        self.stdout_io = self.test_io.message_io(
+            f"{self.io_prefix}-worker-{self.pid}:stdout"
+        )
+        self.stderr_io = self.test_io.message_io(
+            f"{self.io_prefix}-worker-{self.pid}:stderr"
+        )
         _worker_pids[self.pid] = True
 
     def pipe_data_received(self, fd, data):
         if fd == 1 and not self.ready_future.done() and data:
             self.buffer += self.decoder.decode(data)
             if WORKER_READY in self.buffer:
                 data = self.buffer.split(WORKER_READY, 1)[-1]
                 self.ready_future.set_result(True)
-                self.buffer = ''
+                self.buffer = ""
             else:
                 return
 
         elif data:
             data = self.decoder.decode(data)
 
         if data:
@@ -248,42 +277,54 @@
                 self.stderr_io.write(data)
 
     def process_exited(self):
         _worker_pids.pop(self.pid, None)
         if not self.ready_future.done():
             self.ready_future.set_result(True)
 
+
 class RemotePoolExecutor(_base.Executor):
     """Remote pool executor."""
+
     pass
 
+
 class ProcessPoolExecutor(RemotePoolExecutor):
-    """Process pool executor.
-    """
+    """Process pool executor."""
+
     _counter = itertools.count().__next__
 
-    def __init__(self, max_workers=16, process_name_prefix="", _check_max_workers=True, join_on_shutdown=True):
+    def __init__(
+        self,
+        max_workers=16,
+        process_name_prefix="",
+        _check_max_workers=True,
+        join_on_shutdown=True,
+    ):
         if _check_max_workers and int(max_workers) <= 0:
             raise ValueError("max_workers must be greater than 0")
         self._open = False
         self._max_workers = max_workers
         self._raw_work_queue = queue.Queue()
-        self._work_queue = process_service().register(self._raw_work_queue, sync=True, awaited=False)
+        self._work_queue = process_service().register(
+            self._raw_work_queue, sync=True, awaited=False
+        )
         self._processes = set()
         self._broken = False
         self._shutdown = False
         self._shutdown_lock = threading.Lock()
-        self._process_name_prefix = f"{process_name_prefix}ProcessPoolExecutor-{os.getpid()}-{self._counter()}"
+        self._process_name_prefix = (
+            f"{process_name_prefix}ProcessPoolExecutor-{os.getpid()}-{self._counter()}"
+        )
         self._uid = str(uuid.uuid1())
         self._join_on_shutdown = join_on_shutdown
 
     @property
     def open(self):
-        """Return if pool is opened.
-        """
+        """Return if pool is opened."""
         return bool(self._open)
 
     def __enter__(self):
         self._open = True
         return self
 
     def map(self, fn, *iterables, timeout=None, chunksize=1):
@@ -297,29 +338,39 @@
 
         with self._shutdown_lock:
             if not self._open:
                 raise RuntimeError("cannot schedule new futures before pool is opened")
             if self._shutdown:
                 raise RuntimeError("cannot schedule new futures after shutdown")
             if _shutdown:
-                raise RuntimeError("cannot schedule new futures after "
-                    "interpreter shutdown")
+                raise RuntimeError(
+                    "cannot schedule new futures after " "interpreter shutdown"
+                )
 
             service = process_service()
 
             _raw_future = Future()
             _raw_future._executor_uid = self._uid
 
             future = service.register(_raw_future, sync=True, awaited=False)
 
             current_test = service.register(current(), sync=True, awaited=False)
             previous_test = service.register(previous(), sync=True, awaited=False)
             top_test = service.register(top(), sync=True, awaited=False)
 
-            work_item = _WorkItem(WorkerSettings(), current_test, previous_test, top_test, future, fn, args, kwargs)
+            work_item = _WorkItem(
+                WorkerSettings(),
+                current_test,
+                previous_test,
+                top_test,
+                future,
+                fn,
+                args,
+                kwargs,
+            )
 
             idle_workers = self._adjust_process_count()
 
             if (idle_workers or block) and self._max_workers > 0:
                 self._raw_work_queue.put(work_item)
 
         if (not block and not idle_workers) or self._max_workers < 1:
@@ -337,42 +388,59 @@
         """
         if len(self._processes) - self._raw_work_queue.unfinished_tasks > 0:
             return True
 
         num_procs = len(self._processes)
 
         if num_procs < self._max_workers:
-            command = ["tfs-worker",
-                "--oid", str(self._work_queue.oid),
-                "--identity", str(self._work_queue.identity.hex()),
-                "--hostname", str(self._work_queue.address.hostname),
-                "--port", str(self._work_queue.address.port)
+            command = [
+                "tfs-worker",
+                "--oid",
+                str(self._work_queue.oid),
+                "--identity",
+                str(self._work_queue.identity.hex()),
+                "--hostname",
+                str(self._work_queue.address.hostname),
+                "--port",
+                str(self._work_queue.address.port),
             ]
 
             if settings.debug:
                 command.append("--debug")
             if settings.no_colors:
                 command.append("--no-colors")
             if settings.trace:
                 command.append("--trace")
                 command.append(f"{logging.getLevelName(settings.trace).lower()}")
 
             loop = process_service().loop
 
-            proc = Process(*asyncio.run_coroutine_threadsafe(
-                loop.subprocess_exec(
-                    lambda: WorkerProtocol(test_io=current(), io_prefix=self._process_name_prefix, loop=loop),
-                    *command, start_new_session=True), loop=loop).result())
+            proc = Process(
+                *asyncio.run_coroutine_threadsafe(
+                    loop.subprocess_exec(
+                        lambda: WorkerProtocol(
+                            test_io=current(),
+                            io_prefix=self._process_name_prefix,
+                            loop=loop,
+                        ),
+                        *command,
+                        start_new_session=True,
+                    ),
+                    loop=loop,
+                ).result()
+            )
 
             async_wait_for(proc.protocol.ready_future, loop=loop)
 
             returncode = proc.transport.get_returncode()
             if returncode:
-                output = textwrap.indent(proc.protocol.buffer, prefix='  ')
-                raise ProcessError(f"failed to start worker process {proc.transport.get_pid()} return code {returncode}\n{output}")
+                output = textwrap.indent(proc.protocol.buffer, prefix="  ")
+                raise ProcessError(
+                    f"failed to start worker process {proc.transport.get_pid()} return code {returncode}\n{output}"
+                )
             self._processes.add(proc)
             return True
 
         return False
 
     def shutdown(self, wait=True, test=None):
         with self._shutdown_lock:
@@ -385,32 +453,43 @@
 
         if wait:
             if test is None:
                 test = current()
             try:
                 if test:
                     if self._join_on_shutdown:
-                        parallel_join(no_async=True, test=test, filter=lambda future: hasattr(future, "_executor_uid") and future._executor_uid == self._uid, cancel_pending=True)
+                        parallel_join(
+                            no_async=True,
+                            test=test,
+                            filter=lambda future: hasattr(future, "_executor_uid")
+                            and future._executor_uid == self._uid,
+                            cancel_pending=True,
+                        )
             finally:
                 for proc in self._processes:
                     while is_running(proc.transport.get_pid()):
                         time.sleep(0.1)
                 self._processes = set()
 
 
 class SharedProcessPoolExecutor(ProcessPoolExecutor):
-    """Shared process pool executor.
-    """
+    """Shared process pool executor."""
+
     def __init__(self, max_workers, process_name_prefix="", join_on_shutdown=True):
         self.initargs = (max_workers, process_name_prefix, join_on_shutdown)
 
         if int(max_workers) < 0:
             raise ValueError("max_workers must be positive or 0")
         super(SharedProcessPoolExecutor, self).__init__(
-            max_workers=max_workers-1, process_name_prefix=process_name_prefix, _check_max_workers=False,
-            join_on_shutdown=join_on_shutdown)
+            max_workers=max_workers - 1,
+            process_name_prefix=process_name_prefix,
+            _check_max_workers=False,
+            join_on_shutdown=join_on_shutdown,
+        )
 
     def submit(self, fn, args=None, kwargs=None, block=False):
-        return super(SharedProcessPoolExecutor, self).submit(fn=fn, args=args, kwargs=kwargs, block=block)
+        return super(SharedProcessPoolExecutor, self).submit(
+            fn=fn, args=args, kwargs=kwargs, block=block
+        )
 
 
 GlobalProcessPoolExecutor = SharedProcessPoolExecutor
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/parallel/executor/thread.py` & `testflows.core-1.9.230627.1151633/testflows/_core/parallel/executor/thread.py`

 * *Files 4% similar despite different names*

```diff
@@ -22,14 +22,15 @@
 import concurrent.futures.thread as _base
 
 from .future import Future
 from .. import _get_parallel_context
 from ..asyncio import is_running_in_event_loop, wrap_future, asyncio
 from .. import current, join as parallel_join
 
+
 def _worker(executor_weakref, work_queue):
     try:
         while True:
             try:
                 work_item = work_queue.get(block=True, timeout=random.random() % 0.2)
                 try:
                     if work_item is not None:
@@ -47,38 +48,45 @@
                         if executor is not None:
                             executor._shutdown = True
                         work_queue.put(None)
                         return
                 finally:
                     del executor
     except BaseException:
-        _base._base.LOGGER.critical('Exception in thread worker', exc_info=True)
+        _base._base.LOGGER.critical("Exception in thread worker", exc_info=True)
 
 
 class ThreadPoolExecutor(_base.ThreadPoolExecutor):
-    """Thread pool executor.
-    """
-    def __init__(self, max_workers=16, thread_name_prefix="", _check_max_workers=True, join_on_shutdown=True):
+    """Thread pool executor."""
+
+    def __init__(
+        self,
+        max_workers=16,
+        thread_name_prefix="",
+        _check_max_workers=True,
+        join_on_shutdown=True,
+    ):
         if _check_max_workers and int(max_workers) <= 0:
             raise ValueError("max_workers must be greater than 0")
         self._open = False
         self._max_workers = max_workers
         self._work_queue = queue.Queue()
         self._threads = set()
         self._broken = False
         self._shutdown = False
         self._shutdown_lock = threading.Lock()
-        self._thread_name_prefix = f"{thread_name_prefix}ThreadPoolExecutor-{self._counter()}"
+        self._thread_name_prefix = (
+            f"{thread_name_prefix}ThreadPoolExecutor-{self._counter()}"
+        )
         self._uid = str(uuid.uuid1())
         self._join_on_shutdown = join_on_shutdown
 
     @property
     def open(self):
-        """Return if pool is opened.
-        """
+        """Return if pool is opened."""
         return bool(self._open)
 
     def __enter__(self):
         self._open = True
         return self
 
     def submit(self, fn, args=None, kwargs=None, block=True):
@@ -89,16 +97,17 @@
 
         with self._shutdown_lock:
             if not self._open:
                 raise RuntimeError("cannot schedule new futures before pool is opened")
             if self._shutdown:
                 raise RuntimeError("cannot schedule new futures after shutdown")
             if _base._shutdown:
-                raise RuntimeError("cannot schedule new futures after "
-                    "interpreter shutdown")
+                raise RuntimeError(
+                    "cannot schedule new futures after " "interpreter shutdown"
+                )
 
             future = Future()
             future._executor_uid = self._uid
 
             ctx = _get_parallel_context()
             args = fn, *args
             work_item = _base._WorkItem(future, ctx.run, args, kwargs)
@@ -123,17 +132,20 @@
 
         def weakref_cb(_, work_queue=self._work_queue):
             work_queue.put(None)
 
         num_threads = len(self._threads)
         if num_threads < self._max_workers:
             thread_name = "%s_%d" % (self._thread_name_prefix or self, num_threads)
-            thread = threading.Thread(name=thread_name,
-                target=_worker, args=(weakref.ref(self, weakref_cb),
-                self._work_queue), daemon=True)
+            thread = threading.Thread(
+                name=thread_name,
+                target=_worker,
+                args=(weakref.ref(self, weakref_cb), self._work_queue),
+                daemon=True,
+            )
             thread.start()
             self._threads.add(thread)
             _base._threads_queues[thread] = self._work_queue
             return True
 
         return False
 
@@ -145,30 +157,41 @@
             self._work_queue.put(None)
         if wait:
             if test is None:
                 test = current()
             try:
                 if test:
                     if self._join_on_shutdown:
-                        parallel_join(no_async=True, test=test, filter=lambda future: hasattr(future, "_executor_uid") and future._executor_uid == self._uid, cancel_pending=True)
+                        parallel_join(
+                            no_async=True,
+                            test=test,
+                            filter=lambda future: hasattr(future, "_executor_uid")
+                            and future._executor_uid == self._uid,
+                            cancel_pending=True,
+                        )
             finally:
                 for thread in self._threads:
                     thread.join()
 
 
 class SharedThreadPoolExecutor(ThreadPoolExecutor):
-    """Shared thread pool executor.
-    """
+    """Shared thread pool executor."""
+
     def __init__(self, max_workers, thread_name_prefix="", join_on_shutdown=True):
         self.initargs = (max_workers, thread_name_prefix, join_on_shutdown)
 
         if int(max_workers) < 0:
             raise ValueError("max_workers must be positive or 0")
         super(SharedThreadPoolExecutor, self).__init__(
-            max_workers=max_workers-1, thread_name_prefix=thread_name_prefix,
-            _check_max_workers=False, join_on_shutdown=join_on_shutdown)
+            max_workers=max_workers - 1,
+            thread_name_prefix=thread_name_prefix,
+            _check_max_workers=False,
+            join_on_shutdown=join_on_shutdown,
+        )
 
     def submit(self, fn, args=None, kwargs=None, block=False):
-        return super(SharedThreadPoolExecutor, self).submit(fn=fn, args=args, kwargs=kwargs, block=block)
+        return super(SharedThreadPoolExecutor, self).submit(
+            fn=fn, args=args, kwargs=kwargs, block=block
+        )
 
 
 GlobalThreadPoolExecutor = SharedThreadPoolExecutor
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/parallel/service.py` & `testflows.core-1.9.230627.1151633/testflows/_core/parallel/service.py`

 * *Files 15% similar despite different names*

```diff
@@ -27,311 +27,393 @@
 
 from collections import namedtuple
 from multiprocessing.util import Finalize, is_exiting
 
 from testflows._core.contrib import cloudpickle
 from testflows._core.contrib.aiomsg import Socket
 
-from .asyncio import asyncio, is_running_in_event_loop, OptionalFuture, CancelledError, Lock as asyncio_Lock
+from .asyncio import (
+    asyncio,
+    is_running_in_event_loop,
+    OptionalFuture,
+    CancelledError,
+    Lock as asyncio_Lock,
+)
 from .asyncio import TimeoutError as AsyncTimeoutError
 from .executor.thread import SharedThreadPoolExecutor
 
 Address = namedtuple("address", "hostname port", defaults=(None,))
 
 TimeoutError = (asyncio.exceptions.TimeoutError, concurrent.futures._base.TimeoutError)
 
 tracer = tracing.getLogger(__name__)
 
+
 class ServiceError(Exception):
-    """Service error.
-    """
+    """Service error."""
+
     pass
 
 
 class ServiceNotRunningError(ServiceError):
-    """Service not running error.
-    """
+    """Service not running error."""
+
     pass
 
 
 class ServiceObjectNotFoundError(ServiceError):
-    """Service object not found error.
-    """
+    """Service object not found error."""
+
     pass
 
 
 class Service:
     """Remote object service that provides remote
     access to local objects and connects to other
     remote services to access their remote objects.
 
     :param name: name of the service
     :param address: (optional) address of the server, default: (ip_address_of_the_host, 0)
     :param loop: (optional) event loop ,default: None
     """
+
     class MsgTypes:
-        """Service protocol message types.
-        """
-        REPLY_RESULT = b'0'
-        REPLY_EXCEPTION = b'1'
-        REQUEST = b'2'
+        """Service protocol message types."""
 
+        REPLY_RESULT = b"0"
+        REPLY_EXCEPTION = b"1"
+        REQUEST = b"2"
 
     class ObjectItem:
-        """Service object item.
-        """
+        """Service object item."""
+
         def __init__(self, obj, refcount=0):
             self.obj = obj
             self.refcount = refcount
 
     def __init__(self, name, address=None, loop=None):
-        """Initialize process service.
-        """
+        """Initialize process service."""
         self.name = name
         self.loop = loop or asyncio.get_running_loop()
         self.in_socket = Socket(loop=self.loop)
         self.out_socket = Socket(loop=self.loop)
-        self.address = address if address is not None else Address(socket.gethostbyname(socket.gethostname()), 0)
+        self.address = (
+            address
+            if address is not None
+            else Address(socket.gethostbyname(socket.gethostname()), 0)
+        )
         self.identity = self.in_socket.identity
         self.serve_tasks = []
         self.reply_futures = {}
         self.objects = {}
         self.executor = SharedThreadPoolExecutor(sys.maxsize, join_on_shutdown=False)
         self.open = False
         self.lock = asyncio_Lock(loop=self.loop)
         self.init_tracer = tracing.EventAdapter(tracer, None, source=str(self))
         self.tracer = tracing.EventAdapter(tracer, None, source=str(self))
 
     def __str__(self):
         return f"Service(pid={os.getpid()},name={self.name},identity={self.identity.hex()},address={self.address},in_socket={self.in_socket},out_socket={self.out_socket})@0x{id(self):x}"
 
     def register(self, obj, sync=None, expose=None, awaited=True):
-        """Register object with the service to be by remote services.
-        """
-        event_tracer = tracing.EventAdapter(self.tracer, name=f"register({obj},sync={sync},expose={expose},awaited={awaited}")
-        event_tracer.debug("registration started", extra={"event_action":tracing.Action.START})
+        """Register object with the service to be by remote services."""
+        event_tracer = tracing.EventAdapter(
+            self.tracer,
+            name=f"register({obj},sync={sync},expose={expose},awaited={awaited}",
+        )
+        event_tracer.debug(
+            "registration started", extra={"event_action": tracing.Action.START}
+        )
 
         if isinstance(obj, BaseServiceObject):
             raise ValueError(f"registering service objects not allowed")
 
         try:
             loop = asyncio.get_running_loop()
         except RuntimeError:
             loop = None
 
-        def _register(sync: bool=False):
+        def _register(sync: bool = False):
             if not self.open:
                 raise ServiceNotRunningError("service is not running")
 
             _id = id(obj)
 
             if _id not in self.objects:
                 self.objects[_id] = Service.ObjectItem(obj)
 
             try:
                 if sync:
-                    return ServiceObject(obj, identity=self.identity, address=self.address, expose=expose)
-                return AsyncServiceObject(obj, identity=self.identity, address=self.address, expose=expose)
+                    return ServiceObject(
+                        obj, identity=self.identity, address=self.address, expose=expose
+                    )
+                return AsyncServiceObject(
+                    obj, identity=self.identity, address=self.address, expose=expose
+                )
             finally:
-                event_tracer.debug("registration complete", extra={"event_action": tracing.Action.END})
+                event_tracer.debug(
+                    "registration complete", extra={"event_action": tracing.Action.END}
+                )
 
-        async def _async_register(sync: bool=False):
+        async def _async_register(sync: bool = False):
             return _register(sync=sync)
 
         if loop is self.loop and not awaited:
             return _register(sync=sync)
 
         if loop is None or not awaited:
-            return asyncio.run_coroutine_threadsafe(_async_register(sync=True), loop=self.loop).result()
+            return asyncio.run_coroutine_threadsafe(
+                _async_register(sync=True), loop=self.loop
+            ).result()
         elif loop is not self.loop:
-            return asyncio.wrap_future(asyncio.run_coroutine_threadsafe(_async_register(sync=sync), loop=self.loop))
+            return asyncio.wrap_future(
+                asyncio.run_coroutine_threadsafe(
+                    _async_register(sync=sync), loop=self.loop
+                )
+            )
         else:
             return _async_register(sync=sync)
 
     async def unregister(self, obj):
         """Unregister object from the service to stop
         providing object to remote services.
         """
-        event_tracer = tracing.EventAdapter(self.tracer, name=f"unregister({obj}@0x{id(self):x})")
-        event_tracer.debug("unregistration started", extra={"event_action":tracing.Action.START})
+        event_tracer = tracing.EventAdapter(
+            self.tracer, name=f"unregister({obj}@0x{id(self):x})"
+        )
+        event_tracer.debug(
+            "unregistration started", extra={"event_action": tracing.Action.START}
+        )
 
         try:
             loop = asyncio.get_running_loop()
         except RuntimeError:
             loop = None
 
         async def _async_unregister():
             _id = id(obj)
 
             if _id in self.objects:
                 del self.objects[_id]
 
-            event_tracer.debug("unregistration complete", extra={"event_action":tracing.Action.END})
+            event_tracer.debug(
+                "unregistration complete", extra={"event_action": tracing.Action.END}
+            )
 
         if loop is None:
-            return asyncio.run_coroutine_threadsafe(_async_unregister(), loop=self.loop).result()
+            return asyncio.run_coroutine_threadsafe(
+                _async_unregister(), loop=self.loop
+            ).result()
         elif loop is not self.loop:
-            return asyncio.wrap_future(asyncio.run_coroutine_threadsafe(_async_unregister(), loop=self.loop))
+            return asyncio.wrap_future(
+                asyncio.run_coroutine_threadsafe(_async_unregister(), loop=self.loop)
+            )
         else:
             return _async_unregister()
 
     async def _connect(self, rid, identity, address, timeout=None):
         """Connect to the remote service that provides
         access to the remote object.
         """
-        event_tracer = tracing.EventAdapter(self.tracer, name=f"_connect(rid={rid},identity={identity.hex()},address={address})")
+        event_tracer = tracing.EventAdapter(
+            self.tracer,
+            name=f"_connect(rid={rid},identity={identity.hex()},address={address})",
+        )
         event_tracer.debug("connecting", extra={"event_action": tracing.Action.START})
 
         try:
+
             async def local_send(rid, oid, fn, args, kwargs, reply=True, timeout=None):
-                """Send service object request to the local service.
-                """
+                """Send service object request to the local service."""
                 try:
-                    with tracing.Event(event_tracer,
-                                    name=f"local_send(oid=0x{oid:x},fn={fn},args={args},kwargs={kwargs},"
-                                        f"reply={reply},timeout={timeout})") as local_send_tracer:
+                    with tracing.Event(
+                        event_tracer,
+                        name=f"local_send(oid=0x{oid:x},fn={fn},args={args},kwargs={kwargs},"
+                        f"reply={reply},timeout={timeout})",
+                    ) as local_send_tracer:
                         try:
                             msg_type, msg_body = await self._exec(oid, fn, args, kwargs)
 
                             if reply:
                                 future = OptionalFuture()
                                 future.set_result((msg_type, msg_body))
                                 return future
                         except BaseException as exc:
                             raise
                         else:
                             local_send_tracer.debug("reply={msg_body}")
                 finally:
-                    event_tracer.debug(f"complete", extra={"event_action": tracing.Action.END})
+                    event_tracer.debug(
+                        f"complete", extra={"event_action": tracing.Action.END}
+                    )
 
             async def send(rid, oid, fn, args, kwargs, reply=True, timeout=None):
-                """Send service object request to remote service.
-                """
+                """Send service object request to remote service."""
                 try:
-                    with tracing.Event(event_tracer,
-                                       name=f"send(oid=0x{oid:x},fn={fn},args={args},kwargs={kwargs},"
-                                        f"reply={reply},timeout={timeout})") as send_tracer:
+                    with tracing.Event(
+                        event_tracer,
+                        name=f"send(oid=0x{oid:x},fn={fn},args={args},kwargs={kwargs},"
+                        f"reply={reply},timeout={timeout})",
+                    ) as send_tracer:
                         try:
                             try:
-                                await asyncio.wait_for(self.out_socket.send_pickle(
-                                        obj=(self.MsgTypes.REQUEST, rid, (oid, fn, args, kwargs)),
-                                        identity=identity
-                                    ), timeout=timeout)
+                                await asyncio.wait_for(
+                                    self.out_socket.send_pickle(
+                                        obj=(
+                                            self.MsgTypes.REQUEST,
+                                            rid,
+                                            (oid, fn, args, kwargs),
+                                        ),
+                                        identity=identity,
+                                    ),
+                                    timeout=timeout,
+                                )
                                 send_tracer.debug("sent request")
                             except TypeError:
-                                send_tracer.debug("failed to send due to TypeError, creating service objects for args")
+                                send_tracer.debug(
+                                    "failed to send due to TypeError, creating service objects for args"
+                                )
                                 # convert any unpicklable objects to service objects
                                 pickler = self.out_socket.pickler
 
                                 args = list(args)
                                 for i in range(len(args)):
                                     arg = args[i]
                                     try:
                                         pickler.dumps(arg)
                                     except TypeError:
-                                        send_tracer.debug(f"registering {arg}, sync=True")
+                                        send_tracer.debug(
+                                            f"registering {arg}, sync=True"
+                                        )
                                         args[i] = await self.register(arg, sync=True)
 
                                 for k in kwargs:
                                     arg = kwargs[k]
                                     try:
                                         pickler.dumps(arg)
                                     except TypeError:
-                                        send_tracer.debug(f"registering {arg}, sync=True")
+                                        send_tracer.debug(
+                                            f"registering {arg}, sync=True"
+                                        )
                                         kwargs[k] = await self.register(arg, sync=True)
 
-                                send_tracer.debug("trying again to send after TypeError")
-                                await asyncio.wait_for(self.out_socket.send_pickle(
-                                        obj=(self.MsgTypes.REQUEST, rid, (oid, fn, args, kwargs)),
-                                        identity=identity
-                                    ), timeout=timeout)
+                                send_tracer.debug(
+                                    "trying again to send after TypeError"
+                                )
+                                await asyncio.wait_for(
+                                    self.out_socket.send_pickle(
+                                        obj=(
+                                            self.MsgTypes.REQUEST,
+                                            rid,
+                                            (oid, fn, args, kwargs),
+                                        ),
+                                        identity=identity,
+                                    ),
+                                    timeout=timeout,
+                                )
                                 send_tracer.debug("sent request after TypeError")
 
                             if reply:
                                 future = OptionalFuture()
                                 self.reply_futures[rid] = future
                                 send_tracer.debug(f"returning reply future")
                                 return future
                             else:
                                 event_tracer.debug(f"send without reply complete")
 
                         except BaseException as exc:
                             raise
                 finally:
-                    event_tracer.debug("complete", extra={"event_action": tracing.Action.END})
+                    event_tracer.debug(
+                        "complete", extra={"event_action": tracing.Action.END}
+                    )
 
             if not self.open:
                 raise ServiceNotRunningError("service is not running")
 
             if address == self.address:
                 event_tracer.debug("using local_send")
                 return local_send
 
             async with self.lock:
                 event_tracer.debug("got service lock")
                 if not identity in self.out_socket._connections:
-                    event_tracer.debug(f"connecting to identity={identity.hex()},address={address}")
+                    event_tracer.debug(
+                        f"connecting to identity={identity.hex()},address={address}"
+                    )
                     future = OptionalFuture()
 
                     await self.out_socket.connect(
                         address.hostname,
                         address.port,
                         future=future,
                         expected_identity=identity,
-                        reconnection_delay=Socket.exponential_backoff(min_delay=0.1, max_delay=2),
+                        reconnection_delay=Socket.exponential_backoff(
+                            min_delay=0.1, max_delay=2
+                        ),
                         timeout=timeout,
-                        permanent=False
-                        )
+                        permanent=False,
+                    )
 
                     event_tracer.debug("wating for connection")
                     await asyncio.wait_for(future, timeout=timeout)
                     event_tracer.debug("got connection")
 
                     if not identity in self.out_socket._connections:
-                        raise RuntimeError(f"connecting to address={address} didn't result in connection to identity={identity.hex()}")
+                        raise RuntimeError(
+                            f"connecting to address={address} didn't result in connection to identity={identity.hex()}"
+                        )
 
             event_tracer.debug("using non-local send")
             return send
 
         except BaseException as exc:
             event_tracer.exception(exc, extra={"event_action": tracing.Action.END})
             raise
 
     def __enter__(self):
-        """Sync context manager enter.
-        """
-        self.init_tracer.debug("__enter__", extra={"event_action": tracing.Action.START})
-        return asyncio.run_coroutine_threadsafe(self.__aenter__(), loop=self.loop).result()
+        """Sync context manager enter."""
+        self.init_tracer.debug(
+            "__enter__", extra={"event_action": tracing.Action.START}
+        )
+        return asyncio.run_coroutine_threadsafe(
+            self.__aenter__(), loop=self.loop
+        ).result()
 
     def __exit__(self, exc_type, exc_value, exc_tb):
-        """Sync context manager exit.
-        """
+        """Sync context manager exit."""
         try:
-            return asyncio.run_coroutine_threadsafe(self.__aexit__(exc_type, exc_value, exc_tb), loop=self.loop).result()
+            return asyncio.run_coroutine_threadsafe(
+                self.__aexit__(exc_type, exc_value, exc_tb), loop=self.loop
+            ).result()
         finally:
-            self.init_tracer.debug("__exit__", extra={"event_action": tracing.Action.END})
+            self.init_tracer.debug(
+                "__exit__", extra={"event_action": tracing.Action.END}
+            )
 
     async def __aenter__(self):
-        """Async context manager enter.
-        """
+        """Async context manager enter."""
         with tracing.Event(self.init_tracer, name="__aenter__") as event_tracer:
             async with self.lock:
                 event_tracer.debug("got lock")
                 self.executor.__enter__()
-                await self.in_socket.bind(hostname=self.address.hostname, port=self.address.port)
+                await self.in_socket.bind(
+                    hostname=self.address.hostname, port=self.address.port
+                )
                 self.address = Address(*self.in_socket.bind_address)
                 self.tracer = tracing.EventAdapter(tracer, None, source=str(self))
                 self.loop.create_task(self._serve_forever())
                 self.open = True
                 return self
 
     async def __aexit__(self, exc_type, exc_value, exc_tb):
-        """Async context manager exit.
-        """
-        self.init_tracer.info(f"closing {self} with sockets {self.out_socket} and {self.in_socket}")
+        """Async context manager exit."""
+        self.init_tracer.info(
+            f"closing {self} with sockets {self.out_socket} and {self.in_socket}"
+        )
 
         with tracing.Event(self.init_tracer, name="__aexit__") as event_tracer:
             async with self.lock:
                 event_tracer.debug("got lock")
                 try:
                     self.objects = {}
 
@@ -346,51 +428,57 @@
                             await self.in_socket.close()
                     finally:
                         self.executor.__exit__(None, None, None)
                 finally:
                     self.open = False
 
     def __incref__(self, oid, obj_item=None):
-        """Increment object reference count.
-        """
-        with tracing.Event(self.tracer, f"__incref__(oid=0x{oid:x},obj_item={obj_item})") as event_tracer:
+        """Increment object reference count."""
+        with tracing.Event(
+            self.tracer, f"__incref__(oid=0x{oid:x},obj_item={obj_item})"
+        ) as event_tracer:
             if not obj_item:
                 try:
                     obj_item = self.objects[oid]
                 except KeyError:
                     raise ServiceObjectNotFoundError(f"0x{oid}x not found")
 
             obj_item.refcount += 1
             event_tracer.debug(f"new refcount {obj_item.refcount}")
 
     def __decref__(self, oid, obj_item=None):
-        """Decrement object reference count.
-        """
-        with tracing.Event(self.tracer, f"__decref__(oid=0x{oid:x},obj_item={obj_item})") as event_tracer:
+        """Decrement object reference count."""
+        with tracing.Event(
+            self.tracer, f"__decref__(oid=0x{oid:x},obj_item={obj_item})"
+        ) as event_tracer:
             if not obj_item:
                 try:
                     obj_item = self.objects[oid]
                 except KeyError:
                     raise ServiceObjectNotFoundError(f"0x{oid:x} not found")
 
             if obj_item.refcount < 0:
-                raise ValueError(f"0x{oid:x} for {obj_item.obj} has invalid refcount {obj_item.refcount}")
+                raise ValueError(
+                    f"0x{oid:x} for {obj_item.obj} has invalid refcount {obj_item.refcount}"
+                )
             obj_item.refcount -= 1
 
             event_tracer.debug(f"new refcount {obj_item.refcount}")
 
             if obj_item.refcount <= 0:
                 del self.objects[oid]
                 event_tracer.debug(f"deleted")
 
     async def _exec(self, oid, fn, args, kwargs):
         """Execute fn request on a service object specified
         by the object id.
         """
-        with tracing.Event(self.tracer, f"_exec(oid=0x{oid:x},fn={fn},args={args},kwargs={kwargs})") as event_tracer:
+        with tracing.Event(
+            self.tracer, f"_exec(oid=0x{oid:x},fn={fn},args={args},kwargs={kwargs})"
+        ) as event_tracer:
             msg_type = self.MsgTypes.REPLY_RESULT
 
             try:
                 try:
                     obj_item = self.objects[oid]
                 except KeyError:
                     raise ServiceObjectNotFoundError(f"0x{oid:x} not found")
@@ -413,96 +501,114 @@
                 elif fn == "__incref__":
                     with tracing.Event(event_tracer, f"__incref__"):
                         r = self.__incref__(oid, obj_item)
                 elif fn == "__decref__":
                     with tracing.Event(event_tracer, f"__decref__"):
                         r = self.__decref__(oid, obj_item)
                 else:
-                    with tracing.Event(event_tracer, f"run_in_executor({self.executor})"):
+                    with tracing.Event(
+                        event_tracer, f"run_in_executor({self.executor})"
+                    ):
                         r = await self.loop.run_in_executor(self.executor, r)
 
                 if asyncio.iscoroutine(r):
                     with tracing.Event(event_tracer, "result is coroutine"):
                         r = await r
 
             except BaseException as e:
                 event_tracer.exception("executed, got exception={e}")
                 msg_type = self.MsgTypes.REPLY_EXCEPTION
                 exc_type, exc_value, exc_tb = sys.exc_info()
-                r = exc_type(str(exc_value) + "\n\nService Traceback (most recent call last):\n" + "".join(traceback.format_tb(exc_tb)).rstrip())
+                r = exc_type(
+                    str(exc_value)
+                    + "\n\nService Traceback (most recent call last):\n"
+                    + "".join(traceback.format_tb(exc_tb)).rstrip()
+                )
 
             event_tracer.debug(f"executed, result={r}")
             return msg_type, r
 
     async def _process_message(self, identity, message):
-        """Process received message.
-        """
-        with tracing.Event(self.tracer, f"_process_message(identity={identity.hex()}),message={message}") as event_tracer:
+        """Process received message."""
+        with tracing.Event(
+            self.tracer,
+            f"_process_message(identity={identity.hex()}),message={message}",
+        ) as event_tracer:
             msg_type, rid, msg_body = cloudpickle.loads(message)
 
             if msg_type == self.MsgTypes.REQUEST:
                 # process request
                 oid, fn, args, kwargs = msg_body
-                with tracing.Event(event_tracer, f"request:rid={rid},oid=0x{oid:x},fn={fn},args={args},kwargs={kwargs}"):
+                with tracing.Event(
+                    event_tracer,
+                    f"request:rid={rid},oid=0x{oid:x},fn={fn},args={args},kwargs={kwargs}",
+                ):
                     msg_type, r = await self._exec(oid, fn, args, kwargs)
                     try:
-                        await self.in_socket.send_pickle((msg_type, rid, r), identity=identity)
+                        await self.in_socket.send_pickle(
+                            (msg_type, rid, r), identity=identity
+                        )
                     except TypeError as e:
                         _r = await self.register(r, sync=True)
-                        await self.in_socket.send_pickle((msg_type, rid, _r), identity=identity)
+                        await self.in_socket.send_pickle(
+                            (msg_type, rid, _r), identity=identity
+                        )
             else:
                 with tracing.Event(event_tracer, f"reply:rid={rid},message={msg_body}"):
                     # process reply
                     reply_future = self.reply_futures.pop(rid)
                     if not reply_future.cancelled():
                         reply_future.set_result((msg_type, msg_body))
 
     async def _serve_forever(self):
-        """Start service until coroutine is cancelled.
-        """
+        """Start service until coroutine is cancelled."""
         with tracing.Event(self.tracer, "_serve_forever") as event_tracer:
+
             async def _serve_requests():
                 with tracing.Event(event_tracer, "_serve_requests") as requests_tracer:
                     while True:
                         try:
                             requests_tracer.debug("waiting for request")
-                            identity, message = await asyncio.wait_for(self.in_socket.recv_identity(), timeout=1)
+                            identity, message = await asyncio.wait_for(
+                                self.in_socket.recv_identity(), timeout=1
+                            )
                         except AsyncTimeoutError:
                             continue
-                        self.in_socket.loop.create_task(self._process_message(identity, message))
+                        self.in_socket.loop.create_task(
+                            self._process_message(identity, message)
+                        )
 
             async def _serve_replies():
                 with tracing.Event(event_tracer, "_serve_replies") as replies_tracer:
                     while True:
                         try:
                             replies_tracer.debug("waiting for replies")
-                            identity, message = await asyncio.wait_for(self.out_socket.recv_identity(), timeout=1)
+                            identity, message = await asyncio.wait_for(
+                                self.out_socket.recv_identity(), timeout=1
+                            )
                         except AsyncTimeoutError:
                             continue
-                        self.out_socket.loop.create_task(self._process_message(identity, message))
+                        self.out_socket.loop.create_task(
+                            self._process_message(identity, message)
+                        )
 
-            self.serve_tasks.append(
-                    self.in_socket.loop.create_task(_serve_requests())
-                )
+            self.serve_tasks.append(self.in_socket.loop.create_task(_serve_requests()))
             event_tracer.debug("created _serve_requests task")
 
-            self.serve_tasks.append(
-                    self.out_socket.loop.create_task(_serve_replies())
-                )
+            self.serve_tasks.append(self.out_socket.loop.create_task(_serve_replies()))
             event_tracer.debug("created _serve_replies task")
 
 
 # global process wide service
 _process_service = None
 _process_service_lock = threading.Lock()
 
 
 def process_service(**kwargs):
-    """Get or create global process wide object service.
-    """
+    """Get or create global process wide object service."""
     global _process_service
 
     with _process_service_lock:
         if _process_service is None:
             loop = kwargs.pop("loop", None)
 
             if loop is None:
@@ -513,15 +619,17 @@
                     try:
                         loop.run_forever()
                     finally:
                         tasks = [task for task in asyncio.all_tasks(loop=loop)]
                         for task in tasks:
                             task.cancel()
                         try:
-                            loop.run_until_complete(asyncio.gather(*tasks, return_exceptions=True))
+                            loop.run_until_complete(
+                                asyncio.gather(*tasks, return_exceptions=True)
+                            )
                             loop.run_until_complete(loop.shutdown_asyncgens())
                         finally:
                             loop.close()
 
                 thread = threading.Thread(target=run_event_loop, daemon=True)
 
                 def stop_event_loop():
@@ -537,16 +645,15 @@
             _process_service = Service(**kwargs).__enter__()
             atexit.register(_stop_process_service)
 
     return _process_service
 
 
 def _stop_process_service():
-    """Stop global process service.
-    """
+    """Stop global process service."""
     with tracing.Event(tracer, "_stop_process_service") as event_tracer:
         global _process_service
 
         with _process_service_lock:
             event_tracer.debug("got lock")
             if _process_service is not None:
                 _process_service.__exit__(None, None, None)
@@ -555,266 +662,381 @@
 
 class BaseServiceObject:
     """Base class for all service objects.
 
     :param oid: object id
     :param address: address `tuple(hostname, port)`
     """
+
     _exposed = None
     _typename = None
 
     def __init__(self, oid, identity, address, _incref=True):
-        """Initialize service object.
-        """
+        """Initialize service object."""
         self.oid = oid
         self.identity = identity
         self.address = address
         self._tracer = tracing.EventAdapter(tracer, None, source=str(self))
 
         if _incref:
             # increment service object reference count
             self._incref()
         # cleanup object by decrementing reference count
         # when no longer in use
         self._cleanup = Finalize(
-            self, self._decref, args=(self.oid, self.address, self.identity), kwargs={"_tracer": self._tracer},
-            exitpriority=1
-            )
+            self,
+            self._decref,
+            args=(self.oid, self.address, self.identity),
+            kwargs={"_tracer": self._tracer},
+            exitpriority=1,
+        )
 
     def __str__(self):
         return f"{self.__class__.__name__}(oid=0x{self.oid:x},identity={self.identity.hex()},address={self.address})@0x{id(self):x}"
 
     def __repr__(self):
         return str(self)
 
     def _incref(self):
-        """Increment service object reference count.
-        """
+        """Increment service object reference count."""
         oid = self.oid
         address = self.address
         identity = self.identity
 
         with tracing.Event(self._tracer, "_incref"):
             if is_running_in_event_loop():
                 if _process_service:
                     if _process_service.loop is asyncio.get_running_loop():
-                        if  _process_service.address == address:
+                        if _process_service.address == address:
                             _process_service.__incref__(oid)
                         else:
-                            _process_service.loop.create_task(self.__async_proxy_call__(oid, address, identity, "__incref__", _tracer=self._tracer))
+                            _process_service.loop.create_task(
+                                self.__async_proxy_call__(
+                                    oid,
+                                    address,
+                                    identity,
+                                    "__incref__",
+                                    _tracer=self._tracer,
+                                )
+                            )
                         return
 
-            self.__proxy_call__(oid, address, identity, "__incref__", _tracer=self._tracer)
+            self.__proxy_call__(
+                oid, address, identity, "__incref__", _tracer=self._tracer
+            )
 
     @classmethod
-    def _decref(cls, oid, address, identity, _timeout_err={}, _service_not_running_err=[False], _tracer=tracer):
-        """Decrement service object reference count.
-        """
+    def _decref(
+        cls,
+        oid,
+        address,
+        identity,
+        _timeout_err={},
+        _service_not_running_err=[False],
+        _tracer=tracer,
+    ):
+        """Decrement service object reference count."""
         if is_exiting():
             return
 
         with tracing.Event(_tracer, "_decref"):
             if _service_not_running_err[0]:
                 return
 
             if _timeout_err.get(address):
                 return
 
             try:
                 if is_running_in_event_loop():
+
                     async def no_errors(aws):
                         try:
                             await aws
-                        except (ServiceNotRunningError, ServiceObjectNotFoundError, CancelledError):
+                        except (
+                            ServiceNotRunningError,
+                            ServiceObjectNotFoundError,
+                            CancelledError,
+                        ):
                             pass
 
                     if _process_service:
                         if _process_service.loop is asyncio.get_running_loop():
                             if _process_service.address == address:
                                 _process_service.__decref__(oid)
                             else:
-                                _process_service.loop.create_task(no_errors(cls.__async_proxy_call__(oid, address, identity, "__decref__", _tracer=_tracer)))
+                                _process_service.loop.create_task(
+                                    no_errors(
+                                        cls.__async_proxy_call__(
+                                            oid,
+                                            address,
+                                            identity,
+                                            "__decref__",
+                                            _tracer=_tracer,
+                                        )
+                                    )
+                                )
                             return
 
-                cls.__proxy_call__(oid, address, identity, "__decref__", timeout=settings.service_timeout, _tracer=_tracer)
+                cls.__proxy_call__(
+                    oid,
+                    address,
+                    identity,
+                    "__decref__",
+                    timeout=settings.service_timeout,
+                    _tracer=_tracer,
+                )
 
             except TimeoutError:
                 _timeout_err[address] = True
 
             except ServiceNotRunningError:
                 _service_not_running_err[0] = True
 
             except (ServiceObjectNotFoundError, CancelledError):
                 pass
 
     def __eq__(self, other: object) -> bool:
-        """Compare to service objects.
-        """
+        """Compare to service objects."""
         return other.oid == self.oid and other.address == self.address
 
     @classmethod
-    async def __async_proxy_call__(cls, oid, address, identity, fn, args=None, kwargs=None, timeout=None, rid=None, _tracer=tracer):
-        """Execute function call on the remote service.
-        """
+    async def __async_proxy_call__(
+        cls,
+        oid,
+        address,
+        identity,
+        fn,
+        args=None,
+        kwargs=None,
+        timeout=None,
+        rid=None,
+        _tracer=tracer,
+    ):
+        """Execute function call on the remote service."""
         if rid is None:
             rid = uuid.uuid1().hex
 
-        with tracing.Event(_tracer, f"__async_proxy_call__(rid={rid},oid=0x{oid:x},identity={identity.hex()}"
-                                    f",address={address},fn={fn},args={args},kwargs={kwargs},timeout={timeout})"):
+        with tracing.Event(
+            _tracer,
+            f"__async_proxy_call__(rid={rid},oid=0x{oid:x},identity={identity.hex()}"
+            f",address={address},fn={fn},args={args},kwargs={kwargs},timeout={timeout})",
+        ):
             if args is None:
                 args = tuple()
             if kwargs is None:
                 kwargs = dict()
 
             try:
+
                 async def wrap(c):
-                    """Wrap coroutine that is running in another event loop.
-                    """
+                    """Wrap coroutine that is running in another event loop."""
                     if asyncio.coroutines.iscoroutine(c):
                         if asyncio.get_event_loop() is not _process_service.loop:
-                            return await asyncio.wrap_future(asyncio.run_coroutine_threadsafe(c, loop=_process_service.loop))
+                            return await asyncio.wrap_future(
+                                asyncio.run_coroutine_threadsafe(
+                                    c, loop=_process_service.loop
+                                )
+                            )
                     return await c
 
                 send = await wrap(_process_service._connect(rid, identity, address))
-                reply = await wrap(send(rid, oid, fn, args, kwargs, reply=True, timeout=timeout))
+                reply = await wrap(
+                    send(rid, oid, fn, args, kwargs, reply=True, timeout=timeout)
+                )
 
-                reply_type, reply_body = await asyncio.wait_for(wrap(reply), timeout=timeout)
+                reply_type, reply_body = await asyncio.wait_for(
+                    wrap(reply), timeout=timeout
+                )
 
                 if reply_type == Service.MsgTypes.REPLY_EXCEPTION:
                     if isinstance(reply_body, (SystemExit, KeyboardInterrupt)):
-                        reply_body = RuntimeError(f"{reply_body.__class__}: {reply_body}")
+                        reply_body = RuntimeError(
+                            f"{reply_body.__class__}: {reply_body}"
+                        )
                     raise reply_body
             except AttributeError:
                 if _process_service is None:
                     raise ServiceNotRunningError("service has not been started")
                 raise
 
             return reply_body
 
     @classmethod
-    def __proxy_call__(cls, oid, address, identity, fn, args=None, kwargs=None, timeout=None, rid=None, _tracer=tracer):
-        """Synchronously execute function call on the remote service.
-        """
+    def __proxy_call__(
+        cls,
+        oid,
+        address,
+        identity,
+        fn,
+        args=None,
+        kwargs=None,
+        timeout=None,
+        rid=None,
+        _tracer=tracer,
+    ):
+        """Synchronously execute function call on the remote service."""
         if rid is None:
             rid = uuid.uuid1().hex
 
-        with tracing.Event(_tracer, f"__proxy_call__(rid={rid},oid=0x{oid:x},identity={identity.hex()},"
-                                    f"address={address},fn={fn},args={args},kwargs={kwargs},timeout={timeout})"):
+        with tracing.Event(
+            _tracer,
+            f"__proxy_call__(rid={rid},oid=0x{oid:x},identity={identity.hex()},"
+            f"address={address},fn={fn},args={args},kwargs={kwargs},timeout={timeout})",
+        ):
             try:
-                c = cls.__async_proxy_call__(oid, address, identity, fn, args, kwargs, timeout=timeout, rid=rid, _tracer=_tracer)
+                c = cls.__async_proxy_call__(
+                    oid,
+                    address,
+                    identity,
+                    fn,
+                    args,
+                    kwargs,
+                    timeout=timeout,
+                    rid=rid,
+                    _tracer=_tracer,
+                )
                 try:
-                    return asyncio.run_coroutine_threadsafe(c, loop=_process_service.loop).result()
+                    return asyncio.run_coroutine_threadsafe(
+                        c, loop=_process_service.loop
+                    ).result()
                 finally:
                     c.close()
             except AttributeError:
                 if _process_service is None:
                     raise ServiceNotRunningError("service has not been started")
                 raise
 
     def __reduce__(self):
-        """Make service object serializable.
-        """
+        """Make service object serializable."""
         self._incref()
-        return (RebuildServiceObject, (self._typename, self._exposed, self.oid, self.identity, self.address, False))
+        return (
+            RebuildServiceObject,
+            (
+                self._typename,
+                self._exposed,
+                self.oid,
+                self.identity,
+                self.address,
+                False,
+            ),
+        )
 
 
 class AsyncBaseServiceObject(BaseServiceObject):
-    """Async base service object.
-    """
+    """Async base service object."""
+
     def __reduce__(self):
-        """Make service object serializable.
-        """
+        """Make service object serializable."""
         self._incref()
-        return (RebuildAsyncServiceObject, (self._typename, self._exposed, self.oid, self.identity, self.address, False))
+        return (
+            RebuildAsyncServiceObject,
+            (
+                self._typename,
+                self._exposed,
+                self.oid,
+                self.identity,
+                self.address,
+                False,
+            ),
+        )
 
 
 def RebuildServiceObject(typename, exposed, oid, identity, address, _incref=True):
-    """Rebuild service object during unpickling.
-    """
-    return ServiceObjectType(typename, exposed)(oid=oid, identity=identity, address=address, _incref=_incref)
+    """Rebuild service object during unpickling."""
+    return ServiceObjectType(typename, exposed)(
+        oid=oid, identity=identity, address=address, _incref=_incref
+    )
 
 
 def RebuildAsyncServiceObject(typename, exposed, oid, identity, address, _incref=True):
-    """Rebuild async service object during unpickling.
-    """
-    return ServiceObjectType(typename, exposed, asynced=True)(oid=oid, identity=identity, address=address, _incref=_incref)
+    """Rebuild async service object during unpickling."""
+    return ServiceObjectType(typename, exposed, asynced=True)(
+        oid=oid, identity=identity, address=address, _incref=_incref
+    )
 
 
 def make_exposed_defs(exposed, asynced):
-    """Make expose class definitions.
-    """
+    """Make expose class definitions."""
     defs = []
 
     for name in exposed.methods:
-        defs.append(f"{'async ' if asynced else ''}def {name}(self, *args, **kwargs):\n"
-                f"    return {'await ' if asynced else ''}self.__{'async_' if asynced else ''}proxy_call__(self.oid, self.address, self.identity, \"{name}\", args, kwargs, _tracer=self._tracer)",
-            )
+        defs.append(
+            f"{'async ' if asynced else ''}def {name}(self, *args, **kwargs):\n"
+            f"    return {'await ' if asynced else ''}self.__{'async_' if asynced else ''}proxy_call__(self.oid, self.address, self.identity, \"{name}\", args, kwargs, _tracer=self._tracer)",
+        )
 
     for name in exposed.properties:
-        defs.append(f"@property\n"
-                f"{'async ' if asynced else ''}def {name}(self):\n"
-                f"    return {'await ' if asynced else ''}self.__{'async_' if asynced else ''}proxy_call__(self.oid, self.address, self.identity, \"__getattribute__\", [\"{name}\"], _tracer=self._tracer)"
-                f"\n"
-                f"@{name}.setter\n"
-                f"{'async ' if asynced else ''}def {name}(self, v):\n"
-                f"    return {'await ' if asynced else ''}self.__{'async_' if asynced else ''}proxy_call__(self.oid, self.address, self.identity, \"__setattribute__\", [\"{name}\", v], _tracer=self._tracer)",
-            )
+        defs.append(
+            f"@property\n"
+            f"{'async ' if asynced else ''}def {name}(self):\n"
+            f"    return {'await ' if asynced else ''}self.__{'async_' if asynced else ''}proxy_call__(self.oid, self.address, self.identity, \"__getattribute__\", [\"{name}\"], _tracer=self._tracer)"
+            f"\n"
+            f"@{name}.setter\n"
+            f"{'async ' if asynced else ''}def {name}(self, v):\n"
+            f"    return {'await ' if asynced else ''}self.__{'async_' if asynced else ''}proxy_call__(self.oid, self.address, self.identity, \"__setattribute__\", [\"{name}\", v], _tracer=self._tracer)",
+        )
 
     return defs
 
 
 def ServiceObjectType(typename, exposed, asynced=False, _cache={}):
-    """Make service object type.
-    """
+    """Make service object type."""
     try:
         return _cache[(typename, exposed, asynced)]
     except KeyError:
         pass
 
     _attrs = {}
 
     exec("\n".join(make_exposed_defs(exposed, asynced=asynced)), _attrs)
 
     base = AsyncBaseServiceObject if asynced else BaseServiceObject
 
-    service_type = type(f"{'Async' if asynced else ''}ServiceObject[{typename}]", (base,), _attrs)
+    service_type = type(
+        f"{'Async' if asynced else ''}ServiceObject[{typename}]", (base,), _attrs
+    )
     service_type._exposed = exposed
     service_type._typename = typename
 
     _cache[(typename, exposed, asynced)] = service_type
 
     return service_type
 
 
-ExposedMethodsAndProperties = namedtuple("Exposed", "methods properties", defaults=([], []))
+ExposedMethodsAndProperties = namedtuple(
+    "Exposed", "methods properties", defaults=([], [])
+)
 
 
 def auto_expose(obj):
-    """Auto expose all public methods and properties of an object.
-    """
+    """Auto expose all public methods and properties of an object."""
     methods = []
     properties = []
 
     for name, value in inspect.getmembers(obj):
         if name.startswith("_"):
             continue
 
-        if type(value) in [types.MethodWrapperType, types.MethodType, types.BuiltinMethodType]:
+        if type(value) in [
+            types.MethodWrapperType,
+            types.MethodType,
+            types.BuiltinMethodType,
+        ]:
             methods.append(name)
         else:
             properties.append(name)
 
     return ExposedMethodsAndProperties(tuple(methods), tuple(properties))
 
 
 def AsyncServiceObject(obj, identity, address, expose=None, _incref=True):
-    """Make async service object.
-    """
+    """Make async service object."""
     return ServiceObjectType(f"{str(obj)}", expose or auto_expose(obj), asynced=True)(
-        oid=id(obj), identity=identity, address=address, _incref=_incref)
+        oid=id(obj), identity=identity, address=address, _incref=_incref
+    )
 
 
 def ServiceObject(obj, identity, address, expose=None, _incref=True):
-    """Make service object.
-    """
+    """Make service object."""
     return ServiceObjectType(f"{str(obj)}", expose or auto_expose(obj))(
-        oid=id(obj), identity=identity, address=address, _incref=_incref)
+        oid=id(obj), identity=identity, address=address, _incref=_incref
+    )
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/serialize.py` & `testflows.core-1.9.230627.1151633/testflows/_core/serialize.py`

 * *Files 5% similar despite different names*

```diff
@@ -15,45 +15,48 @@
 import json
 import importlib
 
 from json import JSONEncoder
 
 from .baseobject import TestArg
 
+
 class Encoder(JSONEncoder):
-    """Argument value encoder.
-    """
+    """Argument value encoder."""
+
     def default(self, o):
         if isinstance(o, TestArg):
             objtype = ".".join([o.__class__.__module__, o.__class__.__name__])
             args = list(o.initargs.args)
             args.append(o.initargs.kwargs)
-            return {"@py:%s" % objtype : args}
+            return {"@py:%s" % objtype: args}
         return super(Encoder, self).default(o)
 
+
 def object_hook(o):
     if not o:
         return o
     key = next(iter(o))
     if key.startswith("@py:"):
         initargs = o.get(key)
         objtype = key[4:]
         return decode_argument(objtype, initargs)
     return o
-    
+
+
 def decode_argument(objtype, initargs):
-    module, cls = objtype.rsplit('.',1)
-    args = initargs[:-1] 
+    module, cls = objtype.rsplit(".", 1)
+    args = initargs[:-1]
     kwargs = initargs[-1]
     return getattr(importlib.import_module(module), cls)(*args, **kwargs)
 
+
 def dumps(o, *args, **kwargs):
-    """Serialize argument.
-    """
-    cls = kwargs.pop('cls', Encoder)
-    return json.dumps(o, cls=cls, separators=(',', ':'), *args, **kwargs)
+    """Serialize argument."""
+    cls = kwargs.pop("cls", Encoder)
+    return json.dumps(o, cls=cls, separators=(",", ":"), *args, **kwargs)
+
 
 def loads(s, *args, **kwargs):
-    """Deserializes argument.
-    """
-    hook = kwargs.pop('object_hook', object_hook)
+    """Deserializes argument."""
+    hook = kwargs.pop("object_hook", object_hook)
     return json.loads(s, object_hook=hook, *args, **kwargs)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/templog.py` & `testflows.core-1.9.230627.1151633/testflows/_core/temp.py`

 * *Files 16% similar despite different names*

```diff
@@ -13,23 +13,33 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import re
 import time
 import tempfile
 
-parser = re.compile(r".*testflows\.(?P<ppid>\d+)\.(?P<ts>\d+)\.(?P<tss>\d+)\.(?P<pid>\d+)\.log")
-glob = "testflows.*.log"
+
+def parser(extension="log"):
+    return re.compile(
+        r".*testflows\.(?P<ppid>\d+)\.(?P<ts>\d+)\.(?P<tss>\d+)\.(?P<pid>\d+)\."
+        + extension
+    )
+
+
+glob = "testflows.*"
 
 
 def ppid_glob(ppid):
-    return f"testflows.{ppid}.*.log"
+    return f"testflows.{ppid}.*"
+
 
 def dirname():
-    """Return temporary log file directory name.
-    """
+    """Return temporary file directory name."""
     return tempfile.gettempdir()
 
-def filename():
-    """Return temporary log file name.
-    """
-    return os.path.join(tempfile.gettempdir(), f"testflows.{os.getppid()}.{time.time():017.7f}.{os.getpid()}.log")
+
+def filename(extension="log"):
+    """Return temporary file name."""
+    return os.path.join(
+        tempfile.gettempdir(),
+        f"testflows.{os.getppid()}.{time.time():017.7f}.{os.getpid()}.{extension}",
+    )
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/test.py` & `testflows.core-1.9.230627.1151633/testflows/_core/test.py`

 * *Files 8% similar despite different names*

```diff
@@ -27,94 +27,181 @@
 
 import testflows.settings as settings
 import testflows._core.tracing as tracing
 import testflows._core.contrib.yaml as yaml
 import testflows._core.contrib.schema as schema
 
 from .parallel.asyncio import asyncio
-from .templog import filename as templog_filename
-from .exceptions import DummyTestException, ResultException, TestIteration, DescriptionError, TestRerunIndividually
+from .temp import filename as temp_filename
+from .exceptions import (
+    DummyTestException,
+    ResultException,
+    TestIteration,
+    DescriptionError,
+    TestRerunIndividually,
+)
 from .exceptions import TerminatedError
-from .flags import Flags, SKIP, TE, FAIL_NOT_COUNTED, ERROR_NOT_COUNTED, NULL_NOT_COUNTED, MANDATORY, MANUAL, AUTO
-from .flags import REMOTE, PARALLEL, NO_PARALLEL, ASYNC, REPEATED, NOT_REPEATABLE, RETRIED, RETRY, NESTED_RETRY, LAST_RETRY
+from .flags import (
+    Flags,
+    SKIP,
+    TE,
+    FAIL_NOT_COUNTED,
+    ERROR_NOT_COUNTED,
+    NULL_NOT_COUNTED,
+    MANDATORY,
+    MANUAL,
+    AUTO,
+)
+from .flags import (
+    REMOTE,
+    PARALLEL,
+    NO_PARALLEL,
+    ASYNC,
+    REPEATED,
+    NOT_REPEATABLE,
+    RETRIED,
+    RETRY,
+    NESTED_RETRY,
+    LAST_RETRY,
+)
 from .flags import XOK, XFAIL, XNULL, XERROR, XRESULT
 from .flags import EOK, EFAIL, EERROR, ESKIP, ERESULT
 from .flags import CFLAGS, PAUSE_BEFORE, PAUSE_AFTER, PAUSE_ON_PASS, PAUSE_ON_FAIL
 from .flags import SETUP, CLEANUP
 from .testtype import TestType, TestSubType
-from .objects import get, Null, OK, Fail, Skip, Error, PassResults, FailResults, NonFailResults
+from .objects import (
+    get,
+    Null,
+    OK,
+    Fail,
+    Skip,
+    Error,
+    PassResults,
+    FailResults,
+    NonFailResults,
+)
 from .objects import Argument, Attribute, Requirement, ArgumentParser
 from .objects import ExamplesTable, Specification
 from .objects import NamedValue, OnlyTags, SkipTags
 from .objects import RSASecret, Secrets
 from .constants import name_sep, id_sep
 from .io import TestIO
-from .name import join, depth, match, absname, isabs
+from .name import join, depth, match, absname, isabs, basename
 from .funcs import exception, pause, result, value, input
 from .init import init
 from .cli.arg.parser import ArgumentParser as ArgumentParserClass
 from .cli.arg.common import epilog as common_epilog
 from .cli.arg.exit import ExitWithError, ExitException
 from .cli.arg.type import key_value as key_value_type, repeat as repeat_type
 from .cli.arg.type import tags_filter as tags_filter_type, retry as retry_type
-from .cli.arg.type import logfile as logfile_type, rsa_private_key_pem_file as rsa_private_key_pem_file_type
+from .cli.arg.type import (
+    logfile as logfile_type,
+    rsa_private_key_pem_file as rsa_private_key_pem_file_type,
+)
 from .cli.arg.type import file as file_type
-from .cli.arg.type import onoff as onoff_type, NoneValue, count as count_type, trace_level as trace_level_type
+from .cli.arg.type import (
+    onoff as onoff_type,
+    NoneValue,
+    count as count_type,
+    trace_level as trace_level_type,
+)
 from .cli.text import danger, warning
 from .exceptions import exception as get_exception
 from .filters import The
 from .utils.sort import human as human_sort
 from .transform.log.pipeline import ResultsLogPipeline
-from .parallel import current, top, previous, _check_parallel_context, join as parallel_join
+from .parallel import (
+    current,
+    top,
+    previous,
+    _check_parallel_context,
+    join as parallel_join,
+)
 from .parallel import convert_result_to_concurrent_future
 from .parallel.executor.thread import ThreadPoolExecutor, GlobalThreadPoolExecutor
 from .parallel.executor.asyncio import AsyncPoolExecutor, GlobalAsyncPoolExecutor
-from .parallel.executor.process import RemotePoolExecutor, ProcessPoolExecutor, GlobalProcessPoolExecutor
-from .parallel.asyncio import is_running_in_event_loop, async_next, wrap_future, OptionalFuture
+from .parallel.executor.process import (
+    RemotePoolExecutor,
+    ProcessPoolExecutor,
+    GlobalProcessPoolExecutor,
+)
+from .parallel.asyncio import (
+    is_running_in_event_loop,
+    async_next,
+    wrap_future,
+    OptionalFuture,
+)
 
 tracer = tracing.getLogger(__name__)
 
 try:
     import testflows.database as database_module
 except:
     database_module = None
 
-output_formats = ["new-fails", "fails", "classic", "slick", "nice",
-    "brisk", "quiet", "short", "manual", "dots", "progress", "pnice", "raw"]
-
-rerun_results = ["fails", "passes", "xouts", "ok", "fail", "error", "null",
-    "xok", "xfail", "xerror", "xnull", "skip"]
+output_formats = [
+    "new-fails",
+    "fails",
+    "classic",
+    "slick",
+    "nice",
+    "brisk",
+    "quiet",
+    "short",
+    "manual",
+    "dots",
+    "progress",
+    "pnice",
+    "raw",
+]
+
+rerun_results = [
+    "fails",
+    "passes",
+    "xouts",
+    "ok",
+    "fail",
+    "error",
+    "null",
+    "xok",
+    "xfail",
+    "xerror",
+    "xnull",
+    "skip",
+]
 
 # global secrets registry
 settings.secrets_registry = Secrets()
 
+
 async def run_async_generator(generator, consume=False):
-    """Run async generator.
-    """
+    """Run async generator."""
     if consume:
         async for item in generator:
             pass
         return
     return await async_next(generator)
 
+
 def run_generator(generator, consume=False):
-    """Run generator.
-    """
+    """Run generator."""
     if consume:
         for item in generator:
             pass
         return
     return next(generator)
 
+
 def dummy(*args, **kwargs):
     pass
 
+
 class DummyTest(object):
-    """Base class for dummy tests.
-    """
+    """Base class for dummy tests."""
+
     def __init__(self, *args, **kwargs):
         pass
 
     def __enter__(self):
         def dummy(*args, **kwargs):
             pass
 
@@ -125,17 +212,18 @@
         sys.settrace(self.trace)
         raise DummyTestException()
 
     def __exit__(self, exception_type, exception_value, exception_traceback):
         if isinstance(exception_value, DummyTestException):
             return True
 
+
 class Context(object):
-    """Test context.
-    """
+    """Test context."""
+
     def __init__(self, parent, state=None):
         self._parent = parent
         self._state = get(state, {})
         self._cleanups = []
 
     @property
     def parent(self):
@@ -145,43 +233,54 @@
         loop = None
 
         if asyncio.iscoroutinefunction(func):
             if is_running_in_event_loop():
                 loop = asyncio.get_event_loop()
 
         def func_wrapper():
-            """Cleanup function wrapper.
-            """
+            """Cleanup function wrapper."""
             r = func(*args, **kwargs)
 
             async def _task(r):
                 return await r
 
             if asyncio.iscoroutine(r):
                 if is_running_in_event_loop():
+
                     async def _async_wrapper():
-                        """Process async cleanup function.
-                        """
+                        """Process async cleanup function."""
                         if asyncio.get_running_loop() is loop or loop is None:
                             await r
                         else:
                             if loop.is_running():
                                 await asyncio.wrap_future(
-                                    asyncio.run_coroutine_threadsafe(_task(r), loop=loop))
+                                    asyncio.run_coroutine_threadsafe(
+                                        _task(r), loop=loop
+                                    )
+                                )
                             else:
-                                with ThreadPoolExecutor(join_on_shutdown=False) as executor:
-                                    await wrap_future(executor.submit(loop.run_until_complete, args=(_task(r),)))
+                                with ThreadPoolExecutor(
+                                    join_on_shutdown=False
+                                ) as executor:
+                                    await wrap_future(
+                                        executor.submit(
+                                            loop.run_until_complete, args=(_task(r),)
+                                        )
+                                    )
+
                     return _async_wrapper()
 
                 else:
                     if loop is None:
                         asyncio.run(_task(r))
                     else:
                         if loop.is_running():
-                            asyncio.run_coroutine_threadsafe(_task(r), loop=loop).result()
+                            asyncio.run_coroutine_threadsafe(
+                                _task(r), loop=loop
+                            ).result()
                         else:
                             loop.run_until_complete(_task(r))
 
         self._cleanups.append(func_wrapper)
 
     def _cleanup(self):
         exc_type, exc_value, exc_traceback = None, None, None
@@ -219,15 +318,15 @@
             except (Exception, KeyboardInterrupt) as e:
                 if not exc_value:
                     exc_type, exc_value, exc_traceback = sys.exc_info()
         return exc_type, exc_value, exc_traceback
 
     def __getattr__(self, name):
         try:
-            if name.startswith('_'):
+            if name.startswith("_"):
                 return self.__dict__[name]
         except KeyError:
             raise AttributeError(name) from None
 
         curr = self
         while True:
             try:
@@ -235,115 +334,178 @@
             except KeyError:
                 if curr._parent:
                     curr = curr._parent
                     continue
                 raise AttributeError(name) from None
 
     def __setattr__(self, name, value):
-        if name.startswith('_'):
+        if name.startswith("_"):
             self.__dict__[name] = value
         else:
             self._state[name] = value
 
     def __delattr__(self, name):
         try:
             del self._state[name]
         except KeyError:
             raise AttributeError(name) from None
 
     def __contains__(self, name):
-        if name.startswith('_'):
+        if name.startswith("_"):
             return name in self.__dict__
 
         curr = self
         while True:
             if name in curr._state:
                 return True
             if curr._parent:
                 curr = curr._parent
             else:
                 return False
 
+
 class SharedContext(Context):
-    """Share context with parent.
-    """
+    """Share context with parent."""
+
     def __init__(self, parent):
         if not isinstance(parent, Context):
             raise ValueError("parent must be an instance of Context")
         self._parent = parent._parent
         self._state = parent._state
         self._cleanups = parent._cleanups
 
+
 class TestBase(object):
     """Base class for all the tests.
 
     :param name: name
     :param flags: flags
     :param parent: parent name
     :param only: tests to run
     :param start: name of the starting test
     :param end: name of the last test
     """
+
     uid = None
     tags = set()
     attributes = []
     requirements = []
     specifications = []
     examples = None
     name = None
     description = None
     maps = []
     flags = Flags()
     name_sep = "."
     type = TestType.Test
     subtype = None
 
-    def __init__(self, name=None, flags=None, cflags=None, type=None, subtype=None,
-                 uid=None, tags=None, attributes=None, requirements=None, specifications=None,
-                 examples=None, description=None, parent=None, parent_type=None, parent_subtype=None,
-                 xfails=None, xflags=None, ffails=None, only=None, skip=None,
-                 start=None, end=None, only_tags=None, skip_tags=None,
-                 args=None, id=None, maps=None, context=None,
-                 repeats=None, retries=None, private_key=None, setup=None, first_fail=None, test_to_end=None,
-                 parallel_pool_size=None, module=None):
+    def __init__(
+        self,
+        name=None,
+        flags=None,
+        cflags=None,
+        type=None,
+        subtype=None,
+        uid=None,
+        tags=None,
+        attributes=None,
+        requirements=None,
+        specifications=None,
+        examples=None,
+        description=None,
+        parent=None,
+        parent_type=None,
+        parent_subtype=None,
+        xfails=None,
+        xflags=None,
+        ffails=None,
+        only=None,
+        skip=None,
+        start=None,
+        end=None,
+        only_tags=None,
+        skip_tags=None,
+        args=None,
+        id=None,
+        maps=None,
+        context=None,
+        repeats=None,
+        retries=None,
+        private_key=None,
+        setup=None,
+        first_fail=None,
+        test_to_end=None,
+        parallel_pool_size=None,
+        module=None,
+        action=None,
+        behavior=None,
+    ):
 
         self.lock = threading.Lock()
 
         if current() is None:
             if top() is not None:
                 raise TerminatedError("only one top level test is allowed")
             top(self)
             # flag to indicate if main test called init
-            self._init= False
+            self._init = False
 
         current_test = current()
 
         self.io = None
         self.name = name
         if self.name is None:
             raise TypeError("name must be specified")
-        self.name = self.name
         self.child_count = 0
         self.start_time = time.time()
         self.test_time = None
         self.parent = parent
         self.parent_type = parent_type
         self.parent_subtype = parent_subtype
         self.id = get(id, [settings.test_id])
         self.id_str = id_sep + id_sep.join(str(n) for n in self.id)
         self.maps = get(maps, list(self.maps))
         self.module = module
+        self.action = action
         self.type = get(type, self.type)
         self.subtype = get(subtype, self.subtype)
-        self.context = get(context, current_test.context if current_test and self.type < TestType.Iteration else (Context(current_test.context if current_test else None)))
+        self.context = get(
+            context,
+            current_test.context
+            if current_test and self.type < TestType.Iteration
+            else (Context(current_test.context if current_test else None)),
+        )
+        self.behavior = get(
+            behavior,
+            current_test.behavior
+            if current_test and self.type < TestType.Iteration
+            else [],
+        )
+        if action is not None:
+            self.behavior.append(basename(self.name))
         self.tags = tags
-        self.specifications = {s.name: s for s in [Specification(*r) for r in get(specifications, list(self.specifications))]}
-        self.requirements = {r.name: r for r in [Requirement(*r) for r in get(requirements, list(self.requirements))]}
-        self.attributes = {a.name: a for a in [Attribute(*a) for a in get(attributes, list(self.attributes))]}
-        self.args = {k: Argument(k, v) for k,v in get(args, {}).items()}
+        self.specifications = {
+            s.name: s
+            for s in [
+                Specification(*r)
+                for r in get(specifications, list(self.specifications))
+            ]
+        }
+        self.requirements = {
+            r.name: r
+            for r in [
+                Requirement(*r) for r in get(requirements, list(self.requirements))
+            ]
+        }
+        self.attributes = {
+            a.name: a
+            for a in [Attribute(*a) for a in get(attributes, list(self.attributes))]
+        }
+        self.args = {k: Argument(k, v) for k, v in get(args, {}).items()}
         self.description = get(description, self.description)
         self.examples = get(examples, get(self.examples, ExamplesTable()))
         if not isinstance(self.examples, ExamplesTable):
             self.examples = ExamplesTable(*self.examples)
         self.result = Null(test=self.name, start_time=self.start_time)
         if flags is not None:
             self.flags = Flags(flags)
@@ -369,15 +531,17 @@
         self.executor = None
         self.terminating = None
         self.terminated = None
         self.subtests = {}
         self.first_fail = get(first_fail, None)
         self.test_to_end = get(test_to_end, None)
         self.parallel_pool_size = get(parallel_pool_size, None)
-        self.tracer = tracing.EventAdapter(tracing.TestAdapter(tracer, self), None, source=str(self))
+        self.tracer = tracing.EventAdapter(
+            tracing.TestAdapter(tracer, self), None, source=str(self)
+        )
 
         if self.setup is not None:
             if isinstance(self.setup, (TestDecorator, TestDefinition)):
                 pass
             elif inspect.isfunction(self.setup):
                 self.setup = functools.partial(self.setup, self=self)
             else:
@@ -417,58 +581,59 @@
         if args is None:
             args = dict()
         try:
             description = str(description) if description is not None else None
             if description and format:
                 description = description.format(**{"$cls": cls}, **args)
         except Exception as exc:
-            raise DescriptionError(f"can't format '{description}' using {args} {str(exc)}") from None
+            raise DescriptionError(
+                f"can't format '{description}' using {args} {str(exc)}"
+            ) from None
         return description
 
     @classmethod
     def make_tags(cls, tags):
         return {str(tag) for tag in set(get(tags, cls.tags))}
 
     def terminate(self, result=Skip, message=None, reason="terminated"):
-        """Terminate test.
-        """
+        """Terminate test."""
         with tracing.Event(self.tracer, "terminating") as event_tracer:
             if self.terminating:
                 return
 
             with self.lock:
                 if self.terminating:
                     return
                 if self.cflags & CLEANUP:
                     return
                 self.terminating = True
 
-                self.result = self.result(result(message, reason=reason, test=self.name))
+                self.result = self.result(
+                    result(message, reason=reason, test=self.name)
+                )
 
                 for subtest in self.subtests.values():
                     event_tracer.debug(f"terminating {subtest}")
                     subtest.terminate()
                 self.subtests = {}
 
     def add_subtest(self, subtest):
-        """Add subtest.
-        """
+        """Add subtest."""
         with tracing.Event(self.tracer, f"add_subtest({subtest})") as event_tracer:
             with self.lock:
                 event_tracer.debug("got lock")
                 self.subtests[subtest.id_str] = subtest
                 event_tracer.debug(f"modified subtests dictionary")
 
             if self.terminating:
                 event_tracer.debug("terminating subtest")
                 subtest.terminate()
 
     def remove_subtest(self, subtest):
-        """Remove subtest.
-        """
+        """Remove subtest."""
         with self.lock:
             self.subtests.pop(subtest.id_str, None)
 
     def child_id(self):
         with self.lock:
             try:
                 return self.id + [self.child_count]
@@ -503,55 +668,84 @@
             elif isinstance(test_result, Fail) and FAIL_NOT_COUNTED not in flags:
                 self.result = self.result(result)
             else:
                 pass
 
     def _enter(self):
         if self is not top():
-            if self.flags & MANUAL and not self.flags & SKIP and self.type >= TestType.Test:
+            if (
+                self.flags & MANUAL
+                and not self.flags & SKIP
+                and self.type >= TestType.Test
+            ):
                 pause()
 
         self.io = TestIO(self)
 
         if top() is self:
             self._init = init()
             self.io.output.protocol()
             self.io.output.version()
 
-            self.attributes.update({
-                    arg.name: Attribute(name=arg.name, value=arg.value, type=arg.type, group=arg.group, uid=arg.uid)
+            self.attributes.update(
+                {
+                    arg.name: Attribute(
+                        name=arg.name,
+                        value=arg.value,
+                        type=arg.type,
+                        group=arg.group,
+                        uid=arg.uid,
+                    )
                     for arg in self.args.values()
-                })
+                }
+            )
             self.args = {}
 
         self.tracer.debug(f"test start", extra={"event_action": tracing.Action.START})
         self.io.output.test_message()
 
         if self.flags & PAUSE_BEFORE and not self.flags & SKIP:
             pause()
 
         self.caller_test = current()
         current(self)
 
         if top() is self:
             if self.parallel_pool_size:
-                settings.global_thread_pool = GlobalThreadPoolExecutor(max_workers=self.parallel_pool_size, join_on_shutdown=False)
-                settings.global_async_pool = GlobalAsyncPoolExecutor(max_workers=self.parallel_pool_size, join_on_shutdown=False)
-                settings.global_process_pool = GlobalProcessPoolExecutor(max_workers=self.parallel_pool_size, join_on_shutdown=False)
+                settings.global_thread_pool = GlobalThreadPoolExecutor(
+                    max_workers=self.parallel_pool_size, join_on_shutdown=False
+                )
+                settings.global_async_pool = GlobalAsyncPoolExecutor(
+                    max_workers=self.parallel_pool_size, join_on_shutdown=False
+                )
+                settings.global_process_pool = GlobalProcessPoolExecutor(
+                    max_workers=self.parallel_pool_size, join_on_shutdown=False
+                )
 
         for pattern, force_fail in (self.ffails or {}).items():
-            force_result, force_reason, force_when = force_fail[0], force_fail[1], force_fail[2:]
-            force_when = force_when[0] if force_when and force_when[0] is not None else lambda test: True
+            force_result, force_reason, force_when = (
+                force_fail[0],
+                force_fail[1],
+                force_fail[2:],
+            )
+            force_when = (
+                force_when[0]
+                if force_when and force_when[0] is not None
+                else lambda test: True
+            )
             if not self.flags & SKIP or (self.flags & SKIP and force_result is Skip):
                 if match(self.name, pattern):
                     if force_when(self):
                         raise force_result(reason=force_reason, test=self.name)
 
         if self.parent:
-            with tracing.Event(self.tracer, f"adding {self}({self.name}) as subtest of parent {self.parent}"):
+            with tracing.Event(
+                self.tracer,
+                f"adding {self}({self.name}) as subtest of parent {self.parent}",
+            ):
                 self.parent.add_subtest(self)
 
         if self.flags & SKIP:
             raise Skip("skip flag set", test=self.name)
 
         if self.setup is not None:
             r = self.setup()
@@ -561,34 +755,44 @@
             elif inspect.isgenerator(r):
                 res = next(r)
                 self.context.cleanup(run_generator, r, consume=True)
 
         return self
 
     def _exit_process_exception(self, exc_type, exc_value, exc_traceback):
-        """Process exception on exit.
-        """
+        """Process exception on exit."""
         if isinstance(exc_value, ResultException):
             self.result = self.result(exc_value)
 
         elif isinstance(exc_value, TerminatedError):
             self.result = self.result(Skip(None, reason="terminated", test=self.name))
 
         elif isinstance(exc_value, AssertionError):
             exception(exc_type, exc_value, exc_traceback, test=self)
-            self.result = self.result(Fail(exc_type.__name__ + "\n" + get_exception(exc_type, exc_value, exc_traceback), test=self.name))
+            self.result = self.result(
+                Fail(
+                    exc_type.__name__
+                    + "\n"
+                    + get_exception(exc_type, exc_value, exc_traceback),
+                    test=self.name,
+                )
+            )
 
         else:
             exception(exc_type, exc_value, exc_traceback, test=self)
-            result = Error(exc_type.__name__ + "\n" + get_exception(exc_type, exc_value, exc_traceback), test=self.name)
+            result = Error(
+                exc_type.__name__
+                + "\n"
+                + get_exception(exc_type, exc_value, exc_traceback),
+                test=self.name,
+            )
             self.result = self.result(result)
 
     def _exit(self, exc_type, exc_value, exc_traceback):
-        """Synchronous test exit.
-        """
+        """Synchronous test exit."""
         if not self.io:
             return False
 
         if top() is self and not self._init:
             return False
 
         try:
@@ -606,20 +810,28 @@
                 try:
                     parallel_join(futures=self.futures, test=self, all=True)
                 except (Exception, KeyboardInterrupt) as exc:
                     parallel_exception = exc
 
             # context cleanups
             if self.type >= TestType.Iteration:
-                if self.context._cleanups and not isinstance(self.context, SharedContext):
+                if self.context._cleanups and not isinstance(
+                    self.context, SharedContext
+                ):
                     try:
                         with Finally("I clean up"):
-                            cleanup_exc_type, cleanup_exc_value, cleanup_exc_traceback = self.context._cleanup()
+                            (
+                                cleanup_exc_type,
+                                cleanup_exc_value,
+                                cleanup_exc_traceback,
+                            ) = self.context._cleanup()
                             if cleanup_exc_value is not None:
-                                raise cleanup_exc_value.with_traceback(cleanup_exc_traceback)
+                                raise cleanup_exc_value.with_traceback(
+                                    cleanup_exc_traceback
+                                )
                     except Exception:
                         if not exc_value:
                             self._exit_process_exception(*sys.exc_info())
 
             # close parallel executor if any
             if self.executor is not None:
                 self.executor.__exit__(None, None, None)
@@ -637,16 +849,15 @@
             self._exit_result(exc_type, exc_value, exc_traceback, parallel_exception)
         finally:
             self._exit_finally()
 
         return True
 
     async def _async_exit(self, exc_type, exc_value, exc_traceback):
-        """Asynchronous text exit.
-        """
+        """Asynchronous text exit."""
         if not self.io:
             return False
         if top() is self and not self._init:
             return False
 
         try:
             parallel_exception = None
@@ -666,18 +877,23 @@
                 parallel_exception = exc
 
             # context cleanups
             if self.type >= TestType.Iteration:
                 if self.context._cleanups:
                     try:
                         async with Finally("I clean up"):
-                            cleanup_exc_type, cleanup_exc_value, cleanup_exc_traceback = \
-                                await self.context._async_cleanup()
+                            (
+                                cleanup_exc_type,
+                                cleanup_exc_value,
+                                cleanup_exc_traceback,
+                            ) = await self.context._async_cleanup()
                             if cleanup_exc_value is not None:
-                                raise cleanup_exc_value.with_traceback(cleanup_exc_traceback)
+                                raise cleanup_exc_value.with_traceback(
+                                    cleanup_exc_traceback
+                                )
                     except Exception:
                         if not exc_value:
                             self._exit_process_exception(*sys.exc_info())
 
             # close parallel executor if any
             if self.executor is not None:
                 self.executor.__exit__(None, None, None)
@@ -695,36 +911,38 @@
             self._exit_result(exc_type, exc_value, exc_traceback, parallel_exception)
         finally:
             self._exit_finally()
 
         return True
 
     def _exit_result(self, exc_type, exc_value, exc_traceback, parallel_exception):
-        """Set test result on exit.
-        """
+        """Set test result on exit."""
         # set parallel exception if exc_value is None
         if exc_value is None and parallel_exception is not None:
             exc_type = type(parallel_exception)
             exc_value = parallel_exception
             exc_traceback = parallel_exception.__traceback__
 
         if exc_value is not None:
             self._exit_process_exception(exc_type, exc_value, exc_traceback)
         else:
-            if isinstance(self.result, Null) and self.flags & MANUAL and not self.flags & SKIP:
+            if (
+                isinstance(self.result, Null)
+                and self.flags & MANUAL
+                and not self.flags & SKIP
+            ):
                 try:
                     input(result)
                 except Exception:
                     self._exit_process_exception(*sys.exc_info())
             elif isinstance(self.result, Null):
                 self.result = self.result(OK(test=self.name))
 
     def _exit_finally(self):
-        """Finalize test exit.
-        """
+        """Finalize test exit."""
         current(self.caller_test, set_value=True)
         previous(self)
 
         self._apply_eresult_flags()
         self._apply_xresult_flags()
         self._apply_xfails()
 
@@ -745,46 +963,58 @@
                 pause()
             elif self.flags & PAUSE_ON_FAIL and isinstance(self.result, FailResults):
                 pause()
             elif self.flags & PAUSE_ON_PASS and isinstance(self.result, PassResults):
                 pause()
 
     def _apply_eresult_flags(self):
-        """Apply eresult flags to self.result.
-        """
+        """Apply eresult flags to self.result."""
         if not ERESULT in self.flags:
             return
 
         message_template = f"{self.result.message + ', ' if self.result.message else ''}{self.result} result is converted to %(result)s because %(flag)s flag set"
 
         if EOK in self.flags:
             if not isinstance(self.result, OK):
-                self.result = self.result(Fail(message_template % dict(result="Fail", flag="EOK")))
+                self.result = self.result(
+                    Fail(message_template % dict(result="Fail", flag="EOK"))
+                )
 
         if EFAIL in self.flags:
             if not isinstance(self.result, Fail):
-                self.result = self.result(Fail(message_template % dict(result="Fail", flag="EFAIL")))
+                self.result = self.result(
+                    Fail(message_template % dict(result="Fail", flag="EFAIL"))
+                )
             else:
-                self.result = self.result(OK(message_template % dict(result="OK", flag="EFAIL")))
+                self.result = self.result(
+                    OK(message_template % dict(result="OK", flag="EFAIL"))
+                )
 
         if EERROR in self.flags:
             if not isinstance(self.result, Error):
-                self.result = self.result(Fail(message_template % dict(result="Fail", flag="EERROR")))
+                self.result = self.result(
+                    Fail(message_template % dict(result="Fail", flag="EERROR"))
+                )
             else:
-                self.result = self.result(OK(message_template % dict(result="OK", flag="EERROR")))
+                self.result = self.result(
+                    OK(message_template % dict(result="OK", flag="EERROR"))
+                )
 
         if ESKIP in self.flags:
             if not isinstance(self.result, Skip):
-                self.result = self.result(Fail(message_template % dict(result="Fail", flag="ESKIP")))
+                self.result = self.result(
+                    Fail(message_template % dict(result="Fail", flag="ESKIP"))
+                )
             else:
-                self.result = self.result(OK(message_template% dict(result="OK", flag="ESKIP")))
+                self.result = self.result(
+                    OK(message_template % dict(result="OK", flag="ESKIP"))
+                )
 
     def _apply_xresult_flags(self):
-        """Apply xresult flags to self.result.
-        """
+        """Apply xresult flags to self.result."""
         if not XRESULT in self.flags:
             return
 
         if XOK in self.flags and isinstance(self.result, OK):
             self.result = self.result.xout("XOK flag set")
 
         if XFAIL in self.flags and isinstance(self.result, Fail):
@@ -793,34 +1023,39 @@
         if XERROR in self.flags and isinstance(self.result, Error):
             self.result = self.result.xout("XERROR flag set")
 
         if XNULL in self.flags and isinstance(self.result, Null):
             self.result = self.result.xout("XNULL flag set")
 
     def _apply_xfails(self):
-        """Apply xfails to self.result.
-        """
+        """Apply xfails to self.result."""
         if not self.xfails:
             return
 
         for pattern, xouts in self.xfails.items():
             if match(self.name, pattern):
                 for xout in xouts:
                     result, reason = xout[:2]
                     when = xout[2] if len(xout) > 2 else None
                     result_message = xout[3] if len(xout) > 3 else None
                     if when is not None and not when(self):
                         continue
                     if isinstance(self.result, result):
                         if result_message is not None:
                             try:
-                                if self.result.message is None or not re.match(result_message, self.result.message, flags=re.MULTILINE|re.DOTALL):
+                                if self.result.message is None or not re.match(
+                                    result_message,
+                                    self.result.message,
+                                    flags=re.MULTILINE | re.DOTALL,
+                                ):
                                     continue
                             except re.error as exc:
-                                raise RuntimeError(f"xfail '{pattern}' has invalid result message regex expression: {exc}") from None
+                                raise RuntimeError(
+                                    f"xfail '{pattern}' has invalid result message regex expression: {exc}"
+                                ) from None
                         self.result = self.result.xout(reason)
 
     def bind(self, func):
         """Bind function to the current test.
 
         :param func: function that takes an instance of test
             as the argument named 'test'
@@ -837,15 +1072,17 @@
         Note: only write() and flush() methods
         are supported.
 
         :param name: name of the stream, default: None
         """
         return self.io.message_io(name=name)
 
-epilog = """
+
+epilog = (
+    """
 argument values:
 
 pattern
   used to match test names using a unix-like file path pattern that supports wildcards
     '/' path level separator
     '*' matches any zero or more characters including '/' path level separator
     '?' matches any single character
@@ -853,15 +1090,17 @@
     '[!seq]' matches any character not in seq
     ':' matches any one or more characters but not including '/' path level separator
   for a literal match, wrap the meta-characters in brackets where '[?]' matches the character '?'
 
 type
   test type either 'test','suite','module','scenario', 'feature', or 'any'
 
-""" + common_epilog()
+"""
+    + common_epilog()
+)
 
 
 def cli_argparser(kwargs, argparser=None):
     """Command line argument parser.
 
     :argparser: test specific argument parser
     :return: argument parser
@@ -870,155 +1109,350 @@
     if description is not None:
         description = str(description)
 
     main_parser = ArgumentParserClass(
         prog=sys.argv[0],
         description=description,
         description_prog="Test - Framework",
-        epilog=epilog
+        epilog=epilog,
     )
     test_args_schema = None
 
     if argparser:
-        test_args_schema = argparser(main_parser.add_argument_group('test arguments'))
+        test_args_schema = argparser(main_parser.add_argument_group("test arguments"))
 
     parser = main_parser.add_argument_group("common arguments")
 
-    parser.add_argument("--config", "-c", dest ="_config", metavar="yml ...",
-                        action="append", default=[],
-                        help=("test run YAML configuration file. "
-                              "Can be specified more than once "
-                              "to apply multiple configuration files that are "
-                              "applied left to right"), type=file_type("r"))
-    parser.add_argument("--name", dest="_name", metavar="name",
-                        help="test run name", type=str, required=False)
-    parser.add_argument("--tag", dest="_tags", metavar="value", nargs="+",
-                        help="test run tags", type=str, required=False)
-    parser.add_argument("--attr", dest="_attrs", metavar="name=value", nargs="+",
-                        help="test run attributes", type=key_value_type, required=False)
-    parser.add_argument("--only", dest="_only", metavar="pattern", nargs="+",
-                        help="run only selected tests", type=str, required=False)
-    parser.add_argument("--skip", dest="_skip", metavar="pattern",
-                        help="skip selected tests", type=str, nargs="+", required=False)
-    parser.add_argument("--start", dest="_start", metavar="pattern", nargs=1,
-                        help="start at the selected test", type=str, required=False)
-    parser.add_argument("--end", dest="_end", metavar="pattern", nargs=1,
-                        help="end at the selected test", type=str, required=False)
-    parser.add_argument("--only-tags", dest="_only_tags",
-                        help="run only tests with selected tags",
-                        type=tags_filter_type, metavar="type:tag,...",
-                        nargs="+", required=False)
-    parser.add_argument("--skip-tags", dest="_skip_tags",
-                        help="skip tests with selected tags",
-                        type=tags_filter_type, metavar="type:tag,...",
-                        nargs="+", required=False)
-    parser.add_argument("--pause-before", dest="_pause_before", metavar="pattern",
-                        nargs="+", help="pause before executing selected tests",
-                        type=str, required=False)
-    parser.add_argument("--pause-after", dest="_pause_after", metavar="pattern",
-                        nargs="+", help="pause after executing selected tests",
-                        type=str, required=False)
-    parser.add_argument("--pause-on-fail", dest="_pause_on_fail", metavar="pattern",
-                        nargs="+", help="pause after selected tests on failing result",
-                        type=str, required=False)
-    parser.add_argument("--pause-on-pass", dest="_pause_on_pass", metavar="pattern",
-                        nargs="+", help="pause after selected tests on passing result",
-                        type=str, required=False)
-    parser.add_argument("--random", dest="_random", action="store_true",
-                        help="randomize order of auto loaded tests",
-                        required=False, default=None)
-    parser.add_argument("--debug", dest="_debug", action="store_true",
-                        help="enable debugging mode", default=None)
-    parser.add_argument("--no-colors", dest="_no_colors",
-                        metavar=onoff_type.metavar,
-                        help="disable terminal color highlighting", nargs='?',
-                        type=onoff_type, default=NoneValue)
-    parser.add_argument("--id", metavar="id", dest="_id", type=str, help="custom test id")
-    parser.add_argument("-o", "--output", dest="_output", metavar="format", type=str,
-                        choices=output_formats,
-                        help=f"""stdout output format, choices are: {output_formats},
-                            default: 'nice'""")
-    parser.add_argument("-l", "--log", dest="_log", metavar="file", type=str,
-                        help=("path to the log file where test output will be stored, "
-                              "default: uses temporary log file"))
-    parser.add_argument("--show-skipped", dest="_show_skipped", action="store_true",
-                        help="show skipped tests, default: False", default=None)
-    parser.add_argument("--trim-results", dest="_trim_results",
-                        help="enable or disable trimming result messages, default: on",
-                        type=onoff_type, metavar=onoff_type.metavar, default=NoneValue)
-    parser.add_argument("--repeat", dest="_repeat",
-                        help=("repeat a test until it either fails, "
-                              "passes or all iterations are completed.\n"
-                              "Where `pattern` is a test name pattern, "
-                              "`count` is a number times to repeat the test, "
-                              "`until` is either {'pass', 'fail', 'complete'} "
-                              "(default: 'fail')"),
-                        type=repeat_type, metavar="pattern,count[,until]]",
-                        nargs="+", required=False)
-    parser.add_argument("--retry", dest="_retry",
-                        help=("retry a test until it passes or all retries are completed."
-                              "\nFailed retry attempts except the last one are ignored. "
-                              "Where `pattern` is a test name pattern and "
-                              "`count` is a number times to retry the test,"
-                              "`timeout` (optional) maximum number of seconds "
-                              "to retry (default: None),"
-                              "`delay` (optional) delay in seconds between "
-                              "retries (default: 0),"
-                              "`backoff` (optional) backoff factor (default: 1)"),
-                        type=retry_type,
-                        metavar="pattern,count[,timeout[,delay[,backoff]]]",
-                        nargs="+", required=False)
-    parser.add_argument("-r", "--reference", dest="_reference", metavar="log",
-                        type=logfile_type("r", encoding="utf-8"),
-                        help="reference log file")
-
-    parser.add_argument("--rerun", dest="_rerun", metavar="result", type=str,
-                        choices=rerun_results, nargs="+",
-                        help=("rerun tests in the --reference log file.\n"
-                              f"Where `result` is either {rerun_results}"))
-    parser.add_argument("--individually", dest="_individually",
-                        action="store_true", default=None,
-                        help=("if --rerun is specified then rerun tests in the "
-                              "--reference log file individually."))
-
-    parser.add_argument("--parallel", dest="_parallel", type=onoff_type,
-                        metavar=onoff_type.metavar,
-                        help=("enable or disable parallelism for tests "
-                              "that support it, default: on"))
-    parser.add_argument("--parallel-pool", dest="_parallel_pool",
-                        metavar="size", type=count_type,
-                        help=("for parallel tests force to use global parallel "
-                              "pool of the specified size"))
-
-    parser.add_argument("--private-key", dest="_private_key",
-                        metavar="file", type=rsa_private_key_pem_file_type,
-                        help=("RSA private key PEM file that can be "
-                              "used to encrypt secrets."))
+    parser.add_argument(
+        "--config",
+        "-c",
+        dest="_config",
+        metavar="yml ...",
+        action="append",
+        default=[],
+        help=(
+            "test run YAML configuration file. "
+            "Can be specified more than once "
+            "to apply multiple configuration files that are "
+            "applied left to right"
+        ),
+        type=file_type("r"),
+    )
+    parser.add_argument(
+        "--name",
+        dest="_name",
+        metavar="name",
+        help="test run name",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--tag",
+        dest="_tags",
+        metavar="value",
+        nargs="+",
+        help="test run tags",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--attr",
+        dest="_attrs",
+        metavar="name=value",
+        nargs="+",
+        help="test run attributes",
+        type=key_value_type,
+        required=False,
+    )
+    parser.add_argument(
+        "--only",
+        dest="_only",
+        metavar="pattern",
+        nargs="+",
+        help="run only selected tests",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--skip",
+        dest="_skip",
+        metavar="pattern",
+        help="skip selected tests",
+        type=str,
+        nargs="+",
+        required=False,
+    )
+    parser.add_argument(
+        "--start",
+        dest="_start",
+        metavar="pattern",
+        nargs=1,
+        help="start at the selected test",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--end",
+        dest="_end",
+        metavar="pattern",
+        nargs=1,
+        help="end at the selected test",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--only-tags",
+        dest="_only_tags",
+        help="run only tests with selected tags",
+        type=tags_filter_type,
+        metavar="type:tag,...",
+        nargs="+",
+        required=False,
+    )
+    parser.add_argument(
+        "--skip-tags",
+        dest="_skip_tags",
+        help="skip tests with selected tags",
+        type=tags_filter_type,
+        metavar="type:tag,...",
+        nargs="+",
+        required=False,
+    )
+    parser.add_argument(
+        "--pause-before",
+        dest="_pause_before",
+        metavar="pattern",
+        nargs="+",
+        help="pause before executing selected tests",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--pause-after",
+        dest="_pause_after",
+        metavar="pattern",
+        nargs="+",
+        help="pause after executing selected tests",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--pause-on-fail",
+        dest="_pause_on_fail",
+        metavar="pattern",
+        nargs="+",
+        help="pause after selected tests on failing result",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--pause-on-pass",
+        dest="_pause_on_pass",
+        metavar="pattern",
+        nargs="+",
+        help="pause after selected tests on passing result",
+        type=str,
+        required=False,
+    )
+    parser.add_argument(
+        "--random",
+        dest="_random",
+        action="store_true",
+        help="randomize order of auto loaded tests",
+        required=False,
+        default=None,
+    )
+    parser.add_argument(
+        "--debug",
+        dest="_debug",
+        action="store_true",
+        help="enable debugging mode",
+        default=None,
+    )
+    parser.add_argument(
+        "--no-colors",
+        dest="_no_colors",
+        metavar=onoff_type.metavar,
+        help="disable terminal color highlighting",
+        nargs="?",
+        type=onoff_type,
+        default=NoneValue,
+    )
+    parser.add_argument(
+        "--id", metavar="id", dest="_id", type=str, help="custom test id"
+    )
+    parser.add_argument(
+        "-o",
+        "--output",
+        dest="_output",
+        metavar="format",
+        type=str,
+        choices=output_formats,
+        help=f"""stdout output format, choices are: {output_formats},
+                            default: 'nice'""",
+    )
+    parser.add_argument(
+        "-l",
+        "--log",
+        dest="_log",
+        metavar="file",
+        type=str,
+        help=(
+            "path to the log file where test output will be stored, "
+            "default: uses temporary log file"
+        ),
+    )
+    parser.add_argument(
+        "--show-skipped",
+        dest="_show_skipped",
+        action="store_true",
+        help="show skipped tests, default: False",
+        default=None,
+    )
+    parser.add_argument(
+        "--trim-results",
+        dest="_trim_results",
+        help="enable or disable trimming result messages, default: on",
+        type=onoff_type,
+        metavar=onoff_type.metavar,
+        default=NoneValue,
+    )
+    parser.add_argument(
+        "--repeat",
+        dest="_repeat",
+        help=(
+            "repeat a test until it either fails, "
+            "passes or all iterations are completed.\n"
+            "Where `pattern` is a test name pattern, "
+            "`count` is a number times to repeat the test, "
+            "`until` is either {'pass', 'fail', 'complete'} "
+            "(default: 'fail')"
+        ),
+        type=repeat_type,
+        metavar="pattern,count[,until]]",
+        nargs="+",
+        required=False,
+    )
+    parser.add_argument(
+        "--retry",
+        dest="_retry",
+        help=(
+            "retry a test until it passes or all retries are completed."
+            "\nFailed retry attempts except the last one are ignored. "
+            "Where `pattern` is a test name pattern and "
+            "`count` is a number times to retry the test,"
+            "`timeout` (optional) maximum number of seconds "
+            "to retry (default: None),"
+            "`delay` (optional) delay in seconds between "
+            "retries (default: 0),"
+            "`backoff` (optional) backoff factor (default: 1)"
+        ),
+        type=retry_type,
+        metavar="pattern,count[,timeout[,delay[,backoff]]]",
+        nargs="+",
+        required=False,
+    )
+    parser.add_argument(
+        "-r",
+        "--reference",
+        dest="_reference",
+        metavar="log",
+        type=logfile_type("r", encoding="utf-8"),
+        help="reference log file",
+    )
+
+    parser.add_argument(
+        "--rerun",
+        dest="_rerun",
+        metavar="result",
+        type=str,
+        choices=rerun_results,
+        nargs="+",
+        help=(
+            "rerun tests in the --reference log file.\n"
+            f"Where `result` is either {rerun_results}"
+        ),
+    )
+    parser.add_argument(
+        "--individually",
+        dest="_individually",
+        action="store_true",
+        default=None,
+        help=(
+            "if --rerun is specified then rerun tests in the "
+            "--reference log file individually."
+        ),
+    )
+
+    parser.add_argument(
+        "--parallel",
+        dest="_parallel",
+        type=onoff_type,
+        metavar=onoff_type.metavar,
+        help=(
+            "enable or disable parallelism for tests " "that support it, default: on"
+        ),
+    )
+    parser.add_argument(
+        "--parallel-pool",
+        dest="_parallel_pool",
+        metavar="size",
+        type=count_type,
+        help=(
+            "for parallel tests force to use global parallel "
+            "pool of the specified size"
+        ),
+    )
+
+    parser.add_argument(
+        "--private-key",
+        dest="_private_key",
+        metavar="file",
+        type=rsa_private_key_pem_file_type,
+        help=("RSA private key PEM file that can be " "used to encrypt secrets."),
+    )
 
     exit_group = parser.add_mutually_exclusive_group()
-    exit_group.add_argument('--first-fail', dest="_first_fail",
-                            action='store_true', default=None,
-                            help=("force all tests to be first fail and abort "
-                                  "the run on the first failing test"))
-    exit_group.add_argument('--test-to-end', dest="_test_to_end",
-                            action='store_true', default=None,
-                            help=("force all tests to be test to end and continue "
-                                  "the run even if one of the tests fails"))
-
-    parser.add_argument("--trace", dest="_trace",
-                        type=trace_level_type, default=None,
-                        metavar=trace_level_type.metavar,
-                        help="enable low-level test program tracing for debugging "
-                             "using Python's logging module at the specified level.")
+    exit_group.add_argument(
+        "--first-fail",
+        dest="_first_fail",
+        action="store_true",
+        default=None,
+        help=(
+            "force all tests to be first fail and abort "
+            "the run on the first failing test"
+        ),
+    )
+    exit_group.add_argument(
+        "--test-to-end",
+        dest="_test_to_end",
+        action="store_true",
+        default=None,
+        help=(
+            "force all tests to be test to end and continue "
+            "the run even if one of the tests fails"
+        ),
+    )
+
+    parser.add_argument(
+        "--trace",
+        dest="_trace",
+        type=trace_level_type,
+        default=None,
+        metavar=trace_level_type.metavar,
+        help="enable low-level test program tracing for debugging "
+        "using Python's logging module at the specified level.",
+    )
 
     if database_module:
         database_module.argparser(parser)
 
     return main_parser, test_args_schema
 
+
 def parse_cli_args(kwargs, parser_schema):
     """Parse command line arguments.
 
     :parser: argument parser
     :return: parsed known arguments
     """
     debug_processed = False
@@ -1028,51 +1462,60 @@
     # config file validation schema
     class Deprecated(schema.Hook):
         def __init__(self, *args, **kwargs):
             kwargs["handler"] = self._handler
             super(Deprecated, self).__init__(*args, **kwargs)
 
         def _handler(self, key, *args):
-            raise schema.SchemaError(f"key '{key}' is deprecated; " + (self._error or ""))
-
-    common_args_schema = schema.Schema({
-        schema.Optional("name"): str,
-        Deprecated("tag", "use 'tags' instead"): object,
-        schema.Optional("attrs"): [schema.Use(key_value_type)],
-        schema.Optional("tags"): [str],
-        schema.Optional("only"): [str],
-        schema.Optional("skip"): [str],
-        schema.Optional("start"): str,
-        schema.Optional("end"): str,
-        schema.Optional("only-tags"): [schema.Use(tags_filter_type)],
-        schema.Optional("skip-tags"): [schema.Use(tags_filter_type)],
-        schema.Optional("pause-before"): [str],
-        schema.Optional("pause-after"): [str],
-        schema.Optional("random"): bool,
-        schema.Optional("debug"): bool,
-        schema.Optional("no-colors"): bool,
-        schema.Optional("trim-results"): bool,
-        schema.Optional("colors"): bool,
-        schema.Optional("id"): str,
-        schema.Optional("output"): schema.Or(*output_formats, error="key 'output' value is not a valid format"),
-        schema.Optional("log"): str,
-        schema.Optional("show-skipped"): bool,
-        schema.Optional("show-retries"): bool,
-        schema.Optional("repeat"): [schema.Use(repeat_type)],
-        schema.Optional("retry"): [schema.Use(retry_type)],
-        schema.Optional("reference"): str,
-        schema.Optional("rerun"): schema.Or(*rerun_results, error="key 'rerun' values is not a value result"),
-        schema.Optional("individually"): bool,
-        schema.Optional("parallel"): bool,
-        schema.Optional("parallel-pool"): schema.Use(count_type),
-        schema.Optional("private-key"): schema.Use(rsa_private_key_pem_file_type),
-        schema.Optional("first-fail"): bool,
-        schema.Optional("test-to-end"): bool,
-        schema.Optional("database"): [schema.Use(key_value_type)]
-    }, ignore_extra_keys=True)
+            raise schema.SchemaError(
+                f"key '{key}' is deprecated; " + (self._error or "")
+            )
+
+    common_args_schema = schema.Schema(
+        {
+            schema.Optional("name"): str,
+            Deprecated("tag", "use 'tags' instead"): object,
+            schema.Optional("attrs"): [schema.Use(key_value_type)],
+            schema.Optional("tags"): [str],
+            schema.Optional("only"): [str],
+            schema.Optional("skip"): [str],
+            schema.Optional("start"): str,
+            schema.Optional("end"): str,
+            schema.Optional("only-tags"): [schema.Use(tags_filter_type)],
+            schema.Optional("skip-tags"): [schema.Use(tags_filter_type)],
+            schema.Optional("pause-before"): [str],
+            schema.Optional("pause-after"): [str],
+            schema.Optional("random"): bool,
+            schema.Optional("debug"): bool,
+            schema.Optional("no-colors"): bool,
+            schema.Optional("trim-results"): bool,
+            schema.Optional("colors"): bool,
+            schema.Optional("id"): str,
+            schema.Optional("output"): schema.Or(
+                *output_formats, error="key 'output' value is not a valid format"
+            ),
+            schema.Optional("log"): str,
+            schema.Optional("show-skipped"): bool,
+            schema.Optional("show-retries"): bool,
+            schema.Optional("repeat"): [schema.Use(repeat_type)],
+            schema.Optional("retry"): [schema.Use(retry_type)],
+            schema.Optional("reference"): str,
+            schema.Optional("rerun"): schema.Or(
+                *rerun_results, error="key 'rerun' values is not a value result"
+            ),
+            schema.Optional("individually"): bool,
+            schema.Optional("parallel"): bool,
+            schema.Optional("parallel-pool"): schema.Use(count_type),
+            schema.Optional("private-key"): schema.Use(rsa_private_key_pem_file_type),
+            schema.Optional("first-fail"): bool,
+            schema.Optional("test-to-end"): bool,
+            schema.Optional("database"): [schema.Use(key_value_type)],
+        },
+        ignore_extra_keys=True,
+    )
 
     try:
         args, unknown = parser.parse_known_args()
         args = vars(args)
         exc = None
         default_config = os.path.join(os.path.expanduser("~"), ".testflows.yml")
         configs = []
@@ -1094,22 +1537,24 @@
             configs.reverse()
             for config in configs:
                 obj = yaml.safe_load(config) or {}
                 test_run_args = obj.pop("test run", {})
                 try:
                     if test_args_schema:
                         if not isinstance(test_args_schema, schema.Schema):
-                            raise TypeError("argument parser returned invalid config schema")
+                            raise TypeError(
+                                "argument parser returned invalid config schema"
+                            )
                         obj = test_args_schema.validate(obj)
                     test_run_args = common_args_schema.validate(test_run_args)
                 except schema.SchemaError as e:
                     raise schema.SchemaError("in config " + str(e)) from None
-                _args = { f"_{k.replace('-','_')}" : v for k,v in test_run_args.items()}
+                _args = {f"_{k.replace('-','_')}": v for k, v in test_run_args.items()}
                 _args.update(obj)
-                _args.update({k:v for k,v in args.items() if v is not None})
+                _args.update({k: v for k, v in args.items() if v is not None})
                 args = _args
         except Exception as e:
             exc = e
         finally:
             for config in configs:
                 config.close()
 
@@ -1121,30 +1566,34 @@
 
         if unknown:
             raise ExitWithError(f"unknown argument {unknown}")
 
         settings.trace = get(args.pop("_trace", None), get(settings.trace, False))
         tracing.configure_tracing()
 
-        settings.no_colors = get(args.pop("_no_colors", None), get(settings.no_colors, False))
-        settings.trim_results = get(args.pop("_trim_results", None), get(settings.trim_results, True))
+        settings.no_colors = get(
+            args.pop("_no_colors", None), get(settings.no_colors, False)
+        )
+        settings.trim_results = get(
+            args.pop("_trim_results", None), get(settings.trim_results, True)
+        )
 
         if args.get("_name"):
             kwargs["name"] = args.pop("_name")
 
         if args.get("_id"):
             settings.test_id = args.get("_id")
             args.pop("_id")
 
         if args.get("_log"):
             logfile = os.path.abspath(args.get("_log"))
             settings.write_logfile = logfile
             args.pop("_log")
         else:
-            settings.write_logfile = templog_filename()
+            settings.write_logfile = temp_filename(extension="log")
 
         settings.read_logfile = settings.write_logfile
         if os.path.exists(settings.write_logfile):
             os.remove(settings.write_logfile)
 
         settings.output_format = args.pop("_output", None) or "nice"
 
@@ -1226,18 +1675,22 @@
 
         if args.get("_tags"):
             kwargs["tags"] = {value for value in args.pop("_tags")}
 
         if args.get("_attrs"):
             if kwargs.get("attributes", None) is None:
                 kwargs["attributes"] = []
-            kwargs["attributes"] += [Attribute(item.key, item.value) for item in args.pop("_attrs")]
+            kwargs["attributes"] += [
+                Attribute(item.key, item.value) for item in args.pop("_attrs")
+            ]
             for attr in kwargs["attributes"]:
                 if args.get(attr.name, None):
-                    raise AttributeError(f"use test argument '--{attr.name}' instead of '--attr {attr.name}=<value>'")
+                    raise AttributeError(
+                        f"use test argument '--{attr.name}' instead of '--attr {attr.name}=<value>'"
+                    )
 
         if args.get("_first_fail"):
             kwargs["first_fail"] = args.pop("_first_fail")
 
         elif args.get("_test_to_end"):
             kwargs["test_to_end"] = args.pop("_test_to_end")
 
@@ -1257,15 +1710,18 @@
                 repeats.append(item)
             kwargs["repeats"] = {r.pattern: (r.count, r.until) for r in repeats}
 
         if args.get("_retry"):
             retries = []
             for item in args.pop("_retry"):
                 retries.append(item)
-            kwargs["retries"] = {r.pattern: (r.count, r.timeout, r.delay, r.backoff, r.jitter) for r in retries}
+            kwargs["retries"] = {
+                r.pattern: (r.count, r.timeout, r.delay, r.backoff, r.jitter)
+                for r in retries
+            }
 
         if args.get("_rerun"):
             rerun_individually = args.pop("_individually", None) or False
             rerun = args.pop("_rerun")
 
             if not args.get("_reference"):
                 raise ExitWithError(f"--reference argument must be specified")
@@ -1319,30 +1775,38 @@
                     if result["result_type"] in result_types:
                         found = False
                         for rerun_test in rerun_tests:
                             if rerun_test.name.startswith(test_name):
                                 found = True
                                 break
                         if not found:
-                            rerun_tests.append(RerunTest(test_name, test_type, test_tags))
+                            rerun_tests.append(
+                                RerunTest(test_name, test_type, test_tags)
+                            )
 
                 rerun_tests.sort()
                 length = len(rerun_tests)
 
                 for i, test in enumerate(rerun_tests):
-                    if i+1 < length and rerun_tests[i+1].name.startswith(test.name):
+                    if i + 1 < length and rerun_tests[i + 1].name.startswith(test.name):
                         rerun_tests.remove(test)
                         i -= 1
 
             for rerun_test in rerun_tests:
                 if rerun_individually is True:
                     name_parts = rerun_test.name.split(name_sep)
-                    kwargs["rerun_individually"].append(RerunTest(
-                        The(join(name_sep, name_parts[1], ":", *name_parts[2:], "*")),
-                        rerun_test.type, rerun_test.tags))
+                    kwargs["rerun_individually"].append(
+                        RerunTest(
+                            The(
+                                join(name_sep, name_parts[1], ":", *name_parts[2:], "*")
+                            ),
+                            rerun_test.type,
+                            rerun_test.tags,
+                        )
+                    )
                 else:
                     kwargs["only"].append(The(join(rerun_test.name, "*")))
 
         if args.get("func"):
             func = args.pop("func")
             func(args, kwargs)
 
@@ -1350,33 +1814,37 @@
             private_key = kwargs.get("private_key")
             for name, value in args.items():
                 if isinstance(value, RSASecret):
                     value(public_key=private_key.pubkey)
 
     except (ExitException, KeyboardInterrupt, Exception) as exc:
         if not debug_processed or settings.debug:
-            sys.stderr.write(warning(get_exception(), eol='\n'))
+            sys.stderr.write(warning(get_exception(), eol="\n"))
         sys.stderr.write(danger("error: " + str(exc).strip()))
         if isinstance(exc, ExitException):
             sys.exit(exc.exitcode)
         else:
             sys.exit(1)
 
     return args
 
+
 class TestDefinition(object):
     """Test definition.
 
     :param name: name of the test
     :param **kwargs: test class arguments
     """
+
     type = TestType.Test
 
     def __new__(cls, name=None, **kwargs):
-        kwargs = {k: v.value if isinstance(v, NamedValue) else v for k,v in kwargs.items()}
+        kwargs = {
+            k: v.value if isinstance(v, NamedValue) else v for k, v in kwargs.items()
+        }
         run = kwargs.pop("run", None)
         test = kwargs.pop("test", None)
         no_arguments = None
 
         if kwargs.get("args", None):
             no_arguments = False
 
@@ -1390,40 +1858,53 @@
             return _kwargs
 
         if run:
             if isinstance(run, TestDecorator):
                 kwargs = inherit_kwargs(**run.func.kwargs)
                 kwargs["test"] = run
             elif isinstance(run, TestDefinition):
-                kwargs = inherit_kwargs(**run.kwargs, **({"name": run.name} if run.name is not None else {}))
-            elif isinstance(run, TestBase) or inspect.isclass(run) and issubclass(run, (TestBase, TestDefinition)):
+                kwargs = inherit_kwargs(
+                    **run.kwargs, **({"name": run.name} if run.name is not None else {})
+                )
+            elif (
+                isinstance(run, TestBase)
+                or inspect.isclass(run)
+                and issubclass(run, (TestBase, TestDefinition))
+            ):
                 kwargs["test"] = run
             else:
                 raise TypeError(f"'{run}' is not a valid test type")
 
         elif test:
             if isinstance(test, TestDecorator):
                 kwargs = inherit_kwargs(**test.func.kwargs)
                 kwargs["test"] = test
             elif isinstance(test, TestDefinition):
-                kwargs = inherit_kwargs(**test.kwargs, **({"name": test.name} if test.name is not None else {}))
-            elif isinstance(test, TestBase) or inspect.isclass(test) and issubclass(test, (TestBase, TestDefinition)):
+                kwargs = inherit_kwargs(
+                    **test.kwargs,
+                    **({"name": test.name} if test.name is not None else {}),
+                )
+            elif (
+                isinstance(test, TestBase)
+                or inspect.isclass(test)
+                and issubclass(test, (TestBase, TestDefinition))
+            ):
                 kwargs["test"] = test
             else:
                 raise TypeError(f"'{test}' is not a valid test type")
 
         self = cls.__create__(**kwargs)
         self.no_arguments = no_arguments
 
         if run:
             return self()
         return self
 
     @classmethod
-    def __create__(cls,  **kwargs):
+    def __create__(cls, **kwargs):
         self = super(TestDefinition, cls).__new__(cls)
         self.name = None
         self.test = None
         self.parent = None
         self.kwargs = kwargs
         self.tags = None
         self.parallel = self.kwargs.pop("parallel", None)
@@ -1434,15 +1915,17 @@
         self.repeatable_func = None
         self._with_block_frame = None
         self._enter_exc_info = None
         return self
 
     def __call__(self, *pargs, **args):
         if pargs:
-            raise TypeError(f"only named arguments are allowed but {pargs} positional arguments were passed")
+            raise TypeError(
+                f"only named arguments are allowed but {pargs} positional arguments were passed"
+            )
 
         test = self.kwargs.get("test", None)
         executor = self.kwargs.pop("executor", None)
 
         self.kwargs["args"] = dict(self.kwargs.get("args") or {})
         self.kwargs["args"].update(args)
 
@@ -1481,31 +1964,41 @@
 
         async def async_callable():
             if test and isinstance(test, TestDecorator):
                 self.repeatable_func = test
                 async with self as _test:
                     if not asyncio.iscoroutinefunction(test.func):
                         with ThreadPoolExecutor(join_on_shutdown=False) as executor:
+
                             def _wrapper(test):
                                 return test(**self.kwargs["args"])
-                            r = await asyncio.get_event_loop().run_in_executor(executor, _wrapper, (test,))
+
+                            r = await asyncio.get_event_loop().run_in_executor(
+                                executor, _wrapper, (test,)
+                            )
                     else:
                         r = await test(**self.kwargs["args"])
                     if r is not None:
                         value("return", value=r)
                 return _test.result
             else:
                 async with self as _test:
                     pass
                 return _test.result
 
         current_test = current()
         is_async = is_running_in_event_loop()
         is_parallel = self.kwargs.get("flags", Flags()) & PARALLEL or self.parallel
-        is_remote = self.kwargs.get("flags", Flags()) & REMOTE or self.remote or (executor and (isinstance(executor, RemotePoolExecutor)))
+        if is_parallel:
+            self.kwargs["flags"] = self.kwargs.pop("flags", Flags()) & ~NO_PARALLEL
+        is_remote = (
+            self.kwargs.get("flags", Flags()) & REMOTE
+            or self.remote
+            or (executor and (isinstance(executor, RemotePoolExecutor)))
+        )
 
         if current_test:
             if current_test.cflags & NO_PARALLEL:
                 pass
 
             elif is_parallel:
                 self.kwargs["flags"] = self.kwargs.pop("flags", Flags()) | PARALLEL
@@ -1514,19 +2007,25 @@
                 elif is_remote:
                     executor = settings.global_process_pool or executor
                 else:
                     executor = settings.global_thread_pool or executor
 
                 if executor is None:
                     if is_async:
-                        executor = current_test.executor or AsyncPoolExecutor(join_on_shutdown=False)
+                        executor = current_test.executor or AsyncPoolExecutor(
+                            join_on_shutdown=False
+                        )
                     elif is_remote:
-                        executor = current_test.executor or ProcessPoolExecutor(join_on_shutdown=False)
+                        executor = current_test.executor or ProcessPoolExecutor(
+                            join_on_shutdown=False
+                        )
                     else:
-                        executor = current_test.executor or ThreadPoolExecutor(join_on_shutdown=False)
+                        executor = current_test.executor or ThreadPoolExecutor(
+                            join_on_shutdown=False
+                        )
 
                     if current_test.executor is None:
                         current_test.executor = executor
 
                 if not executor.open:
                     executor.__enter__()
 
@@ -1558,21 +2057,19 @@
             if current_test:
                 current_test.futures.append(future)
             return future
 
         return callable()
 
     async def __aenter__(self):
-        """Asynchronous test start.
-        """
+        """Asynchronous test start."""
         return self.__enter__(_check_async=False)
 
     def __enter__(self, _check_async=True):
-        """Test start.
-        """
+        """Test start."""
         if _check_async and is_running_in_event_loop():
             raise RuntimeError("Use `async with` for asynchronous tests.")
 
         _check_parallel_context()
 
         try:
             kwargs = self.kwargs
@@ -1582,99 +2079,179 @@
             parent = kwargs.pop("parent", None) or current()
             keep_type = kwargs.pop("keep_type", None)
             format_name = kwargs.pop("format_name", False)
             format_description = kwargs.pop("format_description", False)
             top_test = top()
 
             if not top_test:
-                cli_args = parse_cli_args(self.kwargs, cli_argparser(self.kwargs, argparser if not isinstance(argparser, ArgumentParser) else argparser.value))
-                kwargs["args"].update({k: v for k,v in cli_args.items() if not k.startswith("_")})
+                cli_args = parse_cli_args(
+                    self.kwargs,
+                    cli_argparser(
+                        self.kwargs,
+                        argparser
+                        if not isinstance(argparser, ArgumentParser)
+                        else argparser.value,
+                    ),
+                )
+                kwargs["args"].update(
+                    {k: v for k, v in cli_args.items() if not k.startswith("_")}
+                )
 
             test = kwargs.pop("test", None)
             kwargs_test = test
             if test and isinstance(test, TestDecorator):
                 test = test.func.kwargs.get("test", None)
             test = test if test is not None else TestBase
             if not issubclass(test, TestBase):
                 raise TypeError(f"{test} must be subclass of TestBase")
 
-            name = test.make_name(kwargs.pop("name", None), parent.name if parent else None, kwargs["args"], format=format_name)
+            name = test.make_name(
+                kwargs.pop("name", None),
+                parent.name if parent else None,
+                kwargs["args"],
+                format=format_name,
+            )
             kwargs["flags"] = Flags(kwargs.get("flags"))
             kwargs["cflags"] = Flags(kwargs.get("cflags"))
 
-            if (kwargs["flags"] & PARALLEL or self.parallel) and not self.repeatable_func:
+            if (
+                kwargs["flags"] & PARALLEL or self.parallel
+            ) and not self.repeatable_func:
                 raise RuntimeError("inline test can't be executed in parallel")
 
             if parent:
                 kwargs["parent"] = parent
                 kwargs["id"] = parent.child_id()
                 kwargs["cflags"] = parent.cflags
                 # propagate manual flag if automatic test flag is not set
                 if not kwargs["flags"] & AUTO:
                     kwargs["flags"] |= parent.flags & MANUAL
                 # propagate xfails, xflags, ffails that prefix match the name of the test
-                kwargs["xfails"] = {
-                    k: v for k, v in parent.xfails.items() if match(name, k, prefix=True)
-                } if parent.xfails else None or kwargs.get("xfails")
-                kwargs["xflags"] = {
-                    k: v for k, v in parent.xflags.items() if match(name, k, prefix=True)
-                } if parent.xflags else None or kwargs.get("xflags")
-                kwargs["ffails"] = {
-                    k: v for k, v in parent.ffails.items() if match(name, k, prefix=True)
-                } if parent.ffails else None or kwargs.get("ffails")
+                kwargs["xfails"] = (
+                    {
+                        k: v
+                        for k, v in parent.xfails.items()
+                        if match(name, k, prefix=True)
+                    }
+                    if parent.xfails
+                    else None or kwargs.get("xfails")
+                )
+                kwargs["xflags"] = (
+                    {
+                        k: v
+                        for k, v in parent.xflags.items()
+                        if match(name, k, prefix=True)
+                    }
+                    if parent.xflags
+                    else None or kwargs.get("xflags")
+                )
+                kwargs["ffails"] = (
+                    {
+                        k: v
+                        for k, v in parent.ffails.items()
+                        if match(name, k, prefix=True)
+                    }
+                    if parent.ffails
+                    else None or kwargs.get("ffails")
+                )
                 # propagate only, skip, start, and end
                 kwargs["only"] = parent.only or kwargs.get("only")
                 kwargs["skip"] = parent.skip or kwargs.get("skip")
                 kwargs["start"] = parent.start or kwargs.get("start")
                 kwargs["end"] = parent.end or kwargs.get("end")
                 kwargs["only_tags"] = parent.only_tags or kwargs.get("only_tags")
                 kwargs["skip_tags"] = parent.skip_tags or kwargs.get("skip_tags")
                 # propagate repeats
-                if parent.repeats and parent.type > TestType.Outline and self.type >= TestType.Outline:
-                    kwargs["repeats"] = {
-                        k: v for k, v in parent.repeats.items() if match(name, k, prefix=True)
-                    } if parent.repeats else None or kwargs.get("repeats")
+                if (
+                    parent.repeats
+                    and parent.type > TestType.Outline
+                    and self.type >= TestType.Outline
+                ):
+                    kwargs["repeats"] = (
+                        {
+                            k: v
+                            for k, v in parent.repeats.items()
+                            if match(name, k, prefix=True)
+                        }
+                        if parent.repeats
+                        else None or kwargs.get("repeats")
+                    )
                 # propagate retries
-                if parent.retries and parent.type > TestType.Outline and self.type >= TestType.Outline:
-                    kwargs["retries"] = {
-                        k: v for k, v in parent.retries.items() if match(name, k, prefix=True)
-                    } if parent.retries else None or kwargs.get("retries")
+                if (
+                    parent.retries
+                    and parent.type > TestType.Outline
+                    and self.type >= TestType.Outline
+                ):
+                    kwargs["retries"] = (
+                        {
+                            k: v
+                            for k, v in parent.retries.items()
+                            if match(name, k, prefix=True)
+                        }
+                        if parent.retries
+                        else None or kwargs.get("retries")
+                    )
                 # handle parent test type propagation
                 if keep_type is None:
                     self._parent_type_propagation(parent, kwargs)
                 # propagate first_fail and test_to_end
                 if kwargs["type"] >= TestType.Iteration:
                     kwargs["first_fail"] = parent.first_fail or kwargs.get("first_fail")
-                    kwargs["test_to_end"] = parent.test_to_end or kwargs.get("test_to_end")
+                    kwargs["test_to_end"] = parent.test_to_end or kwargs.get(
+                        "test_to_end"
+                    )
 
             self.name = name
             self.tags = test.make_tags(kwargs.pop("tags", None))
-            self.description = test.make_description(kwargs.pop("description", None), kwargs["args"], format=format_description)
+            self.description = test.make_description(
+                kwargs.pop("description", None),
+                kwargs["args"],
+                format=format_description,
+            )
             self.parent = parent
 
             # anchor all patterns
             kwargs["xfails"] = {
-                absname(k, name if name else name_sep): v for k, v in dict(kwargs.get("xfails") or {}).items()
+                absname(k, name if name else name_sep): v
+                for k, v in dict(kwargs.get("xfails") or {}).items()
             } or None
             kwargs["xflags"] = {
-                absname(k, name if name else name_sep): v for k, v in dict(kwargs.get("xflags") or {}).items()
+                absname(k, name if name else name_sep): v
+                for k, v in dict(kwargs.get("xflags") or {}).items()
             } or None
             kwargs["ffails"] = {
-                absname(k, name if name else name_sep): v for k, v in dict(kwargs.get("ffails") or {}).items()
+                absname(k, name if name else name_sep): v
+                for k, v in dict(kwargs.get("ffails") or {}).items()
             } or None
             kwargs["repeats"] = {
-                absname(k, name if name else name_sep): v for k, v in dict(kwargs.get("repeats") or {}).items()
+                absname(k, name if name else name_sep): v
+                for k, v in dict(kwargs.get("repeats") or {}).items()
             } or None
             kwargs["retries"] = {
-                absname(k, name if name else name_sep): v for k, v in dict(kwargs.get("retries") or {}).items()
+                absname(k, name if name else name_sep): v
+                for k, v in dict(kwargs.get("retries") or {}).items()
             } or None
-            kwargs["only"] = [The(str(f)).at(name if name else name_sep) for f in kwargs.get("only") or []] or None
-            kwargs["skip"] = [The(str(f)).at(name if name else name_sep) for f in kwargs.get("skip") or []] or None
-            kwargs["start"] = The(str(kwargs.get("start"))).at(name if name else name_sep) if kwargs.get("start") else None
-            kwargs["end"] = The(str(kwargs.get("end"))).at(name if name else name_sep) if kwargs.get("end") else None
+            kwargs["only"] = [
+                The(str(f)).at(name if name else name_sep)
+                for f in kwargs.get("only") or []
+            ] or None
+            kwargs["skip"] = [
+                The(str(f)).at(name if name else name_sep)
+                for f in kwargs.get("skip") or []
+            ] or None
+            kwargs["start"] = (
+                The(str(kwargs.get("start"))).at(name if name else name_sep)
+                if kwargs.get("start")
+                else None
+            )
+            kwargs["end"] = (
+                The(str(kwargs.get("end"))).at(name if name else name_sep)
+                if kwargs.get("end")
+                else None
+            )
             kwargs["only_tags"] = kwargs.get("only_tags") or None
             kwargs["skip_tags"] = kwargs.get("skip_tags") or None
 
             self._apply_xflags(name, kwargs)
             self._apply_start(name, parent, kwargs)
             if top_test:
                 self._apply_only_tags(self.type, self.tags, kwargs)
@@ -1691,21 +2268,30 @@
             # for And subtype we change the subtype to be that of its sibling
             if kwargs.get("subtype") is TestSubType.And:
                 sibling = None
                 prev = previous()
                 if prev and depth(prev.name) == depth(name):
                     sibling = prev
                 if not sibling:
-                    raise TypeError("`And` step can't be used here as it has no sibling from which to inherit test subtype")
+                    raise TypeError(
+                        "`And` step can't be used here as it has no sibling from which to inherit test subtype"
+                    )
                 if sibling.type != kwargs["type"]:
-                    raise TypeError("`And` step can't be used here as its sibling is not of the same test type")
+                    raise TypeError(
+                        "`And` step can't be used here as its sibling is not of the same test type"
+                    )
                 kwargs["subtype"] = sibling.subtype
 
             # auto set mandatory flag for Background, Given, Finally and Cleanup steps
-            if kwargs.get("subtype") in [TestSubType.Background, TestSubType.Given, TestSubType.Finally, TestSubType.Cleanup]:
+            if kwargs.get("subtype") in [
+                TestSubType.Background,
+                TestSubType.Given,
+                TestSubType.Finally,
+                TestSubType.Cleanup,
+            ]:
                 kwargs["flags"] |= MANDATORY
 
             # auto set SETUP flag for Given steps
             if kwargs.get("subtype") in [TestSubType.Background, TestSubType.Given]:
                 kwargs["flags"] |= SETUP
 
             # auto set TE and CLEANUP flag for Finally steps
@@ -1739,42 +2325,71 @@
             kwargs["cflags"] |= kwargs["flags"] & CFLAGS
 
             self.repeats = kwargs.pop("repeats", None)
             self.retries = kwargs.pop("retries", None)
             self.rerun_individually = kwargs.pop("rerun_individually", None)
 
             if self.rerun_individually:
+
                 def transform_pattern(pattern):
                     if isabs(pattern):
                         parts = pattern.split(name_sep)
                         return join(name_sep, parts[1], ":", *parts[2:])
                     return pattern
 
                 # need to fix all anchored patterns
-                kwargs["xfails"] = {transform_pattern(k): v for k, v in
-                    (kwargs.pop("xfails", {}) or {}).items()} or None
-                kwargs["xflags"] = {transform_pattern(k): v for k, v in
-                    (kwargs.pop("xflags", {}) or {}).items()} or None
-                kwargs["ffails"] = {transform_pattern(k): v for k, v in
-                    (kwargs.pop("ffails", {}) or {}).items()} or None
-                kwargs["repeats"] = {transform_pattern(k): v for k, v in
-                    (kwargs.pop("repeats", {}) or {}).items()} or None
-                kwargs["retries"] = {transform_pattern(k): v for k, v in
-                    (kwargs.pop("retries", {}) or {}).items()} or None
-                kwargs["only"] = [The(transform_pattern(str(f))) for f in kwargs.get("only") or []] or None
-                kwargs["skip"] = [The(transform_pattern(str(f))) for f in kwargs.get("skip") or []] or None
-                kwargs["start"] = The(transform_pattern(str(kwargs.get("start")))) if kwargs.get("start") else None
-                kwargs["end"] = The(transform_pattern(str(kwargs.get("end")))) if kwargs.get("end") else None
+                kwargs["xfails"] = {
+                    transform_pattern(k): v
+                    for k, v in (kwargs.pop("xfails", {}) or {}).items()
+                } or None
+                kwargs["xflags"] = {
+                    transform_pattern(k): v
+                    for k, v in (kwargs.pop("xflags", {}) or {}).items()
+                } or None
+                kwargs["ffails"] = {
+                    transform_pattern(k): v
+                    for k, v in (kwargs.pop("ffails", {}) or {}).items()
+                } or None
+                kwargs["repeats"] = {
+                    transform_pattern(k): v
+                    for k, v in (kwargs.pop("repeats", {}) or {}).items()
+                } or None
+                kwargs["retries"] = {
+                    transform_pattern(k): v
+                    for k, v in (kwargs.pop("retries", {}) or {}).items()
+                } or None
+                kwargs["only"] = [
+                    The(transform_pattern(str(f))) for f in kwargs.get("only") or []
+                ] or None
+                kwargs["skip"] = [
+                    The(transform_pattern(str(f))) for f in kwargs.get("skip") or []
+                ] or None
+                kwargs["start"] = (
+                    The(transform_pattern(str(kwargs.get("start"))))
+                    if kwargs.get("start")
+                    else None
+                )
+                kwargs["end"] = (
+                    The(transform_pattern(str(kwargs.get("end"))))
+                    if kwargs.get("end")
+                    else None
+                )
 
             if not kwargs["cflags"] & CLEANUP:
                 if parent and parent.terminating:
                     raise TerminatedError("test has been terminated")
 
-            self.test = test(name, tags=self.tags, description=self.description,
-                repeats=self.repeats, retries=self.retries, **kwargs)
+            self.test = test(
+                name,
+                tags=self.tags,
+                description=self.description,
+                repeats=self.repeats,
+                retries=self.retries,
+                **kwargs,
+            )
 
             if getattr(self, "parent_type", None):
                 self.test.parent_type = self.parent_type
             if getattr(self, "parent_subtype", None):
                 self.test.parent_subtype = self.parent_subtype
 
             # indicate that parent is running an outline
@@ -1783,15 +2398,16 @@
                 self.test._run_outline_with_no_arguments = self.no_arguments
                 self.test._run_outline = True
 
             if self.rerun_individually is not None:
                 self.trace = sys.gettrace()
                 sys.settrace(lambda *args, **kwargs: None)
                 inspect.currentframe().f_back.f_trace = functools.partial(
-                    self.__rerun_individually__, self.rerun_individually)
+                    self.__rerun_individually__, self.rerun_individually
+                )
                 return self.test
 
             retry = None
             repeat = None
 
             if self.repeats is not None:
                 repeat = self._apply_repeats(name, self.repeats)
@@ -1806,15 +2422,16 @@
                 if not self.test.flags & NOT_REPEATABLE:
                     self.test.flags |= RETRIED
 
             if repeat is not None or retry is not None:
                 self.trace = sys.gettrace()
                 sys.settrace(lambda *args, **kwargs: None)
                 inspect.currentframe().f_back.f_trace = functools.partial(
-                    self.__repeat__, repeat, retry)
+                    self.__repeat__, repeat, retry
+                )
                 return self.test
 
         except (KeyboardInterrupt, Exception):
             raise
 
         try:
             return self.test._enter()
@@ -1908,15 +2525,17 @@
 
         for pattern, item in xflags.items():
             if match(name, pattern):
                 set_flags, clear_flags = item[:2]
                 when = item[2] if len(item) > 2 else None
                 if when is not None and not when(self.parent):
                     continue
-                kwargs["flags"] = (kwargs["flags"] & ~Flags(clear_flags)) | Flags(set_flags)
+                kwargs["flags"] = (kwargs["flags"] & ~Flags(clear_flags)) | Flags(
+                    set_flags
+                )
 
     def _parent_type_propagation(self, parent, kwargs):
         """Propagate parent test type if lower
         and not Iteration or RetryIteration.
 
         :param parent: parent
         :param kwargs: test's kwargs
@@ -1960,21 +2579,25 @@
             raise exc_value.with_traceback(exc_tb)
         self._enter_exc_info = (exc_type, exc_value, exc_tb)
 
     def _cleanup_exception(self, exc_value):
         if settings.debug:
             return
         if exc_value.__context__ is not None:
-            if isinstance(exc_value.__context__, (TestIteration, TestRerunIndividually)):
+            if isinstance(
+                exc_value.__context__, (TestIteration, TestRerunIndividually)
+            ):
                 exc_value.__suppress_context__ = True
                 return
             return self._cleanup_exception(exc_value.__context__)
 
-    def _make_complete_traceback(self, exception_traceback, frame, co_filename_filter = "testflows/"):
-        tb = namedtuple('tb', ('tb_frame', 'tb_lasti', 'tb_lineno', 'tb_next'))
+    def _make_complete_traceback(
+        self, exception_traceback, frame, co_filename_filter="testflows/"
+    ):
+        tb = namedtuple("tb", ("tb_frame", "tb_lasti", "tb_lineno", "tb_next"))
 
         def walk_frame(frame, tb_next=None):
             if frame is None:
                 return tb_next
             if not settings.debug and co_filename_filter in frame.f_code.co_filename:
                 tb_next = tb_next
             else:
@@ -1982,18 +2605,24 @@
             return walk_frame(frame.f_back, tb_next)
 
         def walk_tb(tb_frame):
             tb_next = None
             if tb_frame.tb_next:
                 tb_next = walk_tb(tb_frame.tb_next)
 
-            if tb_frame and not settings.debug and co_filename_filter in tb_frame.tb_frame.f_code.co_filename:
+            if (
+                tb_frame
+                and not settings.debug
+                and co_filename_filter in tb_frame.tb_frame.f_code.co_filename
+            ):
                 return tb_next
             else:
-                return tb(tb_frame.tb_frame, tb_frame.tb_lasti, tb_frame.tb_lineno, tb_next)
+                return tb(
+                    tb_frame.tb_frame, tb_frame.tb_lasti, tb_frame.tb_lineno, tb_next
+                )
 
         tb_next = walk_tb(exception_traceback)
         if self._with_block_frame is not None:
             # if self._with_block_frame is set it means an exception was raised
             # in __enter__() during test._enter() call. Now we need to fix
             # traceback so that includes the line where "with" block is defined
             # as it is lost
@@ -2004,16 +2633,15 @@
                 tb_next = tb_next.tb_next
             tb_next = tb(_frame, _lasti, _lineno, tb_next)
         tb_start = walk_frame(frame.f_back, tb_next)
 
         return tb_start
 
     def __exit_process_test_iteration_setup(self, exc_value):
-        """Test iteration setup.
-        """
+        """Test iteration setup."""
         repeat = exc_value.repeat
         retry = exc_value.retry
 
         self.test._enter()
 
         if self.repeatable_func is None or self.test.flags & NOT_REPEATABLE:
             raise Error("not repeatable")
@@ -2046,97 +2674,138 @@
             else:
                 # pass or complete
                 repeat_kwargs["flags"] = Flags(repeat_kwargs.get("flags")) | TE
 
         return repeat, retry, args, repeat_kwargs, retry_kwargs
 
     def __exit_process_test_iteration(self, exc_value):
-        """Process TestIteration exception.
-        """
+        """Process TestIteration exception."""
         if not isinstance(exc_value, TestIteration):
             return
 
-        repeat, retry, args, repeat_kwargs, retry_kwargs = self.__exit_process_test_iteration_setup(exc_value)
+        (
+            repeat,
+            retry,
+            args,
+            repeat_kwargs,
+            retry_kwargs,
+        ) = self.__exit_process_test_iteration_setup(exc_value)
 
         _retry = retry if retry is not None else (1,)
         _repeat = repeat if repeat is not None else (1,)
         retry_kwargs_flags = Flags(retry_kwargs.pop("flags", None))
 
-        parent_type, parent_subtype = (self.test.type, self.test.subtype) if self.test.type not in (Iteration, RetryIteration) else (self.test.parent_type, self.test.parent_subtype)
+        parent_type, parent_subtype = (
+            (self.test.type, self.test.subtype)
+            if self.test.type not in (Iteration, RetryIteration)
+            else (self.test.parent_type, self.test.parent_subtype)
+        )
 
         _repeats = repeats(*_repeat)
         while True:
             try:
-                i = _repeats.__next__(tags=self.tags,parent_type=parent_type, parent_subtype=parent_subtype, **repeat_kwargs)
+                i = _repeats.__next__(
+                    tags=self.tags,
+                    parent_type=parent_type,
+                    parent_subtype=parent_subtype,
+                    **repeat_kwargs,
+                )
             except StopIteration:
                 break
             with i if repeat is not None else NullStep() as iteration:
                 _retries = retries(*_retry)
                 while True:
                     try:
-                        r = _retries.__next__(flags=retry_kwargs_flags, tags=self.tags,
-                            parent_type=parent_type, parent_subtype=parent_subtype, **retry_kwargs)
+                        r = _retries.__next__(
+                            flags=retry_kwargs_flags,
+                            tags=self.tags,
+                            parent_type=parent_type,
+                            parent_subtype=parent_subtype,
+                            **retry_kwargs,
+                        )
                     except StopIteration:
                         break
                     with r if retry is not None else NullStep() as retry_iteration:
                         if retry_iteration is None:
                             retry_iteration = iteration
                         if isinstance(self.repeatable_func, TestOutline):
-                            retry_iteration._run_outline_with_no_arguments = self.no_arguments
+                            retry_iteration._run_outline_with_no_arguments = (
+                                self.no_arguments
+                            )
                             retry_iteration._run_outline = True
                         self.repeatable_func(**args, __run_as_func__=True)
                     if not retry:
                         break
                 if not repeat:
                     break
 
     async def __exit_async_process_test_iteration(self, exc_value):
-        """Process TestIteration exception in asyncronous test.
-        """
+        """Process TestIteration exception in asyncronous test."""
         if not isinstance(exc_value, TestIteration):
             return
 
-        repeat, retry, args, repeat_kwargs, retry_kwargs = self.__exit_process_test_iteration_setup(exc_value)
+        (
+            repeat,
+            retry,
+            args,
+            repeat_kwargs,
+            retry_kwargs,
+        ) = self.__exit_process_test_iteration_setup(exc_value)
 
         _repeat = repeat if repeat is not None else (1,)
         _retry = retry if retry is not None else (1,)
         retry_kwargs_flags = Flags(retry_kwargs.pop("flags", None))
 
-        parent_type, parent_subtype = (self.test.type, self.test.subtype) if self.test.type not in (Iteration, RetryIteration) else (self.test.parent_type, self.test.parent_subtype)
+        parent_type, parent_subtype = (
+            (self.test.type, self.test.subtype)
+            if self.test.type not in (Iteration, RetryIteration)
+            else (self.test.parent_type, self.test.parent_subtype)
+        )
 
         _repeats = repeats(*_repeat)
         while True:
             try:
-                i = _repeats.__next__(tags=self.tags, parent_type=parent_type, parent_subtype=parent_subtype, **repeat_kwargs)
+                i = _repeats.__next__(
+                    tags=self.tags,
+                    parent_type=parent_type,
+                    parent_subtype=parent_subtype,
+                    **repeat_kwargs,
+                )
             except StopIteration:
                 break
             async with i if repeat is not None else AsyncNullStep() as iteration:
                 _retries = retries(*_retry)
                 while True:
                     try:
-                        r = _retries.__next__(flags=retry_kwargs_flags, tags=self.tags,
-                            parent_type=parent_type, parent_subtype=parent_subtype, **retry_kwargs)
+                        r = _retries.__next__(
+                            flags=retry_kwargs_flags,
+                            tags=self.tags,
+                            parent_type=parent_type,
+                            parent_subtype=parent_subtype,
+                            **retry_kwargs,
+                        )
                     except StopIteration:
                         pass
                     async with r if retry is not None else AsyncNullStep() as retry_iteration:
                         if retry_iteration is None:
                             retry_iteration = iteration
                         if isinstance(self.repeatable_func, TestOutline):
-                            retry_iteration._run_outline_with_no_arguments = self.no_arguments
+                            retry_iteration._run_outline_with_no_arguments = (
+                                self.no_arguments
+                            )
                             retry_iteration._run_outline = True
                         await self.repeatable_func(**args, __run_as_func__=True)
 
                     if not retry:
                         break
                 if not repeat:
                     break
 
     def __exit_process_test_rerun_individually_iteration_setup(self, rerun_test):
-        """Setup for an iteration of running test individually.
-        """
+        """Setup for an iteration of running test individually."""
         __kwargs = dict(self.kwargs)
         __kwargs.pop("name", None)
         __kwargs.pop("parent", None)
         __kwargs["flags"] = Flags(__kwargs.get("flags")) | TE
         __kwargs["type"] = TestType.Iteration
         __args = __kwargs.pop("args", {})
 
@@ -2150,64 +2819,77 @@
         self._apply_only(rerun_name, __kwargs)
 
         __only = [rerun_test.name] + (__kwargs.pop("only", []) or [])
 
         return rerun_name, __only, __args, __kwargs
 
     def __exit_process_test_rerun_individually(self, exc_value):
-        """Process TestRerunIndividually exception.
-        """
+        """Process TestRerunIndividually exception."""
         if not isinstance(exc_value, TestRerunIndividually):
             return
 
         rerun_tests = exc_value.tests
 
         self.test._enter()
 
         if self.repeatable_func is None:
             raise Error("not repeatable")
 
         for i, rerun_test in enumerate(rerun_tests):
-            name, only, args, kwargs = self.__exit_process_test_rerun_individually_iteration_setup(rerun_test)
+            (
+                name,
+                only,
+                args,
+                kwargs,
+            ) = self.__exit_process_test_rerun_individually_iteration_setup(rerun_test)
 
             with Module(name=f"{i}", only=only, tags=self.tags, **kwargs) as iteration:
                 if isinstance(self.repeatable_func, TestOutline):
                     iteration._run_outline_with_no_arguments = self.no_arguments
                     iteration._run_outline = True
                 self.repeatable_func(**args)
 
     async def __exit_async_process_test_rerun_individually(self, exc_value):
-        """Process TestRerunIndividually exception for asynchronous test.
-        """
+        """Process TestRerunIndividually exception for asynchronous test."""
         if not isinstance(exc_value, TestRerunIndividually):
             return
 
         rerun_tests = exc_value.tests
 
         self.test._enter()
 
         if self.repeatable_func is None:
             raise Error("not repeatable")
 
         for i, rerun_test in enumerate(rerun_tests):
-            name, only, args, kwargs = self.__exit_process_test_rerun_individually_iteration_setup(rerun_test)
-
-            async with Module(name=f"{i}", only=only, tags=self.tags, **kwargs) as iteration:
+            (
+                name,
+                only,
+                args,
+                kwargs,
+            ) = self.__exit_process_test_rerun_individually_iteration_setup(rerun_test)
+
+            async with Module(
+                name=f"{i}", only=only, tags=self.tags, **kwargs
+            ) as iteration:
                 if isinstance(self.repeatable_func, TestOutline):
                     iteration._run_outline_with_no_arguments = self.no_arguments
                     iteration._run_outline = True
                 await self.repeatable_func(**args)
 
     def __exit_common(self, exc_type, exc_value, exc_traceback, test__exit__):
-        """Common async/sync test exit.
-        """
+        """Common async/sync test exit."""
         if not self.parent:
             if not test__exit__:
                 if settings.debug:
-                    sys.stderr.write(warning(get_exception(exc_type, exc_value, exc_traceback), eol='\n'))
+                    sys.stderr.write(
+                        warning(
+                            get_exception(exc_type, exc_value, exc_traceback), eol="\n"
+                        )
+                    )
                 sys.stderr.write(danger("error: " + str(exc_value).strip()))
                 sys.exit(1)
             sys.exit(0 if self.test.result else 1)
 
         if isinstance(exc_value, KeyboardInterrupt):
             raise KeyboardInterrupt from None
 
@@ -2218,29 +2900,31 @@
         if not self.test.result:
             if isinstance(self.test.result, Fail):
                 result = Fail(test=self.parent.name, message=self.test.result.message)
             else:
                 # convert Null into an Error
                 result = Error(test=self.parent.name, message=self.test.result.message)
 
-            if self.test.type == TestType.RetryIteration and LAST_RETRY not in self.test.flags:
+            if (
+                self.test.type == TestType.RetryIteration
+                and LAST_RETRY not in self.test.flags
+            ):
                 # don't raise or propagate to a parent a failing result of retry
                 # if it is not the last try
                 pass
             else:
                 if TE not in self.test.flags:
                     raise result from None
                 else:
                     self.parent.set_result(self.test.result, self.test.flags)
 
         return True
 
     def __exit__(self, exc_type, exc_value, exc_traceback):
-        """Synchronous text exit.
-        """
+        """Synchronous text exit."""
         frame = inspect.currentframe().f_back
 
         if self._enter_exc_info:
             exc_type, exc_value, exc_traceback = self._enter_exc_info
         if exc_value:
             self._cleanup_exception(exc_value)
             exc_traceback = self._make_complete_traceback(exc_traceback, frame)
@@ -2248,20 +2932,20 @@
             if isinstance(exc_value, (TestIteration, TestRerunIndividually)):
                 try:
                     self.__exit_process_test_iteration(exc_value)
                     self.__exit_process_test_rerun_individually(exc_value)
                 except:
                     try:
                         test__exit__ = self.test._exit(*sys.exc_info())
-                    except(KeyboardInterrupt, Exception):
+                    except (KeyboardInterrupt, Exception):
                         raise
                 else:
                     try:
                         test__exit__ = self.test._exit(None, None, None)
-                    except(KeyboardInterrupt, Exception):
+                    except (KeyboardInterrupt, Exception):
                         raise
             else:
                 try:
                     test__exit__ = self.test._exit(exc_type, exc_value, exc_traceback)
                 except (KeyboardInterrupt, Exception):
                     raise
 
@@ -2271,16 +2955,15 @@
             raise
 
         finally:
             if self.test:
                 self.test.terminated = True
 
     async def __aexit__(self, exc_type, exc_value, exc_traceback):
-        """Asynchronous test exit.
-        """
+        """Asynchronous test exit."""
         frame = inspect.currentframe().f_back
 
         if self._enter_exc_info:
             exc_type, exc_value, exc_traceback = self._enter_exc_info
         if exc_value:
             self._cleanup_exception(exc_value)
             exc_traceback = self._make_complete_traceback(exc_traceback, frame)
@@ -2288,234 +2971,298 @@
             if isinstance(exc_value, (TestIteration, TestRerunIndividually)):
                 try:
                     await self.__exit_async_process_test_iteration(exc_value)
                     await self.__exit_async_process_test_rerun_individually(exc_value)
                 except:
                     try:
                         test__exit__ = await self.test._async_exit(*sys.exc_info())
-                    except(KeyboardInterrupt, Exception):
+                    except (KeyboardInterrupt, Exception):
                         raise
                 else:
                     try:
                         test__exit__ = await self.test._async_exit(None, None, None)
-                    except(KeyboardInterrupt, Exception):
+                    except (KeyboardInterrupt, Exception):
                         raise
             else:
                 try:
-                    test__exit__ = await self.test._async_exit(exc_type, exc_value, exc_traceback)
+                    test__exit__ = await self.test._async_exit(
+                        exc_type, exc_value, exc_traceback
+                    )
                 except (KeyboardInterrupt, Exception):
                     raise
 
             return self.__exit_common(exc_type, exc_value, exc_traceback, test__exit__)
 
         except (Exception, KeyboardInterrupt) as exc:
             raise
 
         finally:
             if self.test:
                 self.test.terminated = True
 
+
 class Module(TestDefinition):
     """Module definition."""
+
     type = TestType.Module
 
     def __new__(cls, name=None, **kwargs):
         kwargs["type"] = TestType.Module
         return super(Module, cls).__new__(cls, name, **kwargs)
 
+
 class Suite(TestDefinition):
     """Suite definition."""
+
     type = TestType.Suite
 
     def __new__(cls, name=None, **kwargs):
         kwargs["type"] = TestType.Suite
         return super(Suite, cls).__new__(cls, name, **kwargs)
 
+
 class Outline(TestDefinition):
     """Outline definition."""
+
     type = TestType.Outline
 
     def __new__(cls, name=None, **kwargs):
         kwargs["type"] = kwargs.pop("type", cls.type)
         return super(Outline, cls).__new__(cls, name, **kwargs)
 
+
 class Test(TestDefinition):
     """Test definition."""
+
     type = TestType.Test
 
     def __new__(cls, name=None, **kwargs):
         kwargs["type"] = TestType.Test
         return super(Test, cls).__new__(cls, name, **kwargs)
 
+
 class Iteration(TestDefinition):
     """Test iteration definition."""
+
     type = TestType.Iteration
 
     def __new__(cls, name=None, **kwargs):
         kwargs["type"] = TestType.Iteration
         parent_type = kwargs.pop("parent_type", TestType.Test)
         parent_subtype = kwargs.pop("parent_subtype", None)
-        self = super(Iteration, cls).__new__(cls, name, **kwargs, parent_type=parent_type, parent_subtype=parent_subtype)
+        self = super(Iteration, cls).__new__(
+            cls, name, **kwargs, parent_type=parent_type, parent_subtype=parent_subtype
+        )
         return self
 
+
 class RetryIteration(TestDefinition):
     """Test retry iteration definition."""
+
     type = TestType.RetryIteration
 
     def __new__(cls, name=None, **kwargs):
         kwargs["type"] = TestType.RetryIteration
         parent_type = kwargs.pop("parent_type", TestType.Test)
         parent_subtype = kwargs.pop("parent_subtype", None)
-        self = super(RetryIteration, cls).__new__(cls, name, **kwargs, parent_type=parent_type, parent_subtype=parent_subtype)
+        self = super(RetryIteration, cls).__new__(
+            cls, name, **kwargs, parent_type=parent_type, parent_subtype=parent_subtype
+        )
         return self
 
+
 class Example(TestDefinition):
     """Example definition."""
+
     def __new__(cls, name=None, **kwargs):
         kwargs["type"] = kwargs.pop("type", cls.type)
         kwargs["subtype"] = TestSubType.Example
         self = super(Example, cls).__new__(cls, name, **kwargs)
         return self
 
+
 class Step(TestDefinition):
     """Step definition."""
+
     type = TestType.Step
     subtype = None
 
     def __new__(cls, name=None, **kwargs):
         kwargs["type"] = kwargs.pop("type", cls.type)
         kwargs["subtype"] = kwargs.pop("subtype", cls.subtype)
         return super(Step, cls).__new__(cls, name, **kwargs)
 
+
 # support for BDD
 class Feature(Suite):
     def __new__(cls, name=None, **kwargs):
         kwargs["subtype"] = TestSubType.Feature
         return super(Feature, cls).__new__(cls, name, **kwargs)
 
+
 class Scenario(Test):
     def __new__(cls, name=None, **kwargs):
         kwargs["subtype"] = TestSubType.Scenario
         return super(Scenario, cls).__new__(cls, name, **kwargs)
 
+
 class Check(Test):
     def __new__(cls, name=None, **kwargs):
         kwargs["subtype"] = TestSubType.Check
         return super(Check, cls).__new__(cls, name, **kwargs)
 
+
 class Critical(Test):
     def __new__(cls, name=None, **kwargs):
         kwargs["subtype"] = TestSubType.Critical
         return super(Critical, cls).__new__(cls, name, **kwargs)
 
+
 class Major(Test):
     def __new__(cls, name=None, **kwargs):
         kwargs["subtype"] = TestSubType.Major
         return super(Major, cls).__new__(cls, name, **kwargs)
 
+
 class Minor(Test):
     def __new__(cls, name=None, **kwargs):
         kwargs["subtype"] = TestSubType.Minor
         return super(Minor, cls).__new__(cls, name, **kwargs)
 
+
 class Background(Step):
     subtype = TestSubType.Background
 
+
 class Given(Step):
     subtype = TestSubType.Given
 
+
 class When(Step):
     subtype = TestSubType.When
 
+
 class Then(Step):
     subtype = TestSubType.Then
 
+
 class And(Step):
     subtype = TestSubType.And
 
+
 class But(Step):
     subtype = TestSubType.But
 
+
 class By(Step):
     subtype = TestSubType.By
 
+
 class Finally(Step):
     subtype = TestSubType.Finally
 
+
 class Cleanup(Step):
     subtype = TestSubType.Cleanup
 
-class NullStep():
+
+class NullStep:
     def __enter__(self):
         return None
 
     def __exit__(self, *args, **kwargs):
         return False
 
-class AsyncNullStep():
+
+class AsyncNullStep:
     async def __aenter__(self):
         return None
 
     async def __aexit__(self, *args, **kwargs):
         return False
 
+
 # decorators
 class TestDecorator(object):
     type = Test
 
     def __init__(self, func):
         self.func = func
 
         self.func.type = self.type.type
-        self.func.name = getattr(self.func, "name", self.func.__name__.replace("_", " "))
+        self.func.name = getattr(
+            self.func, "name", self.func.__name__.replace("_", " ")
+        )
         self.func.description = getattr(self.func, "description", self.func.__doc__)
         self.func.module = ".".join([self.func.__module__, self.func.__name__])
 
         signature = inspect.signature(self.func)
 
         args = getattr(self.func, "args", {})
-        default_args = {p.name: p.default for p in signature.parameters.values() if
-            p.default != inspect.Parameter.empty}
+        default_args = {
+            p.name: p.default
+            for p in signature.parameters.values()
+            if p.default != inspect.Parameter.empty
+        }
 
         self.func.args = default_args
         self.func.args.update(args)
 
         kwargs = dict(vars(self.func))
 
         self.func.kwargs = kwargs
 
         if asyncio.iscoroutinefunction(self.func):
-            self.func.kwargs["flags"] = Flags(self.func.kwargs.pop("flags", None)) | ASYNC
+            self.func.kwargs["flags"] = (
+                Flags(self.func.kwargs.pop("flags", None)) | ASYNC
+            )
 
         _type = self.type
         functools.update_wrapper(self, self.func)
+
         self.type = _type
 
+        action = getattr(self.func, "action", None)
+        if action is not None:
+            _, _, action_map = action
+            if action_map is not None:
+                action_map.add(self)
+
     def __call__(self, *pargs, **args):
         if pargs:
-            raise TypeError(f"only named arguments are allowed but {pargs} positional arguments were passed")
+            raise TypeError(
+                f"only named arguments are allowed but {pargs} positional arguments were passed"
+            )
 
         if is_running_in_event_loop():
-            if not (asyncio.iscoroutinefunction(self.func) or inspect.isasyncgenfunction(self.func)):
+            if not (
+                asyncio.iscoroutinefunction(self.func)
+                or inspect.isasyncgenfunction(self.func)
+            ):
                 with ThreadPoolExecutor(join_on_shutdown=False) as executor:
+
                     def _wrapper():
                         return self.__run__(**args)
+
                     r = asyncio.get_event_loop().run_in_executor(executor, _wrapper)
                     current().futures.append(r)
                     return r
 
-        if asyncio.iscoroutinefunction(self.func) or inspect.isasyncgenfunction(self.func):
+        if asyncio.iscoroutinefunction(self.func) or inspect.isasyncgenfunction(
+            self.func
+        ):
+
             async def _runner():
                 return await self.__run__(**args)
 
             if not is_running_in_event_loop():
                 current_test = current()
                 executor = current_test.executor if current_test else None
                 if not isinstance(executor, AsyncPoolExecutor):
-                     with AsyncPoolExecutor(join_on_shutdown=False) as executor:
+                    with AsyncPoolExecutor(join_on_shutdown=False) as executor:
                         return executor.submit(_runner).result()
                 else:
                     executor = settings.global_async_pool or executor
 
                     if not executor.open:
                         executor.__enter__()
 
@@ -2545,22 +3292,32 @@
             return r
 
         def run(test):
             return process_func_result(self.func(test, **args))
 
         test_running_outline = getattr(test, "_run_outline", False)
 
-        if (test is None
-                or (test and test.type > self.type.type and self.type.type != TestType.Outline)
-                or (test and test_running_outline)) and not (test and _run_as_func):
+        if (
+            test is None
+            or (
+                test
+                and test.type > self.type.type
+                and self.type.type != TestType.Outline
+            )
+            or (test and test_running_outline)
+        ) and not (test and _run_as_func):
             kwargs = dict(self.func.kwargs)
 
             if isinstance(self, TestOutline):
-                no_arguments = not args or getattr(test, "_run_outline_with_no_arguments", False)
-                examples = test_running_outline and getattr(test, "examples") or self.examples
+                no_arguments = not args or getattr(
+                    test, "_run_outline_with_no_arguments", False
+                )
+                examples = (
+                    test_running_outline and getattr(test, "examples") or self.examples
+                )
 
                 if no_arguments and examples:
                     kwargs["args"] = {}
                     kwargs.pop("test", None)
 
                     _test_type = self.type(**kwargs, test=self)
 
@@ -2571,15 +3328,18 @@
                             _kwargs["args"] = dict(kwargs.get("args", {}))
                             _kwargs["args"].update(vars(example))
                             _kwargs.update(dict(examples.args))
                             _kwargs.update(dict(example._args))
                             _kwargs.pop("type", None)
                             _kwargs.pop("examples", None)
 
-                            if _test.type in (TestType.Iteration, TestType.RetryIteration):
+                            if _test.type in (
+                                TestType.Iteration,
+                                TestType.RetryIteration,
+                            ):
                                 type = _test.parent_type
                             else:
                                 type = _test.type
 
                             _example_type = Example(type=type, **_kwargs)
 
                             def execute_example(**args):
@@ -2608,14 +3368,15 @@
                         return self.type(**kwargs, test=self)(**args)
             else:
                 kwargs.pop("test", None)
                 return self.type(**kwargs, test=self)(**args)
         else:
             return run(test)
 
+
 class TestStep(TestDecorator):
     type = Step
     subtype = None
 
     def __init__(self, func_or_subtype=None):
         self.func = None
 
@@ -2633,14 +3394,15 @@
             if self.subtype is not None:
                 self.func.subtype = self.subtype
             TestDecorator.__init__(self, self.func)
             return self
 
         return super(TestStep, self).__call__(*args, **kwargs)
 
+
 class TestOutline(TestDecorator):
     type = Outline
 
     def __init__(self, func_or_type=None):
         self.func = None
         self.examples = None
 
@@ -2662,53 +3424,64 @@
             self.func = args[0]
             self._init_func()
             TestDecorator.__init__(self, self.func)
             return self
 
         return super(TestOutline, self).__call__(*args, **kwargs)
 
+
 class TestCase(TestDecorator):
     type = Test
 
+
 class TestScenario(TestCase):
     type = Scenario
 
+
 class TestCheck(TestCase):
     type = Check
 
+
 class TestCritical(TestCase):
     type = Critical
 
+
 class TestMajor(TestCase):
     type = Major
 
+
 class TestMinor(TestCase):
     type = Minor
 
+
 class TestSuite(TestDecorator):
     type = Suite
 
+
 class TestFeature(TestSuite):
     type = Feature
 
+
 class TestModule(TestDecorator):
     type = Module
 
+
 class TestBackground(TestDecorator):
     type = Background
 
+
 def ordered(tests):
-    """Return ordered list of tests.
-    """
+    """Return ordered list of tests."""
     if settings.random_order:
         random.shuffle(tests)
     else:
         human_sort(tests, key=lambda test: test.__name__)
     return tests
 
+
 def loads(name, *types, package=None, frame=None, filter=None):
     """Load multiple tests from module.
 
     :param name: module name or module
     :param *types: test types (Step, Test, Scenario, Suite, Feature, or Module), default: all
     :param package: package name if module name is relative (optional)
     :param frame: caller frame if module name is not specified (optional)
@@ -2733,14 +3506,15 @@
     tests = ordered([test for name, test in inspect.getmembers(module, is_type)])
 
     if filter:
         return builtins.filter(filter, tests)
 
     return tests
 
+
 class retries(object):
     """Retries object to retry some piece of inline code until it succeeds
     and no exception is raised.
 
     ```python
     for retry in retries(timeout=30, delay=0):
         with retry:
@@ -2751,15 +3525,18 @@
     :param timeout: timeout in sec, default: None
     :param delay: delay in sec between retries, default: 0 sec
     :param backoff: backoff multiplier that is applied to the delay, default: 1
     :param jitter: jitter added to delay between retries specified as
                    a tuple(min, max), default: (0,0)
     :param initial_delay: initial delay in sec before first attempt, default: 0 sec
     """
-    def __init__(self, count=None, timeout=None, delay=0, backoff=1, jitter=None, initial_delay=0):
+
+    def __init__(
+        self, count=None, timeout=None, delay=0, backoff=1, jitter=None, initial_delay=0
+    ):
         self.count = int(count) if count is not None else None
         self.timeout = float(timeout) if timeout is not None else None
         self.delay = float(delay)
         self.initial_delay = float(initial_delay)
         self.backoff = backoff
         self.jitter = tuple(jitter) if jitter else tuple([0, 0])
         self.delay_with_backoff = self.delay
@@ -2773,16 +3550,26 @@
         self.number = -1
         self.started = None
         return self
 
     def __next__(self, **kwargs):
         flags = kwargs.pop("flags", Flags())
         current_type = current().type
-        parent_type = kwargs.pop("parent_type", current_type if current_type not in (Iteration, RetryIteration) else current().parent_type)
-        parent_subtype = kwargs.pop("parent_subtype", current_type if current_type not in (Iteration, RetryIteration) else current().parent_subtype)
+        parent_type = kwargs.pop(
+            "parent_type",
+            current_type
+            if current_type not in (Iteration, RetryIteration)
+            else current().parent_type,
+        )
+        parent_subtype = kwargs.pop(
+            "parent_subtype",
+            current_type
+            if current_type not in (Iteration, RetryIteration)
+            else current().parent_subtype,
+        )
 
         if self.retry is not None:
             if self.retry.test is not None:
                 if isinstance(self.retry.test.result, NonFailResults):
                     raise StopIteration
 
         if self.started and self.delay_with_backoff:
@@ -2794,33 +3581,46 @@
                 delay += random.uniform(*self.jitter)
 
             if self.timeout is not None:
                 delay = min(delay, max(0, self.timeout - (time.time() - self.started)))
 
             time.sleep(delay)
 
-        if self.started and self.timeout is not None and time.time() - self.started >= self.timeout:
+        if (
+            self.started
+            and self.timeout is not None
+            and time.time() - self.started >= self.timeout
+        ):
             flags |= LAST_RETRY
             flags &= ~TE
 
         if not self.started:
             self.started = time.time()
             time.sleep(self.initial_delay)
 
         self.number += 1
 
         if self.count is not None and self.count <= self.number + 1:
             flags |= LAST_RETRY
             flags &= ~TE
 
-        self.retry = RetryIteration(f"try #{self.number}", flags=flags, parent_type=parent_type, parent_subtype=parent_subtype, **kwargs)
+        self.retry = RetryIteration(
+            f"try #{self.number}",
+            flags=flags,
+            parent_type=parent_type,
+            parent_subtype=parent_subtype,
+            **kwargs,
+        )
 
         return self.retry
 
-def retry(func, count=None, timeout=None, delay=0, backoff=1, jitter=None, initial_delay=0):
+
+def retry(
+    func, count=None, timeout=None, delay=0, backoff=1, jitter=None, initial_delay=0
+):
     """Retry function.
 
     For example,
 
     ```python
     retry(my_func, count=5, timeout=30)(*my_args, **kwargs)
     ```
@@ -2830,30 +3630,46 @@
     :param timeout: timeout in sec, default: None
     :param delay: delay in sec between retries, default: 0 sec
     :param backoff: backoff multiplier that is applied to the delay, default: 1
     :param jitter: jitter added to delay between retries specified as
                    a tuple(min, max), default: (0,0)
     :param initial_delay: initial delay in sec before first attempt, default: 0 sec
     """
+
     @functools.wraps(func)
     def wrapper(*args, **kwargs):
-        for _retry in retries(count=count, timeout=timeout, delay=delay, backoff=backoff, jitter=jitter, initial_delay=initial_delay):
+        for _retry in retries(
+            count=count,
+            timeout=timeout,
+            delay=delay,
+            backoff=backoff,
+            jitter=jitter,
+            initial_delay=initial_delay,
+        ):
             with _retry:
                 return func(*args, **kwargs)
 
     @functools.wraps(func)
     async def async_wrapper(*args, **kwargs):
-        for _retry in retries(count=count, timeout=timeout, delay=delay, backoff=backoff, jitter=jitter, initial_delay=initial_delay):
+        for _retry in retries(
+            count=count,
+            timeout=timeout,
+            delay=delay,
+            backoff=backoff,
+            jitter=jitter,
+            initial_delay=initial_delay,
+        ):
             async with _retry:
                 return func(*args, **kwargs)
 
     if is_running_in_event_loop():
         return async_wrapper
     return wrapper
 
+
 class repeats(object):
     """Repeat object to repeat some piece of inline code until it succeeds.
 
     ```python
     for iteration in repeats(count=30, until="complete", delay=0):
         with iteration:
             my_code()
@@ -2884,25 +3700,39 @@
         self.number = -1
         self.started = None
         return self
 
     def __next__(self, **kwargs):
         flags = kwargs.pop("flags", Flags())
         current_type = current().type
-        parent_type = kwargs.pop("parent_type", current_type if current_type not in (Iteration, RetryIteration) else current().parent_type)
-        parent_subtype = kwargs.pop("parent_subtype", current_type if current_type not in (Iteration, RetryIteration) else current().parent_subtype)
+        parent_type = kwargs.pop(
+            "parent_type",
+            current_type
+            if current_type not in (Iteration, RetryIteration)
+            else current().parent_type,
+        )
+        parent_subtype = kwargs.pop(
+            "parent_subtype",
+            current_type
+            if current_type not in (Iteration, RetryIteration)
+            else current().parent_subtype,
+        )
 
         if self.until in ("pass", "complete"):
-            flags |=  TE
+            flags |= TE
 
         if self.iteration is not None:
             if self.iteration.test is not None:
-                if self.until == "pass" and isinstance(self.iteration.test.result, NonFailResults):
+                if self.until == "pass" and isinstance(
+                    self.iteration.test.result, NonFailResults
+                ):
                     raise StopIteration
-                elif self.until == "fail" and isinstance(self.iteration.test.result, FailResults):
+                elif self.until == "fail" and isinstance(
+                    self.iteration.test.result, FailResults
+                ):
                     raise StopIteration
                 elif self.number + 1 == self.count:
                     raise StopIteration
 
         if self.started and self.delay_with_backoff:
             if self.backoff:
                 self.delay_with_backoff *= self.backoff
@@ -2917,18 +3747,25 @@
             self.started = time.time()
 
         self.number += 1
 
         if self.count is not None and self.count <= self.number + 1:
             flags &= ~TE
 
-        self.iteration = Iteration(f"run #{self.number}", flags=flags, parent_type=parent_type, parent_subtype=parent_subtype, **kwargs)
+        self.iteration = Iteration(
+            f"run #{self.number}",
+            flags=flags,
+            parent_type=parent_type,
+            parent_subtype=parent_subtype,
+            **kwargs,
+        )
 
         return self.iteration
 
+
 def repeat(func, count=None, until="complete", delay=0, backoff=1, jitter=None):
     """Repeat function and return a list of the results for each iteration.
 
     For example,
 
     ```python
     repeat(my_func, count=5, until="complete")(*my_args, **kwargs)
@@ -2939,47 +3776,53 @@
     :param until: stop condition, either 'pass', 'fail', or 'complete', default: 'complete'
     :param timeout: timeout in sec, default: None
     :param delay: delay in sec between iterations, default: 0 sec
     :param backoff: backoff multiplier that is applied to the delay, default: 1
     :param jitter: jitter added to delay between repeats specified as
                    a tuple(min, max), default: (0,0)
     """
+
     @functools.wraps(func)
     def wrapper(*args, **kwargs):
         results = []
-        for _iter in repeats(count=count, until=until, delay=delay, backoff=backoff, jitter=jitter):
+        for _iter in repeats(
+            count=count, until=until, delay=delay, backoff=backoff, jitter=jitter
+        ):
             with _iter:
                 try:
                     results.append(func(*args, **kwargs))
                 except Exception as e:
                     results.append(e)
                     raise
         return results
 
     @functools.wraps(func)
     async def async_wrapper(*args, **kwargs):
         results = []
-        for _iter in repeats(count=count, until=until, delay=delay, backoff=backoff, jitter=jitter):
+        for _iter in repeats(
+            count=count, until=until, delay=delay, backoff=backoff, jitter=jitter
+        ):
             async with _iter:
                 try:
                     results.append(func(*args, **kwargs))
                 except Exception as e:
                     results.append(e)
                     raise
         return results
 
     if is_running_in_event_loop():
         return async_wrapper
     return wrapper
 
+
 def define(name, value, encoder=str, type=By, name_prefix="defining "):
     """Adds `By` step to define a value.
 
     :param name: name of the value
     :param value: value
     :param encoder: string encoder, default: str() function
     :param type: test type, default: By
     :param name_prefix: name prefix, default: 'defining '
     :return: value
     """
     with type(f"{name_prefix}{name}", description=f"{encoder(value)}"):
-       return value
+        return value
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/testtype.py` & `testflows.core-1.9.230627.1151633/testflows/_core/testtype.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,29 +10,33 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from .utils.enum import IntEnum
 
+
 class TestType(IntEnum):
     """Test type."""
+
     Module = 40
     Suite = 30
     Test = 20
     Outline = 17
     Iteration = 15
     RetryIteration = 14
     Step = 10
 
+
 class TestSubType(IntEnum):
     """Test behaviour subtype."""
+
     Book = 70
     Feature = 60
-    Chapter  = 55
+    Chapter = 55
     Scenario = 50
     Document = 48
     Section = 47
     Page = 46
     Example = 45
     Background = 40
     Recipe = 35
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/tracing.py` & `testflows.core-1.9.230627.1151633/testflows/_core/tracing.py`

 * *Files 14% similar despite different names*

```diff
@@ -27,129 +27,142 @@
 import multiprocessing.managers
 
 import testflows.settings as settings
 
 from queue import Queue, Empty as EmptyQueue
 from logging import *
 
+
 def uid():
-    """Get unique id.
-    """
+    """Get unique id."""
     return str(uuid.uuid1())
 
+
 class Action:
     START = "start"
     END = "end"
 
+
 class LoggerAdapter(LoggerAdapter):
-    """Logger adapter that preserves message extra.
-    """
+    """Logger adapter that preserves message extra."""
+
     def process(self, msg, kwargs):
         kwargs_extra = kwargs.get("extra", {})
         kwargs["extra"] = dict(self.extra)
         kwargs["extra"].update(kwargs_extra)
         return msg, kwargs
 
+
 @contextlib.contextmanager
 def Event(tracer, name, source=None, event_id=None):
     if event_id is None:
         event_id = uid()
-    
+
     event_tracer = EventAdapter(tracer, name, source=source, event_id=event_id)
     try:
         event_tracer.debug(f"start", extra={"event_action": Action.START})
         yield event_tracer
     except BaseException as exc:
         event_tracer.exception(exc)
         raise
     finally:
         event_tracer.debug(f"end", extra={"event_action": Action.END})
 
+
 def EventAdapter(tracer, name, source=None, event_id=None):
-    """Event adapter.
-    """
+    """Event adapter."""
     if event_id is None:
         event_id = uid()
 
     if hasattr(tracer, "extra") and tracer.extra.get("event_name"):
         if name:
             name = f"{tracer.extra['event_name']}.{name}"
         else:
-            name = tracer.extra['event_name']
-    
+            name = tracer.extra["event_name"]
+
     if hasattr(tracer, "extra") and tracer.extra.get("event_source"):
         if source:
             source = f"{tracer.extra['event_source']}.{source}"
         else:
-            source = tracer.extra['event_source']
+            source = tracer.extra["event_source"]
+
+    return LoggerAdapter(
+        tracer, {"event_id": event_id, "event_name": name, "event_source": source}
+    )
 
-    return LoggerAdapter(tracer, {"event_id": event_id, "event_name": name, "event_source": source})
 
 def TestAdapter(tracer, test):
-    """Test adapter.
-    """
+    """Test adapter."""
     return LoggerAdapter(tracer, {"test": test.name, "test_id": test.id_str})
 
+
 class JSONFormatter(logging.Formatter):
-    """JSON formatter.
-    """
+    """JSON formatter."""
+
     def __init__(self, *args, indent=None, **kwargs):
         self.indent = indent
         super(JSONFormatter, self).__init__(*args, **kwargs)
 
     def format(self, record):
-        return json.dumps({k:v for k,v in record.__dict__.items() if k not in ("msg",)}, indent=self.indent, sort_keys=True)
+        return json.dumps(
+            {k: v for k, v in record.__dict__.items() if k not in ("msg",)},
+            indent=self.indent,
+            sort_keys=True,
+        )
+
 
 class TestFilter(logging.Filter):
-    """Test filter.
-    """
+    """Test filter."""
+
     def __init__(self, test, *args, **kwargs):
         self.test = test.name
         self.test_id = test.id_str
         super(TestFilter, self).__init__(*args, **kwargs)
 
     def filter(self, record):
-        """Filter that adds extra fields to each log record.
-        """
+        """Filter that adds extra fields to each log record."""
         record.test = self.test
         record.test_id = self.test_id
         return True
 
+
 class RecordFilter(logging.Filter):
-    """Record filter.
-    """
+    """Record filter."""
+
     def __init__(self, *args, **kwargs):
         self.hostname = platform.node()
         self.pid = os.getpid()
         self.process_name = multiprocessing.current_process().name
         self.process_command = " ".join(sys.argv)
         self.time = time.time
-        self.thread_ident =  threading.get_ident
+        self.thread_ident = threading.get_ident
         self.thread = threading.current_thread
 
         super(RecordFilter, self).__init__(*args, **kwargs)
 
     def filter(self, record):
-        """Filter that adds extra fields to each log record.
-        """
+        """Filter that adds extra fields to each log record."""
         record.thread = self.thread_ident()
         record.threadName = self.thread().name
         record.hostname = self.hostname
         record.process = self.pid
         record.processName = self.process_name
         record.processCommand = self.process_command
         return True
 
+
 class Manager(multiprocessing.managers.SyncManager):
     pass
 
+
 class BufferedQueueHandler(logging.handlers.QueueHandler):
-    """Buffered queue handler that batches 
+    """Buffered queue handler that batches
     records to improve throughput over remote queues.
     """
+
     def __init__(self, queue, flush_interval=1, flush_level=logging.CRITICAL):
         """
         Initialise an instance, using the passed queue.
         """
         self.buffer = []
         self.flush_level = flush_level
         self.flush_interval = flush_interval
@@ -164,15 +177,15 @@
         try:
             self.flush_time = time.time()
             if self.buffer:
                 self.queue.put_nowait(self.buffer)
                 self.buffer = []
         finally:
             self.release()
-            
+
     def close(self):
         """
         Close the handler.
 
         This version just flushes and chains to the parent class' close().
         """
         try:
@@ -185,64 +198,67 @@
         Enqueue a record.
 
         The base implementation uses put_nowait. You may want to override
         this method if you want to use blocking, timeouts or custom queue
         implementations.
         """
         self.buffer.append(record)
-        if ((time.time() - self.flush_time >= self.flush_interval) or
-            (record.levelno >= self.flush_level)):
+        if (time.time() - self.flush_time >= self.flush_interval) or (
+            record.levelno >= self.flush_level
+        ):
             self.flush()
 
+
 class BufferedQueueListener(logging.handlers.QueueListener):
     """Buffered queue listener that can be paired
     with BufferedQueueHandler to process batched records.
     """
+
     def _monitor(self):
         """
         Monitor the queue for records, and ask the handler
         to deal with them.
 
         This method runs on a separate, internal thread.
         The thread will terminate if it sees a sentinel object in the queue.
         """
         q = self.queue
-        has_task_done = hasattr(q, 'task_done')
+        has_task_done = hasattr(q, "task_done")
         while True:
             try:
                 records = self.dequeue(True)
                 if records is self._sentinel:
                     if has_task_done:
                         q.task_done()
                     break
                 for record in records:
                     self.handle(record)
                 if has_task_done:
                     q.task_done()
             except EmptyQueue:
                 break
 
+
 def configure_tracing(main=True, tracer=None):
-    """Configure tracing logger.
-    """   
+    """Configure tracing logger."""
     if tracer is None:
         tracer = getLogger("testflows")
 
     if not settings.trace:
         tracer.setLevel(logging.CRITICAL + 1)
         return
 
     if main:
-        queue = Queue()  
-        Manager.register("trace_queue", callable=lambda:queue)
+        queue = Queue()
+        Manager.register("trace_queue", callable=lambda: queue)
     else:
         Manager.register("trace_queue")
 
-    manager = Manager(address=('', 3360), authkey=b'abc')
-    
+    manager = Manager(address=("", 3360), authkey=b"abc")
+
     if main:
         manager.start()
     else:
         manager.connect()
 
     queue = manager.trace_queue()
 
@@ -250,20 +266,20 @@
     queue_handler.addFilter(RecordFilter())
 
     tracer.addHandler(queue_handler)
 
     if main:
         file_handler = logging.FileHandler("trace.log", mode="w", encoding="utf-8")
         file_handler.setFormatter(JSONFormatter(indent=None))
-        queue_listener_handler = BufferedQueueListener(queue, file_handler) 
+        queue_listener_handler = BufferedQueueListener(queue, file_handler)
         queue_listener_handler.start()
 
         def _atexit():
             queue_listener_handler.stop()
             queue_handler.close()
             manager.shutdown()
-        
+
         atexit.register(_atexit)
 
     tracer.setLevel(settings.trace)
 
-    return tracer
+    return tracer
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/brisk.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/brisk.py`

 * *Files 6% similar despite different names*

```diff
@@ -23,34 +23,38 @@
 from testflows._core.message import Message
 from testflows._core.objects import ExamplesTable
 from testflows._core.utils.timefuncs import strftime, strftimedelta
 from testflows._core.utils.timefuncs import localfromtimestamp
 from testflows._core.name import split, basename, parentname, sep
 from testflows._core.cli.colors import color, cursor_up
 
-strip_nones = re.compile(r'( None)+$')
+strip_nones = re.compile(r"( None)+$")
 indent = " " * 2
 #: map of tests by name
 tests_by_name = {}
 #: map of tests by parent
 tests_by_parent = {}
 #: map of parent of the test type by name
 test_type_parent_by_name = {}
 #: last message
 last_message = [None]
 
+
 def color_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold"])
 
+
 def color_secondary_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold", "dim"])
 
+
 def color_other(other):
     return color(other, "white", attrs=["dim"])
 
+
 def color_result(result, attrs=None, retry=False):
     if attrs is None:
         attrs = ["bold"]
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=attrs)
     elif result == "OK":
         return functools.partial(color, color="green", attrs=attrs)
@@ -63,158 +67,254 @@
     elif result == "Fail":
         return functools.partial(color, color="red", attrs=attrs)
     elif result == "Null":
         return functools.partial(color, color="magenta", attrs=attrs)
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def format_prompt(msg, keyword):
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
     out = color(icon + lines[0], "yellow", attrs=["bold"])
     if len(lines) > 1:
         out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"])
     return out
 
+
 def format_input(msg, keyword):
-    out = color(msg['message'], "white") + "\n"
+    out = color(msg["message"], "white") + "\n"
     return out
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
     out = textwrap.indent(out, indent + "  ")
     return out
 
+
 def format_test_description(msg, indent):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     desc = format_multiline(msg["test_description"], indent)
     desc = color(desc, "white", attrs=["dim"])
     return desc + "\n"
 
+
 def format_requirements(msg, indent):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     out = [f"{indent}{' ' * 2}{color_secondary_keyword('Requirements')}"]
     for req in msg.requirements:
         out.append(color(f"{indent}{' ' * 4}{req.name}", "white", attrs=["dim"]))
-        out.append(color(f"{indent}{' ' * 6}version {req.version}", "white", attrs=["dim"]))
+        out.append(
+            color(f"{indent}{' ' * 6}version {req.version}", "white", attrs=["dim"])
+        )
     return "\n".join(out) + "\n"
 
+
 def format_attribute(msg):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name:
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Attributes')}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['attribute_name']}", "white", attrs=["dim"]))
-    out.append(color(f"{textwrap.indent(str(msg['attribute_value']), prefix=(_indent + ' ' * 6))}", "white", attrs=["dim"]))
+    out.append(
+        color(f"{_indent}{' ' * 4}{msg['attribute_name']}", "white", attrs=["dim"])
+    )
+    out.append(
+        color(
+            f"{textwrap.indent(str(msg['attribute_value']), prefix=(_indent + ' ' * 6))}",
+            "white",
+            attrs=["dim"],
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_specification(msg):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name:
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Specifications')}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['specification_name']}", "white", attrs=["dim"]))
+    out.append(
+        color(f"{_indent}{' ' * 4}{msg['specification_name']}", "white", attrs=["dim"])
+    )
     if msg["specification_version"]:
-        out.append(color(f"{_indent}{' ' * 6}version {msg['specification_version']}", "white", attrs=["dim"]))
+        out.append(
+            color(
+                f"{_indent}{' ' * 6}version {msg['specification_version']}",
+                "white",
+                attrs=["dim"],
+            )
+        )
     return "\n".join(out) + "\n"
 
+
 def format_requirement(msg):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name:
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Requirements')}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['requirement_name']}", "white", attrs=["dim"]))
-    out.append(color(f"{_indent}{' ' * 6}version {msg['requirement_version']}", "white", attrs=["dim"]))
+    out.append(
+        color(f"{_indent}{' ' * 4}{msg['requirement_name']}", "white", attrs=["dim"])
+    )
+    out.append(
+        color(
+            f"{_indent}{' ' * 6}version {msg['requirement_version']}",
+            "white",
+            attrs=["dim"],
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_tag(msg):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
     if last_message[0] and not last_message[0]["message_keyword"] == Message.TAG.name:
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Tags')}"]
 
     out.append(color(f"{_indent}{' ' * 4}{msg['tag_value']}", "white", attrs=["dim"]))
     return "\n".join(out) + "\n"
 
+
 def format_example(msg):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(msg["example_columns"], msg["example_values"])
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.EXAMPLE.name:
+    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(
+        msg["example_columns"], msg["example_values"]
+    )
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.EXAMPLE.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Examples')}"]
-        out.append(color(textwrap.indent(f"{ExamplesTable.__str_header__(tuple(msg['example_columns']), row_format)}", prefix=f"{_indent}{' ' * 4}"), "white", attrs=["dim"]))
-
-    out.append(color(textwrap.indent(f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}", prefix=f"{_indent}{' ' * 4}"), "white", attrs=["dim"]))
+        out.append(
+            color(
+                textwrap.indent(
+                    f"{ExamplesTable.__str_header__(tuple(msg['example_columns']), row_format)}",
+                    prefix=f"{_indent}{' ' * 4}",
+                ),
+                "white",
+                attrs=["dim"],
+            )
+        )
+
+    out.append(
+        color(
+            textwrap.indent(
+                f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}",
+                prefix=f"{_indent}{' ' * 4}",
+            ),
+            "white",
+            attrs=["dim"],
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_argument(msg):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.ARGUMENT.name:
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ARGUMENT.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Arguments')}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['argument_name']}", "white", attrs=["dim"]))
-    out.append(color(textwrap.indent(f"{msg['argument_value']}", prefix=f"{_indent}{' ' * 6}"), "white", attrs=["dim"]))
+    out.append(
+        color(f"{_indent}{' ' * 4}{msg['argument_name']}", "white", attrs=["dim"])
+    )
+    out.append(
+        color(
+            textwrap.indent(f"{msg['argument_value']}", prefix=f"{_indent}{' ' * 6}"),
+            "white",
+            attrs=["dim"],
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def and_keyword(msg, parent_id, keyword, subtype):
     """Handle processing of Given, When, Then, But, By and Finally
     keywords and convert them to And when necessary.
     """
-    prev = tests_by_parent[parent_id][-2] if len(tests_by_parent.get(parent_id, [])) > 1 else None
-    if prev and get_subtype(prev) == subtype and tests_by_parent.get(prev["test_id"]) is None:
+    prev = (
+        tests_by_parent[parent_id][-2]
+        if len(tests_by_parent.get(parent_id, [])) > 1
+        else None
+    )
+    if (
+        prev
+        and get_subtype(prev) == subtype
+        and tests_by_parent.get(prev["test_id"]) is None
+    ):
         keyword = "And"
     parent = tests_by_name.get(parent_id)
-    if parent and get_subtype(parent) == subtype and len(tests_by_parent.get(parent_id, [])) == 1:
+    if (
+        parent
+        and get_subtype(parent) == subtype
+        and len(tests_by_parent.get(parent_id, [])) == 1
+    ):
         keyword = "And"
     return keyword
 
+
 def get_type(msg):
     return getattr(TestType, msg["test_type"])
 
+
 def get_subtype(msg):
     return getattr(TestSubType, str(msg["test_subtype"]), 0)
 
+
 def format_test(msg, keyword):
     # add test to the tests map
     test_id = msg["test_id"]
     parent = parentname(test_id)
     if tests_by_parent.get(parent) is None:
         tests_by_parent[parent] = []
     tests_by_parent[parent].append(msg)
@@ -235,15 +335,15 @@
                 break
             elif get_type(tests_by_name[head]) >= TestType.Test:
                 test_type_parent_by_name[test_id] = head
                 break
             current_test_id = head
 
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
 
     if test_subtype == TestSubType.Example:
         keyword += "Example"
     elif test_type == TestType.Module:
         if test_subtype == TestSubType.Book:
             keyword += "Book"
         else:
@@ -313,77 +413,131 @@
     out = f"{color_other(_indent)}{_keyword} {_name}{color_other(', flags:' + str(flags) if flags else '')}\n"
     # convert indent to just spaces
     _indent = (len(_indent) + 3) * " "
     if msg["test_description"]:
         out += format_test_description(msg, _indent)
     return out
 
+
 def format_result(msg, prefix):
     test_id = msg["test_id"]
     if test_type_parent_by_name[test_id] != test_id:
-        return ''
+        return ""
     result = msg["result_type"]
-    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(msg["test_flags"])
+    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(
+        msg["test_flags"]
+    )
     _color = color_result(result, retry=_retry)
     _result = _color(prefix + result)
     _test = color_other(basename(msg["result_test"]))
-    _indent = f"{strftimedelta(msg['message_rtime']):>20}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    _indent = (
+        f"{strftimedelta(msg['message_rtime']):>20}"
+        + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    )
 
     _result_message = msg["result_message"]
     if _result_message and settings.trim_results and int(msg["test_level"]) > 1:
         _result_message = _result_message.strip().split("\n", 1)[0].strip()
 
-    out = (f"{color_other(_indent)}{_result} "
+    out = (
+        f"{color_other(_indent)}{_result} "
         f"{_test}{color_other(', ' + msg['result_test'])}"
         f"{(color_other(', ') + _color(format_multiline(_result_message, ' ' * len(_indent)).strip())) if _result_message else ''}"
-        f"{(color_other(', ') + _color(msg['result_reason'])) if msg['result_reason'] else ''}\n")
+        f"{(color_other(', ') + _color(msg['result_reason'])) if msg['result_reason'] else ''}\n"
+    )
 
     return out
 
+
 def format_message(msg, keyword, prefix="", predicate=None):
     out = msg["message"]
     if msg["message_stream"]:
         out = f"[{msg['message_stream']}] {msg['message']}"
 
-    out = textwrap.indent(out, prefix=(indent * (test_type_parent_by_name[msg["test_id"]].count('/') - 1) + " " * 30 + prefix), predicate=predicate)
+    out = textwrap.indent(
+        out,
+        prefix=(
+            indent * (test_type_parent_by_name[msg["test_id"]].count("/") - 1)
+            + " " * 30
+            + prefix
+        ),
+        predicate=predicate,
+    )
     out = out.lstrip(" ")
     if out.endswith("\n"):
         out = out[:-1]
 
-    return color_other(f"{strftimedelta(msg['message_rtime']):>20}{'':3}{indent * (test_type_parent_by_name[msg['test_id']].count('/') - 1)}{keyword} {color_other(out)}\n")
+    return color_other(
+        f"{strftimedelta(msg['message_rtime']):>20}{'':3}{indent * (test_type_parent_by_name[msg['test_id']].count('/') - 1)}{keyword} {color_other(out)}\n"
+    )
+
 
 def format_metric(msg, keyword):
-    prefix = f"{strftimedelta(msg['message_rtime']):>20}" + f"{'':3}{indent * (test_type_parent_by_name[msg['test_id']].count('/') - 1)}"
+    prefix = (
+        f"{strftimedelta(msg['message_rtime']):>20}"
+        + f"{'':3}{indent * (test_type_parent_by_name[msg['test_id']].count('/') - 1)}"
+    )
     _indent = (len(prefix) + 3) * " "
-    out = [color_other(f"{prefix}{keyword}") + color("Metric", "white", attrs=["dim", "bold"]) + color_other(f" {msg['metric_name']}")]
-    out.append(color_other(format_multiline(f"{msg['metric_value']} {msg['metric_units']}", _indent + " " * 2)))
+    out = [
+        color_other(f"{prefix}{keyword}")
+        + color("Metric", "white", attrs=["dim", "bold"])
+        + color_other(f" {msg['metric_name']}")
+    ]
+    out.append(
+        color_other(
+            format_multiline(
+                f"{msg['metric_value']} {msg['metric_units']}", _indent + " " * 2
+            )
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_value(msg, keyword):
-    prefix = f"{strftimedelta(msg['message_rtime']):>20}" + f"{'':3}{indent * (test_type_parent_by_name[msg['test_id']].count('/') - 1)}"
+    prefix = (
+        f"{strftimedelta(msg['message_rtime']):>20}"
+        + f"{'':3}{indent * (test_type_parent_by_name[msg['test_id']].count('/') - 1)}"
+    )
     _indent = (len(prefix) + 3) * " "
-    out = [color_other(f"{prefix}{keyword}") + color("Value", "white", attrs=["dim", "bold"]) + color_other(f" {msg['value_name']}")]
-    out.append(color_other(format_multiline(f"{msg['value_value']}", _indent + " " * 2)))
+    out = [
+        color_other(f"{prefix}{keyword}")
+        + color("Value", "white", attrs=["dim", "bold"])
+        + color_other(f" {msg['value_name']}")
+    ]
+    out.append(
+        color_other(format_multiline(f"{msg['value_value']}", _indent + " " * 2))
+    )
     return "\n".join(out) + "\n"
 
+
 def format_ticket(msg, keyword):
-    prefix = f"{strftimedelta(msg['message_rtime']):>20}" + f"{'':3}{indent * (test_type_parent_by_name[msg['test_id']].count('/') - 1)}"
+    prefix = (
+        f"{strftimedelta(msg['message_rtime']):>20}"
+        + f"{'':3}{indent * (test_type_parent_by_name[msg['test_id']].count('/') - 1)}"
+    )
     _indent = (len(prefix) + 3) * " "
-    out = [color_other(f"{prefix}{keyword}") + color("Ticket", "white", attrs=["dim", "bold"]) + color_other(f" {msg['ticket_name']}")]
-    out.append(color_other(format_multiline(f"{msg['ticket_link']}", _indent + " " * 2)))
+    out = [
+        color_other(f"{prefix}{keyword}")
+        + color("Ticket", "white", attrs=["dim", "bold"])
+        + color_other(f" {msg['ticket_name']}")
+    ]
+    out.append(
+        color_other(format_multiline(f"{msg['ticket_link']}", _indent + " " * 2))
+    )
     return "\n".join(out) + "\n"
 
+
 mark = "\u27e5"
 result_mark = "\u27e5\u27e4"
 
 formatters = {
     Message.INPUT.name: (format_input, f"{mark} "),
     Message.PROMPT.name: (format_prompt, f"{mark} "),
     Message.TEST.name: (format_test, f"{mark}  "),
-    Message.ATTRIBUTE.name: (format_attribute, ),
+    Message.ATTRIBUTE.name: (format_attribute,),
     Message.ARGUMENT.name: (format_argument,),
     Message.SPECIFICATION.name: (format_specification,),
     Message.REQUIREMENT.name: (format_requirement,),
     Message.TAG.name: (format_tag,),
     Message.EXAMPLE.name: (format_example,),
     Message.VALUE.name: (format_value, f"{mark}    "),
     Message.METRIC.name: (format_metric, f"{mark}    "),
@@ -393,14 +547,15 @@
     Message.NOTE.name: (format_message, f"{mark}    [note]"),
     Message.DEBUG.name: (format_message, f"{mark}    [debug]"),
     Message.TRACE.name: (format_message, f"{mark}    [trace]"),
     Message.NONE.name: (format_message, "    "),
     Message.RESULT.name: (format_result, f"{result_mark} "),
 }
 
+
 def transform(show_input=True):
     """Transform parsed log line into a brisk format
     that is similar to nice but excludes step definitions
     and their attributes while keeping their core messages.
     """
     line = None
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/classic.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/classic.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,26 +22,31 @@
 from testflows._core.name import split
 from testflows._core.utils.timefuncs import strftime, strftimedelta
 from testflows._core.utils.timefuncs import localfromtimestamp
 from testflows._core.cli.colors import color, cursor_up
 
 indent = " " * 2
 
+
 def color_other(other):
     return color(other, "white", attrs=["dim"])
 
+
 def color_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["dim"])
 
+
 def color_secondary_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold", "dim"])
 
+
 def color_test_name(name):
     return color(name, "white", attrs=[])
 
+
 def color_result(result, icon=None):
     def result_icon(result):
         r = result.lstrip("X")
         if r == "OK":
             return "\u2714"
         elif r == "Skip":
             return "\u2704"
@@ -63,95 +68,105 @@
     elif result == "Error":
         return color(icon, "yellow", attrs=["bold"])
     elif result == "Fail":
         return color(icon, "red", attrs=["bold"])
     # Null
     return color(icon, "cyan", attrs=["bold"])
 
+
 def format_prompt(msg, keyword):
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
     out = color(icon + lines[0], "yellow", attrs=["bold"])
     if len(lines) > 1:
         out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"])
     return out
 
+
 def format_input(msg, keyword):
-    out = color(msg['message'], "white") + "\n"
+    out = color(msg["message"], "white") + "\n"
     return out
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
     out = textwrap.indent(out, indent + "  ")
     return out
 
+
 def format_test(msg, keyword):
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
 
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
         return
 
-    icon = '\u27A4'
+    icon = "\u27A4"
     time = f"{strftime(localfromtimestamp(msg['message_time'])):>20}"
 
     _name = color_test_name(msg["test_name"])
     out = f"{icon} {color_other(time)} {_name}\n"
 
     return out
 
+
 def format_result(msg):
     result = msg["result_type"]
 
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
 
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
         return
 
     _icon = color_result(result)
     _result = color_result(result, result)
     _test = color_test_name(f"{msg['result_test']}")
 
-    out = f"{_icon} "+ color_other(f"{strftimedelta(msg['message_rtime']):<10}") + f"[ {result.center(6, ' ')} ]".ljust(10, ' ').replace(result, _result)
+    out = (
+        f"{_icon} "
+        + color_other(f"{strftimedelta(msg['message_rtime']):<10}")
+        + f"[ {result.center(6, ' ')} ]".ljust(10, " ").replace(result, _result)
+    )
 
     _result_message = msg["result_message"]
     if _result_message and settings.trim_results and int(msg["test_level"]) > 1:
-        _result_message = _result_message.strip().split("\n",1)[0].strip()
+        _result_message = _result_message.strip().split("\n", 1)[0].strip()
 
     if result in ("Fail", "Error", "Null"):
         out += f" {_test}"
         if _result_message:
             out += f"\n{indent}  {color(format_multiline(_result_message, indent).lstrip(), 'yellow', attrs=['bold'])}"
     elif result.startswith("X"):
         out += f" {_test}"
-        if msg['result_reason']:
+        if msg["result_reason"]:
             out += f"\n{indent}  {color(msg['result_reason'], 'blue', attrs=['bold'])}"
     else:
         out += f" {_test}"
     return out + "\n"
 
+
 formatters = {
     Message.INPUT.name: (format_input, f""),
     Message.PROMPT.name: (format_prompt, f""),
     Message.TEST.name: (format_test, f""),
-    Message.RESULT.name: (format_result,)
+    Message.RESULT.name: (format_result,),
 }
 
+
 def transform(show_input=True):
-    """Transform parsed log line into a classic format.
-    """
+    """Transform parsed log line into a classic format."""
     line = None
     while True:
         if line is not None:
             formatter = formatters.get(line["message_keyword"], None)
             if formatter:
                 if formatter[0] is format_input and show_input is False:
                     line = None
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/collect.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/tests.py`

 * *Files 16% similar despite different names*

```diff
@@ -8,17 +8,22 @@
 #      http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-def transform(msgs):
-    """Collect messages.
-    """
+from testflows._core.testtype import TestType
+
+
+def transform():
+    """Transform msg to test name."""
     msg = None
 
     while True:
+        line = None
+
         if msg is not None:
-            msgs.append(msg)
+            if getattr(TestType, msg["test_type"]) >= TestType.Test:
+                line = f"{msg['test_name']}\n"
 
-        msg = yield msg
+        msg = yield line
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/dots.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/dots.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,31 +18,33 @@
 from testflows._core.cli.colors import color
 from testflows._core.message import Message
 from testflows._core.testtype import TestType
 
 width = 70
 count = 0
 
+
 def color_result(result):
     if result.startswith("X"):
         return color(".", "blue", attrs=["bold"])
     elif result == "OK":
         return color(".", "green", attrs=["bold"])
     elif result == "Skip":
         return color("-", "white", attrs=["dim"])
     # Error, Fail, Null
     elif result == "Error":
         return color("E", "yellow", attrs=["bold"])
     elif result == "Fail":
-         return color("F", "red", attrs=["bold"])
+        return color("F", "red", attrs=["bold"])
     elif result == "Null":
         return color("N", "magenta", attrs=["bold"])
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def format_prompt(msg):
     global count
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
     out = ""
@@ -50,20 +52,22 @@
         out += "\n"
     out += color(icon + lines[0], "yellow", attrs=["bold"])
     if len(lines) > 1:
         out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"])
     count = 0
     return out
 
+
 def format_input(msg):
     global count
-    out = color(msg['message'], "white") + "\n"
+    out = color(msg["message"], "white") + "\n"
     count = 0
     return out
 
+
 def format_result(msg):
     global count
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
 
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
@@ -74,23 +78,24 @@
     # wrap if we hit max width
     if count >= width:
         count = 0
         _result += "\n"
 
     return _result
 
+
 formatters = {
     Message.INPUT.name: (format_input,),
     Message.PROMPT.name: (format_prompt,),
-    Message.RESULT.name: (format_result,)
+    Message.RESULT.name: (format_result,),
 }
 
+
 def transform(stop_event, show_input=True):
-    """Transform parsed log line into a short format.
-    """
+    """Transform parsed log line into a short format."""
     line = None
     while True:
         if line is not None:
             formatter = formatters.get(line["message_keyword"], None)
             if formatter:
                 if formatter[0] is format_input and show_input is False:
                     line = None
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/fails.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/fails.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,26 +21,31 @@
 from testflows._core.message import Message
 from testflows._core.name import split
 from testflows._core.utils.timefuncs import strftimedelta
 from testflows._core.cli.colors import color, cursor_up
 
 indent = " " * 2
 
+
 def color_other(other):
     return color(other, "white", attrs=["dim"])
 
+
 def color_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["dim"])
 
+
 def color_secondary_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold", "dim"])
 
+
 def color_test_name(name):
     return color(name, "white", attrs=[])
 
+
 def color_result(result, icon=None):
     def result_icon(result):
         r = result.lstrip("X")
         if r == "OK":
             return "\u2714"
         elif r == "Skip":
             return "\u2704"
@@ -62,78 +67,88 @@
     elif result == "Error":
         return color(icon, "yellow", attrs=["bold"])
     elif result == "Fail":
         return color(icon, "red", attrs=["bold"])
     # Null
     return color(icon, "cyan", attrs=["bold"])
 
+
 def format_prompt(msg, keyword):
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
     out = color(icon + lines[0], "yellow", attrs=["bold"])
     if len(lines) > 1:
         out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"])
     return out
 
+
 def format_input(msg, keyword):
-    out = color(msg['message'], "white") + "\n"
+    out = color(msg["message"], "white") + "\n"
     return out
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
     out = textwrap.indent(out, indent + "  ")
     return out
 
+
 def format_result(msg, only_new):
     result = msg["result_type"]
 
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
 
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
         return
 
     _icon = color_result(result)
     _result = color_result(result, result)
     _test = color_test_name(f"{msg['result_test']}")
 
-    out = f"{_icon} "+ color_other(f"{strftimedelta(msg['message_rtime']):<10}") + f"[ {result.center(6, ' ')} ]".ljust(10, ' ').replace(result, _result)
+    out = (
+        f"{_icon} "
+        + color_other(f"{strftimedelta(msg['message_rtime']):<10}")
+        + f"[ {result.center(6, ' ')} ]".ljust(10, " ").replace(result, _result)
+    )
 
     _result_message = msg["result_message"]
     if _result_message and settings.trim_results and int(msg["test_level"]) > 1:
-        _result_message = _result_message.strip().split("\n",1)[0].strip()
+        _result_message = _result_message.strip().split("\n", 1)[0].strip()
 
     if result in ("Fail", "Error", "Null"):
         out += f" {_test}"
         if _result_message:
             out += f"\n{indent}  {color(format_multiline(_result_message, indent).lstrip(), 'yellow', attrs=['bold'])}"
         out += "\n"
     elif not only_new and result.startswith("X"):
         out += f" {_test}"
-        if msg['result_reason']:
+        if msg["result_reason"]:
             out += f"\n{indent}  {color(msg['result_reason'], 'blue', attrs=['bold'])}"
         out += "\n"
     else:
         out = None
 
     return out
 
+
 formatters = {
     Message.INPUT.name: (format_input, f""),
     Message.PROMPT.name: (format_prompt, f""),
-    Message.RESULT.name: (format_result,)
+    Message.RESULT.name: (format_result,),
 }
 
+
 def transform(only_new=False, show_input=True):
     """Transform parsed log line into a fails format.
 
     :param only_new: output only new fails
     """
     line = None
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/flat.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/flat.py`

 * *Files 11% similar despite different names*

```diff
@@ -23,170 +23,332 @@
 from testflows._core.name import split, parentname, basename
 from testflows._core.cli.colors import color
 
 indent = " " * 2
 #: last message
 last_message = [None]
 
+
 def color_other(other, no_colors=False):
     return color(other, "white", attrs=["dim"], no_colors=no_colors)
 
+
 def color_keyword(keyword, no_colors=False):
     return color(split(keyword)[-1], "white", attrs=["bold"], no_colors=no_colors)
 
+
 def color_secondary_keyword(keyword, no_colors=False):
-    return color(split(keyword)[-1], "white", attrs=["bold", "dim"], no_colors=no_colors)
+    return color(
+        split(keyword)[-1], "white", attrs=["bold", "dim"], no_colors=no_colors
+    )
+
 
 def color_test_name(name, no_colors=False):
     return color(name, "white", attrs=[], no_colors=no_colors)
 
+
 def color_result(result, attrs=None, no_colors=False, retry=False):
     if attrs is None:
         attrs = ["bold"]
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=attrs, no_colors=no_colors)
     elif result == "OK":
         return functools.partial(color, color="green", attrs=attrs, no_colors=no_colors)
     elif result == "Skip":
         return functools.partial(color, color="cyan", attrs=attrs, no_colors=no_colors)
     elif retry:
         return functools.partial(color, color="cyan", attrs=attrs, no_colors=no_colors)
     elif result == "Error":
-        return functools.partial(color, color="yellow", attrs=attrs, no_colors=no_colors)
+        return functools.partial(
+            color, color="yellow", attrs=attrs, no_colors=no_colors
+        )
     elif result == "Fail":
         return functools.partial(color, color="red", attrs=attrs, no_colors=no_colors)
     elif result == "Null":
-        return functools.partial(color, color="magenta", attrs=attrs, no_colors=no_colors)
+        return functools.partial(
+            color, color="magenta", attrs=attrs, no_colors=no_colors
+        )
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
     out = textwrap.indent(out, indent + "  ")
     return out
 
+
 def format_test_description(msg, indent, no_colors=False):
     desc = format_multiline(msg["test_description"], indent)
     desc = color(desc, "white", attrs=["dim"], no_colors=no_colors)
     return desc
 
+
 def format_specification(msg, no_colors=False):
     out = []
     _indent = indent
 
-    if not last_message[0] or (last_message[0] and last_message[0]["test_name"] != msg["test_name"]):
+    if not last_message[0] or (
+        last_message[0] and last_message[0]["test_name"] != msg["test_name"]
+    ):
         out.append(format_test(msg, keyword="", no_colors=no_colors))
 
-    if not last_message[0] or (last_message[0] and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name or last_message[0]["test_name"] != msg["test_name"]):
-        out.append(f"{_indent}{' ' * 0}{color_secondary_keyword('Specifications', no_colors=no_colors)}")
+    if not last_message[0] or (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name
+        or last_message[0]["test_name"] != msg["test_name"]
+    ):
+        out.append(
+            f"{_indent}{' ' * 0}{color_secondary_keyword('Specifications', no_colors=no_colors)}"
+        )
 
-    out.append(color(f"{_indent}{' ' * 2}{msg['specification_name']}", "white", attrs=["dim"], no_colors=no_colors))
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['specification_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     if msg["specification_version"]:
-        out.append(color(f"{_indent}{' ' * 4}version {msg['specification_version']}", "white", attrs=["dim"], no_colors=no_colors))
+        out.append(
+            color(
+                f"{_indent}{' ' * 4}version {msg['specification_version']}",
+                "white",
+                attrs=["dim"],
+                no_colors=no_colors,
+            )
+        )
     return "\n".join(out) + "\n"
 
+
 def format_requirement(msg, no_colors=False):
     out = []
     _indent = indent
 
-    if not last_message[0] or (last_message[0] and last_message[0]["test_name"] != msg["test_name"]):
+    if not last_message[0] or (
+        last_message[0] and last_message[0]["test_name"] != msg["test_name"]
+    ):
         out.append(format_test(msg, keyword="", no_colors=no_colors))
 
-    if not last_message[0] or (last_message[0] and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name or last_message[0]["test_name"] != msg["test_name"]):
-        out.append(f"{_indent}{' ' * 0}{color_secondary_keyword('Requirements', no_colors=no_colors)}")
+    if not last_message[0] or (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name
+        or last_message[0]["test_name"] != msg["test_name"]
+    ):
+        out.append(
+            f"{_indent}{' ' * 0}{color_secondary_keyword('Requirements', no_colors=no_colors)}"
+        )
 
-    out.append(color(f"{_indent}{' ' * 2}{msg['requirement_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(f"{_indent}{' ' * 4}version {msg['requirement_version']}", "white", attrs=["dim"], no_colors=no_colors))
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['requirement_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            f"{_indent}{' ' * 4}version {msg['requirement_version']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_attribute(msg, no_colors=False):
     out = []
     _indent = indent
 
-    if not last_message[0] or (last_message[0] and last_message[0]["test_name"] != msg["test_name"]):
+    if not last_message[0] or (
+        last_message[0] and last_message[0]["test_name"] != msg["test_name"]
+    ):
         out.append(format_test(msg, keyword="", no_colors=no_colors))
 
-    if not last_message[0] or (last_message[0] and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name or last_message[0]["test_name"] != msg["test_name"]):
-        out.append(f"{_indent}{' ' * 0}{color_secondary_keyword('Attributes', no_colors=no_colors)}")
+    if not last_message[0] or (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name
+        or last_message[0]["test_name"] != msg["test_name"]
+    ):
+        out.append(
+            f"{_indent}{' ' * 0}{color_secondary_keyword('Attributes', no_colors=no_colors)}"
+        )
 
-    out.append(color(f"{_indent}{' ' * 2}{msg['attribute_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(f"{textwrap.indent(str(msg['attribute_value']), prefix=(_indent + ' ' * 6))}", "white", attrs=["dim"], no_colors=no_colors))
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['attribute_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            f"{textwrap.indent(str(msg['attribute_value']), prefix=(_indent + ' ' * 6))}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_tag(msg, no_colors=False):
     out = []
     _indent = indent
 
-    if not last_message[0] or (last_message[0] and last_message[0]["test_name"] != msg["test_name"]):
+    if not last_message[0] or (
+        last_message[0] and last_message[0]["test_name"] != msg["test_name"]
+    ):
         out.append(format_test(msg, keyword="", no_colors=no_colors))
 
-    if not last_message[0] or (last_message[0] and (not last_message[0]["message_keyword"] == Message.TAG.name or last_message[0]["test_name"] != msg["test_name"])):
-        out.append(f"{_indent}{' ' * 0}{color_secondary_keyword('Tags', no_colors=no_colors)}")
+    if not last_message[0] or (
+        last_message[0]
+        and (
+            not last_message[0]["message_keyword"] == Message.TAG.name
+            or last_message[0]["test_name"] != msg["test_name"]
+        )
+    ):
+        out.append(
+            f"{_indent}{' ' * 0}{color_secondary_keyword('Tags', no_colors=no_colors)}"
+        )
 
-    out.append(color(f"{_indent}{' ' * 2}{msg['tag_value']}", "white", attrs=["dim"], no_colors=no_colors))
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['tag_value']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_metric(msg, no_colors=False):
     out = []
     _indent = indent
 
-    if not last_message[0] or (last_message[0] and last_message[0]["test_name"] != msg["test_name"]):
+    if not last_message[0] or (
+        last_message[0] and last_message[0]["test_name"] != msg["test_name"]
+    ):
         out.append(format_test(msg, keyword="", no_colors=no_colors))
 
     out.append(
         color_other(f"{_indent}", no_colors=no_colors)
         + color("Metric", "white", attrs=["dim", "bold"], no_colors=no_colors)
         + color_other(f" {msg['metric_name']}", no_colors=no_colors)
     )
-    out.append(color_other(format_multiline(f"{msg['metric_value']} {msg['metric_units']}", _indent), no_colors=no_colors))
+    out.append(
+        color_other(
+            format_multiline(f"{msg['metric_value']} {msg['metric_units']}", _indent),
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_example(msg, no_colors=False):
     out = []
     _indent = indent
 
-    if not last_message[0] or (last_message[0] and last_message[0]["test_name"] != msg["test_name"]):
+    if not last_message[0] or (
+        last_message[0] and last_message[0]["test_name"] != msg["test_name"]
+    ):
         out.append(format_test(msg, keyword="", no_colors=no_colors))
 
-    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(msg["example_columns"], msg["example_values"])
+    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(
+        msg["example_columns"], msg["example_values"]
+    )
 
-    if not last_message[0] or (last_message[0] and not last_message[0]["message_keyword"] == Message.EXAMPLE.name or last_message[0]["test_name"] != msg["test_name"]):
-        out.append(f"{_indent}{' ' * 0}{color_secondary_keyword('Examples', no_colors=no_colors)}")
-        out.append(color(textwrap.indent(f"{ExamplesTable.__str_header__(tuple(msg['example_columns']),row_format)}",
-            prefix=f"{_indent}{' ' * 2}"), "white", attrs=["dim"], no_colors=no_colors))
+    if not last_message[0] or (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.EXAMPLE.name
+        or last_message[0]["test_name"] != msg["test_name"]
+    ):
+        out.append(
+            f"{_indent}{' ' * 0}{color_secondary_keyword('Examples', no_colors=no_colors)}"
+        )
+        out.append(
+            color(
+                textwrap.indent(
+                    f"{ExamplesTable.__str_header__(tuple(msg['example_columns']),row_format)}",
+                    prefix=f"{_indent}{' ' * 2}",
+                ),
+                "white",
+                attrs=["dim"],
+                no_colors=no_colors,
+            )
+        )
 
-    out.append(color(textwrap.indent(f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}",
-        prefix=f"{_indent}{' ' * 2}"), "white", attrs=["dim"], no_colors=no_colors))
+    out.append(
+        color(
+            textwrap.indent(
+                f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}",
+                prefix=f"{_indent}{' ' * 2}",
+            ),
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_argument(msg, no_colors=False):
     out = []
     _indent = indent
 
-    if not last_message[0] or (last_message[0] and last_message[0]["test_name"] != msg["test_name"]):
+    if not last_message[0] or (
+        last_message[0] and last_message[0]["test_name"] != msg["test_name"]
+    ):
         out.append(format_test(msg, keyword="", no_colors=no_colors))
 
-    if not last_message[0] or (last_message[0] and not last_message[0]["message_keyword"] == Message.ARGUMENT.name or last_message[0]["test_name"] != msg["test_name"]):
-        out.append(f"{_indent}{' ' * 0}{color_secondary_keyword('Arguments', no_colors=no_colors)}")
+    if not last_message[0] or (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ARGUMENT.name
+        or last_message[0]["test_name"] != msg["test_name"]
+    ):
+        out.append(
+            f"{_indent}{' ' * 0}{color_secondary_keyword('Arguments', no_colors=no_colors)}"
+        )
 
-    out.append(color(f"{_indent}{' ' * 2}{msg['argument_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(textwrap.indent(f"{msg['argument_value']}",
-        prefix=f"{_indent}{' ' * 4}"), "white", attrs=["dim"], no_colors=no_colors))
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['argument_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            textwrap.indent(f"{msg['argument_value']}", prefix=f"{_indent}{' ' * 4}"),
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def get_type(msg):
     return getattr(TestType, msg["test_type"])
 
+
 def get_subtype(msg):
     return getattr(TestSubType, str(msg["test_subtype"]), 0)
 
+
 def format_test(msg, keyword, no_colors=False):
     test_type = get_type(msg)
     test_subtype = get_subtype(msg)
 
     if test_subtype == TestSubType.Example:
         keyword += "Example"
     elif test_type == TestType.Module:
@@ -240,25 +402,30 @@
     out = f"{_indent}{_keyword} {_name}"
     if msg.get("test_description"):
         out += "\n" + format_test_description(msg, _indent, no_colors=no_colors)
     if msg["message_keyword"] == Message.TEST.name:
         out += "\n"
     return out
 
+
 def format_result(msg, no_colors=False):
     result = msg["result_type"]
-    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(msg["test_flags"])
+    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(
+        msg["test_flags"]
+    )
     _color = color_result(result, no_colors=no_colors, retry=_retry)
     _result = _color(result, no_colors=no_colors)
     _test = color_test_name(msg["result_test"], no_colors=no_colors)
 
     _indent = ""
     out = ""
 
-    if not last_message[0] or (last_message[0] and last_message[0]["test_name"] != msg["test_name"]):
+    if not last_message[0] or (
+        last_message[0] and last_message[0]["test_name"] != msg["test_name"]
+    ):
         out += format_test(msg, keyword="", no_colors=no_colors) + "\n"
 
     out += f"{_indent}{_result} "
 
     if result in ("Fail", "Error", "Null"):
         out += f" {_test}"
         if msg["result_message"]:
@@ -267,29 +434,30 @@
     elif result.startswith("X"):
         out += f" {_test}"
         if msg["result_reason"]:
             out += color_test_name(",", no_colors=no_colors)
             out += f" {_color(msg['result_reason'], no_colors=no_colors)}"
     return out + "\n"
 
+
 formatters = {
     Message.TEST.name: (format_test, f""),
     Message.RESULT.name: (format_result,),
     Message.ATTRIBUTE.name: (format_attribute,),
     Message.ARGUMENT.name: (format_argument,),
     Message.SPECIFICATION.name: (format_specification,),
     Message.REQUIREMENT.name: (format_requirement,),
     Message.TAG.name: (format_tag,),
     Message.METRIC.name: (format_metric,),
-    Message.EXAMPLE.name: (format_example,)
+    Message.EXAMPLE.name: (format_example,),
 }
 
+
 def transform(no_colors=False, show_input=True):
-    """Transform parsed log line into a flat format.
-    """
+    """Transform parsed log line into a flat format."""
     line = None
     while True:
         if line is not None:
             msg = line
             formatter = formatters.get(line["message_keyword"], None)
             if formatter:
                 flags = Flags(line["test_flags"])
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/manual.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/short.py`

 * *Files 9% similar despite different names*

```diff
@@ -18,188 +18,333 @@
 import testflows.settings as settings
 
 from testflows._core.flags import Flags, SKIP, LAST_RETRY
 from testflows._core.testtype import TestType, TestSubType
 from testflows._core.message import Message
 from testflows._core.objects import ExamplesTable
 from testflows._core.name import split, parentname, basename
-from testflows._core.cli.colors import color, cursor_up, clear_screen
+from testflows._core.cli.colors import color, cursor_up
 
 indent = " " * 2
 #: map of tests by name
 tests_by_id = {}
 #: map of tests by parent
 tests_by_parent = {}
 #: last message
 last_message = [None]
 
-separators = {
-    TestType.Module: color("\u2501" * 80, "cyan", attrs=["bold"]) + "\n",
-    TestType.Suite: color("\u2501" * 80, "white", attrs=["dim"]) + "\n",
-    TestType.Test: color("\u2500" * 80, "cyan", attrs=["dim"]) + "\n",
-    TestType.Outline: color("\u2500" * 80, "cyan", attrs=["dim"]) + "\n",
-    TestType.Iteration: color("\u2500" * 80, "yellow", attrs=["dim"]) + "\n",
-    TestType.RetryIteration: color("\u2500" * 80, "white", attrs=["dim"]) + "\n",
-    TestType.Step: "\u2500" * 80 + "\n"
-}
 
 def color_other(other, no_colors=False):
     return color(other, "white", attrs=["dim"], no_colors=no_colors)
 
+
 def color_keyword(keyword, no_colors=False):
     return color(split(keyword)[-1], "white", attrs=["bold"], no_colors=no_colors)
 
+
 def color_secondary_keyword(keyword, no_colors=False):
-    return color(split(keyword)[-1], "white", attrs=["bold", "dim"], no_colors=no_colors)
+    return color(
+        split(keyword)[-1], "white", attrs=["bold", "dim"], no_colors=no_colors
+    )
+
+
+def color_test_name(name, no_colors=False, use_full_testname=False):
+    if use_full_testname:
+        return color(name, "white", attrs=[], no_colors=no_colors)
+    else:
+        return color(split(name)[-1], "white", attrs=[], no_colors=no_colors)
 
-def color_test_name(name, no_colors=False):
-    return color(split(name)[-1], "white", attrs=[], no_colors=no_colors)
 
 def color_result(result, attrs=None, no_colors=False, retry=False):
     if attrs is None:
         attrs = ["bold"]
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=attrs, no_colors=no_colors)
     elif result == "OK":
         return functools.partial(color, color="green", attrs=attrs, no_colors=no_colors)
     elif result == "Skip":
         return functools.partial(color, color="cyan", attrs=attrs, no_colors=no_colors)
     elif retry:
         return functools.partial(color, color="cyan", attrs=attrs, no_colors=no_colors)
     elif result == "Error":
-        return functools.partial(color, color="yellow", attrs=attrs, no_colors=no_colors)
+        return functools.partial(
+            color, color="yellow", attrs=attrs, no_colors=no_colors
+        )
     elif result == "Fail":
         return functools.partial(color, color="red", attrs=attrs, no_colors=no_colors)
     elif result == "Null":
-        return functools.partial(color, color="magenta", attrs=attrs, no_colors=no_colors)
+        return functools.partial(
+            color, color="magenta", attrs=attrs, no_colors=no_colors
+        )
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def format_input(msg, keyword, no_colors=False):
     out = f"{indent * (msg['test_id'].count('/'))}"
-    out += color("\u270b " + msg["message"], "white", attrs=["dim"], no_colors=no_colors) \
-        + cursor_up(no_colors=no_colors) + "\n"
+    out += (
+        color("\u270b " + msg["message"], "yellow", attrs=["bold"], no_colors=no_colors)
+        + cursor_up(no_colors=no_colors)
+        + "\n"
+    )
     return out
 
+
 def format_prompt(msg, keyword, no_colors=False):
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
-    out = color(icon + lines[0], "white", attrs=["dim"], no_colors=no_colors)
+    out = color(icon + lines[0], "yellow", attrs=["bold"], no_colors=no_colors)
     if len(lines) > 1:
-        out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"], no_colors=no_colors)
+        out += "\n" + color(
+            "\n".join(lines[1:]), "white", attrs=["dim"], no_colors=no_colors
+        )
     return out
 
+
 def format_input(msg, keyword, no_colors=False):
-    out = color(msg['message'], "white", no_colors=no_colors) + "\n"
+    out = color(msg["message"], "white", no_colors=no_colors) + "\n"
     return out
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
-    out = textwrap.indent(out, indent + "")
+    out = textwrap.indent(out, indent + "  ")
     return out
 
+
 def format_test_description(msg, indent, no_colors=False):
     desc = format_multiline(msg["test_description"], indent)
     desc = color(desc, "white", attrs=["dim"], no_colors=no_colors)
     return desc + "\n"
 
+
 def format_specification(msg, no_colors=False):
     out = []
-    _indent = ""
-
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name:
-        out = [f"{_indent}{color_secondary_keyword('Specifications', no_colors=no_colors)}"]
+    _indent = indent * (msg["test_id"].count("/") - 1)
 
-    out.append(color(f"{_indent}{' ' * 2}{msg['specification_name']}", "white", attrs=["dim"], no_colors=no_colors))
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name
+    ):
+        out = [
+            f"{_indent}{' ' * 2}{color_secondary_keyword('Specifications', no_colors=no_colors)}"
+        ]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 4}{msg['specification_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     if msg["specification_version"]:
-        out.append(color(f"{_indent}{' ' * 4}version {msg['specification_version']}", "white", attrs=["dim"], no_colors=no_colors))
+        out.append(
+            color(
+                f"{_indent}{' ' * 6}version {msg['specification_version']}",
+                "white",
+                attrs=["dim"],
+                no_colors=no_colors,
+            )
+        )
     return "\n".join(out) + "\n"
 
+
 def format_requirement(msg, no_colors=False):
     out = []
-    _indent = ""
-
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name:
-        out = [f"{_indent}{color_secondary_keyword('Requirements', no_colors=no_colors)}"]
+    _indent = indent * (msg["test_id"].count("/") - 1)
 
-    out.append(color(f"{_indent}{' ' * 2}{msg['requirement_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(f"{_indent}{' ' * 4}version {msg['requirement_version']}", "white", attrs=["dim"], no_colors=no_colors))
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name
+    ):
+        out = [
+            f"{_indent}{' ' * 2}{color_secondary_keyword('Requirements', no_colors=no_colors)}"
+        ]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 4}{msg['requirement_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            f"{_indent}{' ' * 6}version {msg['requirement_version']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_attribute(msg, no_colors=False):
     out = []
-    _indent = ""
+    _indent = indent * (msg["test_id"].count("/") - 1)
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name:
-        out = [f"{_indent}{color_secondary_keyword('Attributes', no_colors=no_colors)}"]
-
-    out.append(color(f"{_indent}{' ' * 2}{msg['attribute_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(f"{textwrap.indent(str(msg['attribute_value']), prefix=(' ' * 4))}", "white", attrs=["dim"], no_colors=no_colors))
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name
+    ):
+        out = [
+            f"{_indent}{' ' * 2}{color_secondary_keyword('Attributes', no_colors=no_colors)}"
+        ]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 4}{msg['attribute_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            f"{textwrap.indent(str(msg['attribute_value']), prefix=(_indent + ' ' * 6))}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_tag(msg, no_colors=False):
     out = []
-    _indent = ""
+    _indent = indent * (msg["test_id"].count("/") - 1)
 
     if last_message[0] and not last_message[0]["message_keyword"] == Message.TAG.name:
-        out = [f"{_indent}{color_secondary_keyword('Tags', no_colors=no_colors)}"]
-
-    out.append(color(f"{_indent}{' ' * 2}{msg['tag_value']}", "white", attrs=["dim"], no_colors=no_colors))
+        out = [
+            f"{_indent}{' ' * 2}{color_secondary_keyword('Tags', no_colors=no_colors)}"
+        ]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 4}{msg['tag_value']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_example(msg, no_colors=False):
     out = []
-    _indent = ""
-
-    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(msg["example_columns"], msg["example_values"])
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.EXAMPLE.name:
-        out = [f"{_indent}{color_secondary_keyword('Examples', no_colors=no_colors)}"]
-        out.append(color(textwrap.indent(f"{ExamplesTable.__str_header__(tuple(msg['example_columns']),row_format)}",
-            prefix=f"{_indent}{' ' * 2}"), "white", attrs=["dim"], no_colors=no_colors))
+    _indent = indent * (msg["test_id"].count("/") - 1)
 
-    out.append(color(textwrap.indent(f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}",
-        prefix=f"{_indent}{' ' * 2}"), "white", attrs=["dim"], no_colors=no_colors))
+    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(
+        msg["example_columns"], msg["example_values"]
+    )
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.EXAMPLE.name
+    ):
+        out = [
+            f"{_indent}{' ' * 2}{color_secondary_keyword('Examples', no_colors=no_colors)}"
+        ]
+        out.append(
+            color(
+                textwrap.indent(
+                    f"{ExamplesTable.__str_header__(tuple(msg['example_columns']),row_format)}",
+                    prefix=f"{_indent}{' ' * 4}",
+                ),
+                "white",
+                attrs=["dim"],
+                no_colors=no_colors,
+            )
+        )
+
+    out.append(
+        color(
+            textwrap.indent(
+                f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}",
+                prefix=f"{_indent}{' ' * 4}",
+            ),
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_argument(msg, no_colors=False):
     out = []
-    _indent = ""
+    _indent = indent * (msg["test_id"].count("/") - 1)
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.ARGUMENT.name:
-        out = [f"{_indent}{color_secondary_keyword('Arguments', no_colors=no_colors)}"]
-
-    out.append(color(f"{_indent}{' ' * 2}{msg['argument_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(textwrap.indent(f"{msg['argument_value']}",
-        prefix=f"{_indent}{' ' * 4}"), "white", attrs=["dim"], no_colors=no_colors))
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ARGUMENT.name
+    ):
+        out = [
+            f"{_indent}{' ' * 2}{color_secondary_keyword('Arguments', no_colors=no_colors)}"
+        ]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 4}{msg['argument_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            textwrap.indent(f"{msg['argument_value']}", prefix=f"{_indent}{' ' * 6}"),
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def get_type(msg):
     return getattr(TestType, msg["test_type"])
 
+
 def get_subtype(msg):
     return getattr(TestSubType, str(msg["test_subtype"]), 0)
 
+
 def and_keyword(msg, parent_id, keyword, subtype):
     """Handle processing of Given, When, Then, But, By and Finally
     keywords and convert them to And when necessary.
     """
-    prev = tests_by_parent[parent_id][-2] if len(tests_by_parent.get(parent_id, [])) > 1 else None
-    if prev and get_subtype(prev) == subtype and tests_by_parent.get(prev["test_id"]) is None:
-        keyword = "\u25a1 And"
+    prev = (
+        tests_by_parent[parent_id][-2]
+        if len(tests_by_parent.get(parent_id, [])) > 1
+        else None
+    )
+    if (
+        prev
+        and get_subtype(prev) == subtype
+        and tests_by_parent.get(prev["test_id"]) is None
+    ):
+        keyword = "And"
     parent = tests_by_id.get(parent_id)
-    if parent and get_subtype(parent) == subtype and len(tests_by_parent.get(parent_id, [])) == 1:
-        keyword = "\u25a1 And"
+    if (
+        parent
+        and get_subtype(parent) == subtype
+        and len(tests_by_parent.get(parent_id, [])) == 1
+    ):
+        keyword = "And"
     return keyword
 
+
 def format_test(msg, keyword, tests_by_parent, tests_by_id, no_colors=False):
     # add test to the tests map
     parent = parentname(msg["test_id"])
     if tests_by_parent.get(parent) is None:
         tests_by_parent[parent] = []
     tests_by_parent[parent].append(msg)
     tests_by_id[msg["test_id"]] = msg
@@ -207,183 +352,138 @@
     test_type = get_type(msg)
     test_subtype = get_subtype(msg)
 
     if test_subtype == TestSubType.Example:
         keyword += "Example"
     elif test_type == TestType.Module:
         if test_subtype == TestSubType.Book:
-            keyword += "BOOK"
+            keyword += "Book"
         else:
-            keyword += "MODULE"
+            keyword += "Module"
     elif test_type == TestType.Suite:
         if test_subtype == TestSubType.Feature:
-            keyword += "FEATURE"
+            keyword += "Feature"
         elif test_subtype == TestSubType.Chapter:
-            keyword += "CHAPTER"
+            keyword += "Chapter"
         else:
-            keyword += "SUITE"
+            keyword += "Suite"
     elif test_type == TestType.Iteration:
         keyword += "Iteration"
     elif test_type == TestType.RetryIteration:
         keyword += "Retry"
     elif test_type == TestType.Step:
         if test_subtype == TestSubType.And:
-            keyword += "\u25a1 And"
+            keyword += "And"
         elif test_subtype == TestSubType.Given:
-            keyword += and_keyword(msg, parent, "\u25a1 Given", TestSubType.Given)
+            keyword += and_keyword(msg, parent, "Given", TestSubType.Given)
         elif test_subtype == TestSubType.When:
-            keyword += and_keyword(msg, parent, "\u25a1 When", TestSubType.When)
+            keyword += and_keyword(msg, parent, "When", TestSubType.When)
         elif test_subtype == TestSubType.Then:
-            keyword += and_keyword(msg, parent, "\u25a1 Then", TestSubType.Then)
+            keyword += and_keyword(msg, parent, "Then", TestSubType.Then)
         elif test_subtype == TestSubType.By:
-            keyword += and_keyword(msg, parent, "\u25a1 By", TestSubType.By)
+            keyword += and_keyword(msg, parent, "By", TestSubType.By)
         elif test_subtype == TestSubType.But:
-            keyword += and_keyword(msg, parent, "\u25a1 But", TestSubType.But)
+            keyword += and_keyword(msg, parent, "But", TestSubType.But)
         elif test_subtype == TestSubType.Finally:
-            keyword += and_keyword(msg, parent, "\u25a1 Finally", TestSubType.Finally)
+            keyword += and_keyword(msg, parent, "Finally", TestSubType.Finally)
         elif test_subtype == TestSubType.Cleanup:
-            keyword += and_keyword(msg, parent, "\u25a1 Cleanup", TestSubType.Cleanup)
+            keyword += and_keyword(msg, parent, "Cleanup", TestSubType.Cleanup)
         elif test_subtype == TestSubType.Background:
-            keyword += and_keyword(msg, parent, "\u25a1 Background", TestSubType.Background)
+            keyword += and_keyword(msg, parent, "Background", TestSubType.Background)
         elif test_subtype == TestSubType.Paragraph:
-            keyword += and_keyword(msg, parent, "\u25a1 Paragraph", TestSubType.Paragraph)
+            keyword += and_keyword(msg, parent, "Paragraph", TestSubType.Paragraph)
         else:
-            keyword += "\u25a1 Step"
+            keyword += "Step"
     elif test_type == TestType.Outline:
-        keyword += "OUTLINE"
+        keyword += "Outline"
     else:
         if test_subtype == TestSubType.Scenario:
-            keyword += "SCENARIO"
+            keyword += "Scenario"
         elif test_subtype == TestSubType.Check:
-            keyword += "CHECK"
+            keyword += "Check"
         elif test_subtype == TestSubType.Critical:
-            keyword += "CRITICAL"
+            keyword += "Critical"
         elif test_subtype == TestSubType.Major:
-            keyword += "MAJOR"
+            keyword += "Major"
         elif test_subtype == TestSubType.Minor:
-            keyword += "MINOR"
+            keyword += "Minor"
         elif test_subtype == TestSubType.Recipe:
-            keyword += "RECIPE"
+            keyword += "Recipe"
         elif test_subtype == TestSubType.Document:
-            keyword += "DOCUMENT"
+            keyword += "Document"
         elif test_subtype == TestSubType.Page:
-            keyword += "PAGE"
+            keyword += "Page"
         elif test_subtype == TestSubType.Section:
-            keyword += "SECTION"
+            keyword += "Section"
         else:
-            keyword += "TEST"
+            keyword += "Test"
 
     _keyword = color_keyword(keyword, no_colors=no_colors)
     _name = color_test_name(split(msg["test_name"])[-1], no_colors=no_colors)
-
-    out = ""
-
-    if test_type > TestType.Step:
-        out += clear_screen()
-
-    if test_type > TestType.Step:
-        out += f"{separators[test_type]}"
-
-    out += f"{_keyword} {_name}\n"
+    _indent = indent * (msg["test_id"].count("/") - 1)
+    out = f"{_indent}{_keyword} {_name}\n"
     if msg["test_description"]:
-        out += format_test_description(msg, "", no_colors=no_colors)
-
-    if test_type > TestType.Step:
-        out += f"{separators[test_type]}"
-
+        out += format_test_description(msg, _indent, no_colors=no_colors)
     return out
 
-def format_result(msg, no_colors=False):
+
+def format_result(msg, no_colors=False, use_indent=False, use_full_testname=False):
     result = msg["result_type"]
-    test_type = get_type(msg)
-    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(msg["test_flags"])
+    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(
+        msg["test_flags"]
+    )
     _color = color_result(result, no_colors=no_colors, retry=_retry)
-    _result = _color(f"\u25b6  " + result, no_colors=no_colors)
-    _test = color_test_name(basename(msg["result_test"]), no_colors=no_colors)
-    _indent = ""
+    _result = _color(result, no_colors=no_colors)
+    if use_full_testname:
+        _test = color_test_name(
+            msg["result_test"], no_colors=no_colors, use_full_testname=use_full_testname
+        )
+    else:
+        _test = color_test_name(basename(msg["result_test"]), no_colors=no_colors)
+
+    if use_indent is False:
+        _indent = indent * (msg["test_id"].count("/") - 1)
+    else:
+        _indent = use_indent
 
-    out = f"{_result}"
-    out += f", {_test}"
+    out = f"{_indent}{_result}"
 
     _result_message = msg["result_message"]
     if _result_message and settings.trim_results and int(msg["test_level"]) > 1:
-        _result_message = _result_message.strip().split("\n",1)[0].strip()
+        _result_message = _result_message.strip().split("\n", 1)[0].strip()
 
     if result in ("Fail", "Error", "Null"):
+        out += f" {_test}"
         if _result_message:
             out += color_test_name(",", no_colors=no_colors)
             out += f" {_color(format_multiline(_result_message, _indent).lstrip(), no_colors=no_colors)}"
     elif result.startswith("X"):
+        out += f" {_test}"
         if msg["result_reason"]:
             out += color_test_name(",", no_colors=no_colors)
             out += f" {_color(msg['result_reason'], no_colors=no_colors)}"
-    elif _result_message:
-        out += color_test_name(",", no_colors=no_colors)
-        out += f" {_color(format_multiline(_result_message, _indent).lstrip(), no_colors=no_colors)}"
-
-    out += "\n"
-
-    if test_type > TestType.Step:
-        out += f"{separators[test_type]}"
-
-    return out
-
-def format_message(msg, keyword, prefix="", predicate=None, no_colors=False):
-    out = msg["message"]
-    if msg["message_stream"]:
-        out = f"[{msg['message_stream']}] {msg['message']}"
-    out = out.strip(" ")
-    if out.endswith("\n"):
-        out = out[:-1]
-    out = textwrap.indent(out, prefix=prefix, predicate=predicate)
-    return color_other(f"{keyword}{color_other(out, no_colors=no_colors)}\n", no_colors=no_colors)
-
-def format_metric(msg, keyword, no_colors=False):
-    _indent = ""
-    out = [color_other(f"{keyword}", no_colors=no_colors) + color("Metric", "white", attrs=["dim", "bold"], no_colors=no_colors) + color_other(f" {msg['metric_name']}", no_colors=no_colors)]
-    out.append(color_other(format_multiline(f"{msg['metric_value']} {msg['metric_units']}", _indent + " " * 2), no_colors=no_colors))
-    return "\n".join(out) + "\n"
-
-def format_value(msg, keyword, no_colors=False):
-    _indent = ""
-    out = [color_other(f"{keyword}", no_colors=no_colors) + color("Value", "white", attrs=["dim", "bold"], no_colors=no_colors) + color_other(f" {msg['value_name']}", no_colors=no_colors)]
-    out.append(color_other(format_multiline(f"{msg['value_value']}", _indent + " " * 2), no_colors=no_colors))
-    return "\n".join(out) + "\n"
+    return out + "\n"
 
-def format_ticket(msg, keyword, no_colors=False):
-    _indent = ""
-    out = [color_other(f"{keyword}", no_colors=no_colors) + color("Ticket", "white", attrs=["dim", "bold"], no_colors=no_colors) + color_other(f" {msg['ticket_name']}", no_colors=no_colors)]
-    out.append(color_other(format_multiline(f"{msg['ticket_link']}", _indent + " " * 2), no_colors=no_colors))
-    return "\n".join(out) + "\n"
 
 formatters = {
     Message.INPUT.name: (format_input, f""),
     Message.PROMPT.name: (format_prompt, f""),
     Message.TEST.name: (format_test, f"", tests_by_parent, tests_by_id),
     Message.RESULT.name: (format_result,),
     Message.ATTRIBUTE.name: (format_attribute,),
     Message.ARGUMENT.name: (format_argument,),
     Message.SPECIFICATION.name: (format_specification,),
     Message.REQUIREMENT.name: (format_requirement,),
     Message.TAG.name: (format_tag,),
     Message.EXAMPLE.name: (format_example,),
-    Message.VALUE.name: (format_value, f""),
-    Message.METRIC.name: (format_metric, f""),
-    Message.TICKET.name: (format_ticket, f""),
-    Message.EXCEPTION.name: (format_message, f""),
-    Message.TEXT.name: (format_message, f"", f"\u270e    ", lambda line: True),
-    Message.NOTE.name: (format_message, f"[note] "),
-    Message.DEBUG.name: (format_message, f"[debug] "),
-    Message.TRACE.name: (format_message, f"[trace] "),
-    Message.NONE.name: (format_message, ""),
 }
 
+
 def transform(no_colors=False, show_input=True):
-    """Transform parsed log line into 'manual' format.
-    """
+    """Transform parsed log line into a short format."""
     line = None
     while True:
         if line is not None:
             msg = line
             formatter = formatters.get(line["message_keyword"], None)
             if formatter:
                 if formatter[0] is format_input and show_input is False:
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/nice.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/nice.py`

 * *Files 15% similar despite different names*

```diff
@@ -23,35 +23,40 @@
 from testflows._core.message import Message
 from testflows._core.objects import ExamplesTable
 from testflows._core.utils.timefuncs import strftime, strftimedelta
 from testflows._core.utils.timefuncs import localfromtimestamp
 from testflows._core.name import split, basename, parentname
 from testflows._core.cli.colors import color, cursor_up
 
-strip_nones = re.compile(r'( None)+$')
+strip_nones = re.compile(r"( None)+$")
 indent = " " * 2
 #: map of tests by name
 tests_by_name = {}
 #: map of tests by parent
 tests_by_parent = {}
 #: last message
 last_message = [None]
 
+
 def color_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold"])
 
+
 def color_secondary_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold", "dim"])
 
+
 def color_other(other):
     return color(other, "white", attrs=["dim"])
 
+
 def color_prefix(prefix):
     return color("\u22A1 ", "green") + color(prefix, "yellow", attrs=["dim"])
 
+
 def color_result(result, attrs=None, retry=False):
     if attrs is None:
         attrs = ["bold"]
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=attrs)
     elif result == "OK":
         return functools.partial(color, color="green", attrs=attrs)
@@ -64,134 +69,230 @@
     elif result == "Fail":
         return functools.partial(color, color="red", attrs=attrs)
     elif result == "Null":
         return functools.partial(color, color="magenta", attrs=attrs)
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def format_prompt(msg, keyword):
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
     out = color(icon + lines[0], "yellow", attrs=["bold"])
     if len(lines) > 1:
         out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"])
     return out
 
+
 def format_input(msg, keyword):
-    out = color(msg['message'], "white") + "\n"
+    out = color(msg["message"], "white") + "\n"
     return out
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
     out = textwrap.indent(out, indent + "  ")
     return out
 
+
 def format_test_description(msg, indent):
     desc = format_multiline(msg["test_description"], indent)
     desc = color(desc, "white", attrs=["dim"])
     return desc + "\n"
 
+
 def format_requirements(msg, indent):
     out = [f"{indent}{' ' * 2}{color_secondary_keyword('Requirements')}"]
     for req in msg.requirements:
         out.append(color(f"{indent}{' ' * 4}{req.name}", "white", attrs=["dim"]))
-        out.append(color(f"{indent}{' ' * 6}version {req.version}", "white", attrs=["dim"]))
+        out.append(
+            color(f"{indent}{' ' * 6}version {req.version}", "white", attrs=["dim"])
+        )
     return "\n".join(out) + "\n"
 
+
 def format_attribute(msg):
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name:
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Attributes')}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['attribute_name']}", "white", attrs=["dim"]))
-    out.append(color(f"{textwrap.indent(str(msg['attribute_value']), prefix=(_indent + ' ' * 6))}", "white", attrs=["dim"]))
+    out.append(
+        color(f"{_indent}{' ' * 4}{msg['attribute_name']}", "white", attrs=["dim"])
+    )
+    out.append(
+        color(
+            f"{textwrap.indent(str(msg['attribute_value']), prefix=(_indent + ' ' * 6))}",
+            "white",
+            attrs=["dim"],
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_specification(msg):
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name:
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Specifications')}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['specification_name']}", "white", attrs=["dim"]))
+    out.append(
+        color(f"{_indent}{' ' * 4}{msg['specification_name']}", "white", attrs=["dim"])
+    )
     if msg["specification_version"]:
-        out.append(color(f"{_indent}{' ' * 6}version {msg['specification_version']}", "white", attrs=["dim"]))
+        out.append(
+            color(
+                f"{_indent}{' ' * 6}version {msg['specification_version']}",
+                "white",
+                attrs=["dim"],
+            )
+        )
     return "\n".join(out) + "\n"
 
+
 def format_requirement(msg):
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name:
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Requirements')}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['requirement_name']}", "white", attrs=["dim"]))
-    out.append(color(f"{_indent}{' ' * 6}version {msg['requirement_version']}", "white", attrs=["dim"]))
+    out.append(
+        color(f"{_indent}{' ' * 4}{msg['requirement_name']}", "white", attrs=["dim"])
+    )
+    out.append(
+        color(
+            f"{_indent}{' ' * 6}version {msg['requirement_version']}",
+            "white",
+            attrs=["dim"],
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_tag(msg):
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
     if last_message[0] and not last_message[0]["message_keyword"] == Message.TAG.name:
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Tags')}"]
 
     out.append(color(f"{_indent}{' ' * 4}{msg['tag_value']}", "white", attrs=["dim"]))
     return "\n".join(out) + "\n"
 
+
 def format_example(msg):
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(msg["example_columns"], msg["example_values"])
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.EXAMPLE.name:
+    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(
+        msg["example_columns"], msg["example_values"]
+    )
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.EXAMPLE.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Examples')}"]
-        out.append(color(textwrap.indent(f"{ExamplesTable.__str_header__(tuple(msg['example_columns']), row_format)}", prefix=f"{_indent}{' ' * 4}"), "white", attrs=["dim"]))
-
-    out.append(color(textwrap.indent(f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}", prefix=f"{_indent}{' ' * 4}"), "white", attrs=["dim"]))
+        out.append(
+            color(
+                textwrap.indent(
+                    f"{ExamplesTable.__str_header__(tuple(msg['example_columns']), row_format)}",
+                    prefix=f"{_indent}{' ' * 4}",
+                ),
+                "white",
+                attrs=["dim"],
+            )
+        )
+
+    out.append(
+        color(
+            textwrap.indent(
+                f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}",
+                prefix=f"{_indent}{' ' * 4}",
+            ),
+            "white",
+            attrs=["dim"],
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_argument(msg):
     out = []
     _indent = f"{' ':>23}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.ARGUMENT.name:
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ARGUMENT.name
+    ):
         out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Arguments')}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['argument_name']}", "white", attrs=["dim"]))
-    out.append(color(textwrap.indent(f"{msg['argument_value']}", prefix=f"{_indent}{' ' * 6}"), "white", attrs=["dim"]))
+    out.append(
+        color(f"{_indent}{' ' * 4}{msg['argument_name']}", "white", attrs=["dim"])
+    )
+    out.append(
+        color(
+            textwrap.indent(f"{msg['argument_value']}", prefix=f"{_indent}{' ' * 6}"),
+            "white",
+            attrs=["dim"],
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def and_keyword(msg, parent_id, keyword, subtype):
     """Handle processing of Given, When, Then, But, By and Finally
     keywords and convert them to And when necessary.
     """
-    prev = tests_by_parent[parent_id][-2] if len(tests_by_parent.get(parent_id, [])) > 1 else None
-    if prev and get_subtype(prev) == subtype and tests_by_parent.get(prev["test_id"]) is None:
+    prev = (
+        tests_by_parent[parent_id][-2]
+        if len(tests_by_parent.get(parent_id, [])) > 1
+        else None
+    )
+    if (
+        prev
+        and get_subtype(prev) == subtype
+        and tests_by_parent.get(prev["test_id"]) is None
+    ):
         keyword = "And"
     parent = tests_by_name.get(parent_id)
-    if parent and get_subtype(parent) == subtype and len(tests_by_parent.get(parent_id, [])) == 1:
+    if (
+        parent
+        and get_subtype(parent) == subtype
+        and len(tests_by_parent.get(parent_id, [])) == 1
+    ):
         keyword = "And"
     return keyword
 
+
 def get_type(msg):
     return getattr(TestType, msg["test_type"])
 
+
 def get_subtype(msg):
     return getattr(TestSubType, str(msg["test_subtype"]), 0)
 
+
 def format_test(msg, keyword):
     # add test to the tests map
     parent = parentname(msg["test_id"])
     if tests_by_parent.get(parent) is None:
         tests_by_parent[parent] = []
     tests_by_parent[parent].append(msg)
     tests_by_name[msg["test_id"]] = msg
@@ -272,74 +373,124 @@
     out = f"{color_other(_indent)}{_keyword} {_name}{color_other(', flags:' + str(flags) if flags else '')}\n"
     # convert indent to just spaces
     _indent = (len(_indent) + 3) * " "
     if msg["test_description"]:
         out += format_test_description(msg, _indent)
     return out
 
+
 def format_result(msg, prefix):
     result = msg["result_type"]
-    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(msg["test_flags"])
+    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(
+        msg["test_flags"]
+    )
     _color = color_result(result, retry=_retry)
     _result = _color(prefix + result)
     _test = color_other(basename(msg["result_test"]))
-    _indent = f"{strftimedelta(msg['message_rtime']):>20}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    _indent = (
+        f"{strftimedelta(msg['message_rtime']):>20}"
+        + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    )
 
     _result_message = msg["result_message"]
     if _result_message and settings.trim_results and int(msg["test_level"]) > 1:
-        _result_message = _result_message.strip().split("\n",1)[0].strip()
+        _result_message = _result_message.strip().split("\n", 1)[0].strip()
 
-    out = (f"{color_other(_indent)}{_result} "
+    out = (
+        f"{color_other(_indent)}{_result} "
         f"{_test}{color_other(', ' + msg['result_test'])}"
         f"{(color_other(', ') + _color(format_multiline(_result_message, ' ' * len(_indent)).strip())) if _result_message else ''}"
-        f"{(color_other(', ') + _color(msg['result_reason'])) if msg['result_reason'] else ''}\n")
+        f"{(color_other(', ') + _color(msg['result_reason'])) if msg['result_reason'] else ''}\n"
+    )
 
     return out
 
+
 def format_message(msg, keyword, prefix="", predicate=None):
     out = msg["message"]
     if msg["message_stream"]:
         out = f"[{msg['message_stream']}] {msg['message']}"
 
-    out = textwrap.indent(out, predicate=predicate, prefix=(indent * (msg['test_id'].count('/') - 1) + " " * 30 + prefix))
+    out = textwrap.indent(
+        out,
+        predicate=predicate,
+        prefix=(indent * (msg["test_id"].count("/") - 1) + " " * 30 + prefix),
+    )
     out = out.lstrip(" ")
     if out.endswith("\n"):
         out = out[:-1]
 
-    return color_other(f"{strftimedelta(msg['message_rtime']):>20}{'':3}{indent * (msg['test_id'].count('/') - 1)}{keyword} {color_other(out)}\n")
+    return color_other(
+        f"{strftimedelta(msg['message_rtime']):>20}{'':3}{indent * (msg['test_id'].count('/') - 1)}{keyword} {color_other(out)}\n"
+    )
+
 
 def format_metric(msg, keyword):
-    prefix = f"{strftimedelta(msg['message_rtime']):>20}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    prefix = (
+        f"{strftimedelta(msg['message_rtime']):>20}"
+        + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    )
     _indent = (len(prefix) + 3) * " "
-    out = [color_other(f"{prefix}{keyword}") + color("Metric", "white", attrs=["dim", "bold"]) + color_other(f" {msg['metric_name']}")]
-    out.append(color_other(format_multiline(f"{msg['metric_value']} {msg['metric_units']}", _indent + " " * 2)))
+    out = [
+        color_other(f"{prefix}{keyword}")
+        + color("Metric", "white", attrs=["dim", "bold"])
+        + color_other(f" {msg['metric_name']}")
+    ]
+    out.append(
+        color_other(
+            format_multiline(
+                f"{msg['metric_value']} {msg['metric_units']}", _indent + " " * 2
+            )
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_value(msg, keyword):
-    prefix = f"{strftimedelta(msg['message_rtime']):>20}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    prefix = (
+        f"{strftimedelta(msg['message_rtime']):>20}"
+        + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    )
     _indent = (len(prefix) + 3) * " "
-    out = [color_other(f"{prefix}{keyword}") + color("Value", "white", attrs=["dim", "bold"]) + color_other(f" {msg['value_name']}")]
-    out.append(color_other(format_multiline(f"{msg['value_value']}", _indent + " " * 2)))
+    out = [
+        color_other(f"{prefix}{keyword}")
+        + color("Value", "white", attrs=["dim", "bold"])
+        + color_other(f" {msg['value_name']}")
+    ]
+    out.append(
+        color_other(format_multiline(f"{msg['value_value']}", _indent + " " * 2))
+    )
     return "\n".join(out) + "\n"
 
+
 def format_ticket(msg, keyword):
-    prefix = f"{strftimedelta(msg['message_rtime']):>20}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    prefix = (
+        f"{strftimedelta(msg['message_rtime']):>20}"
+        + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    )
     _indent = (len(prefix) + 3) * " "
-    out = [color_other(f"{prefix}{keyword}") + color("Ticket", "white", attrs=["dim", "bold"]) + color_other(f" {msg['ticket_name']}")]
-    out.append(color_other(format_multiline(f"{msg['ticket_link']}", _indent + " " * 2)))
+    out = [
+        color_other(f"{prefix}{keyword}")
+        + color("Ticket", "white", attrs=["dim", "bold"])
+        + color_other(f" {msg['ticket_name']}")
+    ]
+    out.append(
+        color_other(format_multiline(f"{msg['ticket_link']}", _indent + " " * 2))
+    )
     return "\n".join(out) + "\n"
 
+
 mark = "\u27e5"
 result_mark = "\u27e5\u27e4"
 
 formatters = {
     Message.INPUT.name: (format_input, f"{mark} "),
     Message.PROMPT.name: (format_prompt, f"{mark} "),
     Message.TEST.name: (format_test, f"{mark}  "),
-    Message.ATTRIBUTE.name: (format_attribute, ),
+    Message.ATTRIBUTE.name: (format_attribute,),
     Message.ARGUMENT.name: (format_argument,),
     Message.SPECIFICATION.name: (format_specification,),
     Message.REQUIREMENT.name: (format_requirement,),
     Message.TAG.name: (format_tag,),
     Message.EXAMPLE.name: (format_example,),
     Message.VALUE.name: (format_value, f"{mark}    "),
     Message.METRIC.name: (format_metric, f"{mark}    "),
@@ -349,14 +500,15 @@
     Message.NOTE.name: (format_message, f"{mark}    [note]"),
     Message.DEBUG.name: (format_message, f"{mark}    [debug]"),
     Message.TRACE.name: (format_message, f"{mark}    [trace]"),
     Message.NONE.name: (format_message, "    "),
     Message.RESULT.name: (format_result, f"{result_mark} "),
 }
 
+
 def transform(show_input=True, add_test_name_prefix=False):
     """Transform parsed log line into a nice format."""
     line = None
     test_types = {}
 
     while True:
         if line is not None:
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/parse.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/parse.py`

 * *Files 1% similar despite different names*

```diff
@@ -13,17 +13,17 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows.settings as settings
 
 from testflows._core.constants import id_sep
 from testflows._core.message import Message, loads
 
+
 def transform():
-    """Transform log line by parsing it.
-    """
+    """Transform log line by parsing it."""
     msg = None
     parsed_msg = None
 
     while True:
         if msg is not None:
             try:
                 parsed_msg = loads(msg)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/pipeline.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -38,40 +38,42 @@
 from .report.unstable import transform as unstable_report_transform
 from .report.totals import transform as totals_report_transform
 from .report.version import transform as version_report_transform
 from .report.coverage import transform as coverage_report_transform
 from .report.metrics import transform as metrics_transform
 from .report.results import transform as results_transform
 
+
 class Pipeline(object):
     """Combines multiple steps into a pipeline
     that can be executed.
     """
+
     def __init__(self, steps, stop=None):
         self.steps = steps
         self.stop = stop
         # start all the generators
         for step in self.steps:
             next(step)
 
     def run(self):
-        """Execute pipeline.
-        """
+        """Execute pipeline."""
         item = None
         while True:
             try:
                 for step in self.steps:
                     item = step.send(item)
                     if self.stop and self.stop.is_set():
                         continue
                     if item is None:
                         break
             except StopIteration:
                 break
 
+
 def fanout(*steps):
     """Single step of pipeline
     that feeds the same input to
     multiple steps and produces
     a list of outputs from each step.
 
     :param *steps: fan out steps
@@ -82,60 +84,65 @@
         for step in steps:
             output = step.send(item)
             if output is not None:
                 outputs.append(output)
         item = yield outputs or None
         outputs = []
 
+
 def fanin(combinator):
     """Combine multiple outputs into one.
     using the combinator
     """
     item = None
     while True:
         if item is not None:
             item = combinator(item)
         item = yield item
 
+
 class RawLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             raw_transform(),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(RawLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class ReadRawLogPipeline(Pipeline):
     def __init__(self, input, output, encoding=None):
         stop_event = threading.Event()
 
         steps = [
             read_raw_transform(input, stop=stop_event, encoding=encoding),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(ReadRawLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class QuietLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
             quiet_transform(show_input=show_input),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(QuietLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class ShortLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -144,22 +151,21 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(ShortLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class NiceLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -168,22 +174,21 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(NiceLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class ParallelNiceLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -192,22 +197,21 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(ParallelNiceLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class BriskLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -216,22 +220,21 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(BriskLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class SlickLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -240,22 +243,21 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(SlickLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class ManualLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -264,22 +266,21 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(ManualLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class ClassicLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -288,44 +289,42 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(ClassicLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class FailsLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, only_new=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
             fanout(
                 fails_transform(only_new=only_new, show_input=show_input),
                 fails_report_transform(stop_event, only_new=only_new),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(FailsLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class DotsLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -334,22 +333,21 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(DotsLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class ProgressLogPipeline(Pipeline):
     def __init__(self, input, output, tail=False, show_input=True):
         stop_event = threading.Event()
 
         steps = [
             read_transform(input, tail=tail, stop=stop_event),
             parse_transform(),
@@ -358,194 +356,193 @@
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
                 version_report_transform(stop_event),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(ProgressLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class MetricsLogPipeline(Pipeline):
     def __init__(self, input, metrics):
         stop_event = threading.Event()
 
         message_types = [Message.METRIC.name, Message.STOP.name]
-        grep = "grep -E '^\\{\"message_keyword\":\""
+        grep = 'grep -E \'^\\{"message_keyword":"'
         command = f"{grep}({'|'.join(message_types)})\"'"
 
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             metrics_transform(metrics),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(MetricsLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class ResultsReportLogPipeline(Pipeline):
     def __init__(self, input, output):
         stop_event = threading.Event()
 
         message_types = [Message.TEST.name, Message.RESULT.name, Message.STOP.name]
-        grep = "grep -E '^\\{\"message_keyword\":\""
+        grep = 'grep -E \'^\\{"message_keyword":"'
         command = f"{grep}({'|'.join(message_types)})\"'"
 
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             fanout(
                 passing_report_transform(stop_event),
                 fails_report_transform(stop_event),
                 unstable_report_transform(stop_event),
                 coverage_report_transform(stop_event),
                 totals_report_transform(stop_event),
-                version_report_transform(stop_event)
-            ),
-            fanin(
-                "".join
+                version_report_transform(stop_event),
             ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(ResultsReportLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class TotalsReportLogPipeline(Pipeline):
     def __init__(self, input, output):
         stop_event = threading.Event()
 
         message_types = [Message.TEST.name, Message.RESULT.name, Message.STOP.name]
-        grep = "grep -E '^\\{\"message_keyword\":\""
+        grep = 'grep -E \'^\\{"message_keyword":"'
         command = f"{grep}({'|'.join(message_types)})\"'"
 
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             fanout(
                 totals_report_transform(stop_event, divider=""),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(TotalsReportLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class FailsReportLogPipeline(Pipeline):
     def __init__(self, input, output, only_new=False):
         stop_event = threading.Event()
 
         message_types = [Message.RESULT.name, Message.STOP.name]
-        grep = "grep -E '^\\{\"message_keyword\":\""
+        grep = 'grep -E \'^\\{"message_keyword":"'
         command = f"{grep}({'|'.join(message_types)})\"'"
 
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             fanout(
                 fails_report_transform(stop_event, divider="", only_new=only_new),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(FailsReportLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class PassingReportLogPipeline(Pipeline):
     def __init__(self, input, output):
         stop_event = threading.Event()
 
         message_types = [Message.RESULT.name, Message.STOP.name]
-        grep = "grep -E '^\\{\"message_keyword\":\""
+        grep = 'grep -E \'^\\{"message_keyword":"'
         command = f"{grep}({'|'.join(message_types)})\"'"
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             fanout(
                 passing_report_transform(stop_event, divider=""),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(PassingReportLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class UnstableReportLogPipeline(Pipeline):
     def __init__(self, input, output):
         stop_event = threading.Event()
 
         message_types = [Message.RESULT.name, Message.STOP.name]
-        grep = "grep -E '^\\{\"message_keyword\":\""
+        grep = 'grep -E \'^\\{"message_keyword":"'
         command = f"{grep}({'|'.join(message_types)})\"'"
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             fanout(
                 unstable_report_transform(stop_event, divider=""),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(UnstableReportLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class CoverageReportLogPipeline(Pipeline):
     def __init__(self, input, output):
         stop_event = threading.Event()
 
-        message_types = [Message.TEST.name, Message.RESULT.name, Message.REQUIREMENT.name, Message.SPECIFICATION.name, Message.STOP.name]
-        grep = "grep -E '^\\{\"message_keyword\":\""
+        message_types = [
+            Message.TEST.name,
+            Message.RESULT.name,
+            Message.REQUIREMENT.name,
+            Message.SPECIFICATION.name,
+            Message.STOP.name,
+        ]
+        grep = 'grep -E \'^\\{"message_keyword":"'
         command = f"{grep}({'|'.join(message_types)})\"'"
 
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             fanout(
                 coverage_report_transform(stop_event, divider=""),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(CoverageReportLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class VersionReportLogPipeline(Pipeline):
     def __init__(self, input, output):
         stop_event = threading.Event()
 
         message_types = [Message.VERSION.name, Message.STOP.name]
-        grep = "grep -m2 -E '^{\"message_keyword\":\""
+        grep = 'grep -m2 -E \'^{"message_keyword":"'
         command = f"{grep}({'|'.join(message_types)})\"'"
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             fanout(
                 version_report_transform(stop_event, divider=""),
             ),
-            fanin(
-                "".join
-            ),
+            fanin("".join),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(VersionReportLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class ResultsLogPipeline(Pipeline):
     def __init__(self, input, results, steps=True):
         stop_event = threading.Event()
         message_types = [
             Message.PROTOCOL.name,
             Message.VERSION.name,
             Message.TEST.name,
@@ -556,29 +553,32 @@
             Message.ARGUMENT.name,
             Message.SPECIFICATION.name,
             Message.REQUIREMENT.name,
             Message.EXAMPLE.name,
             Message.TICKET.name,
             Message.VALUE.name,
             Message.METRIC.name,
-            Message.STOP.name
+            Message.STOP.name,
         ]
         test_types = [TestType.Module.name, TestType.Suite.name, TestType.Test.name]
-        command = "grep -E '^\\{\"message_keyword\":\""
-        command = (f"{command}({'|'.join(message_types)})\""
-            + ((".+\"test_type\":\"" + f"({'|'.join(test_types)})\"") if not steps else "")
-            + "'")
+        command = 'grep -E \'^\\{"message_keyword":"'
+        command = (
+            f"{command}({'|'.join(message_types)})\""
+            + (('.+"test_type":"' + f"({'|'.join(test_types)})\"") if not steps else "")
+            + "'"
+        )
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             parse_transform(),
             results_transform(results),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(ResultsLogPipeline, self).__init__(steps, stop=stop_event)
 
+
 class CompactRawLogPipeline(Pipeline):
     def __init__(self, input, output, steps=True):
         stop_event = threading.Event()
         message_types = [
             Message.PROTOCOL.name,
             Message.VERSION.name,
             Message.TEST.name,
@@ -588,21 +588,23 @@
             Message.TAG.name,
             Message.ARGUMENT.name,
             Message.REQUIREMENT.name,
             Message.EXAMPLE.name,
             Message.TICKET.name,
             Message.VALUE.name,
             Message.METRIC.name,
-            Message.STOP.name
+            Message.STOP.name,
         ]
         test_types = [TestType.Module.name, TestType.Suite.name, TestType.Test.name]
-        command = "grep -E '^\\{\"message_keyword\":\""
-        command = (f"{command}({'|'.join(message_types)})\""
-            + ((".+\"test_type\":\"" + f"({'|'.join(test_types)})\"") if not steps else "")
-            + "'")
+        command = 'grep -E \'^\\{"message_keyword":"'
+        command = (
+            f"{command}({'|'.join(message_types)})\""
+            + (('.+"test_type":"' + f"({'|'.join(test_types)})\"") if not steps else "")
+            + "'"
+        )
         steps = [
             read_and_filter_transform(input, command=command, stop=stop_event),
             raw_transform(),
             write_transform(output),
-            stop_transform(stop_event)
+            stop_transform(stop_event),
         ]
         super(CompactRawLogPipeline, self).__init__(steps, stop=stop_event)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/procedure.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/procedure.py`

 * *Files 8% similar despite different names*

```diff
@@ -14,21 +14,19 @@
 # limitations under the License.
 import testflows.settings as settings
 
 from testflows._core.flags import Flags, SKIP
 from testflows._core.message import Message
 from testflows._core.transform.log.short import formatters, last_message
 
-formatters = {
-    Message.TEST.name: formatters[Message.TEST.name]
-}
+formatters = {Message.TEST.name: formatters[Message.TEST.name]}
+
 
 def transform():
-    """Transform parsed log line into a procedure format.
-    """
+    """Transform parsed log line into a procedure format."""
     line = None
     while True:
         if line is not None:
             msg = line
 
             formatter = formatters.get(line["message_keyword"], None)
 
@@ -37,8 +35,8 @@
                 if flags & SKIP and settings.show_skipped is False:
                     line = None
                 else:
                     line = formatter[0](line, *formatter[1:])
                     last_message[0] = msg
             else:
                 line = None
-        line = yield line
+        line = yield line
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/progress.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/progress.py`

 * *Files 9% similar despite different names*

```diff
@@ -19,26 +19,29 @@
 from testflows._core.message import Message
 from testflows._core.testtype import TestType
 from .report.totals import Counts
 from .short import format_result as format_failing_result
 
 progress = [
     color("Executing", "white", attrs=["dim"]),
-    color("Executed", "white", attrs=["dim"])
+    color("Executed", "white", attrs=["dim"]),
 ]
 
+
 def clear_line():
     return "\r\033[K\r"
 
+
 def short_test_name(msg, max=80, tail=20):
     test_name = msg["test_name"]
     if len(test_name) > max:
-        test_name = test_name[:max-tail] + "..." + test_name[-tail:]
+        test_name = test_name[: max - tail] + "..." + test_name[-tail:]
     return color(test_name, "white", attrs=["dim"])
 
+
 def format_prompt(msg, *_):
     global count
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
     out = ""
@@ -46,20 +49,22 @@
         out += "\n"
     out += color(icon + lines[0], "yellow", attrs=["bold"])
     if len(lines) > 1:
         out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"])
     count = 0
     return out
 
+
 def format_input(msg, *_):
     global count
-    out = color(msg['message'], "white") + "\n"
+    out = color(msg["message"], "white") + "\n"
     count = 0
     return out
 
+
 def format_result(msg, counter, counts):
     flags = Flags(msg["test_flags"])
     result = msg["result_type"]
 
     if flags & SKIP and settings.show_skipped is False:
         return
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
@@ -67,42 +72,47 @@
 
     counter[0] += 1
     _result = msg["result_type"].lower()
 
     setattr(counts, _result, getattr(counts, _result) + 1)
     out = f"{clear_line()}{progress[counter[0] % (len(progress) - 1)]} {str(counts).rstrip()} {short_test_name(msg)}"
     if result in ("Fail", "Error", "Null"):
-        out += "\n" + format_failing_result(msg, use_full_testname=True, use_indent=" "*2)
+        out += "\n" + format_failing_result(
+            msg, use_full_testname=True, use_indent=" " * 2
+        )
     return out
 
+
 def format_test(msg, counter, counts):
     flags = Flags(msg["test_flags"])
 
     if flags & SKIP and settings.show_skipped is False:
         return
     if getattr(TestType, msg["test_type"]) >= TestType.Iteration:
         counts.units += 1
     counter[0] += 1
 
     return f"{clear_line()}{progress[counter[0] % (len(progress)-1)]} {str(counts).rstrip()} {short_test_name(msg)}"
 
+
 def format_stop(msg, counter, counts):
     return f"{clear_line()}{progress[-1]} {counts}".rstrip()
 
+
 formatters = {
     Message.INPUT.name: (format_input,),
     Message.PROMPT.name: (format_prompt,),
     Message.RESULT.name: (format_result,),
     Message.TEST.name: (format_test,),
-    Message.STOP.name: (format_stop,)
+    Message.STOP.name: (format_stop,),
 }
 
+
 def transform(stop_event, show_input=True):
-    """Transform parsed log line into a progress format.
-    """
+    """Transform parsed log line into a progress format."""
     line = None
     counter = [-1]
     counts = Counts("tests", *([0] * 11))
 
     while True:
         if line is not None:
             formatter = formatters.get(line["message_keyword"], None)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/quiet.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/quiet.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,23 +22,27 @@
 from testflows._core.message import Message
 from testflows._core.utils.timefuncs import strftimedelta
 from testflows._core.name import split, basename
 from testflows._core.cli.colors import color
 
 indent = " " * 2
 
+
 def color_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold"])
 
+
 def color_secondary_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold", "dim"])
 
+
 def color_other(other):
     return color(other, "white", attrs=["dim"])
 
+
 def color_result(result, attrs=None, retry=False):
     if attrs is None:
         attrs = ["bold"]
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=attrs)
     elif result == "OK":
         return functools.partial(color, color="green", attrs=attrs)
@@ -51,77 +55,90 @@
     elif result == "Fail":
         return functools.partial(color, color="red", attrs=attrs)
     elif result == "Null":
         return functools.partial(color, color="magenta", attrs=attrs)
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def format_prompt(msg, keyword):
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
     out = color(icon + lines[0], "yellow", attrs=["bold"])
     if len(lines) > 1:
         out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"])
     return out
 
+
 def format_input(msg, keyword):
-    out = color(msg['message'], "white") + "\n"
+    out = color(msg["message"], "white") + "\n"
     return out
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
     out = textwrap.indent(out, indent + "  ")
     return out
 
+
 def get_type(msg):
     return getattr(TestType, msg["test_type"])
 
+
 def get_subtype(msg):
     return getattr(TestSubType, str(msg["test_subtype"]), 0)
 
+
 def format_result(msg, prefix):
     if int(msg["test_level"]) > 1:
         return
 
     result = msg["result_type"]
 
     if result in ("OK", "Skip") or result.startswith("X"):
         return
 
     _color = color_result(result)
     _result = _color(prefix + result)
     _test = color_other(basename(msg["result_test"]))
-    _indent = f"{strftimedelta(msg['message_rtime']):>10}" + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    _indent = (
+        f"{strftimedelta(msg['message_rtime']):>10}"
+        + f"{'':3}{indent * (msg['test_id'].count('/') - 1)}"
+    )
 
     _result_message = msg["result_message"]
     if _result_message and settings.trim_results and int(msg["test_level"]) > 1:
-        _result_message = _result_message.strip().split("\n",1)[0].strip()
+        _result_message = _result_message.strip().split("\n", 1)[0].strip()
 
-    out = (f"{color_other(_indent)}{_result} "
+    out = (
+        f"{color_other(_indent)}{_result} "
         f"{_test}{color_other(', ' + msg['result_test'])}"
         f"{(color_other(', ') + _color(format_multiline(_result_message, ' ' * len(_indent)).strip())) if _result_message else ''}"
-        f"{(color_other(', ') + _color(msg['result_reason'])) if msg['result_reason'] else ''}\n")
+        f"{(color_other(', ') + _color(msg['result_reason'])) if msg['result_reason'] else ''}\n"
+    )
 
     return out
 
+
 mark = "\u27e5"
 result_mark = "\u27e5\u27e4"
 
 formatters = {
     Message.INPUT.name: (format_input, f"{mark} "),
     Message.PROMPT.name: (format_prompt, f"{mark} "),
     Message.RESULT.name: (format_result, f"{result_mark} "),
 }
 
+
 def transform(show_input=True):
     """Transform parsed log line into a quiet format.
     Only output input, prompt messages as well as fails
     for top level test only.
     """
     line = None
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/raw.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/raw.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,16 +9,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 def transform():
-    """Transform raw message into raw format.
-    """
+    """Transform raw message into raw format."""
     msg = None
     while True:
         if msg is not None:
             if msg[0] != "{" and msg[-1] != "}":
                 msg = None
                 continue
         msg = yield msg
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/read.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/read.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,14 +12,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import time
 
 from testflows._core.message import Message
 
+
 def transform(file, tail=False, offset=False, stop=None):
     """Read lines from a file-like object.
 
     :param file: open file handle
     :param tail: tail mode, default: False
     :param offset: include offset with the message, default: False
     :param stop: stop event
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/read_and_filter.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/read_and_filter.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,29 +12,32 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import subprocess
 
 from testflows._core.message import Message
 
+
 def transform(file, command, tail=False, stop=None):
     """Read lines from a file-like object and
     filter them using Unix grep utility.
 
     :param file: open file handle
     :param command: filter command (like grep)
     :param tail: tail mode, default: False
     :param stop: stop event
     """
     yield None
 
     stop_keyword = ('{"message_keyword":"%s"' % str(Message.STOP)).encode("utf-8")
     stop_keyword_len = len(stop_keyword)
 
-    process = subprocess.Popen(f"tfs transform raw | {command}", stdin=file, stdout=subprocess.PIPE, shell=True)
+    process = subprocess.Popen(
+        f"tfs transform raw | {command}", stdin=file, stdout=subprocess.PIPE, shell=True
+    )
 
     while True:
         line = process.stdout.readline()
 
         if line == b"":
             if not tail:
                 break
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/read_raw.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/read_raw.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/coverage.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/coverage.py`

 * *Files 6% similar despite different names*

```diff
@@ -17,56 +17,61 @@
 
 from testflows._core.flags import Flags, SKIP
 from testflows._core.message import Message
 from testflows._core.cli.colors import color
 from testflows._core.document.srs import Parser, visit_parse_tree
 from testflows._core.document.toc import Visitor as VisitorBase
 
+
 def color_line(line):
     return color(line, "white", attrs=["dim"])
 
+
 def color_counts(result):
     if result == "Satisfied":
         return functools.partial(color, color="green", attrs=["bold"])
     elif result == "Unsatisfied":
         return functools.partial(color, color="red", attrs=["bold"])
     # Untested
     return functools.partial(color, color="yellow", attrs=["bold"])
 
+
 class Heading(object):
     def __init__(self, name, level, num):
         self.name = name
         self.level = level
         self.num = num
 
+
 class Requirement(Heading):
     def __init__(self, name, version, uid, level, num):
         self.version = version
         self.uid = uid
         return super(Requirement, self).__init__(name, level, num)
 
+
 class Visitor(VisitorBase):
     def __init__(self, *args, **kwargs):
         self.headings = []
         super(Visitor, self).__init__(*args, **kwargs)
 
     def visit_line(self, node, children):
         pass
 
     def visit_requirement(self, node, children):
         name = node.requirement_heading.requirement_name.value
         description = None
         uid = None
         version = None
         try:
-            uid = f"\"{node.uid.word}\""
+            uid = f'"{node.uid.word}"'
         except:
             pass
         try:
-            version = f"\"{node.version.word}\""
+            version = f'"{node.version.word}"'
         except:
             pass
         res = self.process_heading(node, children)
         if res:
             level, num = res
             self.headings.append(Requirement(name, version, uid, level, num))
 
@@ -76,14 +81,15 @@
             level, num = res
             name = node.heading_name.value
             self.headings.append(Heading(name, level, num))
 
     def visit_document(self, node, children):
         return self.headings
 
+
 class Counts(object):
     def __init__(self, name, units, ok, nok, untested):
         self.name = name
         self.units = units
         self.ok = ok
         self.nok = nok
         self.untested = untested
@@ -92,114 +98,146 @@
         return self.units > 0
 
     def __str__(self):
         s = f"{self.units} {self.name if self.units != 1 else self.name.rstrip('s')} ("
         s = color(s, "white", attrs=["bold"])
         r = []
         if self.ok > 0:
-            r.append(color_counts("Satisfied")(f"{self.ok} satisfied {(self.ok / self.units) * 100:.1f}%"))
+            r.append(
+                color_counts("Satisfied")(
+                    f"{self.ok} satisfied {(self.ok / self.units) * 100:.1f}%"
+                )
+            )
         if self.nok > 0:
-            r.append(color_counts("Unsatisfied")(f"{self.nok} unsatisfied {(self.nok / self.units) * 100:.1f}%"))
+            r.append(
+                color_counts("Unsatisfied")(
+                    f"{self.nok} unsatisfied {(self.nok / self.units) * 100:.1f}%"
+                )
+            )
         if self.untested > 0:
-            r.append(color_counts("Untested")(f"{self.untested} untested {(self.untested / self.units) * 100:.1f}%"))
+            r.append(
+                color_counts("Untested")(
+                    f"{self.untested} untested {(self.untested / self.units) * 100:.1f}%"
+                )
+            )
         s += color(", ", "white", attrs=["bold"]).join(r)
         s += color(")\n", "white", attrs=["bold"])
         return s
 
+
 class Coverage:
     def __init__(self, specification):
         self.specification = specification
         self.requirements = self.parse_requirements(self.specification)
-        self.counts = Counts("requirements", units=len(self.requirements), ok=0, nok=0, untested=0)
+        self.counts = Counts(
+            "requirements", units=len(self.requirements), ok=0, nok=0, untested=0
+        )
 
     @staticmethod
     def parse_requirements(specification):
         requirements = {}
         parser = Parser()
         tree = parser.parse(specification["specification_content"])
 
         for heading in visit_parse_tree(tree, Visitor()):
             if isinstance(heading, Requirement):
                 requirements[heading.name] = []
 
         return requirements
 
     def calculate(self):
-        """Calculate coverage.
-        """
+        """Calculate coverage."""
         for requirement, tests in self.requirements.items():
             if not tests:
                 self.counts.untested += 1
             else:
-                if sum([0 if test["result"] is not None and test["result"]["result_type"] == "OK" else 1 for test in tests]) == 0:
+                if (
+                    sum(
+                        [
+                            0
+                            if test["result"] is not None
+                            and test["result"]["result_type"] == "OK"
+                            else 1
+                            for test in tests
+                        ]
+                    )
+                    == 0
+                ):
                     self.counts.ok += 1
                 else:
                     self.counts.nok += 1
         return self
 
     def __str__(self):
-        s = color(self.specification["specification_name"], "white", attrs=["bold", "dim"])
+        s = color(
+            self.specification["specification_name"], "white", attrs=["bold", "dim"]
+        )
         s += f"\n  {self.counts}"
         return s
 
     def __contains__(self, requirement_name):
         return requirement_name in self.requirements
 
+
 def format_test(msg, coverages, results):
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
     results[msg["test_id"]] = {"test": msg, "requirements": [], "result": None}
 
+
 def format_specification(msg, coverages, results):
-    flags =  Flags(msg["test_flags"])
-    if flags  & SKIP and settings.show_skipped is False:
+    flags = Flags(msg["test_flags"])
+    if flags & SKIP and settings.show_skipped is False:
         return
     coverages.append(Coverage(msg))
 
+
 def format_requirement(msg, coverages, results):
-    flags =  Flags(msg["test_flags"])
-    if flags  & SKIP and settings.show_skipped is False:
+    flags = Flags(msg["test_flags"])
+    if flags & SKIP and settings.show_skipped is False:
         return
     test_id = msg["test_id"]
     requirement_name = msg["requirement_name"]
 
     if results.get(test_id) is None:
         return
 
     results[test_id]["requirements"].append(msg)
 
     for coverage in coverages:
         if requirement_name in coverage.requirements:
             coverage.requirements[requirement_name].append(results[test_id])
 
+
 def format_result(msg, coverages, results):
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
     test_id = msg["test_id"]
 
     if results.get(test_id) is None:
         return
 
     if not results[test_id]["requirements"]:
         del results[test_id]
     else:
         results[test_id]["result"] = msg
 
+
 formatters = {
     Message.TEST.name: (format_test,),
     Message.SPECIFICATION.name: (format_specification,),
     Message.REQUIREMENT.name: (format_requirement,),
-    Message.RESULT.name: (format_result,)
+    Message.RESULT.name: (format_result,),
 }
 
+
 def generate(coverages, divider):
-    """Generate report.
-    """
+    """Generate report."""
     report = ""
     total_counts = Counts("requirements", units=0, ok=0, nok=0, untested=0)
 
     if coverages:
         report += color(f"{divider}Coverage\n", "white", attrs=["bold"])
 
     for coverage in coverages:
@@ -212,14 +250,15 @@
     if len(coverages) > 1:
         s = color("Total", "white", attrs=["bold", "dim"])
         s += f"\n  {total_counts}"
         report += f"\n{s}"
 
     return report or None
 
+
 def transform(stop, divider="\n"):
     """Totals report.
 
     :param stop: stop event
     """
     line = None
     coverages = []
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/fails.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/fails.py`

 * *Files 4% similar despite different names*

```diff
@@ -19,14 +19,15 @@
 from testflows._core.testtype import TestType
 from testflows._core.message import Message
 from testflows._core.cli.colors import color
 from testflows._core.utils.timefuncs import strftimedelta
 
 indent = " " * 2
 
+
 def color_result(result, attrs=None):
     if attrs is None:
         attrs = ["bold"]
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=attrs)
     elif result == "OK":
         return functools.partial(color, color="green", attrs=attrs)
@@ -37,14 +38,15 @@
     elif result == "Fail":
         return functools.partial(color, color="red", attrs=attrs)
     elif result == "Null":
         return functools.partial(color, color="magenta", attrs=attrs)
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def add_result(msg, results):
     flags = Flags(msg["test_flags"])
     cflags = Flags(msg["test_cflags"])
     result = msg["result_type"]
 
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
         if not result.startswith("X"):
@@ -53,18 +55,20 @@
         return
     if cflags & RETRY:
         return
 
     if not result in ("OK", "Skip"):
         results[msg["test_id"]] = (msg, result)
 
+
 processors = {
     Message.RESULT.name: (add_result,),
 }
 
+
 def generate(results, divider, only_new=False):
     """Generate report"""
     if not results:
         return
 
     retries = ""
     xfails = ""
@@ -73,15 +77,17 @@
     for entry in results:
         msg, result = results[entry]
         _color = color_result(result)
 
         out = _color("\u2718") + f" [ {_color(result)} ] {msg['result_test']}"
         if msg["result_reason"]:
             out += color(f" \u1405 {msg['result_reason']}", "white", attrs=["dim"])
-        out += " " + color("(" + strftimedelta(msg['message_rtime']) + ")", "white", attrs=["dim"])
+        out += " " + color(
+            "(" + strftimedelta(msg["message_rtime"]) + ")", "white", attrs=["dim"]
+        )
         out += "\n"
 
         if result.startswith("X"):
             if not only_new:
                 xfails += out
         else:
             fails += out
@@ -99,14 +105,15 @@
             divider = "\n"
         fails = color(f"{divider}Failing\n\n", "white", attrs=["bold"]) + fails
 
     report = f"{retries}{xfails}{fails}"
 
     return report or None
 
+
 def transform(stop, divider="\n", only_new=False):
     """Transform parsed log line into a short format.
 
     :param stop: stop event
     :param divider: report divider, default: `\n`
     :param only_new: output only new fails, default: `False`
     """
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/metrics.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/metrics.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,31 +13,33 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows.settings as settings
 
 from testflows._core.flags import Flags, SKIP
 from testflows._core.message import Message
 
+
 def format_metric(msg, metrics):
     metrics.append(msg)
 
+
 formatters = {
     Message.METRIC.name: (format_metric,),
 }
 
+
 def transform(metrics):
-    """Transform parsed log into metrics.
-    """
+    """Transform parsed log into metrics."""
     line = None
     while True:
         if line is not None:
             msg = line
             formatter = formatters.get(line["message_keyword"], None)
             if formatter:
                 flags = Flags(line["test_flags"])
                 if flags & SKIP and settings.show_skipped is False:
                     line = None
                 else:
                     line = formatter[0](line, *formatter[1:], metrics)
             else:
                 line = None
-        line = yield line
+        line = yield line
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/passing.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/passing.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,14 +20,15 @@
 from testflows._core.message import Message
 from testflows._core.name import split
 from testflows._core.cli.colors import color
 from testflows._core.utils.timefuncs import strftimedelta
 
 indent = " " * 2
 
+
 def color_result(result, attrs=None):
     if attrs is None:
         attrs = ["bold"]
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=attrs)
     elif result == "OK":
         return functools.partial(color, color="green", attrs=attrs)
@@ -39,56 +40,61 @@
     elif result == "Fail":
         return functools.partial(color, color="red", attrs=attrs)
     elif result == "Null":
         return functools.partial(color, color="magenta", attrs=attrs)
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def add_result(msg, results):
     result = msg["result_type"]
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
         return
     if msg.get("test_parent_type"):
         if getattr(TestType, msg["test_parent_type"]) < TestType.Suite:
             return
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
     if result in ("OK", "Skip"):
         results[msg["test_id"]] = (msg, result)
 
+
 processors = {
     Message.RESULT.name: (add_result,),
 }
 
+
 def generate(results, divider):
     """Generate report"""
     if not results:
         return
 
     passing = ""
 
     for entry in results:
         msg, result = results[entry]
         _color = color_result(result)
         passing += _color("\u2714") + f" [ {_color(result)} ] {msg['result_test']}"
         if msg["result_reason"]:
             passing += color(f" \u1405 {msg['result_reason']}", "white", attrs=["dim"])
-        passing += " " + color("(" + strftimedelta(msg['message_rtime']) + ")", "white", attrs=["dim"])
+        passing += " " + color(
+            "(" + strftimedelta(msg["message_rtime"]) + ")", "white", attrs=["dim"]
+        )
         passing += "\n"
     if passing:
         passing = color(f"{divider}Passing\n\n", "white", attrs=["bold"]) + passing
 
     report = f"{passing}"
 
     return report or None
 
+
 def transform(stop, divider="\n"):
-    """Transform parsed log line into a short format.
-    """
+    """Transform parsed log line into a short format."""
     line = None
     results = {}
     while True:
         if line is not None:
             processor = processors.get(line["message_keyword"], None)
             if processor:
                 processor[0](line, results, *processor[1:])
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/results.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/results.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,88 +11,114 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.name import parentname
 from testflows._core.message import Message
 from testflows._core.transform.log.report.totals import Counts, all_counts
-from testflows._core.transform.log.report.totals import format_test as process_test_counts
-from testflows._core.transform.log.report.totals import format_result as process_result_counts
+from testflows._core.transform.log.report.totals import (
+    format_test as process_test_counts,
+)
+from testflows._core.transform.log.report.totals import (
+    format_result as process_result_counts,
+)
+
 
 def process_test(msg, results, names, unique):
     def add_name(name, names, unique, test_id):
         _name = name
         duplicate = 0
         if name in unique:
             duplicate = unique[name]
             duplicate += 1
-            _name = f'{name} ~{duplicate}'
+            _name = f"{name} ~{duplicate}"
         names[test_id] = _name
         unique[name] = duplicate
         return
 
     add_name(msg["test_name"], names, unique, msg["test_id"])
     test = {
-        "attributes":[], "arguments":[], "tags": [],
-        "specifications": [], "requirements": [],
-        "maps": [], "examples": []
+        "attributes": [],
+        "arguments": [],
+        "tags": [],
+        "specifications": [],
+        "requirements": [],
+        "maps": [],
+        "examples": [],
     }
     test.update(msg)
-    results["tests"][names[msg["test_id"]]] = {"test": test, "result": {"tickets":[], "values":[], "metrics":[]}}
+    results["tests"][names[msg["test_id"]]] = {
+        "test": test,
+        "result": {"tickets": [], "values": [], "metrics": []},
+    }
     process_test_counts(msg, results["counts"])
 
     # add test to the tests map
     parent = parentname(msg["test_id"])
     if results["tests_by_parent"].get(parent) is None:
         results["tests_by_parent"][parent] = []
     results["tests_by_parent"][parent].append(test)
     results["tests_by_id"][msg["test_id"]] = test
 
+
 def process_result(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["result"].update(msg)
     process_result_counts(msg, results["counts"])
 
+
 def process_version(msg, results, names, unique):
     results["version"] = msg["framework_version"]
     results["started"] = msg["message_time"]
 
+
 def process_protocol(msg, results, names, unique):
     results["protocol"] = msg["protocol_version"]
 
+
 def process_attribute(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["test"]["attributes"].append(msg)
 
+
 def process_tag(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["test"]["tags"].append(msg)
 
+
 def process_requirement(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["test"]["requirements"].append(msg)
 
+
 def process_specification(msg, results, names, unique):
     results["specifications"].append(msg)
     results["tests"][names[msg["test_id"]]]["test"]["specifications"].append(msg)
 
+
 def process_argument(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["test"]["arguments"].append(msg)
 
+
 def process_example(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["test"]["examples"].append(msg)
 
+
 def process_map(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["test"]["maps"].append(msg)
 
+
 def process_ticket(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["result"]["tickets"].append(msg)
 
+
 def process_metric(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["result"]["metrics"].append(msg)
 
+
 def process_value(msg, results, names, unique):
     results["tests"][names[msg["test_id"]]]["result"]["values"].append(msg)
 
+
 processors = {
     Message.VERSION.name: process_version,
     Message.PROTOCOL.name: process_protocol,
     Message.TEST.name: process_test,
     Message.RESULT.name: process_result,
     Message.ATTRIBUTE.name: process_attribute,
     Message.TAG.name: process_tag,
@@ -102,17 +128,17 @@
     Message.EXAMPLE.name: process_example,
     Message.MAP.name: process_map,
     Message.TICKET.name: process_ticket,
     Message.METRIC.name: process_metric,
     Message.VALUE.name: process_value,
 }
 
+
 def transform(results):
-    """Transform log file into results.
-    """
+    """Transform log file into results."""
     names = {}
     # unique test names
     unique = {}
 
     if results.get("tests") is None:
         results["tests"] = {}
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/totals.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/totals.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,39 +16,56 @@
 
 from testflows._core.flags import Flags, SKIP, NESTED_RETRY
 from testflows._core.testtype import TestType, TestSubType
 from testflows._core.message import Message
 from testflows._core.utils.timefuncs import strftimedelta
 from testflows._core.cli.colors import color
 
+
 def color_line(line):
     return color(line, "white", attrs=["dim"])
 
+
 def color_result(result, text):
     if result.startswith("X"):
         return color(text, "blue", attrs=["bold"])
     elif result == "OK":
         return color(text, "green", attrs=["bold"])
     elif result == "Skip":
         return color(text, "white", attrs=["dim"])
     # Error, Fail, Null
     elif result == "Error":
         return color(text, "yellow", attrs=["bold"])
     elif result == "Fail":
-         return color(text, "red", attrs=["bold"])
+        return color(text, "red", attrs=["bold"])
     elif result == "Null":
         return color(text, "magenta", attrs=["bold"])
     # Retried
     elif result == "Retried":
         return color(text, "cyan", attrs=["bold"])
     else:
         raise ValueError(f"unknown result {result}")
 
+
 class Counts(object):
-    def __init__(self, name, units, ok, fail, skip, error, null, xok, xfail, xerror, xnull, retried):
+    def __init__(
+        self,
+        name,
+        units,
+        ok,
+        fail,
+        skip,
+        error,
+        null,
+        xok,
+        xfail,
+        xerror,
+        xnull,
+        retried,
+    ):
         self.name = name
         self.units = units
         self.ok = ok
         self.fail = fail
         self.skip = skip
         self.error = error
         self.null = null
@@ -61,15 +78,15 @@
     def __bool__(self):
         return self.units > 0
 
     def __data__(self):
         data = {}
         counts = {}
         data["units"] = self.units
-        data["name"] = self.name if self.units != 1 else self.name.rstrip('s')
+        data["name"] = self.name if self.units != 1 else self.name.rstrip("s")
         data["counts"] = counts
         if self.ok > 0:
             counts["OK"] = self.ok
         if self.fail > 0:
             counts["Fail"] = self.fail
         if self.skip > 0:
             counts["Skip"] = self.skip
@@ -116,14 +133,15 @@
         if r:
             s += color(" (", "white", attrs=["bold"])
             s += color(", ", "white", attrs=["bold"]).join(r)
             s += color(")", "white", attrs=["bold"])
         s += "\n"
         return s
 
+
 def format_test(msg, counts):
     flags = Flags(msg["test_flags"])
 
     if flags & SKIP and settings.show_skipped is False:
         return
 
     test_type = getattr(TestType, msg["test_type"])
@@ -172,14 +190,15 @@
         elif test_subtype == TestSubType.Page:
             counts["page"].units += 1
         elif test_subtype == TestSubType.Section:
             counts["section"].units += 1
         else:
             counts["test"].units += 1
 
+
 def format_result(msg, counts):
     flags = Flags(msg["test_flags"])
     cflags = Flags(msg["test_cflags"])
 
     if flags & SKIP and settings.show_skipped is False:
         return
 
@@ -234,18 +253,17 @@
         elif test_subtype == TestSubType.Page:
             setattr(counts["page"], _name, getattr(counts["page"], _name) + 1)
         elif test_subtype == TestSubType.Section:
             setattr(counts["section"], _name, getattr(counts["section"], _name) + 1)
         else:
             setattr(counts["test"], _name, getattr(counts["test"], _name) + 1)
 
-formatters = {
-    Message.TEST.name: (format_test,),
-    Message.RESULT.name: (format_result,)
-}
+
+formatters = {Message.TEST.name: (format_test,), Message.RESULT.name: (format_result,)}
+
 
 def all_counts():
     return {
         "module": Counts("modules", *([0] * 11)),
         "book": Counts("books", *([0] * 11)),
         "suite": Counts("suites", *([0] * 11)),
         "feature": Counts("features", *([0] * 11)),
@@ -261,17 +279,18 @@
         "check": Counts("checks", *([0] * 11)),
         "critical": Counts("critical", *([0] * 11)),
         "major": Counts("major", *([0] * 11)),
         "minor": Counts("minor", *([0] * 11)),
         "document": Counts("documents", *([0] * 11)),
         "page": Counts("pages", *([0] * 11)),
         "section": Counts("sections", *([0] * 11)),
-        "example": Counts("examples", *([0] * 11))
+        "example": Counts("examples", *([0] * 11)),
     }
 
+
 def transform(stop, divider="\n"):
     """Totals report.
 
     :param stop: stop event
     """
     counts = all_counts()
     line = None
@@ -282,15 +301,15 @@
             formatter = formatters.get(line["message_keyword"], None)
             if formatter:
                 formatter[0](line, *formatter[1:], counts=counts)
             line = None
 
         if stop.is_set():
             line = divider
-            line_icon = "" #"\u27a4 "
+            line_icon = ""  # "\u27a4 "
             if counts["module"]:
                 line += line_icon + str(counts["module"])
             if counts["book"]:
                 line += line_icon + str(counts["book"])
             if counts["suite"]:
                 line += line_icon + str(counts["suite"])
             if counts["feature"]:
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/unstable.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/unstable.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,18 +19,19 @@
 from testflows._core.message import Message
 from testflows._core.name import split, parentname
 from testflows._core.cli.colors import color
 from testflows._core.transform.log.report.totals import Counts, color_result
 
 indent = " " * 2
 
+
 class UnstableCounts(Counts):
     def __str__(self):
         icon = "\u25D4"
-        fail_rate = (self.fail + self.error + self.null)/self.units * 100
+        fail_rate = (self.fail + self.error + self.null) / self.units * 100
         if fail_rate in (0, 100):
             return ""
         fail_rate = color(f"{fail_rate:.2f}%", "cyan", attrs=["bold"])
         s = f"{color(icon, 'cyan', attrs=['bold'])} [ {fail_rate} ] {self.name} ("
         r = []
         if self.ok > 0:
             r.append(color_result("OK", f"{self.ok} ok"))
@@ -53,36 +54,37 @@
         if self.retried > 0:
             r.append(color_result("Retried", f"{self.retried} retried"))
 
         s += color(", ", "white", attrs=["bold"]).join(r)
         s += color(")\n", "white", attrs=["bold"])
         return s
 
+
 def add_result(msg, results):
     flags = Flags(msg["test_flags"])
     cflags = Flags(msg["test_cflags"])
 
     if flags & SKIP and settings.show_skipped is False:
         return
 
-    if (getattr(TestType, msg["test_type"]) == TestType.Iteration
-            and not cflags & RETRY):
+    if getattr(TestType, msg["test_type"]) == TestType.Iteration and not cflags & RETRY:
         result = msg["result_type"]
         parent_id, test_id = split(msg["test_id"])
         if results.get(parent_id) is None:
             results[parent_id] = []
         results[parent_id].append((msg, result))
 
+
 processors = {
     Message.RESULT.name: (add_result,),
 }
 
+
 def generate(results, divider):
-    """Generate report.
-    """
+    """Generate report."""
     if not results:
         return
 
     unstable = ""
 
     for entry in results.values():
         name = parentname(entry[0][0]["test_name"])
@@ -94,20 +96,25 @@
             setattr(counts, result_name, getattr(counts, result_name) + 1)
         _counts = str(counts)
         if _counts:
             _counts += "\n"
         unstable += _counts
 
     if unstable:
-        unstable = color(f"{divider}Unstable\n\n", "white", attrs=["bold"]) + unstable.rstrip() + "\n"
+        unstable = (
+            color(f"{divider}Unstable\n\n", "white", attrs=["bold"])
+            + unstable.rstrip()
+            + "\n"
+        )
 
     report = f"{unstable}"
 
     return report or None
 
+
 def transform(stop, divider="\n"):
     """Generate unstable report.
 
     :param stop: stop event
     :param divider: report divider, default: `\n`
     """
     line = None
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/report/version.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/report/version.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,14 +14,15 @@
 # limitations under the License.
 import time
 
 from testflows._core.cli.colors import color
 from testflows._core.utils.timefuncs import localfromtimestamp
 from testflows._core.message import Message
 
+
 def transform(stop, divider="\n"):
     """Transform parsed log line into a nice format.
 
     :param stop: stop event
     """
     line = None
     version = None
@@ -31,11 +32,17 @@
             if line["message_keyword"] == Message.VERSION.name:
                 version = line["framework_version"]
                 started = localfromtimestamp(line["message_time"])
             line = None
 
         if stop.is_set():
             if started is not None and version is not None:
-                line = color(f"{divider}Executed on {started:%b %d,%Y %-H:%M}\nTestFlows.com Open-Source Software Testing Framework v{version}",
-                    "white", attrs=["dim"]) + "\n"
+                line = (
+                    color(
+                        f"{divider}Executed on {started:%b %d,%Y %-H:%M}\nTestFlows.com Open-Source Software Testing Framework v{version}",
+                        "white",
+                        attrs=["dim"],
+                    )
+                    + "\n"
+                )
 
         line = yield line
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/short.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/manual.py`

 * *Files 27% similar despite different names*

```diff
@@ -18,181 +18,332 @@
 import testflows.settings as settings
 
 from testflows._core.flags import Flags, SKIP, LAST_RETRY
 from testflows._core.testtype import TestType, TestSubType
 from testflows._core.message import Message
 from testflows._core.objects import ExamplesTable
 from testflows._core.name import split, parentname, basename
-from testflows._core.cli.colors import color, cursor_up
+from testflows._core.cli.colors import color, cursor_up, clear_screen
 
 indent = " " * 2
 #: map of tests by name
 tests_by_id = {}
 #: map of tests by parent
 tests_by_parent = {}
 #: last message
 last_message = [None]
 
+separators = {
+    TestType.Module: color("\u2501" * 80, "cyan", attrs=["bold"]) + "\n",
+    TestType.Suite: color("\u2501" * 80, "white", attrs=["dim"]) + "\n",
+    TestType.Test: color("\u2500" * 80, "cyan", attrs=["dim"]) + "\n",
+    TestType.Outline: color("\u2500" * 80, "cyan", attrs=["dim"]) + "\n",
+    TestType.Iteration: color("\u2500" * 80, "yellow", attrs=["dim"]) + "\n",
+    TestType.RetryIteration: color("\u2500" * 80, "white", attrs=["dim"]) + "\n",
+    TestType.Step: "\u2500" * 80 + "\n",
+}
+
+
 def color_other(other, no_colors=False):
     return color(other, "white", attrs=["dim"], no_colors=no_colors)
 
+
 def color_keyword(keyword, no_colors=False):
     return color(split(keyword)[-1], "white", attrs=["bold"], no_colors=no_colors)
 
+
 def color_secondary_keyword(keyword, no_colors=False):
-    return color(split(keyword)[-1], "white", attrs=["bold", "dim"], no_colors=no_colors)
+    return color(
+        split(keyword)[-1], "white", attrs=["bold", "dim"], no_colors=no_colors
+    )
+
+
+def color_test_name(name, no_colors=False):
+    return color(split(name)[-1], "white", attrs=[], no_colors=no_colors)
 
-def color_test_name(name, no_colors=False, use_full_testname=False):
-    if use_full_testname:
-        return color(name, "white", attrs=[], no_colors=no_colors)
-    else:
-        return color(split(name)[-1], "white", attrs=[], no_colors=no_colors)
 
 def color_result(result, attrs=None, no_colors=False, retry=False):
     if attrs is None:
         attrs = ["bold"]
     if result.startswith("X"):
         return functools.partial(color, color="blue", attrs=attrs, no_colors=no_colors)
     elif result == "OK":
         return functools.partial(color, color="green", attrs=attrs, no_colors=no_colors)
     elif result == "Skip":
         return functools.partial(color, color="cyan", attrs=attrs, no_colors=no_colors)
     elif retry:
         return functools.partial(color, color="cyan", attrs=attrs, no_colors=no_colors)
     elif result == "Error":
-        return functools.partial(color, color="yellow", attrs=attrs, no_colors=no_colors)
+        return functools.partial(
+            color, color="yellow", attrs=attrs, no_colors=no_colors
+        )
     elif result == "Fail":
         return functools.partial(color, color="red", attrs=attrs, no_colors=no_colors)
     elif result == "Null":
-        return functools.partial(color, color="magenta", attrs=attrs, no_colors=no_colors)
+        return functools.partial(
+            color, color="magenta", attrs=attrs, no_colors=no_colors
+        )
     else:
         raise ValueError(f"unknown result {result}")
 
+
 def format_input(msg, keyword, no_colors=False):
     out = f"{indent * (msg['test_id'].count('/'))}"
-    out += color("\u270b " + msg["message"], "yellow", attrs=["bold"], no_colors=no_colors) \
-        + cursor_up(no_colors=no_colors) + "\n"
+    out += (
+        color("\u270b " + msg["message"], "white", attrs=["dim"], no_colors=no_colors)
+        + cursor_up(no_colors=no_colors)
+        + "\n"
+    )
     return out
 
+
 def format_prompt(msg, keyword, no_colors=False):
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
-    out = color(icon + lines[0], "yellow", attrs=["bold"], no_colors=no_colors)
+    out = color(icon + lines[0], "white", attrs=["dim"], no_colors=no_colors)
     if len(lines) > 1:
-        out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"], no_colors=no_colors)
+        out += "\n" + color(
+            "\n".join(lines[1:]), "white", attrs=["dim"], no_colors=no_colors
+        )
     return out
 
+
 def format_input(msg, keyword, no_colors=False):
-    out = color(msg['message'], "white", no_colors=no_colors) + "\n"
+    out = color(msg["message"], "white", no_colors=no_colors) + "\n"
     return out
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
-    out = textwrap.indent(out, indent + "  ")
+    out = textwrap.indent(out, indent + "")
     return out
 
+
 def format_test_description(msg, indent, no_colors=False):
     desc = format_multiline(msg["test_description"], indent)
     desc = color(desc, "white", attrs=["dim"], no_colors=no_colors)
     return desc + "\n"
 
+
 def format_specification(msg, no_colors=False):
     out = []
-    _indent = indent * (msg["test_id"].count('/') - 1)
+    _indent = ""
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name:
-        out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Specifications', no_colors=no_colors)}"]
-
-    out.append(color(f"{_indent}{' ' * 4}{msg['specification_name']}", "white", attrs=["dim"], no_colors=no_colors))
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.SPECIFICATION.name
+    ):
+        out = [
+            f"{_indent}{color_secondary_keyword('Specifications', no_colors=no_colors)}"
+        ]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['specification_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     if msg["specification_version"]:
-        out.append(color(f"{_indent}{' ' * 6}version {msg['specification_version']}", "white", attrs=["dim"], no_colors=no_colors))
+        out.append(
+            color(
+                f"{_indent}{' ' * 4}version {msg['specification_version']}",
+                "white",
+                attrs=["dim"],
+                no_colors=no_colors,
+            )
+        )
     return "\n".join(out) + "\n"
 
+
 def format_requirement(msg, no_colors=False):
     out = []
-    _indent = indent * (msg["test_id"].count('/') - 1)
+    _indent = ""
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name:
-        out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Requirements', no_colors=no_colors)}"]
-
-    out.append(color(f"{_indent}{' ' * 4}{msg['requirement_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(f"{_indent}{' ' * 6}version {msg['requirement_version']}", "white", attrs=["dim"], no_colors=no_colors))
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.REQUIREMENT.name
+    ):
+        out = [
+            f"{_indent}{color_secondary_keyword('Requirements', no_colors=no_colors)}"
+        ]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['requirement_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            f"{_indent}{' ' * 4}version {msg['requirement_version']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_attribute(msg, no_colors=False):
     out = []
-    _indent = indent * (msg["test_id"].count('/') - 1)
+    _indent = ""
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name:
-        out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Attributes', no_colors=no_colors)}"]
-
-    out.append(color(f"{_indent}{' ' * 4}{msg['attribute_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(f"{textwrap.indent(str(msg['attribute_value']), prefix=(_indent + ' ' * 6))}", "white", attrs=["dim"], no_colors=no_colors))
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ATTRIBUTE.name
+    ):
+        out = [f"{_indent}{color_secondary_keyword('Attributes', no_colors=no_colors)}"]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['attribute_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            f"{textwrap.indent(str(msg['attribute_value']), prefix=(' ' * 4))}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_tag(msg, no_colors=False):
     out = []
-    _indent = indent * (msg["test_id"].count('/') - 1)
+    _indent = ""
 
     if last_message[0] and not last_message[0]["message_keyword"] == Message.TAG.name:
-        out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Tags', no_colors=no_colors)}"]
+        out = [f"{_indent}{color_secondary_keyword('Tags', no_colors=no_colors)}"]
 
-    out.append(color(f"{_indent}{' ' * 4}{msg['tag_value']}", "white", attrs=["dim"], no_colors=no_colors))
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['tag_value']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_example(msg, no_colors=False):
     out = []
-    _indent = indent * (msg["test_id"].count('/') - 1)
+    _indent = ""
 
-    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(msg["example_columns"], msg["example_values"])
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.EXAMPLE.name:
-        out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Examples', no_colors=no_colors)}"]
-        out.append(color(textwrap.indent(f"{ExamplesTable.__str_header__(tuple(msg['example_columns']),row_format)}",
-            prefix=f"{_indent}{' ' * 4}"), "white", attrs=["dim"], no_colors=no_colors))
-
-    out.append(color(textwrap.indent(f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}",
-        prefix=f"{_indent}{' ' * 4}"), "white", attrs=["dim"], no_colors=no_colors))
+    row_format = msg["example_row_format"] or ExamplesTable.default_row_format(
+        msg["example_columns"], msg["example_values"]
+    )
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.EXAMPLE.name
+    ):
+        out = [f"{_indent}{color_secondary_keyword('Examples', no_colors=no_colors)}"]
+        out.append(
+            color(
+                textwrap.indent(
+                    f"{ExamplesTable.__str_header__(tuple(msg['example_columns']),row_format)}",
+                    prefix=f"{_indent}{' ' * 2}",
+                ),
+                "white",
+                attrs=["dim"],
+                no_colors=no_colors,
+            )
+        )
+
+    out.append(
+        color(
+            textwrap.indent(
+                f"{ExamplesTable.__str_row__(tuple(msg['example_values']),row_format)}",
+                prefix=f"{_indent}{' ' * 2}",
+            ),
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def format_argument(msg, no_colors=False):
     out = []
-    _indent = indent * (msg["test_id"].count('/') - 1)
+    _indent = ""
 
-    if last_message[0] and not last_message[0]["message_keyword"] == Message.ARGUMENT.name:
-        out = [f"{_indent}{' ' * 2}{color_secondary_keyword('Arguments', no_colors=no_colors)}"]
-
-    out.append(color(f"{_indent}{' ' * 4}{msg['argument_name']}", "white", attrs=["dim"], no_colors=no_colors))
-    out.append(color(textwrap.indent(f"{msg['argument_value']}",
-        prefix=f"{_indent}{' ' * 6}"), "white", attrs=["dim"], no_colors=no_colors))
+    if (
+        last_message[0]
+        and not last_message[0]["message_keyword"] == Message.ARGUMENT.name
+    ):
+        out = [f"{_indent}{color_secondary_keyword('Arguments', no_colors=no_colors)}"]
+
+    out.append(
+        color(
+            f"{_indent}{' ' * 2}{msg['argument_name']}",
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
+    out.append(
+        color(
+            textwrap.indent(f"{msg['argument_value']}", prefix=f"{_indent}{' ' * 4}"),
+            "white",
+            attrs=["dim"],
+            no_colors=no_colors,
+        )
+    )
     return "\n".join(out) + "\n"
 
+
 def get_type(msg):
     return getattr(TestType, msg["test_type"])
 
+
 def get_subtype(msg):
     return getattr(TestSubType, str(msg["test_subtype"]), 0)
 
+
 def and_keyword(msg, parent_id, keyword, subtype):
     """Handle processing of Given, When, Then, But, By and Finally
     keywords and convert them to And when necessary.
     """
-    prev = tests_by_parent[parent_id][-2] if len(tests_by_parent.get(parent_id, [])) > 1 else None
-    if prev and get_subtype(prev) == subtype and tests_by_parent.get(prev["test_id"]) is None:
-        keyword = "And"
+    prev = (
+        tests_by_parent[parent_id][-2]
+        if len(tests_by_parent.get(parent_id, [])) > 1
+        else None
+    )
+    if (
+        prev
+        and get_subtype(prev) == subtype
+        and tests_by_parent.get(prev["test_id"]) is None
+    ):
+        keyword = "\u25a1 And"
     parent = tests_by_id.get(parent_id)
-    if parent and get_subtype(parent) == subtype and len(tests_by_parent.get(parent_id, [])) == 1:
-        keyword = "And"
+    if (
+        parent
+        and get_subtype(parent) == subtype
+        and len(tests_by_parent.get(parent_id, [])) == 1
+    ):
+        keyword = "\u25a1 And"
     return keyword
 
+
 def format_test(msg, keyword, tests_by_parent, tests_by_id, no_colors=False):
     # add test to the tests map
     parent = parentname(msg["test_id"])
     if tests_by_parent.get(parent) is None:
         tests_by_parent[parent] = []
     tests_by_parent[parent].append(msg)
     tests_by_id[msg["test_id"]] = msg
@@ -200,133 +351,226 @@
     test_type = get_type(msg)
     test_subtype = get_subtype(msg)
 
     if test_subtype == TestSubType.Example:
         keyword += "Example"
     elif test_type == TestType.Module:
         if test_subtype == TestSubType.Book:
-            keyword += "Book"
+            keyword += "BOOK"
         else:
-            keyword += "Module"
+            keyword += "MODULE"
     elif test_type == TestType.Suite:
         if test_subtype == TestSubType.Feature:
-            keyword += "Feature"
+            keyword += "FEATURE"
         elif test_subtype == TestSubType.Chapter:
-            keyword += "Chapter"
+            keyword += "CHAPTER"
         else:
-            keyword += "Suite"
+            keyword += "SUITE"
     elif test_type == TestType.Iteration:
         keyword += "Iteration"
     elif test_type == TestType.RetryIteration:
         keyword += "Retry"
     elif test_type == TestType.Step:
         if test_subtype == TestSubType.And:
-            keyword += "And"
+            keyword += "\u25a1 And"
         elif test_subtype == TestSubType.Given:
-            keyword += and_keyword(msg, parent, "Given", TestSubType.Given)
+            keyword += and_keyword(msg, parent, "\u25a1 Given", TestSubType.Given)
         elif test_subtype == TestSubType.When:
-            keyword += and_keyword(msg, parent, "When", TestSubType.When)
+            keyword += and_keyword(msg, parent, "\u25a1 When", TestSubType.When)
         elif test_subtype == TestSubType.Then:
-            keyword += and_keyword(msg, parent, "Then", TestSubType.Then)
+            keyword += and_keyword(msg, parent, "\u25a1 Then", TestSubType.Then)
         elif test_subtype == TestSubType.By:
-            keyword += and_keyword(msg, parent, "By", TestSubType.By)
+            keyword += and_keyword(msg, parent, "\u25a1 By", TestSubType.By)
         elif test_subtype == TestSubType.But:
-            keyword += and_keyword(msg, parent, "But", TestSubType.But)
+            keyword += and_keyword(msg, parent, "\u25a1 But", TestSubType.But)
         elif test_subtype == TestSubType.Finally:
-            keyword += and_keyword(msg, parent, "Finally", TestSubType.Finally)
+            keyword += and_keyword(msg, parent, "\u25a1 Finally", TestSubType.Finally)
         elif test_subtype == TestSubType.Cleanup:
-            keyword += and_keyword(msg, parent, "Cleanup", TestSubType.Cleanup)
+            keyword += and_keyword(msg, parent, "\u25a1 Cleanup", TestSubType.Cleanup)
         elif test_subtype == TestSubType.Background:
-            keyword += and_keyword(msg, parent, "Background", TestSubType.Background)
+            keyword += and_keyword(
+                msg, parent, "\u25a1 Background", TestSubType.Background
+            )
         elif test_subtype == TestSubType.Paragraph:
-            keyword += and_keyword(msg, parent, "Paragraph", TestSubType.Paragraph)
+            keyword += and_keyword(
+                msg, parent, "\u25a1 Paragraph", TestSubType.Paragraph
+            )
         else:
-            keyword += "Step"
+            keyword += "\u25a1 Step"
     elif test_type == TestType.Outline:
-        keyword += "Outline"
+        keyword += "OUTLINE"
     else:
         if test_subtype == TestSubType.Scenario:
-            keyword += "Scenario"
+            keyword += "SCENARIO"
         elif test_subtype == TestSubType.Check:
-            keyword += "Check"
+            keyword += "CHECK"
         elif test_subtype == TestSubType.Critical:
-            keyword += "Critical"
+            keyword += "CRITICAL"
         elif test_subtype == TestSubType.Major:
-            keyword += "Major"
+            keyword += "MAJOR"
         elif test_subtype == TestSubType.Minor:
-            keyword += "Minor"
+            keyword += "MINOR"
         elif test_subtype == TestSubType.Recipe:
-            keyword += "Recipe"
+            keyword += "RECIPE"
         elif test_subtype == TestSubType.Document:
-            keyword += "Document"
+            keyword += "DOCUMENT"
         elif test_subtype == TestSubType.Page:
-            keyword += "Page"
+            keyword += "PAGE"
         elif test_subtype == TestSubType.Section:
-            keyword += "Section"
+            keyword += "SECTION"
         else:
-            keyword += "Test"
+            keyword += "TEST"
 
     _keyword = color_keyword(keyword, no_colors=no_colors)
     _name = color_test_name(split(msg["test_name"])[-1], no_colors=no_colors)
-    _indent = indent * (msg["test_id"].count('/') - 1)
-    out = f"{_indent}{_keyword} {_name}\n"
+
+    out = ""
+
+    if test_type > TestType.Step:
+        out += clear_screen()
+
+    if test_type > TestType.Step:
+        out += f"{separators[test_type]}"
+
+    out += f"{_keyword} {_name}\n"
     if msg["test_description"]:
-        out += format_test_description(msg, _indent, no_colors=no_colors)
+        out += format_test_description(msg, "", no_colors=no_colors)
+
+    if test_type > TestType.Step:
+        out += f"{separators[test_type]}"
+
     return out
 
-def format_result(msg, no_colors=False, use_indent=False, use_full_testname=False):
+
+def format_result(msg, no_colors=False):
     result = msg["result_type"]
-    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(msg["test_flags"])
+    test_type = get_type(msg)
+    _retry = get_type(msg) == TestType.RetryIteration and LAST_RETRY not in Flags(
+        msg["test_flags"]
+    )
     _color = color_result(result, no_colors=no_colors, retry=_retry)
-    _result = _color(result, no_colors=no_colors)
-    if use_full_testname:
-        _test = color_test_name(msg["result_test"],
-                    no_colors=no_colors, use_full_testname=use_full_testname)
-    else:
-        _test = color_test_name(basename(msg["result_test"]), no_colors=no_colors)
-
-    if use_indent is False:
-        _indent = indent * (msg["test_id"].count('/') - 1)
-    else:
-        _indent = use_indent
+    _result = _color(f"\u25b6  " + result, no_colors=no_colors)
+    _test = color_test_name(basename(msg["result_test"]), no_colors=no_colors)
+    _indent = ""
 
-    out = f"{_indent}{_result}"
+    out = f"{_result}"
+    out += f", {_test}"
 
     _result_message = msg["result_message"]
     if _result_message and settings.trim_results and int(msg["test_level"]) > 1:
-        _result_message = _result_message.strip().split("\n",1)[0].strip()
+        _result_message = _result_message.strip().split("\n", 1)[0].strip()
 
     if result in ("Fail", "Error", "Null"):
-        out += f" {_test}"
         if _result_message:
             out += color_test_name(",", no_colors=no_colors)
             out += f" {_color(format_multiline(_result_message, _indent).lstrip(), no_colors=no_colors)}"
     elif result.startswith("X"):
-        out += f" {_test}"
         if msg["result_reason"]:
             out += color_test_name(",", no_colors=no_colors)
             out += f" {_color(msg['result_reason'], no_colors=no_colors)}"
-    return out + "\n"
+    elif _result_message:
+        out += color_test_name(",", no_colors=no_colors)
+        out += f" {_color(format_multiline(_result_message, _indent).lstrip(), no_colors=no_colors)}"
+
+    out += "\n"
+
+    if test_type > TestType.Step:
+        out += f"{separators[test_type]}"
+
+    return out
+
+
+def format_message(msg, keyword, prefix="", predicate=None, no_colors=False):
+    out = msg["message"]
+    if msg["message_stream"]:
+        out = f"[{msg['message_stream']}] {msg['message']}"
+    out = out.strip(" ")
+    if out.endswith("\n"):
+        out = out[:-1]
+    out = textwrap.indent(out, prefix=prefix, predicate=predicate)
+    return color_other(
+        f"{keyword}{color_other(out, no_colors=no_colors)}\n", no_colors=no_colors
+    )
+
+
+def format_metric(msg, keyword, no_colors=False):
+    _indent = ""
+    out = [
+        color_other(f"{keyword}", no_colors=no_colors)
+        + color("Metric", "white", attrs=["dim", "bold"], no_colors=no_colors)
+        + color_other(f" {msg['metric_name']}", no_colors=no_colors)
+    ]
+    out.append(
+        color_other(
+            format_multiline(
+                f"{msg['metric_value']} {msg['metric_units']}", _indent + " " * 2
+            ),
+            no_colors=no_colors,
+        )
+    )
+    return "\n".join(out) + "\n"
+
+
+def format_value(msg, keyword, no_colors=False):
+    _indent = ""
+    out = [
+        color_other(f"{keyword}", no_colors=no_colors)
+        + color("Value", "white", attrs=["dim", "bold"], no_colors=no_colors)
+        + color_other(f" {msg['value_name']}", no_colors=no_colors)
+    ]
+    out.append(
+        color_other(
+            format_multiline(f"{msg['value_value']}", _indent + " " * 2),
+            no_colors=no_colors,
+        )
+    )
+    return "\n".join(out) + "\n"
+
+
+def format_ticket(msg, keyword, no_colors=False):
+    _indent = ""
+    out = [
+        color_other(f"{keyword}", no_colors=no_colors)
+        + color("Ticket", "white", attrs=["dim", "bold"], no_colors=no_colors)
+        + color_other(f" {msg['ticket_name']}", no_colors=no_colors)
+    ]
+    out.append(
+        color_other(
+            format_multiline(f"{msg['ticket_link']}", _indent + " " * 2),
+            no_colors=no_colors,
+        )
+    )
+    return "\n".join(out) + "\n"
+
 
 formatters = {
     Message.INPUT.name: (format_input, f""),
     Message.PROMPT.name: (format_prompt, f""),
     Message.TEST.name: (format_test, f"", tests_by_parent, tests_by_id),
     Message.RESULT.name: (format_result,),
     Message.ATTRIBUTE.name: (format_attribute,),
     Message.ARGUMENT.name: (format_argument,),
     Message.SPECIFICATION.name: (format_specification,),
     Message.REQUIREMENT.name: (format_requirement,),
     Message.TAG.name: (format_tag,),
-    Message.EXAMPLE.name: (format_example,)
+    Message.EXAMPLE.name: (format_example,),
+    Message.VALUE.name: (format_value, f""),
+    Message.METRIC.name: (format_metric, f""),
+    Message.TICKET.name: (format_ticket, f""),
+    Message.EXCEPTION.name: (format_message, f""),
+    Message.TEXT.name: (format_message, f"", f"\u270e    ", lambda line: True),
+    Message.NOTE.name: (format_message, f"[note] "),
+    Message.DEBUG.name: (format_message, f"[debug] "),
+    Message.TRACE.name: (format_message, f"[trace] "),
+    Message.NONE.name: (format_message, ""),
 }
 
+
 def transform(no_colors=False, show_input=True):
-    """Transform parsed log line into a short format.
-    """
+    """Transform parsed log line into 'manual' format."""
     line = None
     while True:
         if line is not None:
             msg = line
             formatter = formatters.get(line["message_keyword"], None)
             if formatter:
                 if formatter[0] is format_input and show_input is False:
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/slick.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/slick.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,26 +21,31 @@
 from testflows._core.message import Message
 from testflows._core.objects import ExamplesTable
 from testflows._core.name import split, parentname, basename
 from testflows._core.cli.colors import color, cursor_up
 
 indent = " " * 2
 
+
 def color_other(other):
     return color(other, "white", attrs=["dim"])
 
+
 def color_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["dim"])
 
+
 def color_secondary_keyword(keyword):
     return color(split(keyword)[-1], "white", attrs=["bold", "dim"])
 
+
 def color_test_name(name):
     return color(split(name)[-1], "white", attrs=[])
 
+
 def color_result(result):
     def result_icon(result):
         r = result.lstrip("X")
         if r == "OK":
             return "\u2714"
         elif r == "Skip":
             return "\u2704"
@@ -61,37 +66,41 @@
     elif result == "Error":
         return color(icon, "yellow", attrs=["bold"])
     elif result == "Fail":
         return color(icon, "red", attrs=["bold"])
     # Null
     return color(icon, "magenta", attrs=["bold"])
 
+
 def format_prompt(msg, last_test_id, keyword):
     lines = (msg["message"] or "").splitlines()
     icon = "\u270d  "
     if msg["message"].startswith("Paused"):
         icon = "\u270b "
     out = color(icon + lines[0], "yellow", attrs=["bold"])
     if len(lines) > 1:
         out += "\n" + color("\n".join(lines[1:]), "white", attrs=["dim"])
     return out
 
+
 def format_input(msg, last_test_id, keyword):
-    out = color(msg['message'], "white") + "\n"
+    out = color(msg["message"], "white") + "\n"
     return out
 
+
 def format_multiline(text, indent):
     first, rest = (text.rstrip() + "\n").split("\n", 1)
     first = first.strip()
     if first:
         first += "\n"
     out = f"{first}{textwrap.dedent(rest.rstrip())}".rstrip()
     out = textwrap.indent(out, indent + "  ")
     return out
 
+
 def format_type(msg):
     test_type = getattr(TestType, msg["test_type"])
     test_subtype = getattr(TestSubType, str(msg["test_subtype"]), 0)
 
     if test_subtype == TestSubType.Example:
         return "Example"
     elif test_type == TestType.Module:
@@ -128,83 +137,88 @@
         elif test_subtype == TestSubType.Page:
             return "Page"
         elif test_subtype == TestSubType.Section:
             return "Section"
         else:
             return "Test"
 
+
 def format_test(msg, last_test_id, keyword):
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
 
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
         return
 
-    icon = '\u27A4 '
+    icon = "\u27A4 "
 
     keyword += format_type(msg)
 
     _keyword = color_keyword(keyword)
     _name = color_test_name(split(msg["test_name"])[-1])
-    _indent = indent * (msg["test_id"].count('/') - 1)
+    _indent = indent * (msg["test_id"].count("/") - 1)
     out = f"{_indent}{icon}{_keyword} {_name}\n"
 
     last_test_id.append(msg["test_id"])
 
     return out
 
+
 def format_result(msg, last_test_id):
     result = msg["result_type"]
 
     flags = Flags(msg["test_flags"])
     if flags & SKIP and settings.show_skipped is False:
         return
 
     if getattr(TestType, msg["test_type"]) < TestType.Iteration:
         return
 
     _result = color_result(result)
-    _test = color_keyword(format_type(msg)) + color_test_name(f" {basename(msg['result_test'])}")
+    _test = color_keyword(format_type(msg)) + color_test_name(
+        f" {basename(msg['result_test'])}"
+    )
 
-    _indent = indent * (msg["test_id"].count('/') - 1)
+    _indent = indent * (msg["test_id"].count("/") - 1)
     out = f"{_indent}{_result}"
 
     if last_test_id and last_test_id[-1] == msg["test_id"]:
         out = cursor_up() + "\r" + out
     last_test_id = []
 
     _result_message = msg["result_message"]
     if _result_message and settings.trim_results and int(msg["test_level"]) > 1:
-        _result_message = _result_message.strip().split("\n",1)[0].strip()
+        _result_message = _result_message.strip().split("\n", 1)[0].strip()
 
     if result in ("Fail", "Error", "Null"):
         out += f" {_test}"
         if _result_message:
             out += color_test_name(",")
             out += f" {color(format_multiline(_result_message, _indent).lstrip(), 'yellow', attrs=['bold'])}"
     elif result.startswith("X"):
         out += f" {_test}"
-        if msg['result_reason']:
+        if msg["result_reason"]:
             out += color_test_name(",")
             out += f" {color(msg['result_reason'], 'blue', attrs=['bold'])}"
     else:
         out += f" {_test}"
     return out + "\n"
 
+
 formatters = {
     Message.INPUT.name: (format_input, f""),
     Message.PROMPT.name: (format_prompt, f""),
     Message.TEST.name: (format_test, f""),
-    Message.RESULT.name: (format_result,)
+    Message.RESULT.name: (format_result,),
 }
 
+
 def transform(show_input=True):
-    """Transform parsed log line into a clean format.
-    """
+    """Transform parsed log line into a clean format."""
     last_test_id = []
     line = None
     while True:
         if line is not None:
             formatter = formatters.get(line["message_keyword"], None)
             if formatter:
                 if formatter[0] is format_input and show_input is False:
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/sort.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/sort.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,16 +9,16 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 def transform(msgs, stop=None, key="test_id"):
-    """Sort messages by key.
-    """
+    """Sort messages by key."""
+
     def sorting_key(msg):
         return msg[key]
 
     msgs.sort(key=sorting_key)
 
     length = len(msgs)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/stop.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/stop.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/tests.py` & `testflows.core-1.9.230627.1151633/testflows/core/objects.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,29 +1,22 @@
-# Copyright 2021 Katteli Inc.
+# Copyright 2020 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from testflows._core.testtype import TestType
-
-def transform():
-    """Transform msg to test name.
-    """
-    msg = None
-
-    while True:
-        line = None
-
-        if msg is not None:
-            if getattr(TestType, msg["test_type"]) >= TestType.Test:
-                line = f"{msg['test_name']}\n"
-
-        msg = yield line
+from testflows._core.objects import (
+    Result,
+    XResult,
+    XoutResults,
+    FailResults,
+    PassResults,
+)
+from testflows._core.test import TestDecorator, TestDefinition, TestBase
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/values.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/values.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/transform/log/write.py` & `testflows.core-1.9.230627.1151633/testflows/_core/transform/log/write.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/utils/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/_core/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/utils/enum.py` & `testflows.core-1.9.230627.1151633/testflows/_core/utils/enum.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,10 +10,11 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from enum import IntEnum as IntEnum
 
+
 class IntEnum(IntEnum):
     def __str__(self):
-        return f"{self._name_}"
+        return f"{self._name_}"
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/utils/format.py` & `testflows.core-1.9.230627.1151633/testflows/_core/utils/format.py`

 * *Files 22% similar despite different names*

```diff
@@ -9,19 +9,19 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 def bytesize(nbytes):
-    '''Return human readable size in bytes in
+    """Return human readable size in bytes in
     short form using KB, MB, GB, or TB string.
 
     Credit: https://stackoverflow.com/questions/14996453/python-libraries-to-calculate-human-readable-filesize-from-bytes
-    '''
-    suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']
+    """
+    suffixes = ["B", "KB", "MB", "GB", "TB", "PB"]
     i = 0
-    while nbytes >= 1024 and i < len(suffixes)-1:
-        nbytes /= 1024.
+    while nbytes >= 1024 and i < len(suffixes) - 1:
+        nbytes /= 1024.0
         i += 1
-    f = ('%.2f' % nbytes).rstrip('0').rstrip('.')
-    return '%s %s' % (f, suffixes[i])
+    f = ("%.2f" % nbytes).rstrip("0").rstrip(".")
+    return "%s %s" % (f, suffixes[i])
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/utils/sort.py` & `testflows.core-1.9.230627.1151633/testflows/_core/utils/sort.py`

 * *Files 11% similar despite different names*

```diff
@@ -10,20 +10,21 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import re
 
+
 def human(l, key=None):
     """Sort in human readable format.
 
     Credit: https://blog.codinghorror.com/sorting-for-humans-natural-sort-order/
     :key: optional function to retrieve the key from the element
     """
     get_key = key
     if get_key is None:
         get_key = lambda x: x
     convert = lambda text: int(text) if text.isdigit() else text
-    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', get_key(key)) ]
+    alphanum_key = lambda key: [convert(c) for c in re.split("([0-9]+)", get_key(key))]
     l.sort(key=alphanum_key)
     return l
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/utils/string.py` & `testflows.core-1.9.230627.1151633/testflows/_core/utils/string.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,12 +9,13 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
 def title(s):
     """Convert string to title case keeping any words
     already starting with capital letter as is.
     """
-    return " ".join([w.title() if w.islower() else w for w in s.split()])
+    return " ".join([w.title() if w.islower() else w for w in s.split()])
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/utils/strip.py` & `testflows.core-1.9.230627.1151633/testflows/_core/utils/strip.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,14 +9,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
 def wstrip(s, word, left=True, right=True):
     """Strip word from the beginning or the end of the string.
     By default strips from both sides.
     """
     step = len(word)
     start_pos = None
     end_pos = None
@@ -37,16 +38,16 @@
             end_pos -= step
             found = True
         if not found:
             break
 
     return s[start_pos:end_pos]
 
+
 def lwstrip(s, word):
-    """Strip word only from the left side.
-    """
+    """Strip word only from the left side."""
     return wstrip(s, word, right=False)
 
+
 def rwstrip(s, word):
-    """Strip word only from the right side.
-    """
-    return wstrip(s, word, left=False)
+    """Strip word only from the right side."""
+    return wstrip(s, word, left=False)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/utils/timefuncs.py` & `testflows.core-1.9.230627.1151633/testflows/_core/utils/timefuncs.py`

 * *Files 24% similar despite different names*

```diff
@@ -14,59 +14,64 @@
 # limitations under the License.
 import re
 import time
 
 from datetime import timedelta
 from datetime import datetime
 
+
 def strftime(dt):
-    """Return string representation of datetime.
-    """
+    """Return string representation of datetime."""
     return f"{dt:%b %d,%Y %-H:%M:%S%z}"
 
+
 def localfromtimestamp(timestamp):
     """Convert UTC timestamp to local time.
 
     :param timestamp: UTC timestamp
     """
     utctime = datetime.utcfromtimestamp(timestamp)
     offset = datetime.fromtimestamp(timestamp) - utctime
     return utctime + offset
 
+
 def timestamp():
     """Return epoch timestamp."""
     return time.time()
 
+
 def timestampfromlocal(local):
     """Convert local date time to timestamp.
 
     :param local: local datetime
     """
     return local.timestamp()
 
+
 def timestampfromutc(utc):
     """Convert UTC date time to timestamp.
 
     :param utc: UTC datetime
     """
     return (utc - datetime(1970, 1, 1)).total_seconds()
 
+
 def strftimedelta(td, format=None):
     """Return string representation of timedelta.
 
     :param td: timedelta
     """
     if isinstance(td, (int, float)):
         td = timedelta(seconds=td)
     days = td.days
     hours, left = divmod(int(td.total_seconds()) - (days * 24 * 3600), 3600)
     min, sec = divmod(left, 60)
     ms_float = (td.total_seconds() % 1) * 1000
     ms = int(ms_float)
-    us_float = ((ms_float % 1) * 1000)
+    us_float = (ms_float % 1) * 1000
     us = int(us_float)
 
     if format is None:
         format = "{days}d {hours}h {min}m"
         if days > 0:
             format = "{days}d {hours}h"
         elif hours > 0:
@@ -76,39 +81,37 @@
         elif sec > 0:
             format = "{sec}s {ms}ms"
         elif ms > 0:
             format = "{ms}ms"
         else:
             format = "{us}us"
 
-    return format.format(**{
-        "days": days,
-        "hours": hours,
-        "min": min,
-        "sec": sec,
-        "ms": ms,
-        "us": us
-    })
+    return format.format(
+        **{"days": days, "hours": hours, "min": min, "sec": sec, "ms": ms, "us": us}
+    )
+
 
 def strptimedelta(timelapse):
     """Parse string into timedelta.
 
     Supported format:
         1[d,day,days]1h[r]1m11[.111]s1ms10us
 
     :param timelapse: timelapse string
     """
-    parser = re.compile(r'('
-        '((?P<days>\d+)d|day|days)?'
-        '((?P<hours>\d+)hr?)?'
-        '((?P<min>\d+)m(?!s))?'
-        '((?P<sec>(\d+.\d+)|(\d+))s)?'
-        '((?P<ms>\d+)ms)?'
-        '((?P<us>\d+)us)?'
-    ')?$')
+    parser = re.compile(
+        r"("
+        "((?P<days>\d+)d|day|days)?"
+        "((?P<hours>\d+)hr?)?"
+        "((?P<min>\d+)m(?!s))?"
+        "((?P<sec>(\d+.\d+)|(\d+))s)?"
+        "((?P<ms>\d+)ms)?"
+        "((?P<us>\d+)us)?"
+        ")?$"
+    )
 
     match = parser.match(s)
     if match is None:
         raise ValueError("'%s' time delta string has invalid format" % timelapse)
     match = match.groupdict()
 
     args = {}
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/_core/utils/timer.py` & `testflows.core-1.9.230627.1151633/testflows/_core/utils/timer.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,16 +10,18 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import time
 
+
 class Timer(object):
     """Simple timer."""
+
     def __init__(self, timeout):
         self.timeout = timeout
         self.started = time.time()
         self.stopped = False
         self.stopped_time = None
 
     def reset(self):
@@ -35,8 +37,8 @@
 
     def time(self):
         """Return timer value."""
         if self.stopped:
             return self.stopped_time
         elapsed = time.time() - self.started
         value = max(self.timeout - elapsed, 0)
-        return value
+        return value
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/core/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/core/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -10,53 +10,159 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import testflows._core.contrib.schema as config
 from testflows._core.test import Module, Suite, Test, Step, NullStep
-from testflows._core.test import TestStep, TestCase, TestSuite, TestModule, TestBackground, TestOutline
+from testflows._core.test import (
+    TestStep,
+    TestCase,
+    TestSuite,
+    TestModule,
+    TestBackground,
+    TestOutline,
+)
 from testflows._core.test import Context, SharedContext
 from testflows._core.test import Feature, Background, Scenario, Example, Outline
-from testflows._core.test import Critical, Major, Minor, Check, Given, When, Then, And, But, By, Finally, Cleanup
+from testflows._core.test import (
+    Critical,
+    Major,
+    Minor,
+    Check,
+    Given,
+    When,
+    Then,
+    And,
+    But,
+    By,
+    Finally,
+    Cleanup,
+)
 from testflows._core.test import TestFeature, TestScenario, TestCheck
 from testflows._core.test import loads, ordered, retry, retries, repeat, repeats, define
 from testflows._core.has import has
 from testflows._core.flags import Flags
-from testflows._core.objects import OK, XOK, Fail, XFail, Skip, Error, XError, Null, XNull
-from testflows._core.objects import Name, Description, Uid, Tags, Args, Setup, Parallel, Executor
-from testflows._core.objects import XFails, XFlags, Repeats, Repeat, Retries, Retry, Onlys, Skips
+from testflows._core.objects import (
+    OK,
+    XOK,
+    Fail,
+    XFail,
+    Skip,
+    Error,
+    XError,
+    Null,
+    XNull,
+)
+from testflows._core.objects import (
+    Name,
+    Description,
+    Uid,
+    Tags,
+    Args,
+    Setup,
+    Parallel,
+    Executor,
+)
+from testflows._core.objects import (
+    XFails,
+    XFlags,
+    Repeats,
+    Repeat,
+    Retries,
+    Retry,
+    Onlys,
+    Skips,
+)
 from testflows._core.objects import OnlyTags, SkipTags, Maps
-from testflows._core.objects import FFails, Skipped, Failed, XFailed, XErrored, Okayed, XOkayed
-from testflows._core.objects import Attributes, Requirements, Specifications, Examples, ArgumentParser
-from testflows._core.objects import Node, Tag, Argument, Attribute, Requirement, Specification, Metric, Value, Ticket
+from testflows._core.objects import (
+    FFails,
+    Skipped,
+    Failed,
+    XFailed,
+    XErrored,
+    Okayed,
+    XOkayed,
+)
+from testflows._core.objects import (
+    Attributes,
+    Requirements,
+    Specifications,
+    Examples,
+    ArgumentParser,
+)
+from testflows._core.objects import (
+    Node,
+    Tag,
+    Argument,
+    Attribute,
+    Requirement,
+    Specification,
+    Metric,
+    Value,
+    Ticket,
+)
 from testflows._core.objects import Secret, RSASecret
 from testflows._core.baseobject import Table
 from testflows._core.filters import The
 from testflows._core.funcs import load, append_path, cleanup
 from testflows._core.funcs import main, args, private_key
 from testflows._core.funcs import metric, ticket, value, note, debug, trace, text
 from testflows._core.funcs import attribute, requirement, tag
 from testflows._core.funcs import input, current_time
 from testflows._core.funcs import message, exception, ok, fail, skip, err
-from testflows._core.funcs import result, null, xok, xfail, xerr, xnull, pause, getsattr
-from testflows._core.funcs import current_dir, current_module, load_module, load_submodules
+from testflows._core.funcs import (
+    result,
+    null,
+    xok,
+    xfail,
+    xerr,
+    xnull,
+    pause,
+    getsattr,
+    always,
+)
+from testflows._core.funcs import (
+    current_dir,
+    current_module,
+    load_module,
+    load_submodules,
+)
 from testflows._core.funcs import aslice, chunks
 from testflows._core.flags import TE, UT, SKIP, EOK, EFAIL, EERROR, ESKIP
 from testflows._core.flags import XOK, XFAIL, XERROR, XNULL
 from testflows._core.flags import FAIL_NOT_COUNTED, ERROR_NOT_COUNTED, NULL_NOT_COUNTED
-from testflows._core.flags import PAUSE, PAUSE_BEFORE, PAUSE_AFTER, REPORT, DOCUMENT, MANUAL, AUTO
+from testflows._core.flags import (
+    PAUSE,
+    PAUSE_BEFORE,
+    PAUSE_AFTER,
+    REPORT,
+    DOCUMENT,
+    MANUAL,
+    AUTO,
+)
 from testflows._core.flags import MANDATORY, CLEAR, NOT_REPEATABLE
 from testflows._core.flags import EANY, ERESULT, XRESULT
 from testflows._core.flags import PARALLEL, NO_PARALLEL
 from testflows._core import __author__, __version__, __license__
 from testflows._core.parallel import join, top, current, previous
-from testflows._core.parallel.executor.thread import ThreadPoolExecutor as Pool, ThreadPoolExecutor as ThreadPool, SharedThreadPoolExecutor as SharedThreadPool
-from testflows._core.parallel.executor.asyncio import AsyncPoolExecutor as AsyncPool, SharedAsyncPoolExecutor as SharedAsyncPool
-from testflows._core.parallel.executor.process import ProcessPoolExecutor as ProcessPool, SharedProcessPoolExecutor as SharedProcessPool, process_service
+from testflows._core.parallel.executor.thread import (
+    ThreadPoolExecutor as Pool,
+    ThreadPoolExecutor as ThreadPool,
+    SharedThreadPoolExecutor as SharedThreadPool,
+)
+from testflows._core.parallel.executor.asyncio import (
+    AsyncPoolExecutor as AsyncPool,
+    SharedAsyncPoolExecutor as SharedAsyncPool,
+)
+from testflows._core.parallel.executor.process import (
+    ProcessPoolExecutor as ProcessPool,
+    SharedProcessPoolExecutor as SharedProcessPool,
+    process_service,
+)
 
 import testflows.core.parallel as parallel
 import testflows.core.objects as objects
 import testflows.core.name as name
 
 import testflows._core.utils as utils
 import testflows._core.contrib.rsa as rsa
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/core/exceptions.py` & `testflows.core-1.9.230627.1151633/testflows/core/exceptions.py`

 * *Files identical despite different names*

### Comparing `testflows.core-1.9.230315.1003122/testflows/core/name.py` & `testflows.core-1.9.230627.1151633/testflows/core/name.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,9 +9,18 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.name import match, filter, matchcase, translate, normname, join
-from testflows._core.name import isabs, absname, basename, parentname, depth, split, relname, sep
+from testflows._core.name import (
+    isabs,
+    absname,
+    basename,
+    parentname,
+    depth,
+    split,
+    relname,
+    sep,
+)
 from testflows._core.name import commonprefix, commonname, normcase
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/core/objects.py` & `testflows.core-1.9.230627.1151633/testflows/core/utils.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright 2020 Katteli Inc.
+# Copyright 2019 Katteli Inc.
 # TestFlows.com Open-Source Software Testing Framework (http://testflows.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #      http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from testflows._core.objects import Result, XResult, XoutResults, FailResults, PassResults
-from testflows._core.test import TestDecorator, TestDefinition, TestBase
+from testflows._core.utils.timer import Timer
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/core/parallel.py` & `testflows.core-1.9.230627.1151633/testflows/core/parallel.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,11 +9,24 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from testflows._core.parallel import Context, ContextVar, copy_context
-from testflows._core.parallel.executor.thread import ThreadPoolExecutor as Pool, ThreadPoolExecutor as ThreadPool
-from testflows._core.parallel.executor.thread import SharedThreadPoolExecutor as SharedPool, SharedThreadPoolExecutor as SharedThreadPool
-from testflows._core.parallel.executor.asyncio import AsyncPoolExecutor as AsyncPool, SharedAsyncPoolExecutor as SharedAsyncPool
-from testflows._core.parallel.executor.process import ProcessPoolExecutor as ProcessPool, SharedProcessPoolExecutor as SharedProcessPool, process_service
+from testflows._core.parallel.executor.thread import (
+    ThreadPoolExecutor as Pool,
+    ThreadPoolExecutor as ThreadPool,
+)
+from testflows._core.parallel.executor.thread import (
+    SharedThreadPoolExecutor as SharedPool,
+    SharedThreadPoolExecutor as SharedThreadPool,
+)
+from testflows._core.parallel.executor.asyncio import (
+    AsyncPoolExecutor as AsyncPool,
+    SharedAsyncPoolExecutor as SharedAsyncPool,
+)
+from testflows._core.parallel.executor.process import (
+    ProcessPoolExecutor as ProcessPool,
+    SharedProcessPoolExecutor as SharedProcessPool,
+    process_service,
+)
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/exceptions/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/exceptions/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -11,84 +11,98 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import sys
 import traceback
 
+
 def exception(exc_type=None, exc_value=None, exc_traceback=None):
-    """Get exception string.
-    """
+    """Get exception string."""
     if (exc_type, exc_value, exc_traceback) == (None, None, None):
-        exc_type, exc_value, exc_traceback  = sys.exc_info()
-    return "".join(traceback.format_exception(exc_type, exc_value, exc_traceback)).rstrip()
+        exc_type, exc_value, exc_traceback = sys.exc_info()
+    return "".join(
+        traceback.format_exception(exc_type, exc_value, exc_traceback)
+    ).rstrip()
 
 
 class TestFlowsException(Exception):
-    """Base exception class.
-    """
+    """Base exception class."""
+
     pass
 
+
 class ResultException(TestFlowsException):
-    """Result exception.
-    """
+    """Result exception."""
+
     pass
 
+
 class DummyTestException(TestFlowsException):
-    """Dummy test exception.
-    """
+    """Dummy test exception."""
+
     pass
 
+
 class TestIteration(TestFlowsException):
-    """Repeat test.
-    """
+    """Repeat test."""
+
     def __init__(self, repeat, retry, *args, **kwargs):
         self.repeat = repeat
         self.retry = retry
         super(TestIteration, self).__init__(*args, **kwargs)
 
+
 class TestRerunIndividually(TestFlowsException):
-    """Repeat tests individually.
-    """
+    """Repeat tests individually."""
+
     def __init__(self, tests, *args, **kwargs):
         self.tests = tests
         super(TestRerunIndividually, self).__init__(*args, **kwargs)
 
+
 class TestFlowsError(TestFlowsException):
-    """Base error exception class.
-    """
+    """Base error exception class."""
+
     pass
 
+
 class RequirementError(TestFlowsError):
-    """Requirement error.
-    """
+    """Requirement error."""
+
     pass
 
+
 class SpecificationError(TestFlowsError):
-    """Specification error.
-    """
+    """Specification error."""
+
     pass
 
+
 class DescriptionError(TestFlowsError):
-    """Description error.
-    """
+    """Description error."""
+
     pass
 
+
 class ArgumentError(TestFlowsError):
-    """Argument error.
-    """
+    """Argument error."""
+
     pass
 
+
 class TerminatedError(TestFlowsError):
-    """Terminated error.
-    """
+    """Terminated error."""
+
     pass
 
+
 class ExecutorError(TestFlowsError):
-    """Executor error.
-    """
+    """Executor error."""
+
     pass
 
+
 class ExecutorWorkerError(ExecutorError):
-    """Executor worker error.
-    """
+    """Executor worker error."""
+
     pass
```

### Comparing `testflows.core-1.9.230315.1003122/testflows/settings/__init__.py` & `testflows.core-1.9.230627.1151633/testflows/settings/__init__.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -51,8 +51,8 @@
 #: service timeout
 service_timeout = 0.1
 #: secrets registry
 secrets_registry = None
 #: tracing
 trace = False
 #: license key
-license_key = None
+license_key = None
```

### Comparing `testflows.core-1.9.230315.1003122/testflows.core.egg-info/PKG-INFO` & `testflows.core-1.9.230627.1151633/testflows.core.egg-info/PKG-INFO`

 * *Files 21% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: testflows.core
-Version: 1.9.230315.1003122
+Version: 1.9.230627.1151633
 Summary: TestFlows - Core
 Home-page: https://github.com/testflows/testflows-core
 Author: Vitaliy Zakaznikov
 Author-email: vzakaznikov@testflows.com
 License: Apache-2.0
 Classifier: Development Status :: 2 - Pre-Alpha
 Classifier: Programming Language :: Python :: 3
```

### Comparing `testflows.core-1.9.230315.1003122/testflows.core.egg-info/SOURCES.txt` & `testflows.core-1.9.230627.1151633/testflows.core.egg-info/SOURCES.txt`

 * *Files 0% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 testflows/_core/has.py
 testflows/_core/init.py
 testflows/_core/io.py
 testflows/_core/message.py
 testflows/_core/name.py
 testflows/_core/objects.py
 testflows/_core/serialize.py
-testflows/_core/templog.py
+testflows/_core/temp.py
 testflows/_core/test.py
 testflows/_core/testtype.py
 testflows/_core/tracing.py
 testflows/_core/bin/tfs
 testflows/_core/bin/tfs-worker
 testflows/_core/cli/__init__.py
 testflows/_core/cli/colors.py
```


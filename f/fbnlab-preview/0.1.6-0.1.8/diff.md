# Comparing `tmp/fbnlab_preview-0.1.6-py3-none-any.whl.zip` & `tmp/fbnlab_preview-0.1.8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,45 +1,52 @@
-Zip file size: 32124 bytes, number of entries: 43
--rw-r--r--  2.0 unx      106 b- defN 22-Jul-01 16:40 finbourne_lab/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab/analysis/__init__.py
--rw-r--r--  2.0 unx     9796 b- defN 22-Jul-01 16:40 finbourne_lab/analysis/linear.py
--rw-r--r--  2.0 unx     6291 b- defN 22-Jul-01 16:40 finbourne_lab/analysis/plotting.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab/common/__init__.py
--rw-r--r--  2.0 unx     3535 b- defN 22-Jul-01 16:40 finbourne_lab/common/api_base.py
--rw-r--r--  2.0 unx     8847 b- defN 22-Jul-01 16:40 finbourne_lab/common/base.py
--rw-r--r--  2.0 unx     7142 b- defN 22-Jul-01 16:40 finbourne_lab/common/convener.py
--rw-r--r--  2.0 unx       35 b- defN 22-Jul-01 16:40 finbourne_lab/drive/__init__.py
--rw-r--r--  2.0 unx      934 b- defN 22-Jul-01 16:40 finbourne_lab/drive/experiment.py
--rw-r--r--  2.0 unx      146 b- defN 22-Jul-01 16:40 finbourne_lab/drive/measurements.py
--rw-r--r--  2.0 unx      179 b- defN 22-Jul-01 16:40 finbourne_lab/luminesce/__init__.py
--rw-r--r--  2.0 unx     3404 b- defN 22-Jul-01 16:40 finbourne_lab/luminesce/experiment.py
--rw-r--r--  2.0 unx    19124 b- defN 22-Jul-01 16:40 finbourne_lab/luminesce/measurements.py
--rw-r--r--  2.0 unx     1361 b- defN 22-Jul-01 16:40 finbourne_lab/luminesce/utils.py
--rw-r--r--  2.0 unx       54 b- defN 22-Jul-01 16:40 finbourne_lab/lusid/__init__.py
--rw-r--r--  2.0 unx      964 b- defN 22-Jul-01 16:40 finbourne_lab/lusid/experiment.py
--rw-r--r--  2.0 unx      143 b- defN 22-Jul-01 16:40 finbourne_lab/lusid/measurements.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/integration/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/integration/drive/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/integration/luminesce/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/integration/lusid/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/analysis/__init__.py
--rw-r--r--  2.0 unx     2820 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/analysis/test_linear_scaling_model.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/common/__init__.py
--rw-r--r--  2.0 unx     5619 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/common/test_base_experiment.py
--rw-r--r--  2.0 unx     3377 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/common/test_measurement_set.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/drive/__init__.py
--rw-r--r--  2.0 unx     1048 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/drive/test_drive_experiment.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/luminesce/__init__.py
--rw-r--r--  2.0 unx     4054 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/lusid/__init__.py
--rw-r--r--  2.0 unx     1048 b- defN 22-Jul-01 16:40 finbourne_lab_test/unit/lusid/test_lusid_experiment.py
--rw-r--r--  2.0 unx        0 b- defN 22-Jul-01 16:40 finbourne_lab_test/utils/__init__.py
--rw-r--r--  2.0 unx     2272 b- defN 22-Jul-01 16:40 finbourne_lab_test/utils/mock.py
--rw-r--r--  2.0 unx     1333 b- defN 22-Jul-01 16:40 finbourne_lab_test/utils/test_data_generation.py
--rw-r--r--  2.0 unx      684 b- defN 22-Jul-01 16:40 finbourne_lab_test/utils/test_experiment.py
--rw-r--r--  2.0 unx      496 b- defN 22-Jul-01 16:45 fbnlab_preview-0.1.6.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 22-Jul-01 16:45 fbnlab_preview-0.1.6.dist-info/WHEEL
--rw-r--r--  2.0 unx       33 b- defN 22-Jul-01 16:45 fbnlab_preview-0.1.6.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     4052 b- defN 22-Jul-01 16:45 fbnlab_preview-0.1.6.dist-info/RECORD
-43 files, 88989 bytes uncompressed, 25410 bytes compressed:  71.4%
+Zip file size: 40626 bytes, number of entries: 50
+-rw-r--r--  2.0 unx      106 b- defN 22-Jul-29 08:09 finbourne_lab/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab/analysis/__init__.py
+-rw-r--r--  2.0 unx    10041 b- defN 22-Jul-29 08:09 finbourne_lab/analysis/linear.py
+-rw-r--r--  2.0 unx     6291 b- defN 22-Jul-29 08:09 finbourne_lab/analysis/plotting.py
+-rw-r--r--  2.0 unx      126 b- defN 22-Jul-29 08:09 finbourne_lab/base/__init__.py
+-rw-r--r--  2.0 unx     5885 b- defN 22-Jul-29 08:09 finbourne_lab/base/experiment.py
+-rw-r--r--  2.0 unx     2313 b- defN 22-Jul-29 08:09 finbourne_lab/base/measurement_factory.py
+-rw-r--r--  2.0 unx     1309 b- defN 22-Jul-29 08:09 finbourne_lab/base/result.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab/common/__init__.py
+-rw-r--r--  2.0 unx     3571 b- defN 22-Jul-29 08:09 finbourne_lab/common/api.py
+-rw-r--r--  2.0 unx     8568 b- defN 22-Jul-29 08:09 finbourne_lab/common/convener.py
+-rw-r--r--  2.0 unx       40 b- defN 22-Jul-29 08:09 finbourne_lab/drive/__init__.py
+-rw-r--r--  2.0 unx      934 b- defN 22-Jul-29 08:09 finbourne_lab/drive/experiment.py
+-rw-r--r--  2.0 unx      167 b- defN 22-Jul-29 08:09 finbourne_lab/drive/measurements.py
+-rw-r--r--  2.0 unx      201 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/__init__.py
+-rw-r--r--  2.0 unx     3837 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/experiment.py
+-rw-r--r--  2.0 unx    10469 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/lusid_reader.py
+-rw-r--r--  2.0 unx    13531 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/lusid_writer.py
+-rw-r--r--  2.0 unx     2397 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/measurements.py
+-rw-r--r--  2.0 unx    13211 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/standard.py
+-rw-r--r--  2.0 unx     1361 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/utils.py
+-rw-r--r--  2.0 unx       59 b- defN 22-Jul-29 08:09 finbourne_lab/lusid/__init__.py
+-rw-r--r--  2.0 unx     5190 b- defN 22-Jul-29 08:09 finbourne_lab/lusid/client.py
+-rw-r--r--  2.0 unx      964 b- defN 22-Jul-29 08:09 finbourne_lab/lusid/experiment.py
+-rw-r--r--  2.0 unx      143 b- defN 22-Jul-29 08:09 finbourne_lab/lusid/measurements.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/integration/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/integration/drive/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/integration/luminesce/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/integration/lusid/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/analysis/__init__.py
+-rw-r--r--  2.0 unx     2820 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/analysis/test_linear_scaling_model.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/common/__init__.py
+-rw-r--r--  2.0 unx     5659 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/common/test_base_experiment.py
+-rw-r--r--  2.0 unx     3185 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/common/test_measurement_set.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/drive/__init__.py
+-rw-r--r--  2.0 unx     1058 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/drive/test_drive_experiment.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/luminesce/__init__.py
+-rw-r--r--  2.0 unx     4123 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/lusid/__init__.py
+-rw-r--r--  2.0 unx     1058 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/lusid/test_lusid_experiment.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/utils/__init__.py
+-rw-r--r--  2.0 unx     2277 b- defN 22-Jul-29 08:09 finbourne_lab_test/utils/mock.py
+-rw-r--r--  2.0 unx     1333 b- defN 22-Jul-29 08:09 finbourne_lab_test/utils/test_data_generation.py
+-rw-r--r--  2.0 unx      725 b- defN 22-Jul-29 08:09 finbourne_lab_test/utils/test_experiment.py
+-rw-r--r--  2.0 unx      496 b- defN 22-Jul-29 08:14 fbnlab_preview-0.1.8.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 22-Jul-29 08:14 fbnlab_preview-0.1.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx       33 b- defN 22-Jul-29 08:14 fbnlab_preview-0.1.8.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     4693 b- defN 22-Jul-29 08:14 fbnlab_preview-0.1.8.dist-info/RECORD
+50 files, 118266 bytes uncompressed, 32900 bytes compressed:  72.2%
```

## zipnote {}

```diff
@@ -6,21 +6,30 @@
 
 Filename: finbourne_lab/analysis/linear.py
 Comment: 
 
 Filename: finbourne_lab/analysis/plotting.py
 Comment: 
 
-Filename: finbourne_lab/common/__init__.py
+Filename: finbourne_lab/base/__init__.py
+Comment: 
+
+Filename: finbourne_lab/base/experiment.py
+Comment: 
+
+Filename: finbourne_lab/base/measurement_factory.py
+Comment: 
+
+Filename: finbourne_lab/base/result.py
 Comment: 
 
-Filename: finbourne_lab/common/api_base.py
+Filename: finbourne_lab/common/__init__.py
 Comment: 
 
-Filename: finbourne_lab/common/base.py
+Filename: finbourne_lab/common/api.py
 Comment: 
 
 Filename: finbourne_lab/common/convener.py
 Comment: 
 
 Filename: finbourne_lab/drive/__init__.py
 Comment: 
@@ -33,23 +42,35 @@
 
 Filename: finbourne_lab/luminesce/__init__.py
 Comment: 
 
 Filename: finbourne_lab/luminesce/experiment.py
 Comment: 
 
+Filename: finbourne_lab/luminesce/lusid_reader.py
+Comment: 
+
+Filename: finbourne_lab/luminesce/lusid_writer.py
+Comment: 
+
 Filename: finbourne_lab/luminesce/measurements.py
 Comment: 
 
+Filename: finbourne_lab/luminesce/standard.py
+Comment: 
+
 Filename: finbourne_lab/luminesce/utils.py
 Comment: 
 
 Filename: finbourne_lab/lusid/__init__.py
 Comment: 
 
+Filename: finbourne_lab/lusid/client.py
+Comment: 
+
 Filename: finbourne_lab/lusid/experiment.py
 Comment: 
 
 Filename: finbourne_lab/lusid/measurements.py
 Comment: 
 
 Filename: finbourne_lab_test/__init__.py
@@ -111,20 +132,20 @@
 
 Filename: finbourne_lab_test/utils/test_data_generation.py
 Comment: 
 
 Filename: finbourne_lab_test/utils/test_experiment.py
 Comment: 
 
-Filename: fbnlab_preview-0.1.6.dist-info/METADATA
+Filename: fbnlab_preview-0.1.8.dist-info/METADATA
 Comment: 
 
-Filename: fbnlab_preview-0.1.6.dist-info/WHEEL
+Filename: fbnlab_preview-0.1.8.dist-info/WHEEL
 Comment: 
 
-Filename: fbnlab_preview-0.1.6.dist-info/top_level.txt
+Filename: fbnlab_preview-0.1.8.dist-info/top_level.txt
 Comment: 
 
-Filename: fbnlab_preview-0.1.6.dist-info/RECORD
+Filename: fbnlab_preview-0.1.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## finbourne_lab/analysis/linear.py

```diff
@@ -273,7 +273,16 @@
                 f'x: {self.x} vs {other.x}, y: {self.y} vs {other.y}'
             )
 
         data_l = self.data
         data_r = other.data
         data = pd.concat([data_l, data_r])
         return ScalingModel(data, self.x, self.y, f"{self.x}_{self.y}" if name is None else name)
+
+    def to_csv(self, filepath):
+        """Export the constituent dataset this model is derived from to a CSV
+
+        Args:
+            filepath (str): the path to write the csv at.
+
+        """
+        self.data.to_csv(filepath, index=False)
```

## finbourne_lab/common/convener.py

```diff
@@ -4,95 +4,125 @@
 import uuid
 from pathlib import Path
 from tqdm import tqdm
 
 import numpy as np
 import pandas as pd
 
-from finbourne_lab.common.base import BaseExperiment
+from finbourne_lab.base.experiment import BaseExperiment
 from multiprocessing import Queue
 
 
-# noinspection DuplicatedCode
 class Convener:
     """The convener class looks after the running of experiments and recording their data.
 
     """
 
     def __init__(
             self,
             experiment: BaseExperiment,
             work_dir: str,
             name: str,
             n_obs: int,
-            **kwargs
+            seed=None,
+            err_wait=1,
+            n_parallel=1,
+            soak_time=None,
     ):
         """Constructor of the convener class.
 
         Args:
             experiment (BaseExperiment): the experiment to run.
             work_dir (str): the working directory to write results to.
             name (str): the name of the experiment.
             n_obs (int): number of times to run the experiment and observe values.
-
-        Keyword Args:
-             seed (Optional[int]): random seed to set at the start of the experimental run. Will be chosen randomly if
-             not specified.
-             err_wait (Optional[int]): number of seconds to wait after getting an error.
-             n_parallel (Optional[Union[int, List[int]]]): number of concurrent runs of the experiment to run each time.
+            seed (Optional[int]): random seed to set at the start of the experimental run. Will be chosen randomly if
+            not specified.
+            err_wait (Optional[int]): number of seconds to wait after getting an error.
+            n_parallel (Optional[Union[int, List[int]]]): number of concurrent runs of the experiment to run each time.
+            soak_time (Optional[int]): time in seconds to run repeated experiment iterations for.
 
         """
 
+        self.__validate_concurrency(n_parallel, soak_time)
+
         self.__work_dir = work_dir
         self.__name = name
         self.__experiment = experiment
         self.__n_obs = n_obs
-        self.__seed = kwargs.get('seed', np.random.randint(1989))
-        self.__err_wait = kwargs.get('err_wait', 1)
-        self.__n_parallel = kwargs.get('n_parallel', 1)
+        self.__seed = seed if seed is not None else np.random.randint(1989)
+        self.__err_wait = err_wait
+        self.__n_parallel = n_parallel
+        self.__soak_time = soak_time
         self.__force_stop = False
 
         data_dir = f'{self.__work_dir}/data'
         self.__data_file = f'{data_dir}/{self.__name}.csv'
 
         Path(data_dir).mkdir(parents=True, exist_ok=True)
         Path(f'{self.__work_dir}/plots').mkdir(parents=True, exist_ok=True)
 
+    @staticmethod
+    def __validate_concurrency(n_parallel, soak_time):
+
+        if isinstance(n_parallel, int):
+            _n_parallel = n_parallel
+        elif isinstance(n_parallel, (list, tuple)) and len(n_parallel) == 2:
+            _n_parallel = n_parallel[1]
+        else:
+            raise TypeError(
+                'Input value to n_parallel must be either a single integer or a pair of integers as list/tuple. '
+                f'Was {n_parallel} ({type(n_parallel).__name__}).'
+            )
+
+        if soak_time is None and _n_parallel > 1:
+            raise ValueError(
+                "When running concurrent experiments a value must be given for soak_time when building the convener."
+            )
+
     def __job(self) -> pd.DataFrame:
 
+        np.random.seed(self.__seed + self.__n_obs * 2)
         if isinstance(self.__n_parallel, int):
             n_parallel = self.__n_parallel
-        else:
-            np.random.seed(self.__seed + self.__n_obs*2)
+        elif isinstance(self.__n_parallel, (list, tuple)):
             n_parallel = np.random.randint(self.__n_parallel[0], self.__n_parallel[1] + 1)
+        else:
+            raise ValueError(f"Bad parallelism input: {self.__n_parallel}.")
 
-        queue = Queue()
-        tasks = [self.__experiment.copy(self.__seed) for _ in
-                 range(n_parallel)]
+        def set_seed():
+            if self.__n_parallel == 1:
+                return self.__seed
+            else:
+                return np.random.randint(0, 100000)
+
+        seeds = [set_seed() for _ in range(n_parallel)]
+        tasks = [self.__experiment.copy(s) for s in seeds]
+        queues = [Queue() for _ in range(n_parallel)]
 
         try:
-            for t in tasks:
+            for q, t in zip(queues, tasks):
                 # noinspection PyProtectedMember
-                t._attach_queue(queue)
-                t.start()
+                t._attach_queue(q)._set_soak_time(self.__soak_time).start()
 
             [t.join(force=False) for t in tasks]
 
         except KeyboardInterrupt:
             tqdm.write("\nðŸ›‘ Quitting the experimental run...\n")
             [t.join(force=True) for t in tasks]
             self.__force_stop = True
 
         rows = []
-        while not queue.empty():
-            row = queue.get()
-            row['n_parallel'] = n_parallel
-            rows.append(row)
+        for q in queues:
+            while not q.empty():
+                row = q.get()
+                row['n_parallel'] = n_parallel
+                rows.append(row)
 
-        if len(rows) == 0:
+        if len(rows) == 0 and not self.__force_stop:
             raise ValueError(
                 "Experiment processes produced no outputs. "
                 "There may have been errors in the subprocesses that caused a crash."
             )
 
         return pd.DataFrame(rows)
 
@@ -120,16 +150,17 @@
         start = None
         total_obs = 0
 
         tqdm.write(f"Experiment: {self.__name}")
         tqdm.write(str(self.__experiment))
         tqdm.write(f"Output file: {self.__data_file}")
         tqdm.write(f"Run start: {(run_start + offset).strftime('%Y-%m-%d %H:%M:%S')}")
+
         if self.__n_parallel != 1:
-            tqdm.write(f"Concurrency: {self.__n_parallel}")
+            tqdm.write(f"Concurrency: {self.__n_parallel}  Soak Time: {self.__soak_time}")
 
         pbar = tqdm(
             range(1, self.__n_obs + 1),
             desc=f'{emoji}Doing Science! ',
             unit='Obs',
             total=self.__n_obs,
             bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}'
@@ -158,15 +189,16 @@
                 df = self.__job()
 
                 df['experiment_name'] = self.__name
                 df['run_start'] = run_start
                 experiment_id = str(uuid.uuid4())
                 df['experiment_id'] = experiment_id
 
-                total_obs += df.iloc[0].n_parallel
+                if df.shape[0] > 0:
+                    total_obs += df.iloc[0].n_parallel
 
                 df['run_id'] = run_id
                 df.to_csv(
                     self.__data_file,
                     index=False,
                     mode='a',
                     header=not os.path.exists(self.__data_file)
```

## finbourne_lab/drive/__init__.py

```diff
@@ -1 +1 @@
-from .experiment import Experiment
+from .experiment import DriveExperiment
```

## finbourne_lab/drive/experiment.py

```diff
@@ -1,11 +1,11 @@
-from finbourne_lab.common.api_base import ApiExperiment
+from finbourne_lab.common.api import ApiExperiment
 
 
-class Experiment(ApiExperiment):
+class DriveExperiment(ApiExperiment):
     """Experiment class for the drive api
 
     """
 
     def __init__(self, build_fn, *ranges, **kwargs):
         """Constructor for the Drive API experiment class
```

## finbourne_lab/drive/measurements.py

```diff
@@ -1,6 +1,6 @@
-from finbourne_lab.common.base import BaseMeasurementSet
+from finbourne_lab.base.measurement_factory import BaseMeasurementFactory
 
 
-class MeasurementSet(BaseMeasurementSet):
+class MeasurementSet(BaseMeasurementFactory):
     # Drive measurements go here...
     pass
```

## finbourne_lab/luminesce/__init__.py

```diff
@@ -1,3 +1,3 @@
-from finbourne_lab.luminesce.experiment import Experiment
-from finbourne_lab.luminesce.measurements import MeasurementSet
+from finbourne_lab.luminesce.experiment import LuminesceExperiment
+from finbourne_lab.luminesce.measurements import LuminesceMeasurementFactory
 from finbourne_lab.luminesce.utils import Postprocessing
```

## finbourne_lab/luminesce/experiment.py

```diff
@@ -1,42 +1,45 @@
 import datetime as dt
-from typing import Union, List, Any
+from typing import Union, List, Any, Set
 
 import pandas as pd
-from finbourne_lab.common.base import BaseExperiment, BaseResult
+from finbourne_lab.base.experiment import BaseExperiment
+from finbourne_lab.base.result import BaseResult
 
 
-class Result(BaseResult):
+class LuminesceResult(BaseResult):
     """Class that represents the result for a single luminesce query experiment.
 
     """
 
     def __init__(self):
         """Constructor for the luminesce experiment result class.
 
         """
+        self.send = pd.NaT
         self.submitted = pd.NaT
         self.get = pd.NaT
         self.download_finish = pd.NaT
         self.obs_rows = None
         self.obs_cols = None
+        self.start_query_time = None
         self.query_time = None
         self.download_time = None
         super().__init__()
 
 
-class Experiment(BaseExperiment):
+class LuminesceExperiment(BaseExperiment):
     """Class that encapsulates a luminesce experiment.
 
     """
 
     def __init__(
             self,
             build_fn,
-            *ranges: Union[List[Union[int, float]], Union[int, float]],
+            *ranges: Union[List[Union[int, float]], Any, Set[Any]],
             **kwargs: Any
     ):
         """Constructor for the experiment class.
 
         Args:
             build_fn (Callable): a function that returns a lumipy query object when given a set of values.
             *ranges (Union[List[Union[int, float]], Union[int, float]]): single constant values or ranges to randomly
@@ -61,39 +64,42 @@
     def copy(self, seed: int):
         """Make an independent copy of this experiment object.
 
         Args:
             seed (int): random seed to set in numpy when selecting experiment arg values.
 
         Returns:
-            Experiment: an independent copy of this experiment.
+            LuminesceExperiment: an independent copy of this experiment.
         """
-        return Experiment(self.build_fn, *self._ranges, seed=seed, skip_download=self.skip_download)
+        return LuminesceExperiment(self.build_fn, *self._ranges, seed=seed, skip_download=self.skip_download, keep_for=self.keep_for)
 
-    def _init_result(self) -> Result:
-        return Result()
+    def _init_result(self) -> LuminesceResult:
+        return LuminesceResult()
 
     def _job(self, runnable) -> None:
 
         qry = runnable
 
         if self.should_stop():
             return
 
+        self._return.send = dt.datetime.utcnow()
         job = qry.go_async(keep_for=self.keep_for)
         self._return.execution_id = job.ex_id
         self._return.submitted = dt.datetime.utcnow()
+        self._return.start_query_time = (self._return.submitted - self._return.send).total_seconds()
 
         if self.should_stop():
             return
 
         job.interactive_monitor(True, self.check_period, self.should_stop)
         if job._status == 'Faulted':
-            message = job._progress_lines[-1]
-            raise ValueError(f'Query has ended in an error state:\n\n{message}')
+            message_lines = [l for l in job._progress_lines if l.strip() != '']
+            message = '\n'.join(message_lines[-10:])
+            raise ValueError(f'Query {job.ex_id} has ended in an error state:\n\n{message}')
 
         self._return.get = dt.datetime.utcnow()
         self._return.query_time = (self._return.get - self._return.submitted).total_seconds()
 
         if self.should_stop() or self.skip_download:
             return
```

## finbourne_lab/luminesce/measurements.py

```diff
@@ -1,449 +1,73 @@
-import numpy as np
-from finbourne_lab.luminesce import Experiment
-from finbourne_lab import Convener
-from finbourne_lab.common.base import BaseMeasurementSet
+from finbourne_lab.base.measurement_factory import BaseMeasurementFactory
 
 
-class MeasurementSet(BaseMeasurementSet):
+class LuminesceMeasurementFactory(BaseMeasurementFactory):
     """The standard measurement set for Luminesce
 
     """
 
     def __init__(self, atlas, work_dir):
         """The constructor of the standard measurement set
 
         Args:
             atlas (Atlas): the lumipy atlas to use when running queries.
             work_dir (str): the working directory to use in the conveners of the standard measurement set.
 
         """
         self.atlas = atlas
+        self.n = 10000
+        self.luids = self._get_luids_query().to_table_var()
         super().__init__(work_dir)
 
-    def _reader_test(self, reader, n, x_rng, category, name, n_parallel_set, n_columns=None, check_period=0.1):
+    def _get_luids_query(self):
+        inst = self.atlas.lusid_instrument()
+        return inst.select(
+            inst.lusid_instrument_id,
+            inst.client_internal,
+        ).where(
+            inst.client_internal.str.startswith('lumi-test-instrument-')
+        ).order_by(
+            inst.client_internal.ascending()
+        ).limit(self.n)
+
+    def _ensure_instruments(self):
+
+        # Check the test instruments are there
+        qry = self._get_luids_query()
+        inst_df = qry.go(quiet=True)
+        if inst_df.shape[0] == self.n:
+            print('All test instruments are present.')
+            return
+
+        # Otherwise upsert required test instruments
+        print('Generating test instrument set...')
+        tv = self.atlas.lab_testdata_lusid_instrument().limit(self.n).to_table_var()
+        i_write = self.atlas.lusid_instrument_writer(to_write=tv)
+        i_write.select(
+            i_write.lusid_instrument_id
+        ).order_by(
+            i_write.client_internal.ascending()
+        ).go(quiet=True)
+
+    def _ensure_portfolios(self, n_pf, scope, force):
+
+        # does the scope exist?
+        pf = self.atlas.lusid_portfolio()
+        qry = pf.select(pf.portfolio_scope).where(pf.portfolio_scope == scope).limit(1)
+        scope_exists = qry.go(quiet=True).shape[0] == 1
+
+        # no need to write anything
+        if scope_exists and not force:
+            return scope
+
+        # make the portfolios
+        pf_data = self.atlas.lab_testdata_lusid_portfolio(
+            scope=scope
+        ).select('*').limit(n_pf).to_table_var()
 
-        def build(x):
-            p = reader()
-            select = ['*'] if n_columns is None else p.get_columns()[:n_columns]
-            return p.select(*select).limit(x)
+        pf_write = self.atlas.lusid_portfolio_writer(to_write=pf_data)
+        pf_write.select(pf_write.portfolio_code).limit(1).go(quiet=True)
 
-        e = Experiment(
-            build,
-            x_rng,
-            skip_download=True,
-            check_period=check_period
-        )
+        return scope
 
-        conveners = []
-        for n_p in n_parallel_set:
-            c = Convener(e, self.work_dir + f'/{category}', name + f'_NP{n_p}', n, n_parallel=n_p)
-            conveners.append(c)
 
-        return conveners
-
-    def _file_read_test(self, reader, test_data_path, n, x_rng, name, n_parallel_set, check_period=0.1):
-
-        def fn(x):
-            return reader(file=test_data_path, apply_limit=x).select('*')
-
-        e = Experiment(
-            fn, x_rng,
-            skip_download=True, check_period=check_period
-        )
-
-        conveners = []
-        for n_p in n_parallel_set:
-            c = Convener(e, self.work_dir + '/readers', f'{name}_NP{n_p}', n, n_parallel=n_p)
-            conveners.append(c)
-
-        return conveners
-
-    def _join_test(self, reader, n, x_rng, m, name, n_parallel_set, check_period=0.1):
-
-        if isinstance(x_rng, int):
-            x_rng = [1, x_rng]
-
-        r = reader()
-
-        test_data = r.select(*r.get_columns()[:m]).limit(x_rng[1]).to_table_var('test_data')
-
-        tv = test_data.select('*').limit(x_rng[1]).to_table_var('x')
-
-        def baseline_fn(x):
-            return tv.select('*').limit(1)
-
-        def build_fn(x):
-            tv2 = tv.select('*').limit(x).to_table_var()
-            a = tv2.with_alias('A')
-            b = tv2.with_alias('B')
-            join = a.left_join(b, on=b.i == a.i)
-            return join.select('*')
-
-        convener_pairs = []
-        e = Experiment(build_fn, x_rng, skip_download=True, check_period=check_period)
-        e_base = Experiment(baseline_fn, x_rng, skip_download=True, check_period=check_period)
-
-        for n_p in n_parallel_set:
-            work_dir = self.work_dir + '/core'
-            c = Convener(e, work_dir, name + f'_NP{n_p}', n, n_parallel=n_p)
-            c_base = Convener(e_base, work_dir, name + f'_NP{n_p}_baseline', n, n_parallel=n_p)
-            convener_pairs.append((c_base, c))
-
-        return convener_pairs
-
-    def _writer_test(self, writer, test_data_path, n, x_rng, name, n_parallel_set, check_period=0.1):
-
-        if isinstance(x_rng, int):
-            x_rng = [1, x_rng]
-
-        csv = self.atlas.drive_csv(file=test_data_path, apply_limit=x_rng[1])
-        name = writer.get_name() if name is None else name
-
-        def baseline_fn(x):
-            return csv.select('*').limit(1)
-
-        def writer_fn(x):
-            tv = csv.select('*').limit(x).to_table_var()
-            return writer(to_write=tv).select('*')
-
-        baseline_ex = Experiment(
-            baseline_fn, x_rng,
-            skip_download=True, check_period=check_period
-        )
-        writer_ex = Experiment(
-            writer_fn, x_rng,
-            skip_download=True, check_period=check_period
-        )
-        convener_pairs = []
-
-        for n_p in n_parallel_set:
-            baseline_cv = Convener(baseline_ex, self.work_dir + '/writers', f'{name}_baseline_NP{n_p}', n, n_parallel=n_p)
-            writer_cv = Convener(writer_ex, self.work_dir + '/writers', f'{name}_NP{n_p}', n, n_parallel=n_p)
-            convener_pairs.append((baseline_cv, writer_cv))
-
-        return convener_pairs
-
-    def _file_write_test(self, writer, file_type, n, x_rng, n_cols, name, n_parallel_set, check_period=0.1):
-
-        t = self.atlas.testing10m()
-        name = writer.get_name() if name is None else name
-
-        if isinstance(x_rng, int):
-            x_rng = [1, x_rng]
-
-        def baseline_fn(x):
-            cols = np.random.choice(t.get_columns(), n_cols, replace=False)
-            tv = t.select(*cols).limit(x_rng[1]).to_table_var()
-
-            return tv.select('*').limit(1)
-
-        def writer_fn(x):
-            cols = np.random.choice(t.get_columns(), n_cols, replace=False)
-            tv = t.select(*cols).limit(x_rng[1]).to_table_var()
-
-            tv2 = tv.select('*').limit(x).to_table_var()
-            return writer(
-                tv2,
-                type=file_type,
-                path='/honeycomb/testing/',
-                file_names=f'luminesceTest_{n_cols}Cols'
-            ).select('*')
-
-        baseline_ex = Experiment(
-            baseline_fn, x_rng,
-            skip_download=True, check_period=check_period
-        )
-        writer_ex = Experiment(
-            writer_fn, x_rng,
-            skip_download=True, check_period=check_period
-        )
-        convener_pairs = []
-
-        for n_p in n_parallel_set:
-            baseline_cv = Convener(baseline_ex, self.work_dir + '/writers', f'{name}_cols{n_cols}_baseline_NP{n_p}', n, n_parallel=n_p)
-            writer_cv = Convener(writer_ex, self.work_dir + '/writers', f'{name}_cols{n_cols}_NP{n_p}', n, n_parallel=n_p)
-            convener_pairs.append((baseline_cv, writer_cv))
-
-        return convener_pairs
-
-    def transaction_read_measurement(self, **kwargs):
-        """Create transaction read measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Convener]: list of conveners. One for each degree of parallelism.
-
-        """
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        reader = self.atlas.lusid_portfolio_txn
-        return self._reader_test(reader, n, x_rng, 'lusid/read', 'transaction_read', n_parallel_set)
-
-    def transaction_write_measurement(self, **kwargs):
-        """Create transaction write measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers.
-            txn_write_file (str): path in drive to the CSV containing transactions data to write.
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Tuple[Convener]]: list of convener pairs (first is the baseline measurement second is the main one)
-            There is one pair for each degree of parallelism.
-
-        """
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        path = kwargs.get('txn_write_file', '/honeycomb/testing/luminesceTransactionsTest100k.csv')
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        writer = self.atlas.lusid_portfolio_txn_writer
-        return self._writer_test(writer, path, n, x_rng, 'transaction_write', n_parallel_set)
-
-    def instrument_read_measurement(self, **kwargs):
-        """Create instrument read measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Convener]: list of conveners. One for each degree of parallelism.
-
-        """
-
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        reader = self.atlas.lusid_instrument
-        return self._reader_test(reader, n, x_rng, 'lusid/read', 'instrument_read', n_parallel_set)
-
-    def instrument_write_measurement(self, **kwargs):
-        """Create instrument write measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers.
-            inst_write_file (str): path in drive to the CSV containing instruments data to write.
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Tuple[Convener]]: list of convener pairs (first is the baseline measurement second is the main one)
-            There is one pair for each degree of parallelism.
-
-        """
-
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        path = kwargs.get('inst_write_file', '/honeycomb/testing/luminesceInstrumentsTest100k.csv')
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        writer = self.atlas.lusid_instrument_equity_writer
-        return self._writer_test(writer, path, n, x_rng, 'instrument_write', n_parallel_set)
-
-    def holding_read_measurement(self, **kwargs):
-        """Create instrument read measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Convener]: list of conveners. One for each degree of parallelism.
-
-        """
-
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        reader = self.atlas.lusid_portfolio_holding
-        return self._reader_test(reader, n, x_rng, 'lusid/read', 'holding_read', n_parallel_set)
-
-    def holding_write_measurement(self, **kwargs):
-        """Create holdings write measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers.
-            hld_write_file (str): path in drive to the CSV containing holdings data to write.
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Tuple[Convener]]: list of convener pairs (first is the baseline measurement second is the main one)
-            There is one pair for each degree of parallelism.
-
-        """
-
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        path = kwargs.get('hld_write_file', '/honeycomb/testing/luminesceHoldingsTest100k.csv')
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        writer = self.atlas.lusid_portfolio_holding_writer
-        return self._writer_test(writer, path, n, x_rng, 'holding_write', n_parallel_set)
-
-    def excel_read_measurement(self, **kwargs):
-        """Create drive excel file read measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            xlsx_path (str): path in drive to the xlsx file to use in the measurement.
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Convener]: list of conveners. One for each degree of parallelism.
-
-        """
-
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        path = kwargs.get('xlsx_path', "/honeycomb/testing/luminesceTest100k.xlsx")
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        reader = self.atlas.drive_excel
-        return self._file_read_test(reader, path, n, x_rng, 'excel_read', n_parallel_set)
-
-    def csv_read_measurement(self, **kwargs):
-        """Create drive CSV file read measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            csv_path (str): path in drive to the csv file to use in the measurement.
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Convener]: list of conveners. One for each degree of parallelism.
-
-        """
-
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        path = kwargs.get('csv_path', "/honeycomb/testing/luminesceTest100k.csv")
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        reader = self.atlas.drive_csv
-        return self._file_read_test(reader, path, n, x_rng, 'csv_read', n_parallel_set)
-
-    def excel_write_measurement(self, **kwargs):
-        """Create drive excel write measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            n_cols (int): number of columns to write to the drive excel file
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Tuple[Convener]]: list of convener pairs (first is the baseline measurement second is the main one)
-            There is one pair for each degree of parallelism.
-
-        """
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        n_cols = kwargs.get('n_cols', 50)
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        writer = self.atlas.drive_saveas
-        return self._file_write_test(writer, 'Excel', n, x_rng, n_cols, 'excel_write', n_parallel_set)
-
-    def csv_write_measurement(self, **kwargs):
-        """Create drive CSV write measurement conveners.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            n_columns (int): number of columns to write to the drive CSV file
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Tuple[Convener]]: list of convener pairs (first is the baseline measurement second is the main one)
-            There is one pair for each degree of parallelism.
-
-        """
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        n_cols = kwargs.get('n_cols', 50)
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        writer = self.atlas.drive_saveas
-        return self._file_write_test(writer, 'Csv', n, x_rng, n_cols, 'csv_write', n_parallel_set)
-
-    def view_measurement(self, **kwargs):
-        """Create view read measurement conveners.
-
-        The baseline measurement is how long it takes to query n-many rows with m-many columns from testing10m. The main
-        measurement is how long it takes to do the same thing through a view.
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            n_columns (int): number of columns to query for
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Tuple[Convener]]: list of convener pairs (first is the baseline measurement second is the main one)
-            There is one pair for each degree of parallelism.
-
-        """
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        n_columns = kwargs.get('n_columns', 5)
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        check_period = kwargs.get('check_period', 0.01 if n_columns < 10 else 0.1)
-
-        t10m, t10m_view = self.atlas.testing10m, self.atlas.testing10mview
-        baselines = self._reader_test(t10m, n, x_rng, 'core', f'select_{n_columns}', n_parallel_set, n_columns, check_period)
-        view_tests = self._reader_test(t10m_view, n, x_rng, 'core', f'select_view_{n_columns}', n_parallel_set, n_columns, check_period)
-        return list(zip(baselines, view_tests))
-
-    def join_measurement(self, **kwargs):
-        """Create join measurement conveners.
-
-        The baseline measurement is how long it takes to read data into the table variable that will be joined to itself
-        The main measurement is the read in + the join
-
-        Keyword Args:
-            n_obs (int): the number of observations to make.
-            x_rng (Union[int, List[int]]): the x range of the measurement (number of rows to read). Can be a single
-            integer or a pair of integers. Defaults to [1, 10000]
-            n_columns (int): number of columns on the table that will be joined.
-            n_parallel_set (Optional[List[int]]): a set of parallelism values to create conveners for.
-
-        Returns:
-            List[Tuple[Convener]]: list of convener pairs (first is the baseline measurement second is the main one)
-            There is one pair for each degree of parallelism.
-
-        """
-        n = kwargs.get('n_obs', 100)
-        x_rng = kwargs.get('x_rng', [1, 10000])
-        n_columns = kwargs.get('n_columns', 5)
-        n_parallel_set = kwargs.get('n_parallel_set', (1,))
-
-        check_period = kwargs.get('check_period', 0.01 if n_columns < 10 else 0.1)
-        t10m = self.atlas.testing10m
-        return self._join_test(t10m, n, x_rng, n_columns, 'join' + f'_{n_columns}', n_parallel_set, check_period)
```

## finbourne_lab/lusid/__init__.py

```diff
@@ -1 +1 @@
-from finbourne_lab.lusid.experiment import Experiment
+from finbourne_lab.lusid.experiment import LusidExperiment
```

## finbourne_lab/lusid/experiment.py

```diff
@@ -1,11 +1,11 @@
-from finbourne_lab.common.api_base import ApiExperiment
+from finbourne_lab.common.api import ApiExperiment
 
 
-class Experiment(ApiExperiment):
+class LusidExperiment(ApiExperiment):
     """Experiment class for measuring using LUSID via the LUSID Web API
 
     """
 
     def __init__(self, build_fn, *ranges, **kwargs):
         """Constructor for the Lusid API experiment class
```

## finbourne_lab_test/unit/common/test_base_experiment.py

```diff
@@ -60,22 +60,25 @@
         self.assertEqual(c._Convener__err_wait, 1)
 
         # Sets up the working directory properly
         data_dir = c.data_file_path.replace('convener_build.csv', '')
         self.assertTrue(os.path.exists(data_dir))
         self.assertTrue(os.path.exists(data_dir.replace('/data/', '/plots/')))
 
-        cc = Convener(self.ex, self.work_dir, 'convener_build', 5, seed=1994, n_parallel=10, err_wait=15)
+        cc = Convener(self.ex, self.work_dir, 'convener_build', 5, seed=1994, n_parallel=10, err_wait=15, soak_time=10)
 
         # n parallel can be set
         self.assertEqual(cc._Convener__n_parallel, 10)
 
         # error wait can be set
         self.assertEqual(cc._Convener__err_wait, 15)
 
+        # error wait can be set
+        self.assertEqual(cc._Convener__soak_time, 10)
+
     def test_sequential_base_experiment(self):
 
         c = Convener(self.ex, self.work_dir, 'base_sequential', 5, seed=1989)
         c.go()
         df = c.read_csv()
 
         self.assertEqual(df.shape[0], 5)
@@ -86,29 +89,28 @@
 
         self.assertTrue('arg0' in df.columns and 'arg1' in df.columns)
         self.assertTrue((df.arg1 == 999.0).all())
         self.assertTrue(((df.arg0 >= 1) & (df.arg0 <= 1000)).all())
 
     def test_concurrent_base_experiment(self):
 
-        c = Convener(self.ex, self.work_dir, 'base_concurrent', 5, n_parallel=5, seed=1989)
+        np.random.seed(100)
+        c = Convener(self.ex, self.work_dir, 'base_concurrent', 5, n_parallel=5, seed=1989, soak_time=1)
         c.go()
         df = c.read_csv()
         df['start'] = pd.to_datetime(df.start)
 
-        self.assertEqual(df.shape[0], 25)
         self.assertEqual(df[df.errored].shape[0], 0)
+        self.assertEqual(df.experiment_id.unique().shape[0], 5)
         gdf = df.groupby('experiment_id').agg(
             arg0=('arg0', 'first'),
             start=('start', 'min'),
             n_parallel_exp=('n_parallel', 'first'),
-            n_parallel_obs=('arg0', 'count'),
         ).sort_values('start')
-        self.assertSequenceEqual(gdf.arg0.tolist(), [235, 117, 321, 824, 418])
-        self.assertTrue((gdf.n_parallel_exp == gdf.n_parallel_obs).all())
+        self.assertSequenceEqual(gdf.arg0.tolist(), [203, 170, 909, 140, 385])
         self.assertTrue((df.arg1 == 999.0).all())
         self.assertTrue(((df.arg0 >= 1) & (df.arg0 <= 1000)).all())
 
     def test_sequential_base_experiment_error_capture(self):
 
         c = Convener(self.err_ex, self.work_dir, 'base_sequential_errors', 5, seed=1989)
         c.go()
@@ -119,36 +121,35 @@
         self.assertEqual(err_df.shape[0], 1)
         self.assertTrue(['TEST ERROR' in em for em in err_df.error_message])
         self.assertTrue((df.arg1 == 0.5).all())
         self.assertTrue(((df.arg0 >= 1) & (df.arg0 <= 1000)).all())
 
     def test_concurrent_base_experiment_error_capture(self):
 
-        c = Convener(self.err_ex, self.work_dir, 'base_concurrent_errors', 5, n_parallel=5, seed=1992)
+        c = Convener(self.err_ex, self.work_dir, 'base_concurrent_errors', 5, n_parallel=5, seed=1992, soak_time=1)
         c.go()
         df = c.read_csv()
 
-        self.assertEqual(df.shape[0], 25)
+        self.assertEqual(df.experiment_id.unique().shape[0], 5)
         err_df = df[df.errored]
-        self.assertEqual(err_df.shape[0], 20)
+        self.assertGreater(err_df.shape[0], 0)
         self.assertTrue(['TEST ERROR' in em for em in err_df.error_message])
         self.assertTrue((df.arg1 == 0.5).all())
         self.assertTrue(((df.arg0 >= 1) & (df.arg0 <= 1000)).all())
 
     def test_randomised_concurrency_base_experiment(self):
 
-        c = Convener(self.ex, self.work_dir, 'base_random_concurrent', 5, n_parallel=[1, 5], seed=1992)
+        c = Convener(self.ex, self.work_dir, 'base_random_concurrent', 5, n_parallel=[1, 5], seed=1992, soak_time=1)
         c.go()
         df = c.read_csv()
         df['start'] = pd.to_datetime(df.start)
 
-        self.assertEqual(df.shape[0], 12)
+        self.assertEqual(df.experiment_id.unique().shape[0], 5)
         self.assertEqual(df[df.errored].shape[0], 0)
         gdf = df.groupby('experiment_id').agg(
             arg0=('arg0', 'first'),
             start=('start', 'min'),
             n_parallel_exp=('n_parallel', 'first'),
             n_parallel_obs=('arg0', 'count'),
         ).sort_values('start')
-        self.assertSequenceEqual(gdf.arg0.tolist(), [824, 418, 439, 421, 955])
-        self.assertTrue((gdf.n_parallel_exp == gdf.n_parallel_obs).all())
+        self.assertSequenceEqual(gdf.arg0.tolist(), [677, 293, 44, 122, 685])
         self.assertTrue(((df.n_parallel >= 1) & (df.n_parallel <= 5)).all())
```

## finbourne_lab_test/unit/common/test_measurement_set.py

```diff
@@ -3,25 +3,25 @@
 from pathlib import Path
 from shutil import rmtree
 from time import sleep
 
 import numpy as np
 
 from finbourne_lab import Convener
-from finbourne_lab.common.base import BaseMeasurementSet
+from finbourne_lab.base.measurement_factory import BaseMeasurementFactory
 from finbourne_lab_test.utils.test_experiment import TestExperiment
 
 
-class UndocumentedMockMeasurementSet(BaseMeasurementSet):
+class UndocumentedMockMeasurementSet(BaseMeasurementFactory):
 
     def test1_undocumented_measurement(self, **kwargs):
         pass
 
 
-class MockMeasurementSet(BaseMeasurementSet):
+class MockMeasurementSet(BaseMeasurementFactory):
 
     def __init__(self, work_dir):
         super().__init__(work_dir)
 
     def test1_paired_measurement(self, **kwargs):
 
         """Placeholder 1
@@ -73,15 +73,15 @@
 
         def build(x):
             return lambda: sleep(x*0.01 + 0.5)
 
         ex = TestExperiment(build, [1, x_max])
         conveners = []
         for n_p in parallel_set:
-            c = Convener(ex, self.work_dir, f'test2_NP{n_p}', n_obs, n_parallel=n_p)
+            c = Convener(ex, self.work_dir, f'test2_NP{n_p}', n_obs, n_parallel=n_p, soak_time=1)
             conveners.append(c)
         return conveners
 
 
 class TestMeasurementSet(unittest.TestCase):
 
     work_dir = '/tmp/finbourne_lab_test/measurement_set/'
@@ -114,13 +114,7 @@
 
     def test_measurement_set_convener_list_with_input_kwargs(self):
 
         ms = MockMeasurementSet(self.work_dir)
 
         c_list = ms.list_conveners(n_obs=5, x_max=2000, parallel_set=(1, 50))
         self.assertEqual(5, len(c_list))
-
-    def test_undocumented_measurement_error(self):
-
-        with self.assertRaises(ValueError) as ve:
-            UndocumentedMockMeasurementSet(self.work_dir)
-            self.assertIn('test1_undocumented_measurement', str(ve))
```

## finbourne_lab_test/unit/drive/test_drive_experiment.py

```diff
@@ -2,15 +2,15 @@
 import unittest
 from pathlib import Path
 from shutil import rmtree
 
 from urllib3.response import HTTPResponse
 
 from finbourne_lab import Convener
-from finbourne_lab.drive import Experiment
+from finbourne_lab.drive import DriveExperiment
 from finbourne_lab_test.utils.mock import make_request
 
 
 def api_call(i) -> HTTPResponse:
     return make_request(i, 'drive')
 
 
@@ -28,15 +28,15 @@
         path.mkdir(parents=True, exist_ok=True)
 
     def test_experiment_run(self):
 
         def build(x):
             return lambda: api_call(x)
 
-        ex = Experiment(build, [1, 1000])
+        ex = DriveExperiment(build, [1, 1000])
         c = Convener(ex, self.work_dir, 'run_1', 10)
         c.go()
 
         df = c.read_csv()
 
         self.assertEqual(10, df.shape[0])
         self.assertEqual(0, df[df.client_time.isna()].shape[0])
```

## finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py

```diff
@@ -1,14 +1,14 @@
 import os
 import unittest
 from pathlib import Path
 from shutil import rmtree
 
 from finbourne_lab import Convener
-from finbourne_lab.luminesce import Experiment
+from finbourne_lab.luminesce import LuminesceExperiment
 from finbourne_lab_test.utils.mock import MockQuery
 
 
 class TestLuminesceExperiment(unittest.TestCase):
 
     work_dir = '/tmp/finbourne_lab_test/unit/luminesce/'
 
@@ -38,15 +38,15 @@
         self.assertEqual(qry.call_count, 1)
 
     def test_sequential_experiment(self):
 
         n_experiments = 5
 
         build_fn = MockQuery.build
-        experiment = Experiment(build_fn, [1, 10])
+        experiment = LuminesceExperiment(build_fn, [1, 10])
         convener = Convener(experiment, self.work_dir, 'sequential', n_experiments, seed=1989)
         convener.go()
 
         df = convener.read_csv()
 
         self.assertEqual(df.shape[0], n_experiments)
 
@@ -54,41 +54,41 @@
         self.assertEqual(experiment._ranges, ([1, 10],))
 
     def test_sequential_single_point_experiment(self):
 
         n_experiments = 5
 
         build_fn = MockQuery.build
-        experiment = Experiment(build_fn, 10)
+        experiment = LuminesceExperiment(build_fn, 10)
         convener = Convener(experiment, self.work_dir, 'sequential_sp', n_experiments)
         convener.go()
 
         df = convener.read_csv()
 
         self.assertEqual(df.shape[0], n_experiments)
         self.assertTrue((df.arg0 == 10).all())
 
     def test_concurrent_experiment(self):
 
         n_experiments = 5
         n_parallel = 5
 
         build_fn = MockQuery.build
-        experiment = Experiment(build_fn, [1, 10])
-        convener = Convener(experiment, self.work_dir, 'concurrent', n_experiments, seed=1989, n_parallel=n_parallel)
+        experiment = LuminesceExperiment(build_fn, [1, 10])
+        convener = Convener(experiment, self.work_dir, 'concurrent', n_experiments, seed=1989, n_parallel=n_parallel, soak_time=1)
         convener.go()
 
         df = convener.read_csv()
 
         self.assertEqual(df.shape[0], n_experiments * n_parallel)
 
         for ex_id, ex_df in df.groupby(df.experiment_id):
             self.assertEqual(ex_df.shape[0], n_parallel)
             param_vals = ex_df.arg0.tolist()
-            self.assertTrue(all(p == param_vals[0] for p in param_vals[1:]))
+            self.assertTrue(all(0 < p <= 10 for p in param_vals))
             self.assertTrue(all(e == ex_id for e in ex_df.experiment_id))
             self.assertTrue(all(n == n_parallel for n in ex_df.n_parallel))
 
         self.assertEqual(convener._Convener__n_parallel, 5)
         self.assertEqual(convener._Convener__name, 'concurrent')
         self.assertEqual(convener._Convener__seed, 1989 + n_experiments)
 
@@ -99,30 +99,30 @@
 
     def test_random_concurrency(self):
 
         n_experiments = 5
         n_parallel = [1, 10]
 
         build_fn = MockQuery.build
-        experiment = Experiment(build_fn, [1, 10])
-        convener = Convener(experiment, self.work_dir, 'concurrent_rand', n_experiments, n_parallel=n_parallel)
+        experiment = LuminesceExperiment(build_fn, [1, 10])
+        convener = Convener(experiment, self.work_dir, 'concurrent_rand', n_experiments, n_parallel=n_parallel, soak_time=1)
         convener.go()
 
         df = convener.read_csv()
         gdf = df.groupby('experiment_id').agg(Count=('experiment_id', 'count'))
 
         self.assertGreater(gdf.Count.unique().shape[0], 1)
         self.assertTrue(all(1 <= c <= 10 for c in gdf.Count))
 
     def test_error_catch(self):
 
         n_experiments = 5
 
         build_fn = MockQuery.build
-        experiment = Experiment(build_fn, -1)
+        experiment = LuminesceExperiment(build_fn, -1)
         convener = Convener(experiment, self.work_dir, 'error', n_experiments, err_wait=0)
         convener.go()
 
         df = convener.read_csv()
 
         self.assertEqual(df.shape[0], n_experiments)
         self.assertEqual(df[df.errored].shape[0], n_experiments)
```

## finbourne_lab_test/unit/lusid/test_lusid_experiment.py

```diff
@@ -2,15 +2,15 @@
 import unittest
 from pathlib import Path
 from shutil import rmtree
 
 from urllib3.response import HTTPResponse
 
 from finbourne_lab import Convener
-from finbourne_lab.lusid import Experiment
+from finbourne_lab.lusid import LusidExperiment
 from finbourne_lab_test.utils.mock import make_request
 
 
 def api_call(i) -> HTTPResponse:
     return make_request(i, 'lusid')
 
 
@@ -28,15 +28,15 @@
         path.mkdir(parents=True, exist_ok=True)
 
     def test_experiment_run(self):
 
         def build(x):
             return lambda: api_call(x)
 
-        ex = Experiment(build, [1, 1000])
+        ex = LusidExperiment(build, [1, 1000])
         c = Convener(ex, self.work_dir, 'run_1', 10)
         c.go()
 
         df = c.read_csv()
 
         self.assertEqual(10, df.shape[0])
         self.assertEqual(0, df[df.client_time.isna()].shape[0])
```

## finbourne_lab_test/utils/mock.py

```diff
@@ -22,15 +22,15 @@
     time.sleep(t/1000 + abs(np.random.normal(0, 0.05)))
 
     return HTTPResponse(
         body='{"a":"b"}',
         headers=[
             (f'{app_name}-meta-requestId', f'request_{i}'),
             (f'{app_name}-meta-success', 'true'),
-            (f'{app_name}-meta-duration', str(t)),
+            (f'{app_name}-meta-duration', str(int(t))),
         ]
     )
 
 
 class MockQuery:
     """
```

## finbourne_lab_test/utils/test_experiment.py

```diff
@@ -1,9 +1,10 @@
 from __future__ import annotations
-from finbourne_lab.common.base import BaseExperiment, BaseResult
+from finbourne_lab.base.experiment import BaseExperiment
+from finbourne_lab.base.result import BaseResult
 
 
 class TestExperiment(BaseExperiment):
     """
 
     """
```

## Comparing `finbourne_lab/common/api_base.py` & `finbourne_lab/common/api.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 from __future__ import annotations
 
 import datetime as dt
 
 import pandas as pd
 from urllib3 import HTTPResponse
 
-from finbourne_lab.common.base import BaseResult, BaseExperiment
+from finbourne_lab.base import BaseExperiment
+from finbourne_lab.base import BaseResult
 
 
 class ApiResult(BaseResult):
     """Class that represents the result of a single observation of a Finbourne REST API call.
 
     """
 
@@ -56,15 +57,15 @@
         Returns:
             ApiExperiment: an independent copy of this experiment.
         """
         return type(self)(
             self.build_fn,
             *self._ranges,
             seed=seed,
-            throw_on_failure=self.throw_on_failure
+            throw_on_failure=self.throw_on_failure,
         )
 
     def __str__(self):
         return f"{super().__str__()}  Throw on Fail: {self.throw_on_failure}"
 
     def _init_result(self) -> ApiResult:
         return ApiResult()
@@ -87,13 +88,13 @@
             raise ValueError(
                 f"Received error response from {self.application}: "
                 f"status code = {response.status}, reason = {response.reason}"
             )
 
         self._return.execution_id = response.getheader(f'{self.application}-meta-requestId')
         self._return.failed = not response.getheader(f'{self.application}-meta-success')
-        self._return.server_time = response.getheader(f'{self.application}-meta-duration')
+        self._return.server_time = int(response.getheader(f'{self.application}-meta-duration')) / 1000
 
         if self._return.failed and self.throw_on_failure:
             raise ValueError(
                 f"The response from {self.application} contained failures ({self.application}-meta-success was false)"
             )
```

## Comparing `fbnlab_preview-0.1.6.dist-info/RECORD` & `fbnlab_preview-0.1.8.dist-info/RECORD`

 * *Files 27% similar despite different names*

```diff
@@ -1,43 +1,50 @@
 finbourne_lab/__init__.py,sha256=sPhT5x_mta3SYaJOqNDGI0ECla_jdwX72x5gcFrNQcY,106
 finbourne_lab/analysis/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-finbourne_lab/analysis/linear.py,sha256=45fSNGjTUtoT63YC5IXrF0ALZzIw4LnJs_hPt8CTuFE,9796
+finbourne_lab/analysis/linear.py,sha256=BIB6VLOeQPrrH_VKbflZ6gOLDuv83ZG0ScFT9JD1Hi8,10041
 finbourne_lab/analysis/plotting.py,sha256=GlMO2jAIGI5RVxmPCPEAVWNJJJu-Uyrk98DMcWAhRYA,6291
+finbourne_lab/base/__init__.py,sha256=j0fKW5VfF4sdJCqoFhMthJwlCVaPoOp7sRlt2gqdcus,126
+finbourne_lab/base/experiment.py,sha256=b3Un9Xss7nOJWpkK6cmH9PgZrCm0R8H4E0ekZ6WzG2s,5885
+finbourne_lab/base/measurement_factory.py,sha256=cRsNaxlhobBWWyt5QxVOKcnfbvF6kZEw0ZVsVX-HRJo,2313
+finbourne_lab/base/result.py,sha256=iizA3nt4waaW1bFz_j7Pe8AKtAzUn5NsFXNLcvnTXno,1309
 finbourne_lab/common/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-finbourne_lab/common/api_base.py,sha256=smfgS35LgUDBz0cSQqTtNRRqXXXtuhVdXIJrK1X8r-A,3535
-finbourne_lab/common/base.py,sha256=lmjOMD6YSCADMW5pk6ycnlOoLOP5Zawmm8ffWZZD83M,8847
-finbourne_lab/common/convener.py,sha256=ZTuuOh-xM8TiDmGFryb-K8bEmSHS0emKGUOXG2b5jI8,7142
-finbourne_lab/drive/__init__.py,sha256=WRod1j90DtH9OB3O3_SUXWV64GlKZsXnJNy_VxcCIqg,35
-finbourne_lab/drive/experiment.py,sha256=bU8qhioVqGGI6l48Aa7JQQixw3_rXmp0XBcDVzZzzWg,934
-finbourne_lab/drive/measurements.py,sha256=pZcRC-oxnTbFMqMZCmFWvzt6NISv81j2jKzzie4vhEA,146
-finbourne_lab/luminesce/__init__.py,sha256=dpPlex9r8GRshbr8yilRAPRZsR3Dh1sJGkOum5r1NZk,179
-finbourne_lab/luminesce/experiment.py,sha256=n0GSKDWR-Rsw00TeBPyw0WyQadFsTpN6wCTKQBaQWmk,3404
-finbourne_lab/luminesce/measurements.py,sha256=XampChjHTnScQ3dMxIcxHqbd7tKFRdm7aVqPe22-FT8,19124
+finbourne_lab/common/api.py,sha256=fH8jAUUkuX3NffojWPzBtOh9YjdSaH6w11X8vb6qvGY,3571
+finbourne_lab/common/convener.py,sha256=Ndh3s9uSe-tKFjololW0e9N3-FSVDvcAdRYm9DgOwIs,8568
+finbourne_lab/drive/__init__.py,sha256=eESA3qEw9H_Oho73v2w3_HNsq-3SrZO0AeR1Bz7RCQU,40
+finbourne_lab/drive/experiment.py,sha256=Hl_yw_mIHcMRDmrqI6iv3_0dxFzIMhWRfyAZuSpm6b8,934
+finbourne_lab/drive/measurements.py,sha256=7Vzf99MmIcFq-UHkUoDHjwJtKh_zzVqG56aO0XkleH0,167
+finbourne_lab/luminesce/__init__.py,sha256=rX0d-gAElpJxizMxkjU70rtu89-vPKCY61xgbuX2PUI,201
+finbourne_lab/luminesce/experiment.py,sha256=sy5Rl1-MBcLWGpwKPTyHLXH4-DShWRVKty0-msBRPrk,3837
+finbourne_lab/luminesce/lusid_reader.py,sha256=QUFxD5yTz_hxuP6PymDwK50Vl4UjtyQKi--iNSu8VQ8,10469
+finbourne_lab/luminesce/lusid_writer.py,sha256=RgPGEQuYbKUou4kaFEqchPdbGcatBt9BMVpLVP8FCo4,13531
+finbourne_lab/luminesce/measurements.py,sha256=lTK6F3QzuUzryehX4pvhOXzdC_aexSCt8cWttlK0Z9M,2397
+finbourne_lab/luminesce/standard.py,sha256=4L6h86Q2Ql6ib0ooIKlD-secd8LuWHwYxyuob_j5mWA,13211
 finbourne_lab/luminesce/utils.py,sha256=jDZokJGuoriLwxHvSX4doQcpxni7CA7mKveHu7WfFs0,1361
-finbourne_lab/lusid/__init__.py,sha256=0ouCst8cN3p8zAAYDEQK8d_xSUueY-X8pPj9RA7s7_w,54
-finbourne_lab/lusid/experiment.py,sha256=lVKUUtOQSHdG_1-0sHsylDhVHG7nUD_UMmdAGPfFoWY,964
+finbourne_lab/lusid/__init__.py,sha256=8DznzFIzYp92cuAVHpBMGZknxHOb831Hw-D6dIYx7Js,59
+finbourne_lab/lusid/client.py,sha256=1NnnPMLIchYLcIVDdajUdm7XBR08eNK9UeiEu1wfXOo,5190
+finbourne_lab/lusid/experiment.py,sha256=rUEnSD4NLO9J5zbBKT2XWItCYMJ2APMHtSOfuZkltpA,964
 finbourne_lab/lusid/measurements.py,sha256=7Bgz5wmfVsyCG6Hkgsf6qp8dsioPPESBbgcuiiNVJxI,143
 finbourne_lab_test/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finbourne_lab_test/integration/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finbourne_lab_test/integration/drive/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finbourne_lab_test/integration/luminesce/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finbourne_lab_test/integration/lusid/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finbourne_lab_test/unit/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finbourne_lab_test/unit/analysis/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 finbourne_lab_test/unit/analysis/test_linear_scaling_model.py,sha256=5Tfby-3qMmHxl3XamI_eYbdAaff7dZZw_yG9kEbmakc,2820
 finbourne_lab_test/unit/common/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-finbourne_lab_test/unit/common/test_base_experiment.py,sha256=Ifv37fl_HivJW1628T80dBO-ICRKdzr-D_6NLKACUHc,5619
-finbourne_lab_test/unit/common/test_measurement_set.py,sha256=UNjX6A79AhpxlkmGvWw-XWAaxg_rCgL9aXeBMFtJR4E,3377
+finbourne_lab_test/unit/common/test_base_experiment.py,sha256=aXGNjseyEG01bAFxVQxvYI66gG6xa5gLBpeOQbyASZg,5659
+finbourne_lab_test/unit/common/test_measurement_set.py,sha256=qlBs29C5Emhm8SrqvBsE3buwHKmHari-RAfG8F4ksrw,3185
 finbourne_lab_test/unit/drive/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-finbourne_lab_test/unit/drive/test_drive_experiment.py,sha256=xkBsB1Ye-WFhZcErz9Iu2vXsxIIrPcwpOksBxxO0WCs,1048
+finbourne_lab_test/unit/drive/test_drive_experiment.py,sha256=7cdaSqkApITWlCH6F8vGTUwwBLJAwGvYPcuK6gAXwLo,1058
 finbourne_lab_test/unit/luminesce/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py,sha256=DwOOeWKVKldngumJcKy8923To0V5L8rokWv2OLL-wUc,4054
+finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py,sha256=Ry24qIFhw7y0q63B4EhMQstQwWBlLo--ITW1AV0NNQE,4123
 finbourne_lab_test/unit/lusid/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-finbourne_lab_test/unit/lusid/test_lusid_experiment.py,sha256=5uiaoQhlb3I7DM2WLMo3a4y6nTA9OjGHMsKXeQw2Fgg,1048
+finbourne_lab_test/unit/lusid/test_lusid_experiment.py,sha256=L4W0zp7llg35sMlVVotfFScqxur3niByjeQwocd9ggE,1058
 finbourne_lab_test/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-finbourne_lab_test/utils/mock.py,sha256=OTcSpNlEvm2FNJjk-ry0mSD_Sypr7UBQgV8QDmpbD6E,2272
+finbourne_lab_test/utils/mock.py,sha256=i0g865n0MPtC8FJgh3jJFYJIimiEGClhM7eHA7tm6sE,2277
 finbourne_lab_test/utils/test_data_generation.py,sha256=6y3E8IEnz4x_mC-S-r65WGLiznZj_4WaJLOUnVFfq7U,1333
-finbourne_lab_test/utils/test_experiment.py,sha256=3Lhqjbrp0YhWhbwfoQwYZp9oOw5orBRn6UVQhfhdV8w,684
-fbnlab_preview-0.1.6.dist-info/METADATA,sha256=0jWiaH5vupoX2RA9mWeJxe5vHIdpbKLwX1io4rJccvo,496
-fbnlab_preview-0.1.6.dist-info/WHEEL,sha256=p46_5Uhzqz6AzeSosiOnxK-zmFja1i22CrQCjmYe8ec,92
-fbnlab_preview-0.1.6.dist-info/top_level.txt,sha256=sGYMyzhu-JJjhEpwQ3l5Wj8JBLup5AVrsYV1hbK44y0,33
-fbnlab_preview-0.1.6.dist-info/RECORD,,
+finbourne_lab_test/utils/test_experiment.py,sha256=zYl9a1B7lVQE52BUQ9JK6KlGCJthZan_VVbXTFZbr4U,725
+fbnlab_preview-0.1.8.dist-info/METADATA,sha256=ms88jDeAUJAzaVuiahf--azWVQpisTsNp9wwn2r4P90,496
+fbnlab_preview-0.1.8.dist-info/WHEEL,sha256=p46_5Uhzqz6AzeSosiOnxK-zmFja1i22CrQCjmYe8ec,92
+fbnlab_preview-0.1.8.dist-info/top_level.txt,sha256=sGYMyzhu-JJjhEpwQ3l5Wj8JBLup5AVrsYV1hbK44y0,33
+fbnlab_preview-0.1.8.dist-info/RECORD,,
```

